{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个代码每个epoch都跑一遍训练集和验证集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "shuffle = True\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载resnet101预训练模型\n",
    "model = models.resnet101(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=50) for x in ['train', 'validation']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]:\n",
      "\ttrain 1-1: Loss: 0.2172 Acc: 50.0000%\n",
      "\ttrain 1-2: Loss: 0.1553 Acc: 75.0000%\n",
      "\ttrain 1-3: Loss: 0.1322 Acc: 100.0000%\n",
      "\ttrain 1-4: Loss: 0.1555 Acc: 50.0000%\n",
      "\ttrain 1-5: Loss: 0.0831 Acc: 100.0000%\n",
      "\ttrain 1-6: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 1-7: Loss: 0.4059 Acc: 50.0000%\n",
      "\ttrain 1-8: Loss: 0.2262 Acc: 25.0000%\n",
      "\ttrain 1-9: Loss: 0.2206 Acc: 50.0000%\n",
      "\ttrain 1-10: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 1-11: Loss: 0.1623 Acc: 50.0000%\n",
      "\ttrain 1-12: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 1-13: Loss: 0.2974 Acc: 50.0000%\n",
      "\ttrain 1-14: Loss: 0.2053 Acc: 50.0000%\n",
      "\ttrain 1-15: Loss: 0.2544 Acc: 50.0000%\n",
      "\ttrain 1-16: Loss: 0.2401 Acc: 50.0000%\n",
      "\ttrain 1-17: Loss: 0.1598 Acc: 75.0000%\n",
      "\ttrain 1-18: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 1-19: Loss: 0.2552 Acc: 50.0000%\n",
      "\ttrain 1-20: Loss: 0.2597 Acc: 50.0000%\n",
      "\ttrain 1-21: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 1-22: Loss: 0.1961 Acc: 75.0000%\n",
      "\ttrain 1-23: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 1-24: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 1-25: Loss: 0.2565 Acc: 75.0000%\n",
      "\ttrain 1-26: Loss: 0.4270 Acc: 50.0000%\n",
      "\ttrain 1-27: Loss: 0.3813 Acc: 50.0000%\n",
      "\ttrain 1-28: Loss: 0.2473 Acc: 50.0000%\n",
      "\ttrain 1-29: Loss: 0.2306 Acc: 50.0000%\n",
      "\ttrain 1-30: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 1-31: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 1-32: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 1-33: Loss: 0.4822 Acc: 25.0000%\n",
      "\ttrain 1-34: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 1-35: Loss: 0.3668 Acc: 50.0000%\n",
      "\ttrain 1-36: Loss: 0.6353 Acc: 25.0000%\n",
      "\ttrain 1-37: Loss: 0.7086 Acc: 25.0000%\n",
      "\ttrain 1-38: Loss: 0.5952 Acc: 50.0000%\n",
      "\ttrain 1-39: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 1-40: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 1-41: Loss: 0.3697 Acc: 75.0000%\n",
      "\ttrain 1-42: Loss: 0.1128 Acc: 100.0000%\n",
      "\ttrain 1-43: Loss: 0.2199 Acc: 50.0000%\n",
      "\ttrain 1-44: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 1-45: Loss: 0.3074 Acc: 0.0000%\n",
      "\ttrain 1-46: Loss: 0.4185 Acc: 25.0000%\n",
      "\ttrain 1-47: Loss: 0.1816 Acc: 75.0000%\n",
      "\ttrain 1-48: Loss: 0.1712 Acc: 50.0000%\n",
      "\ttrain 1-49: Loss: 0.1050 Acc: 100.0000%\n",
      "\ttrain 1-50: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 1-51: Loss: 0.1394 Acc: 100.0000%\n",
      "\ttrain 1-52: Loss: 0.4699 Acc: 25.0000%\n",
      "\ttrain 1-53: Loss: 0.4633 Acc: 0.0000%\n",
      "\ttrain 1-54: Loss: 0.1802 Acc: 25.0000%\n",
      "\ttrain 1-55: Loss: 0.1486 Acc: 50.0000%\n",
      "\ttrain 1-56: Loss: 0.1586 Acc: 50.0000%\n",
      "\ttrain 1-57: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 1-58: Loss: 0.4115 Acc: 50.0000%\n",
      "\ttrain 1-59: Loss: 0.2103 Acc: 50.0000%\n",
      "\ttrain 1-60: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 1-61: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 1-62: Loss: 0.2203 Acc: 50.0000%\n",
      "\ttrain 1-63: Loss: 0.2489 Acc: 75.0000%\n",
      "\ttrain 1-64: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 1-65: Loss: 0.4624 Acc: 50.0000%\n",
      "\ttrain 1-66: Loss: 0.2704 Acc: 50.0000%\n",
      "\ttrain 1-67: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 1-68: Loss: 0.2352 Acc: 50.0000%\n",
      "\ttrain 1-69: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 1-70: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 1-71: Loss: 0.3720 Acc: 75.0000%\n",
      "\ttrain 1-72: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 1-73: Loss: 0.6408 Acc: 0.0000%\n",
      "\ttrain 1-74: Loss: 0.3196 Acc: 50.0000%\n",
      "\ttrain 1-75: Loss: 0.3955 Acc: 25.0000%\n",
      "\ttrain 1-76: Loss: 0.3119 Acc: 50.0000%\n",
      "\ttrain 1-77: Loss: 0.1953 Acc: 50.0000%\n",
      "\ttrain 1-78: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 1-79: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 1-80: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 1-81: Loss: 0.4767 Acc: 25.0000%\n",
      "\ttrain 1-82: Loss: 0.3593 Acc: 50.0000%\n",
      "\ttrain 1-83: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 1-84: Loss: 0.2512 Acc: 50.0000%\n",
      "\ttrain 1-85: Loss: 0.3449 Acc: 50.0000%\n",
      "\ttrain 1-86: Loss: 0.2334 Acc: 75.0000%\n",
      "\ttrain 1-87: Loss: 0.2298 Acc: 50.0000%\n",
      "\ttrain 1-88: Loss: 0.2035 Acc: 50.0000%\n",
      "\ttrain 1-89: Loss: 0.0940 Acc: 100.0000%\n",
      "\ttrain 1-90: Loss: 0.1780 Acc: 100.0000%\n",
      "\ttrain 1-91: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 1-92: Loss: 0.1817 Acc: 50.0000%\n",
      "\ttrain 1-93: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 1-94: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 1-95: Loss: 0.5606 Acc: 25.0000%\n",
      "\ttrain 1-96: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 1-97: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 1-98: Loss: 0.8511 Acc: 25.0000%\n",
      "\ttrain 1-99: Loss: 0.3697 Acc: 50.0000%\n",
      "\ttrain 1-100: Loss: 0.5533 Acc: 25.0000%\n",
      "\ttrain 1-101: Loss: 0.6083 Acc: 50.0000%\n",
      "\ttrain 1-102: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 1-103: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 1-104: Loss: 0.2898 Acc: 50.0000%\n",
      "\ttrain 1-105: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 1-106: Loss: 0.2947 Acc: 50.0000%\n",
      "\ttrain 1-107: Loss: 0.4838 Acc: 50.0000%\n",
      "\ttrain 1-108: Loss: 0.2440 Acc: 75.0000%\n",
      "\ttrain 1-109: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 1-110: Loss: 0.1842 Acc: 50.0000%\n",
      "\ttrain 1-111: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 1-112: Loss: 0.3237 Acc: 25.0000%\n",
      "\ttrain 1-113: Loss: 0.3987 Acc: 75.0000%\n",
      "\ttrain 1-114: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 1-115: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 1-116: Loss: 0.0897 Acc: 100.0000%\n",
      "\ttrain 1-117: Loss: 0.5017 Acc: 50.0000%\n",
      "\ttrain 1-118: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 1-119: Loss: 0.1927 Acc: 75.0000%\n",
      "\ttrain 1-120: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 1-121: Loss: 0.2654 Acc: 75.0000%\n",
      "\ttrain 1-122: Loss: 0.6169 Acc: 50.0000%\n",
      "\ttrain 1-123: Loss: 0.1335 Acc: 100.0000%\n",
      "\ttrain 1-124: Loss: 0.1826 Acc: 75.0000%\n",
      "\ttrain 1-125: Loss: 0.5762 Acc: 50.0000%\n",
      "\ttrain 1-126: Loss: 0.7913 Acc: 25.0000%\n",
      "\ttrain 1-127: Loss: 0.1586 Acc: 75.0000%\n",
      "\ttrain 1-128: Loss: 0.4378 Acc: 50.0000%\n",
      "\ttrain 1-129: Loss: 0.2848 Acc: 75.0000%\n",
      "\ttrain 1-130: Loss: 0.5095 Acc: 50.0000%\n",
      "\ttrain 1-131: Loss: 0.4147 Acc: 50.0000%\n",
      "\ttrain 1-132: Loss: 0.4536 Acc: 25.0000%\n",
      "\ttrain 1-133: Loss: 0.3122 Acc: 25.0000%\n",
      "\ttrain 1-134: Loss: 0.3137 Acc: 75.0000%\n",
      "\ttrain 1-135: Loss: 0.1523 Acc: 50.0000%\n",
      "\ttrain 1-136: Loss: 0.2991 Acc: 50.0000%\n",
      "\ttrain 1-137: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 1-138: Loss: 0.5750 Acc: 50.0000%\n",
      "\ttrain 1-139: Loss: 0.1418 Acc: 75.0000%\n",
      "\ttrain 1-140: Loss: 1.0778 Acc: 0.0000%\n",
      "\ttrain 1-141: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 1-142: Loss: 0.4900 Acc: 25.0000%\n",
      "\ttrain 1-143: Loss: 0.5534 Acc: 25.0000%\n",
      "\ttrain 1-144: Loss: 0.4385 Acc: 25.0000%\n",
      "\ttrain 1-145: Loss: 0.1370 Acc: 75.0000%\n",
      "\ttrain 1-146: Loss: 0.8206 Acc: 50.0000%\n",
      "\ttrain 1-147: Loss: 0.8576 Acc: 25.0000%\n",
      "\ttrain 1-148: Loss: 0.8387 Acc: 25.0000%\n",
      "\ttrain 1-149: Loss: 0.6268 Acc: 50.0000%\n",
      "\ttrain 1-150: Loss: 0.5774 Acc: 50.0000%\n",
      "\ttrain 1-151: Loss: 0.4600 Acc: 0.0000%\n",
      "\ttrain 1-152: Loss: 0.3999 Acc: 25.0000%\n",
      "\ttrain 1-153: Loss: 0.2490 Acc: 50.0000%\n",
      "\ttrain 1-154: Loss: 0.4833 Acc: 50.0000%\n",
      "\ttrain 1-155: Loss: 0.1066 Acc: 100.0000%\n",
      "\ttrain 1-156: Loss: 0.2298 Acc: 50.0000%\n",
      "\ttrain 1-157: Loss: 0.3936 Acc: 25.0000%\n",
      "\ttrain 1-158: Loss: 0.4093 Acc: 50.0000%\n",
      "\ttrain 1-159: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 1-160: Loss: 0.7593 Acc: 50.0000%\n",
      "\ttrain 1-161: Loss: 0.6698 Acc: 75.0000%\n",
      "\ttrain 1-162: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 1-163: Loss: 0.4325 Acc: 50.0000%\n",
      "\ttrain 1-164: Loss: 1.0894 Acc: 0.0000%\n",
      "\ttrain 1-165: Loss: 0.4779 Acc: 25.0000%\n",
      "\ttrain 1-166: Loss: 0.2859 Acc: 50.0000%\n",
      "\ttrain 1-167: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 1-168: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 1-169: Loss: 0.1970 Acc: 75.0000%\n",
      "\ttrain 1-170: Loss: 0.0641 Acc: 100.0000%\n",
      "\ttrain 1-171: Loss: 0.4821 Acc: 25.0000%\n",
      "\ttrain 1-172: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 1-173: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 1-174: Loss: 0.3066 Acc: 75.0000%\n",
      "\ttrain 1-175: Loss: 0.4831 Acc: 25.0000%\n",
      "\ttrain 1-176: Loss: 0.5754 Acc: 75.0000%\n",
      "\ttrain 1-177: Loss: 0.1603 Acc: 75.0000%\n",
      "\ttrain 1-178: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 1-179: Loss: 0.4518 Acc: 75.0000%\n",
      "\ttrain 1-180: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 1-181: Loss: 0.3889 Acc: 50.0000%\n",
      "\ttrain 1-182: Loss: 0.4337 Acc: 25.0000%\n",
      "\ttrain 1-183: Loss: 0.1737 Acc: 75.0000%\n",
      "\ttrain 1-184: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 1-185: Loss: 0.3696 Acc: 50.0000%\n",
      "\ttrain 1-186: Loss: 0.6704 Acc: 25.0000%\n",
      "\ttrain 1-187: Loss: 0.2676 Acc: 75.0000%\n",
      "\ttrain 1-188: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 1-189: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 1-190: Loss: 0.2867 Acc: 75.0000%\n",
      "\ttrain 1-191: Loss: 0.3905 Acc: 50.0000%\n",
      "\ttrain 1-192: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 1-193: Loss: 0.3615 Acc: 25.0000%\n",
      "\ttrain 1-194: Loss: 0.2092 Acc: 75.0000%\n",
      "\ttrain 1-195: Loss: 0.2555 Acc: 50.0000%\n",
      "\ttrain 1-196: Loss: 0.5099 Acc: 50.0000%\n",
      "\ttrain 1-197: Loss: 0.3508 Acc: 25.0000%\n",
      "\ttrain 1-198: Loss: 0.5304 Acc: 50.0000%\n",
      "\ttrain 1-199: Loss: 0.6150 Acc: 0.0000%\n",
      "\ttrain 1-200: Loss: 0.3373 Acc: 50.0000%\n",
      "\ttrain 1-201: Loss: 0.3804 Acc: 50.0000%\n",
      "\ttrain 1-202: Loss: 0.1778 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-203: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 1-204: Loss: 0.9454 Acc: 0.0000%\n",
      "\ttrain 1-205: Loss: 0.2448 Acc: 50.0000%\n",
      "\ttrain 1-206: Loss: 0.2469 Acc: 75.0000%\n",
      "\ttrain 1-207: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 1-208: Loss: 0.5723 Acc: 50.0000%\n",
      "\ttrain 1-209: Loss: 0.3472 Acc: 75.0000%\n",
      "\ttrain 1-210: Loss: 0.8865 Acc: 0.0000%\n",
      "\ttrain 1-211: Loss: 0.3613 Acc: 50.0000%\n",
      "\ttrain 1-212: Loss: 0.2242 Acc: 50.0000%\n",
      "\ttrain 1-213: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 1-214: Loss: 0.6518 Acc: 0.0000%\n",
      "\ttrain 1-215: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 1-216: Loss: 0.3851 Acc: 25.0000%\n",
      "\ttrain 1-217: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 1-218: Loss: 0.2808 Acc: 75.0000%\n",
      "\ttrain 1-219: Loss: 0.1562 Acc: 75.0000%\n",
      "\ttrain 1-220: Loss: 0.5077 Acc: 50.0000%\n",
      "\ttrain 1-221: Loss: 0.2684 Acc: 25.0000%\n",
      "\ttrain 1-222: Loss: 0.2144 Acc: 75.0000%\n",
      "\ttrain 1-223: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 1-224: Loss: 0.3630 Acc: 25.0000%\n",
      "\ttrain 1-225: Loss: 0.4478 Acc: 50.0000%\n",
      "\ttrain 1-226: Loss: 0.4326 Acc: 25.0000%\n",
      "\ttrain 1-227: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 1-228: Loss: 0.1115 Acc: 50.0000%\n",
      "\ttrain 1-229: Loss: 0.3671 Acc: 50.0000%\n",
      "\ttrain 1-230: Loss: 0.7951 Acc: 25.0000%\n",
      "\ttrain 1-231: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 1-232: Loss: 0.3839 Acc: 50.0000%\n",
      "\ttrain 1-233: Loss: 0.1584 Acc: 75.0000%\n",
      "\ttrain 1-234: Loss: 0.1960 Acc: 50.0000%\n",
      "\ttrain 1-235: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 1-236: Loss: 0.3293 Acc: 50.0000%\n",
      "\ttrain 1-237: Loss: 0.1989 Acc: 50.0000%\n",
      "\ttrain 1-238: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 1-239: Loss: 0.2593 Acc: 75.0000%\n",
      "\ttrain 1-240: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 1-241: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 1-242: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 1-243: Loss: 0.3269 Acc: 75.0000%\n",
      "\ttrain 1-244: Loss: 0.2036 Acc: 50.0000%\n",
      "\ttrain 1-245: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 1-1: Loss: 0.3754 Acc: 50.0000%\n",
      "\tvalidation 1-2: Loss: 0.0867 Acc: 75.0000%\n",
      "\tvalidation 1-3: Loss: 0.0659 Acc: 75.0000%\n",
      "\tvalidation 1-4: Loss: 0.1072 Acc: 75.0000%\n",
      "\tvalidation 1-5: Loss: 0.0772 Acc: 100.0000%\n",
      "\tvalidation 1-6: Loss: 0.4251 Acc: 75.0000%\n",
      "\tvalidation 1-7: Loss: 0.6827 Acc: 75.0000%\n",
      "\tvalidation 1-8: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 1-9: Loss: 0.2576 Acc: 50.0000%\n",
      "\tvalidation 1-10: Loss: 0.0729 Acc: 100.0000%\n",
      "\tvalidation 1-11: Loss: 0.1858 Acc: 75.0000%\n",
      "\tvalidation 1-12: Loss: 0.0758 Acc: 100.0000%\n",
      "\tvalidation 1-13: Loss: 0.0863 Acc: 100.0000%\n",
      "\tvalidation 1-14: Loss: 0.1356 Acc: 75.0000%\n",
      "\tvalidation 1-15: Loss: 0.1077 Acc: 50.0000%\n",
      "\tvalidation 1-16: Loss: 3.0758 Acc: 50.0000%\n",
      "\tvalidation 1-17: Loss: 0.0862 Acc: 75.0000%\n",
      "\tvalidation 1-18: Loss: 3.9742 Acc: 50.0000%\n",
      "\tvalidation 1-19: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 1-20: Loss: 0.1903 Acc: 75.0000%\n",
      "\tvalidation 1-21: Loss: 0.0625 Acc: 100.0000%\n",
      "\tvalidation 1-22: Loss: 0.1125 Acc: 75.0000%\n",
      "\tvalidation 1-23: Loss: 0.1172 Acc: 75.0000%\n",
      "\tvalidation 1-24: Loss: 0.1033 Acc: 75.0000%\n",
      "\tvalidation 1-25: Loss: 0.2774 Acc: 50.0000%\n",
      "\tvalidation 1-26: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 1-27: Loss: 0.1707 Acc: 50.0000%\n",
      "\tvalidation 1-28: Loss: 0.1157 Acc: 75.0000%\n",
      "\tvalidation 1-29: Loss: 0.0968 Acc: 75.0000%\n",
      "\tvalidation 1-30: Loss: 0.3984 Acc: 50.0000%\n",
      "\tvalidation 1-31: Loss: 0.2603 Acc: 25.0000%\n",
      "\tvalidation 1-32: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 1-33: Loss: 0.0583 Acc: 75.0000%\n",
      "\tvalidation 1-34: Loss: 0.6394 Acc: 50.0000%\n",
      "\tvalidation 1-35: Loss: 0.7687 Acc: 25.0000%\n",
      "\tvalidation 1-36: Loss: 0.1341 Acc: 75.0000%\n",
      "\tvalidation 1-37: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 1-38: Loss: 0.3789 Acc: 50.0000%\n",
      "\tvalidation 1-39: Loss: 1.6095 Acc: 50.0000%\n",
      "\tvalidation 1-40: Loss: 0.0833 Acc: 75.0000%\n",
      "\tvalidation 1-41: Loss: 0.4383 Acc: 50.0000%\n",
      "\tvalidation 1-42: Loss: 0.1413 Acc: 75.0000%\n",
      "\tvalidation 1-43: Loss: 0.2685 Acc: 25.0000%\n",
      "\tvalidation 1-44: Loss: 0.0824 Acc: 75.0000%\n",
      "\tvalidation 1-45: Loss: 0.1219 Acc: 100.0000%\n",
      "\tvalidation 1-46: Loss: 0.3129 Acc: 75.0000%\n",
      "\tvalidation 1-47: Loss: 0.5977 Acc: 75.0000%\n",
      "\tvalidation 1-48: Loss: 0.1589 Acc: 50.0000%\n",
      "\tvalidation 1-49: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-50: Loss: 0.1478 Acc: 50.0000%\n",
      "\tvalidation 1-51: Loss: 0.1055 Acc: 75.0000%\n",
      "\tvalidation 1-52: Loss: 0.1652 Acc: 75.0000%\n",
      "\tvalidation 1-53: Loss: 1.2038 Acc: 50.0000%\n",
      "\tvalidation 1-54: Loss: 0.0517 Acc: 100.0000%\n",
      "\tvalidation 1-55: Loss: 0.0479 Acc: 100.0000%\n",
      "\tvalidation 1-56: Loss: 0.1256 Acc: 50.0000%\n",
      "\tvalidation 1-57: Loss: 0.5154 Acc: 75.0000%\n",
      "\tvalidation 1-58: Loss: 0.2613 Acc: 25.0000%\n",
      "\tvalidation 1-59: Loss: 0.0561 Acc: 100.0000%\n",
      "\tvalidation 1-60: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 1-61: Loss: 0.1424 Acc: 75.0000%\n",
      "\tvalidation 1-62: Loss: 0.4625 Acc: 25.0000%\n",
      "\tvalidation 1-63: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 1-64: Loss: 0.4387 Acc: 75.0000%\n",
      "\tvalidation 1-65: Loss: 0.4408 Acc: 50.0000%\n",
      "\tvalidation 1-66: Loss: 0.0456 Acc: 100.0000%\n",
      "\tvalidation 1-67: Loss: 0.1160 Acc: 50.0000%\n",
      "\tvalidation 1-68: Loss: 0.2012 Acc: 50.0000%\n",
      "\tvalidation 1-69: Loss: 0.0938 Acc: 75.0000%\n",
      "\tvalidation 1-70: Loss: 0.0787 Acc: 75.0000%\n",
      "\tvalidation 1-71: Loss: 0.0919 Acc: 75.0000%\n",
      "\tvalidation 1-72: Loss: 0.0818 Acc: 100.0000%\n",
      "\tvalidation 1-73: Loss: 0.2156 Acc: 75.0000%\n",
      "\tvalidation 1-74: Loss: 1.1752 Acc: 50.0000%\n",
      "\tvalidation 1-75: Loss: 0.0641 Acc: 75.0000%\n",
      "\tvalidation 1-76: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 1-77: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 1-78: Loss: 0.1415 Acc: 75.0000%\n",
      "\tvalidation 1-79: Loss: 0.1304 Acc: 100.0000%\n",
      "\tvalidation 1-80: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 1-81: Loss: 0.6612 Acc: 50.0000%\n",
      "\tvalidation 1-82: Loss: 0.9061 Acc: 50.0000%\n",
      "\tvalidation 1-83: Loss: 0.1391 Acc: 100.0000%\n",
      "\tvalidation 1-84: Loss: 0.0549 Acc: 100.0000%\n",
      "\tvalidation 1-85: Loss: 0.1911 Acc: 50.0000%\n",
      "\tvalidation 1-86: Loss: 0.1146 Acc: 75.0000%\n",
      "\tvalidation 1-87: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 1-88: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 1-89: Loss: 0.1525 Acc: 75.0000%\n",
      "\tvalidation 1-90: Loss: 0.1109 Acc: 50.0000%\n",
      "\tvalidation 1-91: Loss: 0.0766 Acc: 75.0000%\n",
      "\tvalidation 1-92: Loss: 1.6271 Acc: 50.0000%\n",
      "\tvalidation 1-93: Loss: 0.0756 Acc: 100.0000%\n",
      "\tvalidation 1-94: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 1-95: Loss: 0.1493 Acc: 50.0000%\n",
      "\tvalidation 1-96: Loss: 0.1313 Acc: 100.0000%\n",
      "\tvalidation 1-97: Loss: 0.3034 Acc: 50.0000%\n",
      "\tvalidation 1-98: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 1-99: Loss: 0.9766 Acc: 75.0000%\n",
      "\tvalidation 1-100: Loss: 0.1448 Acc: 50.0000%\n",
      "\tvalidation 1-101: Loss: 0.3115 Acc: 50.0000%\n",
      "\tvalidation 1-102: Loss: 0.2018 Acc: 25.0000%\n",
      "\tvalidation 1-103: Loss: 2.6292 Acc: 75.0000%\n",
      "\tvalidation 1-104: Loss: 0.2464 Acc: 75.0000%\n",
      "\tvalidation 1-105: Loss: 0.1771 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2919 Acc: 59.4898%\n",
      "\tvalidation Loss: 0.3264 Acc: 71.4286%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 0s\n",
      "--------------------\n",
      "Epoch [2/40]:\n",
      "\ttrain 2-1: Loss: 0.3045 Acc: 50.0000%\n",
      "\ttrain 2-2: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 2-3: Loss: 0.5294 Acc: 0.0000%\n",
      "\ttrain 2-4: Loss: 0.2478 Acc: 50.0000%\n",
      "\ttrain 2-5: Loss: 0.1806 Acc: 50.0000%\n",
      "\ttrain 2-6: Loss: 0.4732 Acc: 25.0000%\n",
      "\ttrain 2-7: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 2-8: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 2-9: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 2-10: Loss: 0.0874 Acc: 100.0000%\n",
      "\ttrain 2-11: Loss: 0.0706 Acc: 100.0000%\n",
      "\ttrain 2-12: Loss: 0.3721 Acc: 50.0000%\n",
      "\ttrain 2-13: Loss: 0.1734 Acc: 25.0000%\n",
      "\ttrain 2-14: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 2-15: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 2-16: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 2-17: Loss: 0.2018 Acc: 75.0000%\n",
      "\ttrain 2-18: Loss: 0.4034 Acc: 50.0000%\n",
      "\ttrain 2-19: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 2-20: Loss: 0.2667 Acc: 75.0000%\n",
      "\ttrain 2-21: Loss: 0.3707 Acc: 75.0000%\n",
      "\ttrain 2-22: Loss: 0.5229 Acc: 50.0000%\n",
      "\ttrain 2-23: Loss: 0.3982 Acc: 50.0000%\n",
      "\ttrain 2-24: Loss: 0.3694 Acc: 50.0000%\n",
      "\ttrain 2-25: Loss: 0.1731 Acc: 50.0000%\n",
      "\ttrain 2-26: Loss: 0.3042 Acc: 25.0000%\n",
      "\ttrain 2-27: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 2-28: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 2-29: Loss: 0.2001 Acc: 50.0000%\n",
      "\ttrain 2-30: Loss: 0.0609 Acc: 75.0000%\n",
      "\ttrain 2-31: Loss: 0.4042 Acc: 25.0000%\n",
      "\ttrain 2-32: Loss: 0.3400 Acc: 25.0000%\n",
      "\ttrain 2-33: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 2-34: Loss: 0.2078 Acc: 75.0000%\n",
      "\ttrain 2-35: Loss: 0.2282 Acc: 50.0000%\n",
      "\ttrain 2-36: Loss: 0.2383 Acc: 75.0000%\n",
      "\ttrain 2-37: Loss: 0.5997 Acc: 25.0000%\n",
      "\ttrain 2-38: Loss: 0.3827 Acc: 25.0000%\n",
      "\ttrain 2-39: Loss: 0.2512 Acc: 50.0000%\n",
      "\ttrain 2-40: Loss: 0.0505 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-41: Loss: 0.3382 Acc: 25.0000%\n",
      "\ttrain 2-42: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 2-43: Loss: 0.2982 Acc: 25.0000%\n",
      "\ttrain 2-44: Loss: 0.3692 Acc: 25.0000%\n",
      "\ttrain 2-45: Loss: 0.2486 Acc: 50.0000%\n",
      "\ttrain 2-46: Loss: 0.4455 Acc: 25.0000%\n",
      "\ttrain 2-47: Loss: 0.2425 Acc: 25.0000%\n",
      "\ttrain 2-48: Loss: 0.3817 Acc: 50.0000%\n",
      "\ttrain 2-49: Loss: 0.4880 Acc: 50.0000%\n",
      "\ttrain 2-50: Loss: 0.8795 Acc: 25.0000%\n",
      "\ttrain 2-51: Loss: 0.1833 Acc: 75.0000%\n",
      "\ttrain 2-52: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 2-53: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 2-54: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 2-55: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 2-56: Loss: 0.4368 Acc: 50.0000%\n",
      "\ttrain 2-57: Loss: 0.2918 Acc: 25.0000%\n",
      "\ttrain 2-58: Loss: 0.2880 Acc: 50.0000%\n",
      "\ttrain 2-59: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 2-60: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 2-61: Loss: 0.5692 Acc: 25.0000%\n",
      "\ttrain 2-62: Loss: 0.7187 Acc: 25.0000%\n",
      "\ttrain 2-63: Loss: 0.5412 Acc: 25.0000%\n",
      "\ttrain 2-64: Loss: 0.1926 Acc: 50.0000%\n",
      "\ttrain 2-65: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 2-66: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 2-67: Loss: 0.1315 Acc: 50.0000%\n",
      "\ttrain 2-68: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 2-69: Loss: 0.4890 Acc: 25.0000%\n",
      "\ttrain 2-70: Loss: 0.5287 Acc: 25.0000%\n",
      "\ttrain 2-71: Loss: 0.4640 Acc: 25.0000%\n",
      "\ttrain 2-72: Loss: 0.4704 Acc: 25.0000%\n",
      "\ttrain 2-73: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 2-74: Loss: 0.3500 Acc: 50.0000%\n",
      "\ttrain 2-75: Loss: 0.4073 Acc: 75.0000%\n",
      "\ttrain 2-76: Loss: 0.1275 Acc: 100.0000%\n",
      "\ttrain 2-77: Loss: 0.3829 Acc: 25.0000%\n",
      "\ttrain 2-78: Loss: 0.3571 Acc: 50.0000%\n",
      "\ttrain 2-79: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 2-80: Loss: 0.4046 Acc: 50.0000%\n",
      "\ttrain 2-81: Loss: 0.5699 Acc: 25.0000%\n",
      "\ttrain 2-82: Loss: 0.2753 Acc: 25.0000%\n",
      "\ttrain 2-83: Loss: 0.9512 Acc: 0.0000%\n",
      "\ttrain 2-84: Loss: 0.1479 Acc: 75.0000%\n",
      "\ttrain 2-85: Loss: 0.0641 Acc: 100.0000%\n",
      "\ttrain 2-86: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 2-87: Loss: 0.3051 Acc: 75.0000%\n",
      "\ttrain 2-88: Loss: 0.3043 Acc: 25.0000%\n",
      "\ttrain 2-89: Loss: 0.3455 Acc: 50.0000%\n",
      "\ttrain 2-90: Loss: 0.3056 Acc: 50.0000%\n",
      "\ttrain 2-91: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 2-92: Loss: 0.2332 Acc: 75.0000%\n",
      "\ttrain 2-93: Loss: 0.3089 Acc: 50.0000%\n",
      "\ttrain 2-94: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 2-95: Loss: 0.7534 Acc: 25.0000%\n",
      "\ttrain 2-96: Loss: 0.6229 Acc: 25.0000%\n",
      "\ttrain 2-97: Loss: 0.2176 Acc: 50.0000%\n",
      "\ttrain 2-98: Loss: 0.2411 Acc: 50.0000%\n",
      "\ttrain 2-99: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 2-100: Loss: 0.2430 Acc: 50.0000%\n",
      "\ttrain 2-101: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 2-102: Loss: 0.1563 Acc: 50.0000%\n",
      "\ttrain 2-103: Loss: 0.4637 Acc: 75.0000%\n",
      "\ttrain 2-104: Loss: 0.5330 Acc: 75.0000%\n",
      "\ttrain 2-105: Loss: 0.7334 Acc: 25.0000%\n",
      "\ttrain 2-106: Loss: 0.1647 Acc: 100.0000%\n",
      "\ttrain 2-107: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 2-108: Loss: 0.3409 Acc: 50.0000%\n",
      "\ttrain 2-109: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 2-110: Loss: 0.2570 Acc: 75.0000%\n",
      "\ttrain 2-111: Loss: 0.1914 Acc: 50.0000%\n",
      "\ttrain 2-112: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 2-113: Loss: 0.3096 Acc: 25.0000%\n",
      "\ttrain 2-114: Loss: 0.1775 Acc: 25.0000%\n",
      "\ttrain 2-115: Loss: 0.1122 Acc: 100.0000%\n",
      "\ttrain 2-116: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 2-117: Loss: 0.2624 Acc: 50.0000%\n",
      "\ttrain 2-118: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 2-119: Loss: 0.0915 Acc: 100.0000%\n",
      "\ttrain 2-120: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 2-121: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 2-122: Loss: 0.2518 Acc: 50.0000%\n",
      "\ttrain 2-123: Loss: 0.2187 Acc: 50.0000%\n",
      "\ttrain 2-124: Loss: 0.1742 Acc: 50.0000%\n",
      "\ttrain 2-125: Loss: 0.3264 Acc: 50.0000%\n",
      "\ttrain 2-126: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 2-127: Loss: 0.3371 Acc: 25.0000%\n",
      "\ttrain 2-128: Loss: 0.2392 Acc: 50.0000%\n",
      "\ttrain 2-129: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 2-130: Loss: 0.3648 Acc: 50.0000%\n",
      "\ttrain 2-131: Loss: 0.4388 Acc: 25.0000%\n",
      "\ttrain 2-132: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 2-133: Loss: 0.3214 Acc: 25.0000%\n",
      "\ttrain 2-134: Loss: 0.2418 Acc: 25.0000%\n",
      "\ttrain 2-135: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 2-136: Loss: 0.1849 Acc: 50.0000%\n",
      "\ttrain 2-137: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 2-138: Loss: 0.2677 Acc: 50.0000%\n",
      "\ttrain 2-139: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 2-140: Loss: 0.3830 Acc: 50.0000%\n",
      "\ttrain 2-141: Loss: 0.2236 Acc: 75.0000%\n",
      "\ttrain 2-142: Loss: 0.2457 Acc: 50.0000%\n",
      "\ttrain 2-143: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 2-144: Loss: 0.2134 Acc: 75.0000%\n",
      "\ttrain 2-145: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 2-146: Loss: 0.5836 Acc: 50.0000%\n",
      "\ttrain 2-147: Loss: 0.3490 Acc: 25.0000%\n",
      "\ttrain 2-148: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 2-149: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 2-150: Loss: 0.2479 Acc: 75.0000%\n",
      "\ttrain 2-151: Loss: 0.3682 Acc: 50.0000%\n",
      "\ttrain 2-152: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 2-153: Loss: 0.3870 Acc: 0.0000%\n",
      "\ttrain 2-154: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 2-155: Loss: 0.3305 Acc: 50.0000%\n",
      "\ttrain 2-156: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 2-157: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 2-158: Loss: 0.5576 Acc: 25.0000%\n",
      "\ttrain 2-159: Loss: 0.2167 Acc: 50.0000%\n",
      "\ttrain 2-160: Loss: 0.1532 Acc: 75.0000%\n",
      "\ttrain 2-161: Loss: 0.4393 Acc: 50.0000%\n",
      "\ttrain 2-162: Loss: 0.6639 Acc: 25.0000%\n",
      "\ttrain 2-163: Loss: 0.4427 Acc: 25.0000%\n",
      "\ttrain 2-164: Loss: 0.3063 Acc: 50.0000%\n",
      "\ttrain 2-165: Loss: 0.1369 Acc: 50.0000%\n",
      "\ttrain 2-166: Loss: 0.4151 Acc: 25.0000%\n",
      "\ttrain 2-167: Loss: 0.3188 Acc: 25.0000%\n",
      "\ttrain 2-168: Loss: 0.1412 Acc: 100.0000%\n",
      "\ttrain 2-169: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 2-170: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 2-171: Loss: 0.1048 Acc: 100.0000%\n",
      "\ttrain 2-172: Loss: 0.3964 Acc: 25.0000%\n",
      "\ttrain 2-173: Loss: 0.0856 Acc: 100.0000%\n",
      "\ttrain 2-174: Loss: 0.1742 Acc: 50.0000%\n",
      "\ttrain 2-175: Loss: 0.1317 Acc: 100.0000%\n",
      "\ttrain 2-176: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 2-177: Loss: 0.2844 Acc: 50.0000%\n",
      "\ttrain 2-178: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 2-179: Loss: 0.1972 Acc: 50.0000%\n",
      "\ttrain 2-180: Loss: 0.6326 Acc: 25.0000%\n",
      "\ttrain 2-181: Loss: 0.1376 Acc: 50.0000%\n",
      "\ttrain 2-182: Loss: 0.3066 Acc: 50.0000%\n",
      "\ttrain 2-183: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 2-184: Loss: 0.2619 Acc: 25.0000%\n",
      "\ttrain 2-185: Loss: 0.5181 Acc: 25.0000%\n",
      "\ttrain 2-186: Loss: 0.1674 Acc: 50.0000%\n",
      "\ttrain 2-187: Loss: 0.2899 Acc: 0.0000%\n",
      "\ttrain 2-188: Loss: 0.3742 Acc: 50.0000%\n",
      "\ttrain 2-189: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 2-190: Loss: 0.2447 Acc: 50.0000%\n",
      "\ttrain 2-191: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 2-192: Loss: 0.2124 Acc: 50.0000%\n",
      "\ttrain 2-193: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 2-194: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 2-195: Loss: 0.1808 Acc: 25.0000%\n",
      "\ttrain 2-196: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 2-197: Loss: 0.2771 Acc: 25.0000%\n",
      "\ttrain 2-198: Loss: 0.2339 Acc: 50.0000%\n",
      "\ttrain 2-199: Loss: 0.0671 Acc: 75.0000%\n",
      "\ttrain 2-200: Loss: 0.2004 Acc: 75.0000%\n",
      "\ttrain 2-201: Loss: 0.3018 Acc: 0.0000%\n",
      "\ttrain 2-202: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 2-203: Loss: 0.2334 Acc: 75.0000%\n",
      "\ttrain 2-204: Loss: 0.5401 Acc: 0.0000%\n",
      "\ttrain 2-205: Loss: 0.0948 Acc: 100.0000%\n",
      "\ttrain 2-206: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 2-207: Loss: 0.1726 Acc: 50.0000%\n",
      "\ttrain 2-208: Loss: 0.3476 Acc: 50.0000%\n",
      "\ttrain 2-209: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 2-210: Loss: 0.4425 Acc: 25.0000%\n",
      "\ttrain 2-211: Loss: 0.2309 Acc: 25.0000%\n",
      "\ttrain 2-212: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 2-213: Loss: 0.3158 Acc: 50.0000%\n",
      "\ttrain 2-214: Loss: 0.3065 Acc: 50.0000%\n",
      "\ttrain 2-215: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 2-216: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 2-217: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 2-218: Loss: 0.4043 Acc: 50.0000%\n",
      "\ttrain 2-219: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 2-220: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 2-221: Loss: 0.1588 Acc: 50.0000%\n",
      "\ttrain 2-222: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 2-223: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 2-224: Loss: 0.2693 Acc: 50.0000%\n",
      "\ttrain 2-225: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 2-226: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 2-227: Loss: 0.5669 Acc: 25.0000%\n",
      "\ttrain 2-228: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 2-229: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 2-230: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 2-231: Loss: 0.2586 Acc: 50.0000%\n",
      "\ttrain 2-232: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 2-233: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 2-234: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 2-235: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 2-236: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 2-237: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 2-238: Loss: 0.2825 Acc: 50.0000%\n",
      "\ttrain 2-239: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 2-240: Loss: 0.3052 Acc: 50.0000%\n",
      "\ttrain 2-241: Loss: 0.1947 Acc: 75.0000%\n",
      "\ttrain 2-242: Loss: 0.0951 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-243: Loss: 0.3290 Acc: 75.0000%\n",
      "\ttrain 2-244: Loss: 0.4451 Acc: 0.0000%\n",
      "\ttrain 2-245: Loss: 0.3831 Acc: 50.0000%\n",
      "\tvalidation 2-1: Loss: 0.1438 Acc: 50.0000%\n",
      "\tvalidation 2-2: Loss: 0.0825 Acc: 75.0000%\n",
      "\tvalidation 2-3: Loss: 0.1111 Acc: 75.0000%\n",
      "\tvalidation 2-4: Loss: 0.1556 Acc: 50.0000%\n",
      "\tvalidation 2-5: Loss: 0.2957 Acc: 75.0000%\n",
      "\tvalidation 2-6: Loss: 0.0891 Acc: 100.0000%\n",
      "\tvalidation 2-7: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 2-8: Loss: 0.6589 Acc: 50.0000%\n",
      "\tvalidation 2-9: Loss: 1.7416 Acc: 50.0000%\n",
      "\tvalidation 2-10: Loss: 1.3682 Acc: 75.0000%\n",
      "\tvalidation 2-11: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 2-12: Loss: 0.0808 Acc: 75.0000%\n",
      "\tvalidation 2-13: Loss: 4.5145 Acc: 50.0000%\n",
      "\tvalidation 2-14: Loss: 0.1921 Acc: 50.0000%\n",
      "\tvalidation 2-15: Loss: 0.1813 Acc: 50.0000%\n",
      "\tvalidation 2-16: Loss: 0.1316 Acc: 75.0000%\n",
      "\tvalidation 2-17: Loss: 0.0801 Acc: 75.0000%\n",
      "\tvalidation 2-18: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 2-19: Loss: 0.1797 Acc: 50.0000%\n",
      "\tvalidation 2-20: Loss: 0.1222 Acc: 75.0000%\n",
      "\tvalidation 2-21: Loss: 0.1764 Acc: 50.0000%\n",
      "\tvalidation 2-22: Loss: 0.2421 Acc: 50.0000%\n",
      "\tvalidation 2-23: Loss: 0.0957 Acc: 75.0000%\n",
      "\tvalidation 2-24: Loss: 0.1448 Acc: 75.0000%\n",
      "\tvalidation 2-25: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 2-26: Loss: 0.1235 Acc: 75.0000%\n",
      "\tvalidation 2-27: Loss: 1.3169 Acc: 50.0000%\n",
      "\tvalidation 2-28: Loss: 0.4756 Acc: 75.0000%\n",
      "\tvalidation 2-29: Loss: 0.0957 Acc: 75.0000%\n",
      "\tvalidation 2-30: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 2-31: Loss: 0.4332 Acc: 25.0000%\n",
      "\tvalidation 2-32: Loss: 0.0858 Acc: 75.0000%\n",
      "\tvalidation 2-33: Loss: 0.4841 Acc: 75.0000%\n",
      "\tvalidation 2-34: Loss: 0.6361 Acc: 50.0000%\n",
      "\tvalidation 2-35: Loss: 4.0080 Acc: 75.0000%\n",
      "\tvalidation 2-36: Loss: 0.1713 Acc: 75.0000%\n",
      "\tvalidation 2-37: Loss: 0.0954 Acc: 75.0000%\n",
      "\tvalidation 2-38: Loss: 0.1149 Acc: 50.0000%\n",
      "\tvalidation 2-39: Loss: 0.0620 Acc: 100.0000%\n",
      "\tvalidation 2-40: Loss: 0.1320 Acc: 75.0000%\n",
      "\tvalidation 2-41: Loss: 0.0833 Acc: 100.0000%\n",
      "\tvalidation 2-42: Loss: 0.0487 Acc: 100.0000%\n",
      "\tvalidation 2-43: Loss: 0.2690 Acc: 50.0000%\n",
      "\tvalidation 2-44: Loss: 0.0939 Acc: 75.0000%\n",
      "\tvalidation 2-45: Loss: 0.8223 Acc: 50.0000%\n",
      "\tvalidation 2-46: Loss: 0.0582 Acc: 100.0000%\n",
      "\tvalidation 2-47: Loss: 0.7175 Acc: 75.0000%\n",
      "\tvalidation 2-48: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 2-49: Loss: 1.8474 Acc: 75.0000%\n",
      "\tvalidation 2-50: Loss: 5.8738 Acc: 50.0000%\n",
      "\tvalidation 2-51: Loss: 2.2291 Acc: 75.0000%\n",
      "\tvalidation 2-52: Loss: 0.3927 Acc: 75.0000%\n",
      "\tvalidation 2-53: Loss: 0.3223 Acc: 75.0000%\n",
      "\tvalidation 2-54: Loss: 1.9086 Acc: 25.0000%\n",
      "\tvalidation 2-55: Loss: 0.0473 Acc: 100.0000%\n",
      "\tvalidation 2-56: Loss: 0.1215 Acc: 75.0000%\n",
      "\tvalidation 2-57: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 2-58: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 2-59: Loss: 0.3051 Acc: 25.0000%\n",
      "\tvalidation 2-60: Loss: 0.0816 Acc: 75.0000%\n",
      "\tvalidation 2-61: Loss: 0.2493 Acc: 50.0000%\n",
      "\tvalidation 2-62: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 2-63: Loss: 0.1293 Acc: 50.0000%\n",
      "\tvalidation 2-64: Loss: 0.0617 Acc: 75.0000%\n",
      "\tvalidation 2-65: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 2-66: Loss: 0.4464 Acc: 50.0000%\n",
      "\tvalidation 2-67: Loss: 0.0660 Acc: 75.0000%\n",
      "\tvalidation 2-68: Loss: 0.2197 Acc: 50.0000%\n",
      "\tvalidation 2-69: Loss: 0.3854 Acc: 50.0000%\n",
      "\tvalidation 2-70: Loss: 0.0900 Acc: 75.0000%\n",
      "\tvalidation 2-71: Loss: 0.0463 Acc: 100.0000%\n",
      "\tvalidation 2-72: Loss: 0.3178 Acc: 75.0000%\n",
      "\tvalidation 2-73: Loss: 0.1255 Acc: 75.0000%\n",
      "\tvalidation 2-74: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 2-75: Loss: 0.2943 Acc: 75.0000%\n",
      "\tvalidation 2-76: Loss: 0.1413 Acc: 75.0000%\n",
      "\tvalidation 2-77: Loss: 0.2074 Acc: 50.0000%\n",
      "\tvalidation 2-78: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 2-79: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 2-80: Loss: 0.1701 Acc: 75.0000%\n",
      "\tvalidation 2-81: Loss: 0.3112 Acc: 50.0000%\n",
      "\tvalidation 2-82: Loss: 1.6546 Acc: 25.0000%\n",
      "\tvalidation 2-83: Loss: 0.1323 Acc: 50.0000%\n",
      "\tvalidation 2-84: Loss: 0.2806 Acc: 75.0000%\n",
      "\tvalidation 2-85: Loss: 2.7823 Acc: 25.0000%\n",
      "\tvalidation 2-86: Loss: 0.1598 Acc: 75.0000%\n",
      "\tvalidation 2-87: Loss: 0.6111 Acc: 75.0000%\n",
      "\tvalidation 2-88: Loss: 0.0675 Acc: 100.0000%\n",
      "\tvalidation 2-89: Loss: 0.0489 Acc: 100.0000%\n",
      "\tvalidation 2-90: Loss: 0.2011 Acc: 50.0000%\n",
      "\tvalidation 2-91: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 2-92: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 2-93: Loss: 0.1191 Acc: 75.0000%\n",
      "\tvalidation 2-94: Loss: 1.1997 Acc: 25.0000%\n",
      "\tvalidation 2-95: Loss: 0.2474 Acc: 50.0000%\n",
      "\tvalidation 2-96: Loss: 0.4936 Acc: 50.0000%\n",
      "\tvalidation 2-97: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 2-98: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 2-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 2-100: Loss: 0.1425 Acc: 75.0000%\n",
      "\tvalidation 2-101: Loss: 0.1794 Acc: 50.0000%\n",
      "\tvalidation 2-102: Loss: 0.2848 Acc: 75.0000%\n",
      "\tvalidation 2-103: Loss: 0.0750 Acc: 100.0000%\n",
      "\tvalidation 2-104: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 2-105: Loss: 0.7384 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2466 Acc: 58.6735%\n",
      "\tvalidation Loss: 0.4548 Acc: 71.1905%\n",
      "Time passed 0h 1m 57s\n",
      "--------------------\n",
      "Epoch [3/40]:\n",
      "\ttrain 3-1: Loss: 0.2172 Acc: 50.0000%\n",
      "\ttrain 3-2: Loss: 0.1046 Acc: 100.0000%\n",
      "\ttrain 3-3: Loss: 0.3026 Acc: 75.0000%\n",
      "\ttrain 3-4: Loss: 0.1845 Acc: 75.0000%\n",
      "\ttrain 3-5: Loss: 0.3286 Acc: 25.0000%\n",
      "\ttrain 3-6: Loss: 0.1813 Acc: 75.0000%\n",
      "\ttrain 3-7: Loss: 0.1750 Acc: 50.0000%\n",
      "\ttrain 3-8: Loss: 0.0915 Acc: 100.0000%\n",
      "\ttrain 3-9: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 3-10: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 3-11: Loss: 0.2466 Acc: 25.0000%\n",
      "\ttrain 3-12: Loss: 0.2391 Acc: 50.0000%\n",
      "\ttrain 3-13: Loss: 0.1823 Acc: 75.0000%\n",
      "\ttrain 3-14: Loss: 0.0823 Acc: 100.0000%\n",
      "\ttrain 3-15: Loss: 0.0905 Acc: 100.0000%\n",
      "\ttrain 3-16: Loss: 0.2173 Acc: 50.0000%\n",
      "\ttrain 3-17: Loss: 0.5170 Acc: 25.0000%\n",
      "\ttrain 3-18: Loss: 0.2216 Acc: 50.0000%\n",
      "\ttrain 3-19: Loss: 0.2284 Acc: 50.0000%\n",
      "\ttrain 3-20: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 3-21: Loss: 0.1879 Acc: 75.0000%\n",
      "\ttrain 3-22: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 3-23: Loss: 0.3237 Acc: 25.0000%\n",
      "\ttrain 3-24: Loss: 0.4112 Acc: 25.0000%\n",
      "\ttrain 3-25: Loss: 0.3461 Acc: 25.0000%\n",
      "\ttrain 3-26: Loss: 0.1722 Acc: 50.0000%\n",
      "\ttrain 3-27: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 3-28: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 3-29: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 3-30: Loss: 0.2642 Acc: 50.0000%\n",
      "\ttrain 3-31: Loss: 0.2824 Acc: 50.0000%\n",
      "\ttrain 3-32: Loss: 0.4002 Acc: 50.0000%\n",
      "\ttrain 3-33: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 3-34: Loss: 0.2867 Acc: 75.0000%\n",
      "\ttrain 3-35: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 3-36: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 3-37: Loss: 0.2574 Acc: 75.0000%\n",
      "\ttrain 3-38: Loss: 0.3635 Acc: 50.0000%\n",
      "\ttrain 3-39: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 3-40: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 3-41: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 3-42: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 3-43: Loss: 0.3071 Acc: 50.0000%\n",
      "\ttrain 3-44: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 3-45: Loss: 0.3680 Acc: 25.0000%\n",
      "\ttrain 3-46: Loss: 0.2579 Acc: 50.0000%\n",
      "\ttrain 3-47: Loss: 0.2523 Acc: 50.0000%\n",
      "\ttrain 3-48: Loss: 0.3630 Acc: 50.0000%\n",
      "\ttrain 3-49: Loss: 0.6610 Acc: 0.0000%\n",
      "\ttrain 3-50: Loss: 0.1152 Acc: 100.0000%\n",
      "\ttrain 3-51: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 3-52: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 3-53: Loss: 0.4912 Acc: 50.0000%\n",
      "\ttrain 3-54: Loss: 0.4580 Acc: 50.0000%\n",
      "\ttrain 3-55: Loss: 0.3322 Acc: 75.0000%\n",
      "\ttrain 3-56: Loss: 0.2038 Acc: 50.0000%\n",
      "\ttrain 3-57: Loss: 0.2008 Acc: 50.0000%\n",
      "\ttrain 3-58: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 3-59: Loss: 0.2357 Acc: 75.0000%\n",
      "\ttrain 3-60: Loss: 0.0893 Acc: 100.0000%\n",
      "\ttrain 3-61: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 3-62: Loss: 0.1565 Acc: 50.0000%\n",
      "\ttrain 3-63: Loss: 0.2569 Acc: 25.0000%\n",
      "\ttrain 3-64: Loss: 0.2634 Acc: 50.0000%\n",
      "\ttrain 3-65: Loss: 0.3004 Acc: 50.0000%\n",
      "\ttrain 3-66: Loss: 0.2738 Acc: 75.0000%\n",
      "\ttrain 3-67: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 3-68: Loss: 0.2472 Acc: 50.0000%\n",
      "\ttrain 3-69: Loss: 0.2059 Acc: 50.0000%\n",
      "\ttrain 3-70: Loss: 0.3071 Acc: 50.0000%\n",
      "\ttrain 3-71: Loss: 0.1400 Acc: 75.0000%\n",
      "\ttrain 3-72: Loss: 0.1508 Acc: 75.0000%\n",
      "\ttrain 3-73: Loss: 0.2994 Acc: 25.0000%\n",
      "\ttrain 3-74: Loss: 0.1892 Acc: 50.0000%\n",
      "\ttrain 3-75: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 3-76: Loss: 0.2441 Acc: 75.0000%\n",
      "\ttrain 3-77: Loss: 0.3103 Acc: 25.0000%\n",
      "\ttrain 3-78: Loss: 0.2752 Acc: 50.0000%\n",
      "\ttrain 3-79: Loss: 0.2666 Acc: 50.0000%\n",
      "\ttrain 3-80: Loss: 0.1690 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-81: Loss: 0.3600 Acc: 25.0000%\n",
      "\ttrain 3-82: Loss: 0.1716 Acc: 25.0000%\n",
      "\ttrain 3-83: Loss: 0.3892 Acc: 50.0000%\n",
      "\ttrain 3-84: Loss: 0.5483 Acc: 0.0000%\n",
      "\ttrain 3-85: Loss: 0.1801 Acc: 75.0000%\n",
      "\ttrain 3-86: Loss: 0.4381 Acc: 50.0000%\n",
      "\ttrain 3-87: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 3-88: Loss: 0.1579 Acc: 50.0000%\n",
      "\ttrain 3-89: Loss: 0.3004 Acc: 25.0000%\n",
      "\ttrain 3-90: Loss: 0.3922 Acc: 50.0000%\n",
      "\ttrain 3-91: Loss: 0.2352 Acc: 50.0000%\n",
      "\ttrain 3-92: Loss: 0.2585 Acc: 25.0000%\n",
      "\ttrain 3-93: Loss: 0.1620 Acc: 50.0000%\n",
      "\ttrain 3-94: Loss: 0.6910 Acc: 0.0000%\n",
      "\ttrain 3-95: Loss: 0.6173 Acc: 0.0000%\n",
      "\ttrain 3-96: Loss: 0.1872 Acc: 50.0000%\n",
      "\ttrain 3-97: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 3-98: Loss: 0.3470 Acc: 50.0000%\n",
      "\ttrain 3-99: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 3-100: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 3-101: Loss: 0.3195 Acc: 50.0000%\n",
      "\ttrain 3-102: Loss: 0.2323 Acc: 50.0000%\n",
      "\ttrain 3-103: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 3-104: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 3-105: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 3-106: Loss: 0.5798 Acc: 50.0000%\n",
      "\ttrain 3-107: Loss: 0.1481 Acc: 50.0000%\n",
      "\ttrain 3-108: Loss: 0.3228 Acc: 25.0000%\n",
      "\ttrain 3-109: Loss: 0.3468 Acc: 75.0000%\n",
      "\ttrain 3-110: Loss: 0.2638 Acc: 50.0000%\n",
      "\ttrain 3-111: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 3-112: Loss: 0.3083 Acc: 50.0000%\n",
      "\ttrain 3-113: Loss: 0.2195 Acc: 75.0000%\n",
      "\ttrain 3-114: Loss: 0.3291 Acc: 50.0000%\n",
      "\ttrain 3-115: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 3-116: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 3-117: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 3-118: Loss: 0.1555 Acc: 75.0000%\n",
      "\ttrain 3-119: Loss: 0.1346 Acc: 100.0000%\n",
      "\ttrain 3-120: Loss: 0.2633 Acc: 75.0000%\n",
      "\ttrain 3-121: Loss: 0.1898 Acc: 75.0000%\n",
      "\ttrain 3-122: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 3-123: Loss: 0.1354 Acc: 50.0000%\n",
      "\ttrain 3-124: Loss: 0.2719 Acc: 50.0000%\n",
      "\ttrain 3-125: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 3-126: Loss: 0.4569 Acc: 25.0000%\n",
      "\ttrain 3-127: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 3-128: Loss: 0.3167 Acc: 50.0000%\n",
      "\ttrain 3-129: Loss: 0.3110 Acc: 25.0000%\n",
      "\ttrain 3-130: Loss: 0.1986 Acc: 50.0000%\n",
      "\ttrain 3-131: Loss: 0.3546 Acc: 50.0000%\n",
      "\ttrain 3-132: Loss: 0.4058 Acc: 50.0000%\n",
      "\ttrain 3-133: Loss: 0.2620 Acc: 50.0000%\n",
      "\ttrain 3-134: Loss: 0.1524 Acc: 75.0000%\n",
      "\ttrain 3-135: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 3-136: Loss: 0.3974 Acc: 25.0000%\n",
      "\ttrain 3-137: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 3-138: Loss: 0.3529 Acc: 50.0000%\n",
      "\ttrain 3-139: Loss: 0.3394 Acc: 50.0000%\n",
      "\ttrain 3-140: Loss: 0.4717 Acc: 25.0000%\n",
      "\ttrain 3-141: Loss: 0.3288 Acc: 50.0000%\n",
      "\ttrain 3-142: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 3-143: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 3-144: Loss: 0.3105 Acc: 50.0000%\n",
      "\ttrain 3-145: Loss: 0.2642 Acc: 50.0000%\n",
      "\ttrain 3-146: Loss: 0.4140 Acc: 25.0000%\n",
      "\ttrain 3-147: Loss: 0.2609 Acc: 75.0000%\n",
      "\ttrain 3-148: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 3-149: Loss: 0.0940 Acc: 100.0000%\n",
      "\ttrain 3-150: Loss: 0.1017 Acc: 100.0000%\n",
      "\ttrain 3-151: Loss: 0.2876 Acc: 25.0000%\n",
      "\ttrain 3-152: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 3-153: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 3-154: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 3-155: Loss: 0.2921 Acc: 25.0000%\n",
      "\ttrain 3-156: Loss: 0.3161 Acc: 25.0000%\n",
      "\ttrain 3-157: Loss: 0.2795 Acc: 50.0000%\n",
      "\ttrain 3-158: Loss: 0.3798 Acc: 50.0000%\n",
      "\ttrain 3-159: Loss: 0.2306 Acc: 50.0000%\n",
      "\ttrain 3-160: Loss: 0.3382 Acc: 50.0000%\n",
      "\ttrain 3-161: Loss: 0.4239 Acc: 25.0000%\n",
      "\ttrain 3-162: Loss: 0.2162 Acc: 75.0000%\n",
      "\ttrain 3-163: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 3-164: Loss: 0.0902 Acc: 100.0000%\n",
      "\ttrain 3-165: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 3-166: Loss: 0.2556 Acc: 50.0000%\n",
      "\ttrain 3-167: Loss: 0.3326 Acc: 50.0000%\n",
      "\ttrain 3-168: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 3-169: Loss: 0.4652 Acc: 0.0000%\n",
      "\ttrain 3-170: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 3-171: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 3-172: Loss: 0.1618 Acc: 50.0000%\n",
      "\ttrain 3-173: Loss: 0.3229 Acc: 50.0000%\n",
      "\ttrain 3-174: Loss: 0.2769 Acc: 25.0000%\n",
      "\ttrain 3-175: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 3-176: Loss: 0.1918 Acc: 50.0000%\n",
      "\ttrain 3-177: Loss: 0.1322 Acc: 100.0000%\n",
      "\ttrain 3-178: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 3-179: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 3-180: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 3-181: Loss: 0.2833 Acc: 25.0000%\n",
      "\ttrain 3-182: Loss: 0.2358 Acc: 50.0000%\n",
      "\ttrain 3-183: Loss: 0.0950 Acc: 100.0000%\n",
      "\ttrain 3-184: Loss: 0.4715 Acc: 25.0000%\n",
      "\ttrain 3-185: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 3-186: Loss: 0.5651 Acc: 25.0000%\n",
      "\ttrain 3-187: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 3-188: Loss: 0.1322 Acc: 50.0000%\n",
      "\ttrain 3-189: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 3-190: Loss: 0.1717 Acc: 75.0000%\n",
      "\ttrain 3-191: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 3-192: Loss: 0.1547 Acc: 50.0000%\n",
      "\ttrain 3-193: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 3-194: Loss: 0.1868 Acc: 50.0000%\n",
      "\ttrain 3-195: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 3-196: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 3-197: Loss: 0.3773 Acc: 75.0000%\n",
      "\ttrain 3-198: Loss: 0.5585 Acc: 25.0000%\n",
      "\ttrain 3-199: Loss: 0.5564 Acc: 50.0000%\n",
      "\ttrain 3-200: Loss: 0.5202 Acc: 25.0000%\n",
      "\ttrain 3-201: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 3-202: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 3-203: Loss: 0.1470 Acc: 75.0000%\n",
      "\ttrain 3-204: Loss: 0.3658 Acc: 25.0000%\n",
      "\ttrain 3-205: Loss: 0.2334 Acc: 25.0000%\n",
      "\ttrain 3-206: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 3-207: Loss: 0.3035 Acc: 50.0000%\n",
      "\ttrain 3-208: Loss: 0.4073 Acc: 25.0000%\n",
      "\ttrain 3-209: Loss: 0.4140 Acc: 25.0000%\n",
      "\ttrain 3-210: Loss: 0.2260 Acc: 75.0000%\n",
      "\ttrain 3-211: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 3-212: Loss: 0.4984 Acc: 50.0000%\n",
      "\ttrain 3-213: Loss: 0.3883 Acc: 25.0000%\n",
      "\ttrain 3-214: Loss: 0.3721 Acc: 25.0000%\n",
      "\ttrain 3-215: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 3-216: Loss: 0.2241 Acc: 50.0000%\n",
      "\ttrain 3-217: Loss: 0.3787 Acc: 50.0000%\n",
      "\ttrain 3-218: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 3-219: Loss: 0.2950 Acc: 50.0000%\n",
      "\ttrain 3-220: Loss: 0.1593 Acc: 50.0000%\n",
      "\ttrain 3-221: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 3-222: Loss: 0.1124 Acc: 100.0000%\n",
      "\ttrain 3-223: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 3-224: Loss: 0.2090 Acc: 25.0000%\n",
      "\ttrain 3-225: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 3-226: Loss: 0.1635 Acc: 50.0000%\n",
      "\ttrain 3-227: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 3-228: Loss: 0.1049 Acc: 75.0000%\n",
      "\ttrain 3-229: Loss: 0.1707 Acc: 50.0000%\n",
      "\ttrain 3-230: Loss: 0.2378 Acc: 25.0000%\n",
      "\ttrain 3-231: Loss: 0.2383 Acc: 75.0000%\n",
      "\ttrain 3-232: Loss: 0.1217 Acc: 100.0000%\n",
      "\ttrain 3-233: Loss: 0.1582 Acc: 25.0000%\n",
      "\ttrain 3-234: Loss: 0.1180 Acc: 100.0000%\n",
      "\ttrain 3-235: Loss: 0.2777 Acc: 75.0000%\n",
      "\ttrain 3-236: Loss: 0.1646 Acc: 75.0000%\n",
      "\ttrain 3-237: Loss: 0.0945 Acc: 100.0000%\n",
      "\ttrain 3-238: Loss: 0.2392 Acc: 50.0000%\n",
      "\ttrain 3-239: Loss: 0.4633 Acc: 50.0000%\n",
      "\ttrain 3-240: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 3-241: Loss: 0.4632 Acc: 0.0000%\n",
      "\ttrain 3-242: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 3-243: Loss: 0.3678 Acc: 25.0000%\n",
      "\ttrain 3-244: Loss: 0.3582 Acc: 75.0000%\n",
      "\ttrain 3-245: Loss: 0.1264 Acc: 75.0000%\n",
      "\tvalidation 3-1: Loss: 0.1064 Acc: 75.0000%\n",
      "\tvalidation 3-2: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 3-3: Loss: 0.0728 Acc: 75.0000%\n",
      "\tvalidation 3-4: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 3-5: Loss: 0.1027 Acc: 75.0000%\n",
      "\tvalidation 3-6: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 3-7: Loss: 1.1812 Acc: 75.0000%\n",
      "\tvalidation 3-8: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 3-9: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 3-10: Loss: 0.1928 Acc: 50.0000%\n",
      "\tvalidation 3-11: Loss: 0.1182 Acc: 75.0000%\n",
      "\tvalidation 3-12: Loss: 0.1128 Acc: 75.0000%\n",
      "\tvalidation 3-13: Loss: 0.0986 Acc: 75.0000%\n",
      "\tvalidation 3-14: Loss: 0.6639 Acc: 50.0000%\n",
      "\tvalidation 3-15: Loss: 0.0966 Acc: 75.0000%\n",
      "\tvalidation 3-16: Loss: 0.0976 Acc: 75.0000%\n",
      "\tvalidation 3-17: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 3-18: Loss: 0.1198 Acc: 75.0000%\n",
      "\tvalidation 3-19: Loss: 0.5873 Acc: 75.0000%\n",
      "\tvalidation 3-20: Loss: 0.1014 Acc: 75.0000%\n",
      "\tvalidation 3-21: Loss: 0.2123 Acc: 50.0000%\n",
      "\tvalidation 3-22: Loss: 0.1004 Acc: 75.0000%\n",
      "\tvalidation 3-23: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 3-24: Loss: 0.0882 Acc: 75.0000%\n",
      "\tvalidation 3-25: Loss: 0.1927 Acc: 50.0000%\n",
      "\tvalidation 3-26: Loss: 0.0915 Acc: 75.0000%\n",
      "\tvalidation 3-27: Loss: 0.4605 Acc: 75.0000%\n",
      "\tvalidation 3-28: Loss: 0.1441 Acc: 75.0000%\n",
      "\tvalidation 3-29: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 3-30: Loss: 0.2114 Acc: 75.0000%\n",
      "\tvalidation 3-31: Loss: 0.1343 Acc: 75.0000%\n",
      "\tvalidation 3-32: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 3-33: Loss: 0.1811 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-34: Loss: 0.1044 Acc: 75.0000%\n",
      "\tvalidation 3-35: Loss: 0.1884 Acc: 50.0000%\n",
      "\tvalidation 3-36: Loss: 0.1209 Acc: 75.0000%\n",
      "\tvalidation 3-37: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 3-38: Loss: 0.1128 Acc: 75.0000%\n",
      "\tvalidation 3-39: Loss: 1.2147 Acc: 75.0000%\n",
      "\tvalidation 3-40: Loss: 0.7106 Acc: 75.0000%\n",
      "\tvalidation 3-41: Loss: 1.6173 Acc: 50.0000%\n",
      "\tvalidation 3-42: Loss: 0.0241 Acc: 100.0000%\n",
      "\tvalidation 3-43: Loss: 0.1774 Acc: 50.0000%\n",
      "\tvalidation 3-44: Loss: 0.2794 Acc: 75.0000%\n",
      "\tvalidation 3-45: Loss: 0.1742 Acc: 75.0000%\n",
      "\tvalidation 3-46: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-47: Loss: 0.2519 Acc: 25.0000%\n",
      "\tvalidation 3-48: Loss: 0.1622 Acc: 50.0000%\n",
      "\tvalidation 3-49: Loss: 0.0735 Acc: 75.0000%\n",
      "\tvalidation 3-50: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 3-51: Loss: 0.1783 Acc: 50.0000%\n",
      "\tvalidation 3-52: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 3-53: Loss: 0.1614 Acc: 50.0000%\n",
      "\tvalidation 3-54: Loss: 0.1577 Acc: 75.0000%\n",
      "\tvalidation 3-55: Loss: 0.1163 Acc: 75.0000%\n",
      "\tvalidation 3-56: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 3-57: Loss: 0.0592 Acc: 100.0000%\n",
      "\tvalidation 3-58: Loss: 1.6908 Acc: 75.0000%\n",
      "\tvalidation 3-59: Loss: 0.3772 Acc: 50.0000%\n",
      "\tvalidation 3-60: Loss: 0.0918 Acc: 75.0000%\n",
      "\tvalidation 3-61: Loss: 0.3239 Acc: 50.0000%\n",
      "\tvalidation 3-62: Loss: 0.2683 Acc: 75.0000%\n",
      "\tvalidation 3-63: Loss: 0.1973 Acc: 75.0000%\n",
      "\tvalidation 3-64: Loss: 1.9009 Acc: 50.0000%\n",
      "\tvalidation 3-65: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 3-66: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 3-67: Loss: 0.4135 Acc: 75.0000%\n",
      "\tvalidation 3-68: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 3-69: Loss: 0.1836 Acc: 75.0000%\n",
      "\tvalidation 3-70: Loss: 0.4660 Acc: 50.0000%\n",
      "\tvalidation 3-71: Loss: 0.1073 Acc: 75.0000%\n",
      "\tvalidation 3-72: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 3-73: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 3-74: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 3-75: Loss: 0.1053 Acc: 75.0000%\n",
      "\tvalidation 3-76: Loss: 0.0721 Acc: 75.0000%\n",
      "\tvalidation 3-77: Loss: 0.0989 Acc: 75.0000%\n",
      "\tvalidation 3-78: Loss: 0.1336 Acc: 75.0000%\n",
      "\tvalidation 3-79: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 3-80: Loss: 0.1277 Acc: 75.0000%\n",
      "\tvalidation 3-81: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 3-82: Loss: 0.2158 Acc: 50.0000%\n",
      "\tvalidation 3-83: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 3-84: Loss: 4.2162 Acc: 50.0000%\n",
      "\tvalidation 3-85: Loss: 0.0880 Acc: 75.0000%\n",
      "\tvalidation 3-86: Loss: 0.1400 Acc: 75.0000%\n",
      "\tvalidation 3-87: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 3-88: Loss: 0.0865 Acc: 75.0000%\n",
      "\tvalidation 3-89: Loss: 0.8707 Acc: 75.0000%\n",
      "\tvalidation 3-90: Loss: 1.2371 Acc: 50.0000%\n",
      "\tvalidation 3-91: Loss: 0.0902 Acc: 75.0000%\n",
      "\tvalidation 3-92: Loss: 0.0847 Acc: 75.0000%\n",
      "\tvalidation 3-93: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 3-94: Loss: 0.1890 Acc: 50.0000%\n",
      "\tvalidation 3-95: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 3-96: Loss: 1.2435 Acc: 25.0000%\n",
      "\tvalidation 3-97: Loss: 0.1381 Acc: 75.0000%\n",
      "\tvalidation 3-98: Loss: 0.5147 Acc: 25.0000%\n",
      "\tvalidation 3-99: Loss: 0.2898 Acc: 25.0000%\n",
      "\tvalidation 3-100: Loss: 1.0222 Acc: 50.0000%\n",
      "\tvalidation 3-101: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 3-102: Loss: 0.1149 Acc: 75.0000%\n",
      "\tvalidation 3-103: Loss: 0.0820 Acc: 75.0000%\n",
      "\tvalidation 3-104: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 3-105: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2271 Acc: 61.0204%\n",
      "\tvalidation Loss: 0.2802 Acc: 75.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 2m 49s\n",
      "--------------------\n",
      "Epoch [4/40]:\n",
      "\ttrain 4-1: Loss: 0.3438 Acc: 50.0000%\n",
      "\ttrain 4-2: Loss: 0.2567 Acc: 50.0000%\n",
      "\ttrain 4-3: Loss: 0.2026 Acc: 75.0000%\n",
      "\ttrain 4-4: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 4-5: Loss: 0.2914 Acc: 50.0000%\n",
      "\ttrain 4-6: Loss: 0.2247 Acc: 50.0000%\n",
      "\ttrain 4-7: Loss: 0.1406 Acc: 50.0000%\n",
      "\ttrain 4-8: Loss: 0.0612 Acc: 100.0000%\n",
      "\ttrain 4-9: Loss: 0.3338 Acc: 50.0000%\n",
      "\ttrain 4-10: Loss: 0.1129 Acc: 100.0000%\n",
      "\ttrain 4-11: Loss: 0.4145 Acc: 50.0000%\n",
      "\ttrain 4-12: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 4-13: Loss: 0.5073 Acc: 25.0000%\n",
      "\ttrain 4-14: Loss: 0.1445 Acc: 75.0000%\n",
      "\ttrain 4-15: Loss: 0.4657 Acc: 25.0000%\n",
      "\ttrain 4-16: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 4-17: Loss: 0.3332 Acc: 50.0000%\n",
      "\ttrain 4-18: Loss: 0.2322 Acc: 75.0000%\n",
      "\ttrain 4-19: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 4-20: Loss: 0.1134 Acc: 100.0000%\n",
      "\ttrain 4-21: Loss: 0.4705 Acc: 25.0000%\n",
      "\ttrain 4-22: Loss: 0.2488 Acc: 75.0000%\n",
      "\ttrain 4-23: Loss: 0.5589 Acc: 50.0000%\n",
      "\ttrain 4-24: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 4-25: Loss: 0.5784 Acc: 25.0000%\n",
      "\ttrain 4-26: Loss: 0.4270 Acc: 50.0000%\n",
      "\ttrain 4-27: Loss: 0.3299 Acc: 50.0000%\n",
      "\ttrain 4-28: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 4-29: Loss: 0.0822 Acc: 100.0000%\n",
      "\ttrain 4-30: Loss: 0.5009 Acc: 25.0000%\n",
      "\ttrain 4-31: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 4-32: Loss: 0.0918 Acc: 100.0000%\n",
      "\ttrain 4-33: Loss: 0.5022 Acc: 25.0000%\n",
      "\ttrain 4-34: Loss: 0.4338 Acc: 25.0000%\n",
      "\ttrain 4-35: Loss: 0.2336 Acc: 50.0000%\n",
      "\ttrain 4-36: Loss: 0.5853 Acc: 25.0000%\n",
      "\ttrain 4-37: Loss: 0.1595 Acc: 50.0000%\n",
      "\ttrain 4-38: Loss: 0.4645 Acc: 25.0000%\n",
      "\ttrain 4-39: Loss: 0.2240 Acc: 75.0000%\n",
      "\ttrain 4-40: Loss: 0.2527 Acc: 50.0000%\n",
      "\ttrain 4-41: Loss: 0.2462 Acc: 75.0000%\n",
      "\ttrain 4-42: Loss: 0.1666 Acc: 75.0000%\n",
      "\ttrain 4-43: Loss: 0.1698 Acc: 75.0000%\n",
      "\ttrain 4-44: Loss: 0.3289 Acc: 50.0000%\n",
      "\ttrain 4-45: Loss: 0.2355 Acc: 75.0000%\n",
      "\ttrain 4-46: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 4-47: Loss: 0.2268 Acc: 75.0000%\n",
      "\ttrain 4-48: Loss: 0.2088 Acc: 75.0000%\n",
      "\ttrain 4-49: Loss: 0.2287 Acc: 50.0000%\n",
      "\ttrain 4-50: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 4-51: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 4-52: Loss: 0.2347 Acc: 50.0000%\n",
      "\ttrain 4-53: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 4-54: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 4-55: Loss: 0.1842 Acc: 50.0000%\n",
      "\ttrain 4-56: Loss: 0.0895 Acc: 100.0000%\n",
      "\ttrain 4-57: Loss: 0.2396 Acc: 50.0000%\n",
      "\ttrain 4-58: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 4-59: Loss: 0.3954 Acc: 50.0000%\n",
      "\ttrain 4-60: Loss: 0.1989 Acc: 25.0000%\n",
      "\ttrain 4-61: Loss: 0.2401 Acc: 75.0000%\n",
      "\ttrain 4-62: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 4-63: Loss: 0.1308 Acc: 100.0000%\n",
      "\ttrain 4-64: Loss: 0.1431 Acc: 75.0000%\n",
      "\ttrain 4-65: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 4-66: Loss: 0.2628 Acc: 25.0000%\n",
      "\ttrain 4-67: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 4-68: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 4-69: Loss: 0.2109 Acc: 50.0000%\n",
      "\ttrain 4-70: Loss: 0.2885 Acc: 25.0000%\n",
      "\ttrain 4-71: Loss: 0.2036 Acc: 25.0000%\n",
      "\ttrain 4-72: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 4-73: Loss: 0.2101 Acc: 50.0000%\n",
      "\ttrain 4-74: Loss: 0.2892 Acc: 50.0000%\n",
      "\ttrain 4-75: Loss: 0.3840 Acc: 50.0000%\n",
      "\ttrain 4-76: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 4-77: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 4-78: Loss: 0.2826 Acc: 25.0000%\n",
      "\ttrain 4-79: Loss: 0.1103 Acc: 100.0000%\n",
      "\ttrain 4-80: Loss: 0.1932 Acc: 50.0000%\n",
      "\ttrain 4-81: Loss: 0.1999 Acc: 75.0000%\n",
      "\ttrain 4-82: Loss: 0.5478 Acc: 50.0000%\n",
      "\ttrain 4-83: Loss: 0.1979 Acc: 50.0000%\n",
      "\ttrain 4-84: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 4-85: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 4-86: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 4-87: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 4-88: Loss: 0.4207 Acc: 25.0000%\n",
      "\ttrain 4-89: Loss: 0.1480 Acc: 75.0000%\n",
      "\ttrain 4-90: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 4-91: Loss: 0.1437 Acc: 50.0000%\n",
      "\ttrain 4-92: Loss: 0.1172 Acc: 50.0000%\n",
      "\ttrain 4-93: Loss: 0.1251 Acc: 50.0000%\n",
      "\ttrain 4-94: Loss: 0.1334 Acc: 100.0000%\n",
      "\ttrain 4-95: Loss: 0.1901 Acc: 75.0000%\n",
      "\ttrain 4-96: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 4-97: Loss: 0.2982 Acc: 75.0000%\n",
      "\ttrain 4-98: Loss: 0.1186 Acc: 75.0000%\n",
      "\ttrain 4-99: Loss: 0.1400 Acc: 50.0000%\n",
      "\ttrain 4-100: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 4-101: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 4-102: Loss: 0.1523 Acc: 50.0000%\n",
      "\ttrain 4-103: Loss: 0.4509 Acc: 50.0000%\n",
      "\ttrain 4-104: Loss: 0.1729 Acc: 50.0000%\n",
      "\ttrain 4-105: Loss: 0.1858 Acc: 50.0000%\n",
      "\ttrain 4-106: Loss: 0.1264 Acc: 100.0000%\n",
      "\ttrain 4-107: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 4-108: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 4-109: Loss: 0.2204 Acc: 75.0000%\n",
      "\ttrain 4-110: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 4-111: Loss: 0.0497 Acc: 75.0000%\n",
      "\ttrain 4-112: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 4-113: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 4-114: Loss: 0.2380 Acc: 75.0000%\n",
      "\ttrain 4-115: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 4-116: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 4-117: Loss: 0.3542 Acc: 50.0000%\n",
      "\ttrain 4-118: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 4-119: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 4-120: Loss: 0.2077 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-121: Loss: 0.2065 Acc: 50.0000%\n",
      "\ttrain 4-122: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 4-123: Loss: 0.2062 Acc: 50.0000%\n",
      "\ttrain 4-124: Loss: 0.1167 Acc: 50.0000%\n",
      "\ttrain 4-125: Loss: 0.2349 Acc: 50.0000%\n",
      "\ttrain 4-126: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 4-127: Loss: 0.1202 Acc: 100.0000%\n",
      "\ttrain 4-128: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 4-129: Loss: 0.2790 Acc: 50.0000%\n",
      "\ttrain 4-130: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 4-131: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 4-132: Loss: 0.1211 Acc: 50.0000%\n",
      "\ttrain 4-133: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 4-134: Loss: 0.1803 Acc: 25.0000%\n",
      "\ttrain 4-135: Loss: 0.1421 Acc: 50.0000%\n",
      "\ttrain 4-136: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 4-137: Loss: 0.1594 Acc: 50.0000%\n",
      "\ttrain 4-138: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 4-139: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 4-140: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 4-141: Loss: 0.2849 Acc: 50.0000%\n",
      "\ttrain 4-142: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 4-143: Loss: 0.2019 Acc: 75.0000%\n",
      "\ttrain 4-144: Loss: 0.0904 Acc: 100.0000%\n",
      "\ttrain 4-145: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 4-146: Loss: 0.5513 Acc: 50.0000%\n",
      "\ttrain 4-147: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 4-148: Loss: 0.3255 Acc: 25.0000%\n",
      "\ttrain 4-149: Loss: 0.1744 Acc: 50.0000%\n",
      "\ttrain 4-150: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 4-151: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 4-152: Loss: 0.5815 Acc: 25.0000%\n",
      "\ttrain 4-153: Loss: 0.3169 Acc: 50.0000%\n",
      "\ttrain 4-154: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 4-155: Loss: 0.3085 Acc: 50.0000%\n",
      "\ttrain 4-156: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 4-157: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 4-158: Loss: 0.2270 Acc: 50.0000%\n",
      "\ttrain 4-159: Loss: 0.1245 Acc: 75.0000%\n",
      "\ttrain 4-160: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 4-161: Loss: 0.0794 Acc: 100.0000%\n",
      "\ttrain 4-162: Loss: 0.1470 Acc: 50.0000%\n",
      "\ttrain 4-163: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 4-164: Loss: 0.1505 Acc: 75.0000%\n",
      "\ttrain 4-165: Loss: 0.1163 Acc: 100.0000%\n",
      "\ttrain 4-166: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 4-167: Loss: 0.1423 Acc: 100.0000%\n",
      "\ttrain 4-168: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 4-169: Loss: 0.1070 Acc: 100.0000%\n",
      "\ttrain 4-170: Loss: 0.2681 Acc: 50.0000%\n",
      "\ttrain 4-171: Loss: 0.3117 Acc: 75.0000%\n",
      "\ttrain 4-172: Loss: 0.2907 Acc: 50.0000%\n",
      "\ttrain 4-173: Loss: 0.2939 Acc: 75.0000%\n",
      "\ttrain 4-174: Loss: 0.1780 Acc: 75.0000%\n",
      "\ttrain 4-175: Loss: 0.1770 Acc: 50.0000%\n",
      "\ttrain 4-176: Loss: 0.1130 Acc: 100.0000%\n",
      "\ttrain 4-177: Loss: 0.1847 Acc: 25.0000%\n",
      "\ttrain 4-178: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 4-179: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 4-180: Loss: 0.3069 Acc: 25.0000%\n",
      "\ttrain 4-181: Loss: 0.1777 Acc: 50.0000%\n",
      "\ttrain 4-182: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 4-183: Loss: 0.1703 Acc: 75.0000%\n",
      "\ttrain 4-184: Loss: 0.2843 Acc: 75.0000%\n",
      "\ttrain 4-185: Loss: 0.1068 Acc: 100.0000%\n",
      "\ttrain 4-186: Loss: 0.3233 Acc: 25.0000%\n",
      "\ttrain 4-187: Loss: 0.1110 Acc: 50.0000%\n",
      "\ttrain 4-188: Loss: 0.2809 Acc: 75.0000%\n",
      "\ttrain 4-189: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 4-190: Loss: 0.2678 Acc: 75.0000%\n",
      "\ttrain 4-191: Loss: 0.3837 Acc: 25.0000%\n",
      "\ttrain 4-192: Loss: 0.1552 Acc: 75.0000%\n",
      "\ttrain 4-193: Loss: 0.1645 Acc: 50.0000%\n",
      "\ttrain 4-194: Loss: 0.2080 Acc: 75.0000%\n",
      "\ttrain 4-195: Loss: 0.1488 Acc: 50.0000%\n",
      "\ttrain 4-196: Loss: 0.1711 Acc: 50.0000%\n",
      "\ttrain 4-197: Loss: 0.2145 Acc: 50.0000%\n",
      "\ttrain 4-198: Loss: 0.1594 Acc: 50.0000%\n",
      "\ttrain 4-199: Loss: 0.3131 Acc: 25.0000%\n",
      "\ttrain 4-200: Loss: 0.2766 Acc: 50.0000%\n",
      "\ttrain 4-201: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 4-202: Loss: 0.1417 Acc: 50.0000%\n",
      "\ttrain 4-203: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 4-204: Loss: 0.3256 Acc: 50.0000%\n",
      "\ttrain 4-205: Loss: 0.4152 Acc: 25.0000%\n",
      "\ttrain 4-206: Loss: 0.3182 Acc: 25.0000%\n",
      "\ttrain 4-207: Loss: 0.4772 Acc: 25.0000%\n",
      "\ttrain 4-208: Loss: 0.1945 Acc: 50.0000%\n",
      "\ttrain 4-209: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 4-210: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 4-211: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 4-212: Loss: 0.1813 Acc: 50.0000%\n",
      "\ttrain 4-213: Loss: 0.2969 Acc: 50.0000%\n",
      "\ttrain 4-214: Loss: 0.2776 Acc: 50.0000%\n",
      "\ttrain 4-215: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 4-216: Loss: 0.5741 Acc: 25.0000%\n",
      "\ttrain 4-217: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 4-218: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 4-219: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 4-220: Loss: 0.2001 Acc: 50.0000%\n",
      "\ttrain 4-221: Loss: 0.2737 Acc: 50.0000%\n",
      "\ttrain 4-222: Loss: 0.3630 Acc: 50.0000%\n",
      "\ttrain 4-223: Loss: 0.3231 Acc: 25.0000%\n",
      "\ttrain 4-224: Loss: 0.7989 Acc: 0.0000%\n",
      "\ttrain 4-225: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 4-226: Loss: 0.2252 Acc: 50.0000%\n",
      "\ttrain 4-227: Loss: 0.1759 Acc: 50.0000%\n",
      "\ttrain 4-228: Loss: 0.3943 Acc: 50.0000%\n",
      "\ttrain 4-229: Loss: 0.3043 Acc: 50.0000%\n",
      "\ttrain 4-230: Loss: 0.5499 Acc: 50.0000%\n",
      "\ttrain 4-231: Loss: 0.1984 Acc: 50.0000%\n",
      "\ttrain 4-232: Loss: 0.3130 Acc: 50.0000%\n",
      "\ttrain 4-233: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 4-234: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 4-235: Loss: 0.2994 Acc: 25.0000%\n",
      "\ttrain 4-236: Loss: 0.1600 Acc: 50.0000%\n",
      "\ttrain 4-237: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 4-238: Loss: 0.1178 Acc: 100.0000%\n",
      "\ttrain 4-239: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 4-240: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 4-241: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 4-242: Loss: 0.2136 Acc: 50.0000%\n",
      "\ttrain 4-243: Loss: 0.1584 Acc: 75.0000%\n",
      "\ttrain 4-244: Loss: 0.2232 Acc: 50.0000%\n",
      "\ttrain 4-245: Loss: 0.1233 Acc: 100.0000%\n",
      "\tvalidation 4-1: Loss: 0.2003 Acc: 50.0000%\n",
      "\tvalidation 4-2: Loss: 0.0464 Acc: 100.0000%\n",
      "\tvalidation 4-3: Loss: 0.7125 Acc: 25.0000%\n",
      "\tvalidation 4-4: Loss: 0.5225 Acc: 25.0000%\n",
      "\tvalidation 4-5: Loss: 0.0861 Acc: 75.0000%\n",
      "\tvalidation 4-6: Loss: 0.1199 Acc: 75.0000%\n",
      "\tvalidation 4-7: Loss: 0.1707 Acc: 50.0000%\n",
      "\tvalidation 4-8: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 4-9: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 4-10: Loss: 0.1058 Acc: 75.0000%\n",
      "\tvalidation 4-11: Loss: 0.1619 Acc: 75.0000%\n",
      "\tvalidation 4-12: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 4-13: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 4-14: Loss: 0.1115 Acc: 75.0000%\n",
      "\tvalidation 4-15: Loss: 0.7215 Acc: 75.0000%\n",
      "\tvalidation 4-16: Loss: 0.1171 Acc: 75.0000%\n",
      "\tvalidation 4-17: Loss: 1.1554 Acc: 75.0000%\n",
      "\tvalidation 4-18: Loss: 0.5007 Acc: 0.0000%\n",
      "\tvalidation 4-19: Loss: 0.1229 Acc: 75.0000%\n",
      "\tvalidation 4-20: Loss: 0.3063 Acc: 50.0000%\n",
      "\tvalidation 4-21: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 4-22: Loss: 0.1394 Acc: 75.0000%\n",
      "\tvalidation 4-23: Loss: 0.3354 Acc: 75.0000%\n",
      "\tvalidation 4-24: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 4-25: Loss: 0.1699 Acc: 50.0000%\n",
      "\tvalidation 4-26: Loss: 0.1633 Acc: 50.0000%\n",
      "\tvalidation 4-27: Loss: 0.0962 Acc: 75.0000%\n",
      "\tvalidation 4-28: Loss: 0.1007 Acc: 75.0000%\n",
      "\tvalidation 4-29: Loss: 2.8147 Acc: 50.0000%\n",
      "\tvalidation 4-30: Loss: 0.1290 Acc: 75.0000%\n",
      "\tvalidation 4-31: Loss: 0.0947 Acc: 75.0000%\n",
      "\tvalidation 4-32: Loss: 0.0974 Acc: 75.0000%\n",
      "\tvalidation 4-33: Loss: 0.1929 Acc: 50.0000%\n",
      "\tvalidation 4-34: Loss: 0.1508 Acc: 75.0000%\n",
      "\tvalidation 4-35: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 4-36: Loss: 0.2686 Acc: 50.0000%\n",
      "\tvalidation 4-37: Loss: 0.1824 Acc: 75.0000%\n",
      "\tvalidation 4-38: Loss: 0.1879 Acc: 50.0000%\n",
      "\tvalidation 4-39: Loss: 0.1221 Acc: 75.0000%\n",
      "\tvalidation 4-40: Loss: 0.0974 Acc: 75.0000%\n",
      "\tvalidation 4-41: Loss: 0.2692 Acc: 75.0000%\n",
      "\tvalidation 4-42: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 4-43: Loss: 0.1201 Acc: 75.0000%\n",
      "\tvalidation 4-44: Loss: 0.1810 Acc: 50.0000%\n",
      "\tvalidation 4-45: Loss: 0.0709 Acc: 75.0000%\n",
      "\tvalidation 4-46: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 4-47: Loss: 0.3639 Acc: 75.0000%\n",
      "\tvalidation 4-48: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 4-49: Loss: 0.2697 Acc: 25.0000%\n",
      "\tvalidation 4-50: Loss: 2.8634 Acc: 0.0000%\n",
      "\tvalidation 4-51: Loss: 0.2078 Acc: 50.0000%\n",
      "\tvalidation 4-52: Loss: 0.1299 Acc: 75.0000%\n",
      "\tvalidation 4-53: Loss: 0.6397 Acc: 25.0000%\n",
      "\tvalidation 4-54: Loss: 0.1123 Acc: 75.0000%\n",
      "\tvalidation 4-55: Loss: 0.0515 Acc: 100.0000%\n",
      "\tvalidation 4-56: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 4-57: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 4-58: Loss: 0.2112 Acc: 50.0000%\n",
      "\tvalidation 4-59: Loss: 0.4190 Acc: 75.0000%\n",
      "\tvalidation 4-60: Loss: 0.0860 Acc: 75.0000%\n",
      "\tvalidation 4-61: Loss: 0.0796 Acc: 75.0000%\n",
      "\tvalidation 4-62: Loss: 0.5114 Acc: 50.0000%\n",
      "\tvalidation 4-63: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 4-64: Loss: 0.0364 Acc: 100.0000%\n",
      "\tvalidation 4-65: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 4-66: Loss: 0.0507 Acc: 100.0000%\n",
      "\tvalidation 4-67: Loss: 0.1032 Acc: 75.0000%\n",
      "\tvalidation 4-68: Loss: 0.1257 Acc: 75.0000%\n",
      "\tvalidation 4-69: Loss: 0.0938 Acc: 75.0000%\n",
      "\tvalidation 4-70: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 4-71: Loss: 0.0486 Acc: 100.0000%\n",
      "\tvalidation 4-72: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 4-73: Loss: 0.5082 Acc: 25.0000%\n",
      "\tvalidation 4-74: Loss: 0.1035 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 4-75: Loss: 0.1192 Acc: 75.0000%\n",
      "\tvalidation 4-76: Loss: 0.1898 Acc: 50.0000%\n",
      "\tvalidation 4-77: Loss: 0.1045 Acc: 75.0000%\n",
      "\tvalidation 4-78: Loss: 0.8184 Acc: 50.0000%\n",
      "\tvalidation 4-79: Loss: 1.8041 Acc: 75.0000%\n",
      "\tvalidation 4-80: Loss: 0.8720 Acc: 25.0000%\n",
      "\tvalidation 4-81: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 4-82: Loss: 0.2203 Acc: 50.0000%\n",
      "\tvalidation 4-83: Loss: 0.3300 Acc: 75.0000%\n",
      "\tvalidation 4-84: Loss: 0.0984 Acc: 75.0000%\n",
      "\tvalidation 4-85: Loss: 0.1460 Acc: 50.0000%\n",
      "\tvalidation 4-86: Loss: 0.1228 Acc: 75.0000%\n",
      "\tvalidation 4-87: Loss: 0.0986 Acc: 75.0000%\n",
      "\tvalidation 4-88: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 4-89: Loss: 0.0853 Acc: 75.0000%\n",
      "\tvalidation 4-90: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 4-91: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 4-92: Loss: 0.0415 Acc: 100.0000%\n",
      "\tvalidation 4-93: Loss: 0.2274 Acc: 50.0000%\n",
      "\tvalidation 4-94: Loss: 0.9527 Acc: 50.0000%\n",
      "\tvalidation 4-95: Loss: 0.0912 Acc: 75.0000%\n",
      "\tvalidation 4-96: Loss: 0.5878 Acc: 50.0000%\n",
      "\tvalidation 4-97: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 4-98: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 4-99: Loss: 4.0248 Acc: 50.0000%\n",
      "\tvalidation 4-100: Loss: 0.7574 Acc: 25.0000%\n",
      "\tvalidation 4-101: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 4-102: Loss: 0.0724 Acc: 75.0000%\n",
      "\tvalidation 4-103: Loss: 0.1963 Acc: 50.0000%\n",
      "\tvalidation 4-104: Loss: 0.3315 Acc: 50.0000%\n",
      "\tvalidation 4-105: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2053 Acc: 63.7755%\n",
      "\tvalidation Loss: 0.3002 Acc: 70.7143%\n",
      "Time passed 0h 3m 42s\n",
      "--------------------\n",
      "Epoch [5/40]:\n",
      "\ttrain 5-1: Loss: 0.1986 Acc: 50.0000%\n",
      "\ttrain 5-2: Loss: 0.1947 Acc: 75.0000%\n",
      "\ttrain 5-3: Loss: 0.2169 Acc: 50.0000%\n",
      "\ttrain 5-4: Loss: 0.1810 Acc: 75.0000%\n",
      "\ttrain 5-5: Loss: 0.0756 Acc: 100.0000%\n",
      "\ttrain 5-6: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 5-7: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 5-8: Loss: 0.1503 Acc: 50.0000%\n",
      "\ttrain 5-9: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 5-10: Loss: 0.4203 Acc: 50.0000%\n",
      "\ttrain 5-11: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 5-12: Loss: 0.2238 Acc: 50.0000%\n",
      "\ttrain 5-13: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 5-14: Loss: 0.1718 Acc: 75.0000%\n",
      "\ttrain 5-15: Loss: 0.0886 Acc: 100.0000%\n",
      "\ttrain 5-16: Loss: 0.2394 Acc: 50.0000%\n",
      "\ttrain 5-17: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 5-18: Loss: 0.1088 Acc: 100.0000%\n",
      "\ttrain 5-19: Loss: 0.2122 Acc: 50.0000%\n",
      "\ttrain 5-20: Loss: 0.4445 Acc: 25.0000%\n",
      "\ttrain 5-21: Loss: 0.3624 Acc: 75.0000%\n",
      "\ttrain 5-22: Loss: 0.2622 Acc: 50.0000%\n",
      "\ttrain 5-23: Loss: 0.1785 Acc: 75.0000%\n",
      "\ttrain 5-24: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 5-25: Loss: 0.2343 Acc: 75.0000%\n",
      "\ttrain 5-26: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 5-27: Loss: 0.1593 Acc: 50.0000%\n",
      "\ttrain 5-28: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 5-29: Loss: 0.2423 Acc: 50.0000%\n",
      "\ttrain 5-30: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 5-31: Loss: 0.4056 Acc: 25.0000%\n",
      "\ttrain 5-32: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 5-33: Loss: 0.1657 Acc: 50.0000%\n",
      "\ttrain 5-34: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 5-35: Loss: 0.2028 Acc: 50.0000%\n",
      "\ttrain 5-36: Loss: 0.3618 Acc: 25.0000%\n",
      "\ttrain 5-37: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 5-38: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 5-39: Loss: 0.1432 Acc: 75.0000%\n",
      "\ttrain 5-40: Loss: 0.0996 Acc: 100.0000%\n",
      "\ttrain 5-41: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 5-42: Loss: 0.4022 Acc: 25.0000%\n",
      "\ttrain 5-43: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 5-44: Loss: 0.8160 Acc: 25.0000%\n",
      "\ttrain 5-45: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 5-46: Loss: 0.4273 Acc: 50.0000%\n",
      "\ttrain 5-47: Loss: 0.5555 Acc: 0.0000%\n",
      "\ttrain 5-48: Loss: 0.3752 Acc: 50.0000%\n",
      "\ttrain 5-49: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 5-50: Loss: 0.2661 Acc: 50.0000%\n",
      "\ttrain 5-51: Loss: 0.2709 Acc: 75.0000%\n",
      "\ttrain 5-52: Loss: 0.1898 Acc: 50.0000%\n",
      "\ttrain 5-53: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 5-54: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 5-55: Loss: 0.5236 Acc: 50.0000%\n",
      "\ttrain 5-56: Loss: 0.2543 Acc: 75.0000%\n",
      "\ttrain 5-57: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 5-58: Loss: 0.1490 Acc: 50.0000%\n",
      "\ttrain 5-59: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 5-60: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 5-61: Loss: 0.2064 Acc: 75.0000%\n",
      "\ttrain 5-62: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 5-63: Loss: 0.3516 Acc: 50.0000%\n",
      "\ttrain 5-64: Loss: 0.1033 Acc: 100.0000%\n",
      "\ttrain 5-65: Loss: 0.1523 Acc: 75.0000%\n",
      "\ttrain 5-66: Loss: 0.1848 Acc: 75.0000%\n",
      "\ttrain 5-67: Loss: 0.3456 Acc: 50.0000%\n",
      "\ttrain 5-68: Loss: 0.1739 Acc: 50.0000%\n",
      "\ttrain 5-69: Loss: 0.1896 Acc: 50.0000%\n",
      "\ttrain 5-70: Loss: 0.2321 Acc: 75.0000%\n",
      "\ttrain 5-71: Loss: 0.4066 Acc: 25.0000%\n",
      "\ttrain 5-72: Loss: 0.1818 Acc: 25.0000%\n",
      "\ttrain 5-73: Loss: 0.3377 Acc: 25.0000%\n",
      "\ttrain 5-74: Loss: 0.0841 Acc: 100.0000%\n",
      "\ttrain 5-75: Loss: 0.3249 Acc: 50.0000%\n",
      "\ttrain 5-76: Loss: 0.1250 Acc: 100.0000%\n",
      "\ttrain 5-77: Loss: 0.5659 Acc: 25.0000%\n",
      "\ttrain 5-78: Loss: 0.2587 Acc: 25.0000%\n",
      "\ttrain 5-79: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 5-80: Loss: 0.1979 Acc: 50.0000%\n",
      "\ttrain 5-81: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 5-82: Loss: 0.2086 Acc: 50.0000%\n",
      "\ttrain 5-83: Loss: 0.1045 Acc: 100.0000%\n",
      "\ttrain 5-84: Loss: 0.2587 Acc: 75.0000%\n",
      "\ttrain 5-85: Loss: 0.2474 Acc: 75.0000%\n",
      "\ttrain 5-86: Loss: 0.2916 Acc: 50.0000%\n",
      "\ttrain 5-87: Loss: 0.3140 Acc: 50.0000%\n",
      "\ttrain 5-88: Loss: 0.2910 Acc: 75.0000%\n",
      "\ttrain 5-89: Loss: 0.3107 Acc: 50.0000%\n",
      "\ttrain 5-90: Loss: 0.4985 Acc: 50.0000%\n",
      "\ttrain 5-91: Loss: 0.2916 Acc: 75.0000%\n",
      "\ttrain 5-92: Loss: 0.5388 Acc: 25.0000%\n",
      "\ttrain 5-93: Loss: 0.3066 Acc: 50.0000%\n",
      "\ttrain 5-94: Loss: 0.1827 Acc: 50.0000%\n",
      "\ttrain 5-95: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 5-96: Loss: 0.2141 Acc: 25.0000%\n",
      "\ttrain 5-97: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 5-98: Loss: 0.1745 Acc: 50.0000%\n",
      "\ttrain 5-99: Loss: 0.2773 Acc: 50.0000%\n",
      "\ttrain 5-100: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 5-101: Loss: 0.1563 Acc: 50.0000%\n",
      "\ttrain 5-102: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 5-103: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 5-104: Loss: 0.3158 Acc: 25.0000%\n",
      "\ttrain 5-105: Loss: 0.4865 Acc: 50.0000%\n",
      "\ttrain 5-106: Loss: 0.3630 Acc: 25.0000%\n",
      "\ttrain 5-107: Loss: 0.3185 Acc: 25.0000%\n",
      "\ttrain 5-108: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 5-109: Loss: 0.1337 Acc: 50.0000%\n",
      "\ttrain 5-110: Loss: 0.1702 Acc: 75.0000%\n",
      "\ttrain 5-111: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 5-112: Loss: 0.2182 Acc: 75.0000%\n",
      "\ttrain 5-113: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 5-114: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 5-115: Loss: 0.5541 Acc: 50.0000%\n",
      "\ttrain 5-116: Loss: 0.2612 Acc: 75.0000%\n",
      "\ttrain 5-117: Loss: 0.1884 Acc: 50.0000%\n",
      "\ttrain 5-118: Loss: 0.5794 Acc: 0.0000%\n",
      "\ttrain 5-119: Loss: 0.1512 Acc: 50.0000%\n",
      "\ttrain 5-120: Loss: 0.3400 Acc: 50.0000%\n",
      "\ttrain 5-121: Loss: 0.2550 Acc: 50.0000%\n",
      "\ttrain 5-122: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 5-123: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 5-124: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 5-125: Loss: 0.4032 Acc: 50.0000%\n",
      "\ttrain 5-126: Loss: 0.4898 Acc: 25.0000%\n",
      "\ttrain 5-127: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 5-128: Loss: 0.1512 Acc: 75.0000%\n",
      "\ttrain 5-129: Loss: 0.7208 Acc: 0.0000%\n",
      "\ttrain 5-130: Loss: 0.2458 Acc: 25.0000%\n",
      "\ttrain 5-131: Loss: 0.0839 Acc: 100.0000%\n",
      "\ttrain 5-132: Loss: 0.0901 Acc: 100.0000%\n",
      "\ttrain 5-133: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 5-134: Loss: 0.1678 Acc: 75.0000%\n",
      "\ttrain 5-135: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 5-136: Loss: 0.1119 Acc: 100.0000%\n",
      "\ttrain 5-137: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 5-138: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 5-139: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 5-140: Loss: 0.1695 Acc: 50.0000%\n",
      "\ttrain 5-141: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 5-142: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 5-143: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 5-144: Loss: 0.2456 Acc: 75.0000%\n",
      "\ttrain 5-145: Loss: 0.1847 Acc: 50.0000%\n",
      "\ttrain 5-146: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 5-147: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 5-148: Loss: 0.1810 Acc: 50.0000%\n",
      "\ttrain 5-149: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 5-150: Loss: 0.6384 Acc: 25.0000%\n",
      "\ttrain 5-151: Loss: 0.2175 Acc: 50.0000%\n",
      "\ttrain 5-152: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 5-153: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 5-154: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 5-155: Loss: 0.2482 Acc: 50.0000%\n",
      "\ttrain 5-156: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 5-157: Loss: 0.3782 Acc: 25.0000%\n",
      "\ttrain 5-158: Loss: 0.4008 Acc: 25.0000%\n",
      "\ttrain 5-159: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 5-160: Loss: 0.2205 Acc: 50.0000%\n",
      "\ttrain 5-161: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 5-162: Loss: 0.7605 Acc: 0.0000%\n",
      "\ttrain 5-163: Loss: 0.5093 Acc: 50.0000%\n",
      "\ttrain 5-164: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 5-165: Loss: 0.1572 Acc: 50.0000%\n",
      "\ttrain 5-166: Loss: 0.1235 Acc: 100.0000%\n",
      "\ttrain 5-167: Loss: 0.1542 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 5-168: Loss: 0.2012 Acc: 50.0000%\n",
      "\ttrain 5-169: Loss: 0.1063 Acc: 50.0000%\n",
      "\ttrain 5-170: Loss: 0.2253 Acc: 50.0000%\n",
      "\ttrain 5-171: Loss: 0.4112 Acc: 75.0000%\n",
      "\ttrain 5-172: Loss: 0.4636 Acc: 25.0000%\n",
      "\ttrain 5-173: Loss: 0.2898 Acc: 25.0000%\n",
      "\ttrain 5-174: Loss: 0.3454 Acc: 50.0000%\n",
      "\ttrain 5-175: Loss: 0.2311 Acc: 50.0000%\n",
      "\ttrain 5-176: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 5-177: Loss: 0.0852 Acc: 100.0000%\n",
      "\ttrain 5-178: Loss: 0.1950 Acc: 50.0000%\n",
      "\ttrain 5-179: Loss: 0.3123 Acc: 25.0000%\n",
      "\ttrain 5-180: Loss: 0.2556 Acc: 75.0000%\n",
      "\ttrain 5-181: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 5-182: Loss: 0.2123 Acc: 50.0000%\n",
      "\ttrain 5-183: Loss: 0.2063 Acc: 75.0000%\n",
      "\ttrain 5-184: Loss: 0.2383 Acc: 50.0000%\n",
      "\ttrain 5-185: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 5-186: Loss: 0.1969 Acc: 50.0000%\n",
      "\ttrain 5-187: Loss: 0.1839 Acc: 50.0000%\n",
      "\ttrain 5-188: Loss: 0.2238 Acc: 50.0000%\n",
      "\ttrain 5-189: Loss: 0.2539 Acc: 50.0000%\n",
      "\ttrain 5-190: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 5-191: Loss: 0.2291 Acc: 25.0000%\n",
      "\ttrain 5-192: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 5-193: Loss: 0.1968 Acc: 75.0000%\n",
      "\ttrain 5-194: Loss: 0.2285 Acc: 50.0000%\n",
      "\ttrain 5-195: Loss: 0.0896 Acc: 100.0000%\n",
      "\ttrain 5-196: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 5-197: Loss: 0.1981 Acc: 75.0000%\n",
      "\ttrain 5-198: Loss: 0.3566 Acc: 50.0000%\n",
      "\ttrain 5-199: Loss: 0.3606 Acc: 0.0000%\n",
      "\ttrain 5-200: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 5-201: Loss: 0.1699 Acc: 50.0000%\n",
      "\ttrain 5-202: Loss: 0.3244 Acc: 25.0000%\n",
      "\ttrain 5-203: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 5-204: Loss: 0.0996 Acc: 100.0000%\n",
      "\ttrain 5-205: Loss: 0.2682 Acc: 75.0000%\n",
      "\ttrain 5-206: Loss: 0.1739 Acc: 50.0000%\n",
      "\ttrain 5-207: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 5-208: Loss: 0.2309 Acc: 50.0000%\n",
      "\ttrain 5-209: Loss: 0.1625 Acc: 50.0000%\n",
      "\ttrain 5-210: Loss: 0.2230 Acc: 50.0000%\n",
      "\ttrain 5-211: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 5-212: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 5-213: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 5-214: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 5-215: Loss: 0.1927 Acc: 75.0000%\n",
      "\ttrain 5-216: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 5-217: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 5-218: Loss: 0.2227 Acc: 75.0000%\n",
      "\ttrain 5-219: Loss: 0.1946 Acc: 50.0000%\n",
      "\ttrain 5-220: Loss: 0.2138 Acc: 50.0000%\n",
      "\ttrain 5-221: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 5-222: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 5-223: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 5-224: Loss: 0.4033 Acc: 25.0000%\n",
      "\ttrain 5-225: Loss: 0.3743 Acc: 25.0000%\n",
      "\ttrain 5-226: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 5-227: Loss: 0.2755 Acc: 25.0000%\n",
      "\ttrain 5-228: Loss: 0.2961 Acc: 50.0000%\n",
      "\ttrain 5-229: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 5-230: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 5-231: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 5-232: Loss: 0.3877 Acc: 25.0000%\n",
      "\ttrain 5-233: Loss: 0.1517 Acc: 75.0000%\n",
      "\ttrain 5-234: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 5-235: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 5-236: Loss: 0.2134 Acc: 50.0000%\n",
      "\ttrain 5-237: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 5-238: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 5-239: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 5-240: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 5-241: Loss: 0.1488 Acc: 50.0000%\n",
      "\ttrain 5-242: Loss: 0.1197 Acc: 50.0000%\n",
      "\ttrain 5-243: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 5-244: Loss: 0.3984 Acc: 25.0000%\n",
      "\ttrain 5-245: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 5-1: Loss: 0.1218 Acc: 75.0000%\n",
      "\tvalidation 5-2: Loss: 0.0493 Acc: 100.0000%\n",
      "\tvalidation 5-3: Loss: 0.1069 Acc: 100.0000%\n",
      "\tvalidation 5-4: Loss: 0.1116 Acc: 50.0000%\n",
      "\tvalidation 5-5: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 5-6: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 5-7: Loss: 0.0811 Acc: 75.0000%\n",
      "\tvalidation 5-8: Loss: 0.1098 Acc: 75.0000%\n",
      "\tvalidation 5-9: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 5-10: Loss: 0.1641 Acc: 50.0000%\n",
      "\tvalidation 5-11: Loss: 0.0944 Acc: 100.0000%\n",
      "\tvalidation 5-12: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 5-13: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 5-14: Loss: 0.0847 Acc: 75.0000%\n",
      "\tvalidation 5-15: Loss: 0.1228 Acc: 50.0000%\n",
      "\tvalidation 5-16: Loss: 0.1151 Acc: 50.0000%\n",
      "\tvalidation 5-17: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 5-18: Loss: 0.0893 Acc: 75.0000%\n",
      "\tvalidation 5-19: Loss: 0.1964 Acc: 75.0000%\n",
      "\tvalidation 5-20: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 5-21: Loss: 0.1298 Acc: 75.0000%\n",
      "\tvalidation 5-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 5-23: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 5-24: Loss: 0.1229 Acc: 75.0000%\n",
      "\tvalidation 5-25: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 5-26: Loss: 0.0823 Acc: 100.0000%\n",
      "\tvalidation 5-27: Loss: 0.1938 Acc: 50.0000%\n",
      "\tvalidation 5-28: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 5-29: Loss: 0.0467 Acc: 75.0000%\n",
      "\tvalidation 5-30: Loss: 0.1066 Acc: 100.0000%\n",
      "\tvalidation 5-31: Loss: 0.0494 Acc: 100.0000%\n",
      "\tvalidation 5-32: Loss: 0.1326 Acc: 75.0000%\n",
      "\tvalidation 5-33: Loss: 0.1008 Acc: 75.0000%\n",
      "\tvalidation 5-34: Loss: 0.0939 Acc: 100.0000%\n",
      "\tvalidation 5-35: Loss: 0.0967 Acc: 75.0000%\n",
      "\tvalidation 5-36: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 5-37: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 5-38: Loss: 0.0623 Acc: 100.0000%\n",
      "\tvalidation 5-39: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 5-40: Loss: 0.2295 Acc: 50.0000%\n",
      "\tvalidation 5-41: Loss: 0.1205 Acc: 50.0000%\n",
      "\tvalidation 5-42: Loss: 0.2122 Acc: 75.0000%\n",
      "\tvalidation 5-43: Loss: 0.1025 Acc: 75.0000%\n",
      "\tvalidation 5-44: Loss: 0.0501 Acc: 100.0000%\n",
      "\tvalidation 5-45: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 5-46: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 5-47: Loss: 0.0556 Acc: 100.0000%\n",
      "\tvalidation 5-48: Loss: 0.0723 Acc: 75.0000%\n",
      "\tvalidation 5-49: Loss: 0.0489 Acc: 75.0000%\n",
      "\tvalidation 5-50: Loss: 0.1458 Acc: 25.0000%\n",
      "\tvalidation 5-51: Loss: 0.0535 Acc: 75.0000%\n",
      "\tvalidation 5-52: Loss: 0.1064 Acc: 100.0000%\n",
      "\tvalidation 5-53: Loss: 0.1162 Acc: 75.0000%\n",
      "\tvalidation 5-54: Loss: 0.0871 Acc: 75.0000%\n",
      "\tvalidation 5-55: Loss: 0.1377 Acc: 50.0000%\n",
      "\tvalidation 5-56: Loss: 0.1094 Acc: 75.0000%\n",
      "\tvalidation 5-57: Loss: 0.1170 Acc: 50.0000%\n",
      "\tvalidation 5-58: Loss: 0.0725 Acc: 100.0000%\n",
      "\tvalidation 5-59: Loss: 0.1274 Acc: 50.0000%\n",
      "\tvalidation 5-60: Loss: 0.1548 Acc: 75.0000%\n",
      "\tvalidation 5-61: Loss: 0.1088 Acc: 75.0000%\n",
      "\tvalidation 5-62: Loss: 0.0901 Acc: 75.0000%\n",
      "\tvalidation 5-63: Loss: 0.0600 Acc: 100.0000%\n",
      "\tvalidation 5-64: Loss: 0.0484 Acc: 75.0000%\n",
      "\tvalidation 5-65: Loss: 0.1345 Acc: 50.0000%\n",
      "\tvalidation 5-66: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 5-67: Loss: 0.1736 Acc: 50.0000%\n",
      "\tvalidation 5-68: Loss: 0.1014 Acc: 100.0000%\n",
      "\tvalidation 5-69: Loss: 0.0938 Acc: 75.0000%\n",
      "\tvalidation 5-70: Loss: 0.1401 Acc: 50.0000%\n",
      "\tvalidation 5-71: Loss: 0.0663 Acc: 100.0000%\n",
      "\tvalidation 5-72: Loss: 0.0560 Acc: 75.0000%\n",
      "\tvalidation 5-73: Loss: 0.1578 Acc: 75.0000%\n",
      "\tvalidation 5-74: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 5-75: Loss: 0.0547 Acc: 100.0000%\n",
      "\tvalidation 5-76: Loss: 0.1531 Acc: 75.0000%\n",
      "\tvalidation 5-77: Loss: 0.1172 Acc: 75.0000%\n",
      "\tvalidation 5-78: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 5-79: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 5-80: Loss: 0.0628 Acc: 100.0000%\n",
      "\tvalidation 5-81: Loss: 0.2434 Acc: 0.0000%\n",
      "\tvalidation 5-82: Loss: 0.2217 Acc: 75.0000%\n",
      "\tvalidation 5-83: Loss: 0.0829 Acc: 100.0000%\n",
      "\tvalidation 5-84: Loss: 0.0643 Acc: 100.0000%\n",
      "\tvalidation 5-85: Loss: 0.0485 Acc: 75.0000%\n",
      "\tvalidation 5-86: Loss: 0.0736 Acc: 75.0000%\n",
      "\tvalidation 5-87: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 5-88: Loss: 0.0977 Acc: 75.0000%\n",
      "\tvalidation 5-89: Loss: 0.0351 Acc: 100.0000%\n",
      "\tvalidation 5-90: Loss: 0.0277 Acc: 100.0000%\n",
      "\tvalidation 5-91: Loss: 0.1183 Acc: 75.0000%\n",
      "\tvalidation 5-92: Loss: 0.1297 Acc: 50.0000%\n",
      "\tvalidation 5-93: Loss: 0.1120 Acc: 75.0000%\n",
      "\tvalidation 5-94: Loss: 0.0507 Acc: 75.0000%\n",
      "\tvalidation 5-95: Loss: 0.1755 Acc: 25.0000%\n",
      "\tvalidation 5-96: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 5-97: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 5-98: Loss: 0.0541 Acc: 75.0000%\n",
      "\tvalidation 5-99: Loss: 0.0596 Acc: 75.0000%\n",
      "\tvalidation 5-100: Loss: 0.1519 Acc: 75.0000%\n",
      "\tvalidation 5-101: Loss: 0.0875 Acc: 75.0000%\n",
      "\tvalidation 5-102: Loss: 0.1182 Acc: 75.0000%\n",
      "\tvalidation 5-103: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 5-104: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 5-105: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain Loss: 0.2077 Acc: 64.4898%\n",
      "\tvalidation Loss: 0.0889 Acc: 80.2381%\n",
      "网络参数更新\n",
      "Time passed 0h 4m 37s\n",
      "--------------------\n",
      "Epoch [6/40]:\n",
      "\ttrain 6-1: Loss: 0.1423 Acc: 50.0000%\n",
      "\ttrain 6-2: Loss: 0.3718 Acc: 25.0000%\n",
      "\ttrain 6-3: Loss: 0.1368 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-4: Loss: 0.1363 Acc: 100.0000%\n",
      "\ttrain 6-5: Loss: 0.1024 Acc: 50.0000%\n",
      "\ttrain 6-6: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 6-7: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 6-8: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 6-9: Loss: 0.5921 Acc: 25.0000%\n",
      "\ttrain 6-10: Loss: 0.1838 Acc: 50.0000%\n",
      "\ttrain 6-11: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 6-12: Loss: 0.0957 Acc: 50.0000%\n",
      "\ttrain 6-13: Loss: 0.0771 Acc: 100.0000%\n",
      "\ttrain 6-14: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 6-15: Loss: 0.4560 Acc: 50.0000%\n",
      "\ttrain 6-16: Loss: 0.2710 Acc: 50.0000%\n",
      "\ttrain 6-17: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 6-18: Loss: 0.3631 Acc: 25.0000%\n",
      "\ttrain 6-19: Loss: 0.2614 Acc: 50.0000%\n",
      "\ttrain 6-20: Loss: 0.1366 Acc: 50.0000%\n",
      "\ttrain 6-21: Loss: 0.2151 Acc: 50.0000%\n",
      "\ttrain 6-22: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 6-23: Loss: 0.1015 Acc: 100.0000%\n",
      "\ttrain 6-24: Loss: 0.2555 Acc: 50.0000%\n",
      "\ttrain 6-25: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 6-26: Loss: 0.3652 Acc: 50.0000%\n",
      "\ttrain 6-27: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 6-28: Loss: 0.2376 Acc: 50.0000%\n",
      "\ttrain 6-29: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 6-30: Loss: 0.2426 Acc: 25.0000%\n",
      "\ttrain 6-31: Loss: 0.0925 Acc: 100.0000%\n",
      "\ttrain 6-32: Loss: 0.2815 Acc: 75.0000%\n",
      "\ttrain 6-33: Loss: 0.2401 Acc: 75.0000%\n",
      "\ttrain 6-34: Loss: 0.2210 Acc: 50.0000%\n",
      "\ttrain 6-35: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 6-36: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 6-37: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 6-38: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 6-39: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 6-40: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 6-41: Loss: 0.2895 Acc: 50.0000%\n",
      "\ttrain 6-42: Loss: 0.5567 Acc: 25.0000%\n",
      "\ttrain 6-43: Loss: 0.3821 Acc: 25.0000%\n",
      "\ttrain 6-44: Loss: 0.2976 Acc: 50.0000%\n",
      "\ttrain 6-45: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 6-46: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 6-47: Loss: 0.1453 Acc: 75.0000%\n",
      "\ttrain 6-48: Loss: 0.1427 Acc: 50.0000%\n",
      "\ttrain 6-49: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 6-50: Loss: 0.1585 Acc: 75.0000%\n",
      "\ttrain 6-51: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 6-52: Loss: 0.3127 Acc: 50.0000%\n",
      "\ttrain 6-53: Loss: 0.1936 Acc: 75.0000%\n",
      "\ttrain 6-54: Loss: 0.2835 Acc: 50.0000%\n",
      "\ttrain 6-55: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 6-56: Loss: 0.0865 Acc: 100.0000%\n",
      "\ttrain 6-57: Loss: 0.3701 Acc: 50.0000%\n",
      "\ttrain 6-58: Loss: 0.4117 Acc: 25.0000%\n",
      "\ttrain 6-59: Loss: 0.1699 Acc: 50.0000%\n",
      "\ttrain 6-60: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 6-61: Loss: 0.0872 Acc: 100.0000%\n",
      "\ttrain 6-62: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 6-63: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 6-64: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 6-65: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 6-66: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 6-67: Loss: 0.1925 Acc: 50.0000%\n",
      "\ttrain 6-68: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 6-69: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 6-70: Loss: 0.1921 Acc: 75.0000%\n",
      "\ttrain 6-71: Loss: 0.3928 Acc: 50.0000%\n",
      "\ttrain 6-72: Loss: 0.0645 Acc: 100.0000%\n",
      "\ttrain 6-73: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 6-74: Loss: 0.1482 Acc: 100.0000%\n",
      "\ttrain 6-75: Loss: 0.5029 Acc: 25.0000%\n",
      "\ttrain 6-76: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 6-77: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 6-78: Loss: 0.2744 Acc: 50.0000%\n",
      "\ttrain 6-79: Loss: 0.1766 Acc: 75.0000%\n",
      "\ttrain 6-80: Loss: 0.3094 Acc: 75.0000%\n",
      "\ttrain 6-81: Loss: 0.1040 Acc: 100.0000%\n",
      "\ttrain 6-82: Loss: 0.2283 Acc: 75.0000%\n",
      "\ttrain 6-83: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 6-84: Loss: 0.2210 Acc: 50.0000%\n",
      "\ttrain 6-85: Loss: 0.2072 Acc: 50.0000%\n",
      "\ttrain 6-86: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 6-87: Loss: 0.1760 Acc: 50.0000%\n",
      "\ttrain 6-88: Loss: 0.1449 Acc: 75.0000%\n",
      "\ttrain 6-89: Loss: 0.4969 Acc: 0.0000%\n",
      "\ttrain 6-90: Loss: 0.1632 Acc: 50.0000%\n",
      "\ttrain 6-91: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 6-92: Loss: 0.1808 Acc: 75.0000%\n",
      "\ttrain 6-93: Loss: 0.3385 Acc: 50.0000%\n",
      "\ttrain 6-94: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 6-95: Loss: 0.2752 Acc: 50.0000%\n",
      "\ttrain 6-96: Loss: 0.2398 Acc: 25.0000%\n",
      "\ttrain 6-97: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 6-98: Loss: 0.1794 Acc: 50.0000%\n",
      "\ttrain 6-99: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 6-100: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 6-101: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 6-102: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 6-103: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 6-104: Loss: 0.2122 Acc: 75.0000%\n",
      "\ttrain 6-105: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 6-106: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 6-107: Loss: 0.2934 Acc: 25.0000%\n",
      "\ttrain 6-108: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 6-109: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 6-110: Loss: 0.1495 Acc: 50.0000%\n",
      "\ttrain 6-111: Loss: 0.3045 Acc: 75.0000%\n",
      "\ttrain 6-112: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 6-113: Loss: 0.1403 Acc: 50.0000%\n",
      "\ttrain 6-114: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 6-115: Loss: 0.1015 Acc: 100.0000%\n",
      "\ttrain 6-116: Loss: 0.1550 Acc: 50.0000%\n",
      "\ttrain 6-117: Loss: 0.2518 Acc: 50.0000%\n",
      "\ttrain 6-118: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 6-119: Loss: 0.2593 Acc: 25.0000%\n",
      "\ttrain 6-120: Loss: 0.3327 Acc: 50.0000%\n",
      "\ttrain 6-121: Loss: 0.3112 Acc: 50.0000%\n",
      "\ttrain 6-122: Loss: 0.1764 Acc: 50.0000%\n",
      "\ttrain 6-123: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 6-124: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 6-125: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 6-126: Loss: 0.5101 Acc: 25.0000%\n",
      "\ttrain 6-127: Loss: 0.1915 Acc: 50.0000%\n",
      "\ttrain 6-128: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 6-129: Loss: 0.1372 Acc: 75.0000%\n",
      "\ttrain 6-130: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 6-131: Loss: 0.2662 Acc: 75.0000%\n",
      "\ttrain 6-132: Loss: 0.1752 Acc: 50.0000%\n",
      "\ttrain 6-133: Loss: 0.4485 Acc: 25.0000%\n",
      "\ttrain 6-134: Loss: 0.1905 Acc: 50.0000%\n",
      "\ttrain 6-135: Loss: 0.4015 Acc: 75.0000%\n",
      "\ttrain 6-136: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 6-137: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 6-138: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 6-139: Loss: 0.2026 Acc: 50.0000%\n",
      "\ttrain 6-140: Loss: 0.2485 Acc: 75.0000%\n",
      "\ttrain 6-141: Loss: 0.4275 Acc: 50.0000%\n",
      "\ttrain 6-142: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 6-143: Loss: 0.1814 Acc: 50.0000%\n",
      "\ttrain 6-144: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 6-145: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 6-146: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 6-147: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 6-148: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 6-149: Loss: 0.1667 Acc: 75.0000%\n",
      "\ttrain 6-150: Loss: 0.1448 Acc: 75.0000%\n",
      "\ttrain 6-151: Loss: 0.4905 Acc: 50.0000%\n",
      "\ttrain 6-152: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 6-153: Loss: 0.3655 Acc: 50.0000%\n",
      "\ttrain 6-154: Loss: 0.2020 Acc: 50.0000%\n",
      "\ttrain 6-155: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 6-156: Loss: 0.2018 Acc: 50.0000%\n",
      "\ttrain 6-157: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 6-158: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 6-159: Loss: 0.1543 Acc: 50.0000%\n",
      "\ttrain 6-160: Loss: 0.3711 Acc: 75.0000%\n",
      "\ttrain 6-161: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 6-162: Loss: 0.2430 Acc: 50.0000%\n",
      "\ttrain 6-163: Loss: 0.2232 Acc: 75.0000%\n",
      "\ttrain 6-164: Loss: 0.5224 Acc: 25.0000%\n",
      "\ttrain 6-165: Loss: 0.3146 Acc: 50.0000%\n",
      "\ttrain 6-166: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 6-167: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 6-168: Loss: 0.3954 Acc: 25.0000%\n",
      "\ttrain 6-169: Loss: 0.1945 Acc: 50.0000%\n",
      "\ttrain 6-170: Loss: 0.7569 Acc: 0.0000%\n",
      "\ttrain 6-171: Loss: 0.3162 Acc: 50.0000%\n",
      "\ttrain 6-172: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 6-173: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 6-174: Loss: 0.1991 Acc: 75.0000%\n",
      "\ttrain 6-175: Loss: 0.0930 Acc: 100.0000%\n",
      "\ttrain 6-176: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 6-177: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 6-178: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 6-179: Loss: 0.2585 Acc: 50.0000%\n",
      "\ttrain 6-180: Loss: 0.3174 Acc: 50.0000%\n",
      "\ttrain 6-181: Loss: 0.1554 Acc: 75.0000%\n",
      "\ttrain 6-182: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 6-183: Loss: 0.2102 Acc: 75.0000%\n",
      "\ttrain 6-184: Loss: 0.2807 Acc: 50.0000%\n",
      "\ttrain 6-185: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 6-186: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 6-187: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 6-188: Loss: 0.1751 Acc: 50.0000%\n",
      "\ttrain 6-189: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 6-190: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 6-191: Loss: 0.2295 Acc: 75.0000%\n",
      "\ttrain 6-192: Loss: 0.2336 Acc: 50.0000%\n",
      "\ttrain 6-193: Loss: 0.0909 Acc: 100.0000%\n",
      "\ttrain 6-194: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 6-195: Loss: 0.2286 Acc: 25.0000%\n",
      "\ttrain 6-196: Loss: 0.4497 Acc: 25.0000%\n",
      "\ttrain 6-197: Loss: 0.1643 Acc: 50.0000%\n",
      "\ttrain 6-198: Loss: 0.1488 Acc: 50.0000%\n",
      "\ttrain 6-199: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 6-200: Loss: 0.4488 Acc: 0.0000%\n",
      "\ttrain 6-201: Loss: 0.2622 Acc: 25.0000%\n",
      "\ttrain 6-202: Loss: 0.1614 Acc: 50.0000%\n",
      "\ttrain 6-203: Loss: 0.1542 Acc: 50.0000%\n",
      "\ttrain 6-204: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 6-205: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 6-206: Loss: 0.1107 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-207: Loss: 0.1369 Acc: 75.0000%\n",
      "\ttrain 6-208: Loss: 0.4198 Acc: 50.0000%\n",
      "\ttrain 6-209: Loss: 0.3036 Acc: 25.0000%\n",
      "\ttrain 6-210: Loss: 0.4374 Acc: 75.0000%\n",
      "\ttrain 6-211: Loss: 0.3687 Acc: 25.0000%\n",
      "\ttrain 6-212: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 6-213: Loss: 0.2630 Acc: 50.0000%\n",
      "\ttrain 6-214: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 6-215: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 6-216: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 6-217: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 6-218: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 6-219: Loss: 0.4187 Acc: 50.0000%\n",
      "\ttrain 6-220: Loss: 0.2703 Acc: 50.0000%\n",
      "\ttrain 6-221: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 6-222: Loss: 0.3508 Acc: 50.0000%\n",
      "\ttrain 6-223: Loss: 0.2275 Acc: 25.0000%\n",
      "\ttrain 6-224: Loss: 0.2182 Acc: 25.0000%\n",
      "\ttrain 6-225: Loss: 0.1990 Acc: 75.0000%\n",
      "\ttrain 6-226: Loss: 0.1281 Acc: 50.0000%\n",
      "\ttrain 6-227: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 6-228: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 6-229: Loss: 0.2664 Acc: 25.0000%\n",
      "\ttrain 6-230: Loss: 0.4492 Acc: 50.0000%\n",
      "\ttrain 6-231: Loss: 0.5462 Acc: 50.0000%\n",
      "\ttrain 6-232: Loss: 0.2482 Acc: 50.0000%\n",
      "\ttrain 6-233: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 6-234: Loss: 0.0913 Acc: 100.0000%\n",
      "\ttrain 6-235: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 6-236: Loss: 0.2901 Acc: 50.0000%\n",
      "\ttrain 6-237: Loss: 0.1876 Acc: 75.0000%\n",
      "\ttrain 6-238: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 6-239: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 6-240: Loss: 0.1637 Acc: 50.0000%\n",
      "\ttrain 6-241: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 6-242: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 6-243: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 6-244: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 6-245: Loss: 0.3625 Acc: 75.0000%\n",
      "\tvalidation 6-1: Loss: 1.7297 Acc: 25.0000%\n",
      "\tvalidation 6-2: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 6-3: Loss: 0.2134 Acc: 75.0000%\n",
      "\tvalidation 6-4: Loss: 0.0597 Acc: 100.0000%\n",
      "\tvalidation 6-5: Loss: 0.1042 Acc: 75.0000%\n",
      "\tvalidation 6-6: Loss: 2.5891 Acc: 75.0000%\n",
      "\tvalidation 6-7: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 6-8: Loss: 0.1300 Acc: 75.0000%\n",
      "\tvalidation 6-9: Loss: 0.6742 Acc: 50.0000%\n",
      "\tvalidation 6-10: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 6-11: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 6-12: Loss: 0.2057 Acc: 50.0000%\n",
      "\tvalidation 6-13: Loss: 1.5536 Acc: 75.0000%\n",
      "\tvalidation 6-14: Loss: 4.9352 Acc: 25.0000%\n",
      "\tvalidation 6-15: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 6-16: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 6-17: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 6-18: Loss: 0.1790 Acc: 50.0000%\n",
      "\tvalidation 6-19: Loss: 0.0930 Acc: 75.0000%\n",
      "\tvalidation 6-20: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 6-21: Loss: 0.1334 Acc: 75.0000%\n",
      "\tvalidation 6-22: Loss: 0.4536 Acc: 50.0000%\n",
      "\tvalidation 6-23: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 6-24: Loss: 0.2109 Acc: 75.0000%\n",
      "\tvalidation 6-25: Loss: 6.8476 Acc: 75.0000%\n",
      "\tvalidation 6-26: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 6-27: Loss: 0.1854 Acc: 75.0000%\n",
      "\tvalidation 6-28: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 6-29: Loss: 0.1624 Acc: 50.0000%\n",
      "\tvalidation 6-30: Loss: 0.0671 Acc: 75.0000%\n",
      "\tvalidation 6-31: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 6-32: Loss: 0.4817 Acc: 50.0000%\n",
      "\tvalidation 6-33: Loss: 0.2920 Acc: 50.0000%\n",
      "\tvalidation 6-34: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 6-35: Loss: 0.0511 Acc: 100.0000%\n",
      "\tvalidation 6-36: Loss: 0.0838 Acc: 75.0000%\n",
      "\tvalidation 6-37: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 6-38: Loss: 0.2020 Acc: 75.0000%\n",
      "\tvalidation 6-39: Loss: 0.0968 Acc: 75.0000%\n",
      "\tvalidation 6-40: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 6-41: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 6-42: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 6-43: Loss: 0.1170 Acc: 75.0000%\n",
      "\tvalidation 6-44: Loss: 0.4023 Acc: 50.0000%\n",
      "\tvalidation 6-45: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 6-46: Loss: 0.1085 Acc: 75.0000%\n",
      "\tvalidation 6-47: Loss: 0.1480 Acc: 50.0000%\n",
      "\tvalidation 6-48: Loss: 0.0578 Acc: 75.0000%\n",
      "\tvalidation 6-49: Loss: 0.2150 Acc: 75.0000%\n",
      "\tvalidation 6-50: Loss: 5.2528 Acc: 50.0000%\n",
      "\tvalidation 6-51: Loss: 0.2253 Acc: 50.0000%\n",
      "\tvalidation 6-52: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 6-53: Loss: 0.2384 Acc: 25.0000%\n",
      "\tvalidation 6-54: Loss: 0.3682 Acc: 75.0000%\n",
      "\tvalidation 6-55: Loss: 0.1216 Acc: 75.0000%\n",
      "\tvalidation 6-56: Loss: 0.1178 Acc: 75.0000%\n",
      "\tvalidation 6-57: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 6-58: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 6-59: Loss: 0.4245 Acc: 75.0000%\n",
      "\tvalidation 6-60: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 6-61: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 6-62: Loss: 2.5027 Acc: 0.0000%\n",
      "\tvalidation 6-63: Loss: 0.1694 Acc: 50.0000%\n",
      "\tvalidation 6-64: Loss: 0.2150 Acc: 50.0000%\n",
      "\tvalidation 6-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 6-66: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 6-67: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 6-68: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 6-69: Loss: 0.2775 Acc: 50.0000%\n",
      "\tvalidation 6-70: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 6-71: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 6-72: Loss: 0.0922 Acc: 75.0000%\n",
      "\tvalidation 6-73: Loss: 1.3605 Acc: 50.0000%\n",
      "\tvalidation 6-74: Loss: 0.0853 Acc: 75.0000%\n",
      "\tvalidation 6-75: Loss: 0.0819 Acc: 75.0000%\n",
      "\tvalidation 6-76: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 6-77: Loss: 0.0871 Acc: 75.0000%\n",
      "\tvalidation 6-78: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 6-79: Loss: 0.1037 Acc: 75.0000%\n",
      "\tvalidation 6-80: Loss: 0.9816 Acc: 25.0000%\n",
      "\tvalidation 6-81: Loss: 1.0645 Acc: 75.0000%\n",
      "\tvalidation 6-82: Loss: 1.3618 Acc: 75.0000%\n",
      "\tvalidation 6-83: Loss: 0.0854 Acc: 75.0000%\n",
      "\tvalidation 6-84: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 6-85: Loss: 0.3878 Acc: 25.0000%\n",
      "\tvalidation 6-86: Loss: 0.1014 Acc: 75.0000%\n",
      "\tvalidation 6-87: Loss: 0.7344 Acc: 50.0000%\n",
      "\tvalidation 6-88: Loss: 0.0959 Acc: 75.0000%\n",
      "\tvalidation 6-89: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 6-90: Loss: 0.4357 Acc: 50.0000%\n",
      "\tvalidation 6-91: Loss: 1.0369 Acc: 50.0000%\n",
      "\tvalidation 6-92: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 6-93: Loss: 0.4317 Acc: 50.0000%\n",
      "\tvalidation 6-94: Loss: 0.1242 Acc: 75.0000%\n",
      "\tvalidation 6-95: Loss: 0.1472 Acc: 75.0000%\n",
      "\tvalidation 6-96: Loss: 0.0962 Acc: 75.0000%\n",
      "\tvalidation 6-97: Loss: 0.1128 Acc: 75.0000%\n",
      "\tvalidation 6-98: Loss: 0.4901 Acc: 50.0000%\n",
      "\tvalidation 6-99: Loss: 0.1797 Acc: 50.0000%\n",
      "\tvalidation 6-100: Loss: 0.1209 Acc: 75.0000%\n",
      "\tvalidation 6-101: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 6-102: Loss: 0.5305 Acc: 50.0000%\n",
      "\tvalidation 6-103: Loss: 0.0896 Acc: 75.0000%\n",
      "\tvalidation 6-104: Loss: 0.0855 Acc: 75.0000%\n",
      "\tvalidation 6-105: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1908 Acc: 66.4286%\n",
      "\tvalidation Loss: 0.4227 Acc: 74.0476%\n",
      "Time passed 0h 5m 30s\n",
      "--------------------\n",
      "Epoch [7/40]:\n",
      "\ttrain 7-1: Loss: 0.2877 Acc: 50.0000%\n",
      "\ttrain 7-2: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 7-3: Loss: 0.1689 Acc: 75.0000%\n",
      "\ttrain 7-4: Loss: 0.3365 Acc: 75.0000%\n",
      "\ttrain 7-5: Loss: 0.2992 Acc: 50.0000%\n",
      "\ttrain 7-6: Loss: 0.3540 Acc: 50.0000%\n",
      "\ttrain 7-7: Loss: 0.1380 Acc: 50.0000%\n",
      "\ttrain 7-8: Loss: 0.1169 Acc: 100.0000%\n",
      "\ttrain 7-9: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 7-10: Loss: 0.2890 Acc: 25.0000%\n",
      "\ttrain 7-11: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 7-12: Loss: 0.2160 Acc: 50.0000%\n",
      "\ttrain 7-13: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 7-14: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 7-15: Loss: 0.2597 Acc: 50.0000%\n",
      "\ttrain 7-16: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 7-17: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 7-18: Loss: 0.1677 Acc: 50.0000%\n",
      "\ttrain 7-19: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 7-20: Loss: 0.6448 Acc: 0.0000%\n",
      "\ttrain 7-21: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 7-22: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 7-23: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 7-24: Loss: 0.2680 Acc: 25.0000%\n",
      "\ttrain 7-25: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 7-26: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 7-27: Loss: 0.1792 Acc: 75.0000%\n",
      "\ttrain 7-28: Loss: 0.2209 Acc: 50.0000%\n",
      "\ttrain 7-29: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 7-30: Loss: 0.2465 Acc: 50.0000%\n",
      "\ttrain 7-31: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 7-32: Loss: 0.1508 Acc: 50.0000%\n",
      "\ttrain 7-33: Loss: 0.2031 Acc: 75.0000%\n",
      "\ttrain 7-34: Loss: 0.0991 Acc: 100.0000%\n",
      "\ttrain 7-35: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 7-36: Loss: 0.6135 Acc: 25.0000%\n",
      "\ttrain 7-37: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 7-38: Loss: 0.2506 Acc: 50.0000%\n",
      "\ttrain 7-39: Loss: 0.2905 Acc: 25.0000%\n",
      "\ttrain 7-40: Loss: 0.2452 Acc: 25.0000%\n",
      "\ttrain 7-41: Loss: 0.2018 Acc: 50.0000%\n",
      "\ttrain 7-42: Loss: 0.2093 Acc: 75.0000%\n",
      "\ttrain 7-43: Loss: 0.2844 Acc: 25.0000%\n",
      "\ttrain 7-44: Loss: 0.0322 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-45: Loss: 0.4150 Acc: 50.0000%\n",
      "\ttrain 7-46: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 7-47: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 7-48: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 7-49: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 7-50: Loss: 0.2872 Acc: 25.0000%\n",
      "\ttrain 7-51: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 7-52: Loss: 0.2154 Acc: 75.0000%\n",
      "\ttrain 7-53: Loss: 0.2267 Acc: 75.0000%\n",
      "\ttrain 7-54: Loss: 0.2239 Acc: 50.0000%\n",
      "\ttrain 7-55: Loss: 0.2947 Acc: 50.0000%\n",
      "\ttrain 7-56: Loss: 0.3038 Acc: 50.0000%\n",
      "\ttrain 7-57: Loss: 0.3198 Acc: 25.0000%\n",
      "\ttrain 7-58: Loss: 0.2688 Acc: 75.0000%\n",
      "\ttrain 7-59: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 7-60: Loss: 0.1826 Acc: 75.0000%\n",
      "\ttrain 7-61: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 7-62: Loss: 0.4164 Acc: 50.0000%\n",
      "\ttrain 7-63: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 7-64: Loss: 0.3215 Acc: 50.0000%\n",
      "\ttrain 7-65: Loss: 0.4021 Acc: 25.0000%\n",
      "\ttrain 7-66: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 7-67: Loss: 0.4474 Acc: 50.0000%\n",
      "\ttrain 7-68: Loss: 0.5120 Acc: 25.0000%\n",
      "\ttrain 7-69: Loss: 0.2318 Acc: 50.0000%\n",
      "\ttrain 7-70: Loss: 0.0673 Acc: 100.0000%\n",
      "\ttrain 7-71: Loss: 0.3203 Acc: 50.0000%\n",
      "\ttrain 7-72: Loss: 0.1625 Acc: 50.0000%\n",
      "\ttrain 7-73: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 7-74: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 7-75: Loss: 0.2481 Acc: 50.0000%\n",
      "\ttrain 7-76: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 7-77: Loss: 0.4520 Acc: 25.0000%\n",
      "\ttrain 7-78: Loss: 0.3405 Acc: 50.0000%\n",
      "\ttrain 7-79: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 7-80: Loss: 0.1531 Acc: 75.0000%\n",
      "\ttrain 7-81: Loss: 0.1733 Acc: 75.0000%\n",
      "\ttrain 7-82: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 7-83: Loss: 0.1867 Acc: 75.0000%\n",
      "\ttrain 7-84: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 7-85: Loss: 0.1117 Acc: 100.0000%\n",
      "\ttrain 7-86: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 7-87: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 7-88: Loss: 0.1826 Acc: 50.0000%\n",
      "\ttrain 7-89: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 7-90: Loss: 0.0809 Acc: 100.0000%\n",
      "\ttrain 7-91: Loss: 0.1914 Acc: 50.0000%\n",
      "\ttrain 7-92: Loss: 0.1877 Acc: 50.0000%\n",
      "\ttrain 7-93: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 7-94: Loss: 0.3386 Acc: 50.0000%\n",
      "\ttrain 7-95: Loss: 0.3367 Acc: 50.0000%\n",
      "\ttrain 7-96: Loss: 0.1471 Acc: 50.0000%\n",
      "\ttrain 7-97: Loss: 0.3901 Acc: 25.0000%\n",
      "\ttrain 7-98: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 7-99: Loss: 0.3691 Acc: 75.0000%\n",
      "\ttrain 7-100: Loss: 0.1863 Acc: 100.0000%\n",
      "\ttrain 7-101: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 7-102: Loss: 0.3288 Acc: 25.0000%\n",
      "\ttrain 7-103: Loss: 0.3237 Acc: 25.0000%\n",
      "\ttrain 7-104: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 7-105: Loss: 0.3270 Acc: 25.0000%\n",
      "\ttrain 7-106: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 7-107: Loss: 0.1437 Acc: 75.0000%\n",
      "\ttrain 7-108: Loss: 0.1222 Acc: 50.0000%\n",
      "\ttrain 7-109: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 7-110: Loss: 0.1022 Acc: 100.0000%\n",
      "\ttrain 7-111: Loss: 0.2095 Acc: 50.0000%\n",
      "\ttrain 7-112: Loss: 0.1795 Acc: 50.0000%\n",
      "\ttrain 7-113: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 7-114: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 7-115: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 7-116: Loss: 0.1723 Acc: 50.0000%\n",
      "\ttrain 7-117: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 7-118: Loss: 0.1260 Acc: 50.0000%\n",
      "\ttrain 7-119: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 7-120: Loss: 0.1535 Acc: 75.0000%\n",
      "\ttrain 7-121: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 7-122: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 7-123: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 7-124: Loss: 0.1621 Acc: 75.0000%\n",
      "\ttrain 7-125: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 7-126: Loss: 0.3166 Acc: 75.0000%\n",
      "\ttrain 7-127: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 7-128: Loss: 0.1423 Acc: 50.0000%\n",
      "\ttrain 7-129: Loss: 0.1709 Acc: 75.0000%\n",
      "\ttrain 7-130: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 7-131: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 7-132: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 7-133: Loss: 0.2909 Acc: 50.0000%\n",
      "\ttrain 7-134: Loss: 0.0958 Acc: 100.0000%\n",
      "\ttrain 7-135: Loss: 0.1868 Acc: 50.0000%\n",
      "\ttrain 7-136: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 7-137: Loss: 0.0875 Acc: 100.0000%\n",
      "\ttrain 7-138: Loss: 0.3878 Acc: 25.0000%\n",
      "\ttrain 7-139: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 7-140: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 7-141: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 7-142: Loss: 0.3345 Acc: 25.0000%\n",
      "\ttrain 7-143: Loss: 0.2410 Acc: 50.0000%\n",
      "\ttrain 7-144: Loss: 0.2041 Acc: 25.0000%\n",
      "\ttrain 7-145: Loss: 0.4654 Acc: 75.0000%\n",
      "\ttrain 7-146: Loss: 0.1491 Acc: 50.0000%\n",
      "\ttrain 7-147: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 7-148: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 7-149: Loss: 0.0519 Acc: 75.0000%\n",
      "\ttrain 7-150: Loss: 0.3401 Acc: 25.0000%\n",
      "\ttrain 7-151: Loss: 0.1558 Acc: 50.0000%\n",
      "\ttrain 7-152: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 7-153: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 7-154: Loss: 0.2871 Acc: 0.0000%\n",
      "\ttrain 7-155: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 7-156: Loss: 0.0927 Acc: 100.0000%\n",
      "\ttrain 7-157: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 7-158: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 7-159: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 7-160: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 7-161: Loss: 0.3153 Acc: 25.0000%\n",
      "\ttrain 7-162: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 7-163: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 7-164: Loss: 0.1393 Acc: 50.0000%\n",
      "\ttrain 7-165: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 7-166: Loss: 0.2916 Acc: 75.0000%\n",
      "\ttrain 7-167: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 7-168: Loss: 0.3395 Acc: 75.0000%\n",
      "\ttrain 7-169: Loss: 0.2847 Acc: 25.0000%\n",
      "\ttrain 7-170: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 7-171: Loss: 0.1529 Acc: 50.0000%\n",
      "\ttrain 7-172: Loss: 0.3412 Acc: 50.0000%\n",
      "\ttrain 7-173: Loss: 0.1649 Acc: 50.0000%\n",
      "\ttrain 7-174: Loss: 0.1054 Acc: 100.0000%\n",
      "\ttrain 7-175: Loss: 0.0704 Acc: 100.0000%\n",
      "\ttrain 7-176: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 7-177: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 7-178: Loss: 0.1018 Acc: 100.0000%\n",
      "\ttrain 7-179: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 7-180: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 7-181: Loss: 0.1001 Acc: 75.0000%\n",
      "\ttrain 7-182: Loss: 0.1758 Acc: 50.0000%\n",
      "\ttrain 7-183: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 7-184: Loss: 0.2557 Acc: 75.0000%\n",
      "\ttrain 7-185: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 7-186: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 7-187: Loss: 0.1349 Acc: 50.0000%\n",
      "\ttrain 7-188: Loss: 0.1296 Acc: 100.0000%\n",
      "\ttrain 7-189: Loss: 0.0983 Acc: 100.0000%\n",
      "\ttrain 7-190: Loss: 0.7335 Acc: 25.0000%\n",
      "\ttrain 7-191: Loss: 0.2059 Acc: 50.0000%\n",
      "\ttrain 7-192: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 7-193: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 7-194: Loss: 0.4631 Acc: 0.0000%\n",
      "\ttrain 7-195: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 7-196: Loss: 0.0756 Acc: 100.0000%\n",
      "\ttrain 7-197: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 7-198: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 7-199: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 7-200: Loss: 0.2593 Acc: 50.0000%\n",
      "\ttrain 7-201: Loss: 0.4095 Acc: 0.0000%\n",
      "\ttrain 7-202: Loss: 0.3024 Acc: 25.0000%\n",
      "\ttrain 7-203: Loss: 0.0810 Acc: 75.0000%\n",
      "\ttrain 7-204: Loss: 0.1613 Acc: 50.0000%\n",
      "\ttrain 7-205: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 7-206: Loss: 0.2284 Acc: 50.0000%\n",
      "\ttrain 7-207: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 7-208: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 7-209: Loss: 0.4496 Acc: 0.0000%\n",
      "\ttrain 7-210: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 7-211: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 7-212: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 7-213: Loss: 0.1889 Acc: 50.0000%\n",
      "\ttrain 7-214: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 7-215: Loss: 0.1475 Acc: 50.0000%\n",
      "\ttrain 7-216: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 7-217: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 7-218: Loss: 0.0986 Acc: 100.0000%\n",
      "\ttrain 7-219: Loss: 0.3385 Acc: 0.0000%\n",
      "\ttrain 7-220: Loss: 0.1931 Acc: 50.0000%\n",
      "\ttrain 7-221: Loss: 0.1360 Acc: 100.0000%\n",
      "\ttrain 7-222: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 7-223: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 7-224: Loss: 0.3256 Acc: 50.0000%\n",
      "\ttrain 7-225: Loss: 0.2071 Acc: 50.0000%\n",
      "\ttrain 7-226: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 7-227: Loss: 0.1346 Acc: 50.0000%\n",
      "\ttrain 7-228: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 7-229: Loss: 0.4064 Acc: 0.0000%\n",
      "\ttrain 7-230: Loss: 0.4840 Acc: 0.0000%\n",
      "\ttrain 7-231: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 7-232: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 7-233: Loss: 0.2294 Acc: 25.0000%\n",
      "\ttrain 7-234: Loss: 0.2752 Acc: 50.0000%\n",
      "\ttrain 7-235: Loss: 0.0788 Acc: 100.0000%\n",
      "\ttrain 7-236: Loss: 0.1480 Acc: 50.0000%\n",
      "\ttrain 7-237: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 7-238: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 7-239: Loss: 0.2254 Acc: 75.0000%\n",
      "\ttrain 7-240: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 7-241: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 7-242: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 7-243: Loss: 0.0630 Acc: 100.0000%\n",
      "\ttrain 7-244: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 7-245: Loss: 0.1573 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 7-1: Loss: 0.1488 Acc: 25.0000%\n",
      "\tvalidation 7-2: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 7-3: Loss: 0.0572 Acc: 100.0000%\n",
      "\tvalidation 7-4: Loss: 0.2732 Acc: 75.0000%\n",
      "\tvalidation 7-5: Loss: 0.2816 Acc: 50.0000%\n",
      "\tvalidation 7-6: Loss: 0.1070 Acc: 75.0000%\n",
      "\tvalidation 7-7: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 7-8: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 7-9: Loss: 0.2102 Acc: 75.0000%\n",
      "\tvalidation 7-10: Loss: 0.2632 Acc: 75.0000%\n",
      "\tvalidation 7-11: Loss: 0.1178 Acc: 75.0000%\n",
      "\tvalidation 7-12: Loss: 0.3370 Acc: 50.0000%\n",
      "\tvalidation 7-13: Loss: 0.1440 Acc: 50.0000%\n",
      "\tvalidation 7-14: Loss: 0.0241 Acc: 100.0000%\n",
      "\tvalidation 7-15: Loss: 0.1235 Acc: 75.0000%\n",
      "\tvalidation 7-16: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 7-17: Loss: 0.0550 Acc: 100.0000%\n",
      "\tvalidation 7-18: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 7-19: Loss: 0.1436 Acc: 75.0000%\n",
      "\tvalidation 7-20: Loss: 0.3165 Acc: 50.0000%\n",
      "\tvalidation 7-21: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 7-22: Loss: 0.0909 Acc: 75.0000%\n",
      "\tvalidation 7-23: Loss: 0.1604 Acc: 75.0000%\n",
      "\tvalidation 7-24: Loss: 0.2064 Acc: 75.0000%\n",
      "\tvalidation 7-25: Loss: 0.1969 Acc: 75.0000%\n",
      "\tvalidation 7-26: Loss: 0.3462 Acc: 50.0000%\n",
      "\tvalidation 7-27: Loss: 0.2296 Acc: 50.0000%\n",
      "\tvalidation 7-28: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 7-29: Loss: 0.1821 Acc: 75.0000%\n",
      "\tvalidation 7-30: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 7-31: Loss: 0.9231 Acc: 75.0000%\n",
      "\tvalidation 7-32: Loss: 0.0419 Acc: 100.0000%\n",
      "\tvalidation 7-33: Loss: 0.0642 Acc: 75.0000%\n",
      "\tvalidation 7-34: Loss: 0.0728 Acc: 100.0000%\n",
      "\tvalidation 7-35: Loss: 0.3137 Acc: 75.0000%\n",
      "\tvalidation 7-36: Loss: 0.0454 Acc: 100.0000%\n",
      "\tvalidation 7-37: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 7-38: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 7-39: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 7-40: Loss: 0.0655 Acc: 100.0000%\n",
      "\tvalidation 7-41: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 7-42: Loss: 0.0906 Acc: 75.0000%\n",
      "\tvalidation 7-43: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 7-44: Loss: 0.0768 Acc: 100.0000%\n",
      "\tvalidation 7-45: Loss: 0.0909 Acc: 75.0000%\n",
      "\tvalidation 7-46: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 7-47: Loss: 0.0608 Acc: 100.0000%\n",
      "\tvalidation 7-48: Loss: 0.0931 Acc: 75.0000%\n",
      "\tvalidation 7-49: Loss: 0.0497 Acc: 100.0000%\n",
      "\tvalidation 7-50: Loss: 0.0652 Acc: 100.0000%\n",
      "\tvalidation 7-51: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 7-52: Loss: 0.0834 Acc: 75.0000%\n",
      "\tvalidation 7-53: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 7-54: Loss: 0.0670 Acc: 75.0000%\n",
      "\tvalidation 7-55: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 7-56: Loss: 0.0653 Acc: 100.0000%\n",
      "\tvalidation 7-57: Loss: 0.0765 Acc: 75.0000%\n",
      "\tvalidation 7-58: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 7-59: Loss: 0.8108 Acc: 75.0000%\n",
      "\tvalidation 7-60: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 7-61: Loss: 0.0722 Acc: 75.0000%\n",
      "\tvalidation 7-62: Loss: 0.1668 Acc: 75.0000%\n",
      "\tvalidation 7-63: Loss: 0.0703 Acc: 75.0000%\n",
      "\tvalidation 7-64: Loss: 0.0523 Acc: 75.0000%\n",
      "\tvalidation 7-65: Loss: 0.8201 Acc: 75.0000%\n",
      "\tvalidation 7-66: Loss: 0.0519 Acc: 100.0000%\n",
      "\tvalidation 7-67: Loss: 0.1575 Acc: 75.0000%\n",
      "\tvalidation 7-68: Loss: 0.1248 Acc: 75.0000%\n",
      "\tvalidation 7-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 7-70: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 7-71: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 7-72: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 7-73: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 7-74: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 7-75: Loss: 0.2976 Acc: 50.0000%\n",
      "\tvalidation 7-76: Loss: 0.1219 Acc: 75.0000%\n",
      "\tvalidation 7-77: Loss: 1.2628 Acc: 75.0000%\n",
      "\tvalidation 7-78: Loss: 0.1933 Acc: 75.0000%\n",
      "\tvalidation 7-79: Loss: 0.0634 Acc: 75.0000%\n",
      "\tvalidation 7-80: Loss: 0.1091 Acc: 50.0000%\n",
      "\tvalidation 7-81: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 7-82: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 7-83: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 7-84: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 7-85: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 7-86: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 7-87: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 7-88: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 7-89: Loss: 0.0923 Acc: 75.0000%\n",
      "\tvalidation 7-90: Loss: 0.0407 Acc: 100.0000%\n",
      "\tvalidation 7-91: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 7-92: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 7-93: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 7-94: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 7-95: Loss: 0.0674 Acc: 100.0000%\n",
      "\tvalidation 7-96: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 7-97: Loss: 0.1273 Acc: 75.0000%\n",
      "\tvalidation 7-98: Loss: 0.0493 Acc: 100.0000%\n",
      "\tvalidation 7-99: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 7-100: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 7-101: Loss: 0.1806 Acc: 75.0000%\n",
      "\tvalidation 7-102: Loss: 0.0997 Acc: 75.0000%\n",
      "\tvalidation 7-103: Loss: 0.1486 Acc: 75.0000%\n",
      "\tvalidation 7-104: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 7-105: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1779 Acc: 67.0408%\n",
      "\tvalidation Loss: 0.1211 Acc: 85.7143%\n",
      "网络参数更新\n",
      "Time passed 0h 6m 24s\n",
      "--------------------\n",
      "Epoch [8/40]:\n",
      "\ttrain 8-1: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 8-2: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 8-3: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 8-4: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 8-5: Loss: 0.2604 Acc: 25.0000%\n",
      "\ttrain 8-6: Loss: 0.2449 Acc: 75.0000%\n",
      "\ttrain 8-7: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 8-8: Loss: 0.1496 Acc: 75.0000%\n",
      "\ttrain 8-9: Loss: 0.4214 Acc: 75.0000%\n",
      "\ttrain 8-10: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 8-11: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 8-12: Loss: 0.3573 Acc: 50.0000%\n",
      "\ttrain 8-13: Loss: 0.2394 Acc: 75.0000%\n",
      "\ttrain 8-14: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 8-15: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 8-16: Loss: 0.1132 Acc: 100.0000%\n",
      "\ttrain 8-17: Loss: 0.1138 Acc: 100.0000%\n",
      "\ttrain 8-18: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 8-19: Loss: 0.1948 Acc: 25.0000%\n",
      "\ttrain 8-20: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 8-21: Loss: 0.2255 Acc: 50.0000%\n",
      "\ttrain 8-22: Loss: 0.1778 Acc: 75.0000%\n",
      "\ttrain 8-23: Loss: 0.2355 Acc: 50.0000%\n",
      "\ttrain 8-24: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 8-25: Loss: 0.1550 Acc: 50.0000%\n",
      "\ttrain 8-26: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 8-27: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 8-28: Loss: 0.1887 Acc: 50.0000%\n",
      "\ttrain 8-29: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 8-30: Loss: 0.1559 Acc: 50.0000%\n",
      "\ttrain 8-31: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 8-32: Loss: 0.2758 Acc: 75.0000%\n",
      "\ttrain 8-33: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 8-34: Loss: 0.3296 Acc: 75.0000%\n",
      "\ttrain 8-35: Loss: 0.0744 Acc: 100.0000%\n",
      "\ttrain 8-36: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 8-37: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 8-38: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 8-39: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 8-40: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 8-41: Loss: 0.3723 Acc: 50.0000%\n",
      "\ttrain 8-42: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 8-43: Loss: 0.5646 Acc: 0.0000%\n",
      "\ttrain 8-44: Loss: 0.3392 Acc: 50.0000%\n",
      "\ttrain 8-45: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 8-46: Loss: 0.2465 Acc: 75.0000%\n",
      "\ttrain 8-47: Loss: 0.4016 Acc: 25.0000%\n",
      "\ttrain 8-48: Loss: 0.3514 Acc: 50.0000%\n",
      "\ttrain 8-49: Loss: 0.0701 Acc: 75.0000%\n",
      "\ttrain 8-50: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 8-51: Loss: 0.1287 Acc: 50.0000%\n",
      "\ttrain 8-52: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 8-53: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 8-54: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 8-55: Loss: 0.4086 Acc: 50.0000%\n",
      "\ttrain 8-56: Loss: 0.0672 Acc: 100.0000%\n",
      "\ttrain 8-57: Loss: 0.2851 Acc: 75.0000%\n",
      "\ttrain 8-58: Loss: 0.2901 Acc: 75.0000%\n",
      "\ttrain 8-59: Loss: 0.3838 Acc: 50.0000%\n",
      "\ttrain 8-60: Loss: 0.2733 Acc: 50.0000%\n",
      "\ttrain 8-61: Loss: 0.1833 Acc: 50.0000%\n",
      "\ttrain 8-62: Loss: 0.0934 Acc: 100.0000%\n",
      "\ttrain 8-63: Loss: 0.2035 Acc: 75.0000%\n",
      "\ttrain 8-64: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 8-65: Loss: 0.3473 Acc: 50.0000%\n",
      "\ttrain 8-66: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 8-67: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 8-68: Loss: 0.1663 Acc: 50.0000%\n",
      "\ttrain 8-69: Loss: 0.5265 Acc: 25.0000%\n",
      "\ttrain 8-70: Loss: 0.2551 Acc: 25.0000%\n",
      "\ttrain 8-71: Loss: 0.1803 Acc: 75.0000%\n",
      "\ttrain 8-72: Loss: 0.2952 Acc: 75.0000%\n",
      "\ttrain 8-73: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 8-74: Loss: 0.1749 Acc: 50.0000%\n",
      "\ttrain 8-75: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 8-76: Loss: 0.1840 Acc: 75.0000%\n",
      "\ttrain 8-77: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 8-78: Loss: 0.6739 Acc: 25.0000%\n",
      "\ttrain 8-79: Loss: 0.3333 Acc: 75.0000%\n",
      "\ttrain 8-80: Loss: 0.1367 Acc: 75.0000%\n",
      "\ttrain 8-81: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 8-82: Loss: 0.0163 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 8-83: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 8-84: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 8-85: Loss: 0.2586 Acc: 50.0000%\n",
      "\ttrain 8-86: Loss: 0.2351 Acc: 75.0000%\n",
      "\ttrain 8-87: Loss: 0.1908 Acc: 50.0000%\n",
      "\ttrain 8-88: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 8-89: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 8-90: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 8-91: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 8-92: Loss: 0.2657 Acc: 50.0000%\n",
      "\ttrain 8-93: Loss: 0.4053 Acc: 50.0000%\n",
      "\ttrain 8-94: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 8-95: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 8-96: Loss: 0.2670 Acc: 50.0000%\n",
      "\ttrain 8-97: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 8-98: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 8-99: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 8-100: Loss: 0.1248 Acc: 50.0000%\n",
      "\ttrain 8-101: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 8-102: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 8-103: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 8-104: Loss: 0.1678 Acc: 50.0000%\n",
      "\ttrain 8-105: Loss: 0.1978 Acc: 75.0000%\n",
      "\ttrain 8-106: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 8-107: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 8-108: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 8-109: Loss: 0.1846 Acc: 50.0000%\n",
      "\ttrain 8-110: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 8-111: Loss: 0.3098 Acc: 25.0000%\n",
      "\ttrain 8-112: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 8-113: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 8-114: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 8-115: Loss: 0.0822 Acc: 100.0000%\n",
      "\ttrain 8-116: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 8-117: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 8-118: Loss: 0.2948 Acc: 50.0000%\n",
      "\ttrain 8-119: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 8-120: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 8-121: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 8-122: Loss: 0.1543 Acc: 75.0000%\n",
      "\ttrain 8-123: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 8-124: Loss: 0.2260 Acc: 50.0000%\n",
      "\ttrain 8-125: Loss: 0.2172 Acc: 75.0000%\n",
      "\ttrain 8-126: Loss: 0.2858 Acc: 75.0000%\n",
      "\ttrain 8-127: Loss: 0.1490 Acc: 50.0000%\n",
      "\ttrain 8-128: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 8-129: Loss: 0.2699 Acc: 50.0000%\n",
      "\ttrain 8-130: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 8-131: Loss: 0.1448 Acc: 75.0000%\n",
      "\ttrain 8-132: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 8-133: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 8-134: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 8-135: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 8-136: Loss: 0.4437 Acc: 25.0000%\n",
      "\ttrain 8-137: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 8-138: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 8-139: Loss: 0.3478 Acc: 25.0000%\n",
      "\ttrain 8-140: Loss: 0.2157 Acc: 75.0000%\n",
      "\ttrain 8-141: Loss: 0.2533 Acc: 50.0000%\n",
      "\ttrain 8-142: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 8-143: Loss: 0.2140 Acc: 75.0000%\n",
      "\ttrain 8-144: Loss: 0.1939 Acc: 75.0000%\n",
      "\ttrain 8-145: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 8-146: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 8-147: Loss: 0.1112 Acc: 50.0000%\n",
      "\ttrain 8-148: Loss: 0.2413 Acc: 25.0000%\n",
      "\ttrain 8-149: Loss: 0.0998 Acc: 100.0000%\n",
      "\ttrain 8-150: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 8-151: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 8-152: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 8-153: Loss: 0.3231 Acc: 75.0000%\n",
      "\ttrain 8-154: Loss: 0.4153 Acc: 25.0000%\n",
      "\ttrain 8-155: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 8-156: Loss: 0.4576 Acc: 50.0000%\n",
      "\ttrain 8-157: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 8-158: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 8-159: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 8-160: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 8-161: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 8-162: Loss: 0.3111 Acc: 25.0000%\n",
      "\ttrain 8-163: Loss: 0.5273 Acc: 25.0000%\n",
      "\ttrain 8-164: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 8-165: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 8-166: Loss: 0.4491 Acc: 50.0000%\n",
      "\ttrain 8-167: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 8-168: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 8-169: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 8-170: Loss: 0.2644 Acc: 75.0000%\n",
      "\ttrain 8-171: Loss: 0.2337 Acc: 50.0000%\n",
      "\ttrain 8-172: Loss: 0.4571 Acc: 50.0000%\n",
      "\ttrain 8-173: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 8-174: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 8-175: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 8-176: Loss: 0.3341 Acc: 50.0000%\n",
      "\ttrain 8-177: Loss: 0.2767 Acc: 50.0000%\n",
      "\ttrain 8-178: Loss: 0.3989 Acc: 0.0000%\n",
      "\ttrain 8-179: Loss: 0.6745 Acc: 0.0000%\n",
      "\ttrain 8-180: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 8-181: Loss: 0.0861 Acc: 100.0000%\n",
      "\ttrain 8-182: Loss: 0.2349 Acc: 50.0000%\n",
      "\ttrain 8-183: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 8-184: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 8-185: Loss: 0.0976 Acc: 100.0000%\n",
      "\ttrain 8-186: Loss: 0.4121 Acc: 0.0000%\n",
      "\ttrain 8-187: Loss: 0.2295 Acc: 50.0000%\n",
      "\ttrain 8-188: Loss: 0.8235 Acc: 0.0000%\n",
      "\ttrain 8-189: Loss: 0.2479 Acc: 50.0000%\n",
      "\ttrain 8-190: Loss: 0.1801 Acc: 50.0000%\n",
      "\ttrain 8-191: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 8-192: Loss: 0.1568 Acc: 50.0000%\n",
      "\ttrain 8-193: Loss: 0.3078 Acc: 50.0000%\n",
      "\ttrain 8-194: Loss: 0.4348 Acc: 50.0000%\n",
      "\ttrain 8-195: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 8-196: Loss: 0.1902 Acc: 75.0000%\n",
      "\ttrain 8-197: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 8-198: Loss: 0.4943 Acc: 25.0000%\n",
      "\ttrain 8-199: Loss: 0.3057 Acc: 25.0000%\n",
      "\ttrain 8-200: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 8-201: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 8-202: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 8-203: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 8-204: Loss: 0.3164 Acc: 75.0000%\n",
      "\ttrain 8-205: Loss: 0.1455 Acc: 100.0000%\n",
      "\ttrain 8-206: Loss: 0.0805 Acc: 100.0000%\n",
      "\ttrain 8-207: Loss: 0.3541 Acc: 75.0000%\n",
      "\ttrain 8-208: Loss: 0.6557 Acc: 50.0000%\n",
      "\ttrain 8-209: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 8-210: Loss: 0.2948 Acc: 50.0000%\n",
      "\ttrain 8-211: Loss: 0.3155 Acc: 50.0000%\n",
      "\ttrain 8-212: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 8-213: Loss: 0.6013 Acc: 25.0000%\n",
      "\ttrain 8-214: Loss: 0.0834 Acc: 100.0000%\n",
      "\ttrain 8-215: Loss: 0.2091 Acc: 75.0000%\n",
      "\ttrain 8-216: Loss: 0.3172 Acc: 50.0000%\n",
      "\ttrain 8-217: Loss: 0.3954 Acc: 50.0000%\n",
      "\ttrain 8-218: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 8-219: Loss: 0.4944 Acc: 25.0000%\n",
      "\ttrain 8-220: Loss: 0.4361 Acc: 50.0000%\n",
      "\ttrain 8-221: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 8-222: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 8-223: Loss: 0.0806 Acc: 75.0000%\n",
      "\ttrain 8-224: Loss: 0.7214 Acc: 50.0000%\n",
      "\ttrain 8-225: Loss: 0.3020 Acc: 75.0000%\n",
      "\ttrain 8-226: Loss: 0.6565 Acc: 25.0000%\n",
      "\ttrain 8-227: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 8-228: Loss: 0.3022 Acc: 50.0000%\n",
      "\ttrain 8-229: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 8-230: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 8-231: Loss: 0.2437 Acc: 50.0000%\n",
      "\ttrain 8-232: Loss: 0.7165 Acc: 0.0000%\n",
      "\ttrain 8-233: Loss: 0.3058 Acc: 25.0000%\n",
      "\ttrain 8-234: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 8-235: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 8-236: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 8-237: Loss: 0.2074 Acc: 75.0000%\n",
      "\ttrain 8-238: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 8-239: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 8-240: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 8-241: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 8-242: Loss: 0.3280 Acc: 50.0000%\n",
      "\ttrain 8-243: Loss: 0.0803 Acc: 100.0000%\n",
      "\ttrain 8-244: Loss: 0.1766 Acc: 75.0000%\n",
      "\ttrain 8-245: Loss: 0.1150 Acc: 75.0000%\n",
      "\tvalidation 8-1: Loss: 2.1547 Acc: 75.0000%\n",
      "\tvalidation 8-2: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 8-3: Loss: 0.3041 Acc: 50.0000%\n",
      "\tvalidation 8-4: Loss: 0.2216 Acc: 50.0000%\n",
      "\tvalidation 8-5: Loss: 0.4147 Acc: 50.0000%\n",
      "\tvalidation 8-6: Loss: 0.2053 Acc: 75.0000%\n",
      "\tvalidation 8-7: Loss: 0.1378 Acc: 75.0000%\n",
      "\tvalidation 8-8: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 8-9: Loss: 0.1008 Acc: 75.0000%\n",
      "\tvalidation 8-10: Loss: 0.0940 Acc: 75.0000%\n",
      "\tvalidation 8-11: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 8-12: Loss: 0.1715 Acc: 75.0000%\n",
      "\tvalidation 8-13: Loss: 0.1088 Acc: 75.0000%\n",
      "\tvalidation 8-14: Loss: 0.2751 Acc: 75.0000%\n",
      "\tvalidation 8-15: Loss: 0.2378 Acc: 50.0000%\n",
      "\tvalidation 8-16: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 8-17: Loss: 0.1093 Acc: 75.0000%\n",
      "\tvalidation 8-18: Loss: 0.2667 Acc: 75.0000%\n",
      "\tvalidation 8-19: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 8-20: Loss: 0.2337 Acc: 75.0000%\n",
      "\tvalidation 8-21: Loss: 0.1206 Acc: 75.0000%\n",
      "\tvalidation 8-22: Loss: 0.1262 Acc: 75.0000%\n",
      "\tvalidation 8-23: Loss: 0.9088 Acc: 50.0000%\n",
      "\tvalidation 8-24: Loss: 0.4127 Acc: 50.0000%\n",
      "\tvalidation 8-25: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 8-26: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 8-27: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 8-28: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 8-29: Loss: 0.1026 Acc: 75.0000%\n",
      "\tvalidation 8-30: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 8-31: Loss: 0.3106 Acc: 50.0000%\n",
      "\tvalidation 8-32: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 8-33: Loss: 0.4887 Acc: 25.0000%\n",
      "\tvalidation 8-34: Loss: 0.3981 Acc: 25.0000%\n",
      "\tvalidation 8-35: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 8-36: Loss: 0.1695 Acc: 75.0000%\n",
      "\tvalidation 8-37: Loss: 0.1848 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 8-38: Loss: 0.4174 Acc: 50.0000%\n",
      "\tvalidation 8-39: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 8-40: Loss: 0.1546 Acc: 75.0000%\n",
      "\tvalidation 8-41: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 8-42: Loss: 0.2012 Acc: 75.0000%\n",
      "\tvalidation 8-43: Loss: 0.1726 Acc: 75.0000%\n",
      "\tvalidation 8-44: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 8-45: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 8-46: Loss: 0.3423 Acc: 75.0000%\n",
      "\tvalidation 8-47: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 8-48: Loss: 0.4203 Acc: 75.0000%\n",
      "\tvalidation 8-49: Loss: 0.4710 Acc: 25.0000%\n",
      "\tvalidation 8-50: Loss: 0.2164 Acc: 75.0000%\n",
      "\tvalidation 8-51: Loss: 1.1506 Acc: 50.0000%\n",
      "\tvalidation 8-52: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 8-53: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 8-54: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 8-55: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 8-56: Loss: 0.2172 Acc: 75.0000%\n",
      "\tvalidation 8-57: Loss: 0.1021 Acc: 75.0000%\n",
      "\tvalidation 8-58: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 8-59: Loss: 0.0529 Acc: 100.0000%\n",
      "\tvalidation 8-60: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 8-61: Loss: 0.3531 Acc: 50.0000%\n",
      "\tvalidation 8-62: Loss: 0.1825 Acc: 75.0000%\n",
      "\tvalidation 8-63: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 8-64: Loss: 0.2617 Acc: 50.0000%\n",
      "\tvalidation 8-65: Loss: 0.1946 Acc: 75.0000%\n",
      "\tvalidation 8-66: Loss: 0.1720 Acc: 75.0000%\n",
      "\tvalidation 8-67: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 8-68: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 8-69: Loss: 0.3675 Acc: 50.0000%\n",
      "\tvalidation 8-70: Loss: 0.1779 Acc: 75.0000%\n",
      "\tvalidation 8-71: Loss: 0.4791 Acc: 25.0000%\n",
      "\tvalidation 8-72: Loss: 0.4522 Acc: 50.0000%\n",
      "\tvalidation 8-73: Loss: 0.1394 Acc: 75.0000%\n",
      "\tvalidation 8-74: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 8-75: Loss: 0.3633 Acc: 50.0000%\n",
      "\tvalidation 8-76: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 8-77: Loss: 0.1135 Acc: 75.0000%\n",
      "\tvalidation 8-78: Loss: 0.1511 Acc: 75.0000%\n",
      "\tvalidation 8-79: Loss: 0.3848 Acc: 50.0000%\n",
      "\tvalidation 8-80: Loss: 0.2004 Acc: 75.0000%\n",
      "\tvalidation 8-81: Loss: 0.5475 Acc: 50.0000%\n",
      "\tvalidation 8-82: Loss: 0.2522 Acc: 50.0000%\n",
      "\tvalidation 8-83: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 8-84: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 8-85: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 8-86: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 8-87: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 8-88: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 8-89: Loss: 2.0014 Acc: 50.0000%\n",
      "\tvalidation 8-90: Loss: 1.8949 Acc: 50.0000%\n",
      "\tvalidation 8-91: Loss: 0.1710 Acc: 75.0000%\n",
      "\tvalidation 8-92: Loss: 0.1793 Acc: 50.0000%\n",
      "\tvalidation 8-93: Loss: 0.3639 Acc: 50.0000%\n",
      "\tvalidation 8-94: Loss: 0.3556 Acc: 50.0000%\n",
      "\tvalidation 8-95: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 8-96: Loss: 0.6651 Acc: 25.0000%\n",
      "\tvalidation 8-97: Loss: 0.3693 Acc: 75.0000%\n",
      "\tvalidation 8-98: Loss: 0.2882 Acc: 50.0000%\n",
      "\tvalidation 8-99: Loss: 0.2459 Acc: 50.0000%\n",
      "\tvalidation 8-100: Loss: 0.6254 Acc: 25.0000%\n",
      "\tvalidation 8-101: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 8-102: Loss: 0.2193 Acc: 75.0000%\n",
      "\tvalidation 8-103: Loss: 0.3075 Acc: 50.0000%\n",
      "\tvalidation 8-104: Loss: 0.6775 Acc: 75.0000%\n",
      "\tvalidation 8-105: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1873 Acc: 70.3061%\n",
      "\tvalidation Loss: 0.2506 Acc: 74.2857%\n",
      "Time passed 0h 7m 17s\n",
      "--------------------\n",
      "Epoch [9/40]:\n",
      "\ttrain 9-1: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 9-2: Loss: 0.2238 Acc: 75.0000%\n",
      "\ttrain 9-3: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 9-4: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 9-5: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 9-6: Loss: 0.0683 Acc: 100.0000%\n",
      "\ttrain 9-7: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 9-8: Loss: 1.0787 Acc: 0.0000%\n",
      "\ttrain 9-9: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 9-10: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 9-11: Loss: 0.8627 Acc: 0.0000%\n",
      "\ttrain 9-12: Loss: 0.4346 Acc: 25.0000%\n",
      "\ttrain 9-13: Loss: 0.2280 Acc: 50.0000%\n",
      "\ttrain 9-14: Loss: 0.2127 Acc: 75.0000%\n",
      "\ttrain 9-15: Loss: 0.2578 Acc: 25.0000%\n",
      "\ttrain 9-16: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 9-17: Loss: 0.2045 Acc: 50.0000%\n",
      "\ttrain 9-18: Loss: 0.1957 Acc: 75.0000%\n",
      "\ttrain 9-19: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 9-20: Loss: 0.3153 Acc: 75.0000%\n",
      "\ttrain 9-21: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 9-22: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 9-23: Loss: 0.0828 Acc: 100.0000%\n",
      "\ttrain 9-24: Loss: 0.0860 Acc: 100.0000%\n",
      "\ttrain 9-25: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 9-26: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 9-27: Loss: 0.2882 Acc: 25.0000%\n",
      "\ttrain 9-28: Loss: 0.0729 Acc: 100.0000%\n",
      "\ttrain 9-29: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 9-30: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 9-31: Loss: 0.0755 Acc: 100.0000%\n",
      "\ttrain 9-32: Loss: 0.2675 Acc: 50.0000%\n",
      "\ttrain 9-33: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 9-34: Loss: 0.6273 Acc: 0.0000%\n",
      "\ttrain 9-35: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 9-36: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 9-37: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 9-38: Loss: 0.1974 Acc: 75.0000%\n",
      "\ttrain 9-39: Loss: 0.0879 Acc: 100.0000%\n",
      "\ttrain 9-40: Loss: 0.3110 Acc: 50.0000%\n",
      "\ttrain 9-41: Loss: 0.1643 Acc: 50.0000%\n",
      "\ttrain 9-42: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 9-43: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 9-44: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 9-45: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 9-46: Loss: 1.0491 Acc: 0.0000%\n",
      "\ttrain 9-47: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 9-48: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 9-49: Loss: 0.1179 Acc: 100.0000%\n",
      "\ttrain 9-50: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 9-51: Loss: 0.0659 Acc: 100.0000%\n",
      "\ttrain 9-52: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 9-53: Loss: 0.2253 Acc: 50.0000%\n",
      "\ttrain 9-54: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 9-55: Loss: 0.1918 Acc: 50.0000%\n",
      "\ttrain 9-56: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 9-57: Loss: 0.3935 Acc: 50.0000%\n",
      "\ttrain 9-58: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 9-59: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 9-60: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 9-61: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 9-62: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 9-63: Loss: 0.1666 Acc: 75.0000%\n",
      "\ttrain 9-64: Loss: 0.1658 Acc: 75.0000%\n",
      "\ttrain 9-65: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 9-66: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 9-67: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 9-68: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 9-69: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 9-70: Loss: 0.1982 Acc: 75.0000%\n",
      "\ttrain 9-71: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 9-72: Loss: 0.2095 Acc: 50.0000%\n",
      "\ttrain 9-73: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 9-74: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 9-75: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 9-76: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 9-77: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 9-78: Loss: 0.2702 Acc: 25.0000%\n",
      "\ttrain 9-79: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 9-80: Loss: 0.2735 Acc: 75.0000%\n",
      "\ttrain 9-81: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 9-82: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 9-83: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 9-84: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 9-85: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 9-86: Loss: 0.4047 Acc: 50.0000%\n",
      "\ttrain 9-87: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 9-88: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 9-89: Loss: 0.3867 Acc: 25.0000%\n",
      "\ttrain 9-90: Loss: 0.3182 Acc: 75.0000%\n",
      "\ttrain 9-91: Loss: 0.2950 Acc: 75.0000%\n",
      "\ttrain 9-92: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 9-93: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 9-94: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 9-95: Loss: 0.1928 Acc: 75.0000%\n",
      "\ttrain 9-96: Loss: 0.2369 Acc: 50.0000%\n",
      "\ttrain 9-97: Loss: 0.3044 Acc: 50.0000%\n",
      "\ttrain 9-98: Loss: 0.2262 Acc: 75.0000%\n",
      "\ttrain 9-99: Loss: 0.2216 Acc: 75.0000%\n",
      "\ttrain 9-100: Loss: 0.1965 Acc: 50.0000%\n",
      "\ttrain 9-101: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 9-102: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 9-103: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 9-104: Loss: 0.2107 Acc: 50.0000%\n",
      "\ttrain 9-105: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 9-106: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 9-107: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 9-108: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 9-109: Loss: 0.2459 Acc: 50.0000%\n",
      "\ttrain 9-110: Loss: 0.2052 Acc: 75.0000%\n",
      "\ttrain 9-111: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 9-112: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 9-113: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 9-114: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 9-115: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 9-116: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 9-117: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 9-118: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 9-119: Loss: 0.1970 Acc: 75.0000%\n",
      "\ttrain 9-120: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 9-121: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 9-122: Loss: 0.2358 Acc: 75.0000%\n",
      "\ttrain 9-123: Loss: 0.0366 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 9-124: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 9-125: Loss: 0.1390 Acc: 75.0000%\n",
      "\ttrain 9-126: Loss: 0.0612 Acc: 100.0000%\n",
      "\ttrain 9-127: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 9-128: Loss: 0.0813 Acc: 100.0000%\n",
      "\ttrain 9-129: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 9-130: Loss: 0.2597 Acc: 50.0000%\n",
      "\ttrain 9-131: Loss: 0.2415 Acc: 75.0000%\n",
      "\ttrain 9-132: Loss: 0.1952 Acc: 75.0000%\n",
      "\ttrain 9-133: Loss: 0.1789 Acc: 75.0000%\n",
      "\ttrain 9-134: Loss: 0.2800 Acc: 50.0000%\n",
      "\ttrain 9-135: Loss: 0.0858 Acc: 100.0000%\n",
      "\ttrain 9-136: Loss: 0.4354 Acc: 50.0000%\n",
      "\ttrain 9-137: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 9-138: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 9-139: Loss: 0.3119 Acc: 50.0000%\n",
      "\ttrain 9-140: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 9-141: Loss: 0.1890 Acc: 75.0000%\n",
      "\ttrain 9-142: Loss: 0.3338 Acc: 75.0000%\n",
      "\ttrain 9-143: Loss: 0.1844 Acc: 50.0000%\n",
      "\ttrain 9-144: Loss: 0.3685 Acc: 50.0000%\n",
      "\ttrain 9-145: Loss: 0.1037 Acc: 100.0000%\n",
      "\ttrain 9-146: Loss: 0.2152 Acc: 75.0000%\n",
      "\ttrain 9-147: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 9-148: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 9-149: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 9-150: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 9-151: Loss: 0.3094 Acc: 75.0000%\n",
      "\ttrain 9-152: Loss: 0.1785 Acc: 75.0000%\n",
      "\ttrain 9-153: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 9-154: Loss: 0.2886 Acc: 75.0000%\n",
      "\ttrain 9-155: Loss: 0.3431 Acc: 50.0000%\n",
      "\ttrain 9-156: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 9-157: Loss: 0.8537 Acc: 0.0000%\n",
      "\ttrain 9-158: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 9-159: Loss: 0.2451 Acc: 50.0000%\n",
      "\ttrain 9-160: Loss: 0.3376 Acc: 75.0000%\n",
      "\ttrain 9-161: Loss: 0.2554 Acc: 75.0000%\n",
      "\ttrain 9-162: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 9-163: Loss: 0.1293 Acc: 100.0000%\n",
      "\ttrain 9-164: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 9-165: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 9-166: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 9-167: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 9-168: Loss: 0.6937 Acc: 25.0000%\n",
      "\ttrain 9-169: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 9-170: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 9-171: Loss: 0.2480 Acc: 75.0000%\n",
      "\ttrain 9-172: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 9-173: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 9-174: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 9-175: Loss: 0.1882 Acc: 75.0000%\n",
      "\ttrain 9-176: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 9-177: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 9-178: Loss: 0.6012 Acc: 50.0000%\n",
      "\ttrain 9-179: Loss: 0.3482 Acc: 50.0000%\n",
      "\ttrain 9-180: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 9-181: Loss: 0.1902 Acc: 75.0000%\n",
      "\ttrain 9-182: Loss: 0.1954 Acc: 75.0000%\n",
      "\ttrain 9-183: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 9-184: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 9-185: Loss: 0.3890 Acc: 50.0000%\n",
      "\ttrain 9-186: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 9-187: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 9-188: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 9-189: Loss: 0.3223 Acc: 50.0000%\n",
      "\ttrain 9-190: Loss: 0.1947 Acc: 75.0000%\n",
      "\ttrain 9-191: Loss: 0.0729 Acc: 100.0000%\n",
      "\ttrain 9-192: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 9-193: Loss: 0.1590 Acc: 50.0000%\n",
      "\ttrain 9-194: Loss: 0.4173 Acc: 75.0000%\n",
      "\ttrain 9-195: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 9-196: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 9-197: Loss: 0.2536 Acc: 50.0000%\n",
      "\ttrain 9-198: Loss: 0.2353 Acc: 75.0000%\n",
      "\ttrain 9-199: Loss: 0.2129 Acc: 75.0000%\n",
      "\ttrain 9-200: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 9-201: Loss: 0.2698 Acc: 25.0000%\n",
      "\ttrain 9-202: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 9-203: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 9-204: Loss: 0.1888 Acc: 75.0000%\n",
      "\ttrain 9-205: Loss: 0.2601 Acc: 50.0000%\n",
      "\ttrain 9-206: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 9-207: Loss: 0.2417 Acc: 50.0000%\n",
      "\ttrain 9-208: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 9-209: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 9-210: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 9-211: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 9-212: Loss: 0.2398 Acc: 25.0000%\n",
      "\ttrain 9-213: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 9-214: Loss: 0.0721 Acc: 100.0000%\n",
      "\ttrain 9-215: Loss: 0.1843 Acc: 75.0000%\n",
      "\ttrain 9-216: Loss: 0.2915 Acc: 50.0000%\n",
      "\ttrain 9-217: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 9-218: Loss: 0.4153 Acc: 50.0000%\n",
      "\ttrain 9-219: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 9-220: Loss: 0.2811 Acc: 50.0000%\n",
      "\ttrain 9-221: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 9-222: Loss: 0.3262 Acc: 75.0000%\n",
      "\ttrain 9-223: Loss: 0.2834 Acc: 50.0000%\n",
      "\ttrain 9-224: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 9-225: Loss: 0.2181 Acc: 50.0000%\n",
      "\ttrain 9-226: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 9-227: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 9-228: Loss: 0.2842 Acc: 75.0000%\n",
      "\ttrain 9-229: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 9-230: Loss: 0.1931 Acc: 50.0000%\n",
      "\ttrain 9-231: Loss: 0.2134 Acc: 50.0000%\n",
      "\ttrain 9-232: Loss: 0.2873 Acc: 50.0000%\n",
      "\ttrain 9-233: Loss: 0.2777 Acc: 75.0000%\n",
      "\ttrain 9-234: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 9-235: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 9-236: Loss: 0.2607 Acc: 75.0000%\n",
      "\ttrain 9-237: Loss: 0.7039 Acc: 50.0000%\n",
      "\ttrain 9-238: Loss: 0.2757 Acc: 25.0000%\n",
      "\ttrain 9-239: Loss: 0.4709 Acc: 25.0000%\n",
      "\ttrain 9-240: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 9-241: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 9-242: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 9-243: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 9-244: Loss: 0.7993 Acc: 50.0000%\n",
      "\ttrain 9-245: Loss: 0.3924 Acc: 25.0000%\n",
      "\tvalidation 9-1: Loss: 0.2107 Acc: 25.0000%\n",
      "\tvalidation 9-2: Loss: 0.0883 Acc: 75.0000%\n",
      "\tvalidation 9-3: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-4: Loss: 0.1197 Acc: 75.0000%\n",
      "\tvalidation 9-5: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 9-6: Loss: 0.0384 Acc: 100.0000%\n",
      "\tvalidation 9-7: Loss: 0.1019 Acc: 75.0000%\n",
      "\tvalidation 9-8: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 9-9: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 9-10: Loss: 0.1739 Acc: 75.0000%\n",
      "\tvalidation 9-11: Loss: 0.0633 Acc: 75.0000%\n",
      "\tvalidation 9-12: Loss: 0.1320 Acc: 75.0000%\n",
      "\tvalidation 9-13: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 9-14: Loss: 0.2485 Acc: 50.0000%\n",
      "\tvalidation 9-15: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 9-16: Loss: 0.0463 Acc: 100.0000%\n",
      "\tvalidation 9-17: Loss: 0.0770 Acc: 75.0000%\n",
      "\tvalidation 9-18: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 9-19: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 9-20: Loss: 0.2879 Acc: 75.0000%\n",
      "\tvalidation 9-21: Loss: 0.0730 Acc: 100.0000%\n",
      "\tvalidation 9-22: Loss: 0.0473 Acc: 100.0000%\n",
      "\tvalidation 9-23: Loss: 0.1366 Acc: 50.0000%\n",
      "\tvalidation 9-24: Loss: 0.0768 Acc: 100.0000%\n",
      "\tvalidation 9-25: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 9-26: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 9-27: Loss: 0.0700 Acc: 100.0000%\n",
      "\tvalidation 9-28: Loss: 0.0367 Acc: 100.0000%\n",
      "\tvalidation 9-29: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 9-30: Loss: 0.1547 Acc: 50.0000%\n",
      "\tvalidation 9-31: Loss: 0.0535 Acc: 75.0000%\n",
      "\tvalidation 9-32: Loss: 0.1554 Acc: 50.0000%\n",
      "\tvalidation 9-33: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 9-34: Loss: 0.0486 Acc: 100.0000%\n",
      "\tvalidation 9-35: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 9-36: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 9-37: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 9-38: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-39: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 9-40: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 9-41: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 9-42: Loss: 0.0824 Acc: 75.0000%\n",
      "\tvalidation 9-43: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 9-44: Loss: 0.0676 Acc: 100.0000%\n",
      "\tvalidation 9-45: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 9-46: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 9-47: Loss: 0.1269 Acc: 75.0000%\n",
      "\tvalidation 9-48: Loss: 0.0828 Acc: 75.0000%\n",
      "\tvalidation 9-49: Loss: 0.0564 Acc: 100.0000%\n",
      "\tvalidation 9-50: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 9-51: Loss: 0.0628 Acc: 75.0000%\n",
      "\tvalidation 9-52: Loss: 0.0798 Acc: 75.0000%\n",
      "\tvalidation 9-53: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 9-54: Loss: 0.1181 Acc: 75.0000%\n",
      "\tvalidation 9-55: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 9-56: Loss: 0.0893 Acc: 75.0000%\n",
      "\tvalidation 9-57: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 9-58: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 9-59: Loss: 0.0777 Acc: 100.0000%\n",
      "\tvalidation 9-60: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 9-61: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 9-62: Loss: 0.0505 Acc: 100.0000%\n",
      "\tvalidation 9-63: Loss: 0.1442 Acc: 75.0000%\n",
      "\tvalidation 9-64: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 9-65: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 9-66: Loss: 0.0881 Acc: 100.0000%\n",
      "\tvalidation 9-67: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 9-68: Loss: 0.0626 Acc: 75.0000%\n",
      "\tvalidation 9-69: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 9-70: Loss: 0.0347 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 9-71: Loss: 0.0659 Acc: 100.0000%\n",
      "\tvalidation 9-72: Loss: 0.0675 Acc: 75.0000%\n",
      "\tvalidation 9-73: Loss: 0.0595 Acc: 100.0000%\n",
      "\tvalidation 9-74: Loss: 0.1671 Acc: 75.0000%\n",
      "\tvalidation 9-75: Loss: 0.1401 Acc: 50.0000%\n",
      "\tvalidation 9-76: Loss: 0.1144 Acc: 50.0000%\n",
      "\tvalidation 9-77: Loss: 0.0477 Acc: 100.0000%\n",
      "\tvalidation 9-78: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 9-79: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 9-80: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 9-81: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 9-82: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 9-83: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 9-84: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 9-85: Loss: 0.1209 Acc: 75.0000%\n",
      "\tvalidation 9-86: Loss: 0.0753 Acc: 100.0000%\n",
      "\tvalidation 9-87: Loss: 0.1252 Acc: 50.0000%\n",
      "\tvalidation 9-88: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 9-89: Loss: 0.0846 Acc: 75.0000%\n",
      "\tvalidation 9-90: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 9-91: Loss: 0.1251 Acc: 75.0000%\n",
      "\tvalidation 9-92: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 9-93: Loss: 0.0730 Acc: 75.0000%\n",
      "\tvalidation 9-94: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 9-95: Loss: 0.0731 Acc: 100.0000%\n",
      "\tvalidation 9-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 9-97: Loss: 0.0985 Acc: 75.0000%\n",
      "\tvalidation 9-98: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 9-99: Loss: 0.1170 Acc: 75.0000%\n",
      "\tvalidation 9-100: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 9-101: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 9-102: Loss: 0.0551 Acc: 100.0000%\n",
      "\tvalidation 9-103: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 9-104: Loss: 0.0733 Acc: 100.0000%\n",
      "\tvalidation 9-105: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1738 Acc: 75.0000%\n",
      "\tvalidation Loss: 0.0657 Acc: 88.3333%\n",
      "网络参数更新\n",
      "Time passed 0h 8m 10s\n",
      "--------------------\n",
      "Epoch [10/40]:\n",
      "\ttrain 10-1: Loss: 0.2085 Acc: 75.0000%\n",
      "\ttrain 10-2: Loss: 0.3285 Acc: 75.0000%\n",
      "\ttrain 10-3: Loss: 0.3158 Acc: 50.0000%\n",
      "\ttrain 10-4: Loss: 0.3647 Acc: 50.0000%\n",
      "\ttrain 10-5: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 10-6: Loss: 0.0652 Acc: 100.0000%\n",
      "\ttrain 10-7: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 10-8: Loss: 0.0825 Acc: 100.0000%\n",
      "\ttrain 10-9: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 10-10: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 10-11: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 10-12: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 10-13: Loss: 0.4911 Acc: 25.0000%\n",
      "\ttrain 10-14: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 10-15: Loss: 0.0837 Acc: 100.0000%\n",
      "\ttrain 10-16: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 10-17: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 10-18: Loss: 0.1459 Acc: 75.0000%\n",
      "\ttrain 10-19: Loss: 0.4288 Acc: 0.0000%\n",
      "\ttrain 10-20: Loss: 0.3366 Acc: 25.0000%\n",
      "\ttrain 10-21: Loss: 0.2337 Acc: 75.0000%\n",
      "\ttrain 10-22: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 10-23: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 10-24: Loss: 0.1405 Acc: 100.0000%\n",
      "\ttrain 10-25: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 10-26: Loss: 0.2016 Acc: 25.0000%\n",
      "\ttrain 10-27: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 10-28: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 10-29: Loss: 0.6413 Acc: 25.0000%\n",
      "\ttrain 10-30: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 10-31: Loss: 0.2985 Acc: 50.0000%\n",
      "\ttrain 10-32: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 10-33: Loss: 0.1710 Acc: 50.0000%\n",
      "\ttrain 10-34: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 10-35: Loss: 0.1411 Acc: 50.0000%\n",
      "\ttrain 10-36: Loss: 0.1819 Acc: 75.0000%\n",
      "\ttrain 10-37: Loss: 0.1945 Acc: 75.0000%\n",
      "\ttrain 10-38: Loss: 0.5908 Acc: 25.0000%\n",
      "\ttrain 10-39: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 10-40: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 10-41: Loss: 0.2062 Acc: 50.0000%\n",
      "\ttrain 10-42: Loss: 0.1553 Acc: 75.0000%\n",
      "\ttrain 10-43: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 10-44: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 10-45: Loss: 0.2567 Acc: 50.0000%\n",
      "\ttrain 10-46: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 10-47: Loss: 0.1451 Acc: 75.0000%\n",
      "\ttrain 10-48: Loss: 0.5930 Acc: 25.0000%\n",
      "\ttrain 10-49: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 10-50: Loss: 0.7156 Acc: 0.0000%\n",
      "\ttrain 10-51: Loss: 0.4846 Acc: 50.0000%\n",
      "\ttrain 10-52: Loss: 0.3177 Acc: 50.0000%\n",
      "\ttrain 10-53: Loss: 0.1784 Acc: 50.0000%\n",
      "\ttrain 10-54: Loss: 0.1719 Acc: 75.0000%\n",
      "\ttrain 10-55: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 10-56: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 10-57: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 10-58: Loss: 0.2789 Acc: 75.0000%\n",
      "\ttrain 10-59: Loss: 0.0889 Acc: 100.0000%\n",
      "\ttrain 10-60: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 10-61: Loss: 0.1530 Acc: 75.0000%\n",
      "\ttrain 10-62: Loss: 0.2517 Acc: 75.0000%\n",
      "\ttrain 10-63: Loss: 0.3182 Acc: 75.0000%\n",
      "\ttrain 10-64: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 10-65: Loss: 0.2103 Acc: 50.0000%\n",
      "\ttrain 10-66: Loss: 0.2625 Acc: 25.0000%\n",
      "\ttrain 10-67: Loss: 0.3121 Acc: 50.0000%\n",
      "\ttrain 10-68: Loss: 0.2285 Acc: 50.0000%\n",
      "\ttrain 10-69: Loss: 0.3377 Acc: 50.0000%\n",
      "\ttrain 10-70: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 10-71: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 10-72: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 10-73: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 10-74: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 10-75: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 10-76: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 10-77: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 10-78: Loss: 0.2410 Acc: 50.0000%\n",
      "\ttrain 10-79: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 10-80: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 10-81: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 10-82: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 10-83: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 10-84: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 10-85: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 10-86: Loss: 0.0894 Acc: 100.0000%\n",
      "\ttrain 10-87: Loss: 0.3285 Acc: 50.0000%\n",
      "\ttrain 10-88: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 10-89: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 10-90: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 10-91: Loss: 0.4617 Acc: 50.0000%\n",
      "\ttrain 10-92: Loss: 0.1536 Acc: 50.0000%\n",
      "\ttrain 10-93: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 10-94: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 10-95: Loss: 0.1428 Acc: 50.0000%\n",
      "\ttrain 10-96: Loss: 0.2801 Acc: 50.0000%\n",
      "\ttrain 10-97: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 10-98: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 10-99: Loss: 0.8087 Acc: 25.0000%\n",
      "\ttrain 10-100: Loss: 0.2084 Acc: 75.0000%\n",
      "\ttrain 10-101: Loss: 0.4842 Acc: 75.0000%\n",
      "\ttrain 10-102: Loss: 0.5263 Acc: 50.0000%\n",
      "\ttrain 10-103: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 10-104: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 10-105: Loss: 0.1627 Acc: 75.0000%\n",
      "\ttrain 10-106: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 10-107: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 10-108: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 10-109: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 10-110: Loss: 0.1754 Acc: 50.0000%\n",
      "\ttrain 10-111: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 10-112: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 10-113: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 10-114: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 10-115: Loss: 0.2240 Acc: 50.0000%\n",
      "\ttrain 10-116: Loss: 0.0840 Acc: 100.0000%\n",
      "\ttrain 10-117: Loss: 0.0801 Acc: 100.0000%\n",
      "\ttrain 10-118: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 10-119: Loss: 0.2320 Acc: 50.0000%\n",
      "\ttrain 10-120: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 10-121: Loss: 0.1993 Acc: 50.0000%\n",
      "\ttrain 10-122: Loss: 0.6644 Acc: 50.0000%\n",
      "\ttrain 10-123: Loss: 0.1866 Acc: 50.0000%\n",
      "\ttrain 10-124: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 10-125: Loss: 0.0823 Acc: 100.0000%\n",
      "\ttrain 10-126: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 10-127: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 10-128: Loss: 0.3105 Acc: 50.0000%\n",
      "\ttrain 10-129: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 10-130: Loss: 0.2038 Acc: 75.0000%\n",
      "\ttrain 10-131: Loss: 0.5223 Acc: 25.0000%\n",
      "\ttrain 10-132: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 10-133: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 10-134: Loss: 0.2802 Acc: 75.0000%\n",
      "\ttrain 10-135: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 10-136: Loss: 0.0704 Acc: 100.0000%\n",
      "\ttrain 10-137: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 10-138: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 10-139: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 10-140: Loss: 0.1570 Acc: 50.0000%\n",
      "\ttrain 10-141: Loss: 0.3481 Acc: 50.0000%\n",
      "\ttrain 10-142: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 10-143: Loss: 0.1328 Acc: 50.0000%\n",
      "\ttrain 10-144: Loss: 0.4121 Acc: 50.0000%\n",
      "\ttrain 10-145: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 10-146: Loss: 0.0900 Acc: 100.0000%\n",
      "\ttrain 10-147: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 10-148: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 10-149: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 10-150: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 10-151: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 10-152: Loss: 0.4561 Acc: 0.0000%\n",
      "\ttrain 10-153: Loss: 0.1784 Acc: 75.0000%\n",
      "\ttrain 10-154: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 10-155: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 10-156: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 10-157: Loss: 0.0641 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 10-158: Loss: 0.3204 Acc: 50.0000%\n",
      "\ttrain 10-159: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 10-160: Loss: 0.3149 Acc: 50.0000%\n",
      "\ttrain 10-161: Loss: 0.0996 Acc: 100.0000%\n",
      "\ttrain 10-162: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 10-163: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 10-164: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 10-165: Loss: 0.2662 Acc: 50.0000%\n",
      "\ttrain 10-166: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 10-167: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 10-168: Loss: 0.1938 Acc: 50.0000%\n",
      "\ttrain 10-169: Loss: 0.7408 Acc: 0.0000%\n",
      "\ttrain 10-170: Loss: 0.2425 Acc: 75.0000%\n",
      "\ttrain 10-171: Loss: 0.3217 Acc: 50.0000%\n",
      "\ttrain 10-172: Loss: 0.1536 Acc: 75.0000%\n",
      "\ttrain 10-173: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 10-174: Loss: 0.2656 Acc: 50.0000%\n",
      "\ttrain 10-175: Loss: 0.4694 Acc: 25.0000%\n",
      "\ttrain 10-176: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 10-177: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 10-178: Loss: 0.3542 Acc: 50.0000%\n",
      "\ttrain 10-179: Loss: 0.3610 Acc: 75.0000%\n",
      "\ttrain 10-180: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 10-181: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 10-182: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 10-183: Loss: 0.3001 Acc: 50.0000%\n",
      "\ttrain 10-184: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 10-185: Loss: 0.2669 Acc: 25.0000%\n",
      "\ttrain 10-186: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 10-187: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 10-188: Loss: 0.3272 Acc: 50.0000%\n",
      "\ttrain 10-189: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 10-190: Loss: 0.2154 Acc: 75.0000%\n",
      "\ttrain 10-191: Loss: 0.2243 Acc: 50.0000%\n",
      "\ttrain 10-192: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 10-193: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 10-194: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 10-195: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 10-196: Loss: 0.6951 Acc: 50.0000%\n",
      "\ttrain 10-197: Loss: 0.4085 Acc: 50.0000%\n",
      "\ttrain 10-198: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 10-199: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 10-200: Loss: 0.2467 Acc: 50.0000%\n",
      "\ttrain 10-201: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 10-202: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 10-203: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 10-204: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 10-205: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 10-206: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 10-207: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 10-208: Loss: 0.3456 Acc: 25.0000%\n",
      "\ttrain 10-209: Loss: 0.2246 Acc: 50.0000%\n",
      "\ttrain 10-210: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 10-211: Loss: 0.1789 Acc: 75.0000%\n",
      "\ttrain 10-212: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 10-213: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 10-214: Loss: 0.0659 Acc: 100.0000%\n",
      "\ttrain 10-215: Loss: 0.2242 Acc: 50.0000%\n",
      "\ttrain 10-216: Loss: 0.3018 Acc: 50.0000%\n",
      "\ttrain 10-217: Loss: 0.0652 Acc: 75.0000%\n",
      "\ttrain 10-218: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 10-219: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 10-220: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 10-221: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 10-222: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 10-223: Loss: 0.2263 Acc: 50.0000%\n",
      "\ttrain 10-224: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 10-225: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 10-226: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 10-227: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 10-228: Loss: 0.1524 Acc: 75.0000%\n",
      "\ttrain 10-229: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 10-230: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 10-231: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 10-232: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 10-233: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 10-234: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 10-235: Loss: 0.2291 Acc: 75.0000%\n",
      "\ttrain 10-236: Loss: 0.3416 Acc: 25.0000%\n",
      "\ttrain 10-237: Loss: 0.1516 Acc: 75.0000%\n",
      "\ttrain 10-238: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 10-239: Loss: 0.2328 Acc: 50.0000%\n",
      "\ttrain 10-240: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 10-241: Loss: 0.1810 Acc: 75.0000%\n",
      "\ttrain 10-242: Loss: 0.1957 Acc: 75.0000%\n",
      "\ttrain 10-243: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 10-244: Loss: 0.3513 Acc: 75.0000%\n",
      "\ttrain 10-245: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 10-1: Loss: 0.4051 Acc: 50.0000%\n",
      "\tvalidation 10-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 10-3: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 10-4: Loss: 0.6016 Acc: 75.0000%\n",
      "\tvalidation 10-5: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 10-6: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 10-7: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 10-8: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 10-9: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 10-10: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 10-11: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 10-12: Loss: 0.0728 Acc: 100.0000%\n",
      "\tvalidation 10-13: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 10-14: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 10-15: Loss: 0.7001 Acc: 50.0000%\n",
      "\tvalidation 10-16: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 10-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 10-18: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 10-19: Loss: 0.0967 Acc: 75.0000%\n",
      "\tvalidation 10-20: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 10-21: Loss: 0.1417 Acc: 50.0000%\n",
      "\tvalidation 10-22: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 10-23: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 10-24: Loss: 0.2466 Acc: 50.0000%\n",
      "\tvalidation 10-25: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 10-26: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 10-27: Loss: 0.0901 Acc: 75.0000%\n",
      "\tvalidation 10-28: Loss: 2.7678 Acc: 75.0000%\n",
      "\tvalidation 10-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 10-30: Loss: 0.0683 Acc: 75.0000%\n",
      "\tvalidation 10-31: Loss: 0.0542 Acc: 75.0000%\n",
      "\tvalidation 10-32: Loss: 0.1769 Acc: 75.0000%\n",
      "\tvalidation 10-33: Loss: 0.0444 Acc: 100.0000%\n",
      "\tvalidation 10-34: Loss: 0.9494 Acc: 75.0000%\n",
      "\tvalidation 10-35: Loss: 0.0990 Acc: 75.0000%\n",
      "\tvalidation 10-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 10-37: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 10-38: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 10-39: Loss: 0.5030 Acc: 50.0000%\n",
      "\tvalidation 10-40: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 10-41: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 10-42: Loss: 0.1199 Acc: 75.0000%\n",
      "\tvalidation 10-43: Loss: 0.2316 Acc: 75.0000%\n",
      "\tvalidation 10-44: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 10-45: Loss: 0.8240 Acc: 75.0000%\n",
      "\tvalidation 10-46: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 10-47: Loss: 0.4744 Acc: 50.0000%\n",
      "\tvalidation 10-48: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 10-49: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 10-50: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 10-51: Loss: 0.4778 Acc: 25.0000%\n",
      "\tvalidation 10-52: Loss: 0.3745 Acc: 75.0000%\n",
      "\tvalidation 10-53: Loss: 1.2881 Acc: 50.0000%\n",
      "\tvalidation 10-54: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 10-55: Loss: 0.2627 Acc: 50.0000%\n",
      "\tvalidation 10-56: Loss: 0.0833 Acc: 75.0000%\n",
      "\tvalidation 10-57: Loss: 0.0807 Acc: 75.0000%\n",
      "\tvalidation 10-58: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 10-59: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 10-60: Loss: 0.0715 Acc: 75.0000%\n",
      "\tvalidation 10-61: Loss: 0.2003 Acc: 50.0000%\n",
      "\tvalidation 10-62: Loss: 0.4586 Acc: 75.0000%\n",
      "\tvalidation 10-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 10-64: Loss: 0.1832 Acc: 75.0000%\n",
      "\tvalidation 10-65: Loss: 0.4436 Acc: 75.0000%\n",
      "\tvalidation 10-66: Loss: 0.0481 Acc: 75.0000%\n",
      "\tvalidation 10-67: Loss: 0.1362 Acc: 75.0000%\n",
      "\tvalidation 10-68: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 10-69: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 10-70: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 10-71: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 10-72: Loss: 0.0458 Acc: 100.0000%\n",
      "\tvalidation 10-73: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 10-74: Loss: 0.0547 Acc: 100.0000%\n",
      "\tvalidation 10-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 10-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 10-77: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 10-78: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 10-79: Loss: 0.1452 Acc: 75.0000%\n",
      "\tvalidation 10-80: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 10-81: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 10-82: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 10-83: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 10-84: Loss: 0.1184 Acc: 50.0000%\n",
      "\tvalidation 10-85: Loss: 1.3464 Acc: 50.0000%\n",
      "\tvalidation 10-86: Loss: 0.4329 Acc: 75.0000%\n",
      "\tvalidation 10-87: Loss: 1.3560 Acc: 75.0000%\n",
      "\tvalidation 10-88: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 10-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 10-90: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 10-91: Loss: 2.4196 Acc: 75.0000%\n",
      "\tvalidation 10-92: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 10-93: Loss: 0.1548 Acc: 75.0000%\n",
      "\tvalidation 10-94: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 10-95: Loss: 0.0532 Acc: 75.0000%\n",
      "\tvalidation 10-96: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 10-97: Loss: 3.1730 Acc: 50.0000%\n",
      "\tvalidation 10-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 10-99: Loss: 0.1699 Acc: 75.0000%\n",
      "\tvalidation 10-100: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 10-101: Loss: 0.1118 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 10-102: Loss: 0.2085 Acc: 75.0000%\n",
      "\tvalidation 10-103: Loss: 0.6919 Acc: 0.0000%\n",
      "\tvalidation 10-104: Loss: 0.7171 Acc: 75.0000%\n",
      "\tvalidation 10-105: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1669 Acc: 74.0816%\n",
      "\tvalidation Loss: 0.2346 Acc: 84.5238%\n",
      "Time passed 0h 9m 3s\n",
      "--------------------\n",
      "Epoch [11/40]:\n",
      "\ttrain 11-1: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 11-2: Loss: 0.5130 Acc: 25.0000%\n",
      "\ttrain 11-3: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 11-4: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 11-5: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 11-6: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 11-7: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 11-8: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 11-9: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 11-10: Loss: 0.0971 Acc: 100.0000%\n",
      "\ttrain 11-11: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 11-12: Loss: 0.3335 Acc: 50.0000%\n",
      "\ttrain 11-13: Loss: 0.1672 Acc: 75.0000%\n",
      "\ttrain 11-14: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 11-15: Loss: 0.1125 Acc: 100.0000%\n",
      "\ttrain 11-16: Loss: 0.0938 Acc: 100.0000%\n",
      "\ttrain 11-17: Loss: 0.4112 Acc: 50.0000%\n",
      "\ttrain 11-18: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 11-19: Loss: 0.2712 Acc: 75.0000%\n",
      "\ttrain 11-20: Loss: 0.1688 Acc: 50.0000%\n",
      "\ttrain 11-21: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 11-22: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 11-23: Loss: 0.1727 Acc: 75.0000%\n",
      "\ttrain 11-24: Loss: 0.2442 Acc: 50.0000%\n",
      "\ttrain 11-25: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 11-26: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 11-27: Loss: 0.2127 Acc: 75.0000%\n",
      "\ttrain 11-28: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 11-29: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 11-30: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 11-31: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 11-32: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 11-33: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 11-34: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 11-35: Loss: 0.2076 Acc: 50.0000%\n",
      "\ttrain 11-36: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 11-37: Loss: 0.2887 Acc: 50.0000%\n",
      "\ttrain 11-38: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 11-39: Loss: 0.1950 Acc: 75.0000%\n",
      "\ttrain 11-40: Loss: 0.4007 Acc: 50.0000%\n",
      "\ttrain 11-41: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 11-42: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 11-43: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 11-44: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 11-45: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 11-46: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 11-47: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 11-48: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 11-49: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 11-50: Loss: 0.2161 Acc: 75.0000%\n",
      "\ttrain 11-51: Loss: 0.0905 Acc: 100.0000%\n",
      "\ttrain 11-52: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 11-53: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 11-54: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 11-55: Loss: 0.3361 Acc: 50.0000%\n",
      "\ttrain 11-56: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 11-57: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 11-58: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 11-59: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 11-60: Loss: 0.2247 Acc: 50.0000%\n",
      "\ttrain 11-61: Loss: 0.1667 Acc: 75.0000%\n",
      "\ttrain 11-62: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 11-63: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 11-64: Loss: 0.2273 Acc: 75.0000%\n",
      "\ttrain 11-65: Loss: 0.2153 Acc: 75.0000%\n",
      "\ttrain 11-66: Loss: 0.1711 Acc: 50.0000%\n",
      "\ttrain 11-67: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 11-68: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 11-69: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 11-70: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 11-71: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 11-72: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 11-73: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 11-74: Loss: 0.3720 Acc: 75.0000%\n",
      "\ttrain 11-75: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 11-76: Loss: 0.0768 Acc: 100.0000%\n",
      "\ttrain 11-77: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 11-78: Loss: 0.2172 Acc: 50.0000%\n",
      "\ttrain 11-79: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 11-80: Loss: 0.1178 Acc: 50.0000%\n",
      "\ttrain 11-81: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 11-82: Loss: 0.3921 Acc: 50.0000%\n",
      "\ttrain 11-83: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 11-84: Loss: 0.2377 Acc: 50.0000%\n",
      "\ttrain 11-85: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 11-86: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 11-87: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 11-88: Loss: 0.1982 Acc: 50.0000%\n",
      "\ttrain 11-89: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 11-90: Loss: 0.2620 Acc: 75.0000%\n",
      "\ttrain 11-91: Loss: 0.1640 Acc: 75.0000%\n",
      "\ttrain 11-92: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 11-93: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 11-94: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 11-95: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 11-96: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 11-97: Loss: 0.3254 Acc: 50.0000%\n",
      "\ttrain 11-98: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 11-99: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 11-100: Loss: 0.0829 Acc: 100.0000%\n",
      "\ttrain 11-101: Loss: 0.5147 Acc: 25.0000%\n",
      "\ttrain 11-102: Loss: 0.3567 Acc: 50.0000%\n",
      "\ttrain 11-103: Loss: 0.4237 Acc: 50.0000%\n",
      "\ttrain 11-104: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 11-105: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 11-106: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 11-107: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 11-108: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 11-109: Loss: 0.2146 Acc: 50.0000%\n",
      "\ttrain 11-110: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 11-111: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 11-112: Loss: 0.3825 Acc: 50.0000%\n",
      "\ttrain 11-113: Loss: 0.0483 Acc: 75.0000%\n",
      "\ttrain 11-114: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 11-115: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 11-116: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 11-117: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 11-118: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 11-119: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 11-120: Loss: 0.1571 Acc: 75.0000%\n",
      "\ttrain 11-121: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 11-122: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 11-123: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 11-124: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 11-125: Loss: 0.2060 Acc: 75.0000%\n",
      "\ttrain 11-126: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 11-127: Loss: 0.5887 Acc: 50.0000%\n",
      "\ttrain 11-128: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 11-129: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 11-130: Loss: 0.1971 Acc: 75.0000%\n",
      "\ttrain 11-131: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 11-132: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 11-133: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 11-134: Loss: 0.1318 Acc: 50.0000%\n",
      "\ttrain 11-135: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 11-136: Loss: 0.1804 Acc: 75.0000%\n",
      "\ttrain 11-137: Loss: 0.1932 Acc: 75.0000%\n",
      "\ttrain 11-138: Loss: 0.2282 Acc: 75.0000%\n",
      "\ttrain 11-139: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 11-140: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 11-141: Loss: 0.1571 Acc: 75.0000%\n",
      "\ttrain 11-142: Loss: 0.1832 Acc: 75.0000%\n",
      "\ttrain 11-143: Loss: 0.3829 Acc: 50.0000%\n",
      "\ttrain 11-144: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 11-145: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 11-146: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 11-147: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 11-148: Loss: 0.1596 Acc: 75.0000%\n",
      "\ttrain 11-149: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 11-150: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 11-151: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 11-152: Loss: 0.1993 Acc: 75.0000%\n",
      "\ttrain 11-153: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 11-154: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 11-155: Loss: 0.1653 Acc: 50.0000%\n",
      "\ttrain 11-156: Loss: 0.2556 Acc: 75.0000%\n",
      "\ttrain 11-157: Loss: 0.1464 Acc: 50.0000%\n",
      "\ttrain 11-158: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 11-159: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 11-160: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 11-161: Loss: 0.2731 Acc: 50.0000%\n",
      "\ttrain 11-162: Loss: 0.2910 Acc: 50.0000%\n",
      "\ttrain 11-163: Loss: 0.3817 Acc: 50.0000%\n",
      "\ttrain 11-164: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 11-165: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 11-166: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 11-167: Loss: 0.1438 Acc: 50.0000%\n",
      "\ttrain 11-168: Loss: 0.3882 Acc: 50.0000%\n",
      "\ttrain 11-169: Loss: 0.3422 Acc: 75.0000%\n",
      "\ttrain 11-170: Loss: 0.2236 Acc: 50.0000%\n",
      "\ttrain 11-171: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 11-172: Loss: 0.2490 Acc: 25.0000%\n",
      "\ttrain 11-173: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 11-174: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 11-175: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 11-176: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 11-177: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 11-178: Loss: 0.2437 Acc: 25.0000%\n",
      "\ttrain 11-179: Loss: 0.2479 Acc: 50.0000%\n",
      "\ttrain 11-180: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 11-181: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 11-182: Loss: 0.4971 Acc: 75.0000%\n",
      "\ttrain 11-183: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 11-184: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 11-185: Loss: 0.1739 Acc: 75.0000%\n",
      "\ttrain 11-186: Loss: 0.1298 Acc: 50.0000%\n",
      "\ttrain 11-187: Loss: 0.2274 Acc: 75.0000%\n",
      "\ttrain 11-188: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 11-189: Loss: 0.1925 Acc: 50.0000%\n",
      "\ttrain 11-190: Loss: 0.1429 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-191: Loss: 0.2463 Acc: 50.0000%\n",
      "\ttrain 11-192: Loss: 0.2234 Acc: 25.0000%\n",
      "\ttrain 11-193: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 11-194: Loss: 0.1866 Acc: 75.0000%\n",
      "\ttrain 11-195: Loss: 0.2183 Acc: 75.0000%\n",
      "\ttrain 11-196: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 11-197: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 11-198: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 11-199: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 11-200: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 11-201: Loss: 0.1415 Acc: 75.0000%\n",
      "\ttrain 11-202: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 11-203: Loss: 0.1425 Acc: 100.0000%\n",
      "\ttrain 11-204: Loss: 0.1906 Acc: 50.0000%\n",
      "\ttrain 11-205: Loss: 0.2759 Acc: 75.0000%\n",
      "\ttrain 11-206: Loss: 0.2807 Acc: 50.0000%\n",
      "\ttrain 11-207: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 11-208: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 11-209: Loss: 0.1155 Acc: 50.0000%\n",
      "\ttrain 11-210: Loss: 0.0906 Acc: 100.0000%\n",
      "\ttrain 11-211: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 11-212: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 11-213: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 11-214: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 11-215: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 11-216: Loss: 0.1775 Acc: 50.0000%\n",
      "\ttrain 11-217: Loss: 0.1786 Acc: 75.0000%\n",
      "\ttrain 11-218: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 11-219: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 11-220: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 11-221: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 11-222: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 11-223: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 11-224: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 11-225: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 11-226: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 11-227: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 11-228: Loss: 0.1730 Acc: 50.0000%\n",
      "\ttrain 11-229: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 11-230: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 11-231: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 11-232: Loss: 0.2144 Acc: 75.0000%\n",
      "\ttrain 11-233: Loss: 0.0783 Acc: 100.0000%\n",
      "\ttrain 11-234: Loss: 0.0581 Acc: 100.0000%\n",
      "\ttrain 11-235: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 11-236: Loss: 0.2575 Acc: 50.0000%\n",
      "\ttrain 11-237: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 11-238: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 11-239: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 11-240: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 11-241: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 11-242: Loss: 0.2279 Acc: 50.0000%\n",
      "\ttrain 11-243: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 11-244: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 11-245: Loss: 0.1662 Acc: 75.0000%\n",
      "\tvalidation 11-1: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 11-2: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 11-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 11-4: Loss: 0.1096 Acc: 75.0000%\n",
      "\tvalidation 11-5: Loss: 1.8466 Acc: 75.0000%\n",
      "\tvalidation 11-6: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 11-7: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 11-8: Loss: 0.0868 Acc: 75.0000%\n",
      "\tvalidation 11-9: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 11-10: Loss: 0.1438 Acc: 75.0000%\n",
      "\tvalidation 11-11: Loss: 0.3827 Acc: 75.0000%\n",
      "\tvalidation 11-12: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 11-13: Loss: 0.0303 Acc: 100.0000%\n",
      "\tvalidation 11-14: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 11-15: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 11-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 11-17: Loss: 0.2011 Acc: 75.0000%\n",
      "\tvalidation 11-18: Loss: 0.8869 Acc: 50.0000%\n",
      "\tvalidation 11-19: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 11-20: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 11-21: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 11-22: Loss: 0.2052 Acc: 50.0000%\n",
      "\tvalidation 11-23: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 11-24: Loss: 0.5656 Acc: 75.0000%\n",
      "\tvalidation 11-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 11-26: Loss: 0.1367 Acc: 75.0000%\n",
      "\tvalidation 11-27: Loss: 0.1296 Acc: 75.0000%\n",
      "\tvalidation 11-28: Loss: 0.1543 Acc: 50.0000%\n",
      "\tvalidation 11-29: Loss: 2.2762 Acc: 75.0000%\n",
      "\tvalidation 11-30: Loss: 0.1669 Acc: 75.0000%\n",
      "\tvalidation 11-31: Loss: 0.3606 Acc: 50.0000%\n",
      "\tvalidation 11-32: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-33: Loss: 0.0466 Acc: 100.0000%\n",
      "\tvalidation 11-34: Loss: 0.3286 Acc: 50.0000%\n",
      "\tvalidation 11-35: Loss: 0.5698 Acc: 75.0000%\n",
      "\tvalidation 11-36: Loss: 0.0453 Acc: 75.0000%\n",
      "\tvalidation 11-37: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 11-38: Loss: 0.1057 Acc: 75.0000%\n",
      "\tvalidation 11-39: Loss: 0.9303 Acc: 75.0000%\n",
      "\tvalidation 11-40: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 11-41: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 11-42: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 11-43: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 11-44: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 11-45: Loss: 0.2186 Acc: 50.0000%\n",
      "\tvalidation 11-46: Loss: 0.4495 Acc: 75.0000%\n",
      "\tvalidation 11-47: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-48: Loss: 0.0914 Acc: 75.0000%\n",
      "\tvalidation 11-49: Loss: 0.1911 Acc: 25.0000%\n",
      "\tvalidation 11-50: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 11-51: Loss: 0.1225 Acc: 75.0000%\n",
      "\tvalidation 11-52: Loss: 0.1116 Acc: 75.0000%\n",
      "\tvalidation 11-53: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 11-54: Loss: 0.0555 Acc: 100.0000%\n",
      "\tvalidation 11-55: Loss: 0.0424 Acc: 100.0000%\n",
      "\tvalidation 11-56: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 11-57: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 11-58: Loss: 0.7692 Acc: 75.0000%\n",
      "\tvalidation 11-59: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 11-60: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 11-61: Loss: 0.0687 Acc: 75.0000%\n",
      "\tvalidation 11-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 11-63: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 11-64: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 11-65: Loss: 0.1310 Acc: 75.0000%\n",
      "\tvalidation 11-66: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 11-67: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 11-68: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 11-69: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 11-70: Loss: 0.0480 Acc: 100.0000%\n",
      "\tvalidation 11-71: Loss: 0.1849 Acc: 75.0000%\n",
      "\tvalidation 11-72: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 11-73: Loss: 0.1027 Acc: 75.0000%\n",
      "\tvalidation 11-74: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 11-75: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 11-76: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 11-77: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 11-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 11-79: Loss: 0.0543 Acc: 100.0000%\n",
      "\tvalidation 11-80: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 11-81: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 11-82: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 11-83: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 11-84: Loss: 0.1619 Acc: 75.0000%\n",
      "\tvalidation 11-85: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 11-86: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 11-87: Loss: 0.3884 Acc: 75.0000%\n",
      "\tvalidation 11-88: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 11-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 11-90: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 11-91: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 11-92: Loss: 0.0577 Acc: 75.0000%\n",
      "\tvalidation 11-93: Loss: 2.5682 Acc: 75.0000%\n",
      "\tvalidation 11-94: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 11-95: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 11-96: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 11-97: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 11-98: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-99: Loss: 0.0342 Acc: 100.0000%\n",
      "\tvalidation 11-100: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 11-101: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 11-102: Loss: 0.2594 Acc: 50.0000%\n",
      "\tvalidation 11-103: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 11-104: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 11-105: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1259 Acc: 79.5918%\n",
      "\tvalidation Loss: 0.1600 Acc: 88.8095%\n",
      "网络参数更新\n",
      "Time passed 0h 9m 57s\n",
      "--------------------\n",
      "Epoch [12/40]:\n",
      "\ttrain 12-1: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 12-2: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 12-3: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 12-4: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 12-5: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 12-6: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 12-7: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 12-8: Loss: 0.2534 Acc: 75.0000%\n",
      "\ttrain 12-9: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 12-10: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 12-11: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 12-12: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 12-13: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 12-14: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 12-15: Loss: 0.2320 Acc: 75.0000%\n",
      "\ttrain 12-16: Loss: 0.3824 Acc: 50.0000%\n",
      "\ttrain 12-17: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 12-18: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 12-19: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 12-20: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 12-21: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 12-22: Loss: 0.0444 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-23: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 12-24: Loss: 0.4127 Acc: 50.0000%\n",
      "\ttrain 12-25: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 12-26: Loss: 0.2019 Acc: 75.0000%\n",
      "\ttrain 12-27: Loss: 0.2854 Acc: 75.0000%\n",
      "\ttrain 12-28: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 12-29: Loss: 0.3068 Acc: 50.0000%\n",
      "\ttrain 12-30: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 12-31: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 12-32: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 12-33: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 12-34: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 12-35: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 12-36: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 12-37: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 12-38: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 12-39: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 12-40: Loss: 0.0868 Acc: 100.0000%\n",
      "\ttrain 12-41: Loss: 0.1901 Acc: 75.0000%\n",
      "\ttrain 12-42: Loss: 0.0655 Acc: 100.0000%\n",
      "\ttrain 12-43: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 12-44: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 12-45: Loss: 0.3537 Acc: 50.0000%\n",
      "\ttrain 12-46: Loss: 0.2281 Acc: 75.0000%\n",
      "\ttrain 12-47: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 12-48: Loss: 0.2078 Acc: 50.0000%\n",
      "\ttrain 12-49: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 12-50: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 12-51: Loss: 0.0587 Acc: 75.0000%\n",
      "\ttrain 12-52: Loss: 0.3158 Acc: 25.0000%\n",
      "\ttrain 12-53: Loss: 0.1684 Acc: 75.0000%\n",
      "\ttrain 12-54: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 12-55: Loss: 0.3141 Acc: 75.0000%\n",
      "\ttrain 12-56: Loss: 0.1739 Acc: 75.0000%\n",
      "\ttrain 12-57: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 12-58: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 12-59: Loss: 0.4161 Acc: 50.0000%\n",
      "\ttrain 12-60: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 12-61: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 12-62: Loss: 0.2197 Acc: 50.0000%\n",
      "\ttrain 12-63: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 12-64: Loss: 0.3108 Acc: 75.0000%\n",
      "\ttrain 12-65: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 12-66: Loss: 0.3650 Acc: 50.0000%\n",
      "\ttrain 12-67: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 12-68: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 12-69: Loss: 0.2141 Acc: 75.0000%\n",
      "\ttrain 12-70: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 12-71: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 12-72: Loss: 0.3396 Acc: 75.0000%\n",
      "\ttrain 12-73: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 12-74: Loss: 0.2111 Acc: 75.0000%\n",
      "\ttrain 12-75: Loss: 0.2529 Acc: 75.0000%\n",
      "\ttrain 12-76: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 12-77: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 12-78: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 12-79: Loss: 0.1658 Acc: 75.0000%\n",
      "\ttrain 12-80: Loss: 0.0875 Acc: 100.0000%\n",
      "\ttrain 12-81: Loss: 0.4025 Acc: 50.0000%\n",
      "\ttrain 12-82: Loss: 0.2225 Acc: 25.0000%\n",
      "\ttrain 12-83: Loss: 0.1532 Acc: 75.0000%\n",
      "\ttrain 12-84: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 12-85: Loss: 0.2496 Acc: 50.0000%\n",
      "\ttrain 12-86: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 12-87: Loss: 0.1937 Acc: 75.0000%\n",
      "\ttrain 12-88: Loss: 0.1893 Acc: 75.0000%\n",
      "\ttrain 12-89: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 12-90: Loss: 0.2676 Acc: 50.0000%\n",
      "\ttrain 12-91: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 12-92: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 12-93: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 12-94: Loss: 0.1922 Acc: 75.0000%\n",
      "\ttrain 12-95: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 12-96: Loss: 0.1913 Acc: 75.0000%\n",
      "\ttrain 12-97: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 12-98: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 12-99: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 12-100: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 12-101: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 12-102: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 12-103: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 12-104: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 12-105: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 12-106: Loss: 0.2727 Acc: 75.0000%\n",
      "\ttrain 12-107: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 12-108: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 12-109: Loss: 0.3010 Acc: 50.0000%\n",
      "\ttrain 12-110: Loss: 0.0870 Acc: 100.0000%\n",
      "\ttrain 12-111: Loss: 0.2218 Acc: 50.0000%\n",
      "\ttrain 12-112: Loss: 0.2026 Acc: 50.0000%\n",
      "\ttrain 12-113: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 12-114: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 12-115: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 12-116: Loss: 0.5061 Acc: 50.0000%\n",
      "\ttrain 12-117: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 12-118: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 12-119: Loss: 0.2535 Acc: 50.0000%\n",
      "\ttrain 12-120: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 12-121: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 12-122: Loss: 0.1355 Acc: 50.0000%\n",
      "\ttrain 12-123: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 12-124: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 12-125: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 12-126: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 12-127: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 12-128: Loss: 0.1819 Acc: 75.0000%\n",
      "\ttrain 12-129: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 12-130: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 12-131: Loss: 0.1673 Acc: 75.0000%\n",
      "\ttrain 12-132: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 12-133: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 12-134: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 12-135: Loss: 0.1652 Acc: 75.0000%\n",
      "\ttrain 12-136: Loss: 0.5066 Acc: 25.0000%\n",
      "\ttrain 12-137: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 12-138: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 12-139: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 12-140: Loss: 0.0708 Acc: 75.0000%\n",
      "\ttrain 12-141: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 12-142: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 12-143: Loss: 0.2179 Acc: 50.0000%\n",
      "\ttrain 12-144: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 12-145: Loss: 0.2373 Acc: 75.0000%\n",
      "\ttrain 12-146: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 12-147: Loss: 0.1496 Acc: 75.0000%\n",
      "\ttrain 12-148: Loss: 0.1261 Acc: 50.0000%\n",
      "\ttrain 12-149: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 12-150: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 12-151: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 12-152: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 12-153: Loss: 0.3307 Acc: 50.0000%\n",
      "\ttrain 12-154: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 12-155: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 12-156: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 12-157: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 12-158: Loss: 0.2129 Acc: 75.0000%\n",
      "\ttrain 12-159: Loss: 0.2270 Acc: 50.0000%\n",
      "\ttrain 12-160: Loss: 0.2110 Acc: 50.0000%\n",
      "\ttrain 12-161: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 12-162: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 12-163: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 12-164: Loss: 0.1537 Acc: 50.0000%\n",
      "\ttrain 12-165: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 12-166: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 12-167: Loss: 0.2583 Acc: 50.0000%\n",
      "\ttrain 12-168: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 12-169: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 12-170: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 12-171: Loss: 0.3449 Acc: 50.0000%\n",
      "\ttrain 12-172: Loss: 0.3791 Acc: 50.0000%\n",
      "\ttrain 12-173: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 12-174: Loss: 0.1658 Acc: 75.0000%\n",
      "\ttrain 12-175: Loss: 0.2358 Acc: 75.0000%\n",
      "\ttrain 12-176: Loss: 0.3031 Acc: 75.0000%\n",
      "\ttrain 12-177: Loss: 0.5575 Acc: 50.0000%\n",
      "\ttrain 12-178: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 12-179: Loss: 0.1536 Acc: 75.0000%\n",
      "\ttrain 12-180: Loss: 0.1450 Acc: 75.0000%\n",
      "\ttrain 12-181: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 12-182: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 12-183: Loss: 0.2182 Acc: 75.0000%\n",
      "\ttrain 12-184: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 12-185: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 12-186: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 12-187: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 12-188: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 12-189: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 12-190: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 12-191: Loss: 0.1918 Acc: 75.0000%\n",
      "\ttrain 12-192: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 12-193: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 12-194: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 12-195: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 12-196: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 12-197: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 12-198: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 12-199: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 12-200: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 12-201: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 12-202: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 12-203: Loss: 0.2989 Acc: 75.0000%\n",
      "\ttrain 12-204: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 12-205: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 12-206: Loss: 0.3877 Acc: 50.0000%\n",
      "\ttrain 12-207: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 12-208: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 12-209: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 12-210: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 12-211: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 12-212: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 12-213: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 12-214: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 12-215: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 12-216: Loss: 0.5373 Acc: 50.0000%\n",
      "\ttrain 12-217: Loss: 0.2247 Acc: 75.0000%\n",
      "\ttrain 12-218: Loss: 0.1514 Acc: 75.0000%\n",
      "\ttrain 12-219: Loss: 0.1343 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-220: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 12-221: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 12-222: Loss: 0.2028 Acc: 50.0000%\n",
      "\ttrain 12-223: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 12-224: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 12-225: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 12-226: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 12-227: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 12-228: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 12-229: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 12-230: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 12-231: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 12-232: Loss: 0.3345 Acc: 25.0000%\n",
      "\ttrain 12-233: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 12-234: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 12-235: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 12-236: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 12-237: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 12-238: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 12-239: Loss: 0.0920 Acc: 100.0000%\n",
      "\ttrain 12-240: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 12-241: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 12-242: Loss: 0.1992 Acc: 75.0000%\n",
      "\ttrain 12-243: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 12-244: Loss: 0.0706 Acc: 100.0000%\n",
      "\ttrain 12-245: Loss: 0.2216 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 12-1: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 12-2: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 12-3: Loss: 0.1981 Acc: 50.0000%\n",
      "\tvalidation 12-4: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 12-5: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 12-6: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 12-7: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 12-8: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 12-9: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 12-10: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 12-11: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 12-12: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 12-13: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 12-14: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 12-15: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 12-16: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 12-17: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 12-18: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 12-19: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 12-20: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 12-21: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 12-22: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 12-23: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 12-24: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 12-25: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 12-26: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 12-27: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 12-28: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 12-29: Loss: 0.0843 Acc: 75.0000%\n",
      "\tvalidation 12-30: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 12-31: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 12-32: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 12-33: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 12-34: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 12-35: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 12-36: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 12-37: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 12-38: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 12-39: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 12-40: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 12-41: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 12-42: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 12-43: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 12-44: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 12-45: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 12-46: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 12-47: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 12-48: Loss: 1.0507 Acc: 75.0000%\n",
      "\tvalidation 12-49: Loss: 0.1484 Acc: 75.0000%\n",
      "\tvalidation 12-50: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 12-51: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 12-52: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 12-53: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 12-54: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 12-55: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 12-56: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 12-57: Loss: 0.5678 Acc: 75.0000%\n",
      "\tvalidation 12-58: Loss: 0.0672 Acc: 75.0000%\n",
      "\tvalidation 12-59: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 12-60: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 12-61: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 12-62: Loss: 0.5367 Acc: 75.0000%\n",
      "\tvalidation 12-63: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 12-64: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 12-65: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 12-66: Loss: 0.2894 Acc: 75.0000%\n",
      "\tvalidation 12-67: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 12-68: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 12-69: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 12-70: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 12-71: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 12-72: Loss: 0.1482 Acc: 75.0000%\n",
      "\tvalidation 12-73: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 12-74: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 12-75: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 12-76: Loss: 0.0671 Acc: 75.0000%\n",
      "\tvalidation 12-77: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 12-78: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 12-79: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 12-80: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 12-81: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 12-82: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 12-83: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 12-84: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 12-85: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 12-86: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 12-87: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 12-88: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 12-89: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 12-90: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 12-91: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 12-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 12-93: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 12-94: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 12-95: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 12-96: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 12-97: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 12-98: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 12-99: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 12-100: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 12-101: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 12-102: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 12-103: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 12-104: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 12-105: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1174 Acc: 81.9388%\n",
      "\tvalidation Loss: 0.0391 Acc: 96.9048%\n",
      "网络参数更新\n",
      "Time passed 0h 10m 51s\n",
      "--------------------\n",
      "Epoch [13/40]:\n",
      "\ttrain 13-1: Loss: 0.3067 Acc: 50.0000%\n",
      "\ttrain 13-2: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 13-3: Loss: 0.1962 Acc: 75.0000%\n",
      "\ttrain 13-4: Loss: 0.2885 Acc: 75.0000%\n",
      "\ttrain 13-5: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 13-6: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 13-7: Loss: 0.2892 Acc: 50.0000%\n",
      "\ttrain 13-8: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 13-9: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 13-10: Loss: 0.1930 Acc: 50.0000%\n",
      "\ttrain 13-11: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 13-12: Loss: 0.0992 Acc: 100.0000%\n",
      "\ttrain 13-13: Loss: 0.1102 Acc: 50.0000%\n",
      "\ttrain 13-14: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 13-15: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 13-16: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 13-17: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 13-18: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 13-19: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 13-20: Loss: 0.4585 Acc: 75.0000%\n",
      "\ttrain 13-21: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 13-22: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 13-23: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 13-24: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 13-25: Loss: 0.3745 Acc: 50.0000%\n",
      "\ttrain 13-26: Loss: 0.4676 Acc: 50.0000%\n",
      "\ttrain 13-27: Loss: 0.0856 Acc: 100.0000%\n",
      "\ttrain 13-28: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 13-29: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 13-30: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 13-31: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 13-32: Loss: 0.9718 Acc: 0.0000%\n",
      "\ttrain 13-33: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 13-34: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 13-35: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 13-36: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 13-37: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 13-38: Loss: 0.3521 Acc: 50.0000%\n",
      "\ttrain 13-39: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 13-40: Loss: 0.2645 Acc: 50.0000%\n",
      "\ttrain 13-41: Loss: 0.2376 Acc: 75.0000%\n",
      "\ttrain 13-42: Loss: 0.7562 Acc: 25.0000%\n",
      "\ttrain 13-43: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 13-44: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 13-45: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 13-46: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 13-47: Loss: 0.1268 Acc: 100.0000%\n",
      "\ttrain 13-48: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 13-49: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 13-50: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 13-51: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 13-52: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 13-53: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 13-54: Loss: 0.2966 Acc: 50.0000%\n",
      "\ttrain 13-55: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 13-56: Loss: 0.2300 Acc: 50.0000%\n",
      "\ttrain 13-57: Loss: 0.2288 Acc: 75.0000%\n",
      "\ttrain 13-58: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 13-59: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 13-60: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 13-61: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 13-62: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 13-63: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 13-64: Loss: 0.4876 Acc: 25.0000%\n",
      "\ttrain 13-65: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 13-66: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 13-67: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 13-68: Loss: 0.3326 Acc: 50.0000%\n",
      "\ttrain 13-69: Loss: 0.3588 Acc: 75.0000%\n",
      "\ttrain 13-70: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 13-71: Loss: 0.2266 Acc: 50.0000%\n",
      "\ttrain 13-72: Loss: 0.2182 Acc: 75.0000%\n",
      "\ttrain 13-73: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 13-74: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 13-75: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 13-76: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 13-77: Loss: 0.2007 Acc: 50.0000%\n",
      "\ttrain 13-78: Loss: 0.0220 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-79: Loss: 0.1555 Acc: 100.0000%\n",
      "\ttrain 13-80: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 13-81: Loss: 0.3347 Acc: 50.0000%\n",
      "\ttrain 13-82: Loss: 0.1910 Acc: 75.0000%\n",
      "\ttrain 13-83: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 13-84: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 13-85: Loss: 0.4938 Acc: 75.0000%\n",
      "\ttrain 13-86: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 13-87: Loss: 0.1946 Acc: 75.0000%\n",
      "\ttrain 13-88: Loss: 0.1126 Acc: 100.0000%\n",
      "\ttrain 13-89: Loss: 0.2162 Acc: 75.0000%\n",
      "\ttrain 13-90: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 13-91: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 13-92: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 13-93: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 13-94: Loss: 0.2356 Acc: 75.0000%\n",
      "\ttrain 13-95: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 13-96: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 13-97: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 13-98: Loss: 0.1990 Acc: 50.0000%\n",
      "\ttrain 13-99: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 13-100: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 13-101: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 13-102: Loss: 0.0912 Acc: 100.0000%\n",
      "\ttrain 13-103: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 13-104: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 13-105: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 13-106: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 13-107: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 13-108: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 13-109: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 13-110: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 13-111: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 13-112: Loss: 0.2803 Acc: 25.0000%\n",
      "\ttrain 13-113: Loss: 0.4016 Acc: 50.0000%\n",
      "\ttrain 13-114: Loss: 0.0674 Acc: 100.0000%\n",
      "\ttrain 13-115: Loss: 0.4614 Acc: 25.0000%\n",
      "\ttrain 13-116: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 13-117: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 13-118: Loss: 0.1312 Acc: 50.0000%\n",
      "\ttrain 13-119: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 13-120: Loss: 0.6637 Acc: 25.0000%\n",
      "\ttrain 13-121: Loss: 0.1987 Acc: 50.0000%\n",
      "\ttrain 13-122: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 13-123: Loss: 0.2090 Acc: 75.0000%\n",
      "\ttrain 13-124: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 13-125: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 13-126: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 13-127: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 13-128: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 13-129: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 13-130: Loss: 0.0691 Acc: 100.0000%\n",
      "\ttrain 13-131: Loss: 0.0603 Acc: 75.0000%\n",
      "\ttrain 13-132: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 13-133: Loss: 0.1557 Acc: 75.0000%\n",
      "\ttrain 13-134: Loss: 0.1241 Acc: 75.0000%\n",
      "\ttrain 13-135: Loss: 0.4042 Acc: 75.0000%\n",
      "\ttrain 13-136: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 13-137: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 13-138: Loss: 0.2139 Acc: 75.0000%\n",
      "\ttrain 13-139: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 13-140: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 13-141: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 13-142: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 13-143: Loss: 0.4330 Acc: 50.0000%\n",
      "\ttrain 13-144: Loss: 0.1892 Acc: 75.0000%\n",
      "\ttrain 13-145: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 13-146: Loss: 0.5634 Acc: 75.0000%\n",
      "\ttrain 13-147: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 13-148: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 13-149: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 13-150: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 13-151: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 13-152: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 13-153: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 13-154: Loss: 0.2033 Acc: 75.0000%\n",
      "\ttrain 13-155: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 13-156: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 13-157: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 13-158: Loss: 0.1939 Acc: 75.0000%\n",
      "\ttrain 13-159: Loss: 0.1976 Acc: 50.0000%\n",
      "\ttrain 13-160: Loss: 0.1644 Acc: 75.0000%\n",
      "\ttrain 13-161: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 13-162: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 13-163: Loss: 0.1924 Acc: 50.0000%\n",
      "\ttrain 13-164: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 13-165: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 13-166: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 13-167: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 13-168: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 13-169: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 13-170: Loss: 0.2446 Acc: 75.0000%\n",
      "\ttrain 13-171: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 13-172: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 13-173: Loss: 0.3004 Acc: 50.0000%\n",
      "\ttrain 13-174: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 13-175: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 13-176: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 13-177: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 13-178: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 13-179: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 13-180: Loss: 0.5364 Acc: 0.0000%\n",
      "\ttrain 13-181: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 13-182: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 13-183: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 13-184: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 13-185: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 13-186: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 13-187: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 13-188: Loss: 0.2564 Acc: 75.0000%\n",
      "\ttrain 13-189: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 13-190: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 13-191: Loss: 0.1677 Acc: 50.0000%\n",
      "\ttrain 13-192: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 13-193: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 13-194: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 13-195: Loss: 0.3068 Acc: 50.0000%\n",
      "\ttrain 13-196: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 13-197: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 13-198: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 13-199: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 13-200: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 13-201: Loss: 0.3731 Acc: 50.0000%\n",
      "\ttrain 13-202: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 13-203: Loss: 0.3197 Acc: 75.0000%\n",
      "\ttrain 13-204: Loss: 0.3343 Acc: 50.0000%\n",
      "\ttrain 13-205: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 13-206: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 13-207: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 13-208: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 13-209: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 13-210: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 13-211: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 13-212: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 13-213: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 13-214: Loss: 0.3620 Acc: 50.0000%\n",
      "\ttrain 13-215: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 13-216: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 13-217: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 13-218: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 13-219: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 13-220: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 13-221: Loss: 0.1623 Acc: 50.0000%\n",
      "\ttrain 13-222: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 13-223: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 13-224: Loss: 0.0659 Acc: 100.0000%\n",
      "\ttrain 13-225: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 13-226: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 13-227: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 13-228: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 13-229: Loss: 0.5383 Acc: 25.0000%\n",
      "\ttrain 13-230: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 13-231: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 13-232: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 13-233: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 13-234: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 13-235: Loss: 0.1503 Acc: 50.0000%\n",
      "\ttrain 13-236: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 13-237: Loss: 0.0581 Acc: 100.0000%\n",
      "\ttrain 13-238: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 13-239: Loss: 0.1810 Acc: 50.0000%\n",
      "\ttrain 13-240: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 13-241: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 13-242: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 13-243: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 13-244: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 13-245: Loss: 0.1891 Acc: 75.0000%\n",
      "\tvalidation 13-1: Loss: 0.0558 Acc: 100.0000%\n",
      "\tvalidation 13-2: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 13-3: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 13-4: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 13-5: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 13-6: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 13-7: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 13-8: Loss: 0.0612 Acc: 100.0000%\n",
      "\tvalidation 13-9: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 13-10: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 13-11: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 13-12: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 13-13: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 13-14: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 13-15: Loss: 0.1543 Acc: 75.0000%\n",
      "\tvalidation 13-16: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 13-17: Loss: 0.1038 Acc: 75.0000%\n",
      "\tvalidation 13-18: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 13-19: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 13-20: Loss: 0.0401 Acc: 100.0000%\n",
      "\tvalidation 13-21: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 13-22: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 13-23: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 13-24: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 13-25: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 13-26: Loss: 0.0061 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 13-27: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 13-28: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 13-29: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 13-30: Loss: 0.0623 Acc: 75.0000%\n",
      "\tvalidation 13-31: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 13-32: Loss: 0.0483 Acc: 100.0000%\n",
      "\tvalidation 13-33: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 13-34: Loss: 0.1711 Acc: 75.0000%\n",
      "\tvalidation 13-35: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 13-36: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 13-37: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 13-38: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 13-39: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 13-40: Loss: 0.0852 Acc: 75.0000%\n",
      "\tvalidation 13-41: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 13-42: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 13-43: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 13-44: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 13-45: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 13-46: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 13-47: Loss: 0.3125 Acc: 75.0000%\n",
      "\tvalidation 13-48: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 13-49: Loss: 0.0480 Acc: 75.0000%\n",
      "\tvalidation 13-50: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 13-51: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 13-52: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 13-53: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 13-54: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 13-55: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 13-56: Loss: 0.1402 Acc: 50.0000%\n",
      "\tvalidation 13-57: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 13-58: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 13-59: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 13-60: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 13-61: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 13-62: Loss: 0.0498 Acc: 75.0000%\n",
      "\tvalidation 13-63: Loss: 0.4173 Acc: 50.0000%\n",
      "\tvalidation 13-64: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 13-65: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 13-66: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 13-67: Loss: 0.1543 Acc: 75.0000%\n",
      "\tvalidation 13-68: Loss: 0.0484 Acc: 100.0000%\n",
      "\tvalidation 13-69: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 13-70: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 13-71: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 13-72: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 13-73: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 13-74: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 13-75: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 13-76: Loss: 0.1455 Acc: 75.0000%\n",
      "\tvalidation 13-77: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 13-78: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 13-79: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 13-80: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 13-81: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 13-82: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 13-83: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 13-84: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 13-85: Loss: 0.0656 Acc: 75.0000%\n",
      "\tvalidation 13-86: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 13-87: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 13-88: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 13-89: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 13-90: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 13-91: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 13-92: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 13-93: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 13-94: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 13-95: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 13-96: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 13-97: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 13-98: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 13-99: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 13-100: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 13-101: Loss: 0.0504 Acc: 75.0000%\n",
      "\tvalidation 13-102: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 13-103: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 13-104: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 13-105: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1244 Acc: 81.9388%\n",
      "\tvalidation Loss: 0.0303 Acc: 95.9524%\n",
      "Time passed 0h 11m 43s\n",
      "--------------------\n",
      "Epoch [14/40]:\n",
      "\ttrain 14-1: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 14-2: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 14-3: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 14-4: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 14-5: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 14-6: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 14-7: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 14-8: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 14-9: Loss: 0.0581 Acc: 100.0000%\n",
      "\ttrain 14-10: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 14-11: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 14-12: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 14-13: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 14-14: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 14-15: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 14-16: Loss: 0.3127 Acc: 75.0000%\n",
      "\ttrain 14-17: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 14-18: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 14-19: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 14-20: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 14-21: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 14-22: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 14-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 14-24: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 14-25: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 14-26: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 14-27: Loss: 0.3136 Acc: 25.0000%\n",
      "\ttrain 14-28: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 14-29: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 14-30: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 14-31: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 14-32: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 14-33: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 14-34: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 14-35: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 14-36: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 14-37: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 14-38: Loss: 0.2016 Acc: 75.0000%\n",
      "\ttrain 14-39: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 14-40: Loss: 0.1591 Acc: 75.0000%\n",
      "\ttrain 14-41: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 14-42: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 14-43: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 14-44: Loss: 0.2982 Acc: 75.0000%\n",
      "\ttrain 14-45: Loss: 0.1958 Acc: 75.0000%\n",
      "\ttrain 14-46: Loss: 0.2720 Acc: 75.0000%\n",
      "\ttrain 14-47: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 14-48: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 14-49: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 14-50: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 14-51: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 14-52: Loss: 0.1839 Acc: 75.0000%\n",
      "\ttrain 14-53: Loss: 0.0766 Acc: 100.0000%\n",
      "\ttrain 14-54: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 14-55: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 14-56: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 14-57: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 14-58: Loss: 0.4055 Acc: 75.0000%\n",
      "\ttrain 14-59: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 14-60: Loss: 0.1189 Acc: 50.0000%\n",
      "\ttrain 14-61: Loss: 0.5252 Acc: 25.0000%\n",
      "\ttrain 14-62: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 14-63: Loss: 0.2205 Acc: 75.0000%\n",
      "\ttrain 14-64: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 14-65: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 14-66: Loss: 0.4061 Acc: 50.0000%\n",
      "\ttrain 14-67: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 14-68: Loss: 0.1380 Acc: 50.0000%\n",
      "\ttrain 14-69: Loss: 0.2991 Acc: 25.0000%\n",
      "\ttrain 14-70: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 14-71: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 14-72: Loss: 0.1593 Acc: 75.0000%\n",
      "\ttrain 14-73: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 14-74: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 14-75: Loss: 0.3449 Acc: 50.0000%\n",
      "\ttrain 14-76: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 14-77: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 14-78: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 14-79: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 14-80: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 14-81: Loss: 0.3403 Acc: 50.0000%\n",
      "\ttrain 14-82: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 14-83: Loss: 0.2488 Acc: 75.0000%\n",
      "\ttrain 14-84: Loss: 0.2955 Acc: 75.0000%\n",
      "\ttrain 14-85: Loss: 0.1162 Acc: 50.0000%\n",
      "\ttrain 14-86: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 14-87: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 14-88: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 14-89: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 14-90: Loss: 0.1441 Acc: 75.0000%\n",
      "\ttrain 14-91: Loss: 0.1573 Acc: 50.0000%\n",
      "\ttrain 14-92: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 14-93: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 14-94: Loss: 0.2060 Acc: 75.0000%\n",
      "\ttrain 14-95: Loss: 0.4456 Acc: 25.0000%\n",
      "\ttrain 14-96: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 14-97: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 14-98: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 14-99: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 14-100: Loss: 0.2149 Acc: 50.0000%\n",
      "\ttrain 14-101: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 14-102: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 14-103: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 14-104: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 14-105: Loss: 0.0049 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-106: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 14-107: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 14-108: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 14-109: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 14-110: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 14-111: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 14-112: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 14-113: Loss: 0.1703 Acc: 50.0000%\n",
      "\ttrain 14-114: Loss: 0.1702 Acc: 75.0000%\n",
      "\ttrain 14-115: Loss: 0.4684 Acc: 50.0000%\n",
      "\ttrain 14-116: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 14-117: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 14-118: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 14-119: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 14-120: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 14-121: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 14-122: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 14-123: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 14-124: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 14-125: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 14-126: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 14-127: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 14-128: Loss: 0.1763 Acc: 50.0000%\n",
      "\ttrain 14-129: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 14-130: Loss: 0.0901 Acc: 100.0000%\n",
      "\ttrain 14-131: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 14-132: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 14-133: Loss: 0.8032 Acc: 0.0000%\n",
      "\ttrain 14-134: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 14-135: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 14-136: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 14-137: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 14-138: Loss: 0.4122 Acc: 50.0000%\n",
      "\ttrain 14-139: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 14-140: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 14-141: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 14-142: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 14-143: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 14-144: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 14-145: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 14-146: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 14-147: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 14-148: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 14-149: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 14-150: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 14-151: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 14-152: Loss: 0.2475 Acc: 50.0000%\n",
      "\ttrain 14-153: Loss: 0.5003 Acc: 25.0000%\n",
      "\ttrain 14-154: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 14-155: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 14-156: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 14-157: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 14-158: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 14-159: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 14-160: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 14-161: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 14-162: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 14-163: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 14-164: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 14-165: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 14-166: Loss: 0.4600 Acc: 50.0000%\n",
      "\ttrain 14-167: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 14-168: Loss: 0.3476 Acc: 50.0000%\n",
      "\ttrain 14-169: Loss: 0.2126 Acc: 75.0000%\n",
      "\ttrain 14-170: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 14-171: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 14-172: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 14-173: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 14-174: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 14-175: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 14-176: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 14-177: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 14-178: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 14-179: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 14-180: Loss: 0.5289 Acc: 25.0000%\n",
      "\ttrain 14-181: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 14-182: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 14-183: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 14-184: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 14-185: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 14-186: Loss: 0.9192 Acc: 0.0000%\n",
      "\ttrain 14-187: Loss: 0.1344 Acc: 100.0000%\n",
      "\ttrain 14-188: Loss: 1.0667 Acc: 25.0000%\n",
      "\ttrain 14-189: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 14-190: Loss: 0.2534 Acc: 75.0000%\n",
      "\ttrain 14-191: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 14-192: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 14-193: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 14-194: Loss: 0.4185 Acc: 50.0000%\n",
      "\ttrain 14-195: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 14-196: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 14-197: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 14-198: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 14-199: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 14-200: Loss: 0.2240 Acc: 75.0000%\n",
      "\ttrain 14-201: Loss: 0.3302 Acc: 50.0000%\n",
      "\ttrain 14-202: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 14-203: Loss: 0.5578 Acc: 25.0000%\n",
      "\ttrain 14-204: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 14-205: Loss: 0.2089 Acc: 75.0000%\n",
      "\ttrain 14-206: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 14-207: Loss: 0.3794 Acc: 50.0000%\n",
      "\ttrain 14-208: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 14-209: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 14-210: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 14-211: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 14-212: Loss: 0.2166 Acc: 50.0000%\n",
      "\ttrain 14-213: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 14-214: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 14-215: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 14-216: Loss: 0.3591 Acc: 25.0000%\n",
      "\ttrain 14-217: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 14-218: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 14-219: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 14-220: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 14-221: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 14-222: Loss: 0.2532 Acc: 75.0000%\n",
      "\ttrain 14-223: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 14-224: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 14-225: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 14-226: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 14-227: Loss: 0.0729 Acc: 75.0000%\n",
      "\ttrain 14-228: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 14-229: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 14-230: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 14-231: Loss: 0.2812 Acc: 50.0000%\n",
      "\ttrain 14-232: Loss: 0.1986 Acc: 75.0000%\n",
      "\ttrain 14-233: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 14-234: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 14-235: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 14-236: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 14-237: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 14-238: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 14-239: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 14-240: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 14-241: Loss: 0.7184 Acc: 0.0000%\n",
      "\ttrain 14-242: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 14-243: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 14-244: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 14-245: Loss: 0.2084 Acc: 75.0000%\n",
      "\tvalidation 14-1: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 14-2: Loss: 0.0670 Acc: 100.0000%\n",
      "\tvalidation 14-3: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 14-4: Loss: 0.5372 Acc: 75.0000%\n",
      "\tvalidation 14-5: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 14-6: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 14-7: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 14-8: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 14-9: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 14-10: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 14-11: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 14-12: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 14-13: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 14-14: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-15: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 14-16: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 14-17: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 14-18: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 14-19: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 14-20: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 14-21: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 14-22: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 14-23: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 14-24: Loss: 0.1140 Acc: 75.0000%\n",
      "\tvalidation 14-25: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 14-26: Loss: 0.2909 Acc: 75.0000%\n",
      "\tvalidation 14-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 14-28: Loss: 0.2714 Acc: 75.0000%\n",
      "\tvalidation 14-29: Loss: 0.6473 Acc: 75.0000%\n",
      "\tvalidation 14-30: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 14-31: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 14-32: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 14-33: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 14-34: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 14-35: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 14-36: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 14-37: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 14-38: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 14-39: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 14-40: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 14-41: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 14-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-43: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 14-44: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 14-45: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 14-46: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 14-47: Loss: 0.0592 Acc: 100.0000%\n",
      "\tvalidation 14-48: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 14-49: Loss: 0.0154 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 14-50: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 14-51: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 14-52: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 14-53: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 14-54: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 14-55: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-56: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 14-57: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 14-58: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 14-59: Loss: 0.4112 Acc: 75.0000%\n",
      "\tvalidation 14-60: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 14-61: Loss: 0.3196 Acc: 75.0000%\n",
      "\tvalidation 14-62: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 14-63: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 14-64: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 14-65: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-66: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 14-67: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 14-68: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 14-69: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 14-70: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 14-71: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 14-72: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 14-73: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 14-74: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 14-75: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 14-76: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 14-77: Loss: 0.0899 Acc: 75.0000%\n",
      "\tvalidation 14-78: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 14-79: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 14-80: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-81: Loss: 0.3605 Acc: 75.0000%\n",
      "\tvalidation 14-82: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 14-83: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 14-84: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 14-85: Loss: 2.0075 Acc: 75.0000%\n",
      "\tvalidation 14-86: Loss: 0.0500 Acc: 100.0000%\n",
      "\tvalidation 14-87: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 14-88: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 14-89: Loss: 1.7827 Acc: 75.0000%\n",
      "\tvalidation 14-90: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 14-91: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 14-92: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 14-93: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 14-94: Loss: 0.1678 Acc: 75.0000%\n",
      "\tvalidation 14-95: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 14-96: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 14-97: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 14-98: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 14-99: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 14-100: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 14-101: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 14-102: Loss: 1.6500 Acc: 75.0000%\n",
      "\tvalidation 14-103: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 14-104: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 14-105: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1156 Acc: 83.1633%\n",
      "\tvalidation Loss: 0.0913 Acc: 96.6667%\n",
      "Time passed 0h 12m 35s\n",
      "--------------------\n",
      "Epoch [15/40]:\n",
      "\ttrain 15-1: Loss: 0.2347 Acc: 50.0000%\n",
      "\ttrain 15-2: Loss: 0.1563 Acc: 50.0000%\n",
      "\ttrain 15-3: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 15-4: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 15-5: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 15-6: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 15-7: Loss: 0.2224 Acc: 50.0000%\n",
      "\ttrain 15-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 15-9: Loss: 0.1700 Acc: 75.0000%\n",
      "\ttrain 15-10: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 15-11: Loss: 0.2737 Acc: 50.0000%\n",
      "\ttrain 15-12: Loss: 0.2047 Acc: 75.0000%\n",
      "\ttrain 15-13: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 15-14: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 15-15: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 15-16: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 15-17: Loss: 0.1937 Acc: 50.0000%\n",
      "\ttrain 15-18: Loss: 0.2648 Acc: 50.0000%\n",
      "\ttrain 15-19: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 15-20: Loss: 0.1098 Acc: 100.0000%\n",
      "\ttrain 15-21: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 15-22: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 15-23: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 15-24: Loss: 0.2371 Acc: 50.0000%\n",
      "\ttrain 15-25: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 15-26: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 15-27: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 15-28: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 15-29: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 15-30: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 15-31: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 15-32: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 15-33: Loss: 0.1359 Acc: 75.0000%\n",
      "\ttrain 15-34: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 15-35: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 15-36: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 15-37: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 15-38: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 15-39: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 15-40: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 15-41: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 15-42: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 15-43: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 15-44: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 15-45: Loss: 0.7533 Acc: 25.0000%\n",
      "\ttrain 15-46: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 15-47: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 15-48: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 15-49: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 15-50: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 15-51: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 15-52: Loss: 0.2372 Acc: 75.0000%\n",
      "\ttrain 15-53: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 15-54: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 15-55: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 15-56: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 15-57: Loss: 0.3386 Acc: 50.0000%\n",
      "\ttrain 15-58: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 15-59: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 15-60: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 15-61: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 15-62: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 15-63: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 15-64: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 15-65: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 15-66: Loss: 0.2100 Acc: 50.0000%\n",
      "\ttrain 15-67: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 15-68: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 15-69: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 15-70: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 15-71: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 15-72: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 15-73: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 15-74: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 15-75: Loss: 0.5504 Acc: 50.0000%\n",
      "\ttrain 15-76: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 15-77: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 15-78: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 15-79: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 15-80: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 15-81: Loss: 0.2194 Acc: 75.0000%\n",
      "\ttrain 15-82: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 15-83: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 15-84: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 15-85: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 15-86: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 15-87: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 15-88: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 15-89: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 15-90: Loss: 0.1668 Acc: 75.0000%\n",
      "\ttrain 15-91: Loss: 0.2521 Acc: 50.0000%\n",
      "\ttrain 15-92: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 15-93: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 15-94: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 15-95: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 15-96: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 15-97: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 15-98: Loss: 0.1280 Acc: 75.0000%\n",
      "\ttrain 15-99: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 15-100: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 15-101: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 15-102: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 15-103: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 15-104: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 15-105: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 15-106: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 15-107: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 15-108: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 15-109: Loss: 0.2380 Acc: 25.0000%\n",
      "\ttrain 15-110: Loss: 0.0924 Acc: 100.0000%\n",
      "\ttrain 15-111: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 15-112: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 15-113: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 15-114: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 15-115: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 15-116: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 15-117: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 15-118: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 15-119: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 15-120: Loss: 0.3036 Acc: 75.0000%\n",
      "\ttrain 15-121: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 15-122: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 15-123: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 15-124: Loss: 0.4208 Acc: 50.0000%\n",
      "\ttrain 15-125: Loss: 0.3062 Acc: 75.0000%\n",
      "\ttrain 15-126: Loss: 0.2879 Acc: 50.0000%\n",
      "\ttrain 15-127: Loss: 0.3081 Acc: 75.0000%\n",
      "\ttrain 15-128: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 15-129: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 15-130: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 15-131: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 15-132: Loss: 0.3504 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 15-133: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 15-134: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 15-135: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 15-136: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 15-137: Loss: 0.1079 Acc: 50.0000%\n",
      "\ttrain 15-138: Loss: 0.2692 Acc: 25.0000%\n",
      "\ttrain 15-139: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 15-140: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 15-141: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 15-142: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 15-143: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 15-144: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 15-145: Loss: 0.2030 Acc: 75.0000%\n",
      "\ttrain 15-146: Loss: 0.4094 Acc: 75.0000%\n",
      "\ttrain 15-147: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 15-148: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 15-149: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 15-150: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 15-151: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 15-152: Loss: 0.2537 Acc: 75.0000%\n",
      "\ttrain 15-153: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 15-154: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 15-155: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 15-156: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 15-157: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 15-158: Loss: 0.2883 Acc: 50.0000%\n",
      "\ttrain 15-159: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 15-160: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 15-161: Loss: 0.2840 Acc: 75.0000%\n",
      "\ttrain 15-162: Loss: 0.5990 Acc: 50.0000%\n",
      "\ttrain 15-163: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 15-164: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 15-165: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 15-166: Loss: 0.4542 Acc: 25.0000%\n",
      "\ttrain 15-167: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 15-168: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 15-169: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 15-170: Loss: 0.4122 Acc: 0.0000%\n",
      "\ttrain 15-171: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 15-172: Loss: 0.1703 Acc: 75.0000%\n",
      "\ttrain 15-173: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 15-174: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 15-175: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 15-176: Loss: 0.2363 Acc: 50.0000%\n",
      "\ttrain 15-177: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 15-178: Loss: 0.1696 Acc: 75.0000%\n",
      "\ttrain 15-179: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 15-180: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 15-181: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 15-182: Loss: 0.2248 Acc: 75.0000%\n",
      "\ttrain 15-183: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 15-184: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 15-185: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 15-186: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 15-187: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 15-188: Loss: 0.1045 Acc: 100.0000%\n",
      "\ttrain 15-189: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 15-190: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 15-191: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 15-192: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 15-193: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 15-194: Loss: 0.2932 Acc: 75.0000%\n",
      "\ttrain 15-195: Loss: 0.1679 Acc: 50.0000%\n",
      "\ttrain 15-196: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 15-197: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 15-198: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 15-199: Loss: 0.3701 Acc: 50.0000%\n",
      "\ttrain 15-200: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 15-201: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 15-202: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 15-203: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 15-204: Loss: 0.2058 Acc: 50.0000%\n",
      "\ttrain 15-205: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 15-206: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 15-207: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 15-208: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 15-209: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 15-210: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 15-211: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 15-212: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 15-213: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 15-214: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 15-215: Loss: 0.3458 Acc: 50.0000%\n",
      "\ttrain 15-216: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 15-217: Loss: 0.2335 Acc: 50.0000%\n",
      "\ttrain 15-218: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 15-219: Loss: 0.1538 Acc: 75.0000%\n",
      "\ttrain 15-220: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 15-221: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 15-222: Loss: 0.0618 Acc: 100.0000%\n",
      "\ttrain 15-223: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 15-224: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 15-225: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 15-226: Loss: 0.1383 Acc: 75.0000%\n",
      "\ttrain 15-227: Loss: 0.1874 Acc: 75.0000%\n",
      "\ttrain 15-228: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 15-229: Loss: 0.2708 Acc: 50.0000%\n",
      "\ttrain 15-230: Loss: 0.2774 Acc: 75.0000%\n",
      "\ttrain 15-231: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 15-232: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 15-233: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 15-234: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 15-235: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 15-236: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 15-237: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 15-238: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 15-239: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 15-240: Loss: 0.8885 Acc: 0.0000%\n",
      "\ttrain 15-241: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 15-242: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 15-243: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 15-244: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 15-245: Loss: 0.0633 Acc: 100.0000%\n",
      "\tvalidation 15-1: Loss: 1.3034 Acc: 75.0000%\n",
      "\tvalidation 15-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-4: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 15-5: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 15-6: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 15-7: Loss: 5.3256 Acc: 50.0000%\n",
      "\tvalidation 15-8: Loss: 0.1735 Acc: 75.0000%\n",
      "\tvalidation 15-9: Loss: 0.1747 Acc: 75.0000%\n",
      "\tvalidation 15-10: Loss: 2.2949 Acc: 75.0000%\n",
      "\tvalidation 15-11: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 15-12: Loss: 0.7903 Acc: 50.0000%\n",
      "\tvalidation 15-13: Loss: 0.1077 Acc: 75.0000%\n",
      "\tvalidation 15-14: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 15-15: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 15-16: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 15-17: Loss: 0.8505 Acc: 75.0000%\n",
      "\tvalidation 15-18: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 15-19: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 15-20: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-21: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-23: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 15-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-25: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 15-26: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 15-27: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-28: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 15-29: Loss: 0.2993 Acc: 75.0000%\n",
      "\tvalidation 15-30: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-31: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 15-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-33: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-34: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 15-35: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 15-36: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 15-37: Loss: 0.5543 Acc: 75.0000%\n",
      "\tvalidation 15-38: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 15-39: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-41: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 15-42: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 15-43: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 15-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-45: Loss: 0.1816 Acc: 75.0000%\n",
      "\tvalidation 15-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-48: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 15-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-50: Loss: 0.1750 Acc: 75.0000%\n",
      "\tvalidation 15-51: Loss: 0.2398 Acc: 75.0000%\n",
      "\tvalidation 15-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-53: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 15-54: Loss: 1.5911 Acc: 75.0000%\n",
      "\tvalidation 15-55: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-56: Loss: 8.0499 Acc: 50.0000%\n",
      "\tvalidation 15-57: Loss: 1.2985 Acc: 75.0000%\n",
      "\tvalidation 15-58: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-59: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 15-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-63: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 15-64: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 15-65: Loss: 0.4857 Acc: 75.0000%\n",
      "\tvalidation 15-66: Loss: 1.3665 Acc: 75.0000%\n",
      "\tvalidation 15-67: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 15-68: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 15-69: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 15-70: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 15-71: Loss: 0.1394 Acc: 75.0000%\n",
      "\tvalidation 15-72: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 15-73: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 15-74: Loss: 4.9252 Acc: 50.0000%\n",
      "\tvalidation 15-75: Loss: 0.0005 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 15-76: Loss: 1.7664 Acc: 50.0000%\n",
      "\tvalidation 15-77: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 15-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-79: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 15-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 15-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-84: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 15-85: Loss: 0.6087 Acc: 50.0000%\n",
      "\tvalidation 15-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-87: Loss: 1.8311 Acc: 75.0000%\n",
      "\tvalidation 15-88: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 15-89: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 15-90: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-93: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 15-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-95: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 15-96: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 15-97: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 15-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 15-99: Loss: 0.4429 Acc: 75.0000%\n",
      "\tvalidation 15-100: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 15-101: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-102: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-103: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 15-104: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 15-105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0993 Acc: 85.1020%\n",
      "\tvalidation Loss: 0.3365 Acc: 92.6190%\n",
      "Time passed 0h 13m 28s\n",
      "--------------------\n",
      "Epoch [16/40]:\n",
      "\ttrain 16-1: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 16-2: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 16-3: Loss: 0.2418 Acc: 50.0000%\n",
      "\ttrain 16-4: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 16-5: Loss: 0.0677 Acc: 75.0000%\n",
      "\ttrain 16-6: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 16-7: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 16-8: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 16-9: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 16-10: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 16-11: Loss: 0.5858 Acc: 25.0000%\n",
      "\ttrain 16-12: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 16-13: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 16-14: Loss: 0.1832 Acc: 75.0000%\n",
      "\ttrain 16-15: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 16-16: Loss: 0.3341 Acc: 75.0000%\n",
      "\ttrain 16-17: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 16-18: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 16-19: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 16-20: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 16-21: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 16-22: Loss: 0.4766 Acc: 75.0000%\n",
      "\ttrain 16-23: Loss: 0.3152 Acc: 75.0000%\n",
      "\ttrain 16-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 16-25: Loss: 0.2175 Acc: 50.0000%\n",
      "\ttrain 16-26: Loss: 0.2075 Acc: 75.0000%\n",
      "\ttrain 16-27: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 16-28: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 16-29: Loss: 0.0672 Acc: 100.0000%\n",
      "\ttrain 16-30: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 16-31: Loss: 0.4938 Acc: 25.0000%\n",
      "\ttrain 16-32: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 16-33: Loss: 0.1775 Acc: 75.0000%\n",
      "\ttrain 16-34: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 16-35: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 16-36: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 16-37: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 16-38: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 16-39: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 16-40: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 16-41: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 16-42: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 16-43: Loss: 0.2068 Acc: 75.0000%\n",
      "\ttrain 16-44: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 16-45: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 16-46: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 16-47: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 16-48: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 16-49: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 16-50: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 16-51: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 16-52: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 16-53: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 16-54: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 16-55: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 16-56: Loss: 0.3624 Acc: 50.0000%\n",
      "\ttrain 16-57: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 16-58: Loss: 0.3954 Acc: 50.0000%\n",
      "\ttrain 16-59: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 16-60: Loss: 0.3493 Acc: 75.0000%\n",
      "\ttrain 16-61: Loss: 0.4135 Acc: 25.0000%\n",
      "\ttrain 16-62: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 16-63: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 16-64: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 16-65: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 16-66: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 16-67: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 16-68: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 16-69: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 16-70: Loss: 0.2522 Acc: 50.0000%\n",
      "\ttrain 16-71: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 16-72: Loss: 0.4129 Acc: 75.0000%\n",
      "\ttrain 16-73: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 16-74: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 16-75: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 16-76: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 16-77: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 16-78: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 16-79: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 16-80: Loss: 0.1630 Acc: 50.0000%\n",
      "\ttrain 16-81: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 16-82: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 16-83: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 16-84: Loss: 0.1557 Acc: 75.0000%\n",
      "\ttrain 16-85: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 16-86: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 16-87: Loss: 0.1971 Acc: 75.0000%\n",
      "\ttrain 16-88: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 16-89: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 16-90: Loss: 0.3354 Acc: 50.0000%\n",
      "\ttrain 16-91: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 16-92: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 16-93: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 16-94: Loss: 0.0488 Acc: 75.0000%\n",
      "\ttrain 16-95: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 16-96: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 16-97: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 16-98: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 16-99: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 16-100: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 16-101: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 16-102: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 16-103: Loss: 0.5396 Acc: 75.0000%\n",
      "\ttrain 16-104: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 16-105: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 16-106: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 16-107: Loss: 0.3555 Acc: 50.0000%\n",
      "\ttrain 16-108: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 16-109: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 16-110: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 16-111: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 16-112: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 16-113: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 16-114: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 16-115: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 16-116: Loss: 0.1992 Acc: 75.0000%\n",
      "\ttrain 16-117: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 16-118: Loss: 0.0829 Acc: 100.0000%\n",
      "\ttrain 16-119: Loss: 0.1608 Acc: 50.0000%\n",
      "\ttrain 16-120: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 16-121: Loss: 0.2470 Acc: 50.0000%\n",
      "\ttrain 16-122: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 16-123: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 16-124: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 16-125: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 16-126: Loss: 0.2026 Acc: 75.0000%\n",
      "\ttrain 16-127: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 16-128: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 16-129: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 16-130: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 16-131: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 16-132: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 16-133: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 16-134: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 16-135: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 16-136: Loss: 0.0780 Acc: 75.0000%\n",
      "\ttrain 16-137: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 16-138: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 16-139: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 16-140: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 16-141: Loss: 0.1707 Acc: 50.0000%\n",
      "\ttrain 16-142: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 16-143: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 16-144: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 16-145: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 16-146: Loss: 0.2147 Acc: 75.0000%\n",
      "\ttrain 16-147: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 16-148: Loss: 0.1401 Acc: 75.0000%\n",
      "\ttrain 16-149: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 16-150: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 16-151: Loss: 0.1599 Acc: 75.0000%\n",
      "\ttrain 16-152: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 16-153: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 16-154: Loss: 0.3327 Acc: 25.0000%\n",
      "\ttrain 16-155: Loss: 0.4844 Acc: 0.0000%\n",
      "\ttrain 16-156: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 16-157: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 16-158: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 16-159: Loss: 0.1265 Acc: 50.0000%\n",
      "\ttrain 16-160: Loss: 0.0548 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 16-161: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 16-162: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 16-163: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 16-164: Loss: 0.4629 Acc: 50.0000%\n",
      "\ttrain 16-165: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 16-166: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 16-167: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 16-168: Loss: 0.2281 Acc: 75.0000%\n",
      "\ttrain 16-169: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 16-170: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 16-171: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 16-172: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 16-173: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 16-174: Loss: 0.2726 Acc: 75.0000%\n",
      "\ttrain 16-175: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 16-176: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 16-177: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 16-178: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 16-179: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 16-180: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 16-181: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 16-182: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 16-183: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 16-184: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 16-185: Loss: 0.4039 Acc: 50.0000%\n",
      "\ttrain 16-186: Loss: 0.1591 Acc: 75.0000%\n",
      "\ttrain 16-187: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 16-188: Loss: 0.3071 Acc: 50.0000%\n",
      "\ttrain 16-189: Loss: 0.2660 Acc: 75.0000%\n",
      "\ttrain 16-190: Loss: 0.3524 Acc: 50.0000%\n",
      "\ttrain 16-191: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 16-192: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 16-193: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 16-194: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 16-195: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 16-196: Loss: 0.3718 Acc: 75.0000%\n",
      "\ttrain 16-197: Loss: 0.3357 Acc: 75.0000%\n",
      "\ttrain 16-198: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 16-199: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 16-200: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 16-201: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 16-202: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 16-203: Loss: 0.9632 Acc: 25.0000%\n",
      "\ttrain 16-204: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 16-205: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 16-206: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 16-207: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 16-208: Loss: 0.0708 Acc: 75.0000%\n",
      "\ttrain 16-209: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 16-210: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 16-211: Loss: 0.0607 Acc: 75.0000%\n",
      "\ttrain 16-212: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 16-213: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 16-214: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 16-215: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 16-216: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 16-217: Loss: 0.3242 Acc: 50.0000%\n",
      "\ttrain 16-218: Loss: 0.0686 Acc: 100.0000%\n",
      "\ttrain 16-219: Loss: 0.2067 Acc: 50.0000%\n",
      "\ttrain 16-220: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 16-221: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 16-222: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 16-223: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 16-224: Loss: 0.0794 Acc: 100.0000%\n",
      "\ttrain 16-225: Loss: 0.3352 Acc: 50.0000%\n",
      "\ttrain 16-226: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 16-227: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 16-228: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 16-229: Loss: 0.3018 Acc: 25.0000%\n",
      "\ttrain 16-230: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 16-231: Loss: 0.1973 Acc: 50.0000%\n",
      "\ttrain 16-232: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 16-233: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 16-234: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 16-235: Loss: 0.1049 Acc: 75.0000%\n",
      "\ttrain 16-236: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 16-237: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 16-238: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 16-239: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 16-240: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 16-241: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 16-242: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 16-243: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 16-244: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 16-245: Loss: 0.1121 Acc: 75.0000%\n",
      "\tvalidation 16-1: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 16-2: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 16-3: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 16-4: Loss: 0.0735 Acc: 75.0000%\n",
      "\tvalidation 16-5: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 16-6: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 16-7: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-8: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 16-9: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 16-10: Loss: 0.8764 Acc: 75.0000%\n",
      "\tvalidation 16-11: Loss: 0.4733 Acc: 75.0000%\n",
      "\tvalidation 16-12: Loss: 0.0951 Acc: 75.0000%\n",
      "\tvalidation 16-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-14: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 16-15: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 16-16: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-17: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 16-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-19: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 16-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-21: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 16-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-23: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-24: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 16-25: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 16-26: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 16-27: Loss: 0.0621 Acc: 75.0000%\n",
      "\tvalidation 16-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-29: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 16-30: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 16-31: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 16-32: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 16-33: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 16-34: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 16-35: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 16-36: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 16-37: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 16-38: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 16-39: Loss: 0.9482 Acc: 75.0000%\n",
      "\tvalidation 16-40: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-41: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 16-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-43: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 16-44: Loss: 0.9111 Acc: 75.0000%\n",
      "\tvalidation 16-45: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-46: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 16-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-48: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 16-49: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 16-50: Loss: 0.7548 Acc: 75.0000%\n",
      "\tvalidation 16-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 16-52: Loss: 0.2795 Acc: 75.0000%\n",
      "\tvalidation 16-53: Loss: 1.0539 Acc: 50.0000%\n",
      "\tvalidation 16-54: Loss: 0.4948 Acc: 75.0000%\n",
      "\tvalidation 16-55: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 16-56: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 16-57: Loss: 0.0517 Acc: 100.0000%\n",
      "\tvalidation 16-58: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 16-59: Loss: 0.8514 Acc: 75.0000%\n",
      "\tvalidation 16-60: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 16-61: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-62: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-63: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-64: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 16-65: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-66: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 16-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-68: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 16-69: Loss: 0.4425 Acc: 75.0000%\n",
      "\tvalidation 16-70: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 16-71: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-72: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-73: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 16-74: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-76: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 16-77: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-78: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 16-79: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 16-80: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 16-81: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-82: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 16-83: Loss: 1.4939 Acc: 75.0000%\n",
      "\tvalidation 16-84: Loss: 0.2511 Acc: 75.0000%\n",
      "\tvalidation 16-85: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 16-86: Loss: 0.0632 Acc: 75.0000%\n",
      "\tvalidation 16-87: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-88: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 16-89: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 16-90: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 16-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-93: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-94: Loss: 1.6025 Acc: 75.0000%\n",
      "\tvalidation 16-95: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-96: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 16-97: Loss: 0.3705 Acc: 75.0000%\n",
      "\tvalidation 16-98: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 16-99: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-100: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 16-101: Loss: 0.0673 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 16-102: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 16-103: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 16-104: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 16-105: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0978 Acc: 85.5102%\n",
      "\tvalidation Loss: 0.1111 Acc: 95.2381%\n",
      "Time passed 0h 14m 17s\n",
      "--------------------\n",
      "Epoch [17/40]:\n",
      "\ttrain 17-1: Loss: 1.0470 Acc: 0.0000%\n",
      "\ttrain 17-2: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 17-3: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 17-4: Loss: 0.0613 Acc: 100.0000%\n",
      "\ttrain 17-5: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 17-6: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 17-7: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 17-8: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 17-9: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 17-10: Loss: 0.1722 Acc: 50.0000%\n",
      "\ttrain 17-11: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 17-12: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 17-13: Loss: 0.0870 Acc: 100.0000%\n",
      "\ttrain 17-14: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 17-15: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 17-16: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 17-17: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 17-18: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 17-19: Loss: 0.2645 Acc: 75.0000%\n",
      "\ttrain 17-20: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 17-21: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 17-22: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 17-23: Loss: 0.1580 Acc: 75.0000%\n",
      "\ttrain 17-24: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 17-25: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 17-26: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 17-27: Loss: 0.2901 Acc: 25.0000%\n",
      "\ttrain 17-28: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 17-29: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 17-30: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 17-31: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 17-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-33: Loss: 0.3749 Acc: 50.0000%\n",
      "\ttrain 17-34: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 17-35: Loss: 0.0488 Acc: 75.0000%\n",
      "\ttrain 17-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 17-37: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 17-38: Loss: 0.5998 Acc: 50.0000%\n",
      "\ttrain 17-39: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 17-40: Loss: 0.1665 Acc: 75.0000%\n",
      "\ttrain 17-41: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 17-42: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 17-43: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 17-44: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 17-45: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 17-46: Loss: 0.2403 Acc: 75.0000%\n",
      "\ttrain 17-47: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 17-48: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 17-49: Loss: 0.0709 Acc: 100.0000%\n",
      "\ttrain 17-50: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 17-51: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 17-52: Loss: 0.5160 Acc: 75.0000%\n",
      "\ttrain 17-53: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 17-54: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 17-55: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 17-56: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 17-57: Loss: 0.2231 Acc: 50.0000%\n",
      "\ttrain 17-58: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 17-59: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 17-60: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 17-61: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 17-62: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 17-63: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 17-64: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 17-65: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 17-66: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 17-67: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 17-68: Loss: 0.3051 Acc: 50.0000%\n",
      "\ttrain 17-69: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 17-70: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 17-71: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 17-72: Loss: 0.4185 Acc: 75.0000%\n",
      "\ttrain 17-73: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 17-74: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 17-75: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 17-76: Loss: 0.2415 Acc: 50.0000%\n",
      "\ttrain 17-77: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 17-78: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 17-79: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 17-80: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 17-81: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 17-82: Loss: 0.6325 Acc: 50.0000%\n",
      "\ttrain 17-83: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 17-84: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 17-85: Loss: 0.1582 Acc: 75.0000%\n",
      "\ttrain 17-86: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 17-87: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 17-88: Loss: 0.3747 Acc: 75.0000%\n",
      "\ttrain 17-89: Loss: 0.5182 Acc: 25.0000%\n",
      "\ttrain 17-90: Loss: 0.1932 Acc: 75.0000%\n",
      "\ttrain 17-91: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 17-92: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 17-93: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 17-94: Loss: 0.1890 Acc: 75.0000%\n",
      "\ttrain 17-95: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 17-96: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 17-97: Loss: 0.3456 Acc: 0.0000%\n",
      "\ttrain 17-98: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 17-99: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 17-100: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 17-101: Loss: 0.1718 Acc: 50.0000%\n",
      "\ttrain 17-102: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 17-103: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 17-104: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 17-105: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 17-106: Loss: 0.4538 Acc: 50.0000%\n",
      "\ttrain 17-107: Loss: 0.1321 Acc: 50.0000%\n",
      "\ttrain 17-108: Loss: 0.9213 Acc: 0.0000%\n",
      "\ttrain 17-109: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 17-110: Loss: 0.0847 Acc: 75.0000%\n",
      "\ttrain 17-111: Loss: 0.5416 Acc: 50.0000%\n",
      "\ttrain 17-112: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 17-113: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 17-114: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 17-115: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 17-116: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 17-117: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 17-118: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 17-119: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 17-120: Loss: 0.2124 Acc: 75.0000%\n",
      "\ttrain 17-121: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 17-122: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 17-123: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 17-124: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 17-125: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 17-126: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 17-127: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 17-128: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 17-129: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 17-130: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 17-131: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 17-132: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 17-133: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 17-134: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 17-135: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 17-136: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 17-137: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 17-138: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 17-139: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 17-140: Loss: 0.2798 Acc: 50.0000%\n",
      "\ttrain 17-141: Loss: 0.4961 Acc: 25.0000%\n",
      "\ttrain 17-142: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 17-143: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 17-144: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 17-145: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 17-146: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 17-147: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 17-148: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 17-149: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 17-150: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 17-151: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 17-152: Loss: 0.2635 Acc: 50.0000%\n",
      "\ttrain 17-153: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 17-154: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 17-155: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 17-156: Loss: 0.0562 Acc: 75.0000%\n",
      "\ttrain 17-157: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 17-158: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 17-159: Loss: 0.3168 Acc: 75.0000%\n",
      "\ttrain 17-160: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 17-161: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 17-162: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 17-163: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 17-164: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 17-165: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 17-166: Loss: 0.1621 Acc: 75.0000%\n",
      "\ttrain 17-167: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 17-168: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 17-169: Loss: 0.3114 Acc: 50.0000%\n",
      "\ttrain 17-170: Loss: 0.2888 Acc: 75.0000%\n",
      "\ttrain 17-171: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 17-172: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 17-173: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 17-174: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 17-175: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 17-176: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 17-177: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 17-178: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 17-179: Loss: 0.1146 Acc: 50.0000%\n",
      "\ttrain 17-180: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 17-181: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 17-182: Loss: 0.1697 Acc: 50.0000%\n",
      "\ttrain 17-183: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 17-184: Loss: 0.4959 Acc: 50.0000%\n",
      "\ttrain 17-185: Loss: 0.1944 Acc: 75.0000%\n",
      "\ttrain 17-186: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 17-187: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 17-188: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 17-189: Loss: 0.0448 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-190: Loss: 0.1950 Acc: 50.0000%\n",
      "\ttrain 17-191: Loss: 0.2419 Acc: 75.0000%\n",
      "\ttrain 17-192: Loss: 0.1583 Acc: 75.0000%\n",
      "\ttrain 17-193: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 17-194: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 17-195: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 17-196: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 17-197: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 17-198: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 17-199: Loss: 0.1459 Acc: 75.0000%\n",
      "\ttrain 17-200: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 17-201: Loss: 0.3090 Acc: 75.0000%\n",
      "\ttrain 17-202: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 17-203: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 17-204: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 17-205: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 17-206: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 17-207: Loss: 0.1934 Acc: 50.0000%\n",
      "\ttrain 17-208: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 17-209: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 17-210: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 17-211: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 17-212: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 17-213: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 17-214: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 17-215: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 17-216: Loss: 0.1696 Acc: 75.0000%\n",
      "\ttrain 17-217: Loss: 0.4332 Acc: 50.0000%\n",
      "\ttrain 17-218: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 17-219: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 17-220: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 17-221: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 17-222: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 17-223: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 17-224: Loss: 0.6048 Acc: 50.0000%\n",
      "\ttrain 17-225: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 17-226: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 17-227: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 17-228: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 17-229: Loss: 0.2752 Acc: 50.0000%\n",
      "\ttrain 17-230: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 17-231: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 17-232: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 17-233: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 17-234: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 17-235: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 17-236: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 17-237: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 17-238: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 17-239: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 17-240: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 17-241: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 17-242: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 17-243: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 17-244: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 17-245: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 17-1: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-3: Loss: 0.0532 Acc: 100.0000%\n",
      "\tvalidation 17-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-5: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 17-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-7: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 17-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-9: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 17-10: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 17-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-12: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 17-13: Loss: 1.5195 Acc: 50.0000%\n",
      "\tvalidation 17-14: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 17-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-17: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 17-18: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-19: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 17-20: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 17-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-22: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 17-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-24: Loss: 1.2529 Acc: 75.0000%\n",
      "\tvalidation 17-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-26: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 17-27: Loss: 0.0459 Acc: 100.0000%\n",
      "\tvalidation 17-28: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 17-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-30: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 17-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 17-33: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-34: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 17-35: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 17-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-37: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 17-38: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-39: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 17-40: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 17-41: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 17-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-43: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 17-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-45: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 17-47: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 17-48: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 17-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-50: Loss: 0.0800 Acc: 75.0000%\n",
      "\tvalidation 17-51: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 17-52: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 17-53: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 17-54: Loss: 0.4296 Acc: 75.0000%\n",
      "\tvalidation 17-55: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 17-56: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 17-57: Loss: 0.1957 Acc: 75.0000%\n",
      "\tvalidation 17-58: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-59: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 17-60: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 17-61: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-62: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-63: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 17-64: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 17-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-66: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 17-67: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 17-68: Loss: 0.4611 Acc: 50.0000%\n",
      "\tvalidation 17-69: Loss: 0.1573 Acc: 75.0000%\n",
      "\tvalidation 17-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 17-72: Loss: 0.0277 Acc: 100.0000%\n",
      "\tvalidation 17-73: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 17-74: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 17-75: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-76: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 17-77: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-78: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-79: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-80: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-81: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-82: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-83: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-84: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 17-85: Loss: 1.3736 Acc: 75.0000%\n",
      "\tvalidation 17-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-87: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 17-88: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-89: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 17-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-91: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 17-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-93: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-94: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 17-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-96: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 17-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-98: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 17-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-100: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 17-101: Loss: 0.2381 Acc: 75.0000%\n",
      "\tvalidation 17-102: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 17-103: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 17-104: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 17-105: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0969 Acc: 86.6327%\n",
      "\tvalidation Loss: 0.0599 Acc: 97.3810%\n",
      "网络参数更新\n",
      "Time passed 0h 15m 9s\n",
      "--------------------\n",
      "Epoch [18/40]:\n",
      "\ttrain 18-1: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 18-2: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 18-3: Loss: 0.6987 Acc: 25.0000%\n",
      "\ttrain 18-4: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 18-5: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 18-6: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 18-7: Loss: 0.2339 Acc: 75.0000%\n",
      "\ttrain 18-8: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 18-9: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 18-10: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 18-11: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 18-12: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 18-13: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 18-14: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 18-15: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 18-16: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 18-17: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 18-18: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 18-19: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 18-20: Loss: 0.1626 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-21: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 18-22: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 18-23: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 18-24: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 18-25: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 18-26: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 18-27: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 18-28: Loss: 0.1943 Acc: 50.0000%\n",
      "\ttrain 18-29: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 18-30: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-31: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 18-32: Loss: 0.4596 Acc: 50.0000%\n",
      "\ttrain 18-33: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 18-34: Loss: 0.2015 Acc: 75.0000%\n",
      "\ttrain 18-35: Loss: 0.2792 Acc: 50.0000%\n",
      "\ttrain 18-36: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 18-37: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 18-38: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 18-39: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 18-40: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 18-41: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 18-42: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 18-43: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 18-44: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 18-45: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-46: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 18-47: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 18-48: Loss: 0.0813 Acc: 100.0000%\n",
      "\ttrain 18-49: Loss: 0.3529 Acc: 50.0000%\n",
      "\ttrain 18-50: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 18-51: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 18-52: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 18-53: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 18-54: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 18-55: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 18-56: Loss: 0.1748 Acc: 50.0000%\n",
      "\ttrain 18-57: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 18-58: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 18-59: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 18-60: Loss: 0.4188 Acc: 50.0000%\n",
      "\ttrain 18-61: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 18-62: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 18-63: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 18-64: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 18-65: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 18-66: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 18-67: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 18-68: Loss: 0.4836 Acc: 75.0000%\n",
      "\ttrain 18-69: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 18-70: Loss: 0.9405 Acc: 50.0000%\n",
      "\ttrain 18-71: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 18-72: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 18-73: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 18-74: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 18-75: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 18-76: Loss: 0.8504 Acc: 25.0000%\n",
      "\ttrain 18-77: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 18-78: Loss: 0.4582 Acc: 50.0000%\n",
      "\ttrain 18-79: Loss: 0.1968 Acc: 75.0000%\n",
      "\ttrain 18-80: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 18-81: Loss: 0.4253 Acc: 50.0000%\n",
      "\ttrain 18-82: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 18-83: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 18-84: Loss: 0.2372 Acc: 50.0000%\n",
      "\ttrain 18-85: Loss: 0.2733 Acc: 75.0000%\n",
      "\ttrain 18-86: Loss: 0.1604 Acc: 75.0000%\n",
      "\ttrain 18-87: Loss: 0.2013 Acc: 50.0000%\n",
      "\ttrain 18-88: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 18-89: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 18-90: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 18-91: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 18-92: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 18-93: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 18-94: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 18-95: Loss: 0.1045 Acc: 75.0000%\n",
      "\ttrain 18-96: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 18-97: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 18-98: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 18-99: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 18-100: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 18-101: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 18-102: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 18-103: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 18-104: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 18-105: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 18-106: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 18-107: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 18-108: Loss: 0.0707 Acc: 75.0000%\n",
      "\ttrain 18-109: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 18-110: Loss: 0.3585 Acc: 50.0000%\n",
      "\ttrain 18-111: Loss: 0.3489 Acc: 75.0000%\n",
      "\ttrain 18-112: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 18-113: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 18-114: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 18-115: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 18-116: Loss: 0.1998 Acc: 75.0000%\n",
      "\ttrain 18-117: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 18-118: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 18-119: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 18-120: Loss: 0.1513 Acc: 75.0000%\n",
      "\ttrain 18-121: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 18-122: Loss: 0.2022 Acc: 75.0000%\n",
      "\ttrain 18-123: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 18-124: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 18-125: Loss: 0.1957 Acc: 75.0000%\n",
      "\ttrain 18-126: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 18-127: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 18-128: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 18-129: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 18-130: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 18-131: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 18-132: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 18-133: Loss: 0.0735 Acc: 100.0000%\n",
      "\ttrain 18-134: Loss: 0.0961 Acc: 100.0000%\n",
      "\ttrain 18-135: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 18-136: Loss: 0.1511 Acc: 50.0000%\n",
      "\ttrain 18-137: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 18-138: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 18-139: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-140: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 18-141: Loss: 0.2111 Acc: 75.0000%\n",
      "\ttrain 18-142: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 18-143: Loss: 0.2644 Acc: 50.0000%\n",
      "\ttrain 18-144: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 18-145: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 18-146: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-147: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 18-148: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 18-149: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 18-150: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 18-151: Loss: 0.2318 Acc: 50.0000%\n",
      "\ttrain 18-152: Loss: 0.3286 Acc: 50.0000%\n",
      "\ttrain 18-153: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 18-154: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 18-155: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 18-156: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 18-157: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 18-158: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 18-159: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 18-160: Loss: 0.3127 Acc: 50.0000%\n",
      "\ttrain 18-161: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 18-162: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 18-163: Loss: 0.1376 Acc: 75.0000%\n",
      "\ttrain 18-164: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 18-165: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-166: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 18-167: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 18-168: Loss: 0.2334 Acc: 75.0000%\n",
      "\ttrain 18-169: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 18-170: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 18-171: Loss: 0.3399 Acc: 50.0000%\n",
      "\ttrain 18-172: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 18-173: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 18-174: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 18-175: Loss: 0.1747 Acc: 50.0000%\n",
      "\ttrain 18-176: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 18-177: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 18-178: Loss: 0.2295 Acc: 50.0000%\n",
      "\ttrain 18-179: Loss: 0.1459 Acc: 75.0000%\n",
      "\ttrain 18-180: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 18-181: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 18-182: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 18-183: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 18-184: Loss: 0.2626 Acc: 50.0000%\n",
      "\ttrain 18-185: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 18-186: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 18-187: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 18-188: Loss: 0.3059 Acc: 75.0000%\n",
      "\ttrain 18-189: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-190: Loss: 0.3375 Acc: 50.0000%\n",
      "\ttrain 18-191: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 18-192: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 18-193: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 18-194: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 18-195: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 18-196: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-197: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 18-198: Loss: 0.2787 Acc: 25.0000%\n",
      "\ttrain 18-199: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 18-200: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 18-201: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 18-202: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 18-203: Loss: 0.1565 Acc: 75.0000%\n",
      "\ttrain 18-204: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 18-205: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 18-206: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 18-207: Loss: 0.4255 Acc: 25.0000%\n",
      "\ttrain 18-208: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 18-209: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 18-210: Loss: 0.5777 Acc: 50.0000%\n",
      "\ttrain 18-211: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 18-212: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 18-213: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 18-214: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 18-215: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 18-216: Loss: 0.0014 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-217: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 18-218: Loss: 0.2298 Acc: 50.0000%\n",
      "\ttrain 18-219: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 18-220: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 18-221: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 18-222: Loss: 0.3637 Acc: 75.0000%\n",
      "\ttrain 18-223: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 18-224: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 18-225: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 18-226: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 18-227: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 18-228: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 18-229: Loss: 0.2704 Acc: 75.0000%\n",
      "\ttrain 18-230: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 18-231: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 18-232: Loss: 0.3133 Acc: 50.0000%\n",
      "\ttrain 18-233: Loss: 0.2118 Acc: 75.0000%\n",
      "\ttrain 18-234: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 18-235: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 18-236: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 18-237: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 18-238: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 18-239: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 18-240: Loss: 0.1850 Acc: 50.0000%\n",
      "\ttrain 18-241: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 18-242: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 18-243: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 18-244: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 18-245: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 18-1: Loss: 0.1174 Acc: 75.0000%\n",
      "\tvalidation 18-2: Loss: 0.0645 Acc: 75.0000%\n",
      "\tvalidation 18-3: Loss: 0.3242 Acc: 75.0000%\n",
      "\tvalidation 18-4: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 18-5: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 18-6: Loss: 0.0672 Acc: 75.0000%\n",
      "\tvalidation 18-7: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 18-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-9: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 18-10: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 18-11: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 18-12: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 18-13: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 18-14: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 18-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-16: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 18-17: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 18-18: Loss: 0.1670 Acc: 75.0000%\n",
      "\tvalidation 18-19: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-20: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 18-21: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 18-22: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 18-23: Loss: 0.2635 Acc: 75.0000%\n",
      "\tvalidation 18-24: Loss: 0.2133 Acc: 50.0000%\n",
      "\tvalidation 18-25: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 18-26: Loss: 0.4894 Acc: 75.0000%\n",
      "\tvalidation 18-27: Loss: 0.0585 Acc: 75.0000%\n",
      "\tvalidation 18-28: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 18-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-30: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 18-31: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 18-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-33: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 18-34: Loss: 0.3566 Acc: 50.0000%\n",
      "\tvalidation 18-35: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 18-36: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 18-37: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-38: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 18-39: Loss: 0.0591 Acc: 75.0000%\n",
      "\tvalidation 18-40: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 18-41: Loss: 0.9241 Acc: 75.0000%\n",
      "\tvalidation 18-42: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 18-43: Loss: 0.9197 Acc: 75.0000%\n",
      "\tvalidation 18-44: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 18-45: Loss: 0.3268 Acc: 75.0000%\n",
      "\tvalidation 18-46: Loss: 0.0658 Acc: 100.0000%\n",
      "\tvalidation 18-47: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 18-48: Loss: 0.1726 Acc: 75.0000%\n",
      "\tvalidation 18-49: Loss: 0.1331 Acc: 75.0000%\n",
      "\tvalidation 18-50: Loss: 3.0017 Acc: 75.0000%\n",
      "\tvalidation 18-51: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 18-52: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 18-53: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 18-54: Loss: 0.9722 Acc: 75.0000%\n",
      "\tvalidation 18-55: Loss: 0.1417 Acc: 75.0000%\n",
      "\tvalidation 18-56: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-57: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 18-58: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 18-59: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 18-60: Loss: 0.0853 Acc: 75.0000%\n",
      "\tvalidation 18-61: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 18-62: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 18-63: Loss: 0.1123 Acc: 75.0000%\n",
      "\tvalidation 18-64: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-65: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 18-66: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-67: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 18-68: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 18-69: Loss: 0.5496 Acc: 50.0000%\n",
      "\tvalidation 18-70: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 18-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-72: Loss: 2.6014 Acc: 75.0000%\n",
      "\tvalidation 18-73: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 18-74: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 18-75: Loss: 0.9437 Acc: 75.0000%\n",
      "\tvalidation 18-76: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 18-77: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 18-78: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 18-79: Loss: 1.2752 Acc: 75.0000%\n",
      "\tvalidation 18-80: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 18-81: Loss: 0.5799 Acc: 75.0000%\n",
      "\tvalidation 18-82: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 18-83: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 18-84: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-85: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-86: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 18-87: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 18-88: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 18-89: Loss: 0.0733 Acc: 75.0000%\n",
      "\tvalidation 18-90: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-91: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 18-92: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-93: Loss: 0.4172 Acc: 50.0000%\n",
      "\tvalidation 18-94: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 18-95: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 18-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-97: Loss: 0.6000 Acc: 75.0000%\n",
      "\tvalidation 18-98: Loss: 0.0812 Acc: 75.0000%\n",
      "\tvalidation 18-99: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 18-100: Loss: 1.8791 Acc: 75.0000%\n",
      "\tvalidation 18-101: Loss: 0.5688 Acc: 75.0000%\n",
      "\tvalidation 18-102: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-103: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 18-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-105: Loss: 0.7388 Acc: 50.0000%\n",
      "\ttrain Loss: 0.0970 Acc: 86.6327%\n",
      "\tvalidation Loss: 0.1917 Acc: 90.4762%\n",
      "Time passed 0h 16m 0s\n",
      "--------------------\n",
      "Epoch [19/40]:\n",
      "\ttrain 19-1: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 19-2: Loss: 0.3641 Acc: 50.0000%\n",
      "\ttrain 19-3: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 19-4: Loss: 0.0655 Acc: 100.0000%\n",
      "\ttrain 19-5: Loss: 0.3629 Acc: 75.0000%\n",
      "\ttrain 19-6: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 19-7: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 19-8: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 19-9: Loss: 0.1633 Acc: 75.0000%\n",
      "\ttrain 19-10: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 19-11: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 19-12: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 19-13: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 19-14: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 19-15: Loss: 0.1369 Acc: 75.0000%\n",
      "\ttrain 19-16: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 19-17: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 19-18: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 19-19: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 19-20: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 19-21: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 19-22: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 19-23: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 19-24: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 19-25: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 19-26: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 19-27: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 19-28: Loss: 0.2105 Acc: 75.0000%\n",
      "\ttrain 19-29: Loss: 0.0825 Acc: 75.0000%\n",
      "\ttrain 19-30: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 19-31: Loss: 0.6317 Acc: 50.0000%\n",
      "\ttrain 19-32: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 19-33: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 19-34: Loss: 0.4651 Acc: 50.0000%\n",
      "\ttrain 19-35: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 19-36: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 19-37: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 19-38: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 19-39: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 19-40: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 19-41: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 19-42: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 19-43: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 19-44: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 19-45: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 19-46: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 19-47: Loss: 0.1141 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-48: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 19-49: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 19-50: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 19-51: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 19-52: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 19-53: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 19-54: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 19-55: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 19-56: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 19-57: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 19-58: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 19-59: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 19-60: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-61: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 19-62: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 19-63: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 19-64: Loss: 0.2037 Acc: 75.0000%\n",
      "\ttrain 19-65: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 19-66: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 19-67: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 19-68: Loss: 0.3096 Acc: 50.0000%\n",
      "\ttrain 19-69: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 19-70: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 19-71: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 19-72: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 19-73: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 19-74: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 19-75: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 19-76: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 19-77: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 19-78: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 19-79: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 19-80: Loss: 0.1923 Acc: 75.0000%\n",
      "\ttrain 19-81: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 19-82: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 19-83: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 19-84: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 19-85: Loss: 0.3607 Acc: 50.0000%\n",
      "\ttrain 19-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-87: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 19-88: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 19-89: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 19-90: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 19-91: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 19-92: Loss: 0.2988 Acc: 50.0000%\n",
      "\ttrain 19-93: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 19-94: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 19-95: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 19-96: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 19-97: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-98: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 19-99: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 19-100: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 19-101: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 19-102: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 19-103: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 19-104: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 19-105: Loss: 0.2137 Acc: 50.0000%\n",
      "\ttrain 19-106: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 19-107: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 19-108: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 19-109: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 19-110: Loss: 0.1852 Acc: 50.0000%\n",
      "\ttrain 19-111: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 19-112: Loss: 0.1569 Acc: 50.0000%\n",
      "\ttrain 19-113: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 19-114: Loss: 0.2089 Acc: 75.0000%\n",
      "\ttrain 19-115: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 19-116: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 19-117: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 19-118: Loss: 0.1565 Acc: 75.0000%\n",
      "\ttrain 19-119: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 19-120: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 19-121: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 19-122: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-123: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 19-124: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-125: Loss: 0.3099 Acc: 75.0000%\n",
      "\ttrain 19-126: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 19-127: Loss: 0.4285 Acc: 75.0000%\n",
      "\ttrain 19-128: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 19-129: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 19-130: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 19-131: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 19-132: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 19-133: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 19-134: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 19-135: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 19-136: Loss: 0.6600 Acc: 25.0000%\n",
      "\ttrain 19-137: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 19-138: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 19-139: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 19-140: Loss: 0.1897 Acc: 75.0000%\n",
      "\ttrain 19-141: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 19-142: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 19-143: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 19-144: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 19-145: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 19-146: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 19-147: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 19-148: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 19-149: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 19-150: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 19-151: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 19-152: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 19-153: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 19-154: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 19-155: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 19-156: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 19-157: Loss: 0.2721 Acc: 75.0000%\n",
      "\ttrain 19-158: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 19-159: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 19-160: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 19-161: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 19-162: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 19-163: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 19-164: Loss: 0.1426 Acc: 75.0000%\n",
      "\ttrain 19-165: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 19-166: Loss: 0.3601 Acc: 50.0000%\n",
      "\ttrain 19-167: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 19-168: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 19-169: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 19-170: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 19-171: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 19-172: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 19-173: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 19-174: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 19-175: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 19-176: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 19-177: Loss: 0.1702 Acc: 50.0000%\n",
      "\ttrain 19-178: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 19-179: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 19-180: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 19-181: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 19-182: Loss: 0.2923 Acc: 50.0000%\n",
      "\ttrain 19-183: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 19-184: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 19-185: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 19-186: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 19-187: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 19-188: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 19-189: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 19-190: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 19-191: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 19-192: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 19-193: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 19-194: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 19-195: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 19-196: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 19-197: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 19-198: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 19-199: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 19-200: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 19-201: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 19-202: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 19-203: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 19-204: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 19-205: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 19-206: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 19-207: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 19-208: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 19-209: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 19-210: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 19-211: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 19-212: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 19-213: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 19-214: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 19-215: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 19-216: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 19-217: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 19-218: Loss: 0.1950 Acc: 75.0000%\n",
      "\ttrain 19-219: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 19-220: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 19-221: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 19-222: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 19-223: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 19-224: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 19-225: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 19-226: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 19-227: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 19-228: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 19-229: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 19-230: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 19-231: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 19-232: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 19-233: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 19-234: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 19-235: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 19-236: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 19-237: Loss: 0.0776 Acc: 75.0000%\n",
      "\ttrain 19-238: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 19-239: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 19-240: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 19-241: Loss: 0.0836 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-242: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-243: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 19-244: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 19-245: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 19-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-4: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 19-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-6: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-7: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 19-8: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 19-9: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-10: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 19-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-13: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-14: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-15: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-17: Loss: 1.4091 Acc: 75.0000%\n",
      "\tvalidation 19-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-19: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 19-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-21: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 19-22: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 19-23: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-24: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 19-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-26: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 19-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-29: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-30: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 19-31: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 19-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-33: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 19-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-35: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 19-36: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-37: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 19-38: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 19-39: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 19-40: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 19-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-43: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 19-44: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 19-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-46: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 19-47: Loss: 0.3102 Acc: 75.0000%\n",
      "\tvalidation 19-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-49: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-52: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 19-53: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 19-54: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-55: Loss: 0.3842 Acc: 75.0000%\n",
      "\tvalidation 19-56: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 19-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-59: Loss: 0.4729 Acc: 75.0000%\n",
      "\tvalidation 19-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-64: Loss: 0.2010 Acc: 75.0000%\n",
      "\tvalidation 19-65: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 19-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-67: Loss: 0.1137 Acc: 75.0000%\n",
      "\tvalidation 19-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-71: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 19-72: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 19-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-74: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-75: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-76: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 19-77: Loss: 1.7179 Acc: 75.0000%\n",
      "\tvalidation 19-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-80: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 19-81: Loss: 0.0549 Acc: 75.0000%\n",
      "\tvalidation 19-82: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 19-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-84: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-85: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 19-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-87: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-88: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-89: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-91: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 19-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-94: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 19-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-96: Loss: 1.4122 Acc: 75.0000%\n",
      "\tvalidation 19-97: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 19-98: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 19-99: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 19-100: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 19-101: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 19-102: Loss: 0.2046 Acc: 75.0000%\n",
      "\tvalidation 19-103: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-104: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 19-105: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0629 Acc: 91.3265%\n",
      "\tvalidation Loss: 0.0635 Acc: 97.3810%\n",
      "Time passed 0h 16m 50s\n",
      "--------------------\n",
      "Epoch [20/40]:\n",
      "\ttrain 20-1: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 20-2: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 20-3: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 20-4: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 20-5: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 20-6: Loss: 0.8920 Acc: 50.0000%\n",
      "\ttrain 20-7: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 20-8: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 20-9: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 20-10: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 20-11: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 20-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 20-13: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 20-14: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 20-15: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 20-16: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 20-17: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 20-18: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 20-19: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 20-20: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 20-21: Loss: 0.1742 Acc: 75.0000%\n",
      "\ttrain 20-22: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 20-23: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 20-24: Loss: 0.1508 Acc: 50.0000%\n",
      "\ttrain 20-25: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 20-26: Loss: 0.1224 Acc: 75.0000%\n",
      "\ttrain 20-27: Loss: 0.3577 Acc: 25.0000%\n",
      "\ttrain 20-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 20-29: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 20-30: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 20-31: Loss: 0.9111 Acc: 25.0000%\n",
      "\ttrain 20-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 20-33: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 20-34: Loss: 0.1101 Acc: 75.0000%\n",
      "\ttrain 20-35: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 20-36: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 20-37: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 20-38: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 20-39: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 20-40: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 20-41: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 20-42: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 20-43: Loss: 0.1572 Acc: 50.0000%\n",
      "\ttrain 20-44: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 20-45: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 20-46: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 20-47: Loss: 0.2293 Acc: 75.0000%\n",
      "\ttrain 20-48: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 20-49: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 20-50: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 20-51: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 20-52: Loss: 0.7716 Acc: 50.0000%\n",
      "\ttrain 20-53: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 20-54: Loss: 0.3288 Acc: 75.0000%\n",
      "\ttrain 20-55: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 20-56: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 20-57: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 20-58: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-59: Loss: 0.0834 Acc: 100.0000%\n",
      "\ttrain 20-60: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 20-61: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 20-62: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 20-63: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 20-64: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 20-65: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 20-66: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 20-67: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 20-68: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 20-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 20-70: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 20-71: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 20-72: Loss: 0.0028 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-73: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 20-74: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 20-75: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 20-76: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 20-77: Loss: 0.1916 Acc: 50.0000%\n",
      "\ttrain 20-78: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 20-79: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 20-80: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 20-81: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 20-82: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 20-83: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 20-84: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 20-85: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 20-86: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-87: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 20-88: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 20-89: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 20-90: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 20-91: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 20-92: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 20-93: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 20-94: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 20-95: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 20-96: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 20-97: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 20-98: Loss: 0.3977 Acc: 50.0000%\n",
      "\ttrain 20-99: Loss: 0.2801 Acc: 75.0000%\n",
      "\ttrain 20-100: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 20-101: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 20-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 20-103: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 20-104: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 20-105: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 20-106: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 20-107: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 20-108: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 20-109: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-110: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 20-111: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 20-112: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 20-113: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 20-114: Loss: 0.2037 Acc: 75.0000%\n",
      "\ttrain 20-115: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 20-116: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 20-117: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 20-118: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 20-119: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 20-120: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 20-121: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 20-122: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 20-123: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 20-124: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 20-125: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-126: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 20-127: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 20-128: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 20-129: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 20-130: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 20-131: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 20-132: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 20-133: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 20-134: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 20-135: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 20-136: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 20-137: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 20-138: Loss: 0.2120 Acc: 75.0000%\n",
      "\ttrain 20-139: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 20-140: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 20-141: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 20-142: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 20-143: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 20-144: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 20-145: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 20-146: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 20-147: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 20-148: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 20-149: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 20-150: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 20-151: Loss: 0.2419 Acc: 75.0000%\n",
      "\ttrain 20-152: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 20-153: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 20-154: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 20-155: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 20-156: Loss: 0.2020 Acc: 75.0000%\n",
      "\ttrain 20-157: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 20-158: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 20-159: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 20-160: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 20-161: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 20-162: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 20-163: Loss: 0.1765 Acc: 75.0000%\n",
      "\ttrain 20-164: Loss: 0.2875 Acc: 75.0000%\n",
      "\ttrain 20-165: Loss: 0.1981 Acc: 75.0000%\n",
      "\ttrain 20-166: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 20-167: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 20-168: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 20-169: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 20-170: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 20-171: Loss: 1.2081 Acc: 25.0000%\n",
      "\ttrain 20-172: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 20-173: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 20-174: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 20-175: Loss: 0.8709 Acc: 25.0000%\n",
      "\ttrain 20-176: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 20-177: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 20-178: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 20-179: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 20-180: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 20-181: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 20-182: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 20-183: Loss: 0.2303 Acc: 25.0000%\n",
      "\ttrain 20-184: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 20-185: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 20-186: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 20-187: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 20-188: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 20-189: Loss: 0.2272 Acc: 75.0000%\n",
      "\ttrain 20-190: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 20-191: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 20-192: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 20-193: Loss: 0.0819 Acc: 100.0000%\n",
      "\ttrain 20-194: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 20-195: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 20-196: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 20-197: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-198: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 20-199: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 20-200: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-201: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 20-202: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 20-203: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 20-204: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 20-205: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 20-206: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 20-207: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 20-208: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 20-209: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 20-210: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 20-211: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 20-212: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 20-213: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 20-214: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 20-215: Loss: 0.7316 Acc: 25.0000%\n",
      "\ttrain 20-216: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-217: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 20-218: Loss: 0.1347 Acc: 50.0000%\n",
      "\ttrain 20-219: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 20-220: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 20-221: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 20-222: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 20-223: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 20-224: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 20-225: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 20-226: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 20-227: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 20-228: Loss: 0.2103 Acc: 75.0000%\n",
      "\ttrain 20-229: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 20-230: Loss: 0.1692 Acc: 75.0000%\n",
      "\ttrain 20-231: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 20-232: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 20-233: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 20-234: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 20-235: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 20-236: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 20-237: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 20-238: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 20-239: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 20-240: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 20-241: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 20-242: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 20-243: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 20-244: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 20-245: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 20-1: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-2: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-4: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 20-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-7: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-8: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 20-9: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-10: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 20-11: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 20-12: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-13: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 20-14: Loss: 0.6100 Acc: 75.0000%\n",
      "\tvalidation 20-15: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-16: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 20-17: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-18: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 20-19: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 20-20: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 20-21: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 20-22: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-23: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-24: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 20-25: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 20-26: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-27: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 20-28: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 20-29: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-30: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 20-31: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 20-32: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 20-33: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 20-34: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 20-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-36: Loss: 1.9254 Acc: 75.0000%\n",
      "\tvalidation 20-37: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 20-38: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-39: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 20-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-41: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-42: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-43: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 20-44: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 20-45: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-46: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-47: Loss: 1.3961 Acc: 75.0000%\n",
      "\tvalidation 20-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-49: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 20-50: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-51: Loss: 0.0579 Acc: 75.0000%\n",
      "\tvalidation 20-52: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 20-53: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-54: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 20-55: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-56: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 20-57: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-58: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-59: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-61: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 20-62: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 20-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-64: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 20-65: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 20-66: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 20-67: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 20-68: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 20-69: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 20-70: Loss: 0.0724 Acc: 75.0000%\n",
      "\tvalidation 20-71: Loss: 0.3006 Acc: 75.0000%\n",
      "\tvalidation 20-72: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 20-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-74: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 20-75: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 20-76: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 20-77: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 20-78: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-79: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 20-80: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 20-81: Loss: 0.0393 Acc: 100.0000%\n",
      "\tvalidation 20-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-83: Loss: 0.3027 Acc: 75.0000%\n",
      "\tvalidation 20-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-85: Loss: 0.1705 Acc: 75.0000%\n",
      "\tvalidation 20-86: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-88: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-89: Loss: 1.3319 Acc: 75.0000%\n",
      "\tvalidation 20-90: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 20-91: Loss: 0.1020 Acc: 75.0000%\n",
      "\tvalidation 20-92: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 20-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-95: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 20-96: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 20-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-98: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 20-99: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 20-100: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-101: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-102: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 20-103: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-104: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0707 Acc: 91.1224%\n",
      "\tvalidation Loss: 0.0647 Acc: 97.6190%\n",
      "网络参数更新\n",
      "Time passed 0h 17m 44s\n",
      "--------------------\n",
      "Epoch [21/40]:\n",
      "\ttrain 21-1: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 21-2: Loss: 0.5871 Acc: 75.0000%\n",
      "\ttrain 21-3: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 21-4: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 21-5: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 21-6: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 21-7: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 21-8: Loss: 0.3395 Acc: 75.0000%\n",
      "\ttrain 21-9: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-10: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 21-11: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-12: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-13: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 21-14: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 21-15: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 21-16: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 21-17: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 21-18: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 21-19: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 21-20: Loss: 0.2528 Acc: 75.0000%\n",
      "\ttrain 21-21: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 21-22: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 21-23: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-24: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 21-25: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 21-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-27: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 21-28: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 21-29: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 21-30: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 21-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 21-32: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-33: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 21-34: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-35: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 21-36: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-37: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 21-38: Loss: 0.0513 Acc: 75.0000%\n",
      "\ttrain 21-39: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 21-40: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 21-41: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 21-42: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 21-43: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 21-44: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 21-45: Loss: 0.2651 Acc: 50.0000%\n",
      "\ttrain 21-46: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 21-47: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-48: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-49: Loss: 0.2139 Acc: 75.0000%\n",
      "\ttrain 21-50: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 21-51: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 21-52: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-53: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 21-54: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 21-55: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 21-56: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 21-57: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 21-58: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 21-59: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-60: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 21-61: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 21-62: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 21-63: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-64: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-65: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 21-66: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 21-67: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 21-68: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 21-69: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 21-70: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 21-71: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 21-72: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 21-73: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 21-74: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 21-75: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 21-76: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 21-77: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 21-78: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 21-79: Loss: 0.1189 Acc: 100.0000%\n",
      "\ttrain 21-80: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 21-81: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 21-82: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 21-83: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 21-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 21-85: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 21-86: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 21-87: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 21-88: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-89: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 21-90: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-91: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 21-92: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 21-93: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 21-94: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 21-95: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 21-96: Loss: 0.0714 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-97: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 21-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 21-99: Loss: 0.2030 Acc: 75.0000%\n",
      "\ttrain 21-100: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-101: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 21-102: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 21-103: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 21-104: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 21-105: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-106: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-107: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 21-108: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-109: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 21-110: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 21-111: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 21-112: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 21-113: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 21-114: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 21-115: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 21-116: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 21-117: Loss: 0.2253 Acc: 75.0000%\n",
      "\ttrain 21-118: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 21-119: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 21-120: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 21-121: Loss: 0.1375 Acc: 75.0000%\n",
      "\ttrain 21-122: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 21-123: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 21-124: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 21-125: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 21-126: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 21-127: Loss: 0.2332 Acc: 50.0000%\n",
      "\ttrain 21-128: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 21-129: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 21-130: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-131: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 21-132: Loss: 0.3772 Acc: 50.0000%\n",
      "\ttrain 21-133: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 21-134: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-135: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 21-136: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 21-137: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 21-138: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 21-139: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 21-140: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 21-141: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 21-142: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-143: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 21-144: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 21-145: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 21-146: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-147: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 21-148: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 21-149: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 21-150: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 21-151: Loss: 0.2091 Acc: 75.0000%\n",
      "\ttrain 21-152: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 21-153: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 21-154: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 21-155: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 21-156: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-157: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 21-158: Loss: 0.2620 Acc: 50.0000%\n",
      "\ttrain 21-159: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 21-160: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 21-161: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 21-162: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 21-163: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 21-164: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-165: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 21-166: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 21-167: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 21-168: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 21-169: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 21-170: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 21-171: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 21-172: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 21-173: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 21-174: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 21-175: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 21-176: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 21-177: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 21-178: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 21-179: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 21-180: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 21-181: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 21-182: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 21-183: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 21-184: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 21-185: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 21-186: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 21-187: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 21-188: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 21-189: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 21-190: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 21-191: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 21-192: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 21-193: Loss: 0.2301 Acc: 75.0000%\n",
      "\ttrain 21-194: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 21-195: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 21-196: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 21-197: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 21-198: Loss: 0.2591 Acc: 75.0000%\n",
      "\ttrain 21-199: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-200: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 21-201: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 21-202: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 21-203: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 21-204: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 21-205: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 21-206: Loss: 0.2322 Acc: 50.0000%\n",
      "\ttrain 21-207: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-208: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 21-209: Loss: 0.0949 Acc: 100.0000%\n",
      "\ttrain 21-210: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 21-211: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 21-212: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 21-213: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 21-214: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 21-215: Loss: 0.2015 Acc: 50.0000%\n",
      "\ttrain 21-216: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 21-217: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 21-218: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-219: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 21-220: Loss: 0.1316 Acc: 75.0000%\n",
      "\ttrain 21-221: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-222: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-223: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 21-224: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 21-225: Loss: 0.4580 Acc: 50.0000%\n",
      "\ttrain 21-226: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 21-227: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 21-228: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 21-229: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 21-230: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-231: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 21-232: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 21-233: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 21-234: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-235: Loss: 0.1751 Acc: 75.0000%\n",
      "\ttrain 21-236: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 21-237: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 21-238: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 21-239: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 21-240: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 21-241: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-242: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 21-243: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 21-244: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 21-245: Loss: 0.1252 Acc: 50.0000%\n",
      "\tvalidation 21-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-2: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 21-3: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 21-4: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-5: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 21-6: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 21-7: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 21-8: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-9: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 21-10: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-11: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-12: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 21-13: Loss: 0.2911 Acc: 75.0000%\n",
      "\tvalidation 21-14: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 21-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-16: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 21-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-19: Loss: 1.3570 Acc: 75.0000%\n",
      "\tvalidation 21-20: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-21: Loss: 2.0326 Acc: 75.0000%\n",
      "\tvalidation 21-22: Loss: 0.1664 Acc: 75.0000%\n",
      "\tvalidation 21-23: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 21-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 21-26: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 21-27: Loss: 0.9236 Acc: 75.0000%\n",
      "\tvalidation 21-28: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-29: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-31: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 21-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-33: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 21-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-35: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-37: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 21-38: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 21-39: Loss: 0.4970 Acc: 75.0000%\n",
      "\tvalidation 21-40: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-41: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-42: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-43: Loss: 0.0008 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 21-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-45: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-47: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 21-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-49: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-50: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 21-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-52: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 21-53: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-54: Loss: 0.1017 Acc: 75.0000%\n",
      "\tvalidation 21-55: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 21-56: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 21-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-61: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-62: Loss: 0.0502 Acc: 100.0000%\n",
      "\tvalidation 21-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-64: Loss: 0.3595 Acc: 75.0000%\n",
      "\tvalidation 21-65: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 21-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-67: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 21-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-70: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 21-71: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-73: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 21-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-75: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-76: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 21-77: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 21-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-79: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-80: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-81: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 21-82: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-83: Loss: 0.5946 Acc: 50.0000%\n",
      "\tvalidation 21-84: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-86: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-88: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 21-89: Loss: 0.2213 Acc: 75.0000%\n",
      "\tvalidation 21-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-91: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-92: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-93: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 21-94: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-95: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-98: Loss: 0.8161 Acc: 75.0000%\n",
      "\tvalidation 21-99: Loss: 0.2209 Acc: 75.0000%\n",
      "\tvalidation 21-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-101: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 21-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-103: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0488 Acc: 93.6735%\n",
      "\tvalidation Loss: 0.0747 Acc: 96.9048%\n",
      "Time passed 0h 18m 25s\n",
      "--------------------\n",
      "Epoch [22/40]:\n",
      "\ttrain 22-1: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-2: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 22-3: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 22-4: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 22-5: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 22-6: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 22-7: Loss: 0.2912 Acc: 50.0000%\n",
      "\ttrain 22-8: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-9: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 22-10: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 22-11: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 22-12: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 22-13: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 22-14: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 22-15: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 22-16: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 22-17: Loss: 0.2592 Acc: 75.0000%\n",
      "\ttrain 22-18: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 22-19: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 22-20: Loss: 0.3244 Acc: 50.0000%\n",
      "\ttrain 22-21: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 22-22: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 22-23: Loss: 0.1908 Acc: 75.0000%\n",
      "\ttrain 22-24: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 22-25: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 22-26: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 22-27: Loss: 0.2311 Acc: 50.0000%\n",
      "\ttrain 22-28: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 22-29: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 22-30: Loss: 0.1734 Acc: 75.0000%\n",
      "\ttrain 22-31: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 22-32: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 22-33: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 22-34: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 22-35: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 22-36: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 22-37: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 22-38: Loss: 0.1176 Acc: 75.0000%\n",
      "\ttrain 22-39: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 22-40: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 22-41: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 22-42: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 22-43: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 22-44: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 22-45: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 22-46: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 22-47: Loss: 0.8185 Acc: 25.0000%\n",
      "\ttrain 22-48: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 22-49: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 22-50: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 22-51: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-52: Loss: 0.1718 Acc: 75.0000%\n",
      "\ttrain 22-53: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 22-54: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-55: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 22-56: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 22-57: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 22-58: Loss: 0.3034 Acc: 50.0000%\n",
      "\ttrain 22-59: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 22-60: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 22-61: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 22-62: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 22-63: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 22-64: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 22-65: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 22-66: Loss: 0.1937 Acc: 75.0000%\n",
      "\ttrain 22-67: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-68: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 22-69: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-70: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 22-71: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 22-72: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 22-73: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 22-74: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 22-75: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 22-76: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 22-77: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 22-78: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 22-79: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 22-80: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-81: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 22-82: Loss: 0.2604 Acc: 75.0000%\n",
      "\ttrain 22-83: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 22-84: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 22-85: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 22-86: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 22-87: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 22-88: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 22-89: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-90: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 22-91: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 22-92: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 22-93: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 22-94: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 22-95: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 22-96: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 22-97: Loss: 0.1797 Acc: 50.0000%\n",
      "\ttrain 22-98: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 22-99: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 22-100: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 22-101: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 22-102: Loss: 0.0480 Acc: 75.0000%\n",
      "\ttrain 22-103: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-104: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 22-105: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-106: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 22-107: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 22-108: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 22-109: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 22-110: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 22-111: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 22-112: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 22-113: Loss: 0.3705 Acc: 50.0000%\n",
      "\ttrain 22-114: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 22-115: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 22-116: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 22-117: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 22-118: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 22-119: Loss: 0.3162 Acc: 50.0000%\n",
      "\ttrain 22-120: Loss: 0.1528 Acc: 50.0000%\n",
      "\ttrain 22-121: Loss: 0.0719 Acc: 75.0000%\n",
      "\ttrain 22-122: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 22-123: Loss: 0.5701 Acc: 25.0000%\n",
      "\ttrain 22-124: Loss: 0.0020 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-125: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 22-126: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 22-127: Loss: 0.2316 Acc: 75.0000%\n",
      "\ttrain 22-128: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 22-129: Loss: 0.3201 Acc: 50.0000%\n",
      "\ttrain 22-130: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 22-131: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 22-132: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 22-133: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 22-134: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 22-135: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 22-136: Loss: 0.1416 Acc: 75.0000%\n",
      "\ttrain 22-137: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 22-138: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-139: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 22-140: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 22-141: Loss: 0.5442 Acc: 50.0000%\n",
      "\ttrain 22-142: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 22-143: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 22-144: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 22-145: Loss: 0.3896 Acc: 50.0000%\n",
      "\ttrain 22-146: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 22-147: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 22-148: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 22-149: Loss: 0.0699 Acc: 75.0000%\n",
      "\ttrain 22-150: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-151: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 22-152: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 22-153: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 22-154: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 22-155: Loss: 0.2495 Acc: 50.0000%\n",
      "\ttrain 22-156: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 22-157: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 22-158: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 22-159: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 22-160: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 22-161: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 22-162: Loss: 0.1368 Acc: 50.0000%\n",
      "\ttrain 22-163: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 22-164: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 22-165: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 22-166: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 22-167: Loss: 0.2591 Acc: 75.0000%\n",
      "\ttrain 22-168: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 22-169: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 22-170: Loss: 0.3581 Acc: 75.0000%\n",
      "\ttrain 22-171: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 22-172: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 22-173: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 22-174: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 22-175: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 22-176: Loss: 0.1555 Acc: 75.0000%\n",
      "\ttrain 22-177: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 22-178: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 22-179: Loss: 1.0642 Acc: 25.0000%\n",
      "\ttrain 22-180: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 22-181: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 22-182: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 22-183: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 22-184: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 22-185: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 22-186: Loss: 0.1789 Acc: 50.0000%\n",
      "\ttrain 22-187: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 22-188: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 22-189: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 22-190: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 22-191: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 22-192: Loss: 0.2467 Acc: 75.0000%\n",
      "\ttrain 22-193: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 22-194: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 22-195: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 22-196: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 22-197: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 22-198: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 22-199: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 22-200: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 22-201: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 22-202: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 22-203: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 22-204: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 22-205: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 22-206: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 22-207: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-208: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 22-209: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 22-210: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 22-211: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 22-212: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 22-213: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 22-214: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 22-215: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 22-216: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 22-217: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 22-218: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 22-219: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 22-220: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 22-221: Loss: 0.2547 Acc: 50.0000%\n",
      "\ttrain 22-222: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 22-223: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 22-224: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 22-225: Loss: 0.2392 Acc: 75.0000%\n",
      "\ttrain 22-226: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 22-227: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-228: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 22-229: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 22-230: Loss: 0.2545 Acc: 50.0000%\n",
      "\ttrain 22-231: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 22-232: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 22-233: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-234: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 22-235: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 22-236: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-237: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 22-238: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 22-239: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 22-240: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 22-241: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 22-242: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 22-243: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 22-244: Loss: 0.1245 Acc: 75.0000%\n",
      "\ttrain 22-245: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 22-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-2: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 22-3: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 22-4: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-5: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 22-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-7: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-8: Loss: 0.1547 Acc: 75.0000%\n",
      "\tvalidation 22-9: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 22-10: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 22-11: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 22-12: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-13: Loss: 0.3901 Acc: 75.0000%\n",
      "\tvalidation 22-14: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 22-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-16: Loss: 0.5608 Acc: 75.0000%\n",
      "\tvalidation 22-17: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 22-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-20: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 22-21: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 22-22: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 22-23: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-24: Loss: 0.2210 Acc: 75.0000%\n",
      "\tvalidation 22-25: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 22-26: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 22-27: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-29: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 22-30: Loss: 0.1061 Acc: 75.0000%\n",
      "\tvalidation 22-31: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 22-32: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 22-33: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-34: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 22-35: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 22-36: Loss: 0.1578 Acc: 75.0000%\n",
      "\tvalidation 22-37: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-38: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 22-39: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 22-40: Loss: 0.0535 Acc: 75.0000%\n",
      "\tvalidation 22-41: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 22-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-43: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 22-44: Loss: 0.0467 Acc: 75.0000%\n",
      "\tvalidation 22-45: Loss: 0.0573 Acc: 75.0000%\n",
      "\tvalidation 22-46: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 22-47: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-48: Loss: 0.3079 Acc: 75.0000%\n",
      "\tvalidation 22-49: Loss: 0.0930 Acc: 75.0000%\n",
      "\tvalidation 22-50: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 22-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-52: Loss: 0.5054 Acc: 75.0000%\n",
      "\tvalidation 22-53: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 22-54: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 22-55: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 22-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-57: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 22-58: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-59: Loss: 0.5981 Acc: 75.0000%\n",
      "\tvalidation 22-60: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 22-61: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-62: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 22-63: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 22-64: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 22-65: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 22-66: Loss: 0.0048 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 22-67: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 22-68: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 22-69: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 22-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-71: Loss: 2.6484 Acc: 75.0000%\n",
      "\tvalidation 22-72: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 22-73: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 22-74: Loss: 0.2078 Acc: 75.0000%\n",
      "\tvalidation 22-75: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 22-76: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 22-77: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 22-78: Loss: 1.8820 Acc: 75.0000%\n",
      "\tvalidation 22-79: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 22-80: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 22-81: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 22-82: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 22-83: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 22-84: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 22-85: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 22-86: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 22-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-88: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 22-89: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 22-90: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 22-91: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 22-92: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 22-93: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-94: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 22-95: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 22-96: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 22-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-98: Loss: 0.1145 Acc: 75.0000%\n",
      "\tvalidation 22-99: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 22-100: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 22-101: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 22-102: Loss: 2.1493 Acc: 75.0000%\n",
      "\tvalidation 22-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-104: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 22-105: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0673 Acc: 90.0000%\n",
      "\tvalidation Loss: 0.1068 Acc: 95.4762%\n",
      "Time passed 0h 19m 5s\n",
      "--------------------\n",
      "Epoch [23/40]:\n",
      "\ttrain 23-1: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-2: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-3: Loss: 0.1832 Acc: 75.0000%\n",
      "\ttrain 23-4: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 23-5: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-6: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 23-7: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 23-8: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 23-9: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-10: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 23-11: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-12: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 23-13: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 23-14: Loss: 0.1705 Acc: 75.0000%\n",
      "\ttrain 23-15: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 23-16: Loss: 0.2051 Acc: 75.0000%\n",
      "\ttrain 23-17: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 23-18: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 23-19: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 23-20: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-21: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 23-22: Loss: 0.2376 Acc: 75.0000%\n",
      "\ttrain 23-23: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 23-24: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 23-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-26: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 23-27: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 23-28: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 23-29: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 23-30: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 23-31: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 23-32: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 23-33: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 23-34: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-35: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 23-36: Loss: 0.1962 Acc: 50.0000%\n",
      "\ttrain 23-37: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 23-38: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 23-39: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 23-40: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 23-41: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 23-42: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 23-43: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 23-44: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 23-45: Loss: 0.0842 Acc: 100.0000%\n",
      "\ttrain 23-46: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 23-47: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 23-48: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 23-49: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 23-50: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 23-51: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 23-52: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 23-53: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 23-54: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 23-55: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 23-56: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 23-57: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 23-58: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 23-59: Loss: 0.1606 Acc: 75.0000%\n",
      "\ttrain 23-60: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 23-61: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 23-62: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 23-63: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 23-64: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-65: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 23-66: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 23-67: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 23-68: Loss: 0.2015 Acc: 75.0000%\n",
      "\ttrain 23-69: Loss: 0.2312 Acc: 75.0000%\n",
      "\ttrain 23-70: Loss: 0.1789 Acc: 75.0000%\n",
      "\ttrain 23-71: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 23-72: Loss: 0.2025 Acc: 75.0000%\n",
      "\ttrain 23-73: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 23-74: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 23-75: Loss: 0.3124 Acc: 75.0000%\n",
      "\ttrain 23-76: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 23-77: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 23-78: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 23-79: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 23-80: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 23-81: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 23-82: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 23-83: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 23-84: Loss: 0.2671 Acc: 50.0000%\n",
      "\ttrain 23-85: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 23-86: Loss: 0.1741 Acc: 75.0000%\n",
      "\ttrain 23-87: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-88: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 23-89: Loss: 0.0741 Acc: 75.0000%\n",
      "\ttrain 23-90: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 23-91: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 23-92: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 23-93: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 23-94: Loss: 0.1808 Acc: 50.0000%\n",
      "\ttrain 23-95: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-96: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 23-97: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 23-98: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 23-99: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 23-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 23-101: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 23-102: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 23-103: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 23-104: Loss: 0.1832 Acc: 75.0000%\n",
      "\ttrain 23-105: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 23-106: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 23-107: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-108: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 23-109: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 23-110: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 23-111: Loss: 0.1103 Acc: 100.0000%\n",
      "\ttrain 23-112: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 23-113: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 23-114: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 23-115: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 23-116: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 23-117: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 23-118: Loss: 0.2239 Acc: 75.0000%\n",
      "\ttrain 23-119: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-120: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-121: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 23-122: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 23-123: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 23-124: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 23-125: Loss: 0.2692 Acc: 75.0000%\n",
      "\ttrain 23-126: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 23-127: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 23-128: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 23-129: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 23-130: Loss: 0.5199 Acc: 25.0000%\n",
      "\ttrain 23-131: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 23-132: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 23-133: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 23-134: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 23-135: Loss: 0.3407 Acc: 50.0000%\n",
      "\ttrain 23-136: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 23-137: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 23-138: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-139: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 23-140: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 23-141: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 23-142: Loss: 0.2261 Acc: 75.0000%\n",
      "\ttrain 23-143: Loss: 0.2872 Acc: 50.0000%\n",
      "\ttrain 23-144: Loss: 0.0911 Acc: 100.0000%\n",
      "\ttrain 23-145: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 23-146: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 23-147: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 23-148: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 23-149: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 23-150: Loss: 0.0103 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 23-151: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 23-152: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 23-153: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 23-154: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 23-155: Loss: 0.2003 Acc: 75.0000%\n",
      "\ttrain 23-156: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 23-157: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 23-158: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 23-159: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 23-160: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 23-161: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 23-162: Loss: 0.0611 Acc: 75.0000%\n",
      "\ttrain 23-163: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 23-164: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-165: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 23-166: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 23-167: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 23-168: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 23-169: Loss: 0.2428 Acc: 50.0000%\n",
      "\ttrain 23-170: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 23-171: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 23-172: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 23-173: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 23-174: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 23-175: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 23-176: Loss: 0.4318 Acc: 50.0000%\n",
      "\ttrain 23-177: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 23-178: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 23-179: Loss: 0.3060 Acc: 75.0000%\n",
      "\ttrain 23-180: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 23-181: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 23-182: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 23-183: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 23-184: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-185: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 23-186: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 23-187: Loss: 0.2536 Acc: 75.0000%\n",
      "\ttrain 23-188: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-189: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 23-190: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-191: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 23-192: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 23-193: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 23-194: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 23-195: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 23-196: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 23-197: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 23-198: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 23-199: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 23-200: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 23-201: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 23-202: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 23-203: Loss: 0.0685 Acc: 100.0000%\n",
      "\ttrain 23-204: Loss: 0.3052 Acc: 50.0000%\n",
      "\ttrain 23-205: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 23-206: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 23-207: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 23-208: Loss: 0.2360 Acc: 50.0000%\n",
      "\ttrain 23-209: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 23-210: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 23-211: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 23-212: Loss: 0.1922 Acc: 75.0000%\n",
      "\ttrain 23-213: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-214: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 23-215: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 23-216: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 23-217: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 23-218: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 23-219: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 23-220: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 23-221: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 23-222: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 23-223: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 23-224: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 23-225: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-226: Loss: 0.3725 Acc: 75.0000%\n",
      "\ttrain 23-227: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 23-228: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 23-229: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 23-230: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 23-231: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-232: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 23-233: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 23-234: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 23-235: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-236: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 23-237: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 23-238: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 23-239: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 23-240: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 23-241: Loss: 0.3232 Acc: 75.0000%\n",
      "\ttrain 23-242: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 23-243: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 23-244: Loss: 0.4146 Acc: 50.0000%\n",
      "\ttrain 23-245: Loss: 0.0195 Acc: 100.0000%\n",
      "\tvalidation 23-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 23-2: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 23-3: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-4: Loss: 0.0813 Acc: 75.0000%\n",
      "\tvalidation 23-5: Loss: 1.2561 Acc: 50.0000%\n",
      "\tvalidation 23-6: Loss: 0.1048 Acc: 75.0000%\n",
      "\tvalidation 23-7: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 23-8: Loss: 0.0416 Acc: 100.0000%\n",
      "\tvalidation 23-9: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 23-10: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 23-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-12: Loss: 1.3067 Acc: 75.0000%\n",
      "\tvalidation 23-13: Loss: 0.6985 Acc: 75.0000%\n",
      "\tvalidation 23-14: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 23-15: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-16: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 23-17: Loss: 0.1986 Acc: 75.0000%\n",
      "\tvalidation 23-18: Loss: 0.3057 Acc: 50.0000%\n",
      "\tvalidation 23-19: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-20: Loss: 4.8160 Acc: 50.0000%\n",
      "\tvalidation 23-21: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-22: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 23-23: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-24: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 23-25: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 23-26: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 23-27: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-28: Loss: 0.0572 Acc: 100.0000%\n",
      "\tvalidation 23-29: Loss: 0.0719 Acc: 75.0000%\n",
      "\tvalidation 23-30: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 23-31: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 23-32: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-33: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 23-34: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 23-35: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 23-36: Loss: 0.5760 Acc: 75.0000%\n",
      "\tvalidation 23-37: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 23-38: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 23-39: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 23-40: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 23-41: Loss: 0.1259 Acc: 50.0000%\n",
      "\tvalidation 23-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-43: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 23-44: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 23-45: Loss: 0.0454 Acc: 100.0000%\n",
      "\tvalidation 23-46: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 23-47: Loss: 0.3328 Acc: 75.0000%\n",
      "\tvalidation 23-48: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-49: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 23-50: Loss: 0.6290 Acc: 75.0000%\n",
      "\tvalidation 23-51: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 23-52: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 23-53: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-54: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 23-55: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 23-56: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 23-57: Loss: 2.9621 Acc: 75.0000%\n",
      "\tvalidation 23-58: Loss: 3.3528 Acc: 75.0000%\n",
      "\tvalidation 23-59: Loss: 0.5502 Acc: 75.0000%\n",
      "\tvalidation 23-60: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 23-61: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 23-62: Loss: 0.1289 Acc: 75.0000%\n",
      "\tvalidation 23-63: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 23-64: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 23-65: Loss: 0.0743 Acc: 75.0000%\n",
      "\tvalidation 23-66: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-67: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 23-68: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 23-69: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 23-70: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-71: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 23-72: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 23-73: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 23-74: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 23-75: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 23-76: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 23-77: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-78: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 23-79: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 23-80: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 23-81: Loss: 0.8960 Acc: 75.0000%\n",
      "\tvalidation 23-82: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 23-83: Loss: 0.1405 Acc: 75.0000%\n",
      "\tvalidation 23-84: Loss: 0.4466 Acc: 75.0000%\n",
      "\tvalidation 23-85: Loss: 0.0746 Acc: 75.0000%\n",
      "\tvalidation 23-86: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 23-87: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 23-88: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 23-89: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 23-90: Loss: 1.1382 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 23-91: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-92: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 23-93: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 23-94: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-95: Loss: 0.0602 Acc: 75.0000%\n",
      "\tvalidation 23-96: Loss: 0.0399 Acc: 100.0000%\n",
      "\tvalidation 23-97: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 23-98: Loss: 0.1440 Acc: 75.0000%\n",
      "\tvalidation 23-99: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 23-100: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 23-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-102: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 23-103: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-104: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-105: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0612 Acc: 91.9388%\n",
      "\tvalidation Loss: 0.2026 Acc: 93.0952%\n",
      "Time passed 0h 19m 45s\n",
      "--------------------\n",
      "Epoch [24/40]:\n",
      "\ttrain 24-1: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-2: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 24-3: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 24-4: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 24-5: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 24-6: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 24-7: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 24-8: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-9: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 24-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-11: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 24-12: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 24-13: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-14: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 24-15: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 24-16: Loss: 0.7963 Acc: 25.0000%\n",
      "\ttrain 24-17: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 24-18: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 24-19: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 24-20: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 24-21: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-22: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 24-23: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 24-24: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 24-25: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 24-26: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 24-27: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 24-28: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 24-29: Loss: 0.1667 Acc: 75.0000%\n",
      "\ttrain 24-30: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 24-31: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 24-32: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 24-33: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 24-34: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-35: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-36: Loss: 0.4590 Acc: 50.0000%\n",
      "\ttrain 24-37: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 24-38: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 24-39: Loss: 0.4534 Acc: 50.0000%\n",
      "\ttrain 24-40: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 24-41: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-42: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 24-43: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-44: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 24-45: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 24-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 24-47: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-48: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 24-49: Loss: 0.3224 Acc: 50.0000%\n",
      "\ttrain 24-50: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 24-51: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-52: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 24-53: Loss: 0.2151 Acc: 50.0000%\n",
      "\ttrain 24-54: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 24-55: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 24-56: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-57: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 24-58: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 24-59: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 24-60: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 24-61: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 24-62: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 24-63: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 24-64: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 24-65: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 24-66: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-67: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 24-68: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 24-69: Loss: 0.2433 Acc: 25.0000%\n",
      "\ttrain 24-70: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 24-71: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-72: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 24-73: Loss: 0.0444 Acc: 75.0000%\n",
      "\ttrain 24-74: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 24-75: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 24-76: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 24-77: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-78: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 24-79: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-80: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 24-81: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 24-82: Loss: 0.2256 Acc: 75.0000%\n",
      "\ttrain 24-83: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-84: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 24-85: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 24-86: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 24-87: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 24-88: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 24-89: Loss: 0.0471 Acc: 75.0000%\n",
      "\ttrain 24-90: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 24-91: Loss: 0.3101 Acc: 50.0000%\n",
      "\ttrain 24-92: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 24-93: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 24-94: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 24-95: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 24-96: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 24-97: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-98: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 24-99: Loss: 0.1922 Acc: 75.0000%\n",
      "\ttrain 24-100: Loss: 0.1534 Acc: 75.0000%\n",
      "\ttrain 24-101: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 24-102: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 24-103: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-104: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 24-105: Loss: 0.1349 Acc: 50.0000%\n",
      "\ttrain 24-106: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 24-107: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 24-108: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-109: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 24-110: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 24-111: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 24-112: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-113: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 24-114: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-115: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 24-116: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 24-117: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 24-118: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 24-119: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 24-120: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-121: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 24-122: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 24-123: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-124: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 24-125: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 24-126: Loss: 0.2870 Acc: 75.0000%\n",
      "\ttrain 24-127: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 24-128: Loss: 0.0575 Acc: 75.0000%\n",
      "\ttrain 24-129: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-130: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-131: Loss: 0.2006 Acc: 50.0000%\n",
      "\ttrain 24-132: Loss: 0.2106 Acc: 75.0000%\n",
      "\ttrain 24-133: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 24-134: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-135: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 24-136: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-137: Loss: 0.2143 Acc: 50.0000%\n",
      "\ttrain 24-138: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 24-139: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 24-140: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 24-141: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 24-142: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-143: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 24-144: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 24-145: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-146: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 24-147: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 24-148: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 24-149: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 24-150: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-151: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 24-152: Loss: 0.2082 Acc: 50.0000%\n",
      "\ttrain 24-153: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 24-154: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 24-155: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 24-156: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-157: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-158: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 24-159: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 24-160: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 24-161: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 24-162: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 24-163: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-164: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-165: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 24-166: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 24-167: Loss: 0.0452 Acc: 75.0000%\n",
      "\ttrain 24-168: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 24-169: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-170: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 24-171: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-172: Loss: 0.0707 Acc: 75.0000%\n",
      "\ttrain 24-173: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 24-174: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 24-175: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-176: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 24-177: Loss: 0.0129 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-178: Loss: 0.0761 Acc: 100.0000%\n",
      "\ttrain 24-179: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 24-180: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 24-181: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 24-182: Loss: 0.6130 Acc: 50.0000%\n",
      "\ttrain 24-183: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 24-184: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 24-185: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-186: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 24-187: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 24-188: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-189: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 24-190: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 24-191: Loss: 0.2900 Acc: 50.0000%\n",
      "\ttrain 24-192: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 24-193: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 24-194: Loss: 0.3291 Acc: 75.0000%\n",
      "\ttrain 24-195: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 24-196: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 24-197: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 24-198: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-199: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 24-200: Loss: 0.3683 Acc: 50.0000%\n",
      "\ttrain 24-201: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 24-202: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 24-203: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 24-204: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-205: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 24-206: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 24-207: Loss: 0.4238 Acc: 50.0000%\n",
      "\ttrain 24-208: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 24-209: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 24-210: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 24-211: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 24-212: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 24-213: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 24-214: Loss: 0.4207 Acc: 50.0000%\n",
      "\ttrain 24-215: Loss: 0.4058 Acc: 75.0000%\n",
      "\ttrain 24-216: Loss: 0.4155 Acc: 50.0000%\n",
      "\ttrain 24-217: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-218: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 24-219: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 24-220: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-221: Loss: 0.1996 Acc: 75.0000%\n",
      "\ttrain 24-222: Loss: 0.3409 Acc: 50.0000%\n",
      "\ttrain 24-223: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 24-224: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 24-225: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 24-226: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 24-227: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 24-228: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 24-229: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 24-230: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 24-231: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 24-232: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 24-233: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 24-234: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-235: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-236: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 24-237: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 24-238: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-239: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-240: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 24-241: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 24-242: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 24-243: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-244: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-245: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 24-1: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-3: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-4: Loss: 2.8397 Acc: 75.0000%\n",
      "\tvalidation 24-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-6: Loss: 0.2272 Acc: 75.0000%\n",
      "\tvalidation 24-7: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-8: Loss: 0.0531 Acc: 75.0000%\n",
      "\tvalidation 24-9: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 24-10: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 24-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-13: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 24-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-15: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-17: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-18: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-20: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 24-21: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-23: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 24-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-25: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-26: Loss: 3.9740 Acc: 75.0000%\n",
      "\tvalidation 24-27: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-28: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-29: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 24-30: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 24-31: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 24-32: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 24-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-35: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 24-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-38: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 24-39: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 24-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-41: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 24-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-43: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-44: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 24-45: Loss: 0.6153 Acc: 50.0000%\n",
      "\tvalidation 24-46: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-47: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 24-48: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 24-49: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 24-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-53: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 24-54: Loss: 3.1935 Acc: 75.0000%\n",
      "\tvalidation 24-55: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-56: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 24-57: Loss: 0.9037 Acc: 75.0000%\n",
      "\tvalidation 24-58: Loss: 0.0457 Acc: 75.0000%\n",
      "\tvalidation 24-59: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-60: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-62: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-64: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 24-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-66: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 24-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-70: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-71: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 24-72: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 24-73: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 24-74: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-75: Loss: 0.4646 Acc: 75.0000%\n",
      "\tvalidation 24-76: Loss: 0.9272 Acc: 75.0000%\n",
      "\tvalidation 24-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-78: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 24-79: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-80: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-82: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 24-83: Loss: 0.0970 Acc: 75.0000%\n",
      "\tvalidation 24-84: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 24-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-87: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 24-88: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-89: Loss: 0.1547 Acc: 75.0000%\n",
      "\tvalidation 24-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-91: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-92: Loss: 0.4664 Acc: 75.0000%\n",
      "\tvalidation 24-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-94: Loss: 0.0835 Acc: 75.0000%\n",
      "\tvalidation 24-95: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-96: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 24-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-99: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 24-100: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 24-101: Loss: 0.0372 Acc: 100.0000%\n",
      "\tvalidation 24-102: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0621 Acc: 91.2245%\n",
      "\tvalidation Loss: 0.1387 Acc: 96.1905%\n",
      "Time passed 0h 20m 25s\n",
      "--------------------\n",
      "Epoch [25/40]:\n",
      "\ttrain 25-1: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 25-2: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 25-3: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 25-4: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 25-5: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 25-6: Loss: 0.0678 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-7: Loss: 0.2880 Acc: 75.0000%\n",
      "\ttrain 25-8: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 25-9: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 25-10: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 25-11: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 25-12: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 25-13: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-15: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 25-16: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 25-17: Loss: 0.2111 Acc: 75.0000%\n",
      "\ttrain 25-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 25-19: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 25-20: Loss: 1.1595 Acc: 50.0000%\n",
      "\ttrain 25-21: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 25-22: Loss: 0.2241 Acc: 75.0000%\n",
      "\ttrain 25-23: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 25-24: Loss: 0.2965 Acc: 75.0000%\n",
      "\ttrain 25-25: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 25-26: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 25-27: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 25-28: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 25-29: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 25-30: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 25-31: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 25-32: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-33: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 25-34: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 25-35: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 25-36: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 25-37: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 25-38: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 25-39: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 25-40: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 25-41: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 25-42: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-43: Loss: 0.0611 Acc: 75.0000%\n",
      "\ttrain 25-44: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 25-45: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 25-46: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 25-47: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 25-48: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-49: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 25-50: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 25-51: Loss: 0.7208 Acc: 25.0000%\n",
      "\ttrain 25-52: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 25-53: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 25-54: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 25-55: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 25-56: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 25-57: Loss: 0.1239 Acc: 75.0000%\n",
      "\ttrain 25-58: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 25-59: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 25-60: Loss: 0.2915 Acc: 50.0000%\n",
      "\ttrain 25-61: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 25-62: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 25-63: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-64: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-65: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 25-66: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 25-67: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-68: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 25-69: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 25-70: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 25-71: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 25-72: Loss: 0.2486 Acc: 50.0000%\n",
      "\ttrain 25-73: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 25-74: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-75: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 25-76: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 25-77: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 25-78: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-79: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 25-80: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-81: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 25-82: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 25-83: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 25-84: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 25-85: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-86: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 25-87: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 25-88: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 25-89: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 25-90: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 25-91: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 25-92: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-93: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 25-94: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-95: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 25-96: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 25-97: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 25-98: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-99: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-100: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 25-101: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 25-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-103: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 25-104: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 25-105: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 25-106: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 25-107: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 25-108: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-109: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-110: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 25-111: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 25-112: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 25-113: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 25-114: Loss: 0.0677 Acc: 75.0000%\n",
      "\ttrain 25-115: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 25-116: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 25-117: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 25-118: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 25-119: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 25-120: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-121: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 25-122: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 25-123: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 25-124: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 25-125: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 25-126: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 25-127: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-128: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 25-129: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 25-130: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-131: Loss: 0.5082 Acc: 25.0000%\n",
      "\ttrain 25-132: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-133: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-134: Loss: 0.0524 Acc: 75.0000%\n",
      "\ttrain 25-135: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-136: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 25-137: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-138: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 25-139: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 25-140: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 25-141: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 25-142: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-143: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 25-144: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 25-145: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 25-146: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-147: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 25-148: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-149: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 25-150: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-151: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-152: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-153: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-154: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 25-155: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 25-156: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 25-157: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 25-158: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 25-159: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 25-160: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 25-161: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 25-162: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 25-163: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-164: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 25-165: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 25-166: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-167: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 25-168: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 25-169: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 25-170: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 25-171: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-172: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-173: Loss: 0.2214 Acc: 75.0000%\n",
      "\ttrain 25-174: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 25-175: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 25-176: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 25-177: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 25-178: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-179: Loss: 0.1862 Acc: 75.0000%\n",
      "\ttrain 25-180: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-181: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-182: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 25-183: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 25-184: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 25-185: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 25-186: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-187: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 25-188: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-189: Loss: 0.5385 Acc: 75.0000%\n",
      "\ttrain 25-190: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 25-191: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 25-192: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-193: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 25-194: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-195: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 25-196: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 25-197: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-198: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 25-199: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-200: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-201: Loss: 0.1371 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-202: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 25-203: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 25-204: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 25-205: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 25-206: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 25-207: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 25-208: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-209: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 25-210: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 25-211: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-212: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 25-213: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 25-214: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-215: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-216: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 25-217: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 25-218: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 25-219: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-220: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 25-221: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 25-222: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 25-223: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 25-224: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 25-225: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 25-226: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-227: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 25-228: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 25-229: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 25-230: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-231: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 25-232: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 25-233: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 25-234: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 25-235: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 25-236: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-237: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-238: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 25-239: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 25-240: Loss: 0.1862 Acc: 75.0000%\n",
      "\ttrain 25-241: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 25-242: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 25-243: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 25-244: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 25-245: Loss: 0.8513 Acc: 25.0000%\n",
      "\tvalidation 25-1: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-2: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 25-3: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-4: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 25-5: Loss: 0.0557 Acc: 75.0000%\n",
      "\tvalidation 25-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-7: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 25-8: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 25-9: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 25-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-11: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-12: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 25-13: Loss: 1.4366 Acc: 75.0000%\n",
      "\tvalidation 25-14: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 25-15: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 25-16: Loss: 0.0571 Acc: 75.0000%\n",
      "\tvalidation 25-17: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-18: Loss: 0.0653 Acc: 75.0000%\n",
      "\tvalidation 25-19: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 25-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-21: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 25-22: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 25-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-24: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 25-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-26: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-27: Loss: 0.0663 Acc: 75.0000%\n",
      "\tvalidation 25-28: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 25-29: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 25-30: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-31: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-32: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-33: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-34: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 25-35: Loss: 0.0674 Acc: 100.0000%\n",
      "\tvalidation 25-36: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 25-37: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-38: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 25-39: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-41: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-42: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 25-43: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-45: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-46: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 25-47: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-48: Loss: 0.1022 Acc: 75.0000%\n",
      "\tvalidation 25-49: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-50: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-51: Loss: 0.0643 Acc: 75.0000%\n",
      "\tvalidation 25-52: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 25-53: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-54: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-55: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-56: Loss: 0.0681 Acc: 75.0000%\n",
      "\tvalidation 25-57: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 25-58: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-59: Loss: 0.1509 Acc: 75.0000%\n",
      "\tvalidation 25-60: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-61: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-62: Loss: 2.5305 Acc: 50.0000%\n",
      "\tvalidation 25-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-64: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 25-65: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 25-66: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-68: Loss: 1.7821 Acc: 75.0000%\n",
      "\tvalidation 25-69: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 25-70: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 25-71: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 25-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 25-73: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-74: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 25-76: Loss: 0.1127 Acc: 75.0000%\n",
      "\tvalidation 25-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-78: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-79: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-80: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 25-81: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-82: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-83: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-84: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-85: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-88: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-89: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-90: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-93: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 25-94: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 25-95: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-97: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 25-98: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-99: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 25-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-101: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 25-102: Loss: 0.0617 Acc: 75.0000%\n",
      "\tvalidation 25-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-105: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0486 Acc: 94.4898%\n",
      "\tvalidation Loss: 0.0675 Acc: 96.6667%\n",
      "Time passed 0h 21m 6s\n",
      "--------------------\n",
      "Epoch [26/40]:\n",
      "\ttrain 26-1: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 26-2: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 26-3: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-4: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 26-5: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 26-6: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 26-7: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 26-8: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 26-9: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 26-10: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 26-11: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 26-12: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-13: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 26-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-15: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 26-16: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 26-17: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 26-18: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 26-19: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 26-20: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 26-21: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 26-22: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 26-23: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-24: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 26-25: Loss: 0.2677 Acc: 75.0000%\n",
      "\ttrain 26-26: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 26-27: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 26-28: Loss: 0.2126 Acc: 75.0000%\n",
      "\ttrain 26-29: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 26-30: Loss: 0.1093 Acc: 100.0000%\n",
      "\ttrain 26-31: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 26-32: Loss: 0.0083 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-33: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 26-34: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 26-35: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 26-36: Loss: 0.2417 Acc: 25.0000%\n",
      "\ttrain 26-37: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-38: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-39: Loss: 0.3664 Acc: 75.0000%\n",
      "\ttrain 26-40: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 26-41: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 26-42: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 26-43: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 26-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-45: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-46: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 26-47: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 26-48: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 26-49: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 26-50: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 26-51: Loss: 0.2392 Acc: 75.0000%\n",
      "\ttrain 26-52: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 26-53: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 26-54: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 26-55: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-56: Loss: 0.2688 Acc: 75.0000%\n",
      "\ttrain 26-57: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 26-58: Loss: 0.2600 Acc: 75.0000%\n",
      "\ttrain 26-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-60: Loss: 0.9858 Acc: 50.0000%\n",
      "\ttrain 26-61: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 26-62: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 26-63: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 26-64: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 26-65: Loss: 0.4205 Acc: 75.0000%\n",
      "\ttrain 26-66: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 26-67: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 26-68: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 26-69: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-70: Loss: 0.3643 Acc: 25.0000%\n",
      "\ttrain 26-71: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 26-72: Loss: 0.4752 Acc: 50.0000%\n",
      "\ttrain 26-73: Loss: 0.1701 Acc: 75.0000%\n",
      "\ttrain 26-74: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-75: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 26-76: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 26-77: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 26-78: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 26-79: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-80: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 26-81: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 26-82: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 26-83: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 26-84: Loss: 0.3809 Acc: 50.0000%\n",
      "\ttrain 26-85: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 26-86: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 26-87: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 26-88: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-89: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-90: Loss: 0.1954 Acc: 75.0000%\n",
      "\ttrain 26-91: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 26-92: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-93: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 26-94: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 26-95: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 26-96: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 26-97: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-98: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 26-99: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 26-100: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 26-101: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 26-102: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 26-103: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 26-104: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-105: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 26-106: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 26-107: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 26-108: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 26-109: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 26-110: Loss: 0.2141 Acc: 75.0000%\n",
      "\ttrain 26-111: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-112: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 26-113: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 26-114: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 26-115: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-116: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 26-117: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-118: Loss: 0.3926 Acc: 50.0000%\n",
      "\ttrain 26-119: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 26-120: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 26-121: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 26-122: Loss: 0.2103 Acc: 75.0000%\n",
      "\ttrain 26-123: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 26-124: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-125: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 26-126: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 26-127: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 26-128: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 26-129: Loss: 0.3084 Acc: 50.0000%\n",
      "\ttrain 26-130: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 26-131: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-132: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 26-133: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 26-134: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 26-135: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 26-136: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-137: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 26-138: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 26-139: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-140: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 26-141: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 26-142: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 26-143: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 26-144: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-145: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 26-146: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-147: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 26-148: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 26-149: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 26-150: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-151: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 26-152: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-153: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 26-154: Loss: 0.8019 Acc: 25.0000%\n",
      "\ttrain 26-155: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-156: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 26-157: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 26-158: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 26-159: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 26-160: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 26-161: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 26-162: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-163: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 26-164: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 26-165: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 26-166: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 26-167: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 26-168: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 26-169: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 26-170: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 26-171: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-172: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 26-173: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 26-174: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 26-175: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 26-176: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-177: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-178: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 26-179: Loss: 0.2386 Acc: 75.0000%\n",
      "\ttrain 26-180: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-181: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 26-182: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 26-183: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 26-184: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 26-185: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 26-186: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 26-187: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-188: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 26-189: Loss: 0.0975 Acc: 100.0000%\n",
      "\ttrain 26-190: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 26-191: Loss: 0.1706 Acc: 75.0000%\n",
      "\ttrain 26-192: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 26-193: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-194: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-195: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 26-196: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 26-197: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 26-198: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 26-199: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 26-200: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 26-201: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 26-202: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-203: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 26-204: Loss: 0.2391 Acc: 75.0000%\n",
      "\ttrain 26-205: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-206: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 26-207: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 26-208: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-209: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 26-210: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 26-211: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 26-212: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-213: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-214: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-215: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 26-216: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 26-217: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 26-218: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 26-219: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 26-220: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 26-221: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 26-222: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 26-223: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 26-224: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 26-225: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 26-226: Loss: 0.2228 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-227: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 26-228: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 26-229: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 26-230: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 26-231: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 26-232: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 26-233: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 26-234: Loss: 0.0455 Acc: 75.0000%\n",
      "\ttrain 26-235: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 26-236: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-237: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 26-238: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 26-239: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 26-240: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 26-241: Loss: 0.3995 Acc: 50.0000%\n",
      "\ttrain 26-242: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-243: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-244: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 26-245: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-1: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-2: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-4: Loss: 0.0559 Acc: 75.0000%\n",
      "\tvalidation 26-5: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-6: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-7: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-9: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-10: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 26-11: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 26-13: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 26-14: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 26-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 26-16: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 26-17: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-18: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-19: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 26-20: Loss: 0.5364 Acc: 75.0000%\n",
      "\tvalidation 26-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-22: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 26-23: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-24: Loss: 0.5139 Acc: 75.0000%\n",
      "\tvalidation 26-25: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 26-26: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-27: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-29: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 26-30: Loss: 3.0016 Acc: 75.0000%\n",
      "\tvalidation 26-31: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 26-32: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-33: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 26-34: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 26-35: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 26-36: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-37: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-38: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 26-39: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-40: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-41: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 26-42: Loss: 2.6164 Acc: 75.0000%\n",
      "\tvalidation 26-43: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-44: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-45: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-46: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-47: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-48: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-49: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-50: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-51: Loss: 0.0975 Acc: 75.0000%\n",
      "\tvalidation 26-52: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-53: Loss: 0.1410 Acc: 75.0000%\n",
      "\tvalidation 26-54: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-55: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 26-56: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 26-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-58: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-59: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-60: Loss: 2.3395 Acc: 50.0000%\n",
      "\tvalidation 26-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-62: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 26-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-65: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-66: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 26-67: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 26-68: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-69: Loss: 0.1963 Acc: 75.0000%\n",
      "\tvalidation 26-70: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-71: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-72: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 26-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-74: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-75: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 26-76: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-77: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-78: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 26-79: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 26-80: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-81: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-82: Loss: 0.6865 Acc: 75.0000%\n",
      "\tvalidation 26-83: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-84: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 26-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-86: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 26-87: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-88: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-89: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 26-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-91: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-92: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 26-93: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 26-94: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 26-95: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 26-96: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 26-98: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 26-99: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-100: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-101: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-102: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-104: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 26-105: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0580 Acc: 92.6531%\n",
      "\tvalidation Loss: 0.1004 Acc: 97.1429%\n",
      "Time passed 0h 21m 46s\n",
      "--------------------\n",
      "Epoch [27/40]:\n",
      "\ttrain 27-1: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 27-2: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 27-3: Loss: 0.1674 Acc: 75.0000%\n",
      "\ttrain 27-4: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 27-5: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-6: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-7: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-8: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 27-9: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-10: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 27-11: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-12: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 27-13: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 27-14: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 27-15: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 27-16: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 27-17: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 27-18: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 27-19: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 27-20: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 27-21: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 27-22: Loss: 0.1435 Acc: 75.0000%\n",
      "\ttrain 27-23: Loss: 0.2607 Acc: 75.0000%\n",
      "\ttrain 27-24: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 27-25: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 27-26: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 27-27: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 27-28: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 27-29: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-30: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-31: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 27-32: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 27-33: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 27-34: Loss: 0.5357 Acc: 50.0000%\n",
      "\ttrain 27-35: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 27-36: Loss: 0.3366 Acc: 75.0000%\n",
      "\ttrain 27-37: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 27-38: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 27-39: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 27-40: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 27-41: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 27-42: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 27-43: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 27-44: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-45: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 27-46: Loss: 0.1753 Acc: 75.0000%\n",
      "\ttrain 27-47: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 27-48: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 27-49: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 27-50: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 27-51: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 27-52: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 27-53: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 27-54: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 27-55: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 27-56: Loss: 0.2763 Acc: 75.0000%\n",
      "\ttrain 27-57: Loss: 0.0019 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-58: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 27-59: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-60: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 27-61: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 27-62: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 27-63: Loss: 0.0470 Acc: 75.0000%\n",
      "\ttrain 27-64: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 27-65: Loss: 0.2318 Acc: 75.0000%\n",
      "\ttrain 27-66: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 27-67: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 27-68: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 27-69: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 27-70: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 27-71: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 27-72: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 27-73: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 27-74: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 27-75: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 27-76: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 27-77: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 27-78: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-79: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 27-80: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 27-81: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 27-82: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-83: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-84: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 27-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 27-86: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 27-87: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 27-88: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 27-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 27-90: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 27-91: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 27-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 27-93: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 27-94: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 27-95: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 27-97: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-98: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-99: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 27-100: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 27-101: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-102: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 27-103: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 27-104: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 27-105: Loss: 0.3871 Acc: 75.0000%\n",
      "\ttrain 27-106: Loss: 0.4935 Acc: 25.0000%\n",
      "\ttrain 27-107: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-108: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-109: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 27-110: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-111: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 27-112: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 27-113: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 27-114: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-115: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-116: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 27-117: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 27-118: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 27-119: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 27-120: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-121: Loss: 0.4725 Acc: 25.0000%\n",
      "\ttrain 27-122: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 27-123: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 27-124: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 27-125: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 27-126: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 27-127: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 27-128: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-129: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 27-130: Loss: 0.0655 Acc: 100.0000%\n",
      "\ttrain 27-131: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 27-132: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-133: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 27-134: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 27-135: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 27-136: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 27-137: Loss: 0.1638 Acc: 75.0000%\n",
      "\ttrain 27-138: Loss: 0.0721 Acc: 75.0000%\n",
      "\ttrain 27-139: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-140: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-141: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 27-142: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 27-143: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 27-144: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 27-145: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 27-146: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-147: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 27-148: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 27-149: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 27-150: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 27-151: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 27-152: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 27-153: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 27-154: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-155: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-156: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 27-157: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-158: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-159: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-160: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-161: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 27-162: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-163: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 27-164: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-165: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 27-166: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 27-167: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 27-168: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 27-169: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 27-170: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 27-171: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 27-172: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 27-173: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-174: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 27-175: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 27-176: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 27-177: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 27-178: Loss: 0.2634 Acc: 50.0000%\n",
      "\ttrain 27-179: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 27-180: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 27-181: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 27-182: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 27-183: Loss: 0.4606 Acc: 25.0000%\n",
      "\ttrain 27-184: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 27-185: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 27-186: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 27-187: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-188: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 27-189: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 27-190: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 27-191: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-192: Loss: 0.2898 Acc: 75.0000%\n",
      "\ttrain 27-193: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 27-194: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 27-195: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 27-196: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 27-197: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-198: Loss: 0.3373 Acc: 25.0000%\n",
      "\ttrain 27-199: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 27-200: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 27-201: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 27-202: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 27-203: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 27-204: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 27-205: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 27-206: Loss: 0.3165 Acc: 50.0000%\n",
      "\ttrain 27-207: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-208: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 27-209: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 27-210: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 27-211: Loss: 0.0545 Acc: 75.0000%\n",
      "\ttrain 27-212: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 27-213: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 27-214: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 27-215: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-216: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 27-217: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 27-218: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-219: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 27-220: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 27-221: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 27-222: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 27-223: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 27-224: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-225: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 27-226: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-227: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-228: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 27-229: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 27-230: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 27-231: Loss: 0.3385 Acc: 50.0000%\n",
      "\ttrain 27-232: Loss: 0.3219 Acc: 50.0000%\n",
      "\ttrain 27-233: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-234: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 27-235: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-236: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-237: Loss: 0.0446 Acc: 75.0000%\n",
      "\ttrain 27-238: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 27-239: Loss: 0.3623 Acc: 50.0000%\n",
      "\ttrain 27-240: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 27-241: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 27-242: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 27-243: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 27-244: Loss: 0.2311 Acc: 75.0000%\n",
      "\ttrain 27-245: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 27-1: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 27-2: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-3: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 27-4: Loss: 0.1102 Acc: 75.0000%\n",
      "\tvalidation 27-5: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 27-6: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 27-7: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 27-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-9: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 27-10: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-11: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 27-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-13: Loss: 0.3633 Acc: 75.0000%\n",
      "\tvalidation 27-14: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-15: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 27-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-17: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 27-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-20: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 27-21: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-22: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 27-23: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 27-24: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-29: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 27-30: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 27-31: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 27-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-33: Loss: 0.0807 Acc: 75.0000%\n",
      "\tvalidation 27-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-35: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 27-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-38: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 27-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-40: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 27-41: Loss: 0.0464 Acc: 75.0000%\n",
      "\tvalidation 27-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-46: Loss: 0.1815 Acc: 75.0000%\n",
      "\tvalidation 27-47: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 27-48: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-49: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-50: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 27-51: Loss: 0.5727 Acc: 75.0000%\n",
      "\tvalidation 27-52: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 27-53: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-54: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-55: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-56: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 27-57: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 27-58: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-59: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 27-60: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-62: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-65: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 27-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-67: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 27-68: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 27-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-71: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 27-72: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 27-73: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-74: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 27-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-76: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 27-77: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-80: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 27-81: Loss: 0.0648 Acc: 75.0000%\n",
      "\tvalidation 27-82: Loss: 0.0577 Acc: 75.0000%\n",
      "\tvalidation 27-83: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-86: Loss: 0.1403 Acc: 75.0000%\n",
      "\tvalidation 27-87: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-89: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 27-90: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 27-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-93: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-94: Loss: 0.7923 Acc: 75.0000%\n",
      "\tvalidation 27-95: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 27-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-98: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 27-99: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-100: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-101: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 27-102: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-103: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 27-104: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-105: Loss: 0.1176 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0459 Acc: 94.4898%\n",
      "\tvalidation Loss: 0.0276 Acc: 97.3810%\n",
      "Time passed 0h 22m 25s\n",
      "--------------------\n",
      "Epoch [28/40]:\n",
      "\ttrain 28-1: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 28-2: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 28-3: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 28-4: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-5: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-6: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-7: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 28-8: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 28-9: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 28-10: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-11: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 28-12: Loss: 0.2956 Acc: 75.0000%\n",
      "\ttrain 28-13: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 28-14: Loss: 0.3778 Acc: 75.0000%\n",
      "\ttrain 28-15: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 28-16: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 28-17: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 28-18: Loss: 0.0611 Acc: 75.0000%\n",
      "\ttrain 28-19: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 28-20: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-21: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 28-22: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 28-23: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 28-24: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 28-25: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 28-26: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 28-27: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 28-28: Loss: 0.1936 Acc: 50.0000%\n",
      "\ttrain 28-29: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 28-30: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 28-31: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 28-32: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 28-33: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 28-34: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-35: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 28-36: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 28-37: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 28-38: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 28-39: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 28-40: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 28-41: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 28-42: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 28-43: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 28-44: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 28-45: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-46: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 28-47: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 28-48: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 28-49: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-50: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-51: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 28-52: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 28-53: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 28-54: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 28-55: Loss: 1.3526 Acc: 75.0000%\n",
      "\ttrain 28-56: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 28-57: Loss: 0.0492 Acc: 75.0000%\n",
      "\ttrain 28-58: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 28-59: Loss: 0.6320 Acc: 50.0000%\n",
      "\ttrain 28-60: Loss: 0.3552 Acc: 75.0000%\n",
      "\ttrain 28-61: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 28-62: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 28-63: Loss: 0.0674 Acc: 100.0000%\n",
      "\ttrain 28-64: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 28-65: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 28-66: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 28-67: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 28-68: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 28-69: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 28-70: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 28-71: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 28-72: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 28-73: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-74: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 28-75: Loss: 0.0673 Acc: 75.0000%\n",
      "\ttrain 28-76: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 28-77: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 28-78: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 28-79: Loss: 0.1208 Acc: 50.0000%\n",
      "\ttrain 28-80: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 28-81: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 28-82: Loss: 0.1615 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-83: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 28-84: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 28-85: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 28-86: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 28-87: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 28-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-89: Loss: 0.3596 Acc: 50.0000%\n",
      "\ttrain 28-90: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-91: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 28-92: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 28-93: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-94: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 28-95: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 28-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 28-97: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 28-98: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 28-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-100: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 28-101: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 28-102: Loss: 0.1603 Acc: 75.0000%\n",
      "\ttrain 28-103: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 28-104: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 28-105: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 28-106: Loss: 1.0232 Acc: 50.0000%\n",
      "\ttrain 28-107: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 28-108: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-109: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 28-110: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 28-111: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 28-112: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 28-113: Loss: 0.2001 Acc: 75.0000%\n",
      "\ttrain 28-114: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 28-115: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 28-116: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 28-117: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 28-118: Loss: 0.3355 Acc: 25.0000%\n",
      "\ttrain 28-119: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 28-120: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 28-121: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 28-122: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 28-123: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 28-124: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 28-125: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 28-126: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-127: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 28-128: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 28-129: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 28-130: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 28-131: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-132: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 28-133: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 28-134: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 28-135: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 28-136: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 28-137: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 28-138: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 28-139: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 28-140: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 28-141: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 28-142: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 28-143: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 28-144: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 28-145: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 28-146: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 28-147: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 28-148: Loss: 0.3115 Acc: 75.0000%\n",
      "\ttrain 28-149: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 28-150: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-151: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 28-152: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-153: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-154: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 28-155: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 28-156: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 28-157: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 28-158: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 28-159: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 28-160: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 28-161: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-162: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 28-163: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 28-164: Loss: 0.1502 Acc: 75.0000%\n",
      "\ttrain 28-165: Loss: 0.2204 Acc: 50.0000%\n",
      "\ttrain 28-166: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 28-167: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 28-168: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 28-169: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-170: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 28-171: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-172: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 28-173: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 28-174: Loss: 0.3734 Acc: 75.0000%\n",
      "\ttrain 28-175: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 28-176: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-177: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-178: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 28-179: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 28-180: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 28-181: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 28-182: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-183: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 28-184: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-185: Loss: 0.4880 Acc: 50.0000%\n",
      "\ttrain 28-186: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 28-187: Loss: 0.7446 Acc: 25.0000%\n",
      "\ttrain 28-188: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 28-189: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 28-190: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 28-191: Loss: 0.5516 Acc: 75.0000%\n",
      "\ttrain 28-192: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 28-193: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-194: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 28-195: Loss: 0.1854 Acc: 75.0000%\n",
      "\ttrain 28-196: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-197: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 28-198: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 28-199: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 28-200: Loss: 0.0613 Acc: 100.0000%\n",
      "\ttrain 28-201: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 28-202: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 28-203: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 28-204: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-205: Loss: 0.1134 Acc: 50.0000%\n",
      "\ttrain 28-206: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 28-207: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 28-208: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 28-209: Loss: 0.9811 Acc: 25.0000%\n",
      "\ttrain 28-210: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-211: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 28-212: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 28-213: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 28-214: Loss: 0.2180 Acc: 75.0000%\n",
      "\ttrain 28-215: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 28-216: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 28-217: Loss: 0.0748 Acc: 100.0000%\n",
      "\ttrain 28-218: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 28-219: Loss: 0.1571 Acc: 75.0000%\n",
      "\ttrain 28-220: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 28-221: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 28-222: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-223: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 28-224: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 28-225: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 28-226: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 28-227: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-228: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-229: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 28-230: Loss: 0.3031 Acc: 50.0000%\n",
      "\ttrain 28-231: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-232: Loss: 0.3302 Acc: 75.0000%\n",
      "\ttrain 28-233: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 28-234: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-235: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-236: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 28-237: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 28-238: Loss: 0.2280 Acc: 75.0000%\n",
      "\ttrain 28-239: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 28-240: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 28-241: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 28-242: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 28-243: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-244: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 28-245: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 28-1: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 28-2: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 28-3: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 28-4: Loss: 0.1178 Acc: 75.0000%\n",
      "\tvalidation 28-5: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 28-6: Loss: 0.8170 Acc: 75.0000%\n",
      "\tvalidation 28-7: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 28-8: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 28-9: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 28-10: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 28-11: Loss: 0.0670 Acc: 75.0000%\n",
      "\tvalidation 28-12: Loss: 0.0769 Acc: 75.0000%\n",
      "\tvalidation 28-13: Loss: 0.0505 Acc: 75.0000%\n",
      "\tvalidation 28-14: Loss: 0.0819 Acc: 75.0000%\n",
      "\tvalidation 28-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-16: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 28-17: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 28-18: Loss: 0.8494 Acc: 75.0000%\n",
      "\tvalidation 28-19: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 28-20: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 28-21: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 28-22: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 28-23: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 28-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-25: Loss: 0.1090 Acc: 75.0000%\n",
      "\tvalidation 28-26: Loss: 0.0342 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 28-27: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 28-28: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 28-29: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 28-30: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-31: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 28-32: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 28-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-34: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-35: Loss: 0.1256 Acc: 75.0000%\n",
      "\tvalidation 28-36: Loss: 0.0464 Acc: 100.0000%\n",
      "\tvalidation 28-37: Loss: 0.1107 Acc: 75.0000%\n",
      "\tvalidation 28-38: Loss: 0.1289 Acc: 75.0000%\n",
      "\tvalidation 28-39: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-40: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 28-41: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-42: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-43: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 28-44: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 28-45: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 28-46: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 28-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-48: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 28-49: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 28-50: Loss: 0.0863 Acc: 75.0000%\n",
      "\tvalidation 28-51: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 28-52: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 28-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-54: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 28-55: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 28-56: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 28-57: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 28-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-59: Loss: 0.0551 Acc: 75.0000%\n",
      "\tvalidation 28-60: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 28-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-62: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 28-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-64: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 28-65: Loss: 0.1929 Acc: 75.0000%\n",
      "\tvalidation 28-66: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-67: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 28-68: Loss: 0.0987 Acc: 75.0000%\n",
      "\tvalidation 28-69: Loss: 0.0647 Acc: 75.0000%\n",
      "\tvalidation 28-70: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 28-71: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-73: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 28-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-75: Loss: 0.1507 Acc: 75.0000%\n",
      "\tvalidation 28-76: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 28-77: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 28-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-79: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 28-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-81: Loss: 0.0907 Acc: 75.0000%\n",
      "\tvalidation 28-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-84: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 28-85: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 28-86: Loss: 0.0603 Acc: 75.0000%\n",
      "\tvalidation 28-87: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-89: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 28-90: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 28-91: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 28-92: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 28-93: Loss: 1.2423 Acc: 75.0000%\n",
      "\tvalidation 28-94: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-95: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 28-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-97: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 28-98: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 28-99: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 28-100: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 28-101: Loss: 0.0495 Acc: 75.0000%\n",
      "\tvalidation 28-102: Loss: 0.1000 Acc: 75.0000%\n",
      "\tvalidation 28-103: Loss: 0.0783 Acc: 75.0000%\n",
      "\tvalidation 28-104: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 28-105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0678 Acc: 92.9592%\n",
      "\tvalidation Loss: 0.0558 Acc: 93.8095%\n",
      "Time passed 0h 23m 4s\n",
      "--------------------\n",
      "Epoch [29/40]:\n",
      "\ttrain 29-1: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-2: Loss: 0.3485 Acc: 50.0000%\n",
      "\ttrain 29-3: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 29-4: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 29-5: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 29-6: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 29-7: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 29-8: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 29-9: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 29-10: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-11: Loss: 0.1825 Acc: 75.0000%\n",
      "\ttrain 29-12: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 29-13: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 29-14: Loss: 0.2997 Acc: 75.0000%\n",
      "\ttrain 29-15: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 29-16: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-18: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 29-19: Loss: 0.0447 Acc: 75.0000%\n",
      "\ttrain 29-20: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 29-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-22: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 29-23: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 29-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-25: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 29-26: Loss: 0.2185 Acc: 75.0000%\n",
      "\ttrain 29-27: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-28: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-29: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 29-30: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 29-31: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-32: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 29-33: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 29-34: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 29-35: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 29-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-37: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 29-38: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-39: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 29-40: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-43: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 29-44: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-45: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 29-46: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 29-47: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 29-48: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 29-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-50: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 29-51: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 29-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-53: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-54: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 29-55: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-56: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-58: Loss: 0.6625 Acc: 75.0000%\n",
      "\ttrain 29-59: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-60: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-61: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 29-62: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 29-63: Loss: 0.1225 Acc: 50.0000%\n",
      "\ttrain 29-64: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 29-65: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 29-66: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-67: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 29-68: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 29-69: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 29-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-71: Loss: 0.1295 Acc: 50.0000%\n",
      "\ttrain 29-72: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 29-73: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 29-74: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 29-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-76: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 29-77: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-78: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 29-79: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-80: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-81: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 29-82: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 29-83: Loss: 0.2760 Acc: 75.0000%\n",
      "\ttrain 29-84: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-85: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-87: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-88: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 29-89: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-90: Loss: 0.2627 Acc: 75.0000%\n",
      "\ttrain 29-91: Loss: 0.0671 Acc: 75.0000%\n",
      "\ttrain 29-92: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-93: Loss: 0.2506 Acc: 75.0000%\n",
      "\ttrain 29-94: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 29-95: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 29-96: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 29-97: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-98: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 29-99: Loss: 0.7813 Acc: 75.0000%\n",
      "\ttrain 29-100: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 29-101: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 29-102: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 29-103: Loss: 0.0541 Acc: 75.0000%\n",
      "\ttrain 29-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-105: Loss: 0.0181 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-106: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 29-107: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 29-108: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 29-109: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 29-110: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-111: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-112: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 29-113: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 29-114: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-115: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 29-116: Loss: 0.1580 Acc: 75.0000%\n",
      "\ttrain 29-117: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 29-118: Loss: 0.1153 Acc: 50.0000%\n",
      "\ttrain 29-119: Loss: 0.1045 Acc: 75.0000%\n",
      "\ttrain 29-120: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-121: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 29-122: Loss: 0.2141 Acc: 75.0000%\n",
      "\ttrain 29-123: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 29-124: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 29-125: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 29-126: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 29-127: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 29-128: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 29-129: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 29-130: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 29-131: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 29-132: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 29-133: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 29-134: Loss: 0.2886 Acc: 75.0000%\n",
      "\ttrain 29-135: Loss: 0.4271 Acc: 50.0000%\n",
      "\ttrain 29-136: Loss: 0.3714 Acc: 50.0000%\n",
      "\ttrain 29-137: Loss: 0.5990 Acc: 75.0000%\n",
      "\ttrain 29-138: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 29-139: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 29-140: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 29-141: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 29-142: Loss: 0.1687 Acc: 75.0000%\n",
      "\ttrain 29-143: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-144: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 29-145: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 29-146: Loss: 0.4348 Acc: 75.0000%\n",
      "\ttrain 29-147: Loss: 0.4551 Acc: 50.0000%\n",
      "\ttrain 29-148: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 29-149: Loss: 0.6932 Acc: 50.0000%\n",
      "\ttrain 29-150: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 29-151: Loss: 0.6083 Acc: 50.0000%\n",
      "\ttrain 29-152: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-153: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 29-154: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 29-155: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 29-156: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 29-157: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-158: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-159: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-160: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 29-161: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 29-162: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-163: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-164: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 29-165: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-166: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 29-167: Loss: 0.1810 Acc: 75.0000%\n",
      "\ttrain 29-168: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 29-169: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 29-170: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 29-171: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 29-172: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 29-173: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 29-174: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-175: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-176: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 29-177: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-178: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 29-179: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 29-180: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 29-181: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 29-182: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 29-183: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-184: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 29-185: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 29-186: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 29-187: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-188: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 29-189: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-190: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 29-191: Loss: 0.1815 Acc: 75.0000%\n",
      "\ttrain 29-192: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 29-193: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-194: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 29-195: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 29-196: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 29-197: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-198: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 29-199: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-200: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 29-201: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 29-202: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-203: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 29-204: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-205: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 29-206: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 29-207: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 29-208: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 29-209: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 29-210: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-211: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 29-212: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-213: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 29-214: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 29-215: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 29-216: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 29-217: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-218: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 29-219: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 29-220: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 29-221: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 29-222: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-223: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-224: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 29-225: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-226: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 29-227: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 29-228: Loss: 0.1571 Acc: 75.0000%\n",
      "\ttrain 29-229: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 29-230: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 29-231: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-232: Loss: 0.1822 Acc: 75.0000%\n",
      "\ttrain 29-233: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-234: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-235: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-236: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 29-237: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 29-238: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-239: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 29-240: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 29-241: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-242: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-243: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 29-244: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 29-245: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 29-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-5: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 29-6: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 29-7: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-11: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-12: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 29-13: Loss: 1.5537 Acc: 75.0000%\n",
      "\tvalidation 29-14: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-15: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-16: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-19: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 29-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-22: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-23: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-24: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 29-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-26: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 29-27: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 29-28: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-29: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-31: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-33: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-34: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-37: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-38: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-41: Loss: 1.1659 Acc: 75.0000%\n",
      "\tvalidation 29-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-43: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-47: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 29-48: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 29-49: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-50: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-51: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-52: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-53: Loss: 0.0025 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 29-54: Loss: 0.0613 Acc: 100.0000%\n",
      "\tvalidation 29-55: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-56: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-58: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-60: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-62: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 29-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-64: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 29-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-66: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 29-67: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-68: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-69: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 29-70: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 29-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-72: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 29-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-74: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 29-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-76: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 29-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-79: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-80: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 29-81: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-82: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-83: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 29-84: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-87: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-88: Loss: 1.3478 Acc: 75.0000%\n",
      "\tvalidation 29-89: Loss: 0.0649 Acc: 75.0000%\n",
      "\tvalidation 29-90: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 29-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-92: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 29-93: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 29-94: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-96: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 29-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-102: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 29-103: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-105: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0618 Acc: 92.0408%\n",
      "\tvalidation Loss: 0.0419 Acc: 99.0476%\n",
      "网络参数更新\n",
      "Time passed 0h 23m 45s\n",
      "--------------------\n",
      "Epoch [30/40]:\n",
      "\ttrain 30-1: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 30-2: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-3: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 30-4: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-6: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-7: Loss: 0.3853 Acc: 25.0000%\n",
      "\ttrain 30-8: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 30-9: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 30-10: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 30-11: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 30-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-13: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 30-14: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 30-15: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 30-16: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 30-17: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-18: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 30-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-20: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-21: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-22: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-23: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 30-24: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 30-25: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 30-26: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 30-27: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-28: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 30-29: Loss: 0.3490 Acc: 50.0000%\n",
      "\ttrain 30-30: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 30-31: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-32: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 30-33: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 30-34: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 30-35: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-36: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 30-37: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 30-38: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 30-39: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 30-40: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-41: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 30-42: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 30-43: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 30-44: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-45: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-46: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 30-47: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-48: Loss: 0.2259 Acc: 75.0000%\n",
      "\ttrain 30-49: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 30-50: Loss: 0.0563 Acc: 75.0000%\n",
      "\ttrain 30-51: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 30-52: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 30-53: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-54: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-55: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 30-56: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 30-57: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-58: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-59: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-60: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-61: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 30-62: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-63: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 30-64: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 30-65: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 30-66: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-67: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-68: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 30-69: Loss: 0.0543 Acc: 75.0000%\n",
      "\ttrain 30-70: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 30-71: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 30-72: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 30-73: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 30-74: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 30-75: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-76: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 30-77: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-78: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-79: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 30-80: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 30-81: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 30-82: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 30-83: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-84: Loss: 0.1837 Acc: 75.0000%\n",
      "\ttrain 30-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-86: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 30-87: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-88: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 30-89: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 30-90: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 30-91: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 30-92: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 30-93: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 30-94: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-95: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 30-96: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-97: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-98: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 30-99: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 30-100: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 30-101: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 30-102: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 30-103: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-104: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 30-105: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-106: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 30-107: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 30-108: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-109: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 30-110: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 30-111: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 30-112: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-113: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 30-114: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 30-115: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 30-116: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-117: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 30-118: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-119: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 30-120: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 30-121: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-122: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 30-123: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-124: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 30-125: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-126: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 30-127: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 30-128: Loss: 0.1533 Acc: 50.0000%\n",
      "\ttrain 30-129: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 30-130: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-131: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 30-132: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 30-133: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 30-134: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 30-135: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 30-136: Loss: 0.0139 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 30-137: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 30-138: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 30-139: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-140: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-141: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 30-142: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 30-143: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-144: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-145: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 30-146: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 30-147: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 30-148: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 30-149: Loss: 0.1907 Acc: 75.0000%\n",
      "\ttrain 30-150: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-151: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-152: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 30-153: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-154: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 30-155: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 30-156: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 30-157: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 30-158: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 30-159: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 30-160: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 30-161: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 30-162: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 30-163: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-164: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 30-165: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 30-166: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 30-167: Loss: 0.2272 Acc: 25.0000%\n",
      "\ttrain 30-168: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 30-169: Loss: 0.8097 Acc: 75.0000%\n",
      "\ttrain 30-170: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 30-171: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 30-172: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-173: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-174: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-175: Loss: 0.1597 Acc: 75.0000%\n",
      "\ttrain 30-176: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 30-177: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 30-178: Loss: 0.2378 Acc: 50.0000%\n",
      "\ttrain 30-179: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-180: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 30-181: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-182: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 30-183: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 30-184: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 30-185: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 30-186: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-187: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 30-188: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-189: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 30-190: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-191: Loss: 0.1535 Acc: 75.0000%\n",
      "\ttrain 30-192: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 30-193: Loss: 0.4133 Acc: 50.0000%\n",
      "\ttrain 30-194: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 30-195: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-196: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 30-197: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 30-198: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 30-199: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-200: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-201: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 30-202: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 30-203: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-204: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-205: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 30-206: Loss: 0.1455 Acc: 50.0000%\n",
      "\ttrain 30-207: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 30-208: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-209: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-210: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 30-211: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-212: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-213: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 30-214: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-215: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 30-216: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 30-217: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-218: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 30-219: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 30-220: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-221: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-222: Loss: 0.9504 Acc: 25.0000%\n",
      "\ttrain 30-223: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 30-224: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-225: Loss: 0.2815 Acc: 75.0000%\n",
      "\ttrain 30-226: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 30-227: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-228: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-229: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 30-230: Loss: 0.0537 Acc: 75.0000%\n",
      "\ttrain 30-231: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 30-232: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-233: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-234: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-235: Loss: 0.3534 Acc: 75.0000%\n",
      "\ttrain 30-236: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-237: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 30-238: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-239: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 30-240: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-241: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-242: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 30-243: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 30-244: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-245: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 30-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-2: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-3: Loss: 1.5890 Acc: 75.0000%\n",
      "\tvalidation 30-4: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 30-5: Loss: 4.7950 Acc: 75.0000%\n",
      "\tvalidation 30-6: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-7: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 30-8: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-9: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 30-10: Loss: 6.2124 Acc: 75.0000%\n",
      "\tvalidation 30-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-12: Loss: 2.0173 Acc: 75.0000%\n",
      "\tvalidation 30-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-15: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-17: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-20: Loss: 0.1591 Acc: 75.0000%\n",
      "\tvalidation 30-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-24: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 30-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-26: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-27: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 30-28: Loss: 5.2304 Acc: 75.0000%\n",
      "\tvalidation 30-29: Loss: 0.5002 Acc: 75.0000%\n",
      "\tvalidation 30-30: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-32: Loss: 0.8372 Acc: 75.0000%\n",
      "\tvalidation 30-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-37: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-38: Loss: 0.0749 Acc: 75.0000%\n",
      "\tvalidation 30-39: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-40: Loss: 0.7432 Acc: 75.0000%\n",
      "\tvalidation 30-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-44: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-45: Loss: 0.1908 Acc: 75.0000%\n",
      "\tvalidation 30-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-47: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-48: Loss: 0.9299 Acc: 75.0000%\n",
      "\tvalidation 30-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-50: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-51: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 30-52: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 30-53: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-56: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-57: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 30-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-60: Loss: 1.4372 Acc: 75.0000%\n",
      "\tvalidation 30-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-62: Loss: 0.6909 Acc: 75.0000%\n",
      "\tvalidation 30-63: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-65: Loss: 1.3232 Acc: 75.0000%\n",
      "\tvalidation 30-66: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 30-67: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 30-68: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-70: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-73: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-75: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 30-76: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-78: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 30-79: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-81: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-82: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-83: Loss: 0.5071 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 30-84: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 30-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-87: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 30-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-89: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-90: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-93: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-95: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 30-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-99: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-100: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 30-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-102: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-103: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 30-104: Loss: 0.1291 Acc: 75.0000%\n",
      "\tvalidation 30-105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0432 Acc: 93.8776%\n",
      "\tvalidation Loss: 0.2622 Acc: 95.9524%\n",
      "Time passed 0h 24m 25s\n",
      "--------------------\n",
      "Epoch [31/40]:\n",
      "\ttrain 31-1: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-2: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 31-3: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 31-4: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 31-5: Loss: 0.3978 Acc: 75.0000%\n",
      "\ttrain 31-6: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 31-7: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 31-8: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-9: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 31-10: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-11: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-13: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-14: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 31-15: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 31-16: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-17: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 31-18: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 31-19: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-20: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 31-21: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 31-22: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 31-23: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 31-24: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 31-25: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 31-26: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 31-27: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 31-28: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 31-29: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 31-30: Loss: 0.3534 Acc: 50.0000%\n",
      "\ttrain 31-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-33: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 31-34: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 31-35: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 31-36: Loss: 0.2397 Acc: 75.0000%\n",
      "\ttrain 31-37: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 31-38: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-39: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 31-40: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 31-41: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 31-42: Loss: 0.2554 Acc: 75.0000%\n",
      "\ttrain 31-43: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 31-44: Loss: 0.3841 Acc: 50.0000%\n",
      "\ttrain 31-45: Loss: 0.0506 Acc: 75.0000%\n",
      "\ttrain 31-46: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 31-47: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-48: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 31-49: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-50: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-51: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-52: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 31-53: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-54: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 31-55: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 31-56: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 31-57: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-58: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 31-59: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 31-60: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 31-61: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 31-62: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 31-63: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 31-64: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 31-65: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-66: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 31-67: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 31-68: Loss: 0.0575 Acc: 75.0000%\n",
      "\ttrain 31-69: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 31-70: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 31-71: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 31-72: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 31-73: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 31-74: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-75: Loss: 0.2295 Acc: 75.0000%\n",
      "\ttrain 31-76: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-77: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-78: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 31-79: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 31-80: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 31-81: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-82: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-83: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-84: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-85: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 31-86: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-87: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 31-88: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 31-89: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 31-90: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 31-91: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 31-92: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-93: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-94: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 31-95: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-96: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-97: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 31-98: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 31-99: Loss: 0.2220 Acc: 75.0000%\n",
      "\ttrain 31-100: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-101: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 31-102: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 31-103: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 31-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-105: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 31-106: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 31-107: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-108: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 31-109: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 31-110: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 31-111: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 31-112: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 31-113: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 31-114: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 31-115: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 31-116: Loss: 0.2151 Acc: 75.0000%\n",
      "\ttrain 31-117: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-118: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 31-119: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 31-120: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-121: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 31-122: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-123: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 31-124: Loss: 0.0540 Acc: 75.0000%\n",
      "\ttrain 31-125: Loss: 0.2275 Acc: 75.0000%\n",
      "\ttrain 31-126: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 31-127: Loss: 0.2631 Acc: 75.0000%\n",
      "\ttrain 31-128: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-129: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-130: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-131: Loss: 0.1894 Acc: 75.0000%\n",
      "\ttrain 31-132: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-133: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 31-134: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 31-135: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 31-136: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 31-137: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-138: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 31-139: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-140: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 31-141: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 31-142: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 31-143: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 31-144: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-145: Loss: 0.1639 Acc: 50.0000%\n",
      "\ttrain 31-146: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-147: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-148: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 31-149: Loss: 0.1599 Acc: 75.0000%\n",
      "\ttrain 31-150: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-151: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-152: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-153: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-154: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-155: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-156: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 31-157: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 31-158: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 31-159: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-160: Loss: 0.2251 Acc: 75.0000%\n",
      "\ttrain 31-161: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 31-162: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-163: Loss: 0.2868 Acc: 75.0000%\n",
      "\ttrain 31-164: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 31-165: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-166: Loss: 0.1453 Acc: 50.0000%\n",
      "\ttrain 31-167: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 31-168: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-169: Loss: 0.0708 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-170: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-171: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 31-172: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-173: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-174: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-175: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 31-176: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 31-177: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-178: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 31-179: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 31-180: Loss: 0.1837 Acc: 75.0000%\n",
      "\ttrain 31-181: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 31-182: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-183: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 31-184: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 31-185: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-186: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 31-187: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 31-188: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-189: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 31-190: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-191: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 31-192: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-193: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 31-194: Loss: 0.1502 Acc: 50.0000%\n",
      "\ttrain 31-195: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 31-196: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 31-197: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 31-198: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-199: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 31-200: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 31-201: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-202: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 31-203: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 31-204: Loss: 0.2322 Acc: 75.0000%\n",
      "\ttrain 31-205: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-206: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-207: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-208: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-209: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-210: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 31-211: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 31-212: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-213: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 31-214: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 31-215: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-216: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 31-217: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-218: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-219: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 31-220: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 31-221: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 31-222: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-223: Loss: 0.3164 Acc: 75.0000%\n",
      "\ttrain 31-224: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-225: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 31-226: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 31-227: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 31-228: Loss: 0.0445 Acc: 75.0000%\n",
      "\ttrain 31-229: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-230: Loss: 0.1916 Acc: 75.0000%\n",
      "\ttrain 31-231: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 31-232: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 31-233: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-234: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 31-235: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 31-236: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 31-237: Loss: 0.1834 Acc: 75.0000%\n",
      "\ttrain 31-238: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 31-239: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-240: Loss: 0.2084 Acc: 50.0000%\n",
      "\ttrain 31-241: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 31-242: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 31-243: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-244: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-245: Loss: 0.0838 Acc: 75.0000%\n",
      "\tvalidation 31-1: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 31-2: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 31-3: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 31-4: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 31-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-6: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 31-7: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 31-8: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-9: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-10: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 31-11: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 31-12: Loss: 0.2681 Acc: 75.0000%\n",
      "\tvalidation 31-13: Loss: 0.2077 Acc: 75.0000%\n",
      "\tvalidation 31-14: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 31-15: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-17: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 31-18: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 31-19: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-20: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-21: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 31-22: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 31-23: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 31-24: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-25: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 31-26: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 31-27: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-28: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 31-29: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 31-30: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-31: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-32: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-33: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 31-34: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 31-35: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-36: Loss: 0.1989 Acc: 75.0000%\n",
      "\tvalidation 31-37: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 31-38: Loss: 0.0536 Acc: 75.0000%\n",
      "\tvalidation 31-39: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 31-40: Loss: 0.1466 Acc: 75.0000%\n",
      "\tvalidation 31-41: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 31-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-44: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-45: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 31-46: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 31-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-48: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 31-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-52: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-53: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 31-54: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-55: Loss: 0.3204 Acc: 75.0000%\n",
      "\tvalidation 31-56: Loss: 0.0775 Acc: 75.0000%\n",
      "\tvalidation 31-57: Loss: 0.4411 Acc: 75.0000%\n",
      "\tvalidation 31-58: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 31-59: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-60: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 31-61: Loss: 0.1252 Acc: 75.0000%\n",
      "\tvalidation 31-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-63: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 31-64: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-66: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 31-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-68: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 31-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-70: Loss: 1.1112 Acc: 75.0000%\n",
      "\tvalidation 31-71: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-72: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 31-73: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 31-74: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 31-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-79: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-80: Loss: 0.9184 Acc: 75.0000%\n",
      "\tvalidation 31-81: Loss: 0.2166 Acc: 75.0000%\n",
      "\tvalidation 31-82: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 31-83: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 31-84: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-86: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-88: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-89: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 31-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-93: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 31-94: Loss: 0.0483 Acc: 100.0000%\n",
      "\tvalidation 31-95: Loss: 0.4114 Acc: 75.0000%\n",
      "\tvalidation 31-96: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 31-97: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 31-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-99: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 31-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-101: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 31-102: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 31-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-104: Loss: 0.0401 Acc: 100.0000%\n",
      "\tvalidation 31-105: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0453 Acc: 93.3673%\n",
      "\tvalidation Loss: 0.0488 Acc: 96.9048%\n",
      "Time passed 0h 25m 5s\n",
      "--------------------\n",
      "Epoch [32/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-1: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 32-2: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-3: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 32-4: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-5: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 32-6: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-7: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-8: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 32-9: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 32-10: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-11: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-12: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 32-13: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 32-14: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 32-15: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 32-16: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 32-17: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 32-18: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 32-19: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 32-20: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 32-21: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 32-22: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 32-23: Loss: 0.4910 Acc: 25.0000%\n",
      "\ttrain 32-24: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 32-25: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 32-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-27: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 32-28: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 32-29: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 32-30: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 32-31: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 32-32: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 32-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-34: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 32-35: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-36: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 32-37: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-38: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 32-39: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 32-40: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 32-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-42: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 32-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-44: Loss: 0.2460 Acc: 75.0000%\n",
      "\ttrain 32-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-46: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 32-47: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-48: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 32-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-50: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-51: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-52: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 32-53: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-54: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 32-55: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-56: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 32-57: Loss: 0.3585 Acc: 50.0000%\n",
      "\ttrain 32-58: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 32-59: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 32-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-61: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-62: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 32-63: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 32-64: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 32-65: Loss: 0.2404 Acc: 50.0000%\n",
      "\ttrain 32-66: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 32-67: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-68: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-70: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 32-71: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 32-72: Loss: 0.0483 Acc: 75.0000%\n",
      "\ttrain 32-73: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 32-74: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 32-75: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 32-76: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 32-77: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-78: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 32-79: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-80: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 32-81: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 32-82: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-83: Loss: 0.0462 Acc: 75.0000%\n",
      "\ttrain 32-84: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 32-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-86: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 32-87: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-88: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 32-89: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-91: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-94: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 32-95: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 32-96: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 32-97: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-98: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 32-99: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 32-100: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 32-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-102: Loss: 0.2722 Acc: 75.0000%\n",
      "\ttrain 32-103: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-104: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-105: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 32-106: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 32-107: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 32-108: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 32-109: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-110: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 32-111: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-112: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-113: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-114: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-115: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 32-116: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 32-117: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 32-118: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 32-119: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 32-120: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 32-121: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 32-122: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 32-123: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-124: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 32-125: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-126: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 32-127: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-128: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 32-129: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-130: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-131: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 32-132: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 32-133: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-134: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 32-135: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-136: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-137: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 32-138: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 32-139: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-140: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-141: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-143: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 32-144: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-145: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 32-146: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 32-147: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-148: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-149: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 32-150: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-151: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-152: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-153: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-154: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-155: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 32-156: Loss: 0.2092 Acc: 75.0000%\n",
      "\ttrain 32-157: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-158: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-159: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-160: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-161: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-162: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 32-163: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 32-164: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 32-165: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-166: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 32-167: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 32-168: Loss: 0.1633 Acc: 75.0000%\n",
      "\ttrain 32-169: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-170: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-171: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-172: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-173: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 32-174: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 32-175: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-176: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-177: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-178: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 32-179: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 32-180: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 32-181: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 32-182: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-183: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-184: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 32-185: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 32-186: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-187: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-189: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 32-190: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 32-191: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-192: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-193: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-194: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 32-195: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 32-196: Loss: 0.1285 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-197: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-198: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-199: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 32-200: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 32-201: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 32-202: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-203: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 32-204: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 32-205: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 32-206: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-207: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 32-208: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-209: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 32-210: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 32-211: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 32-212: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-213: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-214: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 32-215: Loss: 0.2535 Acc: 75.0000%\n",
      "\ttrain 32-216: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 32-217: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-218: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-219: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 32-220: Loss: 0.1352 Acc: 75.0000%\n",
      "\ttrain 32-221: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 32-222: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 32-223: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-224: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 32-225: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 32-226: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-227: Loss: 0.0467 Acc: 75.0000%\n",
      "\ttrain 32-228: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-229: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-230: Loss: 0.2424 Acc: 75.0000%\n",
      "\ttrain 32-231: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 32-232: Loss: 0.1793 Acc: 75.0000%\n",
      "\ttrain 32-233: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 32-234: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 32-235: Loss: 0.0516 Acc: 75.0000%\n",
      "\ttrain 32-236: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-237: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 32-238: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-239: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-240: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-241: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 32-242: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 32-243: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-244: Loss: 0.1615 Acc: 75.0000%\n",
      "\ttrain 32-245: Loss: 0.1973 Acc: 75.0000%\n",
      "\tvalidation 32-1: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 32-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-3: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-7: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 32-8: Loss: 0.0303 Acc: 100.0000%\n",
      "\tvalidation 32-9: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-10: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 32-11: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 32-12: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 32-13: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 32-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-16: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 32-17: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 32-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-19: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 32-20: Loss: 1.0883 Acc: 75.0000%\n",
      "\tvalidation 32-21: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-22: Loss: 4.1188 Acc: 50.0000%\n",
      "\tvalidation 32-23: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 32-24: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 32-25: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-27: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-28: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-29: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-31: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 32-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 32-33: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 32-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-36: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 32-37: Loss: 3.9167 Acc: 75.0000%\n",
      "\tvalidation 32-38: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-39: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 32-40: Loss: 0.7542 Acc: 75.0000%\n",
      "\tvalidation 32-41: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 32-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-43: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 32-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-46: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 32-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-48: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 32-49: Loss: 0.1371 Acc: 75.0000%\n",
      "\tvalidation 32-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-51: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-52: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 32-53: Loss: 5.6162 Acc: 50.0000%\n",
      "\tvalidation 32-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-55: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 32-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-57: Loss: 0.1622 Acc: 75.0000%\n",
      "\tvalidation 32-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-59: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 32-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-63: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-64: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 32-65: Loss: 0.1367 Acc: 75.0000%\n",
      "\tvalidation 32-66: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 32-67: Loss: 1.3158 Acc: 75.0000%\n",
      "\tvalidation 32-68: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 32-69: Loss: 0.3984 Acc: 75.0000%\n",
      "\tvalidation 32-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-73: Loss: 0.2219 Acc: 75.0000%\n",
      "\tvalidation 32-74: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-76: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 32-77: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-78: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-79: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 32-80: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-81: Loss: 0.6826 Acc: 75.0000%\n",
      "\tvalidation 32-82: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 32-83: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-84: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-86: Loss: 0.0633 Acc: 75.0000%\n",
      "\tvalidation 32-87: Loss: 0.3579 Acc: 75.0000%\n",
      "\tvalidation 32-88: Loss: 0.6991 Acc: 75.0000%\n",
      "\tvalidation 32-89: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 32-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-92: Loss: 0.2846 Acc: 50.0000%\n",
      "\tvalidation 32-93: Loss: 0.5659 Acc: 75.0000%\n",
      "\tvalidation 32-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-95: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 32-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 32-98: Loss: 0.0562 Acc: 100.0000%\n",
      "\tvalidation 32-99: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 32-100: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-102: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 32-103: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 32-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-105: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0326 Acc: 95.3061%\n",
      "\tvalidation Loss: 0.2002 Acc: 95.0000%\n",
      "Time passed 0h 25m 46s\n",
      "--------------------\n",
      "Epoch [33/40]:\n",
      "\ttrain 33-1: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 33-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-3: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-4: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-5: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-6: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 33-7: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-8: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 33-9: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 33-10: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-11: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 33-12: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-13: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-14: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-15: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 33-16: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-17: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 33-18: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 33-19: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-20: Loss: 0.3542 Acc: 75.0000%\n",
      "\ttrain 33-21: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 33-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-23: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-24: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 33-25: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 33-26: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 33-27: Loss: 0.0019 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-28: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 33-29: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 33-30: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-31: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 33-32: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-33: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-34: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 33-35: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 33-36: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 33-37: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-38: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-39: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-40: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 33-41: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-42: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 33-43: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 33-44: Loss: 0.3256 Acc: 50.0000%\n",
      "\ttrain 33-45: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 33-46: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-47: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 33-48: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-50: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-51: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 33-52: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-54: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 33-55: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 33-56: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 33-57: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 33-58: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 33-59: Loss: 0.1402 Acc: 50.0000%\n",
      "\ttrain 33-60: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-61: Loss: 0.3933 Acc: 50.0000%\n",
      "\ttrain 33-62: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 33-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-64: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 33-65: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-68: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-69: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 33-70: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 33-71: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-72: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-73: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-75: Loss: 0.1859 Acc: 50.0000%\n",
      "\ttrain 33-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-77: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-78: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 33-79: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-80: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 33-81: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-83: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 33-84: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 33-85: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 33-86: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-89: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 33-90: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 33-91: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 33-92: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 33-93: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 33-94: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-95: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-97: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 33-98: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 33-99: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 33-100: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 33-101: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 33-102: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-103: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 33-104: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-105: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-106: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 33-107: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 33-108: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-109: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-110: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 33-111: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 33-112: Loss: 0.1975 Acc: 75.0000%\n",
      "\ttrain 33-113: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 33-114: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-115: Loss: 0.0518 Acc: 75.0000%\n",
      "\ttrain 33-116: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 33-117: Loss: 0.8974 Acc: 25.0000%\n",
      "\ttrain 33-118: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-119: Loss: 0.0457 Acc: 75.0000%\n",
      "\ttrain 33-120: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 33-121: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-122: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 33-123: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-124: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-125: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-126: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-127: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 33-128: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 33-129: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 33-130: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 33-131: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-132: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 33-133: Loss: 0.3990 Acc: 50.0000%\n",
      "\ttrain 33-134: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 33-135: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-136: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-137: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 33-138: Loss: 0.2548 Acc: 75.0000%\n",
      "\ttrain 33-139: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 33-140: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 33-141: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 33-142: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 33-143: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 33-144: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-145: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 33-146: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 33-147: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-148: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 33-149: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 33-150: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-151: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 33-152: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-153: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 33-154: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 33-155: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-156: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 33-157: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 33-158: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-159: Loss: 0.1421 Acc: 50.0000%\n",
      "\ttrain 33-160: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 33-161: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 33-162: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 33-163: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-164: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 33-165: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-166: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-167: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 33-168: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 33-169: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 33-170: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-171: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 33-172: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 33-173: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-174: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-175: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-176: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 33-177: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 33-178: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-179: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-180: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-181: Loss: 0.5127 Acc: 25.0000%\n",
      "\ttrain 33-182: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-183: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-184: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 33-185: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 33-186: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 33-187: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 33-188: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 33-189: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 33-190: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 33-191: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 33-192: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 33-193: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 33-194: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 33-195: Loss: 0.2083 Acc: 75.0000%\n",
      "\ttrain 33-196: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 33-197: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-198: Loss: 0.1864 Acc: 75.0000%\n",
      "\ttrain 33-199: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-200: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-201: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-202: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 33-203: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 33-204: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 33-205: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-206: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 33-207: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 33-208: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-209: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 33-210: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 33-211: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 33-212: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-213: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 33-214: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 33-215: Loss: 0.2192 Acc: 75.0000%\n",
      "\ttrain 33-216: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 33-217: Loss: 0.2751 Acc: 50.0000%\n",
      "\ttrain 33-218: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-219: Loss: 0.0792 Acc: 100.0000%\n",
      "\ttrain 33-220: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-221: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 33-222: Loss: 0.5731 Acc: 50.0000%\n",
      "\ttrain 33-223: Loss: 0.0011 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-224: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 33-225: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 33-226: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-227: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-228: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 33-229: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-230: Loss: 0.3211 Acc: 75.0000%\n",
      "\ttrain 33-231: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 33-232: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-233: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-234: Loss: 0.0513 Acc: 75.0000%\n",
      "\ttrain 33-235: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-236: Loss: 1.0093 Acc: 50.0000%\n",
      "\ttrain 33-237: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 33-238: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 33-239: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 33-240: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-241: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 33-242: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 33-243: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 33-244: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 33-245: Loss: 0.0621 Acc: 100.0000%\n",
      "\tvalidation 33-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-3: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-6: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-7: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-8: Loss: 1.0961 Acc: 75.0000%\n",
      "\tvalidation 33-9: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-12: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-15: Loss: 0.0504 Acc: 75.0000%\n",
      "\tvalidation 33-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-17: Loss: 0.4997 Acc: 75.0000%\n",
      "\tvalidation 33-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-19: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-21: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 33-22: Loss: 2.1143 Acc: 50.0000%\n",
      "\tvalidation 33-23: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 33-25: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-29: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 33-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-31: Loss: 0.7336 Acc: 75.0000%\n",
      "\tvalidation 33-32: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-34: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 33-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-36: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 33-37: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 33-38: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-40: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 33-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-47: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 33-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-51: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 33-52: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-53: Loss: 5.7736 Acc: 75.0000%\n",
      "\tvalidation 33-54: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-55: Loss: 6.2650 Acc: 75.0000%\n",
      "\tvalidation 33-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-58: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-60: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-63: Loss: 0.6318 Acc: 75.0000%\n",
      "\tvalidation 33-64: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-67: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-68: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-69: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 33-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-73: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 33-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-77: Loss: 0.2917 Acc: 75.0000%\n",
      "\tvalidation 33-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-80: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 33-81: Loss: 0.8759 Acc: 75.0000%\n",
      "\tvalidation 33-82: Loss: 0.1735 Acc: 75.0000%\n",
      "\tvalidation 33-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-85: Loss: 1.2672 Acc: 75.0000%\n",
      "\tvalidation 33-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-87: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-88: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-89: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-90: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 33-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-94: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 33-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-96: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 33-97: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-99: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 33-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-101: Loss: 5.4917 Acc: 75.0000%\n",
      "\tvalidation 33-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-103: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0474 Acc: 93.7755%\n",
      "\tvalidation Loss: 0.2425 Acc: 96.4286%\n",
      "Time passed 0h 26m 25s\n",
      "--------------------\n",
      "Epoch [34/40]:\n",
      "\ttrain 34-1: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-2: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 34-3: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-4: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 34-5: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-6: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 34-7: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-8: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-9: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-10: Loss: 0.2496 Acc: 50.0000%\n",
      "\ttrain 34-11: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-12: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 34-13: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-14: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 34-15: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 34-16: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 34-17: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-18: Loss: 0.1565 Acc: 75.0000%\n",
      "\ttrain 34-19: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 34-20: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 34-21: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-22: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 34-23: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 34-24: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 34-25: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 34-26: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 34-27: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 34-28: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 34-29: Loss: 0.3383 Acc: 50.0000%\n",
      "\ttrain 34-30: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 34-31: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 34-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-33: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 34-34: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 34-35: Loss: 0.2003 Acc: 75.0000%\n",
      "\ttrain 34-36: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-37: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 34-38: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 34-39: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-40: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-41: Loss: 0.2978 Acc: 75.0000%\n",
      "\ttrain 34-42: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 34-43: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 34-44: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 34-45: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 34-46: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 34-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-48: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 34-49: Loss: 0.2267 Acc: 75.0000%\n",
      "\ttrain 34-50: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 34-51: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 34-52: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 34-53: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 34-54: Loss: 0.0139 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-55: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 34-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-57: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 34-58: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 34-59: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 34-60: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 34-61: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 34-62: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 34-63: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-64: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-66: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 34-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-68: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 34-69: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 34-70: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-71: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 34-72: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 34-73: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 34-74: Loss: 0.3193 Acc: 50.0000%\n",
      "\ttrain 34-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-76: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 34-77: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 34-78: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-79: Loss: 0.2225 Acc: 75.0000%\n",
      "\ttrain 34-80: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 34-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-82: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 34-83: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-84: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-85: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 34-86: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 34-87: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 34-88: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 34-89: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 34-90: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 34-91: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 34-92: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-93: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 34-94: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-95: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 34-96: Loss: 0.1889 Acc: 75.0000%\n",
      "\ttrain 34-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-98: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-99: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-100: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 34-101: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 34-102: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 34-103: Loss: 0.0477 Acc: 75.0000%\n",
      "\ttrain 34-104: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 34-105: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 34-106: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-107: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 34-108: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 34-109: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 34-110: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 34-111: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-112: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-113: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 34-114: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-115: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 34-116: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 34-117: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 34-118: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 34-119: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 34-120: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-121: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 34-122: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-123: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-124: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-125: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-126: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-127: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-128: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 34-129: Loss: 0.0847 Acc: 75.0000%\n",
      "\ttrain 34-130: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 34-131: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 34-132: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 34-133: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 34-134: Loss: 0.1806 Acc: 50.0000%\n",
      "\ttrain 34-135: Loss: 0.1785 Acc: 75.0000%\n",
      "\ttrain 34-136: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-137: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-138: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-139: Loss: 0.2079 Acc: 75.0000%\n",
      "\ttrain 34-140: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 34-141: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 34-142: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 34-143: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-144: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-145: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 34-146: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 34-147: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 34-148: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 34-149: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 34-150: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-151: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 34-152: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 34-153: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-154: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-155: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 34-156: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 34-157: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-158: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 34-159: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-160: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-161: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 34-162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-163: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 34-164: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 34-165: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 34-166: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 34-167: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 34-168: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-169: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 34-170: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 34-171: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-172: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 34-173: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 34-174: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-175: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-176: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 34-177: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 34-178: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 34-179: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-180: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-181: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-182: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 34-183: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-184: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 34-185: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 34-186: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-187: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-188: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 34-189: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-190: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 34-191: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 34-192: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-193: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 34-194: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-195: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 34-196: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-197: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 34-198: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 34-199: Loss: 0.2632 Acc: 75.0000%\n",
      "\ttrain 34-200: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 34-201: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 34-202: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-203: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 34-204: Loss: 0.2812 Acc: 50.0000%\n",
      "\ttrain 34-205: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 34-206: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 34-207: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 34-208: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 34-209: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 34-210: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 34-211: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 34-212: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 34-213: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-214: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-215: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 34-216: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 34-217: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 34-218: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 34-219: Loss: 0.2364 Acc: 75.0000%\n",
      "\ttrain 34-220: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 34-221: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 34-222: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 34-223: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 34-224: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 34-225: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-226: Loss: 0.3321 Acc: 75.0000%\n",
      "\ttrain 34-227: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 34-228: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 34-229: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-230: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-231: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 34-232: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-233: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 34-234: Loss: 0.3333 Acc: 50.0000%\n",
      "\ttrain 34-235: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 34-236: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-237: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-238: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 34-239: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 34-240: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 34-241: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 34-242: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 34-243: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 34-244: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 34-245: Loss: 0.0526 Acc: 100.0000%\n",
      "\tvalidation 34-1: Loss: 0.1082 Acc: 75.0000%\n",
      "\tvalidation 34-2: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 34-3: Loss: 0.0082 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 34-4: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-5: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 34-6: Loss: 0.3318 Acc: 75.0000%\n",
      "\tvalidation 34-7: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-9: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 34-10: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-11: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 34-12: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 34-13: Loss: 0.1370 Acc: 75.0000%\n",
      "\tvalidation 34-14: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 34-15: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-16: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 34-17: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 34-18: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 34-19: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 34-20: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 34-21: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 34-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-24: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 34-25: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 34-26: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 34-27: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 34-28: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 34-29: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-30: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 34-31: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-32: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-33: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 34-34: Loss: 0.2152 Acc: 75.0000%\n",
      "\tvalidation 34-35: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 34-36: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 34-37: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 34-38: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 34-39: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-40: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 34-41: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 34-42: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 34-43: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 34-44: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-45: Loss: 0.2149 Acc: 75.0000%\n",
      "\tvalidation 34-46: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-47: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-48: Loss: 0.0596 Acc: 75.0000%\n",
      "\tvalidation 34-49: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 34-50: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 34-51: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-53: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-55: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 34-56: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-57: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 34-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-59: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 34-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-61: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-63: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-64: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 34-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-66: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-67: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-68: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 34-69: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-70: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 34-72: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 34-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-74: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 34-75: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-76: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-77: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 34-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-79: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 34-80: Loss: 0.1634 Acc: 75.0000%\n",
      "\tvalidation 34-81: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-82: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 34-83: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-85: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 34-86: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 34-87: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 34-88: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 34-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-91: Loss: 0.1347 Acc: 75.0000%\n",
      "\tvalidation 34-92: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-93: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 34-94: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 34-95: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 34-96: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 34-97: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-98: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 34-99: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 34-100: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 34-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-102: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 34-103: Loss: 0.4731 Acc: 75.0000%\n",
      "\tvalidation 34-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-105: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0375 Acc: 94.4898%\n",
      "\tvalidation Loss: 0.0232 Acc: 97.6190%\n",
      "Time passed 0h 27m 4s\n",
      "--------------------\n",
      "Epoch [35/40]:\n",
      "\ttrain 35-1: Loss: 0.1677 Acc: 75.0000%\n",
      "\ttrain 35-2: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 35-3: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 35-4: Loss: 0.3946 Acc: 25.0000%\n",
      "\ttrain 35-5: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 35-6: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 35-7: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 35-8: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-9: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 35-10: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 35-11: Loss: 0.2384 Acc: 75.0000%\n",
      "\ttrain 35-12: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-13: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 35-14: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 35-15: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 35-16: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 35-17: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 35-18: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 35-19: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 35-20: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 35-21: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 35-22: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 35-23: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 35-24: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 35-25: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 35-26: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 35-27: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-28: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 35-29: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 35-30: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 35-31: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 35-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-33: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 35-34: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 35-35: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-36: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 35-37: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 35-38: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 35-39: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-40: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-41: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 35-42: Loss: 0.2108 Acc: 75.0000%\n",
      "\ttrain 35-43: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 35-44: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 35-45: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 35-46: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 35-47: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 35-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-49: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-50: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-52: Loss: 0.4157 Acc: 50.0000%\n",
      "\ttrain 35-53: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 35-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-55: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-56: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 35-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-58: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-59: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-60: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-61: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-62: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 35-63: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 35-64: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-65: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 35-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-67: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-69: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 35-70: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 35-71: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 35-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-73: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 35-74: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 35-75: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-76: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-77: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-78: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-79: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 35-80: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 35-81: Loss: 0.0075 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-82: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 35-83: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-84: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 35-85: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-86: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-87: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 35-88: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-89: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-90: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 35-91: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-92: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-93: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 35-94: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-96: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 35-97: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 35-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-99: Loss: 0.1894 Acc: 75.0000%\n",
      "\ttrain 35-100: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-101: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-102: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 35-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-104: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 35-105: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-106: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-107: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-108: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-109: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-110: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 35-111: Loss: 0.2053 Acc: 75.0000%\n",
      "\ttrain 35-112: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-113: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-114: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 35-115: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-116: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 35-117: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 35-118: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-119: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 35-120: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 35-121: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-122: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 35-123: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-124: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 35-125: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 35-126: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 35-127: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-128: Loss: 0.2215 Acc: 75.0000%\n",
      "\ttrain 35-129: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 35-130: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 35-131: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-132: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 35-133: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 35-134: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-135: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-136: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 35-137: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 35-138: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-139: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 35-141: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-142: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 35-143: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-144: Loss: 0.0912 Acc: 100.0000%\n",
      "\ttrain 35-145: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 35-146: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-147: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 35-148: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 35-149: Loss: 0.2994 Acc: 75.0000%\n",
      "\ttrain 35-150: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-151: Loss: 0.2869 Acc: 75.0000%\n",
      "\ttrain 35-152: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-153: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 35-154: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-155: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-156: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-157: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-158: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 35-159: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 35-160: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 35-161: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 35-162: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 35-163: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-164: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 35-165: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-166: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 35-167: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 35-168: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 35-169: Loss: 0.2394 Acc: 75.0000%\n",
      "\ttrain 35-170: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 35-171: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 35-172: Loss: 0.1535 Acc: 75.0000%\n",
      "\ttrain 35-173: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-174: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-175: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 35-176: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 35-177: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 35-178: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-179: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 35-180: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-181: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 35-182: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-183: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 35-184: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 35-185: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 35-186: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-187: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-188: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-189: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 35-190: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-191: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-192: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 35-193: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-194: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 35-195: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 35-196: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-197: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 35-198: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 35-199: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 35-200: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-201: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 35-202: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-203: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-204: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-205: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 35-206: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 35-207: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 35-208: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-209: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-210: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 35-211: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 35-212: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-213: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 35-214: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 35-215: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 35-216: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-217: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 35-218: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-219: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-220: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-221: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 35-222: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-223: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 35-224: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-225: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 35-226: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-227: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-228: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 35-229: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-230: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-231: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 35-232: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-233: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 35-234: Loss: 0.0611 Acc: 75.0000%\n",
      "\ttrain 35-235: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 35-236: Loss: 0.7163 Acc: 75.0000%\n",
      "\ttrain 35-237: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 35-238: Loss: 0.7565 Acc: 50.0000%\n",
      "\ttrain 35-239: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 35-240: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-241: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-242: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 35-243: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-244: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 35-245: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-2: Loss: 0.6597 Acc: 75.0000%\n",
      "\tvalidation 35-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-4: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-5: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 35-6: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-7: Loss: 0.0670 Acc: 75.0000%\n",
      "\tvalidation 35-8: Loss: 0.0536 Acc: 100.0000%\n",
      "\tvalidation 35-9: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-10: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 35-11: Loss: 1.0910 Acc: 75.0000%\n",
      "\tvalidation 35-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-13: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 35-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-15: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 35-16: Loss: 0.7605 Acc: 75.0000%\n",
      "\tvalidation 35-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-19: Loss: 0.0590 Acc: 75.0000%\n",
      "\tvalidation 35-20: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-21: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 35-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-23: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-24: Loss: 3.5566 Acc: 75.0000%\n",
      "\tvalidation 35-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-26: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-27: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 35-28: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-29: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 35-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-31: Loss: 0.6206 Acc: 75.0000%\n",
      "\tvalidation 35-32: Loss: 0.2215 Acc: 75.0000%\n",
      "\tvalidation 35-33: Loss: 0.3138 Acc: 75.0000%\n",
      "\tvalidation 35-34: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 35-35: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 35-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-37: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 35-38: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 35-39: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 35-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-42: Loss: 0.3300 Acc: 75.0000%\n",
      "\tvalidation 35-43: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-44: Loss: 0.1207 Acc: 75.0000%\n",
      "\tvalidation 35-45: Loss: 0.5331 Acc: 75.0000%\n",
      "\tvalidation 35-46: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 35-47: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-50: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-51: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-52: Loss: 1.0765 Acc: 75.0000%\n",
      "\tvalidation 35-53: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 35-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-55: Loss: 0.1466 Acc: 75.0000%\n",
      "\tvalidation 35-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-58: Loss: 0.3154 Acc: 75.0000%\n",
      "\tvalidation 35-59: Loss: 0.6182 Acc: 75.0000%\n",
      "\tvalidation 35-60: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 35-61: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 35-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-64: Loss: 0.1909 Acc: 75.0000%\n",
      "\tvalidation 35-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-67: Loss: 0.1612 Acc: 75.0000%\n",
      "\tvalidation 35-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-69: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-71: Loss: 0.3423 Acc: 75.0000%\n",
      "\tvalidation 35-72: Loss: 0.4511 Acc: 75.0000%\n",
      "\tvalidation 35-73: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 35-74: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-75: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-76: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 35-77: Loss: 4.5488 Acc: 75.0000%\n",
      "\tvalidation 35-78: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-80: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-81: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-82: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 35-83: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 35-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-85: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 35-86: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-87: Loss: 0.1820 Acc: 75.0000%\n",
      "\tvalidation 35-88: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-89: Loss: 3.5437 Acc: 75.0000%\n",
      "\tvalidation 35-90: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 35-91: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 35-92: Loss: 0.2458 Acc: 75.0000%\n",
      "\tvalidation 35-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-94: Loss: 0.5488 Acc: 75.0000%\n",
      "\tvalidation 35-95: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 35-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-97: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-98: Loss: 0.3123 Acc: 75.0000%\n",
      "\tvalidation 35-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-101: Loss: 0.0866 Acc: 75.0000%\n",
      "\tvalidation 35-102: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-103: Loss: 0.4801 Acc: 75.0000%\n",
      "\tvalidation 35-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-105: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0403 Acc: 94.5918%\n",
      "\tvalidation Loss: 0.2109 Acc: 92.6190%\n",
      "Time passed 0h 27m 43s\n",
      "--------------------\n",
      "Epoch [36/40]:\n",
      "\ttrain 36-1: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 36-2: Loss: 0.3824 Acc: 75.0000%\n",
      "\ttrain 36-3: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-4: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 36-5: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 36-6: Loss: 0.8498 Acc: 50.0000%\n",
      "\ttrain 36-7: Loss: 0.1918 Acc: 75.0000%\n",
      "\ttrain 36-8: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 36-9: Loss: 0.2447 Acc: 50.0000%\n",
      "\ttrain 36-10: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 36-11: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 36-12: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-13: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-15: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 36-16: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 36-17: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 36-18: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 36-19: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-20: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 36-21: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 36-22: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 36-23: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 36-24: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-25: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 36-26: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 36-27: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 36-28: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 36-29: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-30: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-31: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 36-32: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 36-33: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-34: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-35: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 36-36: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 36-37: Loss: 0.0658 Acc: 75.0000%\n",
      "\ttrain 36-38: Loss: 0.2192 Acc: 75.0000%\n",
      "\ttrain 36-39: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-40: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 36-41: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 36-42: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 36-43: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 36-44: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-45: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-46: Loss: 0.2174 Acc: 75.0000%\n",
      "\ttrain 36-47: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-48: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-49: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 36-50: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-51: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-52: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-53: Loss: 0.3580 Acc: 75.0000%\n",
      "\ttrain 36-54: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 36-55: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 36-56: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-57: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 36-58: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-59: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-60: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-61: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 36-62: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-64: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 36-65: Loss: 0.1974 Acc: 75.0000%\n",
      "\ttrain 36-66: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 36-67: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 36-68: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 36-69: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-70: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-72: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 36-73: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 36-74: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 36-75: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-76: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 36-77: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 36-78: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-79: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-80: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 36-81: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-82: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 36-83: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 36-84: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-85: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-86: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-87: Loss: 0.1799 Acc: 75.0000%\n",
      "\ttrain 36-88: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-89: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 36-90: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 36-91: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 36-92: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 36-93: Loss: 0.2657 Acc: 75.0000%\n",
      "\ttrain 36-94: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-95: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-97: Loss: 0.3935 Acc: 25.0000%\n",
      "\ttrain 36-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-99: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 36-100: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 36-101: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-102: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 36-103: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 36-104: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-105: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 36-106: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 36-107: Loss: 0.0015 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-108: Loss: 0.3470 Acc: 75.0000%\n",
      "\ttrain 36-109: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 36-110: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 36-111: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-112: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 36-113: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 36-114: Loss: 0.2396 Acc: 75.0000%\n",
      "\ttrain 36-115: Loss: 0.3179 Acc: 50.0000%\n",
      "\ttrain 36-116: Loss: 0.2765 Acc: 50.0000%\n",
      "\ttrain 36-117: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 36-118: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 36-119: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 36-120: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-121: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 36-122: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 36-123: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 36-124: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-125: Loss: 0.1850 Acc: 75.0000%\n",
      "\ttrain 36-126: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 36-127: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-128: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-129: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-130: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 36-131: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 36-132: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 36-133: Loss: 0.2905 Acc: 75.0000%\n",
      "\ttrain 36-134: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-135: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 36-136: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-137: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-138: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 36-139: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-140: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 36-141: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 36-142: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-143: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-145: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 36-146: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-147: Loss: 0.2435 Acc: 50.0000%\n",
      "\ttrain 36-148: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 36-149: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 36-150: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 36-151: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-152: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 36-153: Loss: 0.2106 Acc: 75.0000%\n",
      "\ttrain 36-154: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 36-155: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-156: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-157: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-158: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 36-159: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-160: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-161: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-162: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 36-163: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 36-164: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-165: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 36-166: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 36-167: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-168: Loss: 0.2498 Acc: 75.0000%\n",
      "\ttrain 36-169: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 36-170: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-171: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-172: Loss: 0.4368 Acc: 75.0000%\n",
      "\ttrain 36-173: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-174: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 36-175: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-176: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 36-177: Loss: 0.5724 Acc: 50.0000%\n",
      "\ttrain 36-178: Loss: 0.2370 Acc: 75.0000%\n",
      "\ttrain 36-179: Loss: 0.2696 Acc: 75.0000%\n",
      "\ttrain 36-180: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 36-181: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 36-182: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 36-183: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 36-184: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 36-185: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-186: Loss: 0.2177 Acc: 75.0000%\n",
      "\ttrain 36-187: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-188: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 36-189: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 36-190: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 36-191: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 36-192: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-193: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 36-194: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 36-195: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-196: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 36-197: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-198: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 36-199: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 36-200: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 36-201: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 36-202: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 36-203: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 36-204: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 36-205: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 36-206: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 36-207: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 36-208: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-209: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 36-210: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 36-211: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 36-212: Loss: 0.1993 Acc: 75.0000%\n",
      "\ttrain 36-213: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 36-214: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 36-215: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-216: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-217: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-218: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-219: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-220: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 36-221: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 36-222: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-223: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-224: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-225: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 36-226: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-227: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 36-228: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-229: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 36-230: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-231: Loss: 0.1578 Acc: 75.0000%\n",
      "\ttrain 36-232: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 36-233: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 36-234: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 36-235: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 36-236: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 36-237: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 36-238: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-239: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-240: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 36-241: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 36-242: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-243: Loss: 0.2038 Acc: 50.0000%\n",
      "\ttrain 36-244: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 36-245: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-2: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 36-3: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 36-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-5: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-6: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-7: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-8: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 36-9: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 36-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-11: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-13: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 36-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-15: Loss: 0.0612 Acc: 75.0000%\n",
      "\tvalidation 36-16: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-17: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-18: Loss: 0.4976 Acc: 75.0000%\n",
      "\tvalidation 36-19: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 36-20: Loss: 0.8322 Acc: 75.0000%\n",
      "\tvalidation 36-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-22: Loss: 0.7828 Acc: 75.0000%\n",
      "\tvalidation 36-23: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 36-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 36-25: Loss: 3.3825 Acc: 75.0000%\n",
      "\tvalidation 36-26: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-27: Loss: 3.5398 Acc: 75.0000%\n",
      "\tvalidation 36-28: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 36-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-32: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-33: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-34: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-35: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-36: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 36-37: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 36-38: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-39: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-43: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 36-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-48: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 36-49: Loss: 0.4894 Acc: 75.0000%\n",
      "\tvalidation 36-50: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 36-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-52: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-53: Loss: 0.0023 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 36-54: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-56: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-57: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 36-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-59: Loss: 1.1955 Acc: 75.0000%\n",
      "\tvalidation 36-60: Loss: 1.4331 Acc: 75.0000%\n",
      "\tvalidation 36-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-63: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-64: Loss: 0.8485 Acc: 75.0000%\n",
      "\tvalidation 36-65: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 36-66: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 36-67: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-68: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-69: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 36-70: Loss: 0.3816 Acc: 75.0000%\n",
      "\tvalidation 36-71: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 36-72: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-73: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-74: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 36-75: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 36-76: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-77: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 36-78: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 36-79: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-80: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 36-81: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 36-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-83: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 36-84: Loss: 0.3118 Acc: 75.0000%\n",
      "\tvalidation 36-85: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 36-86: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 36-87: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-88: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-89: Loss: 0.0533 Acc: 75.0000%\n",
      "\tvalidation 36-90: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 36-91: Loss: 0.0656 Acc: 75.0000%\n",
      "\tvalidation 36-92: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 36-93: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 36-94: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-95: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-96: Loss: 4.4193 Acc: 75.0000%\n",
      "\tvalidation 36-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-98: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 36-99: Loss: 0.1932 Acc: 75.0000%\n",
      "\tvalidation 36-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-103: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0544 Acc: 92.7551%\n",
      "\tvalidation Loss: 0.1789 Acc: 96.1905%\n",
      "Time passed 0h 28m 23s\n",
      "--------------------\n",
      "Epoch [37/40]:\n",
      "\ttrain 37-1: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 37-2: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 37-3: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 37-4: Loss: 0.3052 Acc: 75.0000%\n",
      "\ttrain 37-5: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 37-6: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 37-7: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 37-8: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-9: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 37-10: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 37-11: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 37-12: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-13: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 37-14: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 37-15: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 37-16: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-17: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 37-18: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 37-19: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 37-20: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-21: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 37-22: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-23: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 37-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-25: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 37-26: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 37-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-28: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 37-29: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-30: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 37-31: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-33: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 37-34: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 37-35: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 37-36: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-37: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-38: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-39: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-40: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 37-41: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 37-42: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 37-43: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-44: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-45: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-47: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-49: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 37-50: Loss: 0.2213 Acc: 75.0000%\n",
      "\ttrain 37-51: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-52: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 37-53: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 37-54: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 37-55: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 37-56: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-57: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 37-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-59: Loss: 0.2447 Acc: 75.0000%\n",
      "\ttrain 37-60: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-61: Loss: 0.6510 Acc: 0.0000%\n",
      "\ttrain 37-62: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-63: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 37-64: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 37-65: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-66: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-67: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 37-68: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 37-69: Loss: 0.1531 Acc: 75.0000%\n",
      "\ttrain 37-70: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-73: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 37-74: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 37-75: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-76: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 37-77: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 37-78: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 37-79: Loss: 0.2174 Acc: 75.0000%\n",
      "\ttrain 37-80: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-81: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 37-82: Loss: 0.2846 Acc: 75.0000%\n",
      "\ttrain 37-83: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 37-84: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 37-85: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 37-86: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 37-87: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 37-88: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-89: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 37-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-91: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 37-92: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-93: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 37-94: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 37-95: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-96: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-97: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 37-98: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 37-99: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 37-100: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-101: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 37-102: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 37-103: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 37-104: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 37-105: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 37-106: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 37-107: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 37-108: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-109: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 37-110: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 37-111: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 37-112: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 37-113: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-114: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 37-115: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 37-116: Loss: 0.1573 Acc: 75.0000%\n",
      "\ttrain 37-117: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-118: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-119: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 37-120: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 37-121: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 37-122: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 37-123: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 37-124: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 37-125: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 37-126: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 37-127: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-128: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 37-129: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 37-130: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 37-131: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 37-132: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-133: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 37-134: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 37-135: Loss: 0.0114 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-136: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-137: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 37-138: Loss: 0.3263 Acc: 75.0000%\n",
      "\ttrain 37-139: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 37-140: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-141: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 37-142: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-143: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 37-144: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 37-145: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-146: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 37-147: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-148: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-149: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-150: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-151: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 37-152: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 37-153: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 37-154: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-155: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 37-156: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-157: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-158: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-159: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-160: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-161: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-162: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-163: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 37-164: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 37-165: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 37-166: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 37-167: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 37-168: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 37-169: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-170: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 37-171: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 37-172: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 37-173: Loss: 0.3530 Acc: 75.0000%\n",
      "\ttrain 37-174: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-175: Loss: 0.1431 Acc: 75.0000%\n",
      "\ttrain 37-176: Loss: 0.0642 Acc: 75.0000%\n",
      "\ttrain 37-177: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-178: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 37-179: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-180: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 37-181: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 37-182: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-183: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-184: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 37-185: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-186: Loss: 0.0442 Acc: 75.0000%\n",
      "\ttrain 37-187: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-188: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 37-189: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 37-190: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-191: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 37-192: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 37-193: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 37-194: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-195: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 37-196: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-197: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 37-198: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 37-199: Loss: 1.1814 Acc: 50.0000%\n",
      "\ttrain 37-200: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 37-201: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 37-202: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-203: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-204: Loss: 0.0472 Acc: 75.0000%\n",
      "\ttrain 37-205: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 37-206: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 37-207: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-208: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-209: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 37-210: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 37-211: Loss: 0.0772 Acc: 75.0000%\n",
      "\ttrain 37-212: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 37-213: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-214: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-215: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 37-216: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-217: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 37-218: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-219: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 37-220: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 37-221: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 37-222: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 37-223: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 37-224: Loss: 0.7860 Acc: 25.0000%\n",
      "\ttrain 37-225: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 37-226: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-227: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-228: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 37-229: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-230: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-231: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 37-232: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-233: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-234: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-235: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 37-236: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 37-237: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 37-238: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-239: Loss: 0.2245 Acc: 75.0000%\n",
      "\ttrain 37-240: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 37-241: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-242: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-243: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-244: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 37-245: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-1: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-4: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 37-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-7: Loss: 0.4951 Acc: 75.0000%\n",
      "\tvalidation 37-8: Loss: 2.9952 Acc: 75.0000%\n",
      "\tvalidation 37-9: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 37-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-11: Loss: 0.8010 Acc: 75.0000%\n",
      "\tvalidation 37-12: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-13: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-14: Loss: 0.1884 Acc: 75.0000%\n",
      "\tvalidation 37-15: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-16: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-19: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 37-20: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-21: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-22: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-23: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 37-24: Loss: 2.7309 Acc: 75.0000%\n",
      "\tvalidation 37-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-26: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-27: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 37-28: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-29: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-30: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 37-31: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 37-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-34: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-37: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-38: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-39: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-40: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 37-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-42: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-47: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-48: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-51: Loss: 0.6306 Acc: 75.0000%\n",
      "\tvalidation 37-52: Loss: 0.3851 Acc: 75.0000%\n",
      "\tvalidation 37-53: Loss: 0.2438 Acc: 75.0000%\n",
      "\tvalidation 37-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-55: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-56: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-57: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 37-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-60: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 37-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-65: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 37-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-67: Loss: 0.4121 Acc: 75.0000%\n",
      "\tvalidation 37-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-69: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-71: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-72: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-75: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-76: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-77: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 37-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-79: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-80: Loss: 0.0605 Acc: 75.0000%\n",
      "\tvalidation 37-81: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 37-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-83: Loss: 0.0009 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 37-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-86: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 37-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-88: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 37-89: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-90: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-91: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 37-92: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-93: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 37-94: Loss: 3.6254 Acc: 75.0000%\n",
      "\tvalidation 37-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-99: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-102: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-103: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-104: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 37-105: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0421 Acc: 94.6939%\n",
      "\tvalidation Loss: 0.1213 Acc: 97.3810%\n",
      "Time passed 0h 29m 2s\n",
      "--------------------\n",
      "Epoch [38/40]:\n",
      "\ttrain 38-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-2: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 38-3: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-4: Loss: 0.2019 Acc: 75.0000%\n",
      "\ttrain 38-5: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-6: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-7: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-8: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-9: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-10: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 38-11: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 38-12: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 38-13: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 38-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-15: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 38-16: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 38-17: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 38-18: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-19: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 38-20: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 38-21: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 38-22: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-23: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-24: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-25: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 38-26: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-27: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 38-28: Loss: 0.6951 Acc: 50.0000%\n",
      "\ttrain 38-29: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-30: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-31: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 38-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-33: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 38-34: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 38-35: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 38-36: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-37: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 38-38: Loss: 0.5159 Acc: 50.0000%\n",
      "\ttrain 38-39: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-40: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-41: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 38-42: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-43: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 38-44: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 38-45: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 38-46: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 38-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-48: Loss: 0.0810 Acc: 75.0000%\n",
      "\ttrain 38-49: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-50: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 38-51: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 38-52: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 38-53: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 38-54: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 38-55: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-56: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 38-57: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 38-58: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 38-59: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-60: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 38-61: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 38-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-63: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 38-64: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 38-65: Loss: 0.2774 Acc: 50.0000%\n",
      "\ttrain 38-66: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 38-67: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 38-68: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 38-69: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-70: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-72: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 38-73: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-74: Loss: 0.2707 Acc: 75.0000%\n",
      "\ttrain 38-75: Loss: 0.1968 Acc: 75.0000%\n",
      "\ttrain 38-76: Loss: 0.3454 Acc: 50.0000%\n",
      "\ttrain 38-77: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 38-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-79: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-80: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-81: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-82: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-83: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-84: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-85: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-86: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 38-87: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 38-88: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-89: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 38-90: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-91: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-92: Loss: 0.0515 Acc: 75.0000%\n",
      "\ttrain 38-93: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 38-94: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 38-95: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 38-96: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 38-97: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 38-98: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 38-99: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 38-100: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-101: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 38-102: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 38-103: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-104: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 38-105: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-106: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 38-107: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-108: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-109: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 38-110: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 38-111: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 38-112: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-113: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 38-114: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 38-115: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-116: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-117: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 38-118: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 38-119: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 38-120: Loss: 0.4628 Acc: 25.0000%\n",
      "\ttrain 38-121: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 38-122: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-123: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 38-124: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 38-125: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-126: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-127: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-128: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-129: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-130: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-131: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 38-132: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 38-133: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 38-134: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 38-135: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 38-136: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-137: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 38-138: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 38-139: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 38-140: Loss: 0.1485 Acc: 75.0000%\n",
      "\ttrain 38-141: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-142: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-143: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-144: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 38-145: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-146: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 38-147: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 38-148: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-149: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-150: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-151: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-152: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 38-153: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-154: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 38-155: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 38-156: Loss: 0.1975 Acc: 75.0000%\n",
      "\ttrain 38-157: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 38-158: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-159: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-160: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-161: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 38-162: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-163: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 38-164: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 38-165: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-166: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 38-167: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 38-168: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 38-169: Loss: 0.0629 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 38-170: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-171: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-172: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-173: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-174: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 38-175: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 38-176: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 38-177: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 38-178: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-179: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 38-180: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-181: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-182: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-183: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 38-184: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-185: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 38-186: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-187: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 38-188: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-189: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-190: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 38-191: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-192: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-193: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 38-194: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 38-195: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-196: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 38-197: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-198: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-200: Loss: 0.0450 Acc: 75.0000%\n",
      "\ttrain 38-201: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 38-202: Loss: 0.2209 Acc: 75.0000%\n",
      "\ttrain 38-203: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-204: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 38-205: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 38-206: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 38-207: Loss: 0.1826 Acc: 50.0000%\n",
      "\ttrain 38-208: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-209: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 38-210: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-211: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 38-212: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-213: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 38-214: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-215: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 38-216: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-217: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-218: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 38-219: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 38-220: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-221: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 38-222: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 38-223: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 38-224: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 38-225: Loss: 0.5684 Acc: 75.0000%\n",
      "\ttrain 38-226: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-227: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-228: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-229: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-230: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-231: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-232: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-233: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-234: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-235: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-236: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 38-237: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-238: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 38-239: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-240: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 38-241: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-242: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-243: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 38-244: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-245: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-1: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-2: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 38-3: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 38-4: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-5: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-6: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 38-7: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-8: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-10: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 38-11: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 38-12: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 38-13: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 38-14: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-15: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 38-16: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 38-17: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-18: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 38-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-20: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-21: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 38-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-23: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-25: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-26: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-28: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-29: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-32: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-33: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-34: Loss: 0.0228 Acc: 100.0000%\n",
      "\tvalidation 38-35: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 38-36: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 38-37: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-39: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-40: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-43: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 38-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-45: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 38-46: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 38-47: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 38-48: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 38-49: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-50: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-52: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 38-53: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-54: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 38-55: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-56: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 38-57: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-58: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-59: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-60: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 38-61: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-62: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-65: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-66: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-67: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-68: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-71: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-74: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 38-75: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-76: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 38-77: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 38-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-79: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 38-80: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 38-81: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-82: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 38-83: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-85: Loss: 0.0843 Acc: 75.0000%\n",
      "\tvalidation 38-86: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-87: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 38-88: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 38-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-90: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 38-91: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-92: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-93: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 38-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-96: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-97: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 38-98: Loss: 0.0674 Acc: 100.0000%\n",
      "\tvalidation 38-99: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-100: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-102: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 38-103: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-104: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-105: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0341 Acc: 95.7143%\n",
      "\tvalidation Loss: 0.0044 Acc: 99.7619%\n",
      "网络参数更新\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed 0h 29m 43s\n",
      "--------------------\n",
      "Epoch [39/40]:\n",
      "\ttrain 39-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-2: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 39-3: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-4: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 39-5: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 39-6: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 39-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-8: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 39-9: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 39-10: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 39-11: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 39-12: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 39-13: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-14: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 39-15: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-16: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 39-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-18: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-19: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 39-20: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-21: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 39-22: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-23: Loss: 0.1971 Acc: 50.0000%\n",
      "\ttrain 39-24: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 39-25: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 39-26: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 39-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-28: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 39-29: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 39-30: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 39-31: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 39-32: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 39-33: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 39-34: Loss: 0.1531 Acc: 75.0000%\n",
      "\ttrain 39-35: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 39-36: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 39-37: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 39-38: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 39-39: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 39-40: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-42: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 39-43: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 39-44: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 39-45: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-46: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 39-47: Loss: 0.1829 Acc: 75.0000%\n",
      "\ttrain 39-48: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 39-49: Loss: 0.1702 Acc: 75.0000%\n",
      "\ttrain 39-50: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 39-51: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-52: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 39-53: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-54: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-55: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-56: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-57: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 39-58: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-59: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 39-60: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 39-61: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-62: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-63: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-64: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-65: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-66: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 39-67: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-68: Loss: 0.5740 Acc: 0.0000%\n",
      "\ttrain 39-69: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 39-70: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-71: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-72: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 39-73: Loss: 0.0454 Acc: 75.0000%\n",
      "\ttrain 39-74: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 39-75: Loss: 0.3373 Acc: 50.0000%\n",
      "\ttrain 39-76: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-77: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-78: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 39-79: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-80: Loss: 0.2323 Acc: 75.0000%\n",
      "\ttrain 39-81: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-82: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 39-83: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 39-84: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 39-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-87: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 39-88: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-89: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 39-90: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-91: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 39-92: Loss: 0.2605 Acc: 75.0000%\n",
      "\ttrain 39-93: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 39-94: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-95: Loss: 0.2480 Acc: 75.0000%\n",
      "\ttrain 39-96: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 39-97: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 39-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-99: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-100: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-101: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-102: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-103: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-104: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 39-105: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-106: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-107: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-108: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 39-109: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 39-110: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-111: Loss: 0.2584 Acc: 75.0000%\n",
      "\ttrain 39-112: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 39-113: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 39-114: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 39-115: Loss: 0.3317 Acc: 75.0000%\n",
      "\ttrain 39-116: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-117: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 39-118: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-119: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-120: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 39-121: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 39-122: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-123: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-124: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-125: Loss: 0.4083 Acc: 50.0000%\n",
      "\ttrain 39-126: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-127: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-128: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-129: Loss: 0.1836 Acc: 75.0000%\n",
      "\ttrain 39-130: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 39-131: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 39-132: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 39-133: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-134: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 39-135: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 39-136: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 39-137: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 39-138: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-139: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-140: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-141: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-142: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-143: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 39-144: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-145: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-146: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 39-147: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 39-148: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-149: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-150: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 39-151: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 39-152: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-153: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-154: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 39-155: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 39-156: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 39-157: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-158: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 39-159: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 39-160: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 39-161: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 39-162: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 39-163: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 39-164: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 39-165: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-166: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 39-167: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-168: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-169: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-170: Loss: 0.2846 Acc: 50.0000%\n",
      "\ttrain 39-171: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 39-172: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 39-173: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 39-174: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-175: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 39-176: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 39-177: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-178: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 39-179: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 39-180: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-181: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-182: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-183: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 39-184: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 39-185: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 39-186: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-187: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-188: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 39-189: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-190: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-191: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 39-192: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-193: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 39-194: Loss: 0.0097 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-195: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-196: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-197: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-198: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 39-199: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-200: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 39-201: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 39-202: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-204: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-205: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-206: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-207: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 39-208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-209: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-210: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-211: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-212: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-213: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-214: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-215: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 39-216: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-217: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 39-218: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 39-219: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 39-220: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-221: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 39-222: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 39-223: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-224: Loss: 0.1901 Acc: 75.0000%\n",
      "\ttrain 39-225: Loss: 0.4416 Acc: 50.0000%\n",
      "\ttrain 39-226: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 39-227: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-228: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-229: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 39-230: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 39-231: Loss: 0.0641 Acc: 100.0000%\n",
      "\ttrain 39-232: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 39-233: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-234: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 39-235: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 39-236: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 39-237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-238: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 39-239: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 39-240: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 39-241: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 39-242: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 39-243: Loss: 0.1114 Acc: 50.0000%\n",
      "\ttrain 39-244: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-245: Loss: 0.1320 Acc: 75.0000%\n",
      "\tvalidation 39-1: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-2: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 39-3: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 39-4: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 39-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-6: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 39-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-8: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-9: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-10: Loss: 0.1193 Acc: 75.0000%\n",
      "\tvalidation 39-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-12: Loss: 0.0615 Acc: 75.0000%\n",
      "\tvalidation 39-13: Loss: 0.0718 Acc: 75.0000%\n",
      "\tvalidation 39-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-15: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-16: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 39-17: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-18: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 39-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-20: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 39-21: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-23: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-27: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 39-28: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 39-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-30: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 39-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-32: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-33: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 39-34: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-39: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-40: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 39-41: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 39-42: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 39-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-48: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 39-49: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 39-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-52: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 39-53: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-54: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 39-55: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 39-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-57: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 39-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-60: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-61: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-62: Loss: 0.0660 Acc: 75.0000%\n",
      "\tvalidation 39-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-65: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 39-66: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-67: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-68: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-69: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-70: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 39-71: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-72: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-73: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 39-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-75: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 39-76: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 39-77: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-78: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-79: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-80: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 39-81: Loss: 1.0241 Acc: 75.0000%\n",
      "\tvalidation 39-82: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 39-83: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-85: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-86: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 39-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-89: Loss: 0.8228 Acc: 75.0000%\n",
      "\tvalidation 39-90: Loss: 0.5984 Acc: 75.0000%\n",
      "\tvalidation 39-91: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 39-92: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-93: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 39-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-95: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 39-96: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 39-97: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-101: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-102: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 39-103: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-104: Loss: 0.0230 Acc: 100.0000%\n",
      "\tvalidation 39-105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0383 Acc: 95.0000%\n",
      "\tvalidation Loss: 0.0309 Acc: 98.3333%\n",
      "Time passed 0h 30m 23s\n",
      "--------------------\n",
      "Epoch [40/40]:\n",
      "\ttrain 40-1: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 40-2: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 40-3: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 40-4: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 40-5: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-6: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 40-7: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 40-8: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-9: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 40-10: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-11: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 40-12: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 40-13: Loss: 0.0555 Acc: 75.0000%\n",
      "\ttrain 40-14: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-15: Loss: 0.6956 Acc: 75.0000%\n",
      "\ttrain 40-16: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 40-17: Loss: 0.4800 Acc: 25.0000%\n",
      "\ttrain 40-18: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 40-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-20: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-21: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-22: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 40-23: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-24: Loss: 0.0010 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-25: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-26: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 40-27: Loss: 0.3161 Acc: 75.0000%\n",
      "\ttrain 40-28: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 40-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-30: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 40-31: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-32: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-33: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 40-34: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-35: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-36: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-37: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 40-38: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-39: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 40-40: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 40-41: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 40-42: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 40-43: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 40-44: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 40-45: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 40-46: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-47: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 40-48: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 40-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-50: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-51: Loss: 0.3375 Acc: 75.0000%\n",
      "\ttrain 40-52: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-53: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 40-54: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-55: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-56: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 40-57: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 40-58: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 40-59: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 40-60: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 40-61: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 40-62: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 40-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-65: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 40-66: Loss: 0.1281 Acc: 50.0000%\n",
      "\ttrain 40-67: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 40-68: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 40-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-70: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 40-71: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 40-72: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 40-73: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 40-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-75: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 40-76: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 40-77: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 40-78: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-80: Loss: 0.1869 Acc: 75.0000%\n",
      "\ttrain 40-81: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-82: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 40-83: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 40-84: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 40-85: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 40-86: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 40-87: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-88: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-90: Loss: 0.5330 Acc: 25.0000%\n",
      "\ttrain 40-91: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 40-92: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-94: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 40-95: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-97: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-99: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-100: Loss: 0.1593 Acc: 75.0000%\n",
      "\ttrain 40-101: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-102: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-104: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-105: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 40-106: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 40-107: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 40-108: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-109: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 40-110: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 40-111: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 40-112: Loss: 0.2083 Acc: 75.0000%\n",
      "\ttrain 40-113: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-114: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-115: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-116: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 40-117: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 40-118: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 40-119: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 40-120: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 40-121: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-122: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-123: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 40-124: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 40-125: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-126: Loss: 0.3119 Acc: 50.0000%\n",
      "\ttrain 40-127: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 40-128: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 40-129: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-130: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-131: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-132: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 40-133: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-134: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 40-135: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 40-136: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 40-137: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 40-138: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 40-139: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-140: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-141: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 40-142: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 40-143: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-144: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 40-145: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 40-146: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 40-147: Loss: 0.1724 Acc: 75.0000%\n",
      "\ttrain 40-148: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 40-149: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 40-150: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 40-151: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-152: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-153: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 40-154: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 40-155: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-156: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 40-157: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 40-158: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-159: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 40-160: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 40-161: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 40-162: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-163: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-164: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 40-165: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 40-166: Loss: 0.1342 Acc: 75.0000%\n",
      "\ttrain 40-167: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-168: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 40-169: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 40-170: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-171: Loss: 0.1820 Acc: 75.0000%\n",
      "\ttrain 40-172: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-173: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-174: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 40-175: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-176: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 40-177: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 40-178: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-179: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-180: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 40-181: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-182: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-183: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-184: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-185: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 40-186: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 40-187: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 40-188: Loss: 0.4768 Acc: 75.0000%\n",
      "\ttrain 40-189: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-190: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 40-191: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 40-192: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-193: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-194: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-195: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 40-196: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-197: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 40-198: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-199: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 40-200: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 40-201: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-202: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-203: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-204: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-205: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-206: Loss: 0.1418 Acc: 75.0000%\n",
      "\ttrain 40-207: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 40-208: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-210: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-211: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-212: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 40-213: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 40-214: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 40-215: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-216: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-217: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 40-218: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 40-219: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 40-220: Loss: 0.0065 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-221: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 40-222: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 40-223: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-224: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 40-225: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 40-226: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 40-227: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 40-228: Loss: 0.3343 Acc: 75.0000%\n",
      "\ttrain 40-229: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 40-230: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-231: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-232: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-233: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-234: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-235: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 40-236: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 40-237: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 40-238: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-239: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-240: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 40-241: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-242: Loss: 0.2250 Acc: 75.0000%\n",
      "\ttrain 40-243: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-244: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-245: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-1: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 40-2: Loss: 0.0342 Acc: 100.0000%\n",
      "\tvalidation 40-3: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-4: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 40-5: Loss: 5.1300 Acc: 75.0000%\n",
      "\tvalidation 40-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-8: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 40-9: Loss: 0.1324 Acc: 75.0000%\n",
      "\tvalidation 40-10: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-11: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-12: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 40-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-14: Loss: 0.2273 Acc: 75.0000%\n",
      "\tvalidation 40-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-17: Loss: 4.0573 Acc: 75.0000%\n",
      "\tvalidation 40-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-20: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-21: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 40-22: Loss: 0.0762 Acc: 75.0000%\n",
      "\tvalidation 40-23: Loss: 1.5939 Acc: 75.0000%\n",
      "\tvalidation 40-24: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-25: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 40-26: Loss: 0.6078 Acc: 75.0000%\n",
      "\tvalidation 40-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-28: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 40-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-30: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 40-31: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 40-32: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 40-33: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-34: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-40: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-41: Loss: 0.3473 Acc: 75.0000%\n",
      "\tvalidation 40-42: Loss: 0.5682 Acc: 75.0000%\n",
      "\tvalidation 40-43: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 40-44: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-46: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 40-47: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-49: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 40-50: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-52: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 40-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-54: Loss: 0.1565 Acc: 75.0000%\n",
      "\tvalidation 40-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-56: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 40-57: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 40-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-60: Loss: 1.1450 Acc: 75.0000%\n",
      "\tvalidation 40-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-62: Loss: 0.2095 Acc: 75.0000%\n",
      "\tvalidation 40-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-64: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 40-65: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 40-66: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-67: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-68: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-71: Loss: 0.6844 Acc: 75.0000%\n",
      "\tvalidation 40-72: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 40-73: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 40-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-75: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-76: Loss: 0.1246 Acc: 75.0000%\n",
      "\tvalidation 40-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-78: Loss: 3.0669 Acc: 75.0000%\n",
      "\tvalidation 40-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-84: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-86: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-88: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-90: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 40-91: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-93: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 40-94: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-95: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 40-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-98: Loss: 1.1772 Acc: 75.0000%\n",
      "\tvalidation 40-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-102: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-104: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-105: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0397 Acc: 95.0000%\n",
      "\tvalidation Loss: 0.1872 Acc: 96.1905%\n",
      "Time passed 0h 31m 3s\n",
      "--------------------\n",
      "Training complete in 0h 31m 3s\n",
      "Best validation Acc: 0.997619\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "loss_train = []  # 训练集loss\n",
    "acc_train = []  # 训练集正确率\n",
    "loss_val = []  # 验证集loss\n",
    "acc_val = []  # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "\n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            i = 1\n",
    "            j = 1\n",
    "            # exp_lr_scheduler.step()\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            i = 1\n",
    "            j = 2\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            # if use_gpu:\n",
    "            #     inputs = inputs.cuda()\n",
    "            #     labels = labels.cuda()\n",
    "            # else:\n",
    "            #     inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            # '_'就是一个变量，换成a也是可以的，没有特别的意思，不过一般用_表示的变量好像都是没什么用的一个临时变量，大概是\n",
    "            # 一个编程习惯吧。所以这边'_,'没有特殊的含义，'_'就是一个变量，只是为了让preds取到max函数返回值的第二项，\n",
    "            # 即找到的最大值的索引位置（对应到这里就是类别标签）\n",
    "            # （max函数解释见https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max）\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, num_classes):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "\n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, i, loss.item()/4, torch.sum(preds == labels.data).item()/4.0*100))\n",
    "            i = i + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if j == 1:\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and j == 2:\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'validation' and epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"网络参数更新\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/params_resnet101.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "#             print(\"Model's state_dict:\")\n",
    "#             for param_tensor in best_model_wts:\n",
    "#                 print(param_tensor, \"\\t\", best_model_wts[param_tensor].size())\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.2918989690894983, 0.24658944098925104, 0.22712520151113977, 0.20530519747004217, 0.20772707924550893, 0.19081396118414645, 0.1779104121029377, 0.18731633315280993, 0.1737981757795324, 0.16693661833296017, 0.125907730235129, 0.11736387496395986, 0.12441228445695371, 0.11560528261625037, 0.09929679721897962, 0.09782357037979729, 0.0969054782421005, 0.09697610547347944, 0.06294989744011237, 0.07066593969963035, 0.04877796431585234, 0.06726465675295616, 0.06123028745760723, 0.06213363909295627, 0.04859674372235123, 0.057976044714450836, 0.045928109011479784, 0.06781339126886153, 0.06176334230267272, 0.04322404893381255, 0.045298104976512946, 0.03255704721930076, 0.04735652950345254, 0.03751631617850187, 0.04030546625049747, 0.05441911176455264, 0.04211380414816798, 0.034125421819638235, 0.03829840219446591, 0.03970984872810695]\n",
      "loss_val: [0.3264344858271735, 0.4548488543856712, 0.28018151209467934, 0.30019545200325193, 0.08890250311011359, 0.42267830747933616, 0.12112256178543682, 0.25062684892188936, 0.06566510392086847, 0.23456020922887894, 0.1599912738516217, 0.03905628855739321, 0.03034465703226271, 0.09134647157930192, 0.336482553538822, 0.11114811577967235, 0.059949677331107, 0.19170316464844203, 0.06352712015310923, 0.06465180537530354, 0.07467011802253269, 0.10679183077244532, 0.2026210525206157, 0.1386652213476953, 0.06747966160376867, 0.10042458439157123, 0.02764742573102315, 0.05576411421809878, 0.04194877942403157, 0.2621850650934946, 0.04875974577097666, 0.20019539083753313, 0.2425404517423539, 0.02315989477293832, 0.21094848534890584, 0.17887497324319113, 0.12130409755877086, 0.004399740341163817, 0.030912104816663833, 0.1872495453272547]\n",
      "acc_train: [0.5948979591836735, 0.5867346938775511, 0.610204081632653, 0.6377551020408163, 0.6448979591836734, 0.6642857142857143, 0.6704081632653062, 0.7030612244897959, 0.75, 0.7408163265306122, 0.7959183673469388, 0.8193877551020409, 0.8193877551020409, 0.8316326530612245, 0.8510204081632653, 0.8551020408163266, 0.8663265306122448, 0.8663265306122448, 0.9132653061224489, 0.9112244897959184, 0.936734693877551, 0.9, 0.9193877551020408, 0.9122448979591836, 0.9448979591836735, 0.926530612244898, 0.9448979591836735, 0.9295918367346939, 0.9204081632653062, 0.9387755102040817, 0.9336734693877551, 0.9530612244897959, 0.9377551020408164, 0.9448979591836735, 0.9459183673469388, 0.9275510204081633, 0.9469387755102041, 0.9571428571428572, 0.95, 0.95]\n",
      "acc_val: [0.7142857142857143, 0.7119047619047619, 0.75, 0.7071428571428572, 0.8023809523809524, 0.7404761904761905, 0.8571428571428571, 0.7428571428571429, 0.8833333333333333, 0.8452380952380952, 0.888095238095238, 0.969047619047619, 0.9595238095238096, 0.9666666666666667, 0.9261904761904762, 0.9523809523809523, 0.9738095238095238, 0.9047619047619048, 0.9738095238095238, 0.9761904761904762, 0.969047619047619, 0.9547619047619048, 0.930952380952381, 0.9619047619047619, 0.9666666666666667, 0.9714285714285714, 0.9738095238095238, 0.9380952380952381, 0.9904761904761905, 0.9595238095238096, 0.969047619047619, 0.95, 0.9642857142857143, 0.9761904761904762, 0.9261904761904762, 0.9619047619047619, 0.9738095238095238, 0.9976190476190476, 0.9833333333333333, 0.9619047619047619]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss(ResNet101)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy(ResNet101)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:     77    79    77    81\n",
      "Predicted:     81    79    77    81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('75', '77', '79', '81')\n",
    "\n",
    "dataiter = iter(dataloders['validation'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[z]] for z in range(4)))\n",
    "\n",
    "# test\n",
    "outputs = model(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[z]] for z in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   Predicted\n",
      "\n",
      "\t   75\t77\t79\t81\n",
      "\n",
      "Actual 75  105\t0\t0\t0\t\n",
      "\n",
      "Actual 77  0\t104\t0\t1\t\n",
      "\n",
      "Actual 79  0\t0\t105\t0\t\n",
      "\n",
      "Actual 81  0\t0\t0\t105\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conc = {\n",
    "    '0': '75  ',\n",
    "    '1': '77  ',\n",
    "    '2': '79  ',\n",
    "    '3': '81  '\n",
    "}\n",
    "\n",
    "print(\"\\t   Predicted\\n\")\n",
    "print(\"\\t   75\\t77\\t79\\t81\\n\")\n",
    "for i in range(0, num_classes):\n",
    "    print(\"Actual \", end='')\n",
    "    print(conc[str(i)], end='')\n",
    "    for j in range(0, num_classes):\n",
    "        print(str(best_matrix[i][j]) + '\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
