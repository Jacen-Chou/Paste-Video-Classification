{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load paste_video_classification_vgg16_add_matrix.py\n",
    "\n",
    "# 这个代码每个epoch都跑一遍训练集和验证集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "shuffle = True\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载vgg16预训练模型\n",
    "model = models.vgg16(pretrained=False)\n",
    "model.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(4096, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(4096, num_classes))\n",
    "# 加载上次训练的参数\n",
    "# model.load_state_dict(torch.load('./parameter/params_vgg16.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = shuffle,\n",
    "                                             num_workers = 10) for x in ['train', 'validation']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]:\n",
      "\ttrain 1-1: Loss: 0.3466 Acc: 0.0000%\n",
      "\ttrain 1-2: Loss: 0.3461 Acc: 25.0000%\n",
      "\ttrain 1-3: Loss: 0.3493 Acc: 0.0000%\n",
      "\ttrain 1-4: Loss: 0.3456 Acc: 25.0000%\n",
      "\ttrain 1-5: Loss: 0.3419 Acc: 75.0000%\n",
      "\ttrain 1-6: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 1-7: Loss: 0.3459 Acc: 25.0000%\n",
      "\ttrain 1-8: Loss: 0.3438 Acc: 25.0000%\n",
      "\ttrain 1-9: Loss: 0.3459 Acc: 25.0000%\n",
      "\ttrain 1-10: Loss: 0.3453 Acc: 25.0000%\n",
      "\ttrain 1-11: Loss: 0.3520 Acc: 0.0000%\n",
      "\ttrain 1-12: Loss: 0.3417 Acc: 50.0000%\n",
      "\ttrain 1-13: Loss: 0.3520 Acc: 0.0000%\n",
      "\ttrain 1-14: Loss: 0.3445 Acc: 50.0000%\n",
      "\ttrain 1-15: Loss: 0.3385 Acc: 50.0000%\n",
      "\ttrain 1-16: Loss: 0.3544 Acc: 0.0000%\n",
      "\ttrain 1-17: Loss: 0.3453 Acc: 0.0000%\n",
      "\ttrain 1-18: Loss: 0.3559 Acc: 0.0000%\n",
      "\ttrain 1-19: Loss: 0.3383 Acc: 50.0000%\n",
      "\ttrain 1-20: Loss: 0.3346 Acc: 50.0000%\n",
      "\ttrain 1-21: Loss: 0.3480 Acc: 25.0000%\n",
      "\ttrain 1-22: Loss: 0.3535 Acc: 0.0000%\n",
      "\ttrain 1-23: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 1-24: Loss: 0.3385 Acc: 25.0000%\n",
      "\ttrain 1-25: Loss: 0.3535 Acc: 25.0000%\n",
      "\ttrain 1-26: Loss: 0.3456 Acc: 25.0000%\n",
      "\ttrain 1-27: Loss: 0.3355 Acc: 25.0000%\n",
      "\ttrain 1-28: Loss: 0.3499 Acc: 0.0000%\n",
      "\ttrain 1-29: Loss: 0.3381 Acc: 25.0000%\n",
      "\ttrain 1-30: Loss: 0.3370 Acc: 0.0000%\n",
      "\ttrain 1-31: Loss: 0.3635 Acc: 0.0000%\n",
      "\ttrain 1-32: Loss: 0.3362 Acc: 25.0000%\n",
      "\ttrain 1-33: Loss: 0.3486 Acc: 25.0000%\n",
      "\ttrain 1-34: Loss: 0.3338 Acc: 0.0000%\n",
      "\ttrain 1-35: Loss: 0.3407 Acc: 75.0000%\n",
      "\ttrain 1-36: Loss: 0.3301 Acc: 25.0000%\n",
      "\ttrain 1-37: Loss: 0.3594 Acc: 25.0000%\n",
      "\ttrain 1-38: Loss: 0.3537 Acc: 0.0000%\n",
      "\ttrain 1-39: Loss: 0.3414 Acc: 50.0000%\n",
      "\ttrain 1-40: Loss: 0.3274 Acc: 25.0000%\n",
      "\ttrain 1-41: Loss: 0.3268 Acc: 75.0000%\n",
      "\ttrain 1-42: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 1-43: Loss: 0.3633 Acc: 25.0000%\n",
      "\ttrain 1-44: Loss: 0.3453 Acc: 50.0000%\n",
      "\ttrain 1-45: Loss: 0.3554 Acc: 0.0000%\n",
      "\ttrain 1-46: Loss: 0.3838 Acc: 0.0000%\n",
      "\ttrain 1-47: Loss: 0.3248 Acc: 50.0000%\n",
      "\ttrain 1-48: Loss: 0.3271 Acc: 50.0000%\n",
      "\ttrain 1-49: Loss: 0.3736 Acc: 25.0000%\n",
      "\ttrain 1-50: Loss: 0.3524 Acc: 0.0000%\n",
      "\ttrain 1-51: Loss: 0.3321 Acc: 25.0000%\n",
      "\ttrain 1-52: Loss: 0.3354 Acc: 50.0000%\n",
      "\ttrain 1-53: Loss: 0.3607 Acc: 0.0000%\n",
      "\ttrain 1-54: Loss: 0.3241 Acc: 50.0000%\n",
      "\ttrain 1-55: Loss: 0.3286 Acc: 50.0000%\n",
      "\ttrain 1-56: Loss: 0.3458 Acc: 50.0000%\n",
      "\ttrain 1-57: Loss: 0.3704 Acc: 0.0000%\n",
      "\ttrain 1-58: Loss: 0.3216 Acc: 75.0000%\n",
      "\ttrain 1-59: Loss: 0.3410 Acc: 25.0000%\n",
      "\ttrain 1-60: Loss: 0.3500 Acc: 25.0000%\n",
      "\ttrain 1-61: Loss: 0.3730 Acc: 0.0000%\n",
      "\ttrain 1-62: Loss: 0.3996 Acc: 0.0000%\n",
      "\ttrain 1-63: Loss: 0.3788 Acc: 0.0000%\n",
      "\ttrain 1-64: Loss: 0.3450 Acc: 25.0000%\n",
      "\ttrain 1-65: Loss: 0.3507 Acc: 25.0000%\n",
      "\ttrain 1-66: Loss: 0.3621 Acc: 0.0000%\n",
      "\ttrain 1-67: Loss: 0.3502 Acc: 25.0000%\n",
      "\ttrain 1-68: Loss: 0.3701 Acc: 0.0000%\n",
      "\ttrain 1-69: Loss: 0.3525 Acc: 0.0000%\n",
      "\ttrain 1-70: Loss: 0.3355 Acc: 50.0000%\n",
      "\ttrain 1-71: Loss: 0.3571 Acc: 0.0000%\n",
      "\ttrain 1-72: Loss: 0.3457 Acc: 50.0000%\n",
      "\ttrain 1-73: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 1-74: Loss: 0.3492 Acc: 0.0000%\n",
      "\ttrain 1-75: Loss: 0.3493 Acc: 0.0000%\n",
      "\ttrain 1-76: Loss: 0.3425 Acc: 75.0000%\n",
      "\ttrain 1-77: Loss: 0.3470 Acc: 25.0000%\n",
      "\ttrain 1-78: Loss: 0.3538 Acc: 0.0000%\n",
      "\ttrain 1-79: Loss: 0.3495 Acc: 0.0000%\n",
      "\ttrain 1-80: Loss: 0.3419 Acc: 75.0000%\n",
      "\ttrain 1-81: Loss: 0.3441 Acc: 50.0000%\n",
      "\ttrain 1-82: Loss: 0.3489 Acc: 0.0000%\n",
      "\ttrain 1-83: Loss: 0.3457 Acc: 50.0000%\n",
      "\ttrain 1-84: Loss: 0.3453 Acc: 25.0000%\n",
      "\ttrain 1-85: Loss: 0.3502 Acc: 0.0000%\n",
      "\ttrain 1-86: Loss: 0.3441 Acc: 25.0000%\n",
      "\ttrain 1-87: Loss: 0.3477 Acc: 25.0000%\n",
      "\ttrain 1-88: Loss: 0.3447 Acc: 25.0000%\n",
      "\ttrain 1-89: Loss: 0.3447 Acc: 0.0000%\n",
      "\ttrain 1-90: Loss: 0.3474 Acc: 25.0000%\n",
      "\ttrain 1-91: Loss: 0.3449 Acc: 25.0000%\n",
      "\ttrain 1-92: Loss: 0.3438 Acc: 25.0000%\n",
      "\ttrain 1-93: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 1-94: Loss: 0.3365 Acc: 50.0000%\n",
      "\ttrain 1-95: Loss: 0.3500 Acc: 0.0000%\n",
      "\ttrain 1-96: Loss: 0.3348 Acc: 100.0000%\n",
      "\ttrain 1-97: Loss: 0.3402 Acc: 75.0000%\n",
      "\ttrain 1-98: Loss: 0.3412 Acc: 25.0000%\n",
      "\ttrain 1-99: Loss: 0.3464 Acc: 25.0000%\n",
      "\ttrain 1-100: Loss: 0.3566 Acc: 25.0000%\n",
      "\ttrain 1-101: Loss: 0.3514 Acc: 0.0000%\n",
      "\ttrain 1-102: Loss: 0.3567 Acc: 0.0000%\n",
      "\ttrain 1-103: Loss: 0.3357 Acc: 50.0000%\n",
      "\ttrain 1-104: Loss: 0.3534 Acc: 0.0000%\n",
      "\ttrain 1-105: Loss: 0.3367 Acc: 0.0000%\n",
      "\ttrain 1-106: Loss: 0.3566 Acc: 25.0000%\n",
      "\ttrain 1-107: Loss: 0.3379 Acc: 25.0000%\n",
      "\ttrain 1-108: Loss: 0.3536 Acc: 25.0000%\n",
      "\ttrain 1-109: Loss: 0.3446 Acc: 50.0000%\n",
      "\ttrain 1-110: Loss: 0.3461 Acc: 25.0000%\n",
      "\ttrain 1-111: Loss: 0.3452 Acc: 25.0000%\n",
      "\ttrain 1-112: Loss: 0.3439 Acc: 25.0000%\n",
      "\ttrain 1-113: Loss: 0.3448 Acc: 25.0000%\n",
      "\ttrain 1-114: Loss: 0.3353 Acc: 50.0000%\n",
      "\ttrain 1-115: Loss: 0.3429 Acc: 50.0000%\n",
      "\ttrain 1-116: Loss: 0.3472 Acc: 25.0000%\n",
      "\ttrain 1-117: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 1-118: Loss: 0.3459 Acc: 0.0000%\n",
      "\ttrain 1-119: Loss: 0.3378 Acc: 50.0000%\n",
      "\ttrain 1-120: Loss: 0.3463 Acc: 0.0000%\n",
      "\ttrain 1-121: Loss: 0.3597 Acc: 25.0000%\n",
      "\ttrain 1-122: Loss: 0.3480 Acc: 0.0000%\n",
      "\ttrain 1-123: Loss: 0.3583 Acc: 0.0000%\n",
      "\ttrain 1-124: Loss: 0.3353 Acc: 25.0000%\n",
      "\ttrain 1-125: Loss: 0.3352 Acc: 50.0000%\n",
      "\ttrain 1-126: Loss: 0.3368 Acc: 50.0000%\n",
      "\ttrain 1-127: Loss: 0.3594 Acc: 0.0000%\n",
      "\ttrain 1-128: Loss: 0.3608 Acc: 0.0000%\n",
      "\ttrain 1-129: Loss: 0.3611 Acc: 25.0000%\n",
      "\ttrain 1-130: Loss: 0.3466 Acc: 25.0000%\n",
      "\ttrain 1-131: Loss: 0.3337 Acc: 25.0000%\n",
      "\ttrain 1-132: Loss: 0.3326 Acc: 50.0000%\n",
      "\ttrain 1-133: Loss: 0.3302 Acc: 50.0000%\n",
      "\ttrain 1-134: Loss: 0.3402 Acc: 50.0000%\n",
      "\ttrain 1-135: Loss: 0.3418 Acc: 25.0000%\n",
      "\ttrain 1-136: Loss: 0.3447 Acc: 25.0000%\n",
      "\ttrain 1-137: Loss: 0.3265 Acc: 50.0000%\n",
      "\ttrain 1-138: Loss: 0.3531 Acc: 25.0000%\n",
      "\ttrain 1-139: Loss: 0.3462 Acc: 50.0000%\n",
      "\ttrain 1-140: Loss: 0.3629 Acc: 0.0000%\n",
      "\ttrain 1-141: Loss: 0.3417 Acc: 50.0000%\n",
      "\ttrain 1-142: Loss: 0.3437 Acc: 25.0000%\n",
      "\ttrain 1-143: Loss: 0.3430 Acc: 25.0000%\n",
      "\ttrain 1-144: Loss: 0.3501 Acc: 25.0000%\n",
      "\ttrain 1-145: Loss: 0.3434 Acc: 0.0000%\n",
      "\ttrain 1-146: Loss: 0.3205 Acc: 50.0000%\n",
      "\ttrain 1-147: Loss: 0.3558 Acc: 25.0000%\n",
      "\ttrain 1-148: Loss: 0.3184 Acc: 50.0000%\n",
      "\ttrain 1-149: Loss: 0.3537 Acc: 0.0000%\n",
      "\ttrain 1-150: Loss: 0.3496 Acc: 25.0000%\n",
      "\ttrain 1-151: Loss: 0.3328 Acc: 25.0000%\n",
      "\ttrain 1-152: Loss: 0.3616 Acc: 0.0000%\n",
      "\ttrain 1-153: Loss: 0.3739 Acc: 0.0000%\n",
      "\ttrain 1-154: Loss: 0.3816 Acc: 0.0000%\n",
      "\ttrain 1-155: Loss: 0.3389 Acc: 0.0000%\n",
      "\ttrain 1-156: Loss: 0.3341 Acc: 50.0000%\n",
      "\ttrain 1-157: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 1-158: Loss: 0.3563 Acc: 0.0000%\n",
      "\ttrain 1-159: Loss: 0.3376 Acc: 25.0000%\n",
      "\ttrain 1-160: Loss: 0.3469 Acc: 0.0000%\n",
      "\ttrain 1-161: Loss: 0.3432 Acc: 50.0000%\n",
      "\ttrain 1-162: Loss: 0.3391 Acc: 25.0000%\n",
      "\ttrain 1-163: Loss: 0.3536 Acc: 25.0000%\n",
      "\ttrain 1-164: Loss: 0.3331 Acc: 50.0000%\n",
      "\ttrain 1-165: Loss: 0.3511 Acc: 0.0000%\n",
      "\ttrain 1-166: Loss: 0.3204 Acc: 50.0000%\n",
      "\ttrain 1-167: Loss: 0.3423 Acc: 25.0000%\n",
      "\ttrain 1-168: Loss: 0.3288 Acc: 50.0000%\n",
      "\ttrain 1-169: Loss: 0.3526 Acc: 0.0000%\n",
      "\ttrain 1-170: Loss: 0.3420 Acc: 25.0000%\n",
      "\ttrain 1-171: Loss: 0.3396 Acc: 25.0000%\n",
      "\ttrain 1-172: Loss: 0.3564 Acc: 25.0000%\n",
      "\ttrain 1-173: Loss: 0.3507 Acc: 0.0000%\n",
      "\ttrain 1-174: Loss: 0.3438 Acc: 25.0000%\n",
      "\ttrain 1-175: Loss: 0.3736 Acc: 0.0000%\n",
      "\ttrain 1-176: Loss: 0.3567 Acc: 25.0000%\n",
      "\ttrain 1-177: Loss: 0.3535 Acc: 25.0000%\n",
      "\ttrain 1-178: Loss: 0.3631 Acc: 0.0000%\n",
      "\ttrain 1-179: Loss: 0.3395 Acc: 50.0000%\n",
      "\ttrain 1-180: Loss: 0.3284 Acc: 50.0000%\n",
      "\ttrain 1-181: Loss: 0.3530 Acc: 0.0000%\n",
      "\ttrain 1-182: Loss: 0.3432 Acc: 0.0000%\n",
      "\ttrain 1-183: Loss: 0.3414 Acc: 25.0000%\n",
      "\ttrain 1-184: Loss: 0.3629 Acc: 0.0000%\n",
      "\ttrain 1-185: Loss: 0.3648 Acc: 0.0000%\n",
      "\ttrain 1-186: Loss: 0.3564 Acc: 25.0000%\n",
      "\ttrain 1-187: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 1-188: Loss: 0.3398 Acc: 25.0000%\n",
      "\ttrain 1-189: Loss: 0.3519 Acc: 0.0000%\n",
      "\ttrain 1-190: Loss: 0.3581 Acc: 0.0000%\n",
      "\ttrain 1-191: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 1-192: Loss: 0.3434 Acc: 25.0000%\n",
      "\ttrain 1-193: Loss: 0.3422 Acc: 25.0000%\n",
      "\ttrain 1-194: Loss: 0.3415 Acc: 25.0000%\n",
      "\ttrain 1-195: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 1-196: Loss: 0.3450 Acc: 25.0000%\n",
      "\ttrain 1-197: Loss: 0.3416 Acc: 50.0000%\n",
      "\ttrain 1-198: Loss: 0.3468 Acc: 25.0000%\n",
      "\ttrain 1-199: Loss: 0.3454 Acc: 25.0000%\n",
      "\ttrain 1-200: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 1-201: Loss: 0.3467 Acc: 0.0000%\n",
      "\ttrain 1-202: Loss: 0.3366 Acc: 75.0000%\n",
      "\ttrain 1-203: Loss: 0.3518 Acc: 0.0000%\n",
      "\ttrain 1-204: Loss: 0.3432 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-205: Loss: 0.3550 Acc: 0.0000%\n",
      "\ttrain 1-206: Loss: 0.3465 Acc: 25.0000%\n",
      "\ttrain 1-207: Loss: 0.3415 Acc: 50.0000%\n",
      "\ttrain 1-208: Loss: 0.3401 Acc: 50.0000%\n",
      "\ttrain 1-209: Loss: 0.3466 Acc: 0.0000%\n",
      "\ttrain 1-210: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 1-211: Loss: 0.3415 Acc: 50.0000%\n",
      "\ttrain 1-212: Loss: 0.3565 Acc: 0.0000%\n",
      "\ttrain 1-213: Loss: 0.3521 Acc: 0.0000%\n",
      "\ttrain 1-214: Loss: 0.3442 Acc: 0.0000%\n",
      "\ttrain 1-215: Loss: 0.3466 Acc: 25.0000%\n",
      "\ttrain 1-216: Loss: 0.3429 Acc: 50.0000%\n",
      "\ttrain 1-217: Loss: 0.3472 Acc: 25.0000%\n",
      "\ttrain 1-218: Loss: 0.3526 Acc: 0.0000%\n",
      "\ttrain 1-219: Loss: 0.3472 Acc: 25.0000%\n",
      "\ttrain 1-220: Loss: 0.3374 Acc: 50.0000%\n",
      "\ttrain 1-221: Loss: 0.3403 Acc: 25.0000%\n",
      "\ttrain 1-222: Loss: 0.3483 Acc: 25.0000%\n",
      "\ttrain 1-223: Loss: 0.3489 Acc: 25.0000%\n",
      "\ttrain 1-224: Loss: 0.3383 Acc: 50.0000%\n",
      "\ttrain 1-225: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 1-226: Loss: 0.3498 Acc: 0.0000%\n",
      "\ttrain 1-227: Loss: 0.3389 Acc: 50.0000%\n",
      "\ttrain 1-228: Loss: 0.3419 Acc: 25.0000%\n",
      "\ttrain 1-229: Loss: 0.3499 Acc: 0.0000%\n",
      "\ttrain 1-230: Loss: 0.3389 Acc: 50.0000%\n",
      "\ttrain 1-231: Loss: 0.3452 Acc: 0.0000%\n",
      "\ttrain 1-232: Loss: 0.3503 Acc: 0.0000%\n",
      "\ttrain 1-233: Loss: 0.3505 Acc: 0.0000%\n",
      "\ttrain 1-234: Loss: 0.3401 Acc: 50.0000%\n",
      "\ttrain 1-235: Loss: 0.3484 Acc: 25.0000%\n",
      "\ttrain 1-236: Loss: 0.3416 Acc: 50.0000%\n",
      "\ttrain 1-237: Loss: 0.3460 Acc: 25.0000%\n",
      "\ttrain 1-238: Loss: 0.3453 Acc: 25.0000%\n",
      "\ttrain 1-239: Loss: 0.3520 Acc: 0.0000%\n",
      "\ttrain 1-240: Loss: 0.3446 Acc: 50.0000%\n",
      "\ttrain 1-241: Loss: 0.3485 Acc: 0.0000%\n",
      "\ttrain 1-242: Loss: 0.3393 Acc: 25.0000%\n",
      "\ttrain 1-243: Loss: 0.3537 Acc: 0.0000%\n",
      "\ttrain 1-244: Loss: 0.3466 Acc: 25.0000%\n",
      "\ttrain 1-245: Loss: 0.3470 Acc: 25.0000%\n",
      "\tvalidation 1-1: Loss: 0.3452 Acc: 25.0000%\n",
      "\tvalidation 1-2: Loss: 0.3508 Acc: 0.0000%\n",
      "\tvalidation 1-3: Loss: 0.3451 Acc: 0.0000%\n",
      "\tvalidation 1-4: Loss: 0.3446 Acc: 25.0000%\n",
      "\tvalidation 1-5: Loss: 0.3559 Acc: 0.0000%\n",
      "\tvalidation 1-6: Loss: 0.3440 Acc: 25.0000%\n",
      "\tvalidation 1-7: Loss: 0.3453 Acc: 25.0000%\n",
      "\tvalidation 1-8: Loss: 0.3498 Acc: 25.0000%\n",
      "\tvalidation 1-9: Loss: 0.3390 Acc: 50.0000%\n",
      "\tvalidation 1-10: Loss: 0.3452 Acc: 25.0000%\n",
      "\tvalidation 1-11: Loss: 0.3407 Acc: 25.0000%\n",
      "\tvalidation 1-12: Loss: 0.3394 Acc: 75.0000%\n",
      "\tvalidation 1-13: Loss: 0.3386 Acc: 50.0000%\n",
      "\tvalidation 1-14: Loss: 0.3557 Acc: 0.0000%\n",
      "\tvalidation 1-15: Loss: 0.3491 Acc: 25.0000%\n",
      "\tvalidation 1-16: Loss: 0.3505 Acc: 25.0000%\n",
      "\tvalidation 1-17: Loss: 0.3451 Acc: 25.0000%\n",
      "\tvalidation 1-18: Loss: 0.3488 Acc: 25.0000%\n",
      "\tvalidation 1-19: Loss: 0.3445 Acc: 50.0000%\n",
      "\tvalidation 1-20: Loss: 0.3392 Acc: 50.0000%\n",
      "\tvalidation 1-21: Loss: 0.3448 Acc: 50.0000%\n",
      "\tvalidation 1-22: Loss: 0.3436 Acc: 50.0000%\n",
      "\tvalidation 1-23: Loss: 0.3393 Acc: 75.0000%\n",
      "\tvalidation 1-24: Loss: 0.3424 Acc: 50.0000%\n",
      "\tvalidation 1-25: Loss: 0.3350 Acc: 50.0000%\n",
      "\tvalidation 1-26: Loss: 0.3392 Acc: 25.0000%\n",
      "\tvalidation 1-27: Loss: 0.3454 Acc: 0.0000%\n",
      "\tvalidation 1-28: Loss: 0.3513 Acc: 0.0000%\n",
      "\tvalidation 1-29: Loss: 0.3432 Acc: 50.0000%\n",
      "\tvalidation 1-30: Loss: 0.3563 Acc: 0.0000%\n",
      "\tvalidation 1-31: Loss: 0.3481 Acc: 25.0000%\n",
      "\tvalidation 1-32: Loss: 0.3442 Acc: 50.0000%\n",
      "\tvalidation 1-33: Loss: 0.3389 Acc: 75.0000%\n",
      "\tvalidation 1-34: Loss: 0.3454 Acc: 25.0000%\n",
      "\tvalidation 1-35: Loss: 0.3461 Acc: 0.0000%\n",
      "\tvalidation 1-36: Loss: 0.3454 Acc: 25.0000%\n",
      "\tvalidation 1-37: Loss: 0.3543 Acc: 0.0000%\n",
      "\tvalidation 1-38: Loss: 0.3443 Acc: 0.0000%\n",
      "\tvalidation 1-39: Loss: 0.3509 Acc: 0.0000%\n",
      "\tvalidation 1-40: Loss: 0.3337 Acc: 50.0000%\n",
      "\tvalidation 1-41: Loss: 0.3438 Acc: 25.0000%\n",
      "\tvalidation 1-42: Loss: 0.3447 Acc: 25.0000%\n",
      "\tvalidation 1-43: Loss: 0.3352 Acc: 50.0000%\n",
      "\tvalidation 1-44: Loss: 0.3492 Acc: 25.0000%\n",
      "\tvalidation 1-45: Loss: 0.3459 Acc: 0.0000%\n",
      "\tvalidation 1-46: Loss: 0.3497 Acc: 25.0000%\n",
      "\tvalidation 1-47: Loss: 0.3449 Acc: 25.0000%\n",
      "\tvalidation 1-48: Loss: 0.3500 Acc: 0.0000%\n",
      "\tvalidation 1-49: Loss: 0.3394 Acc: 25.0000%\n",
      "\tvalidation 1-50: Loss: 0.3454 Acc: 25.0000%\n",
      "\tvalidation 1-51: Loss: 0.3463 Acc: 0.0000%\n",
      "\tvalidation 1-52: Loss: 0.3432 Acc: 50.0000%\n",
      "\tvalidation 1-53: Loss: 0.3454 Acc: 0.0000%\n",
      "\tvalidation 1-54: Loss: 0.3391 Acc: 50.0000%\n",
      "\tvalidation 1-55: Loss: 0.3561 Acc: 0.0000%\n",
      "\tvalidation 1-56: Loss: 0.3541 Acc: 0.0000%\n",
      "\tvalidation 1-57: Loss: 0.3412 Acc: 0.0000%\n",
      "\tvalidation 1-58: Loss: 0.3411 Acc: 0.0000%\n",
      "\tvalidation 1-59: Loss: 0.3450 Acc: 50.0000%\n",
      "\tvalidation 1-60: Loss: 0.3347 Acc: 25.0000%\n",
      "\tvalidation 1-61: Loss: 0.3457 Acc: 50.0000%\n",
      "\tvalidation 1-62: Loss: 0.3453 Acc: 0.0000%\n",
      "\tvalidation 1-63: Loss: 0.3399 Acc: 25.0000%\n",
      "\tvalidation 1-64: Loss: 0.3547 Acc: 0.0000%\n",
      "\tvalidation 1-65: Loss: 0.3397 Acc: 50.0000%\n",
      "\tvalidation 1-66: Loss: 0.3398 Acc: 25.0000%\n",
      "\tvalidation 1-67: Loss: 0.3336 Acc: 50.0000%\n",
      "\tvalidation 1-68: Loss: 0.3449 Acc: 25.0000%\n",
      "\tvalidation 1-69: Loss: 0.3334 Acc: 50.0000%\n",
      "\tvalidation 1-70: Loss: 0.3465 Acc: 25.0000%\n",
      "\tvalidation 1-71: Loss: 0.3514 Acc: 25.0000%\n",
      "\tvalidation 1-72: Loss: 0.3499 Acc: 0.0000%\n",
      "\tvalidation 1-73: Loss: 0.3570 Acc: 0.0000%\n",
      "\tvalidation 1-74: Loss: 0.3445 Acc: 25.0000%\n",
      "\tvalidation 1-75: Loss: 0.3376 Acc: 75.0000%\n",
      "\tvalidation 1-76: Loss: 0.3389 Acc: 75.0000%\n",
      "\tvalidation 1-77: Loss: 0.3392 Acc: 75.0000%\n",
      "\tvalidation 1-78: Loss: 0.3449 Acc: 25.0000%\n",
      "\tvalidation 1-79: Loss: 0.3558 Acc: 0.0000%\n",
      "\tvalidation 1-80: Loss: 0.3331 Acc: 50.0000%\n",
      "\tvalidation 1-81: Loss: 0.3498 Acc: 25.0000%\n",
      "\tvalidation 1-82: Loss: 0.3500 Acc: 0.0000%\n",
      "\tvalidation 1-83: Loss: 0.3447 Acc: 25.0000%\n",
      "\tvalidation 1-84: Loss: 0.3486 Acc: 25.0000%\n",
      "\tvalidation 1-85: Loss: 0.3388 Acc: 50.0000%\n",
      "\tvalidation 1-86: Loss: 0.3415 Acc: 0.0000%\n",
      "\tvalidation 1-87: Loss: 0.3504 Acc: 0.0000%\n",
      "\tvalidation 1-88: Loss: 0.3495 Acc: 25.0000%\n",
      "\tvalidation 1-89: Loss: 0.3441 Acc: 25.0000%\n",
      "\tvalidation 1-90: Loss: 0.3404 Acc: 50.0000%\n",
      "\tvalidation 1-91: Loss: 0.3402 Acc: 25.0000%\n",
      "\tvalidation 1-92: Loss: 0.3397 Acc: 50.0000%\n",
      "\tvalidation 1-93: Loss: 0.3446 Acc: 50.0000%\n",
      "\tvalidation 1-94: Loss: 0.3493 Acc: 0.0000%\n",
      "\tvalidation 1-95: Loss: 0.3439 Acc: 25.0000%\n",
      "\tvalidation 1-96: Loss: 0.3374 Acc: 50.0000%\n",
      "\tvalidation 1-97: Loss: 0.3457 Acc: 0.0000%\n",
      "\tvalidation 1-98: Loss: 0.3403 Acc: 50.0000%\n",
      "\tvalidation 1-99: Loss: 0.3391 Acc: 25.0000%\n",
      "\tvalidation 1-100: Loss: 0.3493 Acc: 0.0000%\n",
      "\tvalidation 1-101: Loss: 0.3384 Acc: 75.0000%\n",
      "\tvalidation 1-102: Loss: 0.3456 Acc: 0.0000%\n",
      "\tvalidation 1-103: Loss: 0.3553 Acc: 0.0000%\n",
      "\tvalidation 1-104: Loss: 0.3554 Acc: 0.0000%\n",
      "\tvalidation 1-105: Loss: 0.3403 Acc: 25.0000%\n",
      "\ttrain Loss: 0.3464 Acc: 24.3878%\n",
      "\tvalidation Loss: 0.3448 Acc: 26.6667%\n",
      "网络参数更新\n",
      "Time passed 0h 0m 47s\n",
      "--------------------\n",
      "Epoch [2/40]:\n",
      "\ttrain 2-1: Loss: 0.3403 Acc: 25.0000%\n",
      "\ttrain 2-2: Loss: 0.3399 Acc: 50.0000%\n",
      "\ttrain 2-3: Loss: 0.3498 Acc: 25.0000%\n",
      "\ttrain 2-4: Loss: 0.3375 Acc: 50.0000%\n",
      "\ttrain 2-5: Loss: 0.3370 Acc: 75.0000%\n",
      "\ttrain 2-6: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 2-7: Loss: 0.3555 Acc: 0.0000%\n",
      "\ttrain 2-8: Loss: 0.3394 Acc: 50.0000%\n",
      "\ttrain 2-9: Loss: 0.3495 Acc: 0.0000%\n",
      "\ttrain 2-10: Loss: 0.3503 Acc: 0.0000%\n",
      "\ttrain 2-11: Loss: 0.3507 Acc: 25.0000%\n",
      "\ttrain 2-12: Loss: 0.3441 Acc: 0.0000%\n",
      "\ttrain 2-13: Loss: 0.3366 Acc: 50.0000%\n",
      "\ttrain 2-14: Loss: 0.3438 Acc: 25.0000%\n",
      "\ttrain 2-15: Loss: 0.3448 Acc: 50.0000%\n",
      "\ttrain 2-16: Loss: 0.3398 Acc: 0.0000%\n",
      "\ttrain 2-17: Loss: 0.3456 Acc: 0.0000%\n",
      "\ttrain 2-18: Loss: 0.3506 Acc: 25.0000%\n",
      "\ttrain 2-19: Loss: 0.3405 Acc: 25.0000%\n",
      "\ttrain 2-20: Loss: 0.3478 Acc: 0.0000%\n",
      "\ttrain 2-21: Loss: 0.3542 Acc: 25.0000%\n",
      "\ttrain 2-22: Loss: 0.3392 Acc: 50.0000%\n",
      "\ttrain 2-23: Loss: 0.3522 Acc: 0.0000%\n",
      "\ttrain 2-24: Loss: 0.3340 Acc: 50.0000%\n",
      "\ttrain 2-25: Loss: 0.3380 Acc: 50.0000%\n",
      "\ttrain 2-26: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 2-27: Loss: 0.3347 Acc: 50.0000%\n",
      "\ttrain 2-28: Loss: 0.3537 Acc: 25.0000%\n",
      "\ttrain 2-29: Loss: 0.3296 Acc: 50.0000%\n",
      "\ttrain 2-30: Loss: 0.3408 Acc: 50.0000%\n",
      "\ttrain 2-31: Loss: 0.3591 Acc: 0.0000%\n",
      "\ttrain 2-32: Loss: 0.3551 Acc: 25.0000%\n",
      "\ttrain 2-33: Loss: 0.3262 Acc: 75.0000%\n",
      "\ttrain 2-34: Loss: 0.3599 Acc: 0.0000%\n",
      "\ttrain 2-35: Loss: 0.3557 Acc: 25.0000%\n",
      "\ttrain 2-36: Loss: 0.3621 Acc: 0.0000%\n",
      "\ttrain 2-37: Loss: 0.3471 Acc: 25.0000%\n",
      "\ttrain 2-38: Loss: 0.3505 Acc: 25.0000%\n",
      "\ttrain 2-39: Loss: 0.3569 Acc: 0.0000%\n",
      "\ttrain 2-40: Loss: 0.3403 Acc: 25.0000%\n",
      "\ttrain 2-41: Loss: 0.3608 Acc: 0.0000%\n",
      "\ttrain 2-42: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 2-43: Loss: 0.3331 Acc: 50.0000%\n",
      "\ttrain 2-44: Loss: 0.3449 Acc: 25.0000%\n",
      "\ttrain 2-45: Loss: 0.3361 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-46: Loss: 0.3517 Acc: 0.0000%\n",
      "\ttrain 2-47: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 2-48: Loss: 0.3429 Acc: 25.0000%\n",
      "\ttrain 2-49: Loss: 0.3274 Acc: 75.0000%\n",
      "\ttrain 2-50: Loss: 0.3598 Acc: 0.0000%\n",
      "\ttrain 2-51: Loss: 0.3329 Acc: 75.0000%\n",
      "\ttrain 2-52: Loss: 0.3361 Acc: 25.0000%\n",
      "\ttrain 2-53: Loss: 0.3419 Acc: 25.0000%\n",
      "\ttrain 2-54: Loss: 0.3328 Acc: 50.0000%\n",
      "\ttrain 2-55: Loss: 0.3488 Acc: 0.0000%\n",
      "\ttrain 2-56: Loss: 0.3356 Acc: 50.0000%\n",
      "\ttrain 2-57: Loss: 0.3317 Acc: 25.0000%\n",
      "\ttrain 2-58: Loss: 0.3408 Acc: 25.0000%\n",
      "\ttrain 2-59: Loss: 0.3682 Acc: 0.0000%\n",
      "\ttrain 2-60: Loss: 0.3481 Acc: 25.0000%\n",
      "\ttrain 2-61: Loss: 0.3695 Acc: 0.0000%\n",
      "\ttrain 2-62: Loss: 0.3396 Acc: 25.0000%\n",
      "\ttrain 2-63: Loss: 0.3562 Acc: 25.0000%\n",
      "\ttrain 2-64: Loss: 0.3289 Acc: 50.0000%\n",
      "\ttrain 2-65: Loss: 0.3578 Acc: 0.0000%\n",
      "\ttrain 2-66: Loss: 0.3516 Acc: 0.0000%\n",
      "\ttrain 2-67: Loss: 0.3360 Acc: 25.0000%\n",
      "\ttrain 2-68: Loss: 0.3296 Acc: 50.0000%\n",
      "\ttrain 2-69: Loss: 0.3513 Acc: 0.0000%\n",
      "\ttrain 2-70: Loss: 0.3314 Acc: 25.0000%\n",
      "\ttrain 2-71: Loss: 0.3572 Acc: 0.0000%\n",
      "\ttrain 2-72: Loss: 0.3425 Acc: 25.0000%\n",
      "\ttrain 2-73: Loss: 0.3290 Acc: 25.0000%\n",
      "\ttrain 2-74: Loss: 0.3491 Acc: 0.0000%\n",
      "\ttrain 2-75: Loss: 0.3328 Acc: 25.0000%\n",
      "\ttrain 2-76: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 2-77: Loss: 0.3521 Acc: 25.0000%\n",
      "\ttrain 2-78: Loss: 0.3419 Acc: 25.0000%\n",
      "\ttrain 2-79: Loss: 0.3374 Acc: 50.0000%\n",
      "\ttrain 2-80: Loss: 0.3295 Acc: 0.0000%\n",
      "\ttrain 2-81: Loss: 0.3498 Acc: 25.0000%\n",
      "\ttrain 2-82: Loss: 0.3466 Acc: 0.0000%\n",
      "\ttrain 2-83: Loss: 0.3318 Acc: 50.0000%\n",
      "\ttrain 2-84: Loss: 0.3522 Acc: 25.0000%\n",
      "\ttrain 2-85: Loss: 0.3497 Acc: 25.0000%\n",
      "\ttrain 2-86: Loss: 0.3531 Acc: 25.0000%\n",
      "\ttrain 2-87: Loss: 0.3490 Acc: 0.0000%\n",
      "\ttrain 2-88: Loss: 0.3664 Acc: 0.0000%\n",
      "\ttrain 2-89: Loss: 0.3492 Acc: 25.0000%\n",
      "\ttrain 2-90: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 2-91: Loss: 0.3392 Acc: 25.0000%\n",
      "\ttrain 2-92: Loss: 0.3431 Acc: 25.0000%\n",
      "\ttrain 2-93: Loss: 0.3349 Acc: 25.0000%\n",
      "\ttrain 2-94: Loss: 0.3482 Acc: 25.0000%\n",
      "\ttrain 2-95: Loss: 0.3336 Acc: 50.0000%\n",
      "\ttrain 2-96: Loss: 0.3441 Acc: 25.0000%\n",
      "\ttrain 2-97: Loss: 0.3409 Acc: 50.0000%\n",
      "\ttrain 2-98: Loss: 0.3381 Acc: 25.0000%\n",
      "\ttrain 2-99: Loss: 0.3501 Acc: 25.0000%\n",
      "\ttrain 2-100: Loss: 0.3361 Acc: 50.0000%\n",
      "\ttrain 2-101: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 2-102: Loss: 0.3294 Acc: 50.0000%\n",
      "\ttrain 2-103: Loss: 0.3391 Acc: 50.0000%\n",
      "\ttrain 2-104: Loss: 0.3524 Acc: 0.0000%\n",
      "\ttrain 2-105: Loss: 0.3535 Acc: 0.0000%\n",
      "\ttrain 2-106: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 2-107: Loss: 0.3427 Acc: 25.0000%\n",
      "\ttrain 2-108: Loss: 0.3275 Acc: 50.0000%\n",
      "\ttrain 2-109: Loss: 0.3281 Acc: 50.0000%\n",
      "\ttrain 2-110: Loss: 0.3231 Acc: 50.0000%\n",
      "\ttrain 2-111: Loss: 0.3547 Acc: 0.0000%\n",
      "\ttrain 2-112: Loss: 0.3417 Acc: 25.0000%\n",
      "\ttrain 2-113: Loss: 0.3246 Acc: 50.0000%\n",
      "\ttrain 2-114: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 2-115: Loss: 0.3421 Acc: 25.0000%\n",
      "\ttrain 2-116: Loss: 0.3196 Acc: 50.0000%\n",
      "\ttrain 2-117: Loss: 0.3408 Acc: 25.0000%\n",
      "\ttrain 2-118: Loss: 0.3674 Acc: 0.0000%\n",
      "\ttrain 2-119: Loss: 0.3135 Acc: 50.0000%\n",
      "\ttrain 2-120: Loss: 0.3493 Acc: 0.0000%\n",
      "\ttrain 2-121: Loss: 0.2909 Acc: 50.0000%\n",
      "\ttrain 2-122: Loss: 0.3856 Acc: 0.0000%\n",
      "\ttrain 2-123: Loss: 0.3607 Acc: 25.0000%\n",
      "\ttrain 2-124: Loss: 0.3389 Acc: 0.0000%\n",
      "\ttrain 2-125: Loss: 0.3667 Acc: 0.0000%\n",
      "\ttrain 2-126: Loss: 0.3040 Acc: 50.0000%\n",
      "\ttrain 2-127: Loss: 0.3180 Acc: 50.0000%\n",
      "\ttrain 2-128: Loss: 0.3362 Acc: 50.0000%\n",
      "\ttrain 2-129: Loss: 0.3763 Acc: 0.0000%\n",
      "\ttrain 2-130: Loss: 0.3605 Acc: 0.0000%\n",
      "\ttrain 2-131: Loss: 0.3066 Acc: 50.0000%\n",
      "\ttrain 2-132: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 2-133: Loss: 0.3473 Acc: 25.0000%\n",
      "\ttrain 2-134: Loss: 0.3398 Acc: 25.0000%\n",
      "\ttrain 2-135: Loss: 0.3577 Acc: 25.0000%\n",
      "\ttrain 2-136: Loss: 0.3351 Acc: 50.0000%\n",
      "\ttrain 2-137: Loss: 0.3486 Acc: 0.0000%\n",
      "\ttrain 2-138: Loss: 0.3475 Acc: 0.0000%\n",
      "\ttrain 2-139: Loss: 0.3323 Acc: 25.0000%\n",
      "\ttrain 2-140: Loss: 0.3274 Acc: 50.0000%\n",
      "\ttrain 2-141: Loss: 0.3279 Acc: 50.0000%\n",
      "\ttrain 2-142: Loss: 0.3325 Acc: 25.0000%\n",
      "\ttrain 2-143: Loss: 0.3251 Acc: 50.0000%\n",
      "\ttrain 2-144: Loss: 0.3341 Acc: 50.0000%\n",
      "\ttrain 2-145: Loss: 0.3168 Acc: 50.0000%\n",
      "\ttrain 2-146: Loss: 0.3383 Acc: 0.0000%\n",
      "\ttrain 2-147: Loss: 0.3081 Acc: 50.0000%\n",
      "\ttrain 2-148: Loss: 0.3172 Acc: 75.0000%\n",
      "\ttrain 2-149: Loss: 0.3449 Acc: 25.0000%\n",
      "\ttrain 2-150: Loss: 0.3577 Acc: 25.0000%\n",
      "\ttrain 2-151: Loss: 0.3342 Acc: 25.0000%\n",
      "\ttrain 2-152: Loss: 0.3385 Acc: 25.0000%\n",
      "\ttrain 2-153: Loss: 0.3620 Acc: 25.0000%\n",
      "\ttrain 2-154: Loss: 0.3400 Acc: 0.0000%\n",
      "\ttrain 2-155: Loss: 0.3210 Acc: 50.0000%\n",
      "\ttrain 2-156: Loss: 0.3241 Acc: 50.0000%\n",
      "\ttrain 2-157: Loss: 0.3208 Acc: 25.0000%\n",
      "\ttrain 2-158: Loss: 0.3031 Acc: 50.0000%\n",
      "\ttrain 2-159: Loss: 0.3233 Acc: 25.0000%\n",
      "\ttrain 2-160: Loss: 0.3226 Acc: 25.0000%\n",
      "\ttrain 2-161: Loss: 0.3545 Acc: 0.0000%\n",
      "\ttrain 2-162: Loss: 0.3536 Acc: 0.0000%\n",
      "\ttrain 2-163: Loss: 0.3222 Acc: 25.0000%\n",
      "\ttrain 2-164: Loss: 0.2981 Acc: 75.0000%\n",
      "\ttrain 2-165: Loss: 0.3101 Acc: 25.0000%\n",
      "\ttrain 2-166: Loss: 0.3438 Acc: 0.0000%\n",
      "\ttrain 2-167: Loss: 0.2636 Acc: 75.0000%\n",
      "\ttrain 2-168: Loss: 0.3516 Acc: 0.0000%\n",
      "\ttrain 2-169: Loss: 0.4035 Acc: 0.0000%\n",
      "\ttrain 2-170: Loss: 0.3311 Acc: 25.0000%\n",
      "\ttrain 2-171: Loss: 0.3172 Acc: 25.0000%\n",
      "\ttrain 2-172: Loss: 0.3778 Acc: 0.0000%\n",
      "\ttrain 2-173: Loss: 0.3394 Acc: 0.0000%\n",
      "\ttrain 2-174: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 2-175: Loss: 0.3233 Acc: 25.0000%\n",
      "\ttrain 2-176: Loss: 0.3253 Acc: 25.0000%\n",
      "\ttrain 2-177: Loss: 0.3383 Acc: 0.0000%\n",
      "\ttrain 2-178: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 2-179: Loss: 0.3254 Acc: 50.0000%\n",
      "\ttrain 2-180: Loss: 0.3235 Acc: 25.0000%\n",
      "\ttrain 2-181: Loss: 0.3329 Acc: 50.0000%\n",
      "\ttrain 2-182: Loss: 0.3346 Acc: 50.0000%\n",
      "\ttrain 2-183: Loss: 0.2850 Acc: 75.0000%\n",
      "\ttrain 2-184: Loss: 0.3273 Acc: 50.0000%\n",
      "\ttrain 2-185: Loss: 0.3048 Acc: 75.0000%\n",
      "\ttrain 2-186: Loss: 0.3090 Acc: 25.0000%\n",
      "\ttrain 2-187: Loss: 0.2810 Acc: 50.0000%\n",
      "\ttrain 2-188: Loss: 0.3102 Acc: 25.0000%\n",
      "\ttrain 2-189: Loss: 0.2731 Acc: 25.0000%\n",
      "\ttrain 2-190: Loss: 0.3844 Acc: 0.0000%\n",
      "\ttrain 2-191: Loss: 0.2719 Acc: 50.0000%\n",
      "\ttrain 2-192: Loss: 0.3442 Acc: 0.0000%\n",
      "\ttrain 2-193: Loss: 0.3294 Acc: 0.0000%\n",
      "\ttrain 2-194: Loss: 0.4021 Acc: 0.0000%\n",
      "\ttrain 2-195: Loss: 0.3444 Acc: 0.0000%\n",
      "\ttrain 2-196: Loss: 0.3443 Acc: 50.0000%\n",
      "\ttrain 2-197: Loss: 0.3448 Acc: 25.0000%\n",
      "\ttrain 2-198: Loss: 0.3173 Acc: 25.0000%\n",
      "\ttrain 2-199: Loss: 0.3547 Acc: 0.0000%\n",
      "\ttrain 2-200: Loss: 0.3284 Acc: 75.0000%\n",
      "\ttrain 2-201: Loss: 0.3282 Acc: 75.0000%\n",
      "\ttrain 2-202: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 2-203: Loss: 0.3418 Acc: 0.0000%\n",
      "\ttrain 2-204: Loss: 0.3385 Acc: 50.0000%\n",
      "\ttrain 2-205: Loss: 0.3141 Acc: 75.0000%\n",
      "\ttrain 2-206: Loss: 0.3311 Acc: 25.0000%\n",
      "\ttrain 2-207: Loss: 0.3166 Acc: 25.0000%\n",
      "\ttrain 2-208: Loss: 0.2771 Acc: 50.0000%\n",
      "\ttrain 2-209: Loss: 0.3068 Acc: 25.0000%\n",
      "\ttrain 2-210: Loss: 0.3009 Acc: 25.0000%\n",
      "\ttrain 2-211: Loss: 0.3389 Acc: 0.0000%\n",
      "\ttrain 2-212: Loss: 0.2908 Acc: 50.0000%\n",
      "\ttrain 2-213: Loss: 0.2487 Acc: 75.0000%\n",
      "\ttrain 2-214: Loss: 0.4881 Acc: 0.0000%\n",
      "\ttrain 2-215: Loss: 0.3301 Acc: 25.0000%\n",
      "\ttrain 2-216: Loss: 0.3421 Acc: 25.0000%\n",
      "\ttrain 2-217: Loss: 0.2826 Acc: 25.0000%\n",
      "\ttrain 2-218: Loss: 0.3269 Acc: 25.0000%\n",
      "\ttrain 2-219: Loss: 0.3271 Acc: 75.0000%\n",
      "\ttrain 2-220: Loss: 0.3156 Acc: 75.0000%\n",
      "\ttrain 2-221: Loss: 0.3294 Acc: 25.0000%\n",
      "\ttrain 2-222: Loss: 0.3385 Acc: 25.0000%\n",
      "\ttrain 2-223: Loss: 0.3540 Acc: 25.0000%\n",
      "\ttrain 2-224: Loss: 0.3352 Acc: 50.0000%\n",
      "\ttrain 2-225: Loss: 0.3076 Acc: 75.0000%\n",
      "\ttrain 2-226: Loss: 0.3055 Acc: 25.0000%\n",
      "\ttrain 2-227: Loss: 0.3255 Acc: 0.0000%\n",
      "\ttrain 2-228: Loss: 0.3031 Acc: 75.0000%\n",
      "\ttrain 2-229: Loss: 0.2739 Acc: 50.0000%\n",
      "\ttrain 2-230: Loss: 0.3333 Acc: 50.0000%\n",
      "\ttrain 2-231: Loss: 0.2827 Acc: 50.0000%\n",
      "\ttrain 2-232: Loss: 0.3143 Acc: 50.0000%\n",
      "\ttrain 2-233: Loss: 0.2771 Acc: 25.0000%\n",
      "\ttrain 2-234: Loss: 0.2916 Acc: 25.0000%\n",
      "\ttrain 2-235: Loss: 0.2726 Acc: 25.0000%\n",
      "\ttrain 2-236: Loss: 0.2980 Acc: 50.0000%\n",
      "\ttrain 2-237: Loss: 0.2704 Acc: 50.0000%\n",
      "\ttrain 2-238: Loss: 0.3402 Acc: 25.0000%\n",
      "\ttrain 2-239: Loss: 0.2736 Acc: 50.0000%\n",
      "\ttrain 2-240: Loss: 0.2827 Acc: 50.0000%\n",
      "\ttrain 2-241: Loss: 0.2870 Acc: 0.0000%\n",
      "\ttrain 2-242: Loss: 0.2870 Acc: 100.0000%\n",
      "\ttrain 2-243: Loss: 0.2810 Acc: 25.0000%\n",
      "\ttrain 2-244: Loss: 0.2423 Acc: 75.0000%\n",
      "\ttrain 2-245: Loss: 0.3298 Acc: 50.0000%\n",
      "\tvalidation 2-1: Loss: 0.3006 Acc: 25.0000%\n",
      "\tvalidation 2-2: Loss: 0.3083 Acc: 50.0000%\n",
      "\tvalidation 2-3: Loss: 0.3168 Acc: 50.0000%\n",
      "\tvalidation 2-4: Loss: 0.2127 Acc: 75.0000%\n",
      "\tvalidation 2-5: Loss: 0.2331 Acc: 50.0000%\n",
      "\tvalidation 2-6: Loss: 0.2419 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-7: Loss: 0.2991 Acc: 25.0000%\n",
      "\tvalidation 2-8: Loss: 0.2655 Acc: 25.0000%\n",
      "\tvalidation 2-9: Loss: 0.2127 Acc: 75.0000%\n",
      "\tvalidation 2-10: Loss: 0.2685 Acc: 25.0000%\n",
      "\tvalidation 2-11: Loss: 0.2886 Acc: 75.0000%\n",
      "\tvalidation 2-12: Loss: 0.2784 Acc: 25.0000%\n",
      "\tvalidation 2-13: Loss: 0.2129 Acc: 100.0000%\n",
      "\tvalidation 2-14: Loss: 0.2971 Acc: 50.0000%\n",
      "\tvalidation 2-15: Loss: 0.2972 Acc: 50.0000%\n",
      "\tvalidation 2-16: Loss: 0.1966 Acc: 75.0000%\n",
      "\tvalidation 2-17: Loss: 0.2311 Acc: 100.0000%\n",
      "\tvalidation 2-18: Loss: 0.2845 Acc: 50.0000%\n",
      "\tvalidation 2-19: Loss: 0.2705 Acc: 75.0000%\n",
      "\tvalidation 2-20: Loss: 0.3178 Acc: 25.0000%\n",
      "\tvalidation 2-21: Loss: 0.2776 Acc: 25.0000%\n",
      "\tvalidation 2-22: Loss: 0.2828 Acc: 75.0000%\n",
      "\tvalidation 2-23: Loss: 0.2689 Acc: 50.0000%\n",
      "\tvalidation 2-24: Loss: 0.2828 Acc: 50.0000%\n",
      "\tvalidation 2-25: Loss: 0.2117 Acc: 75.0000%\n",
      "\tvalidation 2-26: Loss: 0.3181 Acc: 75.0000%\n",
      "\tvalidation 2-27: Loss: 0.3343 Acc: 25.0000%\n",
      "\tvalidation 2-28: Loss: 0.2991 Acc: 50.0000%\n",
      "\tvalidation 2-29: Loss: 0.2422 Acc: 75.0000%\n",
      "\tvalidation 2-30: Loss: 0.2265 Acc: 50.0000%\n",
      "\tvalidation 2-31: Loss: 0.2625 Acc: 75.0000%\n",
      "\tvalidation 2-32: Loss: 0.2503 Acc: 25.0000%\n",
      "\tvalidation 2-33: Loss: 0.2647 Acc: 50.0000%\n",
      "\tvalidation 2-34: Loss: 0.1994 Acc: 50.0000%\n",
      "\tvalidation 2-35: Loss: 0.2511 Acc: 75.0000%\n",
      "\tvalidation 2-36: Loss: 0.2672 Acc: 50.0000%\n",
      "\tvalidation 2-37: Loss: 0.3136 Acc: 75.0000%\n",
      "\tvalidation 2-38: Loss: 0.2198 Acc: 25.0000%\n",
      "\tvalidation 2-39: Loss: 0.2866 Acc: 25.0000%\n",
      "\tvalidation 2-40: Loss: 0.2098 Acc: 50.0000%\n",
      "\tvalidation 2-41: Loss: 0.2449 Acc: 75.0000%\n",
      "\tvalidation 2-42: Loss: 0.2815 Acc: 50.0000%\n",
      "\tvalidation 2-43: Loss: 0.2488 Acc: 25.0000%\n",
      "\tvalidation 2-44: Loss: 0.2672 Acc: 75.0000%\n",
      "\tvalidation 2-45: Loss: 0.3201 Acc: 0.0000%\n",
      "\tvalidation 2-46: Loss: 0.3099 Acc: 25.0000%\n",
      "\tvalidation 2-47: Loss: 0.2316 Acc: 75.0000%\n",
      "\tvalidation 2-48: Loss: 0.3028 Acc: 50.0000%\n",
      "\tvalidation 2-49: Loss: 0.2399 Acc: 50.0000%\n",
      "\tvalidation 2-50: Loss: 0.2974 Acc: 25.0000%\n",
      "\tvalidation 2-51: Loss: 0.2397 Acc: 50.0000%\n",
      "\tvalidation 2-52: Loss: 0.3100 Acc: 100.0000%\n",
      "\tvalidation 2-53: Loss: 0.2437 Acc: 50.0000%\n",
      "\tvalidation 2-54: Loss: 0.2766 Acc: 75.0000%\n",
      "\tvalidation 2-55: Loss: 0.2885 Acc: 0.0000%\n",
      "\tvalidation 2-56: Loss: 0.3039 Acc: 50.0000%\n",
      "\tvalidation 2-57: Loss: 0.2458 Acc: 25.0000%\n",
      "\tvalidation 2-58: Loss: 0.2246 Acc: 75.0000%\n",
      "\tvalidation 2-59: Loss: 0.2838 Acc: 25.0000%\n",
      "\tvalidation 2-60: Loss: 0.2760 Acc: 50.0000%\n",
      "\tvalidation 2-61: Loss: 0.2828 Acc: 50.0000%\n",
      "\tvalidation 2-62: Loss: 0.2764 Acc: 50.0000%\n",
      "\tvalidation 2-63: Loss: 0.2617 Acc: 50.0000%\n",
      "\tvalidation 2-64: Loss: 0.2539 Acc: 75.0000%\n",
      "\tvalidation 2-65: Loss: 0.3307 Acc: 50.0000%\n",
      "\tvalidation 2-66: Loss: 0.2918 Acc: 75.0000%\n",
      "\tvalidation 2-67: Loss: 0.2748 Acc: 75.0000%\n",
      "\tvalidation 2-68: Loss: 0.3064 Acc: 75.0000%\n",
      "\tvalidation 2-69: Loss: 0.2554 Acc: 50.0000%\n",
      "\tvalidation 2-70: Loss: 0.2378 Acc: 50.0000%\n",
      "\tvalidation 2-71: Loss: 0.2380 Acc: 50.0000%\n",
      "\tvalidation 2-72: Loss: 0.2446 Acc: 50.0000%\n",
      "\tvalidation 2-73: Loss: 0.2755 Acc: 50.0000%\n",
      "\tvalidation 2-74: Loss: 0.2753 Acc: 75.0000%\n",
      "\tvalidation 2-75: Loss: 0.2824 Acc: 50.0000%\n",
      "\tvalidation 2-76: Loss: 0.2451 Acc: 25.0000%\n",
      "\tvalidation 2-77: Loss: 0.2644 Acc: 50.0000%\n",
      "\tvalidation 2-78: Loss: 0.2323 Acc: 50.0000%\n",
      "\tvalidation 2-79: Loss: 0.2496 Acc: 50.0000%\n",
      "\tvalidation 2-80: Loss: 0.2838 Acc: 0.0000%\n",
      "\tvalidation 2-81: Loss: 0.2465 Acc: 50.0000%\n",
      "\tvalidation 2-82: Loss: 0.2298 Acc: 100.0000%\n",
      "\tvalidation 2-83: Loss: 0.1913 Acc: 75.0000%\n",
      "\tvalidation 2-84: Loss: 0.2984 Acc: 0.0000%\n",
      "\tvalidation 2-85: Loss: 0.2227 Acc: 75.0000%\n",
      "\tvalidation 2-86: Loss: 0.3107 Acc: 0.0000%\n",
      "\tvalidation 2-87: Loss: 0.2477 Acc: 75.0000%\n",
      "\tvalidation 2-88: Loss: 0.2471 Acc: 50.0000%\n",
      "\tvalidation 2-89: Loss: 0.2258 Acc: 25.0000%\n",
      "\tvalidation 2-90: Loss: 0.2689 Acc: 75.0000%\n",
      "\tvalidation 2-91: Loss: 0.2902 Acc: 75.0000%\n",
      "\tvalidation 2-92: Loss: 0.2810 Acc: 75.0000%\n",
      "\tvalidation 2-93: Loss: 0.2842 Acc: 75.0000%\n",
      "\tvalidation 2-94: Loss: 0.3108 Acc: 25.0000%\n",
      "\tvalidation 2-95: Loss: 0.2414 Acc: 75.0000%\n",
      "\tvalidation 2-96: Loss: 0.2424 Acc: 50.0000%\n",
      "\tvalidation 2-97: Loss: 0.2600 Acc: 50.0000%\n",
      "\tvalidation 2-98: Loss: 0.2783 Acc: 50.0000%\n",
      "\tvalidation 2-99: Loss: 0.2809 Acc: 50.0000%\n",
      "\tvalidation 2-100: Loss: 0.2425 Acc: 50.0000%\n",
      "\tvalidation 2-101: Loss: 0.2654 Acc: 50.0000%\n",
      "\tvalidation 2-102: Loss: 0.2527 Acc: 50.0000%\n",
      "\tvalidation 2-103: Loss: 0.2851 Acc: 75.0000%\n",
      "\tvalidation 2-104: Loss: 0.3017 Acc: 25.0000%\n",
      "\tvalidation 2-105: Loss: 0.2849 Acc: 50.0000%\n",
      "\ttrain Loss: 0.3343 Acc: 29.5918%\n",
      "\tvalidation Loss: 0.2666 Acc: 52.3810%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 35s\n",
      "--------------------\n",
      "Epoch [3/40]:\n",
      "\ttrain 3-1: Loss: 0.2584 Acc: 75.0000%\n",
      "\ttrain 3-2: Loss: 0.2914 Acc: 50.0000%\n",
      "\ttrain 3-3: Loss: 0.2649 Acc: 25.0000%\n",
      "\ttrain 3-4: Loss: 0.2627 Acc: 25.0000%\n",
      "\ttrain 3-5: Loss: 0.2109 Acc: 50.0000%\n",
      "\ttrain 3-6: Loss: 0.3571 Acc: 0.0000%\n",
      "\ttrain 3-7: Loss: 0.3305 Acc: 50.0000%\n",
      "\ttrain 3-8: Loss: 0.1869 Acc: 75.0000%\n",
      "\ttrain 3-9: Loss: 0.2623 Acc: 50.0000%\n",
      "\ttrain 3-10: Loss: 0.3089 Acc: 25.0000%\n",
      "\ttrain 3-11: Loss: 0.2994 Acc: 50.0000%\n",
      "\ttrain 3-12: Loss: 0.2277 Acc: 75.0000%\n",
      "\ttrain 3-13: Loss: 0.2842 Acc: 50.0000%\n",
      "\ttrain 3-14: Loss: 0.3259 Acc: 25.0000%\n",
      "\ttrain 3-15: Loss: 0.3292 Acc: 25.0000%\n",
      "\ttrain 3-16: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 3-17: Loss: 0.3450 Acc: 75.0000%\n",
      "\ttrain 3-18: Loss: 0.4341 Acc: 50.0000%\n",
      "\ttrain 3-19: Loss: 0.2417 Acc: 50.0000%\n",
      "\ttrain 3-20: Loss: 0.3591 Acc: 25.0000%\n",
      "\ttrain 3-21: Loss: 0.3271 Acc: 0.0000%\n",
      "\ttrain 3-22: Loss: 0.3053 Acc: 75.0000%\n",
      "\ttrain 3-23: Loss: 0.3587 Acc: 0.0000%\n",
      "\ttrain 3-24: Loss: 0.2832 Acc: 50.0000%\n",
      "\ttrain 3-25: Loss: 0.2812 Acc: 50.0000%\n",
      "\ttrain 3-26: Loss: 0.2735 Acc: 25.0000%\n",
      "\ttrain 3-27: Loss: 0.2312 Acc: 25.0000%\n",
      "\ttrain 3-28: Loss: 0.2620 Acc: 25.0000%\n",
      "\ttrain 3-29: Loss: 0.2993 Acc: 25.0000%\n",
      "\ttrain 3-30: Loss: 0.4488 Acc: 50.0000%\n",
      "\ttrain 3-31: Loss: 0.2574 Acc: 50.0000%\n",
      "\ttrain 3-32: Loss: 0.3039 Acc: 0.0000%\n",
      "\ttrain 3-33: Loss: 0.2622 Acc: 50.0000%\n",
      "\ttrain 3-34: Loss: 0.2558 Acc: 25.0000%\n",
      "\ttrain 3-35: Loss: 0.3367 Acc: 25.0000%\n",
      "\ttrain 3-36: Loss: 0.3338 Acc: 25.0000%\n",
      "\ttrain 3-37: Loss: 0.3328 Acc: 25.0000%\n",
      "\ttrain 3-38: Loss: 0.3640 Acc: 0.0000%\n",
      "\ttrain 3-39: Loss: 0.2648 Acc: 50.0000%\n",
      "\ttrain 3-40: Loss: 0.3405 Acc: 25.0000%\n",
      "\ttrain 3-41: Loss: 0.2450 Acc: 50.0000%\n",
      "\ttrain 3-42: Loss: 0.2569 Acc: 50.0000%\n",
      "\ttrain 3-43: Loss: 0.2169 Acc: 50.0000%\n",
      "\ttrain 3-44: Loss: 0.3925 Acc: 0.0000%\n",
      "\ttrain 3-45: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 3-46: Loss: 0.2787 Acc: 50.0000%\n",
      "\ttrain 3-47: Loss: 0.2501 Acc: 75.0000%\n",
      "\ttrain 3-48: Loss: 0.2510 Acc: 75.0000%\n",
      "\ttrain 3-49: Loss: 0.1726 Acc: 50.0000%\n",
      "\ttrain 3-50: Loss: 0.2084 Acc: 50.0000%\n",
      "\ttrain 3-51: Loss: 0.3498 Acc: 0.0000%\n",
      "\ttrain 3-52: Loss: 0.2692 Acc: 25.0000%\n",
      "\ttrain 3-53: Loss: 0.3066 Acc: 25.0000%\n",
      "\ttrain 3-54: Loss: 0.1536 Acc: 75.0000%\n",
      "\ttrain 3-55: Loss: 0.2364 Acc: 100.0000%\n",
      "\ttrain 3-56: Loss: 0.2710 Acc: 50.0000%\n",
      "\ttrain 3-57: Loss: 0.2451 Acc: 25.0000%\n",
      "\ttrain 3-58: Loss: 0.2912 Acc: 50.0000%\n",
      "\ttrain 3-59: Loss: 0.2237 Acc: 50.0000%\n",
      "\ttrain 3-60: Loss: 0.2406 Acc: 50.0000%\n",
      "\ttrain 3-61: Loss: 0.2721 Acc: 25.0000%\n",
      "\ttrain 3-62: Loss: 0.1696 Acc: 50.0000%\n",
      "\ttrain 3-63: Loss: 0.2513 Acc: 75.0000%\n",
      "\ttrain 3-64: Loss: 0.3240 Acc: 50.0000%\n",
      "\ttrain 3-65: Loss: 0.6010 Acc: 25.0000%\n",
      "\ttrain 3-66: Loss: 0.3728 Acc: 0.0000%\n",
      "\ttrain 3-67: Loss: 0.2572 Acc: 50.0000%\n",
      "\ttrain 3-68: Loss: 0.2884 Acc: 50.0000%\n",
      "\ttrain 3-69: Loss: 0.3308 Acc: 25.0000%\n",
      "\ttrain 3-70: Loss: 0.3344 Acc: 25.0000%\n",
      "\ttrain 3-71: Loss: 0.3220 Acc: 50.0000%\n",
      "\ttrain 3-72: Loss: 0.3577 Acc: 25.0000%\n",
      "\ttrain 3-73: Loss: 0.4018 Acc: 50.0000%\n",
      "\ttrain 3-74: Loss: 0.4005 Acc: 0.0000%\n",
      "\ttrain 3-75: Loss: 0.2863 Acc: 25.0000%\n",
      "\ttrain 3-76: Loss: 0.4147 Acc: 0.0000%\n",
      "\ttrain 3-77: Loss: 0.4121 Acc: 0.0000%\n",
      "\ttrain 3-78: Loss: 0.4318 Acc: 0.0000%\n",
      "\ttrain 3-79: Loss: 0.4104 Acc: 0.0000%\n",
      "\ttrain 3-80: Loss: 0.3256 Acc: 25.0000%\n",
      "\ttrain 3-81: Loss: 0.3661 Acc: 25.0000%\n",
      "\ttrain 3-82: Loss: 0.3467 Acc: 25.0000%\n",
      "\ttrain 3-83: Loss: 0.3803 Acc: 0.0000%\n",
      "\ttrain 3-84: Loss: 0.3506 Acc: 0.0000%\n",
      "\ttrain 3-85: Loss: 0.3751 Acc: 0.0000%\n",
      "\ttrain 3-86: Loss: 0.3845 Acc: 0.0000%\n",
      "\ttrain 3-87: Loss: 0.3563 Acc: 25.0000%\n",
      "\ttrain 3-88: Loss: 0.3257 Acc: 50.0000%\n",
      "\ttrain 3-89: Loss: 0.3255 Acc: 50.0000%\n",
      "\ttrain 3-90: Loss: 0.3618 Acc: 0.0000%\n",
      "\ttrain 3-91: Loss: 0.3386 Acc: 50.0000%\n",
      "\ttrain 3-92: Loss: 0.3378 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-93: Loss: 0.3518 Acc: 25.0000%\n",
      "\ttrain 3-94: Loss: 0.3290 Acc: 50.0000%\n",
      "\ttrain 3-95: Loss: 0.3291 Acc: 50.0000%\n",
      "\ttrain 3-96: Loss: 0.3176 Acc: 75.0000%\n",
      "\ttrain 3-97: Loss: 0.3290 Acc: 50.0000%\n",
      "\ttrain 3-98: Loss: 0.3644 Acc: 0.0000%\n",
      "\ttrain 3-99: Loss: 0.3164 Acc: 75.0000%\n",
      "\ttrain 3-100: Loss: 0.3892 Acc: 25.0000%\n",
      "\ttrain 3-101: Loss: 0.3655 Acc: 25.0000%\n",
      "\ttrain 3-102: Loss: 0.3619 Acc: 25.0000%\n",
      "\ttrain 3-103: Loss: 0.3252 Acc: 25.0000%\n",
      "\ttrain 3-104: Loss: 0.2948 Acc: 75.0000%\n",
      "\ttrain 3-105: Loss: 0.3270 Acc: 25.0000%\n",
      "\ttrain 3-106: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 3-107: Loss: 0.3638 Acc: 0.0000%\n",
      "\ttrain 3-108: Loss: 0.3385 Acc: 25.0000%\n",
      "\ttrain 3-109: Loss: 0.4017 Acc: 25.0000%\n",
      "\ttrain 3-110: Loss: 0.3725 Acc: 25.0000%\n",
      "\ttrain 3-111: Loss: 0.3812 Acc: 0.0000%\n",
      "\ttrain 3-112: Loss: 0.4002 Acc: 0.0000%\n",
      "\ttrain 3-113: Loss: 0.3311 Acc: 50.0000%\n",
      "\ttrain 3-114: Loss: 0.3637 Acc: 0.0000%\n",
      "\ttrain 3-115: Loss: 0.3462 Acc: 0.0000%\n",
      "\ttrain 3-116: Loss: 0.3477 Acc: 25.0000%\n",
      "\ttrain 3-117: Loss: 0.3621 Acc: 0.0000%\n",
      "\ttrain 3-118: Loss: 0.3472 Acc: 25.0000%\n",
      "\ttrain 3-119: Loss: 0.3446 Acc: 25.0000%\n",
      "\ttrain 3-120: Loss: 0.3474 Acc: 0.0000%\n",
      "\ttrain 3-121: Loss: 0.3366 Acc: 50.0000%\n",
      "\ttrain 3-122: Loss: 0.3545 Acc: 0.0000%\n",
      "\ttrain 3-123: Loss: 0.3346 Acc: 50.0000%\n",
      "\ttrain 3-124: Loss: 0.3338 Acc: 50.0000%\n",
      "\ttrain 3-125: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 3-126: Loss: 0.3437 Acc: 50.0000%\n",
      "\ttrain 3-127: Loss: 0.3541 Acc: 25.0000%\n",
      "\ttrain 3-128: Loss: 0.3469 Acc: 25.0000%\n",
      "\ttrain 3-129: Loss: 0.3309 Acc: 75.0000%\n",
      "\ttrain 3-130: Loss: 0.3437 Acc: 25.0000%\n",
      "\ttrain 3-131: Loss: 0.3410 Acc: 25.0000%\n",
      "\ttrain 3-132: Loss: 0.3557 Acc: 50.0000%\n",
      "\ttrain 3-133: Loss: 0.3295 Acc: 50.0000%\n",
      "\ttrain 3-134: Loss: 0.3531 Acc: 25.0000%\n",
      "\ttrain 3-135: Loss: 0.3238 Acc: 0.0000%\n",
      "\ttrain 3-136: Loss: 0.3585 Acc: 25.0000%\n",
      "\ttrain 3-137: Loss: 0.3420 Acc: 0.0000%\n",
      "\ttrain 3-138: Loss: 0.3455 Acc: 50.0000%\n",
      "\ttrain 3-139: Loss: 0.3496 Acc: 25.0000%\n",
      "\ttrain 3-140: Loss: 0.3331 Acc: 50.0000%\n",
      "\ttrain 3-141: Loss: 0.3544 Acc: 25.0000%\n",
      "\ttrain 3-142: Loss: 0.3529 Acc: 25.0000%\n",
      "\ttrain 3-143: Loss: 0.3243 Acc: 50.0000%\n",
      "\ttrain 3-144: Loss: 0.3391 Acc: 25.0000%\n",
      "\ttrain 3-145: Loss: 0.3443 Acc: 25.0000%\n",
      "\ttrain 3-146: Loss: 0.3308 Acc: 50.0000%\n",
      "\ttrain 3-147: Loss: 0.3386 Acc: 25.0000%\n",
      "\ttrain 3-148: Loss: 0.3381 Acc: 25.0000%\n",
      "\ttrain 3-149: Loss: 0.3475 Acc: 25.0000%\n",
      "\ttrain 3-150: Loss: 0.3456 Acc: 25.0000%\n",
      "\ttrain 3-151: Loss: 0.3474 Acc: 0.0000%\n",
      "\ttrain 3-152: Loss: 0.3220 Acc: 75.0000%\n",
      "\ttrain 3-153: Loss: 0.3391 Acc: 50.0000%\n",
      "\ttrain 3-154: Loss: 0.3308 Acc: 25.0000%\n",
      "\ttrain 3-155: Loss: 0.3397 Acc: 50.0000%\n",
      "\ttrain 3-156: Loss: 0.3318 Acc: 25.0000%\n",
      "\ttrain 3-157: Loss: 0.3370 Acc: 25.0000%\n",
      "\ttrain 3-158: Loss: 0.3458 Acc: 50.0000%\n",
      "\ttrain 3-159: Loss: 0.3641 Acc: 25.0000%\n",
      "\ttrain 3-160: Loss: 0.3344 Acc: 50.0000%\n",
      "\ttrain 3-161: Loss: 0.3458 Acc: 25.0000%\n",
      "\ttrain 3-162: Loss: 0.3579 Acc: 0.0000%\n",
      "\ttrain 3-163: Loss: 0.3401 Acc: 50.0000%\n",
      "\ttrain 3-164: Loss: 0.3279 Acc: 50.0000%\n",
      "\ttrain 3-165: Loss: 0.3591 Acc: 25.0000%\n",
      "\ttrain 3-166: Loss: 0.3465 Acc: 25.0000%\n",
      "\ttrain 3-167: Loss: 0.3272 Acc: 50.0000%\n",
      "\ttrain 3-168: Loss: 0.3357 Acc: 25.0000%\n",
      "\ttrain 3-169: Loss: 0.3554 Acc: 25.0000%\n",
      "\ttrain 3-170: Loss: 0.3616 Acc: 25.0000%\n",
      "\ttrain 3-171: Loss: 0.3347 Acc: 50.0000%\n",
      "\ttrain 3-172: Loss: 0.3660 Acc: 0.0000%\n",
      "\ttrain 3-173: Loss: 0.3371 Acc: 25.0000%\n",
      "\ttrain 3-174: Loss: 0.3265 Acc: 50.0000%\n",
      "\ttrain 3-175: Loss: 0.3657 Acc: 0.0000%\n",
      "\ttrain 3-176: Loss: 0.3506 Acc: 0.0000%\n",
      "\ttrain 3-177: Loss: 0.3233 Acc: 50.0000%\n",
      "\ttrain 3-178: Loss: 0.3433 Acc: 25.0000%\n",
      "\ttrain 3-179: Loss: 0.3425 Acc: 50.0000%\n",
      "\ttrain 3-180: Loss: 0.3255 Acc: 50.0000%\n",
      "\ttrain 3-181: Loss: 0.3256 Acc: 25.0000%\n",
      "\ttrain 3-182: Loss: 0.3758 Acc: 25.0000%\n",
      "\ttrain 3-183: Loss: 0.3601 Acc: 25.0000%\n",
      "\ttrain 3-184: Loss: 0.3290 Acc: 25.0000%\n",
      "\ttrain 3-185: Loss: 0.3490 Acc: 0.0000%\n",
      "\ttrain 3-186: Loss: 0.3383 Acc: 25.0000%\n",
      "\ttrain 3-187: Loss: 0.3623 Acc: 25.0000%\n",
      "\ttrain 3-188: Loss: 0.3352 Acc: 75.0000%\n",
      "\ttrain 3-189: Loss: 0.3392 Acc: 50.0000%\n",
      "\ttrain 3-190: Loss: 0.3352 Acc: 50.0000%\n",
      "\ttrain 3-191: Loss: 0.3359 Acc: 50.0000%\n",
      "\ttrain 3-192: Loss: 0.3415 Acc: 0.0000%\n",
      "\ttrain 3-193: Loss: 0.3435 Acc: 25.0000%\n",
      "\ttrain 3-194: Loss: 0.3400 Acc: 25.0000%\n",
      "\ttrain 3-195: Loss: 0.3547 Acc: 25.0000%\n",
      "\ttrain 3-196: Loss: 0.3830 Acc: 0.0000%\n",
      "\ttrain 3-197: Loss: 0.3217 Acc: 50.0000%\n",
      "\ttrain 3-198: Loss: 0.3407 Acc: 50.0000%\n",
      "\ttrain 3-199: Loss: 0.3477 Acc: 25.0000%\n",
      "\ttrain 3-200: Loss: 0.3554 Acc: 0.0000%\n",
      "\ttrain 3-201: Loss: 0.3288 Acc: 25.0000%\n",
      "\ttrain 3-202: Loss: 0.3752 Acc: 0.0000%\n",
      "\ttrain 3-203: Loss: 0.3744 Acc: 0.0000%\n",
      "\ttrain 3-204: Loss: 0.3536 Acc: 25.0000%\n",
      "\ttrain 3-205: Loss: 0.3309 Acc: 25.0000%\n",
      "\ttrain 3-206: Loss: 0.3522 Acc: 25.0000%\n",
      "\ttrain 3-207: Loss: 0.3533 Acc: 25.0000%\n",
      "\ttrain 3-208: Loss: 0.3406 Acc: 50.0000%\n",
      "\ttrain 3-209: Loss: 0.3353 Acc: 50.0000%\n",
      "\ttrain 3-210: Loss: 0.3281 Acc: 25.0000%\n",
      "\ttrain 3-211: Loss: 0.3636 Acc: 0.0000%\n",
      "\ttrain 3-212: Loss: 0.3427 Acc: 25.0000%\n",
      "\ttrain 3-213: Loss: 0.3459 Acc: 0.0000%\n",
      "\ttrain 3-214: Loss: 0.3611 Acc: 0.0000%\n",
      "\ttrain 3-215: Loss: 0.3431 Acc: 25.0000%\n",
      "\ttrain 3-216: Loss: 0.3508 Acc: 25.0000%\n",
      "\ttrain 3-217: Loss: 0.3443 Acc: 50.0000%\n",
      "\ttrain 3-218: Loss: 0.3356 Acc: 50.0000%\n",
      "\ttrain 3-219: Loss: 0.3506 Acc: 0.0000%\n",
      "\ttrain 3-220: Loss: 0.3547 Acc: 25.0000%\n",
      "\ttrain 3-221: Loss: 0.3561 Acc: 0.0000%\n",
      "\ttrain 3-222: Loss: 0.3429 Acc: 25.0000%\n",
      "\ttrain 3-223: Loss: 0.3607 Acc: 0.0000%\n",
      "\ttrain 3-224: Loss: 0.3500 Acc: 0.0000%\n",
      "\ttrain 3-225: Loss: 0.3502 Acc: 0.0000%\n",
      "\ttrain 3-226: Loss: 0.3452 Acc: 25.0000%\n",
      "\ttrain 3-227: Loss: 0.3401 Acc: 50.0000%\n",
      "\ttrain 3-228: Loss: 0.3382 Acc: 50.0000%\n",
      "\ttrain 3-229: Loss: 0.3397 Acc: 50.0000%\n",
      "\ttrain 3-230: Loss: 0.3461 Acc: 25.0000%\n",
      "\ttrain 3-231: Loss: 0.3203 Acc: 75.0000%\n",
      "\ttrain 3-232: Loss: 0.3543 Acc: 0.0000%\n",
      "\ttrain 3-233: Loss: 0.3496 Acc: 0.0000%\n",
      "\ttrain 3-234: Loss: 0.3412 Acc: 25.0000%\n",
      "\ttrain 3-235: Loss: 0.3404 Acc: 0.0000%\n",
      "\ttrain 3-236: Loss: 0.3217 Acc: 100.0000%\n",
      "\ttrain 3-237: Loss: 0.3441 Acc: 25.0000%\n",
      "\ttrain 3-238: Loss: 0.3653 Acc: 0.0000%\n",
      "\ttrain 3-239: Loss: 0.3547 Acc: 0.0000%\n",
      "\ttrain 3-240: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 3-241: Loss: 0.3439 Acc: 25.0000%\n",
      "\ttrain 3-242: Loss: 0.3638 Acc: 25.0000%\n",
      "\ttrain 3-243: Loss: 0.3536 Acc: 25.0000%\n",
      "\ttrain 3-244: Loss: 0.3350 Acc: 25.0000%\n",
      "\ttrain 3-245: Loss: 0.3443 Acc: 25.0000%\n",
      "\tvalidation 3-1: Loss: 0.3358 Acc: 50.0000%\n",
      "\tvalidation 3-2: Loss: 0.3379 Acc: 50.0000%\n",
      "\tvalidation 3-3: Loss: 0.3491 Acc: 25.0000%\n",
      "\tvalidation 3-4: Loss: 0.3585 Acc: 0.0000%\n",
      "\tvalidation 3-5: Loss: 0.3235 Acc: 100.0000%\n",
      "\tvalidation 3-6: Loss: 0.3575 Acc: 25.0000%\n",
      "\tvalidation 3-7: Loss: 0.3355 Acc: 50.0000%\n",
      "\tvalidation 3-8: Loss: 0.3397 Acc: 50.0000%\n",
      "\tvalidation 3-9: Loss: 0.3469 Acc: 50.0000%\n",
      "\tvalidation 3-10: Loss: 0.3388 Acc: 50.0000%\n",
      "\tvalidation 3-11: Loss: 0.3472 Acc: 25.0000%\n",
      "\tvalidation 3-12: Loss: 0.3615 Acc: 0.0000%\n",
      "\tvalidation 3-13: Loss: 0.3354 Acc: 50.0000%\n",
      "\tvalidation 3-14: Loss: 0.3203 Acc: 100.0000%\n",
      "\tvalidation 3-15: Loss: 0.3372 Acc: 50.0000%\n",
      "\tvalidation 3-16: Loss: 0.3417 Acc: 50.0000%\n",
      "\tvalidation 3-17: Loss: 0.3674 Acc: 0.0000%\n",
      "\tvalidation 3-18: Loss: 0.3305 Acc: 75.0000%\n",
      "\tvalidation 3-19: Loss: 0.3281 Acc: 50.0000%\n",
      "\tvalidation 3-20: Loss: 0.3495 Acc: 0.0000%\n",
      "\tvalidation 3-21: Loss: 0.3342 Acc: 25.0000%\n",
      "\tvalidation 3-22: Loss: 0.3454 Acc: 0.0000%\n",
      "\tvalidation 3-23: Loss: 0.3453 Acc: 50.0000%\n",
      "\tvalidation 3-24: Loss: 0.3293 Acc: 50.0000%\n",
      "\tvalidation 3-25: Loss: 0.3337 Acc: 50.0000%\n",
      "\tvalidation 3-26: Loss: 0.3566 Acc: 25.0000%\n",
      "\tvalidation 3-27: Loss: 0.3530 Acc: 0.0000%\n",
      "\tvalidation 3-28: Loss: 0.3386 Acc: 25.0000%\n",
      "\tvalidation 3-29: Loss: 0.3322 Acc: 75.0000%\n",
      "\tvalidation 3-30: Loss: 0.3561 Acc: 25.0000%\n",
      "\tvalidation 3-31: Loss: 0.3168 Acc: 50.0000%\n",
      "\tvalidation 3-32: Loss: 0.3586 Acc: 25.0000%\n",
      "\tvalidation 3-33: Loss: 0.3507 Acc: 25.0000%\n",
      "\tvalidation 3-34: Loss: 0.3416 Acc: 0.0000%\n",
      "\tvalidation 3-35: Loss: 0.3528 Acc: 25.0000%\n",
      "\tvalidation 3-36: Loss: 0.3576 Acc: 25.0000%\n",
      "\tvalidation 3-37: Loss: 0.3409 Acc: 0.0000%\n",
      "\tvalidation 3-38: Loss: 0.3534 Acc: 25.0000%\n",
      "\tvalidation 3-39: Loss: 0.3437 Acc: 25.0000%\n",
      "\tvalidation 3-40: Loss: 0.3453 Acc: 50.0000%\n",
      "\tvalidation 3-41: Loss: 0.3562 Acc: 25.0000%\n",
      "\tvalidation 3-42: Loss: 0.3444 Acc: 0.0000%\n",
      "\tvalidation 3-43: Loss: 0.3593 Acc: 0.0000%\n",
      "\tvalidation 3-44: Loss: 0.3506 Acc: 25.0000%\n",
      "\tvalidation 3-45: Loss: 0.3244 Acc: 75.0000%\n",
      "\tvalidation 3-46: Loss: 0.3404 Acc: 25.0000%\n",
      "\tvalidation 3-47: Loss: 0.3468 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-48: Loss: 0.3488 Acc: 25.0000%\n",
      "\tvalidation 3-49: Loss: 0.3499 Acc: 25.0000%\n",
      "\tvalidation 3-50: Loss: 0.3443 Acc: 25.0000%\n",
      "\tvalidation 3-51: Loss: 0.3507 Acc: 25.0000%\n",
      "\tvalidation 3-52: Loss: 0.3413 Acc: 25.0000%\n",
      "\tvalidation 3-53: Loss: 0.3394 Acc: 25.0000%\n",
      "\tvalidation 3-54: Loss: 0.3364 Acc: 50.0000%\n",
      "\tvalidation 3-55: Loss: 0.3446 Acc: 50.0000%\n",
      "\tvalidation 3-56: Loss: 0.3347 Acc: 50.0000%\n",
      "\tvalidation 3-57: Loss: 0.3520 Acc: 0.0000%\n",
      "\tvalidation 3-58: Loss: 0.3268 Acc: 50.0000%\n",
      "\tvalidation 3-59: Loss: 0.3549 Acc: 0.0000%\n",
      "\tvalidation 3-60: Loss: 0.3575 Acc: 0.0000%\n",
      "\tvalidation 3-61: Loss: 0.3417 Acc: 50.0000%\n",
      "\tvalidation 3-62: Loss: 0.3436 Acc: 50.0000%\n",
      "\tvalidation 3-63: Loss: 0.3295 Acc: 75.0000%\n",
      "\tvalidation 3-64: Loss: 0.3398 Acc: 25.0000%\n",
      "\tvalidation 3-65: Loss: 0.3485 Acc: 25.0000%\n",
      "\tvalidation 3-66: Loss: 0.3357 Acc: 50.0000%\n",
      "\tvalidation 3-67: Loss: 0.3510 Acc: 0.0000%\n",
      "\tvalidation 3-68: Loss: 0.3393 Acc: 50.0000%\n",
      "\tvalidation 3-69: Loss: 0.3497 Acc: 0.0000%\n",
      "\tvalidation 3-70: Loss: 0.3577 Acc: 0.0000%\n",
      "\tvalidation 3-71: Loss: 0.3543 Acc: 25.0000%\n",
      "\tvalidation 3-72: Loss: 0.3566 Acc: 0.0000%\n",
      "\tvalidation 3-73: Loss: 0.3567 Acc: 0.0000%\n",
      "\tvalidation 3-74: Loss: 0.3462 Acc: 25.0000%\n",
      "\tvalidation 3-75: Loss: 0.3245 Acc: 50.0000%\n",
      "\tvalidation 3-76: Loss: 0.3470 Acc: 25.0000%\n",
      "\tvalidation 3-77: Loss: 0.3433 Acc: 25.0000%\n",
      "\tvalidation 3-78: Loss: 0.3411 Acc: 50.0000%\n",
      "\tvalidation 3-79: Loss: 0.3428 Acc: 25.0000%\n",
      "\tvalidation 3-80: Loss: 0.3482 Acc: 25.0000%\n",
      "\tvalidation 3-81: Loss: 0.3613 Acc: 0.0000%\n",
      "\tvalidation 3-82: Loss: 0.3228 Acc: 50.0000%\n",
      "\tvalidation 3-83: Loss: 0.3270 Acc: 75.0000%\n",
      "\tvalidation 3-84: Loss: 0.3282 Acc: 75.0000%\n",
      "\tvalidation 3-85: Loss: 0.3510 Acc: 25.0000%\n",
      "\tvalidation 3-86: Loss: 0.3396 Acc: 50.0000%\n",
      "\tvalidation 3-87: Loss: 0.3637 Acc: 0.0000%\n",
      "\tvalidation 3-88: Loss: 0.3444 Acc: 50.0000%\n",
      "\tvalidation 3-89: Loss: 0.3348 Acc: 25.0000%\n",
      "\tvalidation 3-90: Loss: 0.3522 Acc: 25.0000%\n",
      "\tvalidation 3-91: Loss: 0.3334 Acc: 50.0000%\n",
      "\tvalidation 3-92: Loss: 0.3408 Acc: 25.0000%\n",
      "\tvalidation 3-93: Loss: 0.3626 Acc: 0.0000%\n",
      "\tvalidation 3-94: Loss: 0.3591 Acc: 0.0000%\n",
      "\tvalidation 3-95: Loss: 0.3236 Acc: 75.0000%\n",
      "\tvalidation 3-96: Loss: 0.3510 Acc: 0.0000%\n",
      "\tvalidation 3-97: Loss: 0.3472 Acc: 25.0000%\n",
      "\tvalidation 3-98: Loss: 0.3631 Acc: 0.0000%\n",
      "\tvalidation 3-99: Loss: 0.3452 Acc: 50.0000%\n",
      "\tvalidation 3-100: Loss: 0.3335 Acc: 25.0000%\n",
      "\tvalidation 3-101: Loss: 0.3499 Acc: 25.0000%\n",
      "\tvalidation 3-102: Loss: 0.3409 Acc: 0.0000%\n",
      "\tvalidation 3-103: Loss: 0.3549 Acc: 25.0000%\n",
      "\tvalidation 3-104: Loss: 0.3445 Acc: 25.0000%\n",
      "\tvalidation 3-105: Loss: 0.3331 Acc: 50.0000%\n",
      "\ttrain Loss: 0.3308 Acc: 31.1224%\n",
      "\tvalidation Loss: 0.3442 Acc: 31.1905%\n",
      "Time passed 0h 2m 20s\n",
      "--------------------\n",
      "Epoch [4/40]:\n",
      "\ttrain 4-1: Loss: 0.3349 Acc: 50.0000%\n",
      "\ttrain 4-2: Loss: 0.3336 Acc: 50.0000%\n",
      "\ttrain 4-3: Loss: 0.3626 Acc: 0.0000%\n",
      "\ttrain 4-4: Loss: 0.3183 Acc: 100.0000%\n",
      "\ttrain 4-5: Loss: 0.3436 Acc: 25.0000%\n",
      "\ttrain 4-6: Loss: 0.3330 Acc: 25.0000%\n",
      "\ttrain 4-7: Loss: 0.3517 Acc: 25.0000%\n",
      "\ttrain 4-8: Loss: 0.3631 Acc: 0.0000%\n",
      "\ttrain 4-9: Loss: 0.3207 Acc: 75.0000%\n",
      "\ttrain 4-10: Loss: 0.3541 Acc: 50.0000%\n",
      "\ttrain 4-11: Loss: 0.3299 Acc: 50.0000%\n",
      "\ttrain 4-12: Loss: 0.3309 Acc: 50.0000%\n",
      "\ttrain 4-13: Loss: 0.3481 Acc: 50.0000%\n",
      "\ttrain 4-14: Loss: 0.3437 Acc: 0.0000%\n",
      "\ttrain 4-15: Loss: 0.3518 Acc: 0.0000%\n",
      "\ttrain 4-16: Loss: 0.3259 Acc: 25.0000%\n",
      "\ttrain 4-17: Loss: 0.3389 Acc: 50.0000%\n",
      "\ttrain 4-18: Loss: 0.3317 Acc: 75.0000%\n",
      "\ttrain 4-19: Loss: 0.3689 Acc: 25.0000%\n",
      "\ttrain 4-20: Loss: 0.3573 Acc: 25.0000%\n",
      "\ttrain 4-21: Loss: 0.3430 Acc: 25.0000%\n",
      "\ttrain 4-22: Loss: 0.3346 Acc: 25.0000%\n",
      "\ttrain 4-23: Loss: 0.3131 Acc: 75.0000%\n",
      "\ttrain 4-24: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 4-25: Loss: 0.3334 Acc: 25.0000%\n",
      "\ttrain 4-26: Loss: 0.3421 Acc: 25.0000%\n",
      "\ttrain 4-27: Loss: 0.3472 Acc: 25.0000%\n",
      "\ttrain 4-28: Loss: 0.3094 Acc: 50.0000%\n",
      "\ttrain 4-29: Loss: 0.3434 Acc: 50.0000%\n",
      "\ttrain 4-30: Loss: 0.3230 Acc: 50.0000%\n",
      "\ttrain 4-31: Loss: 0.3491 Acc: 50.0000%\n",
      "\ttrain 4-32: Loss: 0.3349 Acc: 25.0000%\n",
      "\ttrain 4-33: Loss: 0.3220 Acc: 25.0000%\n",
      "\ttrain 4-34: Loss: 0.2865 Acc: 75.0000%\n",
      "\ttrain 4-35: Loss: 0.3122 Acc: 50.0000%\n",
      "\ttrain 4-36: Loss: 0.3661 Acc: 0.0000%\n",
      "\ttrain 4-37: Loss: 0.4093 Acc: 0.0000%\n",
      "\ttrain 4-38: Loss: 0.3892 Acc: 0.0000%\n",
      "\ttrain 4-39: Loss: 0.3442 Acc: 25.0000%\n",
      "\ttrain 4-40: Loss: 0.3619 Acc: 25.0000%\n",
      "\ttrain 4-41: Loss: 0.3117 Acc: 50.0000%\n",
      "\ttrain 4-42: Loss: 0.3186 Acc: 25.0000%\n",
      "\ttrain 4-43: Loss: 0.3216 Acc: 50.0000%\n",
      "\ttrain 4-44: Loss: 0.3302 Acc: 50.0000%\n",
      "\ttrain 4-45: Loss: 0.3296 Acc: 25.0000%\n",
      "\ttrain 4-46: Loss: 0.3239 Acc: 25.0000%\n",
      "\ttrain 4-47: Loss: 0.3333 Acc: 25.0000%\n",
      "\ttrain 4-48: Loss: 0.3334 Acc: 25.0000%\n",
      "\ttrain 4-49: Loss: 0.3475 Acc: 0.0000%\n",
      "\ttrain 4-50: Loss: 0.3156 Acc: 50.0000%\n",
      "\ttrain 4-51: Loss: 0.3181 Acc: 50.0000%\n",
      "\ttrain 4-52: Loss: 0.3613 Acc: 25.0000%\n",
      "\ttrain 4-53: Loss: 0.3893 Acc: 0.0000%\n",
      "\ttrain 4-54: Loss: 0.3163 Acc: 25.0000%\n",
      "\ttrain 4-55: Loss: 0.3286 Acc: 50.0000%\n",
      "\ttrain 4-56: Loss: 0.3435 Acc: 25.0000%\n",
      "\ttrain 4-57: Loss: 0.3454 Acc: 25.0000%\n",
      "\ttrain 4-58: Loss: 0.2912 Acc: 75.0000%\n",
      "\ttrain 4-59: Loss: 0.3413 Acc: 50.0000%\n",
      "\ttrain 4-60: Loss: 0.3177 Acc: 50.0000%\n",
      "\ttrain 4-61: Loss: 0.3163 Acc: 50.0000%\n",
      "\ttrain 4-62: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 4-63: Loss: 0.3149 Acc: 50.0000%\n",
      "\ttrain 4-64: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 4-65: Loss: 0.3271 Acc: 25.0000%\n",
      "\ttrain 4-66: Loss: 0.3812 Acc: 0.0000%\n",
      "\ttrain 4-67: Loss: 0.3336 Acc: 50.0000%\n",
      "\ttrain 4-68: Loss: 0.3680 Acc: 0.0000%\n",
      "\ttrain 4-69: Loss: 0.3375 Acc: 25.0000%\n",
      "\ttrain 4-70: Loss: 0.3868 Acc: 25.0000%\n",
      "\ttrain 4-71: Loss: 0.3254 Acc: 50.0000%\n",
      "\ttrain 4-72: Loss: 0.3294 Acc: 75.0000%\n",
      "\ttrain 4-73: Loss: 0.3234 Acc: 50.0000%\n",
      "\ttrain 4-74: Loss: 0.3422 Acc: 25.0000%\n",
      "\ttrain 4-75: Loss: 0.3418 Acc: 50.0000%\n",
      "\ttrain 4-76: Loss: 0.3405 Acc: 25.0000%\n",
      "\ttrain 4-77: Loss: 0.3349 Acc: 50.0000%\n",
      "\ttrain 4-78: Loss: 0.3358 Acc: 25.0000%\n",
      "\ttrain 4-79: Loss: 0.3346 Acc: 25.0000%\n",
      "\ttrain 4-80: Loss: 0.3408 Acc: 25.0000%\n",
      "\ttrain 4-81: Loss: 0.3388 Acc: 25.0000%\n",
      "\ttrain 4-82: Loss: 0.3344 Acc: 0.0000%\n",
      "\ttrain 4-83: Loss: 0.3512 Acc: 25.0000%\n",
      "\ttrain 4-84: Loss: 0.3183 Acc: 50.0000%\n",
      "\ttrain 4-85: Loss: 0.3189 Acc: 50.0000%\n",
      "\ttrain 4-86: Loss: 0.3265 Acc: 25.0000%\n",
      "\ttrain 4-87: Loss: 0.3018 Acc: 75.0000%\n",
      "\ttrain 4-88: Loss: 0.3614 Acc: 0.0000%\n",
      "\ttrain 4-89: Loss: 0.3669 Acc: 25.0000%\n",
      "\ttrain 4-90: Loss: 0.3421 Acc: 25.0000%\n",
      "\ttrain 4-91: Loss: 0.3334 Acc: 50.0000%\n",
      "\ttrain 4-92: Loss: 0.3304 Acc: 0.0000%\n",
      "\ttrain 4-93: Loss: 0.3220 Acc: 25.0000%\n",
      "\ttrain 4-94: Loss: 0.3372 Acc: 25.0000%\n",
      "\ttrain 4-95: Loss: 0.3105 Acc: 25.0000%\n",
      "\ttrain 4-96: Loss: 0.3554 Acc: 25.0000%\n",
      "\ttrain 4-97: Loss: 0.3244 Acc: 50.0000%\n",
      "\ttrain 4-98: Loss: 0.3357 Acc: 25.0000%\n",
      "\ttrain 4-99: Loss: 0.3192 Acc: 25.0000%\n",
      "\ttrain 4-100: Loss: 0.3428 Acc: 25.0000%\n",
      "\ttrain 4-101: Loss: 0.3578 Acc: 25.0000%\n",
      "\ttrain 4-102: Loss: 0.3360 Acc: 25.0000%\n",
      "\ttrain 4-103: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 4-104: Loss: 0.3297 Acc: 25.0000%\n",
      "\ttrain 4-105: Loss: 0.3152 Acc: 75.0000%\n",
      "\ttrain 4-106: Loss: 0.3368 Acc: 75.0000%\n",
      "\ttrain 4-107: Loss: 0.3310 Acc: 50.0000%\n",
      "\ttrain 4-108: Loss: 0.3368 Acc: 25.0000%\n",
      "\ttrain 4-109: Loss: 0.3396 Acc: 50.0000%\n",
      "\ttrain 4-110: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 4-111: Loss: 0.3345 Acc: 25.0000%\n",
      "\ttrain 4-112: Loss: 0.3307 Acc: 50.0000%\n",
      "\ttrain 4-113: Loss: 0.3062 Acc: 100.0000%\n",
      "\ttrain 4-114: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 4-115: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 4-116: Loss: 0.2947 Acc: 100.0000%\n",
      "\ttrain 4-117: Loss: 0.3237 Acc: 25.0000%\n",
      "\ttrain 4-118: Loss: 0.3142 Acc: 50.0000%\n",
      "\ttrain 4-119: Loss: 0.3159 Acc: 50.0000%\n",
      "\ttrain 4-120: Loss: 0.3655 Acc: 0.0000%\n",
      "\ttrain 4-121: Loss: 0.2989 Acc: 50.0000%\n",
      "\ttrain 4-122: Loss: 0.3096 Acc: 25.0000%\n",
      "\ttrain 4-123: Loss: 0.3444 Acc: 0.0000%\n",
      "\ttrain 4-124: Loss: 0.3336 Acc: 25.0000%\n",
      "\ttrain 4-125: Loss: 0.3040 Acc: 50.0000%\n",
      "\ttrain 4-126: Loss: 0.3399 Acc: 0.0000%\n",
      "\ttrain 4-127: Loss: 0.2544 Acc: 100.0000%\n",
      "\ttrain 4-128: Loss: 0.2695 Acc: 50.0000%\n",
      "\ttrain 4-129: Loss: 0.3481 Acc: 0.0000%\n",
      "\ttrain 4-130: Loss: 0.3254 Acc: 25.0000%\n",
      "\ttrain 4-131: Loss: 0.3190 Acc: 25.0000%\n",
      "\ttrain 4-132: Loss: 0.2679 Acc: 75.0000%\n",
      "\ttrain 4-133: Loss: 0.2730 Acc: 25.0000%\n",
      "\ttrain 4-134: Loss: 0.3565 Acc: 25.0000%\n",
      "\ttrain 4-135: Loss: 0.1649 Acc: 75.0000%\n",
      "\ttrain 4-136: Loss: 0.4130 Acc: 0.0000%\n",
      "\ttrain 4-137: Loss: 0.3327 Acc: 25.0000%\n",
      "\ttrain 4-138: Loss: 0.3225 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-139: Loss: 0.2300 Acc: 75.0000%\n",
      "\ttrain 4-140: Loss: 0.2650 Acc: 75.0000%\n",
      "\ttrain 4-141: Loss: 0.3181 Acc: 50.0000%\n",
      "\ttrain 4-142: Loss: 0.2454 Acc: 50.0000%\n",
      "\ttrain 4-143: Loss: 0.3107 Acc: 25.0000%\n",
      "\ttrain 4-144: Loss: 0.3490 Acc: 0.0000%\n",
      "\ttrain 4-145: Loss: 0.2471 Acc: 50.0000%\n",
      "\ttrain 4-146: Loss: 0.3208 Acc: 0.0000%\n",
      "\ttrain 4-147: Loss: 0.3236 Acc: 25.0000%\n",
      "\ttrain 4-148: Loss: 0.2101 Acc: 50.0000%\n",
      "\ttrain 4-149: Loss: 0.2351 Acc: 50.0000%\n",
      "\ttrain 4-150: Loss: 0.2715 Acc: 50.0000%\n",
      "\ttrain 4-151: Loss: 0.3606 Acc: 0.0000%\n",
      "\ttrain 4-152: Loss: 0.3313 Acc: 0.0000%\n",
      "\ttrain 4-153: Loss: 0.3293 Acc: 0.0000%\n",
      "\ttrain 4-154: Loss: 0.2418 Acc: 75.0000%\n",
      "\ttrain 4-155: Loss: 0.2554 Acc: 75.0000%\n",
      "\ttrain 4-156: Loss: 0.3222 Acc: 25.0000%\n",
      "\ttrain 4-157: Loss: 0.2957 Acc: 25.0000%\n",
      "\ttrain 4-158: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 4-159: Loss: 0.2637 Acc: 50.0000%\n",
      "\ttrain 4-160: Loss: 0.3235 Acc: 0.0000%\n",
      "\ttrain 4-161: Loss: 0.2906 Acc: 50.0000%\n",
      "\ttrain 4-162: Loss: 0.3302 Acc: 50.0000%\n",
      "\ttrain 4-163: Loss: 0.2061 Acc: 50.0000%\n",
      "\ttrain 4-164: Loss: 0.2704 Acc: 25.0000%\n",
      "\ttrain 4-165: Loss: 0.2442 Acc: 50.0000%\n",
      "\ttrain 4-166: Loss: 0.3099 Acc: 50.0000%\n",
      "\ttrain 4-167: Loss: 0.2638 Acc: 75.0000%\n",
      "\ttrain 4-168: Loss: 0.2890 Acc: 75.0000%\n",
      "\ttrain 4-169: Loss: 0.2983 Acc: 50.0000%\n",
      "\ttrain 4-170: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 4-171: Loss: 0.3163 Acc: 0.0000%\n",
      "\ttrain 4-172: Loss: 0.2762 Acc: 50.0000%\n",
      "\ttrain 4-173: Loss: 0.2936 Acc: 75.0000%\n",
      "\ttrain 4-174: Loss: 0.2739 Acc: 0.0000%\n",
      "\ttrain 4-175: Loss: 0.2596 Acc: 25.0000%\n",
      "\ttrain 4-176: Loss: 0.2616 Acc: 50.0000%\n",
      "\ttrain 4-177: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 4-178: Loss: 0.3101 Acc: 25.0000%\n",
      "\ttrain 4-179: Loss: 0.1173 Acc: 100.0000%\n",
      "\ttrain 4-180: Loss: 0.3113 Acc: 50.0000%\n",
      "\ttrain 4-181: Loss: 0.2681 Acc: 75.0000%\n",
      "\ttrain 4-182: Loss: 0.2940 Acc: 25.0000%\n",
      "\ttrain 4-183: Loss: 0.2822 Acc: 25.0000%\n",
      "\ttrain 4-184: Loss: 0.2805 Acc: 50.0000%\n",
      "\ttrain 4-185: Loss: 0.2487 Acc: 50.0000%\n",
      "\ttrain 4-186: Loss: 0.2097 Acc: 75.0000%\n",
      "\ttrain 4-187: Loss: 0.1311 Acc: 100.0000%\n",
      "\ttrain 4-188: Loss: 0.2592 Acc: 50.0000%\n",
      "\ttrain 4-189: Loss: 0.2584 Acc: 50.0000%\n",
      "\ttrain 4-190: Loss: 0.2224 Acc: 50.0000%\n",
      "\ttrain 4-191: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 4-192: Loss: 0.1735 Acc: 75.0000%\n",
      "\ttrain 4-193: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 4-194: Loss: 0.2203 Acc: 50.0000%\n",
      "\ttrain 4-195: Loss: 0.2258 Acc: 75.0000%\n",
      "\ttrain 4-196: Loss: 0.3885 Acc: 25.0000%\n",
      "\ttrain 4-197: Loss: 0.3379 Acc: 0.0000%\n",
      "\ttrain 4-198: Loss: 0.2759 Acc: 50.0000%\n",
      "\ttrain 4-199: Loss: 0.4035 Acc: 25.0000%\n",
      "\ttrain 4-200: Loss: 0.4814 Acc: 0.0000%\n",
      "\ttrain 4-201: Loss: 0.3634 Acc: 50.0000%\n",
      "\ttrain 4-202: Loss: 0.4222 Acc: 25.0000%\n",
      "\ttrain 4-203: Loss: 0.4277 Acc: 25.0000%\n",
      "\ttrain 4-204: Loss: 0.4872 Acc: 25.0000%\n",
      "\ttrain 4-205: Loss: 0.3878 Acc: 25.0000%\n",
      "\ttrain 4-206: Loss: 0.2932 Acc: 25.0000%\n",
      "\ttrain 4-207: Loss: 0.3757 Acc: 0.0000%\n",
      "\ttrain 4-208: Loss: 0.2990 Acc: 50.0000%\n",
      "\ttrain 4-209: Loss: 0.3270 Acc: 25.0000%\n",
      "\ttrain 4-210: Loss: 0.3189 Acc: 25.0000%\n",
      "\ttrain 4-211: Loss: 0.3012 Acc: 50.0000%\n",
      "\ttrain 4-212: Loss: 0.3865 Acc: 25.0000%\n",
      "\ttrain 4-213: Loss: 0.3651 Acc: 25.0000%\n",
      "\ttrain 4-214: Loss: 0.3471 Acc: 25.0000%\n",
      "\ttrain 4-215: Loss: 0.2722 Acc: 75.0000%\n",
      "\ttrain 4-216: Loss: 0.3908 Acc: 0.0000%\n",
      "\ttrain 4-217: Loss: 0.3768 Acc: 25.0000%\n",
      "\ttrain 4-218: Loss: 0.3096 Acc: 50.0000%\n",
      "\ttrain 4-219: Loss: 0.2941 Acc: 50.0000%\n",
      "\ttrain 4-220: Loss: 0.3929 Acc: 0.0000%\n",
      "\ttrain 4-221: Loss: 0.3300 Acc: 25.0000%\n",
      "\ttrain 4-222: Loss: 0.4165 Acc: 0.0000%\n",
      "\ttrain 4-223: Loss: 0.3710 Acc: 25.0000%\n",
      "\ttrain 4-224: Loss: 0.3555 Acc: 0.0000%\n",
      "\ttrain 4-225: Loss: 0.3780 Acc: 25.0000%\n",
      "\ttrain 4-226: Loss: 0.3530 Acc: 25.0000%\n",
      "\ttrain 4-227: Loss: 0.3675 Acc: 25.0000%\n",
      "\ttrain 4-228: Loss: 0.3692 Acc: 50.0000%\n",
      "\ttrain 4-229: Loss: 0.3175 Acc: 75.0000%\n",
      "\ttrain 4-230: Loss: 0.3463 Acc: 50.0000%\n",
      "\ttrain 4-231: Loss: 0.3364 Acc: 0.0000%\n",
      "\ttrain 4-232: Loss: 0.3489 Acc: 0.0000%\n",
      "\ttrain 4-233: Loss: 0.3310 Acc: 0.0000%\n",
      "\ttrain 4-234: Loss: 0.3592 Acc: 0.0000%\n",
      "\ttrain 4-235: Loss: 0.3910 Acc: 0.0000%\n",
      "\ttrain 4-236: Loss: 0.3588 Acc: 0.0000%\n",
      "\ttrain 4-237: Loss: 0.3598 Acc: 0.0000%\n",
      "\ttrain 4-238: Loss: 0.3593 Acc: 25.0000%\n",
      "\ttrain 4-239: Loss: 0.3186 Acc: 50.0000%\n",
      "\ttrain 4-240: Loss: 0.3665 Acc: 0.0000%\n",
      "\ttrain 4-241: Loss: 0.3492 Acc: 0.0000%\n",
      "\ttrain 4-242: Loss: 0.3626 Acc: 25.0000%\n",
      "\ttrain 4-243: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 4-244: Loss: 0.3324 Acc: 25.0000%\n",
      "\ttrain 4-245: Loss: 0.3198 Acc: 25.0000%\n",
      "\tvalidation 4-1: Loss: 0.3486 Acc: 0.0000%\n",
      "\tvalidation 4-2: Loss: 0.3598 Acc: 25.0000%\n",
      "\tvalidation 4-3: Loss: 0.3519 Acc: 50.0000%\n",
      "\tvalidation 4-4: Loss: 0.3410 Acc: 50.0000%\n",
      "\tvalidation 4-5: Loss: 0.3553 Acc: 0.0000%\n",
      "\tvalidation 4-6: Loss: 0.3329 Acc: 50.0000%\n",
      "\tvalidation 4-7: Loss: 0.3450 Acc: 25.0000%\n",
      "\tvalidation 4-8: Loss: 0.3442 Acc: 50.0000%\n",
      "\tvalidation 4-9: Loss: 0.3185 Acc: 25.0000%\n",
      "\tvalidation 4-10: Loss: 0.3509 Acc: 50.0000%\n",
      "\tvalidation 4-11: Loss: 0.3331 Acc: 25.0000%\n",
      "\tvalidation 4-12: Loss: 0.3499 Acc: 25.0000%\n",
      "\tvalidation 4-13: Loss: 0.3413 Acc: 50.0000%\n",
      "\tvalidation 4-14: Loss: 0.3499 Acc: 50.0000%\n",
      "\tvalidation 4-15: Loss: 0.3291 Acc: 50.0000%\n",
      "\tvalidation 4-16: Loss: 0.3433 Acc: 0.0000%\n",
      "\tvalidation 4-17: Loss: 0.3612 Acc: 0.0000%\n",
      "\tvalidation 4-18: Loss: 0.3293 Acc: 0.0000%\n",
      "\tvalidation 4-19: Loss: 0.3521 Acc: 50.0000%\n",
      "\tvalidation 4-20: Loss: 0.3818 Acc: 0.0000%\n",
      "\tvalidation 4-21: Loss: 0.3341 Acc: 0.0000%\n",
      "\tvalidation 4-22: Loss: 0.3612 Acc: 25.0000%\n",
      "\tvalidation 4-23: Loss: 0.3661 Acc: 0.0000%\n",
      "\tvalidation 4-24: Loss: 0.3416 Acc: 25.0000%\n",
      "\tvalidation 4-25: Loss: 0.3603 Acc: 0.0000%\n",
      "\tvalidation 4-26: Loss: 0.3475 Acc: 0.0000%\n",
      "\tvalidation 4-27: Loss: 0.3305 Acc: 25.0000%\n",
      "\tvalidation 4-28: Loss: 0.3352 Acc: 75.0000%\n",
      "\tvalidation 4-29: Loss: 0.3343 Acc: 25.0000%\n",
      "\tvalidation 4-30: Loss: 0.3348 Acc: 50.0000%\n",
      "\tvalidation 4-31: Loss: 0.3649 Acc: 0.0000%\n",
      "\tvalidation 4-32: Loss: 0.3182 Acc: 75.0000%\n",
      "\tvalidation 4-33: Loss: 0.3430 Acc: 25.0000%\n",
      "\tvalidation 4-34: Loss: 0.3780 Acc: 0.0000%\n",
      "\tvalidation 4-35: Loss: 0.3495 Acc: 0.0000%\n",
      "\tvalidation 4-36: Loss: 0.3499 Acc: 25.0000%\n",
      "\tvalidation 4-37: Loss: 0.3426 Acc: 0.0000%\n",
      "\tvalidation 4-38: Loss: 0.3623 Acc: 25.0000%\n",
      "\tvalidation 4-39: Loss: 0.3314 Acc: 25.0000%\n",
      "\tvalidation 4-40: Loss: 0.3463 Acc: 50.0000%\n",
      "\tvalidation 4-41: Loss: 0.3299 Acc: 25.0000%\n",
      "\tvalidation 4-42: Loss: 0.3612 Acc: 0.0000%\n",
      "\tvalidation 4-43: Loss: 0.3596 Acc: 0.0000%\n",
      "\tvalidation 4-44: Loss: 0.3645 Acc: 25.0000%\n",
      "\tvalidation 4-45: Loss: 0.3575 Acc: 25.0000%\n",
      "\tvalidation 4-46: Loss: 0.3364 Acc: 25.0000%\n",
      "\tvalidation 4-47: Loss: 0.3349 Acc: 50.0000%\n",
      "\tvalidation 4-48: Loss: 0.3804 Acc: 0.0000%\n",
      "\tvalidation 4-49: Loss: 0.3456 Acc: 50.0000%\n",
      "\tvalidation 4-50: Loss: 0.3270 Acc: 25.0000%\n",
      "\tvalidation 4-51: Loss: 0.3661 Acc: 25.0000%\n",
      "\tvalidation 4-52: Loss: 0.3276 Acc: 25.0000%\n",
      "\tvalidation 4-53: Loss: 0.3524 Acc: 25.0000%\n",
      "\tvalidation 4-54: Loss: 0.3465 Acc: 25.0000%\n",
      "\tvalidation 4-55: Loss: 0.3303 Acc: 50.0000%\n",
      "\tvalidation 4-56: Loss: 0.3452 Acc: 50.0000%\n",
      "\tvalidation 4-57: Loss: 0.3177 Acc: 50.0000%\n",
      "\tvalidation 4-58: Loss: 0.3419 Acc: 50.0000%\n",
      "\tvalidation 4-59: Loss: 0.3650 Acc: 0.0000%\n",
      "\tvalidation 4-60: Loss: 0.3398 Acc: 50.0000%\n",
      "\tvalidation 4-61: Loss: 0.3455 Acc: 0.0000%\n",
      "\tvalidation 4-62: Loss: 0.3646 Acc: 0.0000%\n",
      "\tvalidation 4-63: Loss: 0.3339 Acc: 50.0000%\n",
      "\tvalidation 4-64: Loss: 0.3346 Acc: 50.0000%\n",
      "\tvalidation 4-65: Loss: 0.3296 Acc: 50.0000%\n",
      "\tvalidation 4-66: Loss: 0.3422 Acc: 50.0000%\n",
      "\tvalidation 4-67: Loss: 0.3292 Acc: 50.0000%\n",
      "\tvalidation 4-68: Loss: 0.3663 Acc: 0.0000%\n",
      "\tvalidation 4-69: Loss: 0.3299 Acc: 50.0000%\n",
      "\tvalidation 4-70: Loss: 0.3573 Acc: 0.0000%\n",
      "\tvalidation 4-71: Loss: 0.3281 Acc: 25.0000%\n",
      "\tvalidation 4-72: Loss: 0.3337 Acc: 50.0000%\n",
      "\tvalidation 4-73: Loss: 0.3464 Acc: 50.0000%\n",
      "\tvalidation 4-74: Loss: 0.3428 Acc: 25.0000%\n",
      "\tvalidation 4-75: Loss: 0.3464 Acc: 25.0000%\n",
      "\tvalidation 4-76: Loss: 0.3284 Acc: 25.0000%\n",
      "\tvalidation 4-77: Loss: 0.3533 Acc: 0.0000%\n",
      "\tvalidation 4-78: Loss: 0.3589 Acc: 0.0000%\n",
      "\tvalidation 4-79: Loss: 0.3564 Acc: 0.0000%\n",
      "\tvalidation 4-80: Loss: 0.3547 Acc: 25.0000%\n",
      "\tvalidation 4-81: Loss: 0.3487 Acc: 50.0000%\n",
      "\tvalidation 4-82: Loss: 0.3623 Acc: 0.0000%\n",
      "\tvalidation 4-83: Loss: 0.3436 Acc: 25.0000%\n",
      "\tvalidation 4-84: Loss: 0.3183 Acc: 75.0000%\n",
      "\tvalidation 4-85: Loss: 0.3532 Acc: 0.0000%\n",
      "\tvalidation 4-86: Loss: 0.3291 Acc: 0.0000%\n",
      "\tvalidation 4-87: Loss: 0.3424 Acc: 25.0000%\n",
      "\tvalidation 4-88: Loss: 0.3793 Acc: 0.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 4-89: Loss: 0.3514 Acc: 25.0000%\n",
      "\tvalidation 4-90: Loss: 0.3606 Acc: 0.0000%\n",
      "\tvalidation 4-91: Loss: 0.3328 Acc: 75.0000%\n",
      "\tvalidation 4-92: Loss: 0.3447 Acc: 25.0000%\n",
      "\tvalidation 4-93: Loss: 0.3594 Acc: 25.0000%\n",
      "\tvalidation 4-94: Loss: 0.3629 Acc: 25.0000%\n",
      "\tvalidation 4-95: Loss: 0.3453 Acc: 0.0000%\n",
      "\tvalidation 4-96: Loss: 0.3634 Acc: 0.0000%\n",
      "\tvalidation 4-97: Loss: 0.3502 Acc: 25.0000%\n",
      "\tvalidation 4-98: Loss: 0.3278 Acc: 25.0000%\n",
      "\tvalidation 4-99: Loss: 0.3599 Acc: 25.0000%\n",
      "\tvalidation 4-100: Loss: 0.3301 Acc: 0.0000%\n",
      "\tvalidation 4-101: Loss: 0.3653 Acc: 0.0000%\n",
      "\tvalidation 4-102: Loss: 0.3470 Acc: 50.0000%\n",
      "\tvalidation 4-103: Loss: 0.3462 Acc: 0.0000%\n",
      "\tvalidation 4-104: Loss: 0.3328 Acc: 0.0000%\n",
      "\tvalidation 4-105: Loss: 0.3705 Acc: 25.0000%\n",
      "\ttrain Loss: 0.3214 Acc: 35.7143%\n",
      "\tvalidation Loss: 0.3466 Acc: 25.0000%\n",
      "Time passed 0h 3m 6s\n",
      "--------------------\n",
      "Epoch [5/40]:\n",
      "\ttrain 5-1: Loss: 0.3711 Acc: 0.0000%\n",
      "\ttrain 5-2: Loss: 0.3524 Acc: 25.0000%\n",
      "\ttrain 5-3: Loss: 0.3598 Acc: 25.0000%\n",
      "\ttrain 5-4: Loss: 0.3583 Acc: 25.0000%\n",
      "\ttrain 5-5: Loss: 0.3488 Acc: 0.0000%\n",
      "\ttrain 5-6: Loss: 0.3464 Acc: 0.0000%\n",
      "\ttrain 5-7: Loss: 0.3375 Acc: 25.0000%\n",
      "\ttrain 5-8: Loss: 0.3486 Acc: 25.0000%\n",
      "\ttrain 5-9: Loss: 0.3395 Acc: 50.0000%\n",
      "\ttrain 5-10: Loss: 0.3515 Acc: 25.0000%\n",
      "\ttrain 5-11: Loss: 0.3464 Acc: 25.0000%\n",
      "\ttrain 5-12: Loss: 0.3403 Acc: 50.0000%\n",
      "\ttrain 5-13: Loss: 0.3465 Acc: 25.0000%\n",
      "\ttrain 5-14: Loss: 0.3462 Acc: 50.0000%\n",
      "\ttrain 5-15: Loss: 0.3484 Acc: 25.0000%\n",
      "\ttrain 5-16: Loss: 0.3421 Acc: 50.0000%\n",
      "\ttrain 5-17: Loss: 0.3423 Acc: 0.0000%\n",
      "\ttrain 5-18: Loss: 0.3371 Acc: 75.0000%\n",
      "\ttrain 5-19: Loss: 0.3311 Acc: 50.0000%\n",
      "\ttrain 5-20: Loss: 0.3389 Acc: 50.0000%\n",
      "\ttrain 5-21: Loss: 0.3455 Acc: 0.0000%\n",
      "\ttrain 5-22: Loss: 0.3270 Acc: 50.0000%\n",
      "\ttrain 5-23: Loss: 0.3269 Acc: 50.0000%\n",
      "\ttrain 5-24: Loss: 0.3725 Acc: 25.0000%\n",
      "\ttrain 5-25: Loss: 0.3693 Acc: 25.0000%\n",
      "\ttrain 5-26: Loss: 0.3484 Acc: 25.0000%\n",
      "\ttrain 5-27: Loss: 0.3692 Acc: 25.0000%\n",
      "\ttrain 5-28: Loss: 0.3414 Acc: 50.0000%\n",
      "\ttrain 5-29: Loss: 0.3295 Acc: 50.0000%\n",
      "\ttrain 5-30: Loss: 0.3363 Acc: 25.0000%\n",
      "\ttrain 5-31: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 5-32: Loss: 0.3501 Acc: 0.0000%\n",
      "\ttrain 5-33: Loss: 0.3385 Acc: 50.0000%\n",
      "\ttrain 5-34: Loss: 0.3471 Acc: 25.0000%\n",
      "\ttrain 5-35: Loss: 0.3387 Acc: 50.0000%\n",
      "\ttrain 5-36: Loss: 0.3183 Acc: 50.0000%\n",
      "\ttrain 5-37: Loss: 0.3415 Acc: 50.0000%\n",
      "\ttrain 5-38: Loss: 0.3393 Acc: 25.0000%\n",
      "\ttrain 5-39: Loss: 0.3581 Acc: 0.0000%\n",
      "\ttrain 5-40: Loss: 0.3290 Acc: 50.0000%\n",
      "\ttrain 5-41: Loss: 0.3573 Acc: 0.0000%\n",
      "\ttrain 5-42: Loss: 0.3655 Acc: 0.0000%\n",
      "\ttrain 5-43: Loss: 0.3477 Acc: 25.0000%\n",
      "\ttrain 5-44: Loss: 0.3415 Acc: 25.0000%\n",
      "\ttrain 5-45: Loss: 0.3239 Acc: 50.0000%\n",
      "\ttrain 5-46: Loss: 0.3400 Acc: 0.0000%\n",
      "\ttrain 5-47: Loss: 0.3307 Acc: 50.0000%\n",
      "\ttrain 5-48: Loss: 0.3520 Acc: 25.0000%\n",
      "\ttrain 5-49: Loss: 0.3410 Acc: 25.0000%\n",
      "\ttrain 5-50: Loss: 0.3362 Acc: 50.0000%\n",
      "\ttrain 5-51: Loss: 0.3417 Acc: 25.0000%\n",
      "\ttrain 5-52: Loss: 0.3437 Acc: 0.0000%\n",
      "\ttrain 5-53: Loss: 0.3293 Acc: 50.0000%\n",
      "\ttrain 5-54: Loss: 0.3406 Acc: 25.0000%\n",
      "\ttrain 5-55: Loss: 0.3328 Acc: 25.0000%\n",
      "\ttrain 5-56: Loss: 0.3447 Acc: 50.0000%\n",
      "\ttrain 5-57: Loss: 0.3525 Acc: 25.0000%\n",
      "\ttrain 5-58: Loss: 0.3102 Acc: 100.0000%\n",
      "\ttrain 5-59: Loss: 0.3437 Acc: 25.0000%\n",
      "\ttrain 5-60: Loss: 0.3221 Acc: 50.0000%\n",
      "\ttrain 5-61: Loss: 0.3345 Acc: 50.0000%\n",
      "\ttrain 5-62: Loss: 0.3142 Acc: 50.0000%\n",
      "\ttrain 5-63: Loss: 0.3669 Acc: 0.0000%\n",
      "\ttrain 5-64: Loss: 0.3362 Acc: 25.0000%\n",
      "\ttrain 5-65: Loss: 0.3272 Acc: 50.0000%\n",
      "\ttrain 5-66: Loss: 0.3593 Acc: 25.0000%\n",
      "\ttrain 5-67: Loss: 0.3375 Acc: 25.0000%\n",
      "\ttrain 5-68: Loss: 0.3378 Acc: 50.0000%\n",
      "\ttrain 5-69: Loss: 0.3438 Acc: 50.0000%\n",
      "\ttrain 5-70: Loss: 0.3367 Acc: 50.0000%\n",
      "\ttrain 5-71: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 5-72: Loss: 0.3030 Acc: 75.0000%\n",
      "\ttrain 5-73: Loss: 0.3083 Acc: 50.0000%\n",
      "\ttrain 5-74: Loss: 0.3489 Acc: 25.0000%\n",
      "\ttrain 5-75: Loss: 0.3271 Acc: 50.0000%\n",
      "\ttrain 5-76: Loss: 0.3082 Acc: 50.0000%\n",
      "\ttrain 5-77: Loss: 0.4137 Acc: 0.0000%\n",
      "\ttrain 5-78: Loss: 0.3461 Acc: 25.0000%\n",
      "\ttrain 5-79: Loss: 0.3519 Acc: 0.0000%\n",
      "\ttrain 5-80: Loss: 0.3626 Acc: 25.0000%\n",
      "\ttrain 5-81: Loss: 0.3184 Acc: 25.0000%\n",
      "\ttrain 5-82: Loss: 0.3377 Acc: 50.0000%\n",
      "\ttrain 5-83: Loss: 0.3479 Acc: 25.0000%\n",
      "\ttrain 5-84: Loss: 0.3408 Acc: 25.0000%\n",
      "\ttrain 5-85: Loss: 0.3259 Acc: 75.0000%\n",
      "\ttrain 5-86: Loss: 0.3405 Acc: 25.0000%\n",
      "\ttrain 5-87: Loss: 0.3501 Acc: 25.0000%\n",
      "\ttrain 5-88: Loss: 0.3430 Acc: 25.0000%\n",
      "\ttrain 5-89: Loss: 0.3541 Acc: 25.0000%\n",
      "\ttrain 5-90: Loss: 0.3286 Acc: 25.0000%\n",
      "\ttrain 5-91: Loss: 0.3313 Acc: 25.0000%\n",
      "\ttrain 5-92: Loss: 0.3204 Acc: 75.0000%\n",
      "\ttrain 5-93: Loss: 0.3340 Acc: 0.0000%\n",
      "\ttrain 5-94: Loss: 0.3093 Acc: 50.0000%\n",
      "\ttrain 5-95: Loss: 0.3328 Acc: 50.0000%\n",
      "\ttrain 5-96: Loss: 0.2928 Acc: 50.0000%\n",
      "\ttrain 5-97: Loss: 0.3177 Acc: 25.0000%\n",
      "\ttrain 5-98: Loss: 0.2742 Acc: 50.0000%\n",
      "\ttrain 5-99: Loss: 0.2683 Acc: 50.0000%\n",
      "\ttrain 5-100: Loss: 0.3644 Acc: 25.0000%\n",
      "\ttrain 5-101: Loss: 0.4054 Acc: 0.0000%\n",
      "\ttrain 5-102: Loss: 0.2792 Acc: 25.0000%\n",
      "\ttrain 5-103: Loss: 0.2634 Acc: 50.0000%\n",
      "\ttrain 5-104: Loss: 0.3042 Acc: 50.0000%\n",
      "\ttrain 5-105: Loss: 0.2939 Acc: 75.0000%\n",
      "\ttrain 5-106: Loss: 0.3265 Acc: 0.0000%\n",
      "\ttrain 5-107: Loss: 0.2747 Acc: 25.0000%\n",
      "\ttrain 5-108: Loss: 0.3240 Acc: 25.0000%\n",
      "\ttrain 5-109: Loss: 0.2968 Acc: 50.0000%\n",
      "\ttrain 5-110: Loss: 0.2512 Acc: 75.0000%\n",
      "\ttrain 5-111: Loss: 0.3022 Acc: 75.0000%\n",
      "\ttrain 5-112: Loss: 0.2934 Acc: 0.0000%\n",
      "\ttrain 5-113: Loss: 0.2167 Acc: 75.0000%\n",
      "\ttrain 5-114: Loss: 0.2808 Acc: 25.0000%\n",
      "\ttrain 5-115: Loss: 0.2609 Acc: 50.0000%\n",
      "\ttrain 5-116: Loss: 0.2524 Acc: 75.0000%\n",
      "\ttrain 5-117: Loss: 0.2691 Acc: 50.0000%\n",
      "\ttrain 5-118: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 5-119: Loss: 0.3005 Acc: 25.0000%\n",
      "\ttrain 5-120: Loss: 0.2529 Acc: 75.0000%\n",
      "\ttrain 5-121: Loss: 0.3436 Acc: 25.0000%\n",
      "\ttrain 5-122: Loss: 0.2211 Acc: 75.0000%\n",
      "\ttrain 5-123: Loss: 0.2666 Acc: 50.0000%\n",
      "\ttrain 5-124: Loss: 0.2735 Acc: 25.0000%\n",
      "\ttrain 5-125: Loss: 0.3111 Acc: 25.0000%\n",
      "\ttrain 5-126: Loss: 0.2841 Acc: 75.0000%\n",
      "\ttrain 5-127: Loss: 0.3180 Acc: 25.0000%\n",
      "\ttrain 5-128: Loss: 0.2071 Acc: 75.0000%\n",
      "\ttrain 5-129: Loss: 0.2753 Acc: 25.0000%\n",
      "\ttrain 5-130: Loss: 0.2055 Acc: 50.0000%\n",
      "\ttrain 5-131: Loss: 0.3143 Acc: 0.0000%\n",
      "\ttrain 5-132: Loss: 0.2200 Acc: 75.0000%\n",
      "\ttrain 5-133: Loss: 0.1613 Acc: 50.0000%\n",
      "\ttrain 5-134: Loss: 0.2394 Acc: 50.0000%\n",
      "\ttrain 5-135: Loss: 0.2193 Acc: 75.0000%\n",
      "\ttrain 5-136: Loss: 0.2170 Acc: 75.0000%\n",
      "\ttrain 5-137: Loss: 0.2532 Acc: 25.0000%\n",
      "\ttrain 5-138: Loss: 0.2637 Acc: 50.0000%\n",
      "\ttrain 5-139: Loss: 0.3050 Acc: 0.0000%\n",
      "\ttrain 5-140: Loss: 0.3038 Acc: 25.0000%\n",
      "\ttrain 5-141: Loss: 0.3197 Acc: 50.0000%\n",
      "\ttrain 5-142: Loss: 0.3212 Acc: 25.0000%\n",
      "\ttrain 5-143: Loss: 0.3627 Acc: 0.0000%\n",
      "\ttrain 5-144: Loss: 0.3212 Acc: 50.0000%\n",
      "\ttrain 5-145: Loss: 0.3260 Acc: 50.0000%\n",
      "\ttrain 5-146: Loss: 0.3634 Acc: 25.0000%\n",
      "\ttrain 5-147: Loss: 0.3732 Acc: 0.0000%\n",
      "\ttrain 5-148: Loss: 0.3673 Acc: 50.0000%\n",
      "\ttrain 5-149: Loss: 0.3990 Acc: 25.0000%\n",
      "\ttrain 5-150: Loss: 0.3646 Acc: 0.0000%\n",
      "\ttrain 5-151: Loss: 0.3902 Acc: 0.0000%\n",
      "\ttrain 5-152: Loss: 0.3568 Acc: 25.0000%\n",
      "\ttrain 5-153: Loss: 0.3218 Acc: 50.0000%\n",
      "\ttrain 5-154: Loss: 0.3096 Acc: 75.0000%\n",
      "\ttrain 5-155: Loss: 0.3238 Acc: 25.0000%\n",
      "\ttrain 5-156: Loss: 0.3454 Acc: 50.0000%\n",
      "\ttrain 5-157: Loss: 0.3203 Acc: 25.0000%\n",
      "\ttrain 5-158: Loss: 0.3988 Acc: 0.0000%\n",
      "\ttrain 5-159: Loss: 0.3076 Acc: 50.0000%\n",
      "\ttrain 5-160: Loss: 0.3528 Acc: 0.0000%\n",
      "\ttrain 5-161: Loss: 0.3773 Acc: 0.0000%\n",
      "\ttrain 5-162: Loss: 0.3106 Acc: 25.0000%\n",
      "\ttrain 5-163: Loss: 0.3746 Acc: 0.0000%\n",
      "\ttrain 5-164: Loss: 0.3666 Acc: 25.0000%\n",
      "\ttrain 5-165: Loss: 0.3673 Acc: 25.0000%\n",
      "\ttrain 5-166: Loss: 0.3489 Acc: 25.0000%\n",
      "\ttrain 5-167: Loss: 0.3455 Acc: 25.0000%\n",
      "\ttrain 5-168: Loss: 0.3325 Acc: 25.0000%\n",
      "\ttrain 5-169: Loss: 0.3402 Acc: 50.0000%\n",
      "\ttrain 5-170: Loss: 0.3609 Acc: 0.0000%\n",
      "\ttrain 5-171: Loss: 0.3184 Acc: 50.0000%\n",
      "\ttrain 5-172: Loss: 0.3407 Acc: 25.0000%\n",
      "\ttrain 5-173: Loss: 0.3372 Acc: 50.0000%\n",
      "\ttrain 5-174: Loss: 0.3235 Acc: 50.0000%\n",
      "\ttrain 5-175: Loss: 0.3528 Acc: 25.0000%\n",
      "\ttrain 5-176: Loss: 0.3711 Acc: 0.0000%\n",
      "\ttrain 5-177: Loss: 0.3194 Acc: 25.0000%\n",
      "\ttrain 5-178: Loss: 0.3394 Acc: 50.0000%\n",
      "\ttrain 5-179: Loss: 0.3418 Acc: 50.0000%\n",
      "\ttrain 5-180: Loss: 0.3479 Acc: 0.0000%\n",
      "\ttrain 5-181: Loss: 0.3290 Acc: 75.0000%\n",
      "\ttrain 5-182: Loss: 0.3481 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 5-183: Loss: 0.3348 Acc: 25.0000%\n",
      "\ttrain 5-184: Loss: 0.3589 Acc: 0.0000%\n",
      "\ttrain 5-185: Loss: 0.3271 Acc: 25.0000%\n",
      "\ttrain 5-186: Loss: 0.3521 Acc: 25.0000%\n",
      "\ttrain 5-187: Loss: 0.3341 Acc: 50.0000%\n",
      "\ttrain 5-188: Loss: 0.3245 Acc: 75.0000%\n",
      "\ttrain 5-189: Loss: 0.3306 Acc: 50.0000%\n",
      "\ttrain 5-190: Loss: 0.3826 Acc: 25.0000%\n",
      "\ttrain 5-191: Loss: 0.3997 Acc: 0.0000%\n",
      "\ttrain 5-192: Loss: 0.3760 Acc: 0.0000%\n",
      "\ttrain 5-193: Loss: 0.3242 Acc: 50.0000%\n",
      "\ttrain 5-194: Loss: 0.3371 Acc: 0.0000%\n",
      "\ttrain 5-195: Loss: 0.3207 Acc: 50.0000%\n",
      "\ttrain 5-196: Loss: 0.3380 Acc: 25.0000%\n",
      "\ttrain 5-197: Loss: 0.3205 Acc: 75.0000%\n",
      "\ttrain 5-198: Loss: 0.3510 Acc: 50.0000%\n",
      "\ttrain 5-199: Loss: 0.3338 Acc: 50.0000%\n",
      "\ttrain 5-200: Loss: 0.3286 Acc: 25.0000%\n",
      "\ttrain 5-201: Loss: 0.3446 Acc: 25.0000%\n",
      "\ttrain 5-202: Loss: 0.3267 Acc: 0.0000%\n",
      "\ttrain 5-203: Loss: 0.3613 Acc: 25.0000%\n",
      "\ttrain 5-204: Loss: 0.3389 Acc: 25.0000%\n",
      "\ttrain 5-205: Loss: 0.3162 Acc: 25.0000%\n",
      "\ttrain 5-206: Loss: 0.3281 Acc: 50.0000%\n",
      "\ttrain 5-207: Loss: 0.3481 Acc: 25.0000%\n",
      "\ttrain 5-208: Loss: 0.3360 Acc: 75.0000%\n",
      "\ttrain 5-209: Loss: 0.3349 Acc: 25.0000%\n",
      "\ttrain 5-210: Loss: 0.3325 Acc: 25.0000%\n",
      "\ttrain 5-211: Loss: 0.3172 Acc: 50.0000%\n",
      "\ttrain 5-212: Loss: 0.3211 Acc: 25.0000%\n",
      "\ttrain 5-213: Loss: 0.3171 Acc: 75.0000%\n",
      "\ttrain 5-214: Loss: 0.2963 Acc: 25.0000%\n",
      "\ttrain 5-215: Loss: 0.3546 Acc: 25.0000%\n",
      "\ttrain 5-216: Loss: 0.3928 Acc: 0.0000%\n",
      "\ttrain 5-217: Loss: 0.2863 Acc: 75.0000%\n",
      "\ttrain 5-218: Loss: 0.3106 Acc: 50.0000%\n",
      "\ttrain 5-219: Loss: 0.4045 Acc: 0.0000%\n",
      "\ttrain 5-220: Loss: 0.3144 Acc: 25.0000%\n",
      "\ttrain 5-221: Loss: 0.4162 Acc: 0.0000%\n",
      "\ttrain 5-222: Loss: 0.3204 Acc: 50.0000%\n",
      "\ttrain 5-223: Loss: 0.3262 Acc: 50.0000%\n",
      "\ttrain 5-224: Loss: 0.3221 Acc: 25.0000%\n",
      "\ttrain 5-225: Loss: 0.3363 Acc: 25.0000%\n",
      "\ttrain 5-226: Loss: 0.3401 Acc: 0.0000%\n",
      "\ttrain 5-227: Loss: 0.3498 Acc: 25.0000%\n",
      "\ttrain 5-228: Loss: 0.3070 Acc: 50.0000%\n",
      "\ttrain 5-229: Loss: 0.3366 Acc: 50.0000%\n",
      "\ttrain 5-230: Loss: 0.3209 Acc: 50.0000%\n",
      "\ttrain 5-231: Loss: 0.3485 Acc: 0.0000%\n",
      "\ttrain 5-232: Loss: 0.3193 Acc: 25.0000%\n",
      "\ttrain 5-233: Loss: 0.3375 Acc: 25.0000%\n",
      "\ttrain 5-234: Loss: 0.3520 Acc: 25.0000%\n",
      "\ttrain 5-235: Loss: 0.3307 Acc: 50.0000%\n",
      "\ttrain 5-236: Loss: 0.3373 Acc: 25.0000%\n",
      "\ttrain 5-237: Loss: 0.3168 Acc: 75.0000%\n",
      "\ttrain 5-238: Loss: 0.3267 Acc: 50.0000%\n",
      "\ttrain 5-239: Loss: 0.3206 Acc: 50.0000%\n",
      "\ttrain 5-240: Loss: 0.3233 Acc: 75.0000%\n",
      "\ttrain 5-241: Loss: 0.3075 Acc: 25.0000%\n",
      "\ttrain 5-242: Loss: 0.2938 Acc: 100.0000%\n",
      "\ttrain 5-243: Loss: 0.3499 Acc: 25.0000%\n",
      "\ttrain 5-244: Loss: 0.3074 Acc: 50.0000%\n",
      "\ttrain 5-245: Loss: 0.3336 Acc: 50.0000%\n",
      "\tvalidation 5-1: Loss: 0.2764 Acc: 75.0000%\n",
      "\tvalidation 5-2: Loss: 0.3145 Acc: 50.0000%\n",
      "\tvalidation 5-3: Loss: 0.2966 Acc: 75.0000%\n",
      "\tvalidation 5-4: Loss: 0.3001 Acc: 75.0000%\n",
      "\tvalidation 5-5: Loss: 0.3126 Acc: 50.0000%\n",
      "\tvalidation 5-6: Loss: 0.2879 Acc: 100.0000%\n",
      "\tvalidation 5-7: Loss: 0.3315 Acc: 25.0000%\n",
      "\tvalidation 5-8: Loss: 0.3073 Acc: 50.0000%\n",
      "\tvalidation 5-9: Loss: 0.2889 Acc: 75.0000%\n",
      "\tvalidation 5-10: Loss: 0.3543 Acc: 25.0000%\n",
      "\tvalidation 5-11: Loss: 0.3365 Acc: 25.0000%\n",
      "\tvalidation 5-12: Loss: 0.2989 Acc: 75.0000%\n",
      "\tvalidation 5-13: Loss: 0.3381 Acc: 0.0000%\n",
      "\tvalidation 5-14: Loss: 0.2549 Acc: 100.0000%\n",
      "\tvalidation 5-15: Loss: 0.2928 Acc: 75.0000%\n",
      "\tvalidation 5-16: Loss: 0.2958 Acc: 75.0000%\n",
      "\tvalidation 5-17: Loss: 0.3346 Acc: 50.0000%\n",
      "\tvalidation 5-18: Loss: 0.3179 Acc: 25.0000%\n",
      "\tvalidation 5-19: Loss: 0.3119 Acc: 50.0000%\n",
      "\tvalidation 5-20: Loss: 0.2842 Acc: 100.0000%\n",
      "\tvalidation 5-21: Loss: 0.2939 Acc: 75.0000%\n",
      "\tvalidation 5-22: Loss: 0.2889 Acc: 50.0000%\n",
      "\tvalidation 5-23: Loss: 0.3033 Acc: 50.0000%\n",
      "\tvalidation 5-24: Loss: 0.3144 Acc: 50.0000%\n",
      "\tvalidation 5-25: Loss: 0.3228 Acc: 50.0000%\n",
      "\tvalidation 5-26: Loss: 0.2655 Acc: 100.0000%\n",
      "\tvalidation 5-27: Loss: 0.3278 Acc: 50.0000%\n",
      "\tvalidation 5-28: Loss: 0.2989 Acc: 25.0000%\n",
      "\tvalidation 5-29: Loss: 0.3067 Acc: 25.0000%\n",
      "\tvalidation 5-30: Loss: 0.3209 Acc: 0.0000%\n",
      "\tvalidation 5-31: Loss: 0.2728 Acc: 100.0000%\n",
      "\tvalidation 5-32: Loss: 0.2696 Acc: 75.0000%\n",
      "\tvalidation 5-33: Loss: 0.2914 Acc: 75.0000%\n",
      "\tvalidation 5-34: Loss: 0.3150 Acc: 50.0000%\n",
      "\tvalidation 5-35: Loss: 0.3108 Acc: 50.0000%\n",
      "\tvalidation 5-36: Loss: 0.3019 Acc: 50.0000%\n",
      "\tvalidation 5-37: Loss: 0.3186 Acc: 50.0000%\n",
      "\tvalidation 5-38: Loss: 0.3241 Acc: 50.0000%\n",
      "\tvalidation 5-39: Loss: 0.2829 Acc: 75.0000%\n",
      "\tvalidation 5-40: Loss: 0.3103 Acc: 50.0000%\n",
      "\tvalidation 5-41: Loss: 0.3156 Acc: 75.0000%\n",
      "\tvalidation 5-42: Loss: 0.3164 Acc: 75.0000%\n",
      "\tvalidation 5-43: Loss: 0.3138 Acc: 50.0000%\n",
      "\tvalidation 5-44: Loss: 0.3487 Acc: 25.0000%\n",
      "\tvalidation 5-45: Loss: 0.2913 Acc: 75.0000%\n",
      "\tvalidation 5-46: Loss: 0.3147 Acc: 50.0000%\n",
      "\tvalidation 5-47: Loss: 0.3219 Acc: 50.0000%\n",
      "\tvalidation 5-48: Loss: 0.3043 Acc: 25.0000%\n",
      "\tvalidation 5-49: Loss: 0.3055 Acc: 50.0000%\n",
      "\tvalidation 5-50: Loss: 0.2899 Acc: 75.0000%\n",
      "\tvalidation 5-51: Loss: 0.2853 Acc: 50.0000%\n",
      "\tvalidation 5-52: Loss: 0.2918 Acc: 75.0000%\n",
      "\tvalidation 5-53: Loss: 0.3093 Acc: 75.0000%\n",
      "\tvalidation 5-54: Loss: 0.2997 Acc: 75.0000%\n",
      "\tvalidation 5-55: Loss: 0.3196 Acc: 25.0000%\n",
      "\tvalidation 5-56: Loss: 0.3095 Acc: 75.0000%\n",
      "\tvalidation 5-57: Loss: 0.3017 Acc: 50.0000%\n",
      "\tvalidation 5-58: Loss: 0.2904 Acc: 50.0000%\n",
      "\tvalidation 5-59: Loss: 0.3148 Acc: 25.0000%\n",
      "\tvalidation 5-60: Loss: 0.3069 Acc: 50.0000%\n",
      "\tvalidation 5-61: Loss: 0.3067 Acc: 50.0000%\n",
      "\tvalidation 5-62: Loss: 0.3231 Acc: 50.0000%\n",
      "\tvalidation 5-63: Loss: 0.2964 Acc: 75.0000%\n",
      "\tvalidation 5-64: Loss: 0.2826 Acc: 50.0000%\n",
      "\tvalidation 5-65: Loss: 0.3175 Acc: 25.0000%\n",
      "\tvalidation 5-66: Loss: 0.2985 Acc: 50.0000%\n",
      "\tvalidation 5-67: Loss: 0.3159 Acc: 75.0000%\n",
      "\tvalidation 5-68: Loss: 0.3099 Acc: 50.0000%\n",
      "\tvalidation 5-69: Loss: 0.2802 Acc: 75.0000%\n",
      "\tvalidation 5-70: Loss: 0.3147 Acc: 75.0000%\n",
      "\tvalidation 5-71: Loss: 0.3281 Acc: 25.0000%\n",
      "\tvalidation 5-72: Loss: 0.3033 Acc: 100.0000%\n",
      "\tvalidation 5-73: Loss: 0.3543 Acc: 25.0000%\n",
      "\tvalidation 5-74: Loss: 0.2874 Acc: 75.0000%\n",
      "\tvalidation 5-75: Loss: 0.2712 Acc: 100.0000%\n",
      "\tvalidation 5-76: Loss: 0.2830 Acc: 50.0000%\n",
      "\tvalidation 5-77: Loss: 0.3069 Acc: 50.0000%\n",
      "\tvalidation 5-78: Loss: 0.3446 Acc: 25.0000%\n",
      "\tvalidation 5-79: Loss: 0.2611 Acc: 100.0000%\n",
      "\tvalidation 5-80: Loss: 0.3383 Acc: 50.0000%\n",
      "\tvalidation 5-81: Loss: 0.3008 Acc: 50.0000%\n",
      "\tvalidation 5-82: Loss: 0.3098 Acc: 25.0000%\n",
      "\tvalidation 5-83: Loss: 0.3214 Acc: 75.0000%\n",
      "\tvalidation 5-84: Loss: 0.2900 Acc: 50.0000%\n",
      "\tvalidation 5-85: Loss: 0.3174 Acc: 50.0000%\n",
      "\tvalidation 5-86: Loss: 0.2954 Acc: 100.0000%\n",
      "\tvalidation 5-87: Loss: 0.3080 Acc: 75.0000%\n",
      "\tvalidation 5-88: Loss: 0.2790 Acc: 100.0000%\n",
      "\tvalidation 5-89: Loss: 0.3183 Acc: 25.0000%\n",
      "\tvalidation 5-90: Loss: 0.3007 Acc: 75.0000%\n",
      "\tvalidation 5-91: Loss: 0.2805 Acc: 100.0000%\n",
      "\tvalidation 5-92: Loss: 0.2917 Acc: 75.0000%\n",
      "\tvalidation 5-93: Loss: 0.2868 Acc: 75.0000%\n",
      "\tvalidation 5-94: Loss: 0.2978 Acc: 75.0000%\n",
      "\tvalidation 5-95: Loss: 0.2851 Acc: 50.0000%\n",
      "\tvalidation 5-96: Loss: 0.3173 Acc: 50.0000%\n",
      "\tvalidation 5-97: Loss: 0.2634 Acc: 75.0000%\n",
      "\tvalidation 5-98: Loss: 0.3055 Acc: 50.0000%\n",
      "\tvalidation 5-99: Loss: 0.2965 Acc: 50.0000%\n",
      "\tvalidation 5-100: Loss: 0.3081 Acc: 75.0000%\n",
      "\tvalidation 5-101: Loss: 0.3198 Acc: 50.0000%\n",
      "\tvalidation 5-102: Loss: 0.2884 Acc: 50.0000%\n",
      "\tvalidation 5-103: Loss: 0.3151 Acc: 50.0000%\n",
      "\tvalidation 5-104: Loss: 0.3206 Acc: 75.0000%\n",
      "\tvalidation 5-105: Loss: 0.3430 Acc: 25.0000%\n",
      "\ttrain Loss: 0.3291 Acc: 34.5918%\n",
      "\tvalidation Loss: 0.3049 Acc: 58.0952%\n",
      "网络参数更新\n",
      "Time passed 0h 3m 55s\n",
      "--------------------\n",
      "Epoch [6/40]:\n",
      "\ttrain 6-1: Loss: 0.3180 Acc: 75.0000%\n",
      "\ttrain 6-2: Loss: 0.3136 Acc: 25.0000%\n",
      "\ttrain 6-3: Loss: 0.2924 Acc: 50.0000%\n",
      "\ttrain 6-4: Loss: 0.2884 Acc: 50.0000%\n",
      "\ttrain 6-5: Loss: 0.3098 Acc: 50.0000%\n",
      "\ttrain 6-6: Loss: 0.3182 Acc: 50.0000%\n",
      "\ttrain 6-7: Loss: 0.3021 Acc: 25.0000%\n",
      "\ttrain 6-8: Loss: 0.2738 Acc: 50.0000%\n",
      "\ttrain 6-9: Loss: 0.2944 Acc: 75.0000%\n",
      "\ttrain 6-10: Loss: 0.2812 Acc: 25.0000%\n",
      "\ttrain 6-11: Loss: 0.2242 Acc: 75.0000%\n",
      "\ttrain 6-12: Loss: 0.3478 Acc: 25.0000%\n",
      "\ttrain 6-13: Loss: 0.3299 Acc: 50.0000%\n",
      "\ttrain 6-14: Loss: 0.2854 Acc: 25.0000%\n",
      "\ttrain 6-15: Loss: 0.2367 Acc: 25.0000%\n",
      "\ttrain 6-16: Loss: 0.2605 Acc: 25.0000%\n",
      "\ttrain 6-17: Loss: 0.3240 Acc: 50.0000%\n",
      "\ttrain 6-18: Loss: 0.3012 Acc: 25.0000%\n",
      "\ttrain 6-19: Loss: 0.2737 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-20: Loss: 0.2513 Acc: 100.0000%\n",
      "\ttrain 6-21: Loss: 0.2976 Acc: 50.0000%\n",
      "\ttrain 6-22: Loss: 0.1892 Acc: 50.0000%\n",
      "\ttrain 6-23: Loss: 0.2490 Acc: 50.0000%\n",
      "\ttrain 6-24: Loss: 0.1957 Acc: 50.0000%\n",
      "\ttrain 6-25: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 6-26: Loss: 0.2254 Acc: 25.0000%\n",
      "\ttrain 6-27: Loss: 0.2939 Acc: 50.0000%\n",
      "\ttrain 6-28: Loss: 0.1710 Acc: 50.0000%\n",
      "\ttrain 6-29: Loss: 0.3490 Acc: 25.0000%\n",
      "\ttrain 6-30: Loss: 0.2241 Acc: 75.0000%\n",
      "\ttrain 6-31: Loss: 0.3209 Acc: 0.0000%\n",
      "\ttrain 6-32: Loss: 0.3485 Acc: 0.0000%\n",
      "\ttrain 6-33: Loss: 0.3874 Acc: 25.0000%\n",
      "\ttrain 6-34: Loss: 0.3279 Acc: 0.0000%\n",
      "\ttrain 6-35: Loss: 0.2930 Acc: 50.0000%\n",
      "\ttrain 6-36: Loss: 0.4086 Acc: 0.0000%\n",
      "\ttrain 6-37: Loss: 0.3176 Acc: 25.0000%\n",
      "\ttrain 6-38: Loss: 0.1941 Acc: 100.0000%\n",
      "\ttrain 6-39: Loss: 0.2985 Acc: 50.0000%\n",
      "\ttrain 6-40: Loss: 0.2109 Acc: 50.0000%\n",
      "\ttrain 6-41: Loss: 0.2551 Acc: 50.0000%\n",
      "\ttrain 6-42: Loss: 0.1611 Acc: 100.0000%\n",
      "\ttrain 6-43: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 6-44: Loss: 0.2775 Acc: 50.0000%\n",
      "\ttrain 6-45: Loss: 0.2379 Acc: 75.0000%\n",
      "\ttrain 6-46: Loss: 0.1477 Acc: 75.0000%\n",
      "\ttrain 6-47: Loss: 0.0954 Acc: 100.0000%\n",
      "\ttrain 6-48: Loss: 0.2234 Acc: 25.0000%\n",
      "\ttrain 6-49: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 6-50: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 6-51: Loss: 0.2410 Acc: 25.0000%\n",
      "\ttrain 6-52: Loss: 0.1453 Acc: 75.0000%\n",
      "\ttrain 6-53: Loss: 0.1234 Acc: 100.0000%\n",
      "\ttrain 6-54: Loss: 0.3291 Acc: 25.0000%\n",
      "\ttrain 6-55: Loss: 0.2395 Acc: 25.0000%\n",
      "\ttrain 6-56: Loss: 0.1742 Acc: 75.0000%\n",
      "\ttrain 6-57: Loss: 0.4081 Acc: 0.0000%\n",
      "\ttrain 6-58: Loss: 0.1857 Acc: 50.0000%\n",
      "\ttrain 6-59: Loss: 0.1965 Acc: 75.0000%\n",
      "\ttrain 6-60: Loss: 0.1851 Acc: 50.0000%\n",
      "\ttrain 6-61: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 6-62: Loss: 0.2535 Acc: 50.0000%\n",
      "\ttrain 6-63: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 6-64: Loss: 0.2387 Acc: 50.0000%\n",
      "\ttrain 6-65: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 6-66: Loss: 0.2680 Acc: 50.0000%\n",
      "\ttrain 6-67: Loss: 0.2435 Acc: 50.0000%\n",
      "\ttrain 6-68: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 6-69: Loss: 0.1808 Acc: 75.0000%\n",
      "\ttrain 6-70: Loss: 0.3401 Acc: 25.0000%\n",
      "\ttrain 6-71: Loss: 0.3410 Acc: 25.0000%\n",
      "\ttrain 6-72: Loss: 0.4692 Acc: 0.0000%\n",
      "\ttrain 6-73: Loss: 0.1842 Acc: 75.0000%\n",
      "\ttrain 6-74: Loss: 0.1944 Acc: 75.0000%\n",
      "\ttrain 6-75: Loss: 0.2879 Acc: 75.0000%\n",
      "\ttrain 6-76: Loss: 0.0655 Acc: 100.0000%\n",
      "\ttrain 6-77: Loss: 0.2594 Acc: 50.0000%\n",
      "\ttrain 6-78: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 6-79: Loss: 0.1377 Acc: 75.0000%\n",
      "\ttrain 6-80: Loss: 0.3528 Acc: 50.0000%\n",
      "\ttrain 6-81: Loss: 0.2671 Acc: 25.0000%\n",
      "\ttrain 6-82: Loss: 0.2122 Acc: 50.0000%\n",
      "\ttrain 6-83: Loss: 0.1415 Acc: 50.0000%\n",
      "\ttrain 6-84: Loss: 0.0786 Acc: 100.0000%\n",
      "\ttrain 6-85: Loss: 0.2551 Acc: 50.0000%\n",
      "\ttrain 6-86: Loss: 0.3034 Acc: 75.0000%\n",
      "\ttrain 6-87: Loss: 0.2367 Acc: 50.0000%\n",
      "\ttrain 6-88: Loss: 0.2220 Acc: 75.0000%\n",
      "\ttrain 6-89: Loss: 0.2551 Acc: 100.0000%\n",
      "\ttrain 6-90: Loss: 0.1797 Acc: 50.0000%\n",
      "\ttrain 6-91: Loss: 0.2365 Acc: 75.0000%\n",
      "\ttrain 6-92: Loss: 0.1592 Acc: 50.0000%\n",
      "\ttrain 6-93: Loss: 0.0995 Acc: 100.0000%\n",
      "\ttrain 6-94: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 6-95: Loss: 0.2138 Acc: 50.0000%\n",
      "\ttrain 6-96: Loss: 0.1722 Acc: 50.0000%\n",
      "\ttrain 6-97: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 6-98: Loss: 0.1999 Acc: 75.0000%\n",
      "\ttrain 6-99: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 6-100: Loss: 0.2390 Acc: 50.0000%\n",
      "\ttrain 6-101: Loss: 0.2353 Acc: 50.0000%\n",
      "\ttrain 6-102: Loss: 0.1731 Acc: 50.0000%\n",
      "\ttrain 6-103: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 6-104: Loss: 0.1756 Acc: 50.0000%\n",
      "\ttrain 6-105: Loss: 0.6143 Acc: 50.0000%\n",
      "\ttrain 6-106: Loss: 0.1977 Acc: 75.0000%\n",
      "\ttrain 6-107: Loss: 0.1356 Acc: 50.0000%\n",
      "\ttrain 6-108: Loss: 0.2091 Acc: 50.0000%\n",
      "\ttrain 6-109: Loss: 0.2480 Acc: 25.0000%\n",
      "\ttrain 6-110: Loss: 0.1905 Acc: 50.0000%\n",
      "\ttrain 6-111: Loss: 0.3682 Acc: 25.0000%\n",
      "\ttrain 6-112: Loss: 0.0887 Acc: 100.0000%\n",
      "\ttrain 6-113: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 6-114: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 6-115: Loss: 0.1505 Acc: 75.0000%\n",
      "\ttrain 6-116: Loss: 0.2260 Acc: 50.0000%\n",
      "\ttrain 6-117: Loss: 0.1278 Acc: 100.0000%\n",
      "\ttrain 6-118: Loss: 0.2267 Acc: 25.0000%\n",
      "\ttrain 6-119: Loss: 0.2030 Acc: 50.0000%\n",
      "\ttrain 6-120: Loss: 0.1662 Acc: 100.0000%\n",
      "\ttrain 6-121: Loss: 0.1062 Acc: 100.0000%\n",
      "\ttrain 6-122: Loss: 0.1486 Acc: 100.0000%\n",
      "\ttrain 6-123: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 6-124: Loss: 0.2168 Acc: 50.0000%\n",
      "\ttrain 6-125: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 6-126: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 6-127: Loss: 0.1903 Acc: 75.0000%\n",
      "\ttrain 6-128: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 6-129: Loss: 0.1628 Acc: 100.0000%\n",
      "\ttrain 6-130: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 6-131: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 6-132: Loss: 0.2368 Acc: 50.0000%\n",
      "\ttrain 6-133: Loss: 0.1979 Acc: 50.0000%\n",
      "\ttrain 6-134: Loss: 0.2725 Acc: 75.0000%\n",
      "\ttrain 6-135: Loss: 0.3074 Acc: 25.0000%\n",
      "\ttrain 6-136: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 6-137: Loss: 0.1397 Acc: 50.0000%\n",
      "\ttrain 6-138: Loss: 0.2491 Acc: 50.0000%\n",
      "\ttrain 6-139: Loss: 0.7889 Acc: 25.0000%\n",
      "\ttrain 6-140: Loss: 0.2038 Acc: 25.0000%\n",
      "\ttrain 6-141: Loss: 0.2085 Acc: 75.0000%\n",
      "\ttrain 6-142: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 6-143: Loss: 0.6351 Acc: 50.0000%\n",
      "\ttrain 6-144: Loss: 0.2824 Acc: 25.0000%\n",
      "\ttrain 6-145: Loss: 0.2287 Acc: 50.0000%\n",
      "\ttrain 6-146: Loss: 0.2427 Acc: 50.0000%\n",
      "\ttrain 6-147: Loss: 0.4396 Acc: 0.0000%\n",
      "\ttrain 6-148: Loss: 0.3423 Acc: 25.0000%\n",
      "\ttrain 6-149: Loss: 0.3887 Acc: 50.0000%\n",
      "\ttrain 6-150: Loss: 0.2803 Acc: 25.0000%\n",
      "\ttrain 6-151: Loss: 0.2188 Acc: 50.0000%\n",
      "\ttrain 6-152: Loss: 0.3341 Acc: 25.0000%\n",
      "\ttrain 6-153: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 6-154: Loss: 0.2463 Acc: 25.0000%\n",
      "\ttrain 6-155: Loss: 0.3595 Acc: 0.0000%\n",
      "\ttrain 6-156: Loss: 0.2261 Acc: 50.0000%\n",
      "\ttrain 6-157: Loss: 0.2902 Acc: 50.0000%\n",
      "\ttrain 6-158: Loss: 0.2425 Acc: 75.0000%\n",
      "\ttrain 6-159: Loss: 0.2260 Acc: 75.0000%\n",
      "\ttrain 6-160: Loss: 0.2508 Acc: 75.0000%\n",
      "\ttrain 6-161: Loss: 0.2953 Acc: 0.0000%\n",
      "\ttrain 6-162: Loss: 0.3476 Acc: 0.0000%\n",
      "\ttrain 6-163: Loss: 0.2079 Acc: 75.0000%\n",
      "\ttrain 6-164: Loss: 0.3274 Acc: 25.0000%\n",
      "\ttrain 6-165: Loss: 0.2905 Acc: 25.0000%\n",
      "\ttrain 6-166: Loss: 0.3058 Acc: 25.0000%\n",
      "\ttrain 6-167: Loss: 0.3651 Acc: 25.0000%\n",
      "\ttrain 6-168: Loss: 0.2869 Acc: 50.0000%\n",
      "\ttrain 6-169: Loss: 0.2096 Acc: 50.0000%\n",
      "\ttrain 6-170: Loss: 0.1939 Acc: 50.0000%\n",
      "\ttrain 6-171: Loss: 0.2188 Acc: 50.0000%\n",
      "\ttrain 6-172: Loss: 0.3153 Acc: 75.0000%\n",
      "\ttrain 6-173: Loss: 0.3831 Acc: 25.0000%\n",
      "\ttrain 6-174: Loss: 0.1970 Acc: 50.0000%\n",
      "\ttrain 6-175: Loss: 0.2589 Acc: 50.0000%\n",
      "\ttrain 6-176: Loss: 0.3206 Acc: 25.0000%\n",
      "\ttrain 6-177: Loss: 0.3430 Acc: 50.0000%\n",
      "\ttrain 6-178: Loss: 0.2480 Acc: 75.0000%\n",
      "\ttrain 6-179: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 6-180: Loss: 0.2836 Acc: 50.0000%\n",
      "\ttrain 6-181: Loss: 0.2226 Acc: 25.0000%\n",
      "\ttrain 6-182: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 6-183: Loss: 0.2916 Acc: 25.0000%\n",
      "\ttrain 6-184: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 6-185: Loss: 0.4264 Acc: 25.0000%\n",
      "\ttrain 6-186: Loss: 0.2266 Acc: 75.0000%\n",
      "\ttrain 6-187: Loss: 0.2560 Acc: 50.0000%\n",
      "\ttrain 6-188: Loss: 0.3023 Acc: 25.0000%\n",
      "\ttrain 6-189: Loss: 0.2866 Acc: 25.0000%\n",
      "\ttrain 6-190: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 6-191: Loss: 0.2573 Acc: 25.0000%\n",
      "\ttrain 6-192: Loss: 0.2803 Acc: 50.0000%\n",
      "\ttrain 6-193: Loss: 0.2838 Acc: 25.0000%\n",
      "\ttrain 6-194: Loss: 0.3065 Acc: 50.0000%\n",
      "\ttrain 6-195: Loss: 0.2451 Acc: 75.0000%\n",
      "\ttrain 6-196: Loss: 0.2306 Acc: 50.0000%\n",
      "\ttrain 6-197: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 6-198: Loss: 0.2148 Acc: 75.0000%\n",
      "\ttrain 6-199: Loss: 0.3255 Acc: 50.0000%\n",
      "\ttrain 6-200: Loss: 0.3131 Acc: 50.0000%\n",
      "\ttrain 6-201: Loss: 0.2315 Acc: 50.0000%\n",
      "\ttrain 6-202: Loss: 0.7240 Acc: 50.0000%\n",
      "\ttrain 6-203: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 6-204: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 6-205: Loss: 0.1824 Acc: 75.0000%\n",
      "\ttrain 6-206: Loss: 0.2024 Acc: 50.0000%\n",
      "\ttrain 6-207: Loss: 0.1987 Acc: 100.0000%\n",
      "\ttrain 6-208: Loss: 0.1349 Acc: 100.0000%\n",
      "\ttrain 6-209: Loss: 0.2374 Acc: 50.0000%\n",
      "\ttrain 6-210: Loss: 0.2341 Acc: 50.0000%\n",
      "\ttrain 6-211: Loss: 0.3060 Acc: 50.0000%\n",
      "\ttrain 6-212: Loss: 0.2459 Acc: 25.0000%\n",
      "\ttrain 6-213: Loss: 0.3013 Acc: 25.0000%\n",
      "\ttrain 6-214: Loss: 0.3712 Acc: 25.0000%\n",
      "\ttrain 6-215: Loss: 0.2278 Acc: 75.0000%\n",
      "\ttrain 6-216: Loss: 0.3585 Acc: 25.0000%\n",
      "\ttrain 6-217: Loss: 0.4070 Acc: 25.0000%\n",
      "\ttrain 6-218: Loss: 0.4253 Acc: 0.0000%\n",
      "\ttrain 6-219: Loss: 0.3504 Acc: 50.0000%\n",
      "\ttrain 6-220: Loss: 0.3787 Acc: 50.0000%\n",
      "\ttrain 6-221: Loss: 0.3755 Acc: 50.0000%\n",
      "\ttrain 6-222: Loss: 0.5915 Acc: 0.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-223: Loss: 0.4091 Acc: 0.0000%\n",
      "\ttrain 6-224: Loss: 0.3507 Acc: 50.0000%\n",
      "\ttrain 6-225: Loss: 0.3246 Acc: 0.0000%\n",
      "\ttrain 6-226: Loss: 0.3208 Acc: 25.0000%\n",
      "\ttrain 6-227: Loss: 0.2893 Acc: 75.0000%\n",
      "\ttrain 6-228: Loss: 0.3104 Acc: 50.0000%\n",
      "\ttrain 6-229: Loss: 0.2912 Acc: 25.0000%\n",
      "\ttrain 6-230: Loss: 0.3133 Acc: 0.0000%\n",
      "\ttrain 6-231: Loss: 0.3531 Acc: 25.0000%\n",
      "\ttrain 6-232: Loss: 0.3293 Acc: 50.0000%\n",
      "\ttrain 6-233: Loss: 0.3089 Acc: 25.0000%\n",
      "\ttrain 6-234: Loss: 0.3218 Acc: 25.0000%\n",
      "\ttrain 6-235: Loss: 0.3101 Acc: 50.0000%\n",
      "\ttrain 6-236: Loss: 0.2854 Acc: 25.0000%\n",
      "\ttrain 6-237: Loss: 0.2801 Acc: 75.0000%\n",
      "\ttrain 6-238: Loss: 0.2923 Acc: 75.0000%\n",
      "\ttrain 6-239: Loss: 0.3367 Acc: 25.0000%\n",
      "\ttrain 6-240: Loss: 0.3001 Acc: 50.0000%\n",
      "\ttrain 6-241: Loss: 0.2326 Acc: 75.0000%\n",
      "\ttrain 6-242: Loss: 0.2741 Acc: 75.0000%\n",
      "\ttrain 6-243: Loss: 0.3191 Acc: 50.0000%\n",
      "\ttrain 6-244: Loss: 0.2857 Acc: 75.0000%\n",
      "\ttrain 6-245: Loss: 0.2176 Acc: 75.0000%\n",
      "\tvalidation 6-1: Loss: 0.2142 Acc: 75.0000%\n",
      "\tvalidation 6-2: Loss: 0.2724 Acc: 25.0000%\n",
      "\tvalidation 6-3: Loss: 0.2556 Acc: 75.0000%\n",
      "\tvalidation 6-4: Loss: 0.2415 Acc: 50.0000%\n",
      "\tvalidation 6-5: Loss: 0.2523 Acc: 50.0000%\n",
      "\tvalidation 6-6: Loss: 0.2001 Acc: 75.0000%\n",
      "\tvalidation 6-7: Loss: 0.0984 Acc: 75.0000%\n",
      "\tvalidation 6-8: Loss: 0.3073 Acc: 0.0000%\n",
      "\tvalidation 6-9: Loss: 0.3943 Acc: 25.0000%\n",
      "\tvalidation 6-10: Loss: 0.1973 Acc: 25.0000%\n",
      "\tvalidation 6-11: Loss: 0.1811 Acc: 75.0000%\n",
      "\tvalidation 6-12: Loss: 0.2842 Acc: 0.0000%\n",
      "\tvalidation 6-13: Loss: 0.2413 Acc: 25.0000%\n",
      "\tvalidation 6-14: Loss: 0.3701 Acc: 50.0000%\n",
      "\tvalidation 6-15: Loss: 0.2162 Acc: 25.0000%\n",
      "\tvalidation 6-16: Loss: 0.2072 Acc: 75.0000%\n",
      "\tvalidation 6-17: Loss: 0.2205 Acc: 75.0000%\n",
      "\tvalidation 6-18: Loss: 0.3068 Acc: 25.0000%\n",
      "\tvalidation 6-19: Loss: 0.2812 Acc: 25.0000%\n",
      "\tvalidation 6-20: Loss: 0.1627 Acc: 50.0000%\n",
      "\tvalidation 6-21: Loss: 0.2094 Acc: 50.0000%\n",
      "\tvalidation 6-22: Loss: 0.3272 Acc: 50.0000%\n",
      "\tvalidation 6-23: Loss: 0.2551 Acc: 25.0000%\n",
      "\tvalidation 6-24: Loss: 0.2751 Acc: 75.0000%\n",
      "\tvalidation 6-25: Loss: 0.1962 Acc: 75.0000%\n",
      "\tvalidation 6-26: Loss: 0.2287 Acc: 50.0000%\n",
      "\tvalidation 6-27: Loss: 0.3121 Acc: 50.0000%\n",
      "\tvalidation 6-28: Loss: 0.3128 Acc: 50.0000%\n",
      "\tvalidation 6-29: Loss: 0.2088 Acc: 50.0000%\n",
      "\tvalidation 6-30: Loss: 0.2778 Acc: 50.0000%\n",
      "\tvalidation 6-31: Loss: 0.3210 Acc: 25.0000%\n",
      "\tvalidation 6-32: Loss: 0.1836 Acc: 50.0000%\n",
      "\tvalidation 6-33: Loss: 0.2052 Acc: 50.0000%\n",
      "\tvalidation 6-34: Loss: 0.2663 Acc: 50.0000%\n",
      "\tvalidation 6-35: Loss: 0.1536 Acc: 75.0000%\n",
      "\tvalidation 6-36: Loss: 0.2066 Acc: 50.0000%\n",
      "\tvalidation 6-37: Loss: 0.4720 Acc: 25.0000%\n",
      "\tvalidation 6-38: Loss: 0.2846 Acc: 50.0000%\n",
      "\tvalidation 6-39: Loss: 0.2800 Acc: 0.0000%\n",
      "\tvalidation 6-40: Loss: 0.3368 Acc: 0.0000%\n",
      "\tvalidation 6-41: Loss: 0.3217 Acc: 50.0000%\n",
      "\tvalidation 6-42: Loss: 0.2671 Acc: 75.0000%\n",
      "\tvalidation 6-43: Loss: 0.0734 Acc: 100.0000%\n",
      "\tvalidation 6-44: Loss: 0.2107 Acc: 50.0000%\n",
      "\tvalidation 6-45: Loss: 0.2717 Acc: 100.0000%\n",
      "\tvalidation 6-46: Loss: 0.1657 Acc: 100.0000%\n",
      "\tvalidation 6-47: Loss: 0.2738 Acc: 25.0000%\n",
      "\tvalidation 6-48: Loss: 0.1730 Acc: 100.0000%\n",
      "\tvalidation 6-49: Loss: 0.2039 Acc: 75.0000%\n",
      "\tvalidation 6-50: Loss: 0.3127 Acc: 25.0000%\n",
      "\tvalidation 6-51: Loss: 0.2123 Acc: 75.0000%\n",
      "\tvalidation 6-52: Loss: 0.2264 Acc: 75.0000%\n",
      "\tvalidation 6-53: Loss: 0.2256 Acc: 100.0000%\n",
      "\tvalidation 6-54: Loss: 0.2784 Acc: 0.0000%\n",
      "\tvalidation 6-55: Loss: 0.2189 Acc: 50.0000%\n",
      "\tvalidation 6-56: Loss: 0.2981 Acc: 25.0000%\n",
      "\tvalidation 6-57: Loss: 0.2011 Acc: 100.0000%\n",
      "\tvalidation 6-58: Loss: 0.1776 Acc: 50.0000%\n",
      "\tvalidation 6-59: Loss: 0.3159 Acc: 25.0000%\n",
      "\tvalidation 6-60: Loss: 0.1391 Acc: 50.0000%\n",
      "\tvalidation 6-61: Loss: 0.3258 Acc: 50.0000%\n",
      "\tvalidation 6-62: Loss: 0.1686 Acc: 50.0000%\n",
      "\tvalidation 6-63: Loss: 0.1786 Acc: 50.0000%\n",
      "\tvalidation 6-64: Loss: 0.4008 Acc: 25.0000%\n",
      "\tvalidation 6-65: Loss: 0.3270 Acc: 25.0000%\n",
      "\tvalidation 6-66: Loss: 0.2016 Acc: 75.0000%\n",
      "\tvalidation 6-67: Loss: 0.2220 Acc: 25.0000%\n",
      "\tvalidation 6-68: Loss: 0.2671 Acc: 50.0000%\n",
      "\tvalidation 6-69: Loss: 0.2537 Acc: 25.0000%\n",
      "\tvalidation 6-70: Loss: 0.2166 Acc: 50.0000%\n",
      "\tvalidation 6-71: Loss: 0.3331 Acc: 0.0000%\n",
      "\tvalidation 6-72: Loss: 0.3356 Acc: 75.0000%\n",
      "\tvalidation 6-73: Loss: 0.2510 Acc: 75.0000%\n",
      "\tvalidation 6-74: Loss: 0.1955 Acc: 75.0000%\n",
      "\tvalidation 6-75: Loss: 0.1547 Acc: 75.0000%\n",
      "\tvalidation 6-76: Loss: 0.3160 Acc: 25.0000%\n",
      "\tvalidation 6-77: Loss: 0.2303 Acc: 25.0000%\n",
      "\tvalidation 6-78: Loss: 0.2985 Acc: 0.0000%\n",
      "\tvalidation 6-79: Loss: 0.2612 Acc: 50.0000%\n",
      "\tvalidation 6-80: Loss: 0.2660 Acc: 50.0000%\n",
      "\tvalidation 6-81: Loss: 0.2830 Acc: 75.0000%\n",
      "\tvalidation 6-82: Loss: 0.2829 Acc: 75.0000%\n",
      "\tvalidation 6-83: Loss: 0.2074 Acc: 25.0000%\n",
      "\tvalidation 6-84: Loss: 0.2087 Acc: 75.0000%\n",
      "\tvalidation 6-85: Loss: 0.1824 Acc: 75.0000%\n",
      "\tvalidation 6-86: Loss: 0.2271 Acc: 50.0000%\n",
      "\tvalidation 6-87: Loss: 0.1631 Acc: 75.0000%\n",
      "\tvalidation 6-88: Loss: 0.3684 Acc: 0.0000%\n",
      "\tvalidation 6-89: Loss: 0.1651 Acc: 50.0000%\n",
      "\tvalidation 6-90: Loss: 0.1423 Acc: 75.0000%\n",
      "\tvalidation 6-91: Loss: 0.3058 Acc: 50.0000%\n",
      "\tvalidation 6-92: Loss: 0.3414 Acc: 50.0000%\n",
      "\tvalidation 6-93: Loss: 0.1484 Acc: 75.0000%\n",
      "\tvalidation 6-94: Loss: 0.1663 Acc: 75.0000%\n",
      "\tvalidation 6-95: Loss: 0.3798 Acc: 50.0000%\n",
      "\tvalidation 6-96: Loss: 0.3127 Acc: 25.0000%\n",
      "\tvalidation 6-97: Loss: 0.2696 Acc: 25.0000%\n",
      "\tvalidation 6-98: Loss: 0.1795 Acc: 50.0000%\n",
      "\tvalidation 6-99: Loss: 0.2081 Acc: 75.0000%\n",
      "\tvalidation 6-100: Loss: 0.2525 Acc: 25.0000%\n",
      "\tvalidation 6-101: Loss: 0.1795 Acc: 75.0000%\n",
      "\tvalidation 6-102: Loss: 0.3129 Acc: 50.0000%\n",
      "\tvalidation 6-103: Loss: 0.3555 Acc: 25.0000%\n",
      "\tvalidation 6-104: Loss: 0.1742 Acc: 75.0000%\n",
      "\tvalidation 6-105: Loss: 0.3221 Acc: 25.0000%\n",
      "\ttrain Loss: 0.2522 Acc: 52.2449%\n",
      "\tvalidation Loss: 0.2488 Acc: 50.0000%\n",
      "Time passed 0h 4m 40s\n",
      "--------------------\n",
      "Epoch [7/40]:\n",
      "\ttrain 7-1: Loss: 0.2438 Acc: 100.0000%\n",
      "\ttrain 7-2: Loss: 0.3134 Acc: 0.0000%\n",
      "\ttrain 7-3: Loss: 0.3106 Acc: 25.0000%\n",
      "\ttrain 7-4: Loss: 0.2725 Acc: 25.0000%\n",
      "\ttrain 7-5: Loss: 0.2052 Acc: 50.0000%\n",
      "\ttrain 7-6: Loss: 0.2955 Acc: 50.0000%\n",
      "\ttrain 7-7: Loss: 0.2598 Acc: 50.0000%\n",
      "\ttrain 7-8: Loss: 0.2556 Acc: 50.0000%\n",
      "\ttrain 7-9: Loss: 0.2022 Acc: 75.0000%\n",
      "\ttrain 7-10: Loss: 0.1809 Acc: 100.0000%\n",
      "\ttrain 7-11: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 7-12: Loss: 0.1579 Acc: 75.0000%\n",
      "\ttrain 7-13: Loss: 0.2171 Acc: 50.0000%\n",
      "\ttrain 7-14: Loss: 0.1832 Acc: 50.0000%\n",
      "\ttrain 7-15: Loss: 0.2320 Acc: 50.0000%\n",
      "\ttrain 7-16: Loss: 0.1505 Acc: 100.0000%\n",
      "\ttrain 7-17: Loss: 0.2761 Acc: 50.0000%\n",
      "\ttrain 7-18: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 7-19: Loss: 0.2301 Acc: 50.0000%\n",
      "\ttrain 7-20: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 7-21: Loss: 0.6501 Acc: 25.0000%\n",
      "\ttrain 7-22: Loss: 0.1764 Acc: 50.0000%\n",
      "\ttrain 7-23: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 7-24: Loss: 0.1806 Acc: 75.0000%\n",
      "\ttrain 7-25: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 7-26: Loss: 0.1937 Acc: 50.0000%\n",
      "\ttrain 7-27: Loss: 0.1406 Acc: 75.0000%\n",
      "\ttrain 7-28: Loss: 0.1656 Acc: 50.0000%\n",
      "\ttrain 7-29: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 7-30: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 7-31: Loss: 0.2171 Acc: 50.0000%\n",
      "\ttrain 7-32: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 7-33: Loss: 0.2830 Acc: 50.0000%\n",
      "\ttrain 7-34: Loss: 0.1588 Acc: 100.0000%\n",
      "\ttrain 7-35: Loss: 0.0894 Acc: 100.0000%\n",
      "\ttrain 7-36: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 7-37: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 7-38: Loss: 0.1936 Acc: 50.0000%\n",
      "\ttrain 7-39: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 7-40: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 7-41: Loss: 0.1217 Acc: 100.0000%\n",
      "\ttrain 7-42: Loss: 0.1676 Acc: 50.0000%\n",
      "\ttrain 7-43: Loss: 0.2213 Acc: 50.0000%\n",
      "\ttrain 7-44: Loss: 0.1972 Acc: 50.0000%\n",
      "\ttrain 7-45: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 7-46: Loss: 0.3057 Acc: 50.0000%\n",
      "\ttrain 7-47: Loss: 0.1836 Acc: 50.0000%\n",
      "\ttrain 7-48: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 7-49: Loss: 0.2187 Acc: 50.0000%\n",
      "\ttrain 7-50: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 7-51: Loss: 0.2072 Acc: 25.0000%\n",
      "\ttrain 7-52: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 7-53: Loss: 0.2463 Acc: 50.0000%\n",
      "\ttrain 7-54: Loss: 0.1904 Acc: 50.0000%\n",
      "\ttrain 7-55: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 7-56: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 7-57: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 7-58: Loss: 0.1715 Acc: 50.0000%\n",
      "\ttrain 7-59: Loss: 0.1575 Acc: 75.0000%\n",
      "\ttrain 7-60: Loss: 0.1414 Acc: 50.0000%\n",
      "\ttrain 7-61: Loss: 0.2014 Acc: 25.0000%\n",
      "\ttrain 7-62: Loss: 0.1383 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-63: Loss: 0.3408 Acc: 50.0000%\n",
      "\ttrain 7-64: Loss: 0.1122 Acc: 50.0000%\n",
      "\ttrain 7-65: Loss: 0.3948 Acc: 50.0000%\n",
      "\ttrain 7-66: Loss: 0.2006 Acc: 75.0000%\n",
      "\ttrain 7-67: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 7-68: Loss: 0.0642 Acc: 75.0000%\n",
      "\ttrain 7-69: Loss: 0.2429 Acc: 50.0000%\n",
      "\ttrain 7-70: Loss: 0.2339 Acc: 75.0000%\n",
      "\ttrain 7-71: Loss: 0.4014 Acc: 25.0000%\n",
      "\ttrain 7-72: Loss: 0.2502 Acc: 25.0000%\n",
      "\ttrain 7-73: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 7-74: Loss: 0.1725 Acc: 50.0000%\n",
      "\ttrain 7-75: Loss: 0.1806 Acc: 75.0000%\n",
      "\ttrain 7-76: Loss: 0.2689 Acc: 50.0000%\n",
      "\ttrain 7-77: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 7-78: Loss: 0.1226 Acc: 100.0000%\n",
      "\ttrain 7-79: Loss: 0.1825 Acc: 50.0000%\n",
      "\ttrain 7-80: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 7-81: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 7-82: Loss: 0.2084 Acc: 50.0000%\n",
      "\ttrain 7-83: Loss: 0.2862 Acc: 50.0000%\n",
      "\ttrain 7-84: Loss: 0.2102 Acc: 50.0000%\n",
      "\ttrain 7-85: Loss: 0.1809 Acc: 50.0000%\n",
      "\ttrain 7-86: Loss: 0.2381 Acc: 50.0000%\n",
      "\ttrain 7-87: Loss: 0.2265 Acc: 25.0000%\n",
      "\ttrain 7-88: Loss: 0.1655 Acc: 50.0000%\n",
      "\ttrain 7-89: Loss: 0.1945 Acc: 50.0000%\n",
      "\ttrain 7-90: Loss: 0.1883 Acc: 75.0000%\n",
      "\ttrain 7-91: Loss: 0.2266 Acc: 50.0000%\n",
      "\ttrain 7-92: Loss: 0.2211 Acc: 75.0000%\n",
      "\ttrain 7-93: Loss: 0.3101 Acc: 50.0000%\n",
      "\ttrain 7-94: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 7-95: Loss: 0.1343 Acc: 100.0000%\n",
      "\ttrain 7-96: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 7-97: Loss: 0.2345 Acc: 25.0000%\n",
      "\ttrain 7-98: Loss: 0.1832 Acc: 50.0000%\n",
      "\ttrain 7-99: Loss: 0.2300 Acc: 50.0000%\n",
      "\ttrain 7-100: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 7-101: Loss: 0.1040 Acc: 100.0000%\n",
      "\ttrain 7-102: Loss: 0.2136 Acc: 50.0000%\n",
      "\ttrain 7-103: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 7-104: Loss: 0.1800 Acc: 50.0000%\n",
      "\ttrain 7-105: Loss: 0.2702 Acc: 25.0000%\n",
      "\ttrain 7-106: Loss: 0.1630 Acc: 50.0000%\n",
      "\ttrain 7-107: Loss: 0.1971 Acc: 50.0000%\n",
      "\ttrain 7-108: Loss: 0.2030 Acc: 50.0000%\n",
      "\ttrain 7-109: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 7-110: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 7-111: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 7-112: Loss: 0.1989 Acc: 50.0000%\n",
      "\ttrain 7-113: Loss: 0.1079 Acc: 50.0000%\n",
      "\ttrain 7-114: Loss: 0.2119 Acc: 50.0000%\n",
      "\ttrain 7-115: Loss: 0.4343 Acc: 25.0000%\n",
      "\ttrain 7-116: Loss: 0.1166 Acc: 50.0000%\n",
      "\ttrain 7-117: Loss: 0.1755 Acc: 50.0000%\n",
      "\ttrain 7-118: Loss: 0.3160 Acc: 25.0000%\n",
      "\ttrain 7-119: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 7-120: Loss: 0.1772 Acc: 25.0000%\n",
      "\ttrain 7-121: Loss: 0.3926 Acc: 0.0000%\n",
      "\ttrain 7-122: Loss: 0.1332 Acc: 100.0000%\n",
      "\ttrain 7-123: Loss: 0.1944 Acc: 50.0000%\n",
      "\ttrain 7-124: Loss: 0.1502 Acc: 75.0000%\n",
      "\ttrain 7-125: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 7-126: Loss: 0.2156 Acc: 50.0000%\n",
      "\ttrain 7-127: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 7-128: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 7-129: Loss: 0.2219 Acc: 25.0000%\n",
      "\ttrain 7-130: Loss: 0.1902 Acc: 75.0000%\n",
      "\ttrain 7-131: Loss: 0.0626 Acc: 75.0000%\n",
      "\ttrain 7-132: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 7-133: Loss: 0.1795 Acc: 75.0000%\n",
      "\ttrain 7-134: Loss: 0.2462 Acc: 50.0000%\n",
      "\ttrain 7-135: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 7-136: Loss: 0.2252 Acc: 25.0000%\n",
      "\ttrain 7-137: Loss: 0.2359 Acc: 50.0000%\n",
      "\ttrain 7-138: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 7-139: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 7-140: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 7-141: Loss: 0.1107 Acc: 50.0000%\n",
      "\ttrain 7-142: Loss: 0.1845 Acc: 50.0000%\n",
      "\ttrain 7-143: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 7-144: Loss: 0.2943 Acc: 50.0000%\n",
      "\ttrain 7-145: Loss: 0.0865 Acc: 100.0000%\n",
      "\ttrain 7-146: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 7-147: Loss: 0.1570 Acc: 50.0000%\n",
      "\ttrain 7-148: Loss: 0.2019 Acc: 25.0000%\n",
      "\ttrain 7-149: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 7-150: Loss: 0.2098 Acc: 0.0000%\n",
      "\ttrain 7-151: Loss: 0.1550 Acc: 25.0000%\n",
      "\ttrain 7-152: Loss: 0.0920 Acc: 100.0000%\n",
      "\ttrain 7-153: Loss: 0.1104 Acc: 50.0000%\n",
      "\ttrain 7-154: Loss: 0.1301 Acc: 100.0000%\n",
      "\ttrain 7-155: Loss: 0.0887 Acc: 100.0000%\n",
      "\ttrain 7-156: Loss: 0.1162 Acc: 100.0000%\n",
      "\ttrain 7-157: Loss: 0.3244 Acc: 25.0000%\n",
      "\ttrain 7-158: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 7-159: Loss: 0.1113 Acc: 100.0000%\n",
      "\ttrain 7-160: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 7-161: Loss: 0.1390 Acc: 75.0000%\n",
      "\ttrain 7-162: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 7-163: Loss: 0.1341 Acc: 50.0000%\n",
      "\ttrain 7-164: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 7-165: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 7-166: Loss: 0.2356 Acc: 50.0000%\n",
      "\ttrain 7-167: Loss: 0.1792 Acc: 75.0000%\n",
      "\ttrain 7-168: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 7-169: Loss: 0.2605 Acc: 50.0000%\n",
      "\ttrain 7-170: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 7-171: Loss: 0.1857 Acc: 50.0000%\n",
      "\ttrain 7-172: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 7-173: Loss: 0.2568 Acc: 25.0000%\n",
      "\ttrain 7-174: Loss: 0.7369 Acc: 50.0000%\n",
      "\ttrain 7-175: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 7-176: Loss: 0.2735 Acc: 0.0000%\n",
      "\ttrain 7-177: Loss: 0.2141 Acc: 25.0000%\n",
      "\ttrain 7-178: Loss: 0.2741 Acc: 25.0000%\n",
      "\ttrain 7-179: Loss: 0.2698 Acc: 25.0000%\n",
      "\ttrain 7-180: Loss: 0.2745 Acc: 50.0000%\n",
      "\ttrain 7-181: Loss: 0.2826 Acc: 50.0000%\n",
      "\ttrain 7-182: Loss: 0.6385 Acc: 50.0000%\n",
      "\ttrain 7-183: Loss: 0.1754 Acc: 75.0000%\n",
      "\ttrain 7-184: Loss: 0.1914 Acc: 75.0000%\n",
      "\ttrain 7-185: Loss: 0.1775 Acc: 75.0000%\n",
      "\ttrain 7-186: Loss: 0.3077 Acc: 25.0000%\n",
      "\ttrain 7-187: Loss: 0.1934 Acc: 50.0000%\n",
      "\ttrain 7-188: Loss: 0.1558 Acc: 100.0000%\n",
      "\ttrain 7-189: Loss: 0.2476 Acc: 50.0000%\n",
      "\ttrain 7-190: Loss: 0.1341 Acc: 100.0000%\n",
      "\ttrain 7-191: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 7-192: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 7-193: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 7-194: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 7-195: Loss: 0.2437 Acc: 50.0000%\n",
      "\ttrain 7-196: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 7-197: Loss: 0.1931 Acc: 50.0000%\n",
      "\ttrain 7-198: Loss: 0.2217 Acc: 50.0000%\n",
      "\ttrain 7-199: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 7-200: Loss: 0.2124 Acc: 50.0000%\n",
      "\ttrain 7-201: Loss: 0.1376 Acc: 100.0000%\n",
      "\ttrain 7-202: Loss: 0.2436 Acc: 50.0000%\n",
      "\ttrain 7-203: Loss: 0.1534 Acc: 75.0000%\n",
      "\ttrain 7-204: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 7-205: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 7-206: Loss: 0.2226 Acc: 50.0000%\n",
      "\ttrain 7-207: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 7-208: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 7-209: Loss: 0.1609 Acc: 75.0000%\n",
      "\ttrain 7-210: Loss: 0.1545 Acc: 50.0000%\n",
      "\ttrain 7-211: Loss: 0.1273 Acc: 100.0000%\n",
      "\ttrain 7-212: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 7-213: Loss: 0.1416 Acc: 75.0000%\n",
      "\ttrain 7-214: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 7-215: Loss: 0.3126 Acc: 25.0000%\n",
      "\ttrain 7-216: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 7-217: Loss: 0.1919 Acc: 75.0000%\n",
      "\ttrain 7-218: Loss: 0.1709 Acc: 50.0000%\n",
      "\ttrain 7-219: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 7-220: Loss: 0.2813 Acc: 25.0000%\n",
      "\ttrain 7-221: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 7-222: Loss: 0.1821 Acc: 75.0000%\n",
      "\ttrain 7-223: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 7-224: Loss: 0.1146 Acc: 100.0000%\n",
      "\ttrain 7-225: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 7-226: Loss: 0.1624 Acc: 50.0000%\n",
      "\ttrain 7-227: Loss: 0.2853 Acc: 25.0000%\n",
      "\ttrain 7-228: Loss: 0.2696 Acc: 75.0000%\n",
      "\ttrain 7-229: Loss: 0.1997 Acc: 50.0000%\n",
      "\ttrain 7-230: Loss: 0.2365 Acc: 50.0000%\n",
      "\ttrain 7-231: Loss: 0.2681 Acc: 25.0000%\n",
      "\ttrain 7-232: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 7-233: Loss: 0.2185 Acc: 25.0000%\n",
      "\ttrain 7-234: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 7-235: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 7-236: Loss: 0.2100 Acc: 50.0000%\n",
      "\ttrain 7-237: Loss: 0.1392 Acc: 75.0000%\n",
      "\ttrain 7-238: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 7-239: Loss: 0.1169 Acc: 50.0000%\n",
      "\ttrain 7-240: Loss: 0.2786 Acc: 50.0000%\n",
      "\ttrain 7-241: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 7-242: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 7-243: Loss: 0.1191 Acc: 100.0000%\n",
      "\ttrain 7-244: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 7-245: Loss: 0.3533 Acc: 50.0000%\n",
      "\tvalidation 7-1: Loss: 0.1475 Acc: 75.0000%\n",
      "\tvalidation 7-2: Loss: 0.0565 Acc: 75.0000%\n",
      "\tvalidation 7-3: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 7-4: Loss: 0.0912 Acc: 100.0000%\n",
      "\tvalidation 7-5: Loss: 0.0557 Acc: 75.0000%\n",
      "\tvalidation 7-6: Loss: 0.1117 Acc: 75.0000%\n",
      "\tvalidation 7-7: Loss: 0.0536 Acc: 75.0000%\n",
      "\tvalidation 7-8: Loss: 0.1888 Acc: 75.0000%\n",
      "\tvalidation 7-9: Loss: 0.0477 Acc: 100.0000%\n",
      "\tvalidation 7-10: Loss: 0.0549 Acc: 75.0000%\n",
      "\tvalidation 7-11: Loss: 0.1083 Acc: 50.0000%\n",
      "\tvalidation 7-12: Loss: 0.3557 Acc: 25.0000%\n",
      "\tvalidation 7-13: Loss: 0.1033 Acc: 75.0000%\n",
      "\tvalidation 7-14: Loss: 0.1935 Acc: 75.0000%\n",
      "\tvalidation 7-15: Loss: 0.0610 Acc: 75.0000%\n",
      "\tvalidation 7-16: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 7-17: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 7-18: Loss: 0.0443 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 7-19: Loss: 0.1080 Acc: 50.0000%\n",
      "\tvalidation 7-20: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 7-21: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 7-22: Loss: 0.1074 Acc: 50.0000%\n",
      "\tvalidation 7-23: Loss: 0.0454 Acc: 100.0000%\n",
      "\tvalidation 7-24: Loss: 0.0515 Acc: 100.0000%\n",
      "\tvalidation 7-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-26: Loss: 0.0539 Acc: 75.0000%\n",
      "\tvalidation 7-27: Loss: 0.0460 Acc: 100.0000%\n",
      "\tvalidation 7-28: Loss: 0.0986 Acc: 75.0000%\n",
      "\tvalidation 7-29: Loss: 0.1529 Acc: 50.0000%\n",
      "\tvalidation 7-30: Loss: 0.1833 Acc: 100.0000%\n",
      "\tvalidation 7-31: Loss: 0.0570 Acc: 75.0000%\n",
      "\tvalidation 7-32: Loss: 0.1373 Acc: 75.0000%\n",
      "\tvalidation 7-33: Loss: 0.1132 Acc: 50.0000%\n",
      "\tvalidation 7-34: Loss: 0.1128 Acc: 50.0000%\n",
      "\tvalidation 7-35: Loss: 0.0542 Acc: 75.0000%\n",
      "\tvalidation 7-36: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 7-37: Loss: 0.1331 Acc: 100.0000%\n",
      "\tvalidation 7-38: Loss: 0.1002 Acc: 75.0000%\n",
      "\tvalidation 7-39: Loss: 0.1518 Acc: 50.0000%\n",
      "\tvalidation 7-40: Loss: 0.0970 Acc: 75.0000%\n",
      "\tvalidation 7-41: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 7-42: Loss: 0.1416 Acc: 75.0000%\n",
      "\tvalidation 7-43: Loss: 0.0904 Acc: 100.0000%\n",
      "\tvalidation 7-44: Loss: 0.0554 Acc: 75.0000%\n",
      "\tvalidation 7-45: Loss: 0.0536 Acc: 100.0000%\n",
      "\tvalidation 7-46: Loss: 0.0570 Acc: 75.0000%\n",
      "\tvalidation 7-47: Loss: 0.1239 Acc: 50.0000%\n",
      "\tvalidation 7-48: Loss: 0.1079 Acc: 50.0000%\n",
      "\tvalidation 7-49: Loss: 0.1024 Acc: 75.0000%\n",
      "\tvalidation 7-50: Loss: 0.1010 Acc: 75.0000%\n",
      "\tvalidation 7-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 7-52: Loss: 0.1415 Acc: 75.0000%\n",
      "\tvalidation 7-53: Loss: 0.1734 Acc: 50.0000%\n",
      "\tvalidation 7-54: Loss: 0.0540 Acc: 75.0000%\n",
      "\tvalidation 7-55: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 7-56: Loss: 0.1367 Acc: 100.0000%\n",
      "\tvalidation 7-57: Loss: 0.1021 Acc: 75.0000%\n",
      "\tvalidation 7-58: Loss: 0.0562 Acc: 75.0000%\n",
      "\tvalidation 7-59: Loss: 0.1011 Acc: 75.0000%\n",
      "\tvalidation 7-60: Loss: 0.1095 Acc: 50.0000%\n",
      "\tvalidation 7-61: Loss: 0.0989 Acc: 75.0000%\n",
      "\tvalidation 7-62: Loss: 0.1996 Acc: 75.0000%\n",
      "\tvalidation 7-63: Loss: 0.1074 Acc: 50.0000%\n",
      "\tvalidation 7-64: Loss: 0.0479 Acc: 100.0000%\n",
      "\tvalidation 7-65: Loss: 0.1472 Acc: 75.0000%\n",
      "\tvalidation 7-66: Loss: 0.1003 Acc: 75.0000%\n",
      "\tvalidation 7-67: Loss: 0.1099 Acc: 50.0000%\n",
      "\tvalidation 7-68: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 7-69: Loss: 0.0560 Acc: 75.0000%\n",
      "\tvalidation 7-70: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 7-71: Loss: 0.2083 Acc: 25.0000%\n",
      "\tvalidation 7-72: Loss: 0.1076 Acc: 50.0000%\n",
      "\tvalidation 7-73: Loss: 0.2187 Acc: 50.0000%\n",
      "\tvalidation 7-74: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 7-75: Loss: 0.2105 Acc: 25.0000%\n",
      "\tvalidation 7-76: Loss: 0.1093 Acc: 50.0000%\n",
      "\tvalidation 7-77: Loss: 0.1489 Acc: 50.0000%\n",
      "\tvalidation 7-78: Loss: 0.1847 Acc: 75.0000%\n",
      "\tvalidation 7-79: Loss: 0.2151 Acc: 50.0000%\n",
      "\tvalidation 7-80: Loss: 0.0671 Acc: 100.0000%\n",
      "\tvalidation 7-81: Loss: 0.1782 Acc: 100.0000%\n",
      "\tvalidation 7-82: Loss: 0.0407 Acc: 100.0000%\n",
      "\tvalidation 7-83: Loss: 0.1344 Acc: 100.0000%\n",
      "\tvalidation 7-84: Loss: 0.1042 Acc: 75.0000%\n",
      "\tvalidation 7-85: Loss: 0.0966 Acc: 75.0000%\n",
      "\tvalidation 7-86: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 7-87: Loss: 0.1081 Acc: 50.0000%\n",
      "\tvalidation 7-88: Loss: 0.1007 Acc: 75.0000%\n",
      "\tvalidation 7-89: Loss: 0.1469 Acc: 75.0000%\n",
      "\tvalidation 7-90: Loss: 0.1140 Acc: 75.0000%\n",
      "\tvalidation 7-91: Loss: 0.1571 Acc: 50.0000%\n",
      "\tvalidation 7-92: Loss: 0.0929 Acc: 100.0000%\n",
      "\tvalidation 7-93: Loss: 0.1466 Acc: 75.0000%\n",
      "\tvalidation 7-94: Loss: 0.1086 Acc: 50.0000%\n",
      "\tvalidation 7-95: Loss: 0.1060 Acc: 50.0000%\n",
      "\tvalidation 7-96: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 7-97: Loss: 0.1068 Acc: 75.0000%\n",
      "\tvalidation 7-98: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 7-99: Loss: 0.1891 Acc: 75.0000%\n",
      "\tvalidation 7-100: Loss: 0.1497 Acc: 50.0000%\n",
      "\tvalidation 7-101: Loss: 0.1498 Acc: 50.0000%\n",
      "\tvalidation 7-102: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 7-103: Loss: 0.0986 Acc: 75.0000%\n",
      "\tvalidation 7-104: Loss: 0.0915 Acc: 100.0000%\n",
      "\tvalidation 7-105: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1810 Acc: 63.0612%\n",
      "\tvalidation Loss: 0.1042 Acc: 75.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 5m 28s\n",
      "--------------------\n",
      "Epoch [8/40]:\n",
      "\ttrain 8-1: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 8-2: Loss: 0.1834 Acc: 75.0000%\n",
      "\ttrain 8-3: Loss: 0.2840 Acc: 75.0000%\n",
      "\ttrain 8-4: Loss: 0.4694 Acc: 25.0000%\n",
      "\ttrain 8-5: Loss: 0.5414 Acc: 0.0000%\n",
      "\ttrain 8-6: Loss: 0.2799 Acc: 25.0000%\n",
      "\ttrain 8-7: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 8-8: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 8-9: Loss: 0.1448 Acc: 50.0000%\n",
      "\ttrain 8-10: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 8-11: Loss: 0.2112 Acc: 50.0000%\n",
      "\ttrain 8-12: Loss: 0.3499 Acc: 0.0000%\n",
      "\ttrain 8-13: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 8-14: Loss: 0.4760 Acc: 0.0000%\n",
      "\ttrain 8-15: Loss: 0.1444 Acc: 100.0000%\n",
      "\ttrain 8-16: Loss: 0.2171 Acc: 75.0000%\n",
      "\ttrain 8-17: Loss: 0.1692 Acc: 75.0000%\n",
      "\ttrain 8-18: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 8-19: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 8-20: Loss: 0.2717 Acc: 25.0000%\n",
      "\ttrain 8-21: Loss: 0.2826 Acc: 25.0000%\n",
      "\ttrain 8-22: Loss: 0.3778 Acc: 0.0000%\n",
      "\ttrain 8-23: Loss: 0.3241 Acc: 25.0000%\n",
      "\ttrain 8-24: Loss: 0.2830 Acc: 25.0000%\n",
      "\ttrain 8-25: Loss: 0.2318 Acc: 50.0000%\n",
      "\ttrain 8-26: Loss: 0.4776 Acc: 25.0000%\n",
      "\ttrain 8-27: Loss: 0.3803 Acc: 50.0000%\n",
      "\ttrain 8-28: Loss: 0.2012 Acc: 50.0000%\n",
      "\ttrain 8-29: Loss: 0.2877 Acc: 25.0000%\n",
      "\ttrain 8-30: Loss: 0.2535 Acc: 25.0000%\n",
      "\ttrain 8-31: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 8-32: Loss: 0.1818 Acc: 75.0000%\n",
      "\ttrain 8-33: Loss: 0.1670 Acc: 75.0000%\n",
      "\ttrain 8-34: Loss: 0.2971 Acc: 25.0000%\n",
      "\ttrain 8-35: Loss: 0.3221 Acc: 25.0000%\n",
      "\ttrain 8-36: Loss: 0.3908 Acc: 75.0000%\n",
      "\ttrain 8-37: Loss: 0.3300 Acc: 25.0000%\n",
      "\ttrain 8-38: Loss: 0.1791 Acc: 50.0000%\n",
      "\ttrain 8-39: Loss: 0.2973 Acc: 50.0000%\n",
      "\ttrain 8-40: Loss: 0.1629 Acc: 100.0000%\n",
      "\ttrain 8-41: Loss: 0.1841 Acc: 100.0000%\n",
      "\ttrain 8-42: Loss: 0.1885 Acc: 75.0000%\n",
      "\ttrain 8-43: Loss: 0.2150 Acc: 0.0000%\n",
      "\ttrain 8-44: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 8-45: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 8-46: Loss: 0.1578 Acc: 75.0000%\n",
      "\ttrain 8-47: Loss: 0.1502 Acc: 50.0000%\n",
      "\ttrain 8-48: Loss: 0.2549 Acc: 25.0000%\n",
      "\ttrain 8-49: Loss: 0.1866 Acc: 25.0000%\n",
      "\ttrain 8-50: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 8-51: Loss: 0.2480 Acc: 50.0000%\n",
      "\ttrain 8-52: Loss: 0.1717 Acc: 75.0000%\n",
      "\ttrain 8-53: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 8-54: Loss: 0.2127 Acc: 50.0000%\n",
      "\ttrain 8-55: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 8-56: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 8-57: Loss: 0.2146 Acc: 75.0000%\n",
      "\ttrain 8-58: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 8-59: Loss: 0.0690 Acc: 100.0000%\n",
      "\ttrain 8-60: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 8-61: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 8-62: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 8-63: Loss: 0.1240 Acc: 50.0000%\n",
      "\ttrain 8-64: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 8-65: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 8-66: Loss: 0.4827 Acc: 75.0000%\n",
      "\ttrain 8-67: Loss: 0.1904 Acc: 75.0000%\n",
      "\ttrain 8-68: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 8-69: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 8-70: Loss: 0.1395 Acc: 50.0000%\n",
      "\ttrain 8-71: Loss: 0.2017 Acc: 50.0000%\n",
      "\ttrain 8-72: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 8-73: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 8-74: Loss: 0.1116 Acc: 50.0000%\n",
      "\ttrain 8-75: Loss: 0.1874 Acc: 50.0000%\n",
      "\ttrain 8-76: Loss: 0.2122 Acc: 75.0000%\n",
      "\ttrain 8-77: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 8-78: Loss: 0.1141 Acc: 100.0000%\n",
      "\ttrain 8-79: Loss: 0.1335 Acc: 50.0000%\n",
      "\ttrain 8-80: Loss: 0.2066 Acc: 75.0000%\n",
      "\ttrain 8-81: Loss: 0.1003 Acc: 100.0000%\n",
      "\ttrain 8-82: Loss: 0.2182 Acc: 50.0000%\n",
      "\ttrain 8-83: Loss: 0.1862 Acc: 50.0000%\n",
      "\ttrain 8-84: Loss: 0.1951 Acc: 50.0000%\n",
      "\ttrain 8-85: Loss: 0.1542 Acc: 50.0000%\n",
      "\ttrain 8-86: Loss: 0.3709 Acc: 50.0000%\n",
      "\ttrain 8-87: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 8-88: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 8-89: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 8-90: Loss: 0.0693 Acc: 100.0000%\n",
      "\ttrain 8-91: Loss: 0.0780 Acc: 100.0000%\n",
      "\ttrain 8-92: Loss: 0.0730 Acc: 100.0000%\n",
      "\ttrain 8-93: Loss: 0.2406 Acc: 25.0000%\n",
      "\ttrain 8-94: Loss: 0.1430 Acc: 50.0000%\n",
      "\ttrain 8-95: Loss: 0.1453 Acc: 75.0000%\n",
      "\ttrain 8-96: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 8-97: Loss: 0.1565 Acc: 75.0000%\n",
      "\ttrain 8-98: Loss: 0.2004 Acc: 50.0000%\n",
      "\ttrain 8-99: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 8-100: Loss: 0.0826 Acc: 100.0000%\n",
      "\ttrain 8-101: Loss: 0.1615 Acc: 75.0000%\n",
      "\ttrain 8-102: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 8-103: Loss: 0.1089 Acc: 75.0000%\n",
      "\ttrain 8-104: Loss: 0.2136 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 8-105: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 8-106: Loss: 0.2400 Acc: 25.0000%\n",
      "\ttrain 8-107: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 8-108: Loss: 0.1261 Acc: 50.0000%\n",
      "\ttrain 8-109: Loss: 0.1120 Acc: 50.0000%\n",
      "\ttrain 8-110: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 8-111: Loss: 0.2363 Acc: 50.0000%\n",
      "\ttrain 8-112: Loss: 0.2282 Acc: 75.0000%\n",
      "\ttrain 8-113: Loss: 0.1911 Acc: 50.0000%\n",
      "\ttrain 8-114: Loss: 0.0772 Acc: 75.0000%\n",
      "\ttrain 8-115: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 8-116: Loss: 0.1936 Acc: 50.0000%\n",
      "\ttrain 8-117: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 8-118: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 8-119: Loss: 0.1398 Acc: 50.0000%\n",
      "\ttrain 8-120: Loss: 0.3486 Acc: 25.0000%\n",
      "\ttrain 8-121: Loss: 0.1902 Acc: 25.0000%\n",
      "\ttrain 8-122: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 8-123: Loss: 0.2185 Acc: 50.0000%\n",
      "\ttrain 8-124: Loss: 0.1706 Acc: 50.0000%\n",
      "\ttrain 8-125: Loss: 0.1831 Acc: 75.0000%\n",
      "\ttrain 8-126: Loss: 0.1737 Acc: 75.0000%\n",
      "\ttrain 8-127: Loss: 0.2526 Acc: 0.0000%\n",
      "\ttrain 8-128: Loss: 0.1120 Acc: 100.0000%\n",
      "\ttrain 8-129: Loss: 0.2797 Acc: 75.0000%\n",
      "\ttrain 8-130: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 8-131: Loss: 0.3310 Acc: 75.0000%\n",
      "\ttrain 8-132: Loss: 0.2128 Acc: 75.0000%\n",
      "\ttrain 8-133: Loss: 0.1609 Acc: 50.0000%\n",
      "\ttrain 8-134: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 8-135: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 8-136: Loss: 0.1839 Acc: 100.0000%\n",
      "\ttrain 8-137: Loss: 0.1494 Acc: 50.0000%\n",
      "\ttrain 8-138: Loss: 0.1765 Acc: 50.0000%\n",
      "\ttrain 8-139: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 8-140: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 8-141: Loss: 0.1494 Acc: 50.0000%\n",
      "\ttrain 8-142: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 8-143: Loss: 0.1425 Acc: 100.0000%\n",
      "\ttrain 8-144: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 8-145: Loss: 0.1178 Acc: 100.0000%\n",
      "\ttrain 8-146: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 8-147: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 8-148: Loss: 0.1190 Acc: 100.0000%\n",
      "\ttrain 8-149: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 8-150: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 8-151: Loss: 0.1137 Acc: 75.0000%\n",
      "\ttrain 8-152: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 8-153: Loss: 0.1560 Acc: 25.0000%\n",
      "\ttrain 8-154: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 8-155: Loss: 0.0885 Acc: 100.0000%\n",
      "\ttrain 8-156: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 8-157: Loss: 0.1381 Acc: 50.0000%\n",
      "\ttrain 8-158: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 8-159: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 8-160: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 8-161: Loss: 0.2769 Acc: 50.0000%\n",
      "\ttrain 8-162: Loss: 0.1651 Acc: 50.0000%\n",
      "\ttrain 8-163: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 8-164: Loss: 0.1430 Acc: 50.0000%\n",
      "\ttrain 8-165: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 8-166: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 8-167: Loss: 0.1116 Acc: 50.0000%\n",
      "\ttrain 8-168: Loss: 0.0952 Acc: 100.0000%\n",
      "\ttrain 8-169: Loss: 0.1772 Acc: 50.0000%\n",
      "\ttrain 8-170: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 8-171: Loss: 0.1739 Acc: 50.0000%\n",
      "\ttrain 8-172: Loss: 0.1352 Acc: 75.0000%\n",
      "\ttrain 8-173: Loss: 0.1983 Acc: 50.0000%\n",
      "\ttrain 8-174: Loss: 0.2818 Acc: 25.0000%\n",
      "\ttrain 8-175: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 8-176: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 8-177: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 8-178: Loss: 0.1521 Acc: 50.0000%\n",
      "\ttrain 8-179: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 8-180: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 8-181: Loss: 0.1459 Acc: 50.0000%\n",
      "\ttrain 8-182: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 8-183: Loss: 0.0609 Acc: 75.0000%\n",
      "\ttrain 8-184: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 8-185: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 8-186: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 8-187: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 8-188: Loss: 0.1021 Acc: 50.0000%\n",
      "\ttrain 8-189: Loss: 0.0775 Acc: 100.0000%\n",
      "\ttrain 8-190: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 8-191: Loss: 0.1130 Acc: 100.0000%\n",
      "\ttrain 8-192: Loss: 0.1655 Acc: 75.0000%\n",
      "\ttrain 8-193: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 8-194: Loss: 0.1936 Acc: 50.0000%\n",
      "\ttrain 8-195: Loss: 0.2562 Acc: 75.0000%\n",
      "\ttrain 8-196: Loss: 0.1537 Acc: 50.0000%\n",
      "\ttrain 8-197: Loss: 0.1512 Acc: 50.0000%\n",
      "\ttrain 8-198: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 8-199: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 8-200: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 8-201: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 8-202: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 8-203: Loss: 0.0861 Acc: 100.0000%\n",
      "\ttrain 8-204: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 8-205: Loss: 0.4101 Acc: 25.0000%\n",
      "\ttrain 8-206: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 8-207: Loss: 0.1883 Acc: 75.0000%\n",
      "\ttrain 8-208: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 8-209: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 8-210: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 8-211: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 8-212: Loss: 0.2025 Acc: 25.0000%\n",
      "\ttrain 8-213: Loss: 0.1909 Acc: 50.0000%\n",
      "\ttrain 8-214: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 8-215: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 8-216: Loss: 0.1290 Acc: 100.0000%\n",
      "\ttrain 8-217: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 8-218: Loss: 0.1444 Acc: 100.0000%\n",
      "\ttrain 8-219: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 8-220: Loss: 0.1111 Acc: 50.0000%\n",
      "\ttrain 8-221: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 8-222: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 8-223: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 8-224: Loss: 0.1010 Acc: 50.0000%\n",
      "\ttrain 8-225: Loss: 0.0473 Acc: 75.0000%\n",
      "\ttrain 8-226: Loss: 0.1164 Acc: 100.0000%\n",
      "\ttrain 8-227: Loss: 0.2025 Acc: 50.0000%\n",
      "\ttrain 8-228: Loss: 0.1852 Acc: 50.0000%\n",
      "\ttrain 8-229: Loss: 0.1450 Acc: 75.0000%\n",
      "\ttrain 8-230: Loss: 0.1469 Acc: 50.0000%\n",
      "\ttrain 8-231: Loss: 0.1793 Acc: 50.0000%\n",
      "\ttrain 8-232: Loss: 0.2211 Acc: 50.0000%\n",
      "\ttrain 8-233: Loss: 0.1892 Acc: 50.0000%\n",
      "\ttrain 8-234: Loss: 0.1048 Acc: 100.0000%\n",
      "\ttrain 8-235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 8-236: Loss: 0.2006 Acc: 25.0000%\n",
      "\ttrain 8-237: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 8-238: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 8-239: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 8-240: Loss: 0.1766 Acc: 75.0000%\n",
      "\ttrain 8-241: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 8-242: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 8-243: Loss: 0.1832 Acc: 25.0000%\n",
      "\ttrain 8-244: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 8-245: Loss: 0.0854 Acc: 100.0000%\n",
      "\tvalidation 8-1: Loss: 0.0796 Acc: 100.0000%\n",
      "\tvalidation 8-2: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 8-3: Loss: 0.0465 Acc: 75.0000%\n",
      "\tvalidation 8-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 8-5: Loss: 0.0949 Acc: 50.0000%\n",
      "\tvalidation 8-6: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 8-7: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 8-8: Loss: 0.1289 Acc: 50.0000%\n",
      "\tvalidation 8-9: Loss: 0.0803 Acc: 100.0000%\n",
      "\tvalidation 8-10: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 8-11: Loss: 0.1414 Acc: 25.0000%\n",
      "\tvalidation 8-12: Loss: 0.1810 Acc: 25.0000%\n",
      "\tvalidation 8-13: Loss: 0.1262 Acc: 75.0000%\n",
      "\tvalidation 8-14: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 8-15: Loss: 0.0490 Acc: 75.0000%\n",
      "\tvalidation 8-16: Loss: 0.0828 Acc: 100.0000%\n",
      "\tvalidation 8-17: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 8-18: Loss: 0.1774 Acc: 50.0000%\n",
      "\tvalidation 8-19: Loss: 0.1332 Acc: 50.0000%\n",
      "\tvalidation 8-20: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 8-21: Loss: 0.0912 Acc: 50.0000%\n",
      "\tvalidation 8-22: Loss: 0.0845 Acc: 75.0000%\n",
      "\tvalidation 8-23: Loss: 0.0954 Acc: 50.0000%\n",
      "\tvalidation 8-24: Loss: 0.1381 Acc: 25.0000%\n",
      "\tvalidation 8-25: Loss: 0.0920 Acc: 50.0000%\n",
      "\tvalidation 8-26: Loss: 0.1326 Acc: 50.0000%\n",
      "\tvalidation 8-27: Loss: 0.0947 Acc: 50.0000%\n",
      "\tvalidation 8-28: Loss: 0.0431 Acc: 100.0000%\n",
      "\tvalidation 8-29: Loss: 0.0919 Acc: 50.0000%\n",
      "\tvalidation 8-30: Loss: 0.1838 Acc: 25.0000%\n",
      "\tvalidation 8-31: Loss: 0.0919 Acc: 50.0000%\n",
      "\tvalidation 8-32: Loss: 0.1305 Acc: 75.0000%\n",
      "\tvalidation 8-33: Loss: 0.0853 Acc: 75.0000%\n",
      "\tvalidation 8-34: Loss: 0.0889 Acc: 75.0000%\n",
      "\tvalidation 8-35: Loss: 0.1967 Acc: 75.0000%\n",
      "\tvalidation 8-36: Loss: 0.0889 Acc: 75.0000%\n",
      "\tvalidation 8-37: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 8-38: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 8-39: Loss: 0.0832 Acc: 100.0000%\n",
      "\tvalidation 8-40: Loss: 0.1308 Acc: 50.0000%\n",
      "\tvalidation 8-41: Loss: 0.0895 Acc: 75.0000%\n",
      "\tvalidation 8-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 8-43: Loss: 0.1311 Acc: 50.0000%\n",
      "\tvalidation 8-44: Loss: 0.1213 Acc: 100.0000%\n",
      "\tvalidation 8-45: Loss: 0.0953 Acc: 50.0000%\n",
      "\tvalidation 8-46: Loss: 0.1844 Acc: 50.0000%\n",
      "\tvalidation 8-47: Loss: 0.0926 Acc: 50.0000%\n",
      "\tvalidation 8-48: Loss: 0.0450 Acc: 75.0000%\n",
      "\tvalidation 8-49: Loss: 0.0403 Acc: 100.0000%\n",
      "\tvalidation 8-50: Loss: 0.0898 Acc: 75.0000%\n",
      "\tvalidation 8-51: Loss: 0.0476 Acc: 75.0000%\n",
      "\tvalidation 8-52: Loss: 0.0809 Acc: 100.0000%\n",
      "\tvalidation 8-53: Loss: 0.0947 Acc: 50.0000%\n",
      "\tvalidation 8-54: Loss: 0.0484 Acc: 75.0000%\n",
      "\tvalidation 8-55: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 8-56: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 8-57: Loss: 0.0471 Acc: 75.0000%\n",
      "\tvalidation 8-58: Loss: 0.0472 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 8-59: Loss: 0.0785 Acc: 100.0000%\n",
      "\tvalidation 8-60: Loss: 0.1172 Acc: 75.0000%\n",
      "\tvalidation 8-61: Loss: 0.0884 Acc: 75.0000%\n",
      "\tvalidation 8-62: Loss: 0.1279 Acc: 75.0000%\n",
      "\tvalidation 8-63: Loss: 0.0882 Acc: 100.0000%\n",
      "\tvalidation 8-64: Loss: 0.1314 Acc: 75.0000%\n",
      "\tvalidation 8-65: Loss: 0.0416 Acc: 100.0000%\n",
      "\tvalidation 8-66: Loss: 0.0451 Acc: 75.0000%\n",
      "\tvalidation 8-67: Loss: 0.0956 Acc: 50.0000%\n",
      "\tvalidation 8-68: Loss: 0.0824 Acc: 100.0000%\n",
      "\tvalidation 8-69: Loss: 0.0861 Acc: 75.0000%\n",
      "\tvalidation 8-70: Loss: 0.0809 Acc: 100.0000%\n",
      "\tvalidation 8-71: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 8-72: Loss: 0.0482 Acc: 75.0000%\n",
      "\tvalidation 8-73: Loss: 0.1374 Acc: 50.0000%\n",
      "\tvalidation 8-74: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 8-75: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 8-76: Loss: 0.1288 Acc: 75.0000%\n",
      "\tvalidation 8-77: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 8-78: Loss: 0.1738 Acc: 75.0000%\n",
      "\tvalidation 8-79: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 8-80: Loss: 0.1235 Acc: 100.0000%\n",
      "\tvalidation 8-81: Loss: 0.1319 Acc: 50.0000%\n",
      "\tvalidation 8-82: Loss: 0.0848 Acc: 75.0000%\n",
      "\tvalidation 8-83: Loss: 0.0838 Acc: 100.0000%\n",
      "\tvalidation 8-84: Loss: 0.1293 Acc: 75.0000%\n",
      "\tvalidation 8-85: Loss: 0.0982 Acc: 50.0000%\n",
      "\tvalidation 8-86: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 8-87: Loss: 0.1235 Acc: 75.0000%\n",
      "\tvalidation 8-88: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 8-89: Loss: 0.0449 Acc: 75.0000%\n",
      "\tvalidation 8-90: Loss: 0.1391 Acc: 25.0000%\n",
      "\tvalidation 8-91: Loss: 0.1717 Acc: 50.0000%\n",
      "\tvalidation 8-92: Loss: 0.1255 Acc: 75.0000%\n",
      "\tvalidation 8-93: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 8-94: Loss: 0.0904 Acc: 50.0000%\n",
      "\tvalidation 8-95: Loss: 0.0464 Acc: 75.0000%\n",
      "\tvalidation 8-96: Loss: 0.1231 Acc: 100.0000%\n",
      "\tvalidation 8-97: Loss: 0.0859 Acc: 100.0000%\n",
      "\tvalidation 8-98: Loss: 0.0419 Acc: 100.0000%\n",
      "\tvalidation 8-99: Loss: 0.0812 Acc: 100.0000%\n",
      "\tvalidation 8-100: Loss: 0.0936 Acc: 50.0000%\n",
      "\tvalidation 8-101: Loss: 0.0943 Acc: 50.0000%\n",
      "\tvalidation 8-102: Loss: 0.1696 Acc: 75.0000%\n",
      "\tvalidation 8-103: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 8-104: Loss: 0.1410 Acc: 25.0000%\n",
      "\tvalidation 8-105: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1553 Acc: 67.7551%\n",
      "\tvalidation Loss: 0.0893 Acc: 74.2857%\n",
      "Time passed 0h 6m 13s\n",
      "--------------------\n",
      "Epoch [9/40]:\n",
      "\ttrain 9-1: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 9-2: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 9-3: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 9-4: Loss: 0.1452 Acc: 25.0000%\n",
      "\ttrain 9-5: Loss: 0.0474 Acc: 75.0000%\n",
      "\ttrain 9-6: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 9-7: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 9-8: Loss: 0.5482 Acc: 50.0000%\n",
      "\ttrain 9-9: Loss: 0.2467 Acc: 75.0000%\n",
      "\ttrain 9-10: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 9-11: Loss: 0.4738 Acc: 75.0000%\n",
      "\ttrain 9-12: Loss: 0.2860 Acc: 50.0000%\n",
      "\ttrain 9-13: Loss: 0.2685 Acc: 50.0000%\n",
      "\ttrain 9-14: Loss: 0.5073 Acc: 25.0000%\n",
      "\ttrain 9-15: Loss: 0.4470 Acc: 25.0000%\n",
      "\ttrain 9-16: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 9-17: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 9-18: Loss: 0.2274 Acc: 50.0000%\n",
      "\ttrain 9-19: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 9-20: Loss: 0.1973 Acc: 75.0000%\n",
      "\ttrain 9-21: Loss: 0.2780 Acc: 50.0000%\n",
      "\ttrain 9-22: Loss: 0.2041 Acc: 50.0000%\n",
      "\ttrain 9-23: Loss: 0.2727 Acc: 25.0000%\n",
      "\ttrain 9-24: Loss: 0.1757 Acc: 75.0000%\n",
      "\ttrain 9-25: Loss: 0.2270 Acc: 25.0000%\n",
      "\ttrain 9-26: Loss: 0.2857 Acc: 50.0000%\n",
      "\ttrain 9-27: Loss: 0.0769 Acc: 100.0000%\n",
      "\ttrain 9-28: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 9-29: Loss: 0.2279 Acc: 25.0000%\n",
      "\ttrain 9-30: Loss: 0.1475 Acc: 25.0000%\n",
      "\ttrain 9-31: Loss: 0.2014 Acc: 50.0000%\n",
      "\ttrain 9-32: Loss: 0.2450 Acc: 25.0000%\n",
      "\ttrain 9-33: Loss: 0.2481 Acc: 50.0000%\n",
      "\ttrain 9-34: Loss: 0.2714 Acc: 50.0000%\n",
      "\ttrain 9-35: Loss: 0.1074 Acc: 100.0000%\n",
      "\ttrain 9-36: Loss: 0.1624 Acc: 50.0000%\n",
      "\ttrain 9-37: Loss: 0.2101 Acc: 25.0000%\n",
      "\ttrain 9-38: Loss: 0.3115 Acc: 25.0000%\n",
      "\ttrain 9-39: Loss: 0.1334 Acc: 100.0000%\n",
      "\ttrain 9-40: Loss: 0.1028 Acc: 100.0000%\n",
      "\ttrain 9-41: Loss: 0.1637 Acc: 50.0000%\n",
      "\ttrain 9-42: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 9-43: Loss: 0.2181 Acc: 25.0000%\n",
      "\ttrain 9-44: Loss: 0.1075 Acc: 50.0000%\n",
      "\ttrain 9-45: Loss: 0.2460 Acc: 50.0000%\n",
      "\ttrain 9-46: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 9-47: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 9-48: Loss: 0.0879 Acc: 100.0000%\n",
      "\ttrain 9-49: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 9-50: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 9-51: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 9-52: Loss: 0.1123 Acc: 100.0000%\n",
      "\ttrain 9-53: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 9-54: Loss: 0.1495 Acc: 50.0000%\n",
      "\ttrain 9-55: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 9-56: Loss: 0.0935 Acc: 100.0000%\n",
      "\ttrain 9-57: Loss: 0.1823 Acc: 25.0000%\n",
      "\ttrain 9-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 9-59: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 9-60: Loss: 0.1920 Acc: 75.0000%\n",
      "\ttrain 9-61: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 9-62: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 9-63: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 9-64: Loss: 0.4825 Acc: 25.0000%\n",
      "\ttrain 9-65: Loss: 0.3832 Acc: 75.0000%\n",
      "\ttrain 9-66: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 9-67: Loss: 0.1104 Acc: 50.0000%\n",
      "\ttrain 9-68: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 9-69: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 9-70: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 9-71: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 9-72: Loss: 0.4060 Acc: 50.0000%\n",
      "\ttrain 9-73: Loss: 0.3281 Acc: 0.0000%\n",
      "\ttrain 9-74: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 9-75: Loss: 0.0909 Acc: 100.0000%\n",
      "\ttrain 9-76: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 9-77: Loss: 0.1127 Acc: 50.0000%\n",
      "\ttrain 9-78: Loss: 0.2033 Acc: 50.0000%\n",
      "\ttrain 9-79: Loss: 0.1130 Acc: 50.0000%\n",
      "\ttrain 9-80: Loss: 0.3204 Acc: 25.0000%\n",
      "\ttrain 9-81: Loss: 0.1897 Acc: 50.0000%\n",
      "\ttrain 9-82: Loss: 0.2237 Acc: 50.0000%\n",
      "\ttrain 9-83: Loss: 0.0949 Acc: 100.0000%\n",
      "\ttrain 9-84: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 9-85: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 9-86: Loss: 0.2661 Acc: 50.0000%\n",
      "\ttrain 9-87: Loss: 0.1322 Acc: 50.0000%\n",
      "\ttrain 9-88: Loss: 0.1325 Acc: 100.0000%\n",
      "\ttrain 9-89: Loss: 0.1846 Acc: 50.0000%\n",
      "\ttrain 9-90: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 9-91: Loss: 0.1724 Acc: 50.0000%\n",
      "\ttrain 9-92: Loss: 0.0783 Acc: 100.0000%\n",
      "\ttrain 9-93: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 9-94: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 9-95: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 9-96: Loss: 0.1192 Acc: 50.0000%\n",
      "\ttrain 9-97: Loss: 0.1306 Acc: 75.0000%\n",
      "\ttrain 9-98: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 9-99: Loss: 0.1114 Acc: 50.0000%\n",
      "\ttrain 9-100: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 9-101: Loss: 0.1702 Acc: 75.0000%\n",
      "\ttrain 9-102: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 9-103: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 9-104: Loss: 0.1488 Acc: 50.0000%\n",
      "\ttrain 9-105: Loss: 0.1358 Acc: 75.0000%\n",
      "\ttrain 9-106: Loss: 0.1531 Acc: 50.0000%\n",
      "\ttrain 9-107: Loss: 0.1625 Acc: 75.0000%\n",
      "\ttrain 9-108: Loss: 0.1042 Acc: 100.0000%\n",
      "\ttrain 9-109: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 9-110: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 9-111: Loss: 0.1377 Acc: 50.0000%\n",
      "\ttrain 9-112: Loss: 0.1265 Acc: 50.0000%\n",
      "\ttrain 9-113: Loss: 0.1754 Acc: 75.0000%\n",
      "\ttrain 9-114: Loss: 0.1362 Acc: 50.0000%\n",
      "\ttrain 9-115: Loss: 0.1350 Acc: 50.0000%\n",
      "\ttrain 9-116: Loss: 0.0775 Acc: 100.0000%\n",
      "\ttrain 9-117: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 9-118: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 9-119: Loss: 0.1435 Acc: 50.0000%\n",
      "\ttrain 9-120: Loss: 0.0885 Acc: 100.0000%\n",
      "\ttrain 9-121: Loss: 0.1337 Acc: 100.0000%\n",
      "\ttrain 9-122: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 9-123: Loss: 0.2252 Acc: 50.0000%\n",
      "\ttrain 9-124: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 9-125: Loss: 0.1118 Acc: 50.0000%\n",
      "\ttrain 9-126: Loss: 0.1417 Acc: 50.0000%\n",
      "\ttrain 9-127: Loss: 0.0952 Acc: 100.0000%\n",
      "\ttrain 9-128: Loss: 0.1253 Acc: 100.0000%\n",
      "\ttrain 9-129: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 9-130: Loss: 0.2353 Acc: 25.0000%\n",
      "\ttrain 9-131: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 9-132: Loss: 0.2486 Acc: 50.0000%\n",
      "\ttrain 9-133: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 9-134: Loss: 0.2375 Acc: 50.0000%\n",
      "\ttrain 9-135: Loss: 0.3054 Acc: 50.0000%\n",
      "\ttrain 9-136: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 9-137: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 9-138: Loss: 0.1869 Acc: 25.0000%\n",
      "\ttrain 9-139: Loss: 0.1299 Acc: 50.0000%\n",
      "\ttrain 9-140: Loss: 0.1340 Acc: 100.0000%\n",
      "\ttrain 9-141: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 9-142: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 9-143: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 9-144: Loss: 0.1808 Acc: 25.0000%\n",
      "\ttrain 9-145: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 9-146: Loss: 0.1383 Acc: 75.0000%\n",
      "\ttrain 9-147: Loss: 0.1635 Acc: 50.0000%\n",
      "\ttrain 9-148: Loss: 0.0567 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 9-149: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 9-150: Loss: 0.1654 Acc: 50.0000%\n",
      "\ttrain 9-151: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 9-152: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 9-153: Loss: 0.1247 Acc: 50.0000%\n",
      "\ttrain 9-154: Loss: 0.0941 Acc: 100.0000%\n",
      "\ttrain 9-155: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 9-156: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 9-157: Loss: 0.2133 Acc: 50.0000%\n",
      "\ttrain 9-158: Loss: 0.2880 Acc: 0.0000%\n",
      "\ttrain 9-159: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 9-160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 9-161: Loss: 0.1238 Acc: 100.0000%\n",
      "\ttrain 9-162: Loss: 0.2260 Acc: 50.0000%\n",
      "\ttrain 9-163: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 9-164: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 9-165: Loss: 0.1073 Acc: 50.0000%\n",
      "\ttrain 9-166: Loss: 0.2704 Acc: 0.0000%\n",
      "\ttrain 9-167: Loss: 0.1205 Acc: 100.0000%\n",
      "\ttrain 9-168: Loss: 0.1780 Acc: 50.0000%\n",
      "\ttrain 9-169: Loss: 0.2162 Acc: 50.0000%\n",
      "\ttrain 9-170: Loss: 0.2490 Acc: 75.0000%\n",
      "\ttrain 9-171: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 9-172: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 9-173: Loss: 0.2646 Acc: 50.0000%\n",
      "\ttrain 9-174: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 9-175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 9-176: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 9-177: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 9-178: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 9-179: Loss: 0.1906 Acc: 50.0000%\n",
      "\ttrain 9-180: Loss: 0.0685 Acc: 100.0000%\n",
      "\ttrain 9-181: Loss: 0.1861 Acc: 25.0000%\n",
      "\ttrain 9-182: Loss: 0.0812 Acc: 100.0000%\n",
      "\ttrain 9-183: Loss: 0.2075 Acc: 50.0000%\n",
      "\ttrain 9-184: Loss: 0.3098 Acc: 25.0000%\n",
      "\ttrain 9-185: Loss: 0.1819 Acc: 75.0000%\n",
      "\ttrain 9-186: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 9-187: Loss: 0.1237 Acc: 50.0000%\n",
      "\ttrain 9-188: Loss: 0.2863 Acc: 25.0000%\n",
      "\ttrain 9-189: Loss: 0.2064 Acc: 25.0000%\n",
      "\ttrain 9-190: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 9-191: Loss: 0.1123 Acc: 100.0000%\n",
      "\ttrain 9-192: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 9-193: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 9-194: Loss: 0.1979 Acc: 25.0000%\n",
      "\ttrain 9-195: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 9-196: Loss: 0.1859 Acc: 50.0000%\n",
      "\ttrain 9-197: Loss: 0.1679 Acc: 25.0000%\n",
      "\ttrain 9-198: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 9-199: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 9-200: Loss: 0.1938 Acc: 50.0000%\n",
      "\ttrain 9-201: Loss: 0.0729 Acc: 100.0000%\n",
      "\ttrain 9-202: Loss: 0.3688 Acc: 75.0000%\n",
      "\ttrain 9-203: Loss: 0.0508 Acc: 75.0000%\n",
      "\ttrain 9-204: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 9-205: Loss: 0.1668 Acc: 50.0000%\n",
      "\ttrain 9-206: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 9-207: Loss: 0.1484 Acc: 50.0000%\n",
      "\ttrain 9-208: Loss: 0.0697 Acc: 100.0000%\n",
      "\ttrain 9-209: Loss: 0.0845 Acc: 100.0000%\n",
      "\ttrain 9-210: Loss: 0.1875 Acc: 25.0000%\n",
      "\ttrain 9-211: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 9-212: Loss: 0.1954 Acc: 75.0000%\n",
      "\ttrain 9-213: Loss: 0.0939 Acc: 75.0000%\n",
      "\ttrain 9-214: Loss: 0.0460 Acc: 75.0000%\n",
      "\ttrain 9-215: Loss: 0.1114 Acc: 100.0000%\n",
      "\ttrain 9-216: Loss: 0.1568 Acc: 50.0000%\n",
      "\ttrain 9-217: Loss: 0.1233 Acc: 50.0000%\n",
      "\ttrain 9-218: Loss: 0.1300 Acc: 50.0000%\n",
      "\ttrain 9-219: Loss: 0.2550 Acc: 25.0000%\n",
      "\ttrain 9-220: Loss: 0.1300 Acc: 50.0000%\n",
      "\ttrain 9-221: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 9-222: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 9-223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 9-224: Loss: 0.2910 Acc: 75.0000%\n",
      "\ttrain 9-225: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 9-226: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 9-227: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 9-228: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 9-229: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 9-230: Loss: 0.1449 Acc: 50.0000%\n",
      "\ttrain 9-231: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 9-232: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 9-233: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 9-234: Loss: 0.2213 Acc: 25.0000%\n",
      "\ttrain 9-235: Loss: 0.0755 Acc: 100.0000%\n",
      "\ttrain 9-236: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 9-237: Loss: 0.1662 Acc: 50.0000%\n",
      "\ttrain 9-238: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 9-239: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 9-240: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 9-241: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 9-242: Loss: 0.1528 Acc: 50.0000%\n",
      "\ttrain 9-243: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 9-244: Loss: 0.1486 Acc: 50.0000%\n",
      "\ttrain 9-245: Loss: 0.0489 Acc: 100.0000%\n",
      "\tvalidation 9-1: Loss: 0.1361 Acc: 50.0000%\n",
      "\tvalidation 9-2: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 9-3: Loss: 0.1389 Acc: 50.0000%\n",
      "\tvalidation 9-4: Loss: 0.0381 Acc: 100.0000%\n",
      "\tvalidation 9-5: Loss: 0.2201 Acc: 50.0000%\n",
      "\tvalidation 9-6: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 9-7: Loss: 0.0786 Acc: 100.0000%\n",
      "\tvalidation 9-8: Loss: 0.0808 Acc: 100.0000%\n",
      "\tvalidation 9-9: Loss: 0.1938 Acc: 0.0000%\n",
      "\tvalidation 9-10: Loss: 0.1432 Acc: 50.0000%\n",
      "\tvalidation 9-11: Loss: 0.1305 Acc: 50.0000%\n",
      "\tvalidation 9-12: Loss: 0.0817 Acc: 100.0000%\n",
      "\tvalidation 9-13: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 9-14: Loss: 0.1316 Acc: 75.0000%\n",
      "\tvalidation 9-15: Loss: 0.0773 Acc: 100.0000%\n",
      "\tvalidation 9-16: Loss: 0.1303 Acc: 75.0000%\n",
      "\tvalidation 9-17: Loss: 0.1288 Acc: 100.0000%\n",
      "\tvalidation 9-18: Loss: 0.1451 Acc: 25.0000%\n",
      "\tvalidation 9-19: Loss: 0.0519 Acc: 75.0000%\n",
      "\tvalidation 9-20: Loss: 0.1273 Acc: 100.0000%\n",
      "\tvalidation 9-21: Loss: 0.0994 Acc: 50.0000%\n",
      "\tvalidation 9-22: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 9-23: Loss: 0.1314 Acc: 50.0000%\n",
      "\tvalidation 9-24: Loss: 0.0463 Acc: 75.0000%\n",
      "\tvalidation 9-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 9-26: Loss: 0.0998 Acc: 50.0000%\n",
      "\tvalidation 9-27: Loss: 0.0813 Acc: 75.0000%\n",
      "\tvalidation 9-28: Loss: 0.0498 Acc: 75.0000%\n",
      "\tvalidation 9-29: Loss: 0.0474 Acc: 75.0000%\n",
      "\tvalidation 9-30: Loss: 0.0499 Acc: 75.0000%\n",
      "\tvalidation 9-31: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 9-32: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 9-33: Loss: 0.0393 Acc: 100.0000%\n",
      "\tvalidation 9-34: Loss: 0.0464 Acc: 100.0000%\n",
      "\tvalidation 9-35: Loss: 0.0458 Acc: 75.0000%\n",
      "\tvalidation 9-36: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 9-37: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 9-38: Loss: 0.1415 Acc: 50.0000%\n",
      "\tvalidation 9-39: Loss: 0.0858 Acc: 75.0000%\n",
      "\tvalidation 9-40: Loss: 0.1297 Acc: 100.0000%\n",
      "\tvalidation 9-41: Loss: 0.0504 Acc: 75.0000%\n",
      "\tvalidation 9-42: Loss: 0.1411 Acc: 50.0000%\n",
      "\tvalidation 9-43: Loss: 0.0710 Acc: 75.0000%\n",
      "\tvalidation 9-44: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 9-45: Loss: 0.1324 Acc: 50.0000%\n",
      "\tvalidation 9-46: Loss: 0.0985 Acc: 50.0000%\n",
      "\tvalidation 9-47: Loss: 0.0912 Acc: 75.0000%\n",
      "\tvalidation 9-48: Loss: 0.1360 Acc: 50.0000%\n",
      "\tvalidation 9-49: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 9-50: Loss: 0.1384 Acc: 50.0000%\n",
      "\tvalidation 9-51: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 9-52: Loss: 0.0482 Acc: 75.0000%\n",
      "\tvalidation 9-53: Loss: 0.0966 Acc: 50.0000%\n",
      "\tvalidation 9-54: Loss: 0.0852 Acc: 100.0000%\n",
      "\tvalidation 9-55: Loss: 0.0844 Acc: 75.0000%\n",
      "\tvalidation 9-56: Loss: 0.0381 Acc: 100.0000%\n",
      "\tvalidation 9-57: Loss: 0.0544 Acc: 75.0000%\n",
      "\tvalidation 9-58: Loss: 0.1210 Acc: 100.0000%\n",
      "\tvalidation 9-59: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 9-60: Loss: 0.1202 Acc: 75.0000%\n",
      "\tvalidation 9-61: Loss: 0.1468 Acc: 25.0000%\n",
      "\tvalidation 9-62: Loss: 0.0609 Acc: 100.0000%\n",
      "\tvalidation 9-63: Loss: 0.0843 Acc: 75.0000%\n",
      "\tvalidation 9-64: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 9-65: Loss: 0.1207 Acc: 100.0000%\n",
      "\tvalidation 9-66: Loss: 0.0497 Acc: 75.0000%\n",
      "\tvalidation 9-67: Loss: 0.1366 Acc: 50.0000%\n",
      "\tvalidation 9-68: Loss: 0.0781 Acc: 100.0000%\n",
      "\tvalidation 9-69: Loss: 0.1240 Acc: 75.0000%\n",
      "\tvalidation 9-70: Loss: 0.0994 Acc: 75.0000%\n",
      "\tvalidation 9-71: Loss: 0.0939 Acc: 75.0000%\n",
      "\tvalidation 9-72: Loss: 0.0905 Acc: 75.0000%\n",
      "\tvalidation 9-73: Loss: 0.0836 Acc: 75.0000%\n",
      "\tvalidation 9-74: Loss: 0.1249 Acc: 100.0000%\n",
      "\tvalidation 9-75: Loss: 0.1308 Acc: 75.0000%\n",
      "\tvalidation 9-76: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 9-77: Loss: 0.0538 Acc: 75.0000%\n",
      "\tvalidation 9-78: Loss: 0.1412 Acc: 50.0000%\n",
      "\tvalidation 9-79: Loss: 0.0798 Acc: 100.0000%\n",
      "\tvalidation 9-80: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 9-81: Loss: 0.1318 Acc: 75.0000%\n",
      "\tvalidation 9-82: Loss: 0.1387 Acc: 25.0000%\n",
      "\tvalidation 9-83: Loss: 0.0901 Acc: 75.0000%\n",
      "\tvalidation 9-84: Loss: 0.0958 Acc: 50.0000%\n",
      "\tvalidation 9-85: Loss: 0.0843 Acc: 100.0000%\n",
      "\tvalidation 9-86: Loss: 0.0883 Acc: 75.0000%\n",
      "\tvalidation 9-87: Loss: 0.1206 Acc: 100.0000%\n",
      "\tvalidation 9-88: Loss: 0.1407 Acc: 50.0000%\n",
      "\tvalidation 9-89: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 9-90: Loss: 0.0982 Acc: 50.0000%\n",
      "\tvalidation 9-91: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 9-92: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 9-93: Loss: 0.0401 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 9-94: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 9-95: Loss: 0.1364 Acc: 50.0000%\n",
      "\tvalidation 9-96: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 9-97: Loss: 0.0522 Acc: 75.0000%\n",
      "\tvalidation 9-98: Loss: 0.1297 Acc: 75.0000%\n",
      "\tvalidation 9-99: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 9-100: Loss: 0.0783 Acc: 100.0000%\n",
      "\tvalidation 9-101: Loss: 0.1492 Acc: 25.0000%\n",
      "\tvalidation 9-102: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 9-103: Loss: 0.0815 Acc: 100.0000%\n",
      "\tvalidation 9-104: Loss: 0.0948 Acc: 50.0000%\n",
      "\tvalidation 9-105: Loss: 0.1006 Acc: 50.0000%\n",
      "\ttrain Loss: 0.1441 Acc: 68.5714%\n",
      "\tvalidation Loss: 0.0906 Acc: 75.9524%\n",
      "网络参数更新\n",
      "Time passed 0h 7m 3s\n",
      "--------------------\n",
      "Epoch [10/40]:\n",
      "\ttrain 10-1: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 10-2: Loss: 0.1368 Acc: 50.0000%\n",
      "\ttrain 10-3: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 10-4: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 10-5: Loss: 0.2126 Acc: 50.0000%\n",
      "\ttrain 10-6: Loss: 0.0840 Acc: 100.0000%\n",
      "\ttrain 10-7: Loss: 0.2322 Acc: 75.0000%\n",
      "\ttrain 10-8: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 10-9: Loss: 0.2279 Acc: 50.0000%\n",
      "\ttrain 10-10: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 10-11: Loss: 0.2094 Acc: 25.0000%\n",
      "\ttrain 10-12: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 10-13: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 10-14: Loss: 0.0814 Acc: 100.0000%\n",
      "\ttrain 10-15: Loss: 0.1529 Acc: 50.0000%\n",
      "\ttrain 10-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-17: Loss: 0.1088 Acc: 50.0000%\n",
      "\ttrain 10-18: Loss: 0.1452 Acc: 50.0000%\n",
      "\ttrain 10-19: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 10-20: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 10-21: Loss: 0.0992 Acc: 50.0000%\n",
      "\ttrain 10-22: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 10-23: Loss: 0.1845 Acc: 25.0000%\n",
      "\ttrain 10-24: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 10-25: Loss: 0.1866 Acc: 50.0000%\n",
      "\ttrain 10-26: Loss: 0.1849 Acc: 50.0000%\n",
      "\ttrain 10-27: Loss: 0.1143 Acc: 50.0000%\n",
      "\ttrain 10-28: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 10-29: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 10-30: Loss: 0.1244 Acc: 100.0000%\n",
      "\ttrain 10-31: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 10-32: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 10-33: Loss: 0.1203 Acc: 100.0000%\n",
      "\ttrain 10-34: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 10-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 10-36: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 10-37: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 10-38: Loss: 0.1350 Acc: 50.0000%\n",
      "\ttrain 10-39: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 10-40: Loss: 0.1360 Acc: 50.0000%\n",
      "\ttrain 10-41: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 10-42: Loss: 0.0730 Acc: 100.0000%\n",
      "\ttrain 10-43: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 10-44: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 10-45: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 10-46: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 10-47: Loss: 0.0930 Acc: 50.0000%\n",
      "\ttrain 10-48: Loss: 0.2606 Acc: 75.0000%\n",
      "\ttrain 10-49: Loss: 0.0526 Acc: 75.0000%\n",
      "\ttrain 10-50: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 10-51: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 10-52: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 10-53: Loss: 0.0477 Acc: 75.0000%\n",
      "\ttrain 10-54: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 10-55: Loss: 0.1610 Acc: 50.0000%\n",
      "\ttrain 10-56: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 10-57: Loss: 0.2354 Acc: 50.0000%\n",
      "\ttrain 10-58: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 10-59: Loss: 0.3973 Acc: 25.0000%\n",
      "\ttrain 10-60: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 10-61: Loss: 0.1835 Acc: 50.0000%\n",
      "\ttrain 10-62: Loss: 0.0488 Acc: 75.0000%\n",
      "\ttrain 10-63: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 10-64: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 10-65: Loss: 0.1431 Acc: 50.0000%\n",
      "\ttrain 10-66: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 10-67: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 10-68: Loss: 0.1647 Acc: 25.0000%\n",
      "\ttrain 10-69: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 10-70: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 10-71: Loss: 0.1286 Acc: 50.0000%\n",
      "\ttrain 10-72: Loss: 0.3661 Acc: 25.0000%\n",
      "\ttrain 10-73: Loss: 0.1835 Acc: 25.0000%\n",
      "\ttrain 10-74: Loss: 0.1528 Acc: 50.0000%\n",
      "\ttrain 10-75: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 10-76: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 10-77: Loss: 0.0842 Acc: 100.0000%\n",
      "\ttrain 10-78: Loss: 0.0746 Acc: 100.0000%\n",
      "\ttrain 10-79: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 10-80: Loss: 0.1870 Acc: 75.0000%\n",
      "\ttrain 10-81: Loss: 0.1421 Acc: 50.0000%\n",
      "\ttrain 10-82: Loss: 0.1186 Acc: 100.0000%\n",
      "\ttrain 10-83: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 10-84: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 10-85: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 10-86: Loss: 0.2045 Acc: 50.0000%\n",
      "\ttrain 10-87: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 10-88: Loss: 0.1824 Acc: 75.0000%\n",
      "\ttrain 10-89: Loss: 0.2441 Acc: 50.0000%\n",
      "\ttrain 10-90: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 10-91: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 10-92: Loss: 0.0992 Acc: 100.0000%\n",
      "\ttrain 10-93: Loss: 0.2571 Acc: 25.0000%\n",
      "\ttrain 10-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 10-95: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 10-96: Loss: 0.1604 Acc: 50.0000%\n",
      "\ttrain 10-97: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 10-98: Loss: 0.1955 Acc: 75.0000%\n",
      "\ttrain 10-99: Loss: 0.2785 Acc: 50.0000%\n",
      "\ttrain 10-100: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 10-101: Loss: 0.1693 Acc: 50.0000%\n",
      "\ttrain 10-102: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 10-103: Loss: 0.2310 Acc: 25.0000%\n",
      "\ttrain 10-104: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 10-105: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 10-106: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 10-107: Loss: 0.0927 Acc: 50.0000%\n",
      "\ttrain 10-108: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 10-109: Loss: 0.0857 Acc: 100.0000%\n",
      "\ttrain 10-110: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 10-111: Loss: 0.1479 Acc: 50.0000%\n",
      "\ttrain 10-112: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 10-113: Loss: 0.1368 Acc: 50.0000%\n",
      "\ttrain 10-114: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 10-115: Loss: 0.1872 Acc: 25.0000%\n",
      "\ttrain 10-116: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 10-117: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 10-118: Loss: 0.0976 Acc: 50.0000%\n",
      "\ttrain 10-119: Loss: 0.2108 Acc: 25.0000%\n",
      "\ttrain 10-120: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 10-121: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 10-122: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 10-123: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 10-124: Loss: 0.1271 Acc: 50.0000%\n",
      "\ttrain 10-125: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 10-126: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 10-127: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 10-128: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 10-129: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 10-130: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 10-131: Loss: 0.0479 Acc: 75.0000%\n",
      "\ttrain 10-132: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 10-133: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 10-134: Loss: 0.1175 Acc: 50.0000%\n",
      "\ttrain 10-135: Loss: 0.1445 Acc: 50.0000%\n",
      "\ttrain 10-136: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 10-137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-138: Loss: 0.1583 Acc: 25.0000%\n",
      "\ttrain 10-139: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 10-140: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 10-141: Loss: 0.2302 Acc: 25.0000%\n",
      "\ttrain 10-142: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 10-143: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 10-144: Loss: 0.1783 Acc: 50.0000%\n",
      "\ttrain 10-145: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 10-146: Loss: 0.1436 Acc: 50.0000%\n",
      "\ttrain 10-147: Loss: 0.1835 Acc: 50.0000%\n",
      "\ttrain 10-148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-149: Loss: 0.1809 Acc: 50.0000%\n",
      "\ttrain 10-150: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 10-151: Loss: 0.0929 Acc: 100.0000%\n",
      "\ttrain 10-152: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 10-153: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 10-154: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 10-155: Loss: 0.1177 Acc: 50.0000%\n",
      "\ttrain 10-156: Loss: 0.1842 Acc: 75.0000%\n",
      "\ttrain 10-157: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 10-158: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 10-159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-160: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 10-161: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 10-162: Loss: 0.1658 Acc: 50.0000%\n",
      "\ttrain 10-163: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 10-164: Loss: 0.1700 Acc: 50.0000%\n",
      "\ttrain 10-165: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 10-166: Loss: 0.1300 Acc: 50.0000%\n",
      "\ttrain 10-167: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 10-168: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 10-169: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 10-170: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 10-171: Loss: 0.1080 Acc: 100.0000%\n",
      "\ttrain 10-172: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 10-173: Loss: 0.2009 Acc: 50.0000%\n",
      "\ttrain 10-174: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 10-175: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 10-176: Loss: 0.0785 Acc: 100.0000%\n",
      "\ttrain 10-177: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 10-178: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 10-179: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 10-180: Loss: 0.0851 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 10-181: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 10-182: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 10-183: Loss: 0.0534 Acc: 75.0000%\n",
      "\ttrain 10-184: Loss: 0.1514 Acc: 50.0000%\n",
      "\ttrain 10-185: Loss: 0.0773 Acc: 100.0000%\n",
      "\ttrain 10-186: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 10-187: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 10-188: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 10-189: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 10-190: Loss: 0.1167 Acc: 100.0000%\n",
      "\ttrain 10-191: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 10-192: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 10-193: Loss: 0.1485 Acc: 75.0000%\n",
      "\ttrain 10-194: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 10-195: Loss: 0.2031 Acc: 50.0000%\n",
      "\ttrain 10-196: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 10-197: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 10-198: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 10-199: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 10-200: Loss: 0.0519 Acc: 75.0000%\n",
      "\ttrain 10-201: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 10-202: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 10-203: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 10-204: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 10-205: Loss: 0.1746 Acc: 50.0000%\n",
      "\ttrain 10-206: Loss: 0.2422 Acc: 50.0000%\n",
      "\ttrain 10-207: Loss: 0.1601 Acc: 50.0000%\n",
      "\ttrain 10-208: Loss: 0.1157 Acc: 50.0000%\n",
      "\ttrain 10-209: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 10-210: Loss: 0.1858 Acc: 50.0000%\n",
      "\ttrain 10-211: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 10-212: Loss: 0.2741 Acc: 50.0000%\n",
      "\ttrain 10-213: Loss: 0.2485 Acc: 25.0000%\n",
      "\ttrain 10-214: Loss: 0.1608 Acc: 50.0000%\n",
      "\ttrain 10-215: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 10-216: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 10-217: Loss: 0.1943 Acc: 50.0000%\n",
      "\ttrain 10-218: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 10-219: Loss: 0.1628 Acc: 50.0000%\n",
      "\ttrain 10-220: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 10-221: Loss: 0.1101 Acc: 75.0000%\n",
      "\ttrain 10-222: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 10-223: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 10-224: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 10-225: Loss: 0.1254 Acc: 50.0000%\n",
      "\ttrain 10-226: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 10-227: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 10-228: Loss: 0.1973 Acc: 75.0000%\n",
      "\ttrain 10-229: Loss: 0.6923 Acc: 50.0000%\n",
      "\ttrain 10-230: Loss: 0.1705 Acc: 75.0000%\n",
      "\ttrain 10-231: Loss: 0.3304 Acc: 50.0000%\n",
      "\ttrain 10-232: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 10-233: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 10-234: Loss: 0.3454 Acc: 25.0000%\n",
      "\ttrain 10-235: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 10-236: Loss: 0.1973 Acc: 75.0000%\n",
      "\ttrain 10-237: Loss: 0.4143 Acc: 25.0000%\n",
      "\ttrain 10-238: Loss: 0.2497 Acc: 50.0000%\n",
      "\ttrain 10-239: Loss: 0.2322 Acc: 50.0000%\n",
      "\ttrain 10-240: Loss: 0.1791 Acc: 75.0000%\n",
      "\ttrain 10-241: Loss: 0.2544 Acc: 50.0000%\n",
      "\ttrain 10-242: Loss: 0.1606 Acc: 75.0000%\n",
      "\ttrain 10-243: Loss: 0.1980 Acc: 75.0000%\n",
      "\ttrain 10-244: Loss: 0.2460 Acc: 50.0000%\n",
      "\ttrain 10-245: Loss: 0.6828 Acc: 25.0000%\n",
      "\tvalidation 10-1: Loss: 0.3168 Acc: 75.0000%\n",
      "\tvalidation 10-2: Loss: 0.2300 Acc: 50.0000%\n",
      "\tvalidation 10-3: Loss: 0.3285 Acc: 0.0000%\n",
      "\tvalidation 10-4: Loss: 0.3509 Acc: 25.0000%\n",
      "\tvalidation 10-5: Loss: 0.2157 Acc: 75.0000%\n",
      "\tvalidation 10-6: Loss: 0.1438 Acc: 75.0000%\n",
      "\tvalidation 10-7: Loss: 0.2201 Acc: 75.0000%\n",
      "\tvalidation 10-8: Loss: 0.1445 Acc: 100.0000%\n",
      "\tvalidation 10-9: Loss: 0.0929 Acc: 100.0000%\n",
      "\tvalidation 10-10: Loss: 0.2712 Acc: 50.0000%\n",
      "\tvalidation 10-11: Loss: 0.2039 Acc: 100.0000%\n",
      "\tvalidation 10-12: Loss: 0.2774 Acc: 50.0000%\n",
      "\tvalidation 10-13: Loss: 0.1186 Acc: 100.0000%\n",
      "\tvalidation 10-14: Loss: 0.2366 Acc: 50.0000%\n",
      "\tvalidation 10-15: Loss: 0.2145 Acc: 75.0000%\n",
      "\tvalidation 10-16: Loss: 0.1266 Acc: 100.0000%\n",
      "\tvalidation 10-17: Loss: 0.1466 Acc: 75.0000%\n",
      "\tvalidation 10-18: Loss: 0.1738 Acc: 75.0000%\n",
      "\tvalidation 10-19: Loss: 0.2294 Acc: 75.0000%\n",
      "\tvalidation 10-20: Loss: 0.1678 Acc: 75.0000%\n",
      "\tvalidation 10-21: Loss: 0.1535 Acc: 75.0000%\n",
      "\tvalidation 10-22: Loss: 0.1629 Acc: 100.0000%\n",
      "\tvalidation 10-23: Loss: 0.2666 Acc: 50.0000%\n",
      "\tvalidation 10-24: Loss: 0.1993 Acc: 100.0000%\n",
      "\tvalidation 10-25: Loss: 0.2720 Acc: 25.0000%\n",
      "\tvalidation 10-26: Loss: 0.2533 Acc: 25.0000%\n",
      "\tvalidation 10-27: Loss: 0.1587 Acc: 100.0000%\n",
      "\tvalidation 10-28: Loss: 0.3475 Acc: 25.0000%\n",
      "\tvalidation 10-29: Loss: 0.1384 Acc: 75.0000%\n",
      "\tvalidation 10-30: Loss: 0.4014 Acc: 25.0000%\n",
      "\tvalidation 10-31: Loss: 0.2275 Acc: 50.0000%\n",
      "\tvalidation 10-32: Loss: 0.2417 Acc: 50.0000%\n",
      "\tvalidation 10-33: Loss: 0.1658 Acc: 75.0000%\n",
      "\tvalidation 10-34: Loss: 0.2204 Acc: 50.0000%\n",
      "\tvalidation 10-35: Loss: 0.2054 Acc: 75.0000%\n",
      "\tvalidation 10-36: Loss: 0.2905 Acc: 25.0000%\n",
      "\tvalidation 10-37: Loss: 0.2636 Acc: 75.0000%\n",
      "\tvalidation 10-38: Loss: 0.2395 Acc: 50.0000%\n",
      "\tvalidation 10-39: Loss: 0.2050 Acc: 50.0000%\n",
      "\tvalidation 10-40: Loss: 0.1822 Acc: 75.0000%\n",
      "\tvalidation 10-41: Loss: 0.1900 Acc: 100.0000%\n",
      "\tvalidation 10-42: Loss: 0.1249 Acc: 100.0000%\n",
      "\tvalidation 10-43: Loss: 0.2413 Acc: 75.0000%\n",
      "\tvalidation 10-44: Loss: 0.3807 Acc: 25.0000%\n",
      "\tvalidation 10-45: Loss: 0.1534 Acc: 100.0000%\n",
      "\tvalidation 10-46: Loss: 0.2530 Acc: 50.0000%\n",
      "\tvalidation 10-47: Loss: 0.2982 Acc: 75.0000%\n",
      "\tvalidation 10-48: Loss: 0.3491 Acc: 25.0000%\n",
      "\tvalidation 10-49: Loss: 0.2120 Acc: 75.0000%\n",
      "\tvalidation 10-50: Loss: 0.2263 Acc: 75.0000%\n",
      "\tvalidation 10-51: Loss: 0.1511 Acc: 75.0000%\n",
      "\tvalidation 10-52: Loss: 0.2093 Acc: 50.0000%\n",
      "\tvalidation 10-53: Loss: 0.1949 Acc: 25.0000%\n",
      "\tvalidation 10-54: Loss: 0.1170 Acc: 100.0000%\n",
      "\tvalidation 10-55: Loss: 0.3657 Acc: 50.0000%\n",
      "\tvalidation 10-56: Loss: 0.2446 Acc: 50.0000%\n",
      "\tvalidation 10-57: Loss: 0.1461 Acc: 100.0000%\n",
      "\tvalidation 10-58: Loss: 0.1822 Acc: 75.0000%\n",
      "\tvalidation 10-59: Loss: 0.2758 Acc: 50.0000%\n",
      "\tvalidation 10-60: Loss: 0.2195 Acc: 75.0000%\n",
      "\tvalidation 10-61: Loss: 0.3029 Acc: 50.0000%\n",
      "\tvalidation 10-62: Loss: 0.2199 Acc: 75.0000%\n",
      "\tvalidation 10-63: Loss: 0.1862 Acc: 75.0000%\n",
      "\tvalidation 10-64: Loss: 0.2778 Acc: 25.0000%\n",
      "\tvalidation 10-65: Loss: 0.2898 Acc: 25.0000%\n",
      "\tvalidation 10-66: Loss: 0.1687 Acc: 75.0000%\n",
      "\tvalidation 10-67: Loss: 0.2402 Acc: 50.0000%\n",
      "\tvalidation 10-68: Loss: 0.2008 Acc: 50.0000%\n",
      "\tvalidation 10-69: Loss: 0.1824 Acc: 75.0000%\n",
      "\tvalidation 10-70: Loss: 0.1964 Acc: 75.0000%\n",
      "\tvalidation 10-71: Loss: 0.1931 Acc: 75.0000%\n",
      "\tvalidation 10-72: Loss: 0.2062 Acc: 75.0000%\n",
      "\tvalidation 10-73: Loss: 0.2053 Acc: 75.0000%\n",
      "\tvalidation 10-74: Loss: 0.3197 Acc: 25.0000%\n",
      "\tvalidation 10-75: Loss: 0.2934 Acc: 25.0000%\n",
      "\tvalidation 10-76: Loss: 0.1766 Acc: 75.0000%\n",
      "\tvalidation 10-77: Loss: 0.2551 Acc: 50.0000%\n",
      "\tvalidation 10-78: Loss: 0.1732 Acc: 75.0000%\n",
      "\tvalidation 10-79: Loss: 0.2953 Acc: 50.0000%\n",
      "\tvalidation 10-80: Loss: 0.1509 Acc: 75.0000%\n",
      "\tvalidation 10-81: Loss: 0.1290 Acc: 100.0000%\n",
      "\tvalidation 10-82: Loss: 0.2288 Acc: 50.0000%\n",
      "\tvalidation 10-83: Loss: 0.2096 Acc: 75.0000%\n",
      "\tvalidation 10-84: Loss: 0.2013 Acc: 50.0000%\n",
      "\tvalidation 10-85: Loss: 0.1847 Acc: 75.0000%\n",
      "\tvalidation 10-86: Loss: 0.2001 Acc: 75.0000%\n",
      "\tvalidation 10-87: Loss: 0.1887 Acc: 75.0000%\n",
      "\tvalidation 10-88: Loss: 0.2478 Acc: 75.0000%\n",
      "\tvalidation 10-89: Loss: 0.2089 Acc: 50.0000%\n",
      "\tvalidation 10-90: Loss: 0.2985 Acc: 25.0000%\n",
      "\tvalidation 10-91: Loss: 0.2152 Acc: 75.0000%\n",
      "\tvalidation 10-92: Loss: 0.1851 Acc: 50.0000%\n",
      "\tvalidation 10-93: Loss: 0.2859 Acc: 25.0000%\n",
      "\tvalidation 10-94: Loss: 0.0832 Acc: 100.0000%\n",
      "\tvalidation 10-95: Loss: 0.5680 Acc: 0.0000%\n",
      "\tvalidation 10-96: Loss: 0.1386 Acc: 100.0000%\n",
      "\tvalidation 10-97: Loss: 0.2548 Acc: 50.0000%\n",
      "\tvalidation 10-98: Loss: 0.1611 Acc: 75.0000%\n",
      "\tvalidation 10-99: Loss: 0.1246 Acc: 100.0000%\n",
      "\tvalidation 10-100: Loss: 0.1100 Acc: 100.0000%\n",
      "\tvalidation 10-101: Loss: 0.3059 Acc: 25.0000%\n",
      "\tvalidation 10-102: Loss: 0.2249 Acc: 75.0000%\n",
      "\tvalidation 10-103: Loss: 0.2841 Acc: 25.0000%\n",
      "\tvalidation 10-104: Loss: 0.2747 Acc: 50.0000%\n",
      "\tvalidation 10-105: Loss: 0.3126 Acc: 25.0000%\n",
      "\ttrain Loss: 0.1247 Acc: 72.4490%\n",
      "\tvalidation Loss: 0.2238 Acc: 63.0952%\n",
      "Time passed 0h 7m 47s\n",
      "--------------------\n",
      "Epoch [11/40]:\n",
      "\ttrain 11-1: Loss: 0.4241 Acc: 50.0000%\n",
      "\ttrain 11-2: Loss: 0.1396 Acc: 100.0000%\n",
      "\ttrain 11-3: Loss: 0.2384 Acc: 50.0000%\n",
      "\ttrain 11-4: Loss: 0.3815 Acc: 0.0000%\n",
      "\ttrain 11-5: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 11-6: Loss: 0.2618 Acc: 25.0000%\n",
      "\ttrain 11-7: Loss: 0.4125 Acc: 0.0000%\n",
      "\ttrain 11-8: Loss: 0.3355 Acc: 25.0000%\n",
      "\ttrain 11-9: Loss: 0.2244 Acc: 25.0000%\n",
      "\ttrain 11-10: Loss: 0.2493 Acc: 0.0000%\n",
      "\ttrain 11-11: Loss: 0.2775 Acc: 50.0000%\n",
      "\ttrain 11-12: Loss: 0.2318 Acc: 75.0000%\n",
      "\ttrain 11-13: Loss: 0.2701 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-14: Loss: 0.2421 Acc: 25.0000%\n",
      "\ttrain 11-15: Loss: 0.2274 Acc: 25.0000%\n",
      "\ttrain 11-16: Loss: 0.1683 Acc: 75.0000%\n",
      "\ttrain 11-17: Loss: 0.2979 Acc: 25.0000%\n",
      "\ttrain 11-18: Loss: 0.1831 Acc: 50.0000%\n",
      "\ttrain 11-19: Loss: 0.2200 Acc: 75.0000%\n",
      "\ttrain 11-20: Loss: 0.1601 Acc: 75.0000%\n",
      "\ttrain 11-21: Loss: 0.1918 Acc: 50.0000%\n",
      "\ttrain 11-22: Loss: 0.1741 Acc: 50.0000%\n",
      "\ttrain 11-23: Loss: 0.2224 Acc: 50.0000%\n",
      "\ttrain 11-24: Loss: 0.1368 Acc: 50.0000%\n",
      "\ttrain 11-25: Loss: 0.2328 Acc: 50.0000%\n",
      "\ttrain 11-26: Loss: 0.1882 Acc: 50.0000%\n",
      "\ttrain 11-27: Loss: 0.3099 Acc: 25.0000%\n",
      "\ttrain 11-28: Loss: 0.0974 Acc: 100.0000%\n",
      "\ttrain 11-29: Loss: 0.2307 Acc: 75.0000%\n",
      "\ttrain 11-30: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 11-31: Loss: 0.1332 Acc: 75.0000%\n",
      "\ttrain 11-32: Loss: 0.3648 Acc: 0.0000%\n",
      "\ttrain 11-33: Loss: 0.1569 Acc: 50.0000%\n",
      "\ttrain 11-34: Loss: 0.2378 Acc: 25.0000%\n",
      "\ttrain 11-35: Loss: 0.0725 Acc: 75.0000%\n",
      "\ttrain 11-36: Loss: 0.1427 Acc: 50.0000%\n",
      "\ttrain 11-37: Loss: 0.1512 Acc: 75.0000%\n",
      "\ttrain 11-38: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 11-39: Loss: 0.2196 Acc: 0.0000%\n",
      "\ttrain 11-40: Loss: 0.1441 Acc: 50.0000%\n",
      "\ttrain 11-41: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 11-42: Loss: 0.1614 Acc: 50.0000%\n",
      "\ttrain 11-43: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 11-44: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 11-45: Loss: 0.1410 Acc: 50.0000%\n",
      "\ttrain 11-46: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 11-47: Loss: 0.1815 Acc: 50.0000%\n",
      "\ttrain 11-48: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 11-49: Loss: 0.2595 Acc: 50.0000%\n",
      "\ttrain 11-50: Loss: 0.1348 Acc: 50.0000%\n",
      "\ttrain 11-51: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 11-52: Loss: 0.1547 Acc: 50.0000%\n",
      "\ttrain 11-53: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 11-54: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 11-55: Loss: 0.1028 Acc: 50.0000%\n",
      "\ttrain 11-56: Loss: 0.2499 Acc: 25.0000%\n",
      "\ttrain 11-57: Loss: 0.1851 Acc: 25.0000%\n",
      "\ttrain 11-58: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 11-59: Loss: 0.0764 Acc: 100.0000%\n",
      "\ttrain 11-60: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 11-61: Loss: 0.1190 Acc: 50.0000%\n",
      "\ttrain 11-62: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 11-63: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 11-64: Loss: 0.0933 Acc: 100.0000%\n",
      "\ttrain 11-65: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 11-66: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 11-67: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 11-68: Loss: 0.1582 Acc: 50.0000%\n",
      "\ttrain 11-69: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 11-70: Loss: 0.6370 Acc: 50.0000%\n",
      "\ttrain 11-71: Loss: 0.1121 Acc: 100.0000%\n",
      "\ttrain 11-72: Loss: 0.3400 Acc: 50.0000%\n",
      "\ttrain 11-73: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 11-74: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 11-75: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 11-76: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 11-77: Loss: 0.1884 Acc: 75.0000%\n",
      "\ttrain 11-78: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 11-79: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 11-80: Loss: 0.5474 Acc: 0.0000%\n",
      "\ttrain 11-81: Loss: 0.2392 Acc: 50.0000%\n",
      "\ttrain 11-82: Loss: 0.1772 Acc: 25.0000%\n",
      "\ttrain 11-83: Loss: 0.1304 Acc: 50.0000%\n",
      "\ttrain 11-84: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 11-85: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 11-86: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 11-87: Loss: 0.1763 Acc: 50.0000%\n",
      "\ttrain 11-88: Loss: 0.1583 Acc: 75.0000%\n",
      "\ttrain 11-89: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 11-90: Loss: 0.1278 Acc: 100.0000%\n",
      "\ttrain 11-91: Loss: 0.2289 Acc: 50.0000%\n",
      "\ttrain 11-92: Loss: 0.2819 Acc: 75.0000%\n",
      "\ttrain 11-93: Loss: 0.1698 Acc: 25.0000%\n",
      "\ttrain 11-94: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 11-95: Loss: 0.1850 Acc: 75.0000%\n",
      "\ttrain 11-96: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 11-97: Loss: 0.2316 Acc: 75.0000%\n",
      "\ttrain 11-98: Loss: 0.2272 Acc: 50.0000%\n",
      "\ttrain 11-99: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 11-100: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 11-101: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 11-102: Loss: 0.1123 Acc: 50.0000%\n",
      "\ttrain 11-103: Loss: 0.1482 Acc: 50.0000%\n",
      "\ttrain 11-104: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 11-105: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 11-106: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 11-107: Loss: 0.1888 Acc: 50.0000%\n",
      "\ttrain 11-108: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 11-109: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 11-110: Loss: 0.1743 Acc: 75.0000%\n",
      "\ttrain 11-111: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 11-112: Loss: 0.2390 Acc: 50.0000%\n",
      "\ttrain 11-113: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 11-114: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 11-115: Loss: 0.1105 Acc: 50.0000%\n",
      "\ttrain 11-116: Loss: 0.0503 Acc: 75.0000%\n",
      "\ttrain 11-117: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 11-118: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 11-119: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 11-120: Loss: 0.1072 Acc: 100.0000%\n",
      "\ttrain 11-121: Loss: 0.0939 Acc: 75.0000%\n",
      "\ttrain 11-122: Loss: 0.1838 Acc: 50.0000%\n",
      "\ttrain 11-123: Loss: 0.0793 Acc: 100.0000%\n",
      "\ttrain 11-124: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 11-125: Loss: 0.1707 Acc: 100.0000%\n",
      "\ttrain 11-126: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 11-127: Loss: 0.0491 Acc: 75.0000%\n",
      "\ttrain 11-128: Loss: 0.3519 Acc: 50.0000%\n",
      "\ttrain 11-129: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 11-130: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 11-131: Loss: 0.0751 Acc: 100.0000%\n",
      "\ttrain 11-132: Loss: 0.2956 Acc: 25.0000%\n",
      "\ttrain 11-133: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 11-134: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 11-135: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 11-136: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 11-137: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 11-138: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 11-139: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 11-140: Loss: 0.1226 Acc: 50.0000%\n",
      "\ttrain 11-141: Loss: 0.1350 Acc: 50.0000%\n",
      "\ttrain 11-142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 11-143: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 11-144: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 11-145: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 11-146: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 11-147: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 11-148: Loss: 0.2167 Acc: 75.0000%\n",
      "\ttrain 11-149: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 11-150: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 11-151: Loss: 0.1051 Acc: 50.0000%\n",
      "\ttrain 11-152: Loss: 0.1608 Acc: 100.0000%\n",
      "\ttrain 11-153: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 11-154: Loss: 0.1318 Acc: 50.0000%\n",
      "\ttrain 11-155: Loss: 0.1711 Acc: 50.0000%\n",
      "\ttrain 11-156: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 11-157: Loss: 0.1470 Acc: 50.0000%\n",
      "\ttrain 11-158: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 11-159: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 11-160: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 11-161: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 11-162: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 11-163: Loss: 0.0907 Acc: 100.0000%\n",
      "\ttrain 11-164: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 11-165: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 11-166: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 11-167: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 11-168: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 11-169: Loss: 0.3211 Acc: 25.0000%\n",
      "\ttrain 11-170: Loss: 0.1262 Acc: 100.0000%\n",
      "\ttrain 11-171: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 11-172: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 11-173: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 11-174: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 11-175: Loss: 0.1924 Acc: 50.0000%\n",
      "\ttrain 11-176: Loss: 0.0506 Acc: 75.0000%\n",
      "\ttrain 11-177: Loss: 0.0495 Acc: 75.0000%\n",
      "\ttrain 11-178: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 11-179: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 11-180: Loss: 0.1355 Acc: 50.0000%\n",
      "\ttrain 11-181: Loss: 0.2309 Acc: 0.0000%\n",
      "\ttrain 11-182: Loss: 0.0730 Acc: 100.0000%\n",
      "\ttrain 11-183: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 11-184: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 11-185: Loss: 0.2147 Acc: 25.0000%\n",
      "\ttrain 11-186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 11-187: Loss: 0.1411 Acc: 50.0000%\n",
      "\ttrain 11-188: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 11-189: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 11-190: Loss: 0.1436 Acc: 50.0000%\n",
      "\ttrain 11-191: Loss: 0.1088 Acc: 50.0000%\n",
      "\ttrain 11-192: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 11-193: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 11-194: Loss: 0.2545 Acc: 50.0000%\n",
      "\ttrain 11-195: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 11-196: Loss: 0.1390 Acc: 50.0000%\n",
      "\ttrain 11-197: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 11-198: Loss: 0.2204 Acc: 75.0000%\n",
      "\ttrain 11-199: Loss: 0.0519 Acc: 75.0000%\n",
      "\ttrain 11-200: Loss: 0.0938 Acc: 50.0000%\n",
      "\ttrain 11-201: Loss: 0.2918 Acc: 50.0000%\n",
      "\ttrain 11-202: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 11-203: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 11-204: Loss: 0.0970 Acc: 50.0000%\n",
      "\ttrain 11-205: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 11-206: Loss: 0.1545 Acc: 50.0000%\n",
      "\ttrain 11-207: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 11-208: Loss: 0.1741 Acc: 50.0000%\n",
      "\ttrain 11-209: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 11-210: Loss: 0.1362 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-211: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 11-212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 11-213: Loss: 0.0467 Acc: 75.0000%\n",
      "\ttrain 11-214: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 11-215: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 11-216: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 11-217: Loss: 0.1589 Acc: 50.0000%\n",
      "\ttrain 11-218: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 11-219: Loss: 0.2332 Acc: 25.0000%\n",
      "\ttrain 11-220: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 11-221: Loss: 0.3791 Acc: 50.0000%\n",
      "\ttrain 11-222: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 11-223: Loss: 0.1970 Acc: 25.0000%\n",
      "\ttrain 11-224: Loss: 0.1298 Acc: 50.0000%\n",
      "\ttrain 11-225: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 11-226: Loss: 0.1459 Acc: 75.0000%\n",
      "\ttrain 11-227: Loss: 0.0512 Acc: 75.0000%\n",
      "\ttrain 11-228: Loss: 0.2120 Acc: 25.0000%\n",
      "\ttrain 11-229: Loss: 0.1254 Acc: 100.0000%\n",
      "\ttrain 11-230: Loss: 0.0603 Acc: 75.0000%\n",
      "\ttrain 11-231: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 11-232: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 11-233: Loss: 0.1142 Acc: 50.0000%\n",
      "\ttrain 11-234: Loss: 0.0944 Acc: 100.0000%\n",
      "\ttrain 11-235: Loss: 0.1740 Acc: 25.0000%\n",
      "\ttrain 11-236: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 11-237: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 11-238: Loss: 0.1600 Acc: 50.0000%\n",
      "\ttrain 11-239: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 11-240: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 11-241: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 11-242: Loss: 0.3326 Acc: 50.0000%\n",
      "\ttrain 11-243: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 11-244: Loss: 0.1553 Acc: 50.0000%\n",
      "\ttrain 11-245: Loss: 0.0559 Acc: 75.0000%\n",
      "\tvalidation 11-1: Loss: 0.1743 Acc: 75.0000%\n",
      "\tvalidation 11-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 11-3: Loss: 0.1055 Acc: 50.0000%\n",
      "\tvalidation 11-4: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 11-5: Loss: 0.1049 Acc: 100.0000%\n",
      "\tvalidation 11-6: Loss: 0.1147 Acc: 50.0000%\n",
      "\tvalidation 11-7: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 11-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 11-9: Loss: 0.1087 Acc: 50.0000%\n",
      "\tvalidation 11-10: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 11-11: Loss: 0.1059 Acc: 50.0000%\n",
      "\tvalidation 11-12: Loss: 0.0686 Acc: 100.0000%\n",
      "\tvalidation 11-13: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 11-14: Loss: 0.0574 Acc: 75.0000%\n",
      "\tvalidation 11-15: Loss: 0.0568 Acc: 75.0000%\n",
      "\tvalidation 11-16: Loss: 0.0519 Acc: 75.0000%\n",
      "\tvalidation 11-17: Loss: 0.1531 Acc: 50.0000%\n",
      "\tvalidation 11-18: Loss: 0.0973 Acc: 75.0000%\n",
      "\tvalidation 11-19: Loss: 0.1081 Acc: 50.0000%\n",
      "\tvalidation 11-20: Loss: 0.0522 Acc: 75.0000%\n",
      "\tvalidation 11-21: Loss: 0.1092 Acc: 50.0000%\n",
      "\tvalidation 11-22: Loss: 0.0539 Acc: 75.0000%\n",
      "\tvalidation 11-23: Loss: 0.1480 Acc: 50.0000%\n",
      "\tvalidation 11-24: Loss: 0.0705 Acc: 100.0000%\n",
      "\tvalidation 11-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 11-26: Loss: 0.0687 Acc: 100.0000%\n",
      "\tvalidation 11-27: Loss: 0.1912 Acc: 25.0000%\n",
      "\tvalidation 11-28: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 11-29: Loss: 0.1556 Acc: 50.0000%\n",
      "\tvalidation 11-30: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 11-31: Loss: 0.0571 Acc: 75.0000%\n",
      "\tvalidation 11-32: Loss: 0.1830 Acc: 25.0000%\n",
      "\tvalidation 11-33: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 11-34: Loss: 0.1885 Acc: 50.0000%\n",
      "\tvalidation 11-35: Loss: 0.0763 Acc: 100.0000%\n",
      "\tvalidation 11-36: Loss: 0.1176 Acc: 100.0000%\n",
      "\tvalidation 11-37: Loss: 0.1535 Acc: 50.0000%\n",
      "\tvalidation 11-38: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 11-39: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 11-40: Loss: 0.0772 Acc: 100.0000%\n",
      "\tvalidation 11-41: Loss: 0.1241 Acc: 75.0000%\n",
      "\tvalidation 11-42: Loss: 0.0704 Acc: 100.0000%\n",
      "\tvalidation 11-43: Loss: 0.0875 Acc: 75.0000%\n",
      "\tvalidation 11-44: Loss: 0.0495 Acc: 75.0000%\n",
      "\tvalidation 11-45: Loss: 0.4447 Acc: 75.0000%\n",
      "\tvalidation 11-46: Loss: 0.1226 Acc: 75.0000%\n",
      "\tvalidation 11-47: Loss: 0.0954 Acc: 75.0000%\n",
      "\tvalidation 11-48: Loss: 0.0718 Acc: 100.0000%\n",
      "\tvalidation 11-49: Loss: 0.1682 Acc: 75.0000%\n",
      "\tvalidation 11-50: Loss: 0.0839 Acc: 75.0000%\n",
      "\tvalidation 11-51: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 11-52: Loss: 0.2101 Acc: 25.0000%\n",
      "\tvalidation 11-53: Loss: 0.1490 Acc: 50.0000%\n",
      "\tvalidation 11-54: Loss: 0.0814 Acc: 100.0000%\n",
      "\tvalidation 11-55: Loss: 0.1739 Acc: 50.0000%\n",
      "\tvalidation 11-56: Loss: 0.0770 Acc: 100.0000%\n",
      "\tvalidation 11-57: Loss: 0.0762 Acc: 100.0000%\n",
      "\tvalidation 11-58: Loss: 0.0820 Acc: 75.0000%\n",
      "\tvalidation 11-59: Loss: 0.0552 Acc: 75.0000%\n",
      "\tvalidation 11-60: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 11-61: Loss: 0.1504 Acc: 50.0000%\n",
      "\tvalidation 11-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 11-63: Loss: 0.0534 Acc: 75.0000%\n",
      "\tvalidation 11-64: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 11-65: Loss: 0.1470 Acc: 50.0000%\n",
      "\tvalidation 11-66: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 11-67: Loss: 0.0577 Acc: 75.0000%\n",
      "\tvalidation 11-68: Loss: 0.0718 Acc: 100.0000%\n",
      "\tvalidation 11-69: Loss: 0.0552 Acc: 75.0000%\n",
      "\tvalidation 11-70: Loss: 0.0532 Acc: 75.0000%\n",
      "\tvalidation 11-71: Loss: 0.0886 Acc: 75.0000%\n",
      "\tvalidation 11-72: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 11-73: Loss: 0.0708 Acc: 100.0000%\n",
      "\tvalidation 11-74: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 11-75: Loss: 0.1151 Acc: 100.0000%\n",
      "\tvalidation 11-76: Loss: 0.1274 Acc: 75.0000%\n",
      "\tvalidation 11-77: Loss: 0.0792 Acc: 100.0000%\n",
      "\tvalidation 11-78: Loss: 0.1243 Acc: 75.0000%\n",
      "\tvalidation 11-79: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 11-80: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 11-81: Loss: 0.1793 Acc: 25.0000%\n",
      "\tvalidation 11-82: Loss: 0.1311 Acc: 75.0000%\n",
      "\tvalidation 11-83: Loss: 0.0558 Acc: 75.0000%\n",
      "\tvalidation 11-84: Loss: 0.0927 Acc: 75.0000%\n",
      "\tvalidation 11-85: Loss: 0.0931 Acc: 75.0000%\n",
      "\tvalidation 11-86: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 11-87: Loss: 0.0833 Acc: 75.0000%\n",
      "\tvalidation 11-88: Loss: 0.1992 Acc: 25.0000%\n",
      "\tvalidation 11-89: Loss: 0.1435 Acc: 50.0000%\n",
      "\tvalidation 11-90: Loss: 0.1147 Acc: 50.0000%\n",
      "\tvalidation 11-91: Loss: 0.1117 Acc: 50.0000%\n",
      "\tvalidation 11-92: Loss: 0.0742 Acc: 100.0000%\n",
      "\tvalidation 11-93: Loss: 0.1586 Acc: 50.0000%\n",
      "\tvalidation 11-94: Loss: 0.1566 Acc: 50.0000%\n",
      "\tvalidation 11-95: Loss: 0.1249 Acc: 50.0000%\n",
      "\tvalidation 11-96: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 11-97: Loss: 0.1086 Acc: 100.0000%\n",
      "\tvalidation 11-98: Loss: 0.0501 Acc: 75.0000%\n",
      "\tvalidation 11-99: Loss: 0.1011 Acc: 75.0000%\n",
      "\tvalidation 11-100: Loss: 0.0546 Acc: 75.0000%\n",
      "\tvalidation 11-101: Loss: 0.1313 Acc: 75.0000%\n",
      "\tvalidation 11-102: Loss: 0.1985 Acc: 25.0000%\n",
      "\tvalidation 11-103: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 11-104: Loss: 0.1024 Acc: 50.0000%\n",
      "\tvalidation 11-105: Loss: 0.3295 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1414 Acc: 67.4490%\n",
      "\tvalidation Loss: 0.0993 Acc: 74.7619%\n",
      "Time passed 0h 8m 32s\n",
      "--------------------\n",
      "Epoch [12/40]:\n",
      "\ttrain 12-1: Loss: 0.1736 Acc: 100.0000%\n",
      "\ttrain 12-2: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 12-3: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 12-4: Loss: 0.1141 Acc: 50.0000%\n",
      "\ttrain 12-5: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 12-6: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 12-7: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 12-8: Loss: 0.1043 Acc: 50.0000%\n",
      "\ttrain 12-9: Loss: 0.1494 Acc: 100.0000%\n",
      "\ttrain 12-10: Loss: 0.1565 Acc: 50.0000%\n",
      "\ttrain 12-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 12-12: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 12-13: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 12-14: Loss: 0.1285 Acc: 100.0000%\n",
      "\ttrain 12-15: Loss: 0.1053 Acc: 50.0000%\n",
      "\ttrain 12-16: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 12-17: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 12-18: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 12-19: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 12-20: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 12-21: Loss: 0.0814 Acc: 100.0000%\n",
      "\ttrain 12-22: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 12-23: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 12-24: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 12-25: Loss: 0.1245 Acc: 50.0000%\n",
      "\ttrain 12-26: Loss: 0.0629 Acc: 75.0000%\n",
      "\ttrain 12-27: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 12-28: Loss: 0.1691 Acc: 75.0000%\n",
      "\ttrain 12-29: Loss: 0.1598 Acc: 25.0000%\n",
      "\ttrain 12-30: Loss: 0.2715 Acc: 0.0000%\n",
      "\ttrain 12-31: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 12-32: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 12-33: Loss: 0.1783 Acc: 50.0000%\n",
      "\ttrain 12-34: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 12-35: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 12-36: Loss: 0.1517 Acc: 25.0000%\n",
      "\ttrain 12-37: Loss: 0.1100 Acc: 50.0000%\n",
      "\ttrain 12-38: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 12-39: Loss: 0.0503 Acc: 75.0000%\n",
      "\ttrain 12-40: Loss: 0.1779 Acc: 75.0000%\n",
      "\ttrain 12-41: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 12-42: Loss: 0.1480 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-43: Loss: 0.2608 Acc: 75.0000%\n",
      "\ttrain 12-44: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 12-45: Loss: 0.0903 Acc: 100.0000%\n",
      "\ttrain 12-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 12-47: Loss: 0.1485 Acc: 50.0000%\n",
      "\ttrain 12-48: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 12-49: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 12-50: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 12-51: Loss: 0.1789 Acc: 75.0000%\n",
      "\ttrain 12-52: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 12-53: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 12-54: Loss: 0.2161 Acc: 25.0000%\n",
      "\ttrain 12-55: Loss: 0.1101 Acc: 50.0000%\n",
      "\ttrain 12-56: Loss: 0.1692 Acc: 25.0000%\n",
      "\ttrain 12-57: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 12-58: Loss: 0.0848 Acc: 100.0000%\n",
      "\ttrain 12-59: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 12-60: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 12-61: Loss: 0.1088 Acc: 50.0000%\n",
      "\ttrain 12-62: Loss: 0.3787 Acc: 25.0000%\n",
      "\ttrain 12-63: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 12-64: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 12-65: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 12-66: Loss: 0.3965 Acc: 50.0000%\n",
      "\ttrain 12-67: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 12-68: Loss: 0.2158 Acc: 50.0000%\n",
      "\ttrain 12-69: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 12-70: Loss: 0.2917 Acc: 25.0000%\n",
      "\ttrain 12-71: Loss: 0.2273 Acc: 50.0000%\n",
      "\ttrain 12-72: Loss: 0.4103 Acc: 25.0000%\n",
      "\ttrain 12-73: Loss: 0.4937 Acc: 50.0000%\n",
      "\ttrain 12-74: Loss: 0.4334 Acc: 50.0000%\n",
      "\ttrain 12-75: Loss: 0.3769 Acc: 50.0000%\n",
      "\ttrain 12-76: Loss: 0.1046 Acc: 100.0000%\n",
      "\ttrain 12-77: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 12-78: Loss: 0.2271 Acc: 50.0000%\n",
      "\ttrain 12-79: Loss: 0.0839 Acc: 100.0000%\n",
      "\ttrain 12-80: Loss: 0.2698 Acc: 0.0000%\n",
      "\ttrain 12-81: Loss: 0.2493 Acc: 50.0000%\n",
      "\ttrain 12-82: Loss: 0.2520 Acc: 25.0000%\n",
      "\ttrain 12-83: Loss: 0.1129 Acc: 100.0000%\n",
      "\ttrain 12-84: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 12-85: Loss: 0.2280 Acc: 50.0000%\n",
      "\ttrain 12-86: Loss: 0.1364 Acc: 50.0000%\n",
      "\ttrain 12-87: Loss: 0.2202 Acc: 25.0000%\n",
      "\ttrain 12-88: Loss: 0.2707 Acc: 50.0000%\n",
      "\ttrain 12-89: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 12-90: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 12-91: Loss: 0.2624 Acc: 50.0000%\n",
      "\ttrain 12-92: Loss: 0.2048 Acc: 50.0000%\n",
      "\ttrain 12-93: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 12-94: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 12-95: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 12-96: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 12-97: Loss: 0.1400 Acc: 50.0000%\n",
      "\ttrain 12-98: Loss: 0.2103 Acc: 50.0000%\n",
      "\ttrain 12-99: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 12-100: Loss: 0.1849 Acc: 25.0000%\n",
      "\ttrain 12-101: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 12-102: Loss: 0.0992 Acc: 50.0000%\n",
      "\ttrain 12-103: Loss: 0.1019 Acc: 50.0000%\n",
      "\ttrain 12-104: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 12-105: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 12-106: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 12-107: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 12-108: Loss: 0.1383 Acc: 75.0000%\n",
      "\ttrain 12-109: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 12-110: Loss: 0.1971 Acc: 50.0000%\n",
      "\ttrain 12-111: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 12-112: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 12-113: Loss: 0.1890 Acc: 50.0000%\n",
      "\ttrain 12-114: Loss: 0.1065 Acc: 50.0000%\n",
      "\ttrain 12-115: Loss: 0.1081 Acc: 50.0000%\n",
      "\ttrain 12-116: Loss: 0.2140 Acc: 75.0000%\n",
      "\ttrain 12-117: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 12-118: Loss: 0.1391 Acc: 50.0000%\n",
      "\ttrain 12-119: Loss: 0.1603 Acc: 25.0000%\n",
      "\ttrain 12-120: Loss: 0.2591 Acc: 50.0000%\n",
      "\ttrain 12-121: Loss: 0.1025 Acc: 50.0000%\n",
      "\ttrain 12-122: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 12-123: Loss: 0.1549 Acc: 25.0000%\n",
      "\ttrain 12-124: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 12-125: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 12-126: Loss: 0.1376 Acc: 50.0000%\n",
      "\ttrain 12-127: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 12-128: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 12-129: Loss: 0.0716 Acc: 100.0000%\n",
      "\ttrain 12-130: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 12-131: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 12-132: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 12-133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 12-134: Loss: 0.1306 Acc: 100.0000%\n",
      "\ttrain 12-135: Loss: 0.0923 Acc: 100.0000%\n",
      "\ttrain 12-136: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 12-137: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 12-138: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 12-139: Loss: 0.2437 Acc: 75.0000%\n",
      "\ttrain 12-140: Loss: 0.1047 Acc: 50.0000%\n",
      "\ttrain 12-141: Loss: 0.1175 Acc: 50.0000%\n",
      "\ttrain 12-142: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 12-143: Loss: 0.1624 Acc: 100.0000%\n",
      "\ttrain 12-144: Loss: 0.0756 Acc: 100.0000%\n",
      "\ttrain 12-145: Loss: 0.1345 Acc: 100.0000%\n",
      "\ttrain 12-146: Loss: 0.1006 Acc: 100.0000%\n",
      "\ttrain 12-147: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 12-148: Loss: 0.1683 Acc: 50.0000%\n",
      "\ttrain 12-149: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 12-150: Loss: 0.2412 Acc: 25.0000%\n",
      "\ttrain 12-151: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 12-152: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 12-153: Loss: 0.1567 Acc: 50.0000%\n",
      "\ttrain 12-154: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 12-155: Loss: 0.3437 Acc: 50.0000%\n",
      "\ttrain 12-156: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 12-157: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 12-158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 12-159: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 12-160: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 12-161: Loss: 0.1480 Acc: 50.0000%\n",
      "\ttrain 12-162: Loss: 0.2315 Acc: 50.0000%\n",
      "\ttrain 12-163: Loss: 0.1620 Acc: 50.0000%\n",
      "\ttrain 12-164: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 12-165: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 12-166: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 12-167: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 12-168: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 12-169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 12-170: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 12-171: Loss: 0.2337 Acc: 75.0000%\n",
      "\ttrain 12-172: Loss: 0.2632 Acc: 75.0000%\n",
      "\ttrain 12-173: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 12-174: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 12-175: Loss: 0.2273 Acc: 50.0000%\n",
      "\ttrain 12-176: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 12-177: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 12-178: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 12-179: Loss: 0.1429 Acc: 100.0000%\n",
      "\ttrain 12-180: Loss: 0.1386 Acc: 75.0000%\n",
      "\ttrain 12-181: Loss: 0.1572 Acc: 50.0000%\n",
      "\ttrain 12-182: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 12-183: Loss: 0.1648 Acc: 50.0000%\n",
      "\ttrain 12-184: Loss: 0.1983 Acc: 50.0000%\n",
      "\ttrain 12-185: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 12-186: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 12-187: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 12-188: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 12-189: Loss: 0.2100 Acc: 50.0000%\n",
      "\ttrain 12-190: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 12-191: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 12-192: Loss: 0.2367 Acc: 25.0000%\n",
      "\ttrain 12-193: Loss: 0.1652 Acc: 50.0000%\n",
      "\ttrain 12-194: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 12-195: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 12-196: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 12-197: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 12-198: Loss: 0.0876 Acc: 100.0000%\n",
      "\ttrain 12-199: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 12-200: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 12-201: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 12-202: Loss: 0.0952 Acc: 50.0000%\n",
      "\ttrain 12-203: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 12-204: Loss: 0.1609 Acc: 100.0000%\n",
      "\ttrain 12-205: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 12-206: Loss: 0.2431 Acc: 50.0000%\n",
      "\ttrain 12-207: Loss: 0.3678 Acc: 50.0000%\n",
      "\ttrain 12-208: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 12-209: Loss: 0.0560 Acc: 75.0000%\n",
      "\ttrain 12-210: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 12-211: Loss: 0.1766 Acc: 50.0000%\n",
      "\ttrain 12-212: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 12-213: Loss: 0.1390 Acc: 50.0000%\n",
      "\ttrain 12-214: Loss: 0.1475 Acc: 50.0000%\n",
      "\ttrain 12-215: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 12-216: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 12-217: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 12-218: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 12-219: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 12-220: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 12-221: Loss: 0.1448 Acc: 100.0000%\n",
      "\ttrain 12-222: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 12-223: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 12-224: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 12-225: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 12-226: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 12-227: Loss: 0.2351 Acc: 75.0000%\n",
      "\ttrain 12-228: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 12-229: Loss: 0.1913 Acc: 25.0000%\n",
      "\ttrain 12-230: Loss: 0.1622 Acc: 50.0000%\n",
      "\ttrain 12-231: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 12-232: Loss: 0.1437 Acc: 50.0000%\n",
      "\ttrain 12-233: Loss: 0.1823 Acc: 50.0000%\n",
      "\ttrain 12-234: Loss: 0.3895 Acc: 75.0000%\n",
      "\ttrain 12-235: Loss: 0.1968 Acc: 75.0000%\n",
      "\ttrain 12-236: Loss: 0.0518 Acc: 75.0000%\n",
      "\ttrain 12-237: Loss: 0.2258 Acc: 0.0000%\n",
      "\ttrain 12-238: Loss: 0.1631 Acc: 75.0000%\n",
      "\ttrain 12-239: Loss: 0.3624 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-240: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 12-241: Loss: 0.1199 Acc: 50.0000%\n",
      "\ttrain 12-242: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 12-243: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 12-244: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 12-245: Loss: 0.1008 Acc: 100.0000%\n",
      "\tvalidation 12-1: Loss: 0.1360 Acc: 75.0000%\n",
      "\tvalidation 12-2: Loss: 0.1369 Acc: 75.0000%\n",
      "\tvalidation 12-3: Loss: 0.1028 Acc: 50.0000%\n",
      "\tvalidation 12-4: Loss: 0.1346 Acc: 50.0000%\n",
      "\tvalidation 12-5: Loss: 0.2617 Acc: 50.0000%\n",
      "\tvalidation 12-6: Loss: 0.0401 Acc: 100.0000%\n",
      "\tvalidation 12-7: Loss: 0.1315 Acc: 75.0000%\n",
      "\tvalidation 12-8: Loss: 0.1045 Acc: 50.0000%\n",
      "\tvalidation 12-9: Loss: 0.0526 Acc: 75.0000%\n",
      "\tvalidation 12-10: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 12-11: Loss: 0.1697 Acc: 75.0000%\n",
      "\tvalidation 12-12: Loss: 0.0459 Acc: 100.0000%\n",
      "\tvalidation 12-13: Loss: 0.1493 Acc: 50.0000%\n",
      "\tvalidation 12-14: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 12-15: Loss: 0.0809 Acc: 100.0000%\n",
      "\tvalidation 12-16: Loss: 0.1429 Acc: 50.0000%\n",
      "\tvalidation 12-17: Loss: 0.0557 Acc: 75.0000%\n",
      "\tvalidation 12-18: Loss: 0.0485 Acc: 100.0000%\n",
      "\tvalidation 12-19: Loss: 0.1003 Acc: 50.0000%\n",
      "\tvalidation 12-20: Loss: 0.1755 Acc: 25.0000%\n",
      "\tvalidation 12-21: Loss: 0.0764 Acc: 100.0000%\n",
      "\tvalidation 12-22: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 12-23: Loss: 0.1510 Acc: 50.0000%\n",
      "\tvalidation 12-24: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 12-25: Loss: 0.0849 Acc: 75.0000%\n",
      "\tvalidation 12-26: Loss: 0.0739 Acc: 100.0000%\n",
      "\tvalidation 12-27: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 12-28: Loss: 0.1368 Acc: 75.0000%\n",
      "\tvalidation 12-29: Loss: 0.0723 Acc: 100.0000%\n",
      "\tvalidation 12-30: Loss: 0.0559 Acc: 75.0000%\n",
      "\tvalidation 12-31: Loss: 0.1116 Acc: 50.0000%\n",
      "\tvalidation 12-32: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 12-33: Loss: 0.0632 Acc: 100.0000%\n",
      "\tvalidation 12-34: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 12-35: Loss: 0.1356 Acc: 75.0000%\n",
      "\tvalidation 12-36: Loss: 0.1013 Acc: 75.0000%\n",
      "\tvalidation 12-37: Loss: 0.1020 Acc: 75.0000%\n",
      "\tvalidation 12-38: Loss: 0.1021 Acc: 50.0000%\n",
      "\tvalidation 12-39: Loss: 0.0900 Acc: 75.0000%\n",
      "\tvalidation 12-40: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 12-41: Loss: 0.0940 Acc: 75.0000%\n",
      "\tvalidation 12-42: Loss: 0.0973 Acc: 75.0000%\n",
      "\tvalidation 12-43: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 12-44: Loss: 0.1067 Acc: 50.0000%\n",
      "\tvalidation 12-45: Loss: 0.2792 Acc: 50.0000%\n",
      "\tvalidation 12-46: Loss: 0.0512 Acc: 100.0000%\n",
      "\tvalidation 12-47: Loss: 0.0572 Acc: 75.0000%\n",
      "\tvalidation 12-48: Loss: 0.1163 Acc: 75.0000%\n",
      "\tvalidation 12-49: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 12-50: Loss: 0.0900 Acc: 75.0000%\n",
      "\tvalidation 12-51: Loss: 0.1705 Acc: 75.0000%\n",
      "\tvalidation 12-52: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 12-53: Loss: 0.0928 Acc: 75.0000%\n",
      "\tvalidation 12-54: Loss: 0.0432 Acc: 100.0000%\n",
      "\tvalidation 12-55: Loss: 0.1372 Acc: 75.0000%\n",
      "\tvalidation 12-56: Loss: 0.0909 Acc: 75.0000%\n",
      "\tvalidation 12-57: Loss: 0.0899 Acc: 75.0000%\n",
      "\tvalidation 12-58: Loss: 0.1712 Acc: 75.0000%\n",
      "\tvalidation 12-59: Loss: 0.0948 Acc: 75.0000%\n",
      "\tvalidation 12-60: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 12-61: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 12-62: Loss: 0.1489 Acc: 50.0000%\n",
      "\tvalidation 12-63: Loss: 0.1321 Acc: 75.0000%\n",
      "\tvalidation 12-64: Loss: 0.0517 Acc: 75.0000%\n",
      "\tvalidation 12-65: Loss: 0.1854 Acc: 50.0000%\n",
      "\tvalidation 12-66: Loss: 0.1673 Acc: 75.0000%\n",
      "\tvalidation 12-67: Loss: 0.0586 Acc: 75.0000%\n",
      "\tvalidation 12-68: Loss: 0.1691 Acc: 25.0000%\n",
      "\tvalidation 12-69: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 12-70: Loss: 0.1302 Acc: 100.0000%\n",
      "\tvalidation 12-71: Loss: 0.0840 Acc: 100.0000%\n",
      "\tvalidation 12-72: Loss: 0.1020 Acc: 75.0000%\n",
      "\tvalidation 12-73: Loss: 0.1583 Acc: 25.0000%\n",
      "\tvalidation 12-74: Loss: 0.1039 Acc: 50.0000%\n",
      "\tvalidation 12-75: Loss: 0.1105 Acc: 50.0000%\n",
      "\tvalidation 12-76: Loss: 0.1811 Acc: 50.0000%\n",
      "\tvalidation 12-77: Loss: 0.1280 Acc: 75.0000%\n",
      "\tvalidation 12-78: Loss: 0.1435 Acc: 75.0000%\n",
      "\tvalidation 12-79: Loss: 0.0511 Acc: 100.0000%\n",
      "\tvalidation 12-80: Loss: 0.1623 Acc: 25.0000%\n",
      "\tvalidation 12-81: Loss: 0.0541 Acc: 75.0000%\n",
      "\tvalidation 12-82: Loss: 0.1092 Acc: 75.0000%\n",
      "\tvalidation 12-83: Loss: 0.1070 Acc: 50.0000%\n",
      "\tvalidation 12-84: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 12-85: Loss: 0.1028 Acc: 75.0000%\n",
      "\tvalidation 12-86: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 12-87: Loss: 0.0651 Acc: 75.0000%\n",
      "\tvalidation 12-88: Loss: 0.1705 Acc: 50.0000%\n",
      "\tvalidation 12-89: Loss: 0.0596 Acc: 75.0000%\n",
      "\tvalidation 12-90: Loss: 0.1061 Acc: 50.0000%\n",
      "\tvalidation 12-91: Loss: 0.0598 Acc: 75.0000%\n",
      "\tvalidation 12-92: Loss: 0.0964 Acc: 75.0000%\n",
      "\tvalidation 12-93: Loss: 0.0936 Acc: 75.0000%\n",
      "\tvalidation 12-94: Loss: 0.0895 Acc: 75.0000%\n",
      "\tvalidation 12-95: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 12-96: Loss: 0.0544 Acc: 75.0000%\n",
      "\tvalidation 12-97: Loss: 0.0518 Acc: 75.0000%\n",
      "\tvalidation 12-98: Loss: 0.0927 Acc: 100.0000%\n",
      "\tvalidation 12-99: Loss: 0.0764 Acc: 100.0000%\n",
      "\tvalidation 12-100: Loss: 0.0530 Acc: 75.0000%\n",
      "\tvalidation 12-101: Loss: 0.1031 Acc: 75.0000%\n",
      "\tvalidation 12-102: Loss: 0.1612 Acc: 100.0000%\n",
      "\tvalidation 12-103: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 12-104: Loss: 0.0753 Acc: 100.0000%\n",
      "\tvalidation 12-105: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1280 Acc: 71.6327%\n",
      "\tvalidation Loss: 0.0991 Acc: 75.0000%\n",
      "Time passed 0h 9m 17s\n",
      "--------------------\n",
      "Epoch [13/40]:\n",
      "\ttrain 13-1: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 13-2: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 13-3: Loss: 0.1951 Acc: 25.0000%\n",
      "\ttrain 13-4: Loss: 0.2119 Acc: 50.0000%\n",
      "\ttrain 13-5: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 13-6: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 13-7: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 13-8: Loss: 0.1677 Acc: 50.0000%\n",
      "\ttrain 13-9: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 13-10: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 13-11: Loss: 0.0890 Acc: 100.0000%\n",
      "\ttrain 13-12: Loss: 0.1709 Acc: 75.0000%\n",
      "\ttrain 13-13: Loss: 0.1101 Acc: 75.0000%\n",
      "\ttrain 13-14: Loss: 0.1244 Acc: 50.0000%\n",
      "\ttrain 13-15: Loss: 0.0462 Acc: 75.0000%\n",
      "\ttrain 13-16: Loss: 0.2186 Acc: 50.0000%\n",
      "\ttrain 13-17: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 13-18: Loss: 0.1315 Acc: 50.0000%\n",
      "\ttrain 13-19: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 13-20: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 13-21: Loss: 0.0785 Acc: 75.0000%\n",
      "\ttrain 13-22: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 13-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 13-24: Loss: 0.0501 Acc: 75.0000%\n",
      "\ttrain 13-25: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 13-26: Loss: 0.0769 Acc: 100.0000%\n",
      "\ttrain 13-27: Loss: 0.1197 Acc: 100.0000%\n",
      "\ttrain 13-28: Loss: 0.1744 Acc: 25.0000%\n",
      "\ttrain 13-29: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 13-30: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 13-31: Loss: 0.1361 Acc: 100.0000%\n",
      "\ttrain 13-32: Loss: 0.1663 Acc: 50.0000%\n",
      "\ttrain 13-33: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 13-34: Loss: 0.1342 Acc: 50.0000%\n",
      "\ttrain 13-35: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 13-36: Loss: 0.1858 Acc: 50.0000%\n",
      "\ttrain 13-37: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 13-38: Loss: 0.1390 Acc: 50.0000%\n",
      "\ttrain 13-39: Loss: 0.0981 Acc: 50.0000%\n",
      "\ttrain 13-40: Loss: 0.1880 Acc: 25.0000%\n",
      "\ttrain 13-41: Loss: 0.0768 Acc: 100.0000%\n",
      "\ttrain 13-42: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 13-43: Loss: 0.1194 Acc: 50.0000%\n",
      "\ttrain 13-44: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 13-45: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 13-46: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 13-47: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 13-48: Loss: 0.1196 Acc: 50.0000%\n",
      "\ttrain 13-49: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 13-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-51: Loss: 0.1147 Acc: 50.0000%\n",
      "\ttrain 13-52: Loss: 0.1351 Acc: 50.0000%\n",
      "\ttrain 13-53: Loss: 0.1237 Acc: 50.0000%\n",
      "\ttrain 13-54: Loss: 0.0965 Acc: 100.0000%\n",
      "\ttrain 13-55: Loss: 0.1342 Acc: 75.0000%\n",
      "\ttrain 13-56: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 13-57: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 13-58: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 13-59: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 13-60: Loss: 0.2467 Acc: 50.0000%\n",
      "\ttrain 13-61: Loss: 0.1354 Acc: 50.0000%\n",
      "\ttrain 13-62: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 13-63: Loss: 0.2268 Acc: 0.0000%\n",
      "\ttrain 13-64: Loss: 0.3689 Acc: 75.0000%\n",
      "\ttrain 13-65: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 13-66: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 13-67: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 13-68: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 13-69: Loss: 0.2428 Acc: 25.0000%\n",
      "\ttrain 13-70: Loss: 0.1694 Acc: 25.0000%\n",
      "\ttrain 13-71: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 13-72: Loss: 0.0545 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-73: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 13-74: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 13-75: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 13-76: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 13-77: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 13-78: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 13-79: Loss: 0.1402 Acc: 50.0000%\n",
      "\ttrain 13-80: Loss: 0.1053 Acc: 100.0000%\n",
      "\ttrain 13-81: Loss: 0.1461 Acc: 50.0000%\n",
      "\ttrain 13-82: Loss: 0.0694 Acc: 100.0000%\n",
      "\ttrain 13-83: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 13-84: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 13-85: Loss: 0.1384 Acc: 50.0000%\n",
      "\ttrain 13-86: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 13-87: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 13-88: Loss: 0.1873 Acc: 25.0000%\n",
      "\ttrain 13-89: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 13-90: Loss: 0.2138 Acc: 25.0000%\n",
      "\ttrain 13-91: Loss: 0.1336 Acc: 50.0000%\n",
      "\ttrain 13-92: Loss: 0.0917 Acc: 100.0000%\n",
      "\ttrain 13-93: Loss: 0.1232 Acc: 100.0000%\n",
      "\ttrain 13-94: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 13-95: Loss: 0.1935 Acc: 75.0000%\n",
      "\ttrain 13-96: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 13-97: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 13-98: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 13-99: Loss: 0.1881 Acc: 50.0000%\n",
      "\ttrain 13-100: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 13-101: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 13-102: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 13-103: Loss: 0.2589 Acc: 50.0000%\n",
      "\ttrain 13-104: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 13-105: Loss: 0.4591 Acc: 0.0000%\n",
      "\ttrain 13-106: Loss: 0.0626 Acc: 75.0000%\n",
      "\ttrain 13-107: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 13-108: Loss: 0.1935 Acc: 50.0000%\n",
      "\ttrain 13-109: Loss: 0.2011 Acc: 50.0000%\n",
      "\ttrain 13-110: Loss: 0.1186 Acc: 100.0000%\n",
      "\ttrain 13-111: Loss: 0.1931 Acc: 75.0000%\n",
      "\ttrain 13-112: Loss: 0.1393 Acc: 50.0000%\n",
      "\ttrain 13-113: Loss: 0.1616 Acc: 50.0000%\n",
      "\ttrain 13-114: Loss: 0.1393 Acc: 50.0000%\n",
      "\ttrain 13-115: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 13-116: Loss: 0.1439 Acc: 25.0000%\n",
      "\ttrain 13-117: Loss: 0.1737 Acc: 50.0000%\n",
      "\ttrain 13-118: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 13-119: Loss: 0.1479 Acc: 50.0000%\n",
      "\ttrain 13-120: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 13-121: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 13-122: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 13-123: Loss: 0.1456 Acc: 50.0000%\n",
      "\ttrain 13-124: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 13-125: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 13-126: Loss: 0.1164 Acc: 50.0000%\n",
      "\ttrain 13-127: Loss: 0.1298 Acc: 50.0000%\n",
      "\ttrain 13-128: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 13-129: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 13-130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-131: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 13-132: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 13-133: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 13-134: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 13-135: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 13-136: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 13-137: Loss: 0.2280 Acc: 25.0000%\n",
      "\ttrain 13-138: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 13-139: Loss: 0.2234 Acc: 75.0000%\n",
      "\ttrain 13-140: Loss: 0.1474 Acc: 50.0000%\n",
      "\ttrain 13-141: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 13-142: Loss: 0.3582 Acc: 50.0000%\n",
      "\ttrain 13-143: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 13-144: Loss: 0.2102 Acc: 50.0000%\n",
      "\ttrain 13-145: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 13-146: Loss: 0.2798 Acc: 25.0000%\n",
      "\ttrain 13-147: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 13-148: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 13-149: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 13-150: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 13-151: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 13-152: Loss: 0.1433 Acc: 50.0000%\n",
      "\ttrain 13-153: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 13-154: Loss: 0.0896 Acc: 100.0000%\n",
      "\ttrain 13-155: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 13-156: Loss: 0.1806 Acc: 75.0000%\n",
      "\ttrain 13-157: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 13-158: Loss: 0.1071 Acc: 50.0000%\n",
      "\ttrain 13-159: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 13-160: Loss: 0.2087 Acc: 25.0000%\n",
      "\ttrain 13-161: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 13-162: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 13-163: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 13-164: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 13-165: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 13-166: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 13-167: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 13-168: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 13-169: Loss: 0.1462 Acc: 50.0000%\n",
      "\ttrain 13-170: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 13-171: Loss: 0.0868 Acc: 100.0000%\n",
      "\ttrain 13-172: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 13-173: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 13-174: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 13-175: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 13-176: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 13-177: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 13-178: Loss: 0.2460 Acc: 25.0000%\n",
      "\ttrain 13-179: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 13-180: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 13-181: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 13-182: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 13-183: Loss: 0.0847 Acc: 100.0000%\n",
      "\ttrain 13-184: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 13-185: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 13-186: Loss: 0.2322 Acc: 25.0000%\n",
      "\ttrain 13-187: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 13-188: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 13-189: Loss: 0.1640 Acc: 75.0000%\n",
      "\ttrain 13-190: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 13-191: Loss: 0.1187 Acc: 100.0000%\n",
      "\ttrain 13-192: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 13-193: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 13-194: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 13-195: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 13-196: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 13-197: Loss: 0.2004 Acc: 100.0000%\n",
      "\ttrain 13-198: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 13-199: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 13-200: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 13-201: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 13-202: Loss: 0.1072 Acc: 50.0000%\n",
      "\ttrain 13-203: Loss: 0.1619 Acc: 25.0000%\n",
      "\ttrain 13-204: Loss: 0.1421 Acc: 25.0000%\n",
      "\ttrain 13-205: Loss: 0.0850 Acc: 100.0000%\n",
      "\ttrain 13-206: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 13-207: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 13-208: Loss: 0.1431 Acc: 50.0000%\n",
      "\ttrain 13-209: Loss: 0.2252 Acc: 25.0000%\n",
      "\ttrain 13-210: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 13-211: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 13-212: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 13-213: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 13-214: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 13-215: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 13-216: Loss: 0.1215 Acc: 50.0000%\n",
      "\ttrain 13-217: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 13-218: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 13-219: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 13-220: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 13-221: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 13-222: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 13-223: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 13-224: Loss: 0.4450 Acc: 25.0000%\n",
      "\ttrain 13-225: Loss: 0.0984 Acc: 100.0000%\n",
      "\ttrain 13-226: Loss: 0.1646 Acc: 75.0000%\n",
      "\ttrain 13-227: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 13-228: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 13-229: Loss: 0.1351 Acc: 50.0000%\n",
      "\ttrain 13-230: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 13-231: Loss: 0.1001 Acc: 75.0000%\n",
      "\ttrain 13-232: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 13-233: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 13-234: Loss: 0.2177 Acc: 75.0000%\n",
      "\ttrain 13-235: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 13-236: Loss: 0.1906 Acc: 25.0000%\n",
      "\ttrain 13-237: Loss: 0.1743 Acc: 75.0000%\n",
      "\ttrain 13-238: Loss: 0.1093 Acc: 100.0000%\n",
      "\ttrain 13-239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-240: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 13-241: Loss: 0.1568 Acc: 50.0000%\n",
      "\ttrain 13-242: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 13-243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-244: Loss: 0.1015 Acc: 50.0000%\n",
      "\ttrain 13-245: Loss: 0.0486 Acc: 75.0000%\n",
      "\tvalidation 13-1: Loss: 0.0412 Acc: 100.0000%\n",
      "\tvalidation 13-2: Loss: 0.0541 Acc: 75.0000%\n",
      "\tvalidation 13-3: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 13-4: Loss: 0.0405 Acc: 100.0000%\n",
      "\tvalidation 13-5: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 13-6: Loss: 0.1146 Acc: 50.0000%\n",
      "\tvalidation 13-7: Loss: 0.0845 Acc: 75.0000%\n",
      "\tvalidation 13-8: Loss: 0.0780 Acc: 100.0000%\n",
      "\tvalidation 13-9: Loss: 0.1013 Acc: 75.0000%\n",
      "\tvalidation 13-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-11: Loss: 0.0544 Acc: 75.0000%\n",
      "\tvalidation 13-12: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 13-13: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 13-14: Loss: 0.0481 Acc: 75.0000%\n",
      "\tvalidation 13-15: Loss: 0.0792 Acc: 100.0000%\n",
      "\tvalidation 13-16: Loss: 0.0992 Acc: 75.0000%\n",
      "\tvalidation 13-17: Loss: 0.2491 Acc: 25.0000%\n",
      "\tvalidation 13-18: Loss: 0.0609 Acc: 75.0000%\n",
      "\tvalidation 13-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-20: Loss: 0.1364 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 13-21: Loss: 0.0764 Acc: 100.0000%\n",
      "\tvalidation 13-22: Loss: 0.1042 Acc: 75.0000%\n",
      "\tvalidation 13-23: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 13-24: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 13-25: Loss: 0.1117 Acc: 75.0000%\n",
      "\tvalidation 13-26: Loss: 0.1376 Acc: 50.0000%\n",
      "\tvalidation 13-27: Loss: 0.1434 Acc: 50.0000%\n",
      "\tvalidation 13-28: Loss: 0.1975 Acc: 50.0000%\n",
      "\tvalidation 13-29: Loss: 0.0555 Acc: 75.0000%\n",
      "\tvalidation 13-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-31: Loss: 0.4261 Acc: 50.0000%\n",
      "\tvalidation 13-32: Loss: 0.0764 Acc: 100.0000%\n",
      "\tvalidation 13-33: Loss: 0.4142 Acc: 50.0000%\n",
      "\tvalidation 13-34: Loss: 0.0871 Acc: 100.0000%\n",
      "\tvalidation 13-35: Loss: 0.0783 Acc: 100.0000%\n",
      "\tvalidation 13-36: Loss: 0.1027 Acc: 50.0000%\n",
      "\tvalidation 13-37: Loss: 0.4996 Acc: 50.0000%\n",
      "\tvalidation 13-38: Loss: 0.6090 Acc: 50.0000%\n",
      "\tvalidation 13-39: Loss: 0.0608 Acc: 75.0000%\n",
      "\tvalidation 13-40: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 13-41: Loss: 0.0904 Acc: 75.0000%\n",
      "\tvalidation 13-42: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 13-43: Loss: 0.1027 Acc: 50.0000%\n",
      "\tvalidation 13-44: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 13-45: Loss: 0.1290 Acc: 75.0000%\n",
      "\tvalidation 13-46: Loss: 0.0851 Acc: 75.0000%\n",
      "\tvalidation 13-47: Loss: 0.0793 Acc: 100.0000%\n",
      "\tvalidation 13-48: Loss: 0.0926 Acc: 75.0000%\n",
      "\tvalidation 13-49: Loss: 0.0904 Acc: 75.0000%\n",
      "\tvalidation 13-50: Loss: 0.1832 Acc: 50.0000%\n",
      "\tvalidation 13-51: Loss: 0.1585 Acc: 50.0000%\n",
      "\tvalidation 13-52: Loss: 0.0801 Acc: 100.0000%\n",
      "\tvalidation 13-53: Loss: 0.1803 Acc: 50.0000%\n",
      "\tvalidation 13-54: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 13-55: Loss: 0.2549 Acc: 50.0000%\n",
      "\tvalidation 13-56: Loss: 0.1055 Acc: 75.0000%\n",
      "\tvalidation 13-57: Loss: 0.1241 Acc: 75.0000%\n",
      "\tvalidation 13-58: Loss: 0.0555 Acc: 75.0000%\n",
      "\tvalidation 13-59: Loss: 0.0554 Acc: 75.0000%\n",
      "\tvalidation 13-60: Loss: 0.0809 Acc: 75.0000%\n",
      "\tvalidation 13-61: Loss: 0.0784 Acc: 100.0000%\n",
      "\tvalidation 13-62: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 13-63: Loss: 0.1378 Acc: 75.0000%\n",
      "\tvalidation 13-64: Loss: 0.0862 Acc: 100.0000%\n",
      "\tvalidation 13-65: Loss: 0.0370 Acc: 100.0000%\n",
      "\tvalidation 13-66: Loss: 0.0809 Acc: 100.0000%\n",
      "\tvalidation 13-67: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 13-68: Loss: 0.2672 Acc: 25.0000%\n",
      "\tvalidation 13-69: Loss: 0.1208 Acc: 50.0000%\n",
      "\tvalidation 13-70: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 13-71: Loss: 0.1107 Acc: 100.0000%\n",
      "\tvalidation 13-72: Loss: 0.1232 Acc: 100.0000%\n",
      "\tvalidation 13-73: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 13-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-75: Loss: 0.0788 Acc: 100.0000%\n",
      "\tvalidation 13-76: Loss: 0.1434 Acc: 50.0000%\n",
      "\tvalidation 13-77: Loss: 0.1194 Acc: 75.0000%\n",
      "\tvalidation 13-78: Loss: 0.1152 Acc: 75.0000%\n",
      "\tvalidation 13-79: Loss: 0.1194 Acc: 100.0000%\n",
      "\tvalidation 13-80: Loss: 0.1033 Acc: 75.0000%\n",
      "\tvalidation 13-81: Loss: 0.1579 Acc: 50.0000%\n",
      "\tvalidation 13-82: Loss: 0.1400 Acc: 50.0000%\n",
      "\tvalidation 13-83: Loss: 0.1217 Acc: 100.0000%\n",
      "\tvalidation 13-84: Loss: 0.1029 Acc: 75.0000%\n",
      "\tvalidation 13-85: Loss: 0.0527 Acc: 75.0000%\n",
      "\tvalidation 13-86: Loss: 0.1923 Acc: 25.0000%\n",
      "\tvalidation 13-87: Loss: 0.1725 Acc: 50.0000%\n",
      "\tvalidation 13-88: Loss: 0.1330 Acc: 75.0000%\n",
      "\tvalidation 13-89: Loss: 0.0615 Acc: 75.0000%\n",
      "\tvalidation 13-90: Loss: 0.1096 Acc: 50.0000%\n",
      "\tvalidation 13-91: Loss: 0.0842 Acc: 100.0000%\n",
      "\tvalidation 13-92: Loss: 0.1020 Acc: 75.0000%\n",
      "\tvalidation 13-93: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 13-94: Loss: 0.7746 Acc: 75.0000%\n",
      "\tvalidation 13-95: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 13-96: Loss: 0.1890 Acc: 75.0000%\n",
      "\tvalidation 13-97: Loss: 0.1286 Acc: 75.0000%\n",
      "\tvalidation 13-98: Loss: 0.0488 Acc: 75.0000%\n",
      "\tvalidation 13-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-100: Loss: 0.1252 Acc: 100.0000%\n",
      "\tvalidation 13-101: Loss: 0.1011 Acc: 75.0000%\n",
      "\tvalidation 13-102: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 13-103: Loss: 0.0980 Acc: 75.0000%\n",
      "\tvalidation 13-104: Loss: 0.0393 Acc: 100.0000%\n",
      "\tvalidation 13-105: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1114 Acc: 73.6735%\n",
      "\tvalidation Loss: 0.1185 Acc: 76.6667%\n",
      "网络参数更新\n",
      "Time passed 0h 10m 6s\n",
      "--------------------\n",
      "Epoch [14/40]:\n",
      "\ttrain 14-1: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 14-2: Loss: 0.1622 Acc: 50.0000%\n",
      "\ttrain 14-3: Loss: 0.1482 Acc: 75.0000%\n",
      "\ttrain 14-4: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 14-5: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 14-6: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 14-7: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 14-8: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 14-9: Loss: 0.2004 Acc: 50.0000%\n",
      "\ttrain 14-10: Loss: 0.1772 Acc: 50.0000%\n",
      "\ttrain 14-11: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 14-12: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 14-13: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 14-14: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 14-15: Loss: 0.1104 Acc: 50.0000%\n",
      "\ttrain 14-16: Loss: 0.6480 Acc: 75.0000%\n",
      "\ttrain 14-17: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 14-18: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 14-19: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 14-20: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 14-21: Loss: 0.1100 Acc: 75.0000%\n",
      "\ttrain 14-22: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 14-23: Loss: 0.2775 Acc: 50.0000%\n",
      "\ttrain 14-24: Loss: 0.1461 Acc: 100.0000%\n",
      "\ttrain 14-25: Loss: 0.1119 Acc: 50.0000%\n",
      "\ttrain 14-26: Loss: 0.0954 Acc: 100.0000%\n",
      "\ttrain 14-27: Loss: 0.1164 Acc: 50.0000%\n",
      "\ttrain 14-28: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 14-29: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 14-30: Loss: 0.1716 Acc: 25.0000%\n",
      "\ttrain 14-31: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 14-32: Loss: 0.3776 Acc: 25.0000%\n",
      "\ttrain 14-33: Loss: 0.1195 Acc: 50.0000%\n",
      "\ttrain 14-34: Loss: 0.1205 Acc: 100.0000%\n",
      "\ttrain 14-35: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 14-36: Loss: 0.0479 Acc: 75.0000%\n",
      "\ttrain 14-37: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 14-38: Loss: 0.1462 Acc: 50.0000%\n",
      "\ttrain 14-39: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 14-40: Loss: 0.1291 Acc: 50.0000%\n",
      "\ttrain 14-41: Loss: 0.2574 Acc: 25.0000%\n",
      "\ttrain 14-42: Loss: 0.1380 Acc: 100.0000%\n",
      "\ttrain 14-43: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 14-44: Loss: 0.1248 Acc: 50.0000%\n",
      "\ttrain 14-45: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 14-46: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 14-47: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 14-48: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 14-49: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 14-50: Loss: 0.1619 Acc: 50.0000%\n",
      "\ttrain 14-51: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 14-52: Loss: 0.1855 Acc: 25.0000%\n",
      "\ttrain 14-53: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 14-54: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 14-55: Loss: 0.1128 Acc: 50.0000%\n",
      "\ttrain 14-56: Loss: 0.0579 Acc: 75.0000%\n",
      "\ttrain 14-57: Loss: 0.1580 Acc: 50.0000%\n",
      "\ttrain 14-58: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 14-59: Loss: 0.1176 Acc: 75.0000%\n",
      "\ttrain 14-60: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 14-61: Loss: 0.1221 Acc: 50.0000%\n",
      "\ttrain 14-62: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 14-63: Loss: 0.0642 Acc: 75.0000%\n",
      "\ttrain 14-64: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 14-65: Loss: 0.1834 Acc: 50.0000%\n",
      "\ttrain 14-66: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 14-67: Loss: 0.2303 Acc: 25.0000%\n",
      "\ttrain 14-68: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 14-69: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 14-70: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 14-71: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 14-72: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 14-73: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 14-74: Loss: 0.2834 Acc: 75.0000%\n",
      "\ttrain 14-75: Loss: 0.0881 Acc: 100.0000%\n",
      "\ttrain 14-76: Loss: 0.2768 Acc: 50.0000%\n",
      "\ttrain 14-77: Loss: 0.1257 Acc: 50.0000%\n",
      "\ttrain 14-78: Loss: 0.1779 Acc: 50.0000%\n",
      "\ttrain 14-79: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 14-80: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 14-81: Loss: 0.1410 Acc: 100.0000%\n",
      "\ttrain 14-82: Loss: 0.1415 Acc: 75.0000%\n",
      "\ttrain 14-83: Loss: 0.1386 Acc: 50.0000%\n",
      "\ttrain 14-84: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 14-85: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 14-86: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 14-87: Loss: 0.1259 Acc: 50.0000%\n",
      "\ttrain 14-88: Loss: 0.2489 Acc: 75.0000%\n",
      "\ttrain 14-89: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 14-90: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 14-91: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 14-92: Loss: 0.1041 Acc: 50.0000%\n",
      "\ttrain 14-93: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 14-94: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 14-95: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 14-96: Loss: 0.1746 Acc: 50.0000%\n",
      "\ttrain 14-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 14-98: Loss: 0.0923 Acc: 100.0000%\n",
      "\ttrain 14-99: Loss: 0.0748 Acc: 100.0000%\n",
      "\ttrain 14-100: Loss: 0.5595 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-101: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 14-102: Loss: 0.2421 Acc: 75.0000%\n",
      "\ttrain 14-103: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 14-104: Loss: 0.1642 Acc: 25.0000%\n",
      "\ttrain 14-105: Loss: 0.3009 Acc: 25.0000%\n",
      "\ttrain 14-106: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 14-107: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 14-108: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 14-109: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 14-110: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 14-111: Loss: 0.1344 Acc: 50.0000%\n",
      "\ttrain 14-112: Loss: 0.1419 Acc: 50.0000%\n",
      "\ttrain 14-113: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 14-114: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 14-115: Loss: 0.0896 Acc: 100.0000%\n",
      "\ttrain 14-116: Loss: 0.1372 Acc: 50.0000%\n",
      "\ttrain 14-117: Loss: 0.1271 Acc: 50.0000%\n",
      "\ttrain 14-118: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 14-119: Loss: 0.0859 Acc: 100.0000%\n",
      "\ttrain 14-120: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 14-121: Loss: 0.1380 Acc: 50.0000%\n",
      "\ttrain 14-122: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 14-123: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 14-124: Loss: 0.1338 Acc: 50.0000%\n",
      "\ttrain 14-125: Loss: 0.1238 Acc: 50.0000%\n",
      "\ttrain 14-126: Loss: 0.1016 Acc: 50.0000%\n",
      "\ttrain 14-127: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 14-128: Loss: 0.1204 Acc: 100.0000%\n",
      "\ttrain 14-129: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 14-130: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 14-131: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 14-132: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 14-133: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 14-134: Loss: 0.1476 Acc: 50.0000%\n",
      "\ttrain 14-135: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 14-136: Loss: 0.1618 Acc: 25.0000%\n",
      "\ttrain 14-137: Loss: 0.1861 Acc: 50.0000%\n",
      "\ttrain 14-138: Loss: 0.1930 Acc: 50.0000%\n",
      "\ttrain 14-139: Loss: 0.0741 Acc: 75.0000%\n",
      "\ttrain 14-140: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 14-141: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 14-142: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 14-143: Loss: 0.2493 Acc: 50.0000%\n",
      "\ttrain 14-144: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 14-145: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 14-146: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 14-147: Loss: 0.1472 Acc: 50.0000%\n",
      "\ttrain 14-148: Loss: 0.1107 Acc: 50.0000%\n",
      "\ttrain 14-149: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 14-150: Loss: 0.0960 Acc: 100.0000%\n",
      "\ttrain 14-151: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 14-152: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 14-153: Loss: 0.2249 Acc: 50.0000%\n",
      "\ttrain 14-154: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 14-155: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 14-156: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 14-157: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 14-158: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 14-159: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 14-160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 14-161: Loss: 0.0929 Acc: 50.0000%\n",
      "\ttrain 14-162: Loss: 0.1686 Acc: 50.0000%\n",
      "\ttrain 14-163: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 14-164: Loss: 0.1471 Acc: 50.0000%\n",
      "\ttrain 14-165: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 14-166: Loss: 0.1926 Acc: 25.0000%\n",
      "\ttrain 14-167: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 14-168: Loss: 0.1435 Acc: 75.0000%\n",
      "\ttrain 14-169: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 14-170: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 14-171: Loss: 0.2499 Acc: 50.0000%\n",
      "\ttrain 14-172: Loss: 0.3185 Acc: 50.0000%\n",
      "\ttrain 14-173: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 14-174: Loss: 0.0972 Acc: 50.0000%\n",
      "\ttrain 14-175: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 14-176: Loss: 0.0988 Acc: 50.0000%\n",
      "\ttrain 14-177: Loss: 0.1308 Acc: 100.0000%\n",
      "\ttrain 14-178: Loss: 0.0826 Acc: 100.0000%\n",
      "\ttrain 14-179: Loss: 0.1612 Acc: 25.0000%\n",
      "\ttrain 14-180: Loss: 0.2070 Acc: 75.0000%\n",
      "\ttrain 14-181: Loss: 0.1978 Acc: 50.0000%\n",
      "\ttrain 14-182: Loss: 0.3021 Acc: 25.0000%\n",
      "\ttrain 14-183: Loss: 0.3771 Acc: 25.0000%\n",
      "\ttrain 14-184: Loss: 0.4977 Acc: 50.0000%\n",
      "\ttrain 14-185: Loss: 0.2603 Acc: 50.0000%\n",
      "\ttrain 14-186: Loss: 0.0859 Acc: 100.0000%\n",
      "\ttrain 14-187: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 14-188: Loss: 0.1088 Acc: 100.0000%\n",
      "\ttrain 14-189: Loss: 0.1239 Acc: 50.0000%\n",
      "\ttrain 14-190: Loss: 0.1814 Acc: 50.0000%\n",
      "\ttrain 14-191: Loss: 0.2262 Acc: 50.0000%\n",
      "\ttrain 14-192: Loss: 0.5765 Acc: 0.0000%\n",
      "\ttrain 14-193: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 14-194: Loss: 0.1661 Acc: 75.0000%\n",
      "\ttrain 14-195: Loss: 0.2265 Acc: 75.0000%\n",
      "\ttrain 14-196: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 14-197: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 14-198: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 14-199: Loss: 0.1583 Acc: 75.0000%\n",
      "\ttrain 14-200: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 14-201: Loss: 0.1037 Acc: 50.0000%\n",
      "\ttrain 14-202: Loss: 0.2133 Acc: 50.0000%\n",
      "\ttrain 14-203: Loss: 0.0828 Acc: 100.0000%\n",
      "\ttrain 14-204: Loss: 0.2057 Acc: 25.0000%\n",
      "\ttrain 14-205: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 14-206: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 14-207: Loss: 0.1929 Acc: 50.0000%\n",
      "\ttrain 14-208: Loss: 0.3046 Acc: 0.0000%\n",
      "\ttrain 14-209: Loss: 0.2965 Acc: 50.0000%\n",
      "\ttrain 14-210: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 14-211: Loss: 0.3269 Acc: 25.0000%\n",
      "\ttrain 14-212: Loss: 0.2228 Acc: 50.0000%\n",
      "\ttrain 14-213: Loss: 0.2174 Acc: 25.0000%\n",
      "\ttrain 14-214: Loss: 0.1742 Acc: 25.0000%\n",
      "\ttrain 14-215: Loss: 0.2122 Acc: 50.0000%\n",
      "\ttrain 14-216: Loss: 0.1815 Acc: 50.0000%\n",
      "\ttrain 14-217: Loss: 0.3683 Acc: 25.0000%\n",
      "\ttrain 14-218: Loss: 0.1748 Acc: 50.0000%\n",
      "\ttrain 14-219: Loss: 0.0677 Acc: 100.0000%\n",
      "\ttrain 14-220: Loss: 0.1992 Acc: 75.0000%\n",
      "\ttrain 14-221: Loss: 0.3176 Acc: 50.0000%\n",
      "\ttrain 14-222: Loss: 0.1812 Acc: 50.0000%\n",
      "\ttrain 14-223: Loss: 0.2369 Acc: 50.0000%\n",
      "\ttrain 14-224: Loss: 0.0959 Acc: 100.0000%\n",
      "\ttrain 14-225: Loss: 0.1693 Acc: 75.0000%\n",
      "\ttrain 14-226: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 14-227: Loss: 0.1771 Acc: 75.0000%\n",
      "\ttrain 14-228: Loss: 0.1530 Acc: 50.0000%\n",
      "\ttrain 14-229: Loss: 0.2328 Acc: 25.0000%\n",
      "\ttrain 14-230: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 14-231: Loss: 0.3917 Acc: 75.0000%\n",
      "\ttrain 14-232: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 14-233: Loss: 0.1935 Acc: 75.0000%\n",
      "\ttrain 14-234: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 14-235: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 14-236: Loss: 0.1791 Acc: 50.0000%\n",
      "\ttrain 14-237: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 14-238: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 14-239: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 14-240: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 14-241: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 14-242: Loss: 0.1750 Acc: 25.0000%\n",
      "\ttrain 14-243: Loss: 0.2773 Acc: 75.0000%\n",
      "\ttrain 14-244: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 14-245: Loss: 0.2159 Acc: 50.0000%\n",
      "\tvalidation 14-1: Loss: 0.0915 Acc: 75.0000%\n",
      "\tvalidation 14-2: Loss: 0.1661 Acc: 50.0000%\n",
      "\tvalidation 14-3: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 14-4: Loss: 0.0888 Acc: 100.0000%\n",
      "\tvalidation 14-5: Loss: 0.1520 Acc: 50.0000%\n",
      "\tvalidation 14-6: Loss: 0.0909 Acc: 75.0000%\n",
      "\tvalidation 14-7: Loss: 0.0587 Acc: 75.0000%\n",
      "\tvalidation 14-8: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 14-9: Loss: 0.1904 Acc: 50.0000%\n",
      "\tvalidation 14-10: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 14-11: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 14-12: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-13: Loss: 0.0946 Acc: 75.0000%\n",
      "\tvalidation 14-14: Loss: 0.2076 Acc: 25.0000%\n",
      "\tvalidation 14-15: Loss: 0.1848 Acc: 25.0000%\n",
      "\tvalidation 14-16: Loss: 0.2111 Acc: 25.0000%\n",
      "\tvalidation 14-17: Loss: 0.1532 Acc: 50.0000%\n",
      "\tvalidation 14-18: Loss: 0.1599 Acc: 50.0000%\n",
      "\tvalidation 14-19: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 14-20: Loss: 0.1704 Acc: 50.0000%\n",
      "\tvalidation 14-21: Loss: 0.0883 Acc: 100.0000%\n",
      "\tvalidation 14-22: Loss: 0.1443 Acc: 50.0000%\n",
      "\tvalidation 14-23: Loss: 0.1854 Acc: 50.0000%\n",
      "\tvalidation 14-24: Loss: 0.0537 Acc: 100.0000%\n",
      "\tvalidation 14-25: Loss: 0.0581 Acc: 100.0000%\n",
      "\tvalidation 14-26: Loss: 0.1144 Acc: 75.0000%\n",
      "\tvalidation 14-27: Loss: 0.1533 Acc: 75.0000%\n",
      "\tvalidation 14-28: Loss: 0.1669 Acc: 50.0000%\n",
      "\tvalidation 14-29: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 14-30: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 14-31: Loss: 0.1481 Acc: 50.0000%\n",
      "\tvalidation 14-32: Loss: 0.0689 Acc: 75.0000%\n",
      "\tvalidation 14-33: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 14-34: Loss: 0.0608 Acc: 100.0000%\n",
      "\tvalidation 14-35: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 14-36: Loss: 0.0660 Acc: 75.0000%\n",
      "\tvalidation 14-37: Loss: 0.1530 Acc: 50.0000%\n",
      "\tvalidation 14-38: Loss: 0.1129 Acc: 75.0000%\n",
      "\tvalidation 14-39: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 14-40: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 14-41: Loss: 0.0987 Acc: 75.0000%\n",
      "\tvalidation 14-42: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 14-43: Loss: 0.2077 Acc: 25.0000%\n",
      "\tvalidation 14-44: Loss: 0.1440 Acc: 75.0000%\n",
      "\tvalidation 14-45: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 14-46: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 14-47: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 14-48: Loss: 0.1090 Acc: 75.0000%\n",
      "\tvalidation 14-49: Loss: 0.1296 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 14-50: Loss: 0.1631 Acc: 50.0000%\n",
      "\tvalidation 14-51: Loss: 0.0725 Acc: 75.0000%\n",
      "\tvalidation 14-52: Loss: 0.0603 Acc: 75.0000%\n",
      "\tvalidation 14-53: Loss: 0.1299 Acc: 75.0000%\n",
      "\tvalidation 14-54: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 14-55: Loss: 0.0673 Acc: 100.0000%\n",
      "\tvalidation 14-56: Loss: 0.0626 Acc: 100.0000%\n",
      "\tvalidation 14-57: Loss: 0.0689 Acc: 75.0000%\n",
      "\tvalidation 14-58: Loss: 0.1829 Acc: 50.0000%\n",
      "\tvalidation 14-59: Loss: 0.0778 Acc: 75.0000%\n",
      "\tvalidation 14-60: Loss: 0.0910 Acc: 100.0000%\n",
      "\tvalidation 14-61: Loss: 0.0936 Acc: 75.0000%\n",
      "\tvalidation 14-62: Loss: 0.1597 Acc: 50.0000%\n",
      "\tvalidation 14-63: Loss: 0.1576 Acc: 75.0000%\n",
      "\tvalidation 14-64: Loss: 0.1271 Acc: 75.0000%\n",
      "\tvalidation 14-65: Loss: 0.0596 Acc: 100.0000%\n",
      "\tvalidation 14-66: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 14-67: Loss: 0.1906 Acc: 50.0000%\n",
      "\tvalidation 14-68: Loss: 0.1095 Acc: 75.0000%\n",
      "\tvalidation 14-69: Loss: 0.0681 Acc: 75.0000%\n",
      "\tvalidation 14-70: Loss: 0.0770 Acc: 75.0000%\n",
      "\tvalidation 14-71: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 14-72: Loss: 0.0811 Acc: 75.0000%\n",
      "\tvalidation 14-73: Loss: 0.1896 Acc: 50.0000%\n",
      "\tvalidation 14-74: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 14-75: Loss: 0.1468 Acc: 75.0000%\n",
      "\tvalidation 14-76: Loss: 0.0967 Acc: 75.0000%\n",
      "\tvalidation 14-77: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 14-78: Loss: 0.1336 Acc: 75.0000%\n",
      "\tvalidation 14-79: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 14-80: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 14-81: Loss: 0.1340 Acc: 50.0000%\n",
      "\tvalidation 14-82: Loss: 0.1356 Acc: 50.0000%\n",
      "\tvalidation 14-83: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 14-84: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 14-85: Loss: 0.1416 Acc: 50.0000%\n",
      "\tvalidation 14-86: Loss: 0.1719 Acc: 50.0000%\n",
      "\tvalidation 14-87: Loss: 0.1354 Acc: 50.0000%\n",
      "\tvalidation 14-88: Loss: 0.0919 Acc: 75.0000%\n",
      "\tvalidation 14-89: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 14-90: Loss: 0.0595 Acc: 100.0000%\n",
      "\tvalidation 14-91: Loss: 0.1389 Acc: 50.0000%\n",
      "\tvalidation 14-92: Loss: 0.0687 Acc: 75.0000%\n",
      "\tvalidation 14-93: Loss: 0.0600 Acc: 75.0000%\n",
      "\tvalidation 14-94: Loss: 0.1014 Acc: 75.0000%\n",
      "\tvalidation 14-95: Loss: 0.2268 Acc: 25.0000%\n",
      "\tvalidation 14-96: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 14-97: Loss: 0.1207 Acc: 75.0000%\n",
      "\tvalidation 14-98: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 14-99: Loss: 0.1240 Acc: 75.0000%\n",
      "\tvalidation 14-100: Loss: 0.2000 Acc: 25.0000%\n",
      "\tvalidation 14-101: Loss: 0.0578 Acc: 100.0000%\n",
      "\tvalidation 14-102: Loss: 0.1007 Acc: 75.0000%\n",
      "\tvalidation 14-103: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 14-104: Loss: 0.1229 Acc: 75.0000%\n",
      "\tvalidation 14-105: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1386 Acc: 69.0816%\n",
      "\tvalidation Loss: 0.0986 Acc: 74.7619%\n",
      "Time passed 0h 10m 52s\n",
      "--------------------\n",
      "Epoch [15/40]:\n",
      "\ttrain 15-1: Loss: 0.1511 Acc: 50.0000%\n",
      "\ttrain 15-2: Loss: 0.1403 Acc: 100.0000%\n",
      "\ttrain 15-3: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 15-4: Loss: 0.1580 Acc: 75.0000%\n",
      "\ttrain 15-5: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 15-6: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 15-7: Loss: 0.0536 Acc: 75.0000%\n",
      "\ttrain 15-8: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 15-9: Loss: 0.1532 Acc: 50.0000%\n",
      "\ttrain 15-10: Loss: 0.1750 Acc: 50.0000%\n",
      "\ttrain 15-11: Loss: 0.1631 Acc: 50.0000%\n",
      "\ttrain 15-12: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 15-13: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 15-14: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 15-15: Loss: 0.0564 Acc: 75.0000%\n",
      "\ttrain 15-16: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 15-17: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 15-18: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 15-19: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 15-20: Loss: 0.1509 Acc: 50.0000%\n",
      "\ttrain 15-21: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 15-22: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 15-23: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 15-24: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 15-25: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 15-26: Loss: 0.0799 Acc: 100.0000%\n",
      "\ttrain 15-27: Loss: 0.1942 Acc: 25.0000%\n",
      "\ttrain 15-28: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 15-29: Loss: 0.1450 Acc: 100.0000%\n",
      "\ttrain 15-30: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 15-31: Loss: 0.1404 Acc: 50.0000%\n",
      "\ttrain 15-32: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 15-33: Loss: 0.0988 Acc: 100.0000%\n",
      "\ttrain 15-34: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 15-35: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 15-36: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 15-37: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 15-38: Loss: 0.1345 Acc: 50.0000%\n",
      "\ttrain 15-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 15-40: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 15-41: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 15-42: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 15-43: Loss: 0.3309 Acc: 75.0000%\n",
      "\ttrain 15-44: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 15-45: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 15-46: Loss: 0.2684 Acc: 50.0000%\n",
      "\ttrain 15-47: Loss: 0.0863 Acc: 100.0000%\n",
      "\ttrain 15-48: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 15-49: Loss: 0.1701 Acc: 75.0000%\n",
      "\ttrain 15-50: Loss: 0.1421 Acc: 50.0000%\n",
      "\ttrain 15-51: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 15-52: Loss: 0.1515 Acc: 50.0000%\n",
      "\ttrain 15-53: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 15-54: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 15-55: Loss: 0.0933 Acc: 100.0000%\n",
      "\ttrain 15-56: Loss: 0.3734 Acc: 25.0000%\n",
      "\ttrain 15-57: Loss: 0.3159 Acc: 25.0000%\n",
      "\ttrain 15-58: Loss: 0.1349 Acc: 50.0000%\n",
      "\ttrain 15-59: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 15-60: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 15-61: Loss: 0.1073 Acc: 50.0000%\n",
      "\ttrain 15-62: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 15-63: Loss: 0.1612 Acc: 100.0000%\n",
      "\ttrain 15-64: Loss: 0.2136 Acc: 0.0000%\n",
      "\ttrain 15-65: Loss: 0.1041 Acc: 100.0000%\n",
      "\ttrain 15-66: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 15-67: Loss: 0.1221 Acc: 100.0000%\n",
      "\ttrain 15-68: Loss: 0.0761 Acc: 100.0000%\n",
      "\ttrain 15-69: Loss: 0.1293 Acc: 100.0000%\n",
      "\ttrain 15-70: Loss: 0.1534 Acc: 50.0000%\n",
      "\ttrain 15-71: Loss: 0.1661 Acc: 75.0000%\n",
      "\ttrain 15-72: Loss: 0.1665 Acc: 75.0000%\n",
      "\ttrain 15-73: Loss: 0.1674 Acc: 25.0000%\n",
      "\ttrain 15-74: Loss: 0.1485 Acc: 100.0000%\n",
      "\ttrain 15-75: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 15-76: Loss: 0.2897 Acc: 50.0000%\n",
      "\ttrain 15-77: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 15-78: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 15-79: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 15-80: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 15-81: Loss: 0.2190 Acc: 50.0000%\n",
      "\ttrain 15-82: Loss: 0.1133 Acc: 50.0000%\n",
      "\ttrain 15-83: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 15-84: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 15-85: Loss: 0.1652 Acc: 75.0000%\n",
      "\ttrain 15-86: Loss: 0.1141 Acc: 50.0000%\n",
      "\ttrain 15-87: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 15-88: Loss: 0.2219 Acc: 75.0000%\n",
      "\ttrain 15-89: Loss: 0.0919 Acc: 100.0000%\n",
      "\ttrain 15-90: Loss: 0.1021 Acc: 100.0000%\n",
      "\ttrain 15-91: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 15-92: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 15-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 15-94: Loss: 0.2072 Acc: 50.0000%\n",
      "\ttrain 15-95: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 15-96: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 15-97: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 15-98: Loss: 0.1482 Acc: 75.0000%\n",
      "\ttrain 15-99: Loss: 0.1930 Acc: 75.0000%\n",
      "\ttrain 15-100: Loss: 0.3072 Acc: 50.0000%\n",
      "\ttrain 15-101: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 15-102: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 15-103: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 15-104: Loss: 0.2525 Acc: 25.0000%\n",
      "\ttrain 15-105: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 15-106: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 15-107: Loss: 0.0832 Acc: 100.0000%\n",
      "\ttrain 15-108: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 15-109: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 15-110: Loss: 0.1514 Acc: 50.0000%\n",
      "\ttrain 15-111: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 15-112: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 15-113: Loss: 0.1618 Acc: 75.0000%\n",
      "\ttrain 15-114: Loss: 0.0973 Acc: 100.0000%\n",
      "\ttrain 15-115: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 15-116: Loss: 0.1855 Acc: 50.0000%\n",
      "\ttrain 15-117: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 15-118: Loss: 0.1836 Acc: 50.0000%\n",
      "\ttrain 15-119: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 15-120: Loss: 0.1359 Acc: 50.0000%\n",
      "\ttrain 15-121: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 15-122: Loss: 0.1896 Acc: 25.0000%\n",
      "\ttrain 15-123: Loss: 0.1498 Acc: 25.0000%\n",
      "\ttrain 15-124: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 15-125: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 15-126: Loss: 0.0473 Acc: 75.0000%\n",
      "\ttrain 15-127: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 15-128: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 15-129: Loss: 0.1449 Acc: 75.0000%\n",
      "\ttrain 15-130: Loss: 0.1982 Acc: 50.0000%\n",
      "\ttrain 15-131: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 15-132: Loss: 0.1113 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 15-133: Loss: 0.1495 Acc: 50.0000%\n",
      "\ttrain 15-134: Loss: 0.1065 Acc: 50.0000%\n",
      "\ttrain 15-135: Loss: 0.1538 Acc: 50.0000%\n",
      "\ttrain 15-136: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 15-137: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 15-138: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 15-139: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 15-140: Loss: 0.1630 Acc: 50.0000%\n",
      "\ttrain 15-141: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 15-142: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 15-143: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 15-144: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 15-145: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 15-146: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 15-147: Loss: 0.1932 Acc: 25.0000%\n",
      "\ttrain 15-148: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 15-149: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 15-150: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 15-151: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 15-152: Loss: 0.0563 Acc: 75.0000%\n",
      "\ttrain 15-153: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 15-154: Loss: 0.0970 Acc: 50.0000%\n",
      "\ttrain 15-155: Loss: 0.1443 Acc: 50.0000%\n",
      "\ttrain 15-156: Loss: 0.0812 Acc: 100.0000%\n",
      "\ttrain 15-157: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 15-158: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 15-159: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 15-160: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 15-161: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 15-162: Loss: 0.0687 Acc: 100.0000%\n",
      "\ttrain 15-163: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 15-164: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 15-165: Loss: 0.1262 Acc: 50.0000%\n",
      "\ttrain 15-166: Loss: 0.1470 Acc: 50.0000%\n",
      "\ttrain 15-167: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 15-168: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 15-169: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 15-170: Loss: 0.1127 Acc: 50.0000%\n",
      "\ttrain 15-171: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 15-172: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 15-173: Loss: 0.1581 Acc: 25.0000%\n",
      "\ttrain 15-174: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 15-175: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 15-176: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 15-177: Loss: 0.1188 Acc: 100.0000%\n",
      "\ttrain 15-178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 15-179: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 15-180: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 15-181: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 15-182: Loss: 0.1416 Acc: 50.0000%\n",
      "\ttrain 15-183: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 15-184: Loss: 0.1066 Acc: 50.0000%\n",
      "\ttrain 15-185: Loss: 0.2433 Acc: 0.0000%\n",
      "\ttrain 15-186: Loss: 0.0652 Acc: 100.0000%\n",
      "\ttrain 15-187: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 15-188: Loss: 0.2698 Acc: 25.0000%\n",
      "\ttrain 15-189: Loss: 0.1688 Acc: 50.0000%\n",
      "\ttrain 15-190: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 15-191: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 15-192: Loss: 0.1075 Acc: 50.0000%\n",
      "\ttrain 15-193: Loss: 0.0709 Acc: 100.0000%\n",
      "\ttrain 15-194: Loss: 0.0564 Acc: 75.0000%\n",
      "\ttrain 15-195: Loss: 0.1686 Acc: 50.0000%\n",
      "\ttrain 15-196: Loss: 0.1094 Acc: 50.0000%\n",
      "\ttrain 15-197: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 15-198: Loss: 0.1772 Acc: 50.0000%\n",
      "\ttrain 15-199: Loss: 0.1887 Acc: 25.0000%\n",
      "\ttrain 15-200: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 15-201: Loss: 0.0748 Acc: 100.0000%\n",
      "\ttrain 15-202: Loss: 0.1080 Acc: 50.0000%\n",
      "\ttrain 15-203: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 15-204: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 15-205: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 15-206: Loss: 0.1376 Acc: 75.0000%\n",
      "\ttrain 15-207: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 15-208: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 15-209: Loss: 0.1826 Acc: 25.0000%\n",
      "\ttrain 15-210: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 15-211: Loss: 0.1197 Acc: 100.0000%\n",
      "\ttrain 15-212: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 15-213: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 15-214: Loss: 0.2191 Acc: 0.0000%\n",
      "\ttrain 15-215: Loss: 0.1451 Acc: 50.0000%\n",
      "\ttrain 15-216: Loss: 0.1303 Acc: 50.0000%\n",
      "\ttrain 15-217: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 15-218: Loss: 0.5495 Acc: 75.0000%\n",
      "\ttrain 15-219: Loss: 0.0873 Acc: 100.0000%\n",
      "\ttrain 15-220: Loss: 0.1688 Acc: 75.0000%\n",
      "\ttrain 15-221: Loss: 0.1651 Acc: 50.0000%\n",
      "\ttrain 15-222: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 15-223: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 15-224: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 15-225: Loss: 0.2246 Acc: 25.0000%\n",
      "\ttrain 15-226: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 15-227: Loss: 0.0843 Acc: 100.0000%\n",
      "\ttrain 15-228: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 15-229: Loss: 0.4000 Acc: 50.0000%\n",
      "\ttrain 15-230: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 15-231: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 15-232: Loss: 0.0785 Acc: 100.0000%\n",
      "\ttrain 15-233: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 15-234: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 15-235: Loss: 0.1795 Acc: 50.0000%\n",
      "\ttrain 15-236: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 15-237: Loss: 0.0975 Acc: 50.0000%\n",
      "\ttrain 15-238: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 15-239: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 15-240: Loss: 0.1001 Acc: 50.0000%\n",
      "\ttrain 15-241: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 15-242: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 15-243: Loss: 0.1878 Acc: 75.0000%\n",
      "\ttrain 15-244: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 15-245: Loss: 0.1627 Acc: 25.0000%\n",
      "\tvalidation 15-1: Loss: 0.0459 Acc: 75.0000%\n",
      "\tvalidation 15-2: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 15-3: Loss: 0.1385 Acc: 50.0000%\n",
      "\tvalidation 15-4: Loss: 0.1730 Acc: 75.0000%\n",
      "\tvalidation 15-5: Loss: 0.1272 Acc: 100.0000%\n",
      "\tvalidation 15-6: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-7: Loss: 0.1462 Acc: 25.0000%\n",
      "\tvalidation 15-8: Loss: 0.0902 Acc: 75.0000%\n",
      "\tvalidation 15-9: Loss: 0.0937 Acc: 75.0000%\n",
      "\tvalidation 15-10: Loss: 0.0453 Acc: 75.0000%\n",
      "\tvalidation 15-11: Loss: 0.1283 Acc: 100.0000%\n",
      "\tvalidation 15-12: Loss: 0.0781 Acc: 75.0000%\n",
      "\tvalidation 15-13: Loss: 0.0902 Acc: 100.0000%\n",
      "\tvalidation 15-14: Loss: 0.1355 Acc: 100.0000%\n",
      "\tvalidation 15-15: Loss: 0.0880 Acc: 100.0000%\n",
      "\tvalidation 15-16: Loss: 0.0966 Acc: 50.0000%\n",
      "\tvalidation 15-17: Loss: 0.0962 Acc: 50.0000%\n",
      "\tvalidation 15-18: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 15-19: Loss: 0.0679 Acc: 100.0000%\n",
      "\tvalidation 15-20: Loss: 0.1322 Acc: 100.0000%\n",
      "\tvalidation 15-21: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 15-22: Loss: 0.0939 Acc: 75.0000%\n",
      "\tvalidation 15-23: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 15-24: Loss: 0.0817 Acc: 100.0000%\n",
      "\tvalidation 15-25: Loss: 0.1386 Acc: 75.0000%\n",
      "\tvalidation 15-26: Loss: 0.1251 Acc: 100.0000%\n",
      "\tvalidation 15-27: Loss: 0.1344 Acc: 75.0000%\n",
      "\tvalidation 15-28: Loss: 0.1297 Acc: 75.0000%\n",
      "\tvalidation 15-29: Loss: 0.1346 Acc: 75.0000%\n",
      "\tvalidation 15-30: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 15-31: Loss: 0.1328 Acc: 75.0000%\n",
      "\tvalidation 15-32: Loss: 0.1739 Acc: 75.0000%\n",
      "\tvalidation 15-33: Loss: 0.0364 Acc: 100.0000%\n",
      "\tvalidation 15-34: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 15-35: Loss: 0.1327 Acc: 100.0000%\n",
      "\tvalidation 15-36: Loss: 0.1755 Acc: 100.0000%\n",
      "\tvalidation 15-37: Loss: 0.0466 Acc: 100.0000%\n",
      "\tvalidation 15-38: Loss: 0.0462 Acc: 75.0000%\n",
      "\tvalidation 15-39: Loss: 0.1337 Acc: 100.0000%\n",
      "\tvalidation 15-40: Loss: 0.1357 Acc: 75.0000%\n",
      "\tvalidation 15-41: Loss: 0.0446 Acc: 100.0000%\n",
      "\tvalidation 15-42: Loss: 0.0370 Acc: 100.0000%\n",
      "\tvalidation 15-43: Loss: 0.0453 Acc: 100.0000%\n",
      "\tvalidation 15-44: Loss: 0.1696 Acc: 75.0000%\n",
      "\tvalidation 15-45: Loss: 0.0432 Acc: 100.0000%\n",
      "\tvalidation 15-46: Loss: 0.1345 Acc: 100.0000%\n",
      "\tvalidation 15-47: Loss: 0.1797 Acc: 50.0000%\n",
      "\tvalidation 15-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-49: Loss: 0.1140 Acc: 75.0000%\n",
      "\tvalidation 15-50: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 15-51: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 15-52: Loss: 0.1098 Acc: 100.0000%\n",
      "\tvalidation 15-53: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 15-54: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 15-55: Loss: 0.0919 Acc: 75.0000%\n",
      "\tvalidation 15-56: Loss: 0.1462 Acc: 50.0000%\n",
      "\tvalidation 15-57: Loss: 0.1343 Acc: 75.0000%\n",
      "\tvalidation 15-58: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 15-59: Loss: 0.0947 Acc: 50.0000%\n",
      "\tvalidation 15-60: Loss: 0.1298 Acc: 75.0000%\n",
      "\tvalidation 15-61: Loss: 0.0726 Acc: 100.0000%\n",
      "\tvalidation 15-62: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 15-63: Loss: 0.0923 Acc: 75.0000%\n",
      "\tvalidation 15-64: Loss: 0.1364 Acc: 50.0000%\n",
      "\tvalidation 15-65: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 15-66: Loss: 0.0928 Acc: 75.0000%\n",
      "\tvalidation 15-67: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 15-68: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-69: Loss: 0.1781 Acc: 50.0000%\n",
      "\tvalidation 15-70: Loss: 0.0465 Acc: 75.0000%\n",
      "\tvalidation 15-71: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 15-72: Loss: 0.1200 Acc: 50.0000%\n",
      "\tvalidation 15-73: Loss: 0.0908 Acc: 75.0000%\n",
      "\tvalidation 15-74: Loss: 0.1299 Acc: 100.0000%\n",
      "\tvalidation 15-75: Loss: 0.0884 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 15-76: Loss: 0.1734 Acc: 100.0000%\n",
      "\tvalidation 15-77: Loss: 0.0941 Acc: 75.0000%\n",
      "\tvalidation 15-78: Loss: 0.1855 Acc: 25.0000%\n",
      "\tvalidation 15-79: Loss: 0.1235 Acc: 100.0000%\n",
      "\tvalidation 15-80: Loss: 0.1266 Acc: 75.0000%\n",
      "\tvalidation 15-81: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 15-82: Loss: 0.1819 Acc: 50.0000%\n",
      "\tvalidation 15-83: Loss: 0.0556 Acc: 75.0000%\n",
      "\tvalidation 15-84: Loss: 0.0853 Acc: 100.0000%\n",
      "\tvalidation 15-85: Loss: 0.0855 Acc: 100.0000%\n",
      "\tvalidation 15-86: Loss: 0.0458 Acc: 75.0000%\n",
      "\tvalidation 15-87: Loss: 0.0854 Acc: 100.0000%\n",
      "\tvalidation 15-88: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 15-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-90: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 15-91: Loss: 0.0952 Acc: 50.0000%\n",
      "\tvalidation 15-92: Loss: 0.0918 Acc: 75.0000%\n",
      "\tvalidation 15-93: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 15-94: Loss: 0.1181 Acc: 75.0000%\n",
      "\tvalidation 15-95: Loss: 0.0868 Acc: 100.0000%\n",
      "\tvalidation 15-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-98: Loss: 0.1321 Acc: 50.0000%\n",
      "\tvalidation 15-99: Loss: 0.1337 Acc: 75.0000%\n",
      "\tvalidation 15-100: Loss: 0.1288 Acc: 100.0000%\n",
      "\tvalidation 15-101: Loss: 0.0941 Acc: 75.0000%\n",
      "\tvalidation 15-102: Loss: 0.0431 Acc: 100.0000%\n",
      "\tvalidation 15-103: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 15-104: Loss: 0.0890 Acc: 100.0000%\n",
      "\tvalidation 15-105: Loss: 0.0517 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1130 Acc: 75.0000%\n",
      "\tvalidation Loss: 0.0919 Acc: 82.8571%\n",
      "网络参数更新\n",
      "Time passed 0h 11m 41s\n",
      "--------------------\n",
      "Epoch [16/40]:\n",
      "\ttrain 16-1: Loss: 0.1548 Acc: 50.0000%\n",
      "\ttrain 16-2: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 16-3: Loss: 0.1887 Acc: 25.0000%\n",
      "\ttrain 16-4: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 16-5: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 16-6: Loss: 0.2443 Acc: 50.0000%\n",
      "\ttrain 16-7: Loss: 0.0508 Acc: 75.0000%\n",
      "\ttrain 16-8: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 16-9: Loss: 0.0895 Acc: 100.0000%\n",
      "\ttrain 16-10: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 16-11: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 16-12: Loss: 0.0567 Acc: 75.0000%\n",
      "\ttrain 16-13: Loss: 0.1404 Acc: 50.0000%\n",
      "\ttrain 16-14: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 16-15: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 16-16: Loss: 0.1739 Acc: 75.0000%\n",
      "\ttrain 16-17: Loss: 0.1048 Acc: 50.0000%\n",
      "\ttrain 16-18: Loss: 0.0973 Acc: 50.0000%\n",
      "\ttrain 16-19: Loss: 0.3635 Acc: 50.0000%\n",
      "\ttrain 16-20: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 16-21: Loss: 0.0683 Acc: 100.0000%\n",
      "\ttrain 16-22: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 16-23: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 16-24: Loss: 0.1685 Acc: 50.0000%\n",
      "\ttrain 16-25: Loss: 0.2107 Acc: 0.0000%\n",
      "\ttrain 16-26: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 16-27: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 16-28: Loss: 0.0856 Acc: 100.0000%\n",
      "\ttrain 16-29: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 16-30: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 16-31: Loss: 0.1426 Acc: 50.0000%\n",
      "\ttrain 16-32: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 16-33: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 16-34: Loss: 0.0847 Acc: 100.0000%\n",
      "\ttrain 16-35: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 16-36: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 16-37: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 16-38: Loss: 0.1331 Acc: 100.0000%\n",
      "\ttrain 16-39: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 16-40: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 16-41: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 16-42: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 16-43: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 16-44: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 16-45: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 16-46: Loss: 0.1983 Acc: 50.0000%\n",
      "\ttrain 16-47: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 16-48: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 16-49: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 16-50: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 16-51: Loss: 0.0641 Acc: 100.0000%\n",
      "\ttrain 16-52: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 16-53: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 16-54: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 16-55: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 16-56: Loss: 0.1731 Acc: 50.0000%\n",
      "\ttrain 16-57: Loss: 0.2257 Acc: 25.0000%\n",
      "\ttrain 16-58: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 16-59: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 16-60: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 16-61: Loss: 0.0575 Acc: 75.0000%\n",
      "\ttrain 16-62: Loss: 0.1527 Acc: 50.0000%\n",
      "\ttrain 16-63: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 16-64: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 16-65: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 16-66: Loss: 0.1516 Acc: 50.0000%\n",
      "\ttrain 16-67: Loss: 0.1001 Acc: 75.0000%\n",
      "\ttrain 16-68: Loss: 0.1284 Acc: 50.0000%\n",
      "\ttrain 16-69: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 16-70: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 16-71: Loss: 0.1338 Acc: 100.0000%\n",
      "\ttrain 16-72: Loss: 0.1100 Acc: 100.0000%\n",
      "\ttrain 16-73: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 16-74: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 16-75: Loss: 0.1940 Acc: 50.0000%\n",
      "\ttrain 16-76: Loss: 0.0969 Acc: 100.0000%\n",
      "\ttrain 16-77: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 16-78: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 16-79: Loss: 0.0876 Acc: 50.0000%\n",
      "\ttrain 16-80: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 16-81: Loss: 0.1710 Acc: 50.0000%\n",
      "\ttrain 16-82: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 16-83: Loss: 0.0815 Acc: 100.0000%\n",
      "\ttrain 16-84: Loss: 0.3764 Acc: 50.0000%\n",
      "\ttrain 16-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-86: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 16-87: Loss: 0.0526 Acc: 75.0000%\n",
      "\ttrain 16-88: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 16-89: Loss: 0.1017 Acc: 50.0000%\n",
      "\ttrain 16-90: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-91: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 16-92: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 16-93: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 16-94: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 16-95: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 16-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-97: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 16-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-99: Loss: 0.1820 Acc: 50.0000%\n",
      "\ttrain 16-100: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 16-101: Loss: 0.0788 Acc: 100.0000%\n",
      "\ttrain 16-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 16-103: Loss: 0.1563 Acc: 50.0000%\n",
      "\ttrain 16-104: Loss: 0.1732 Acc: 75.0000%\n",
      "\ttrain 16-105: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 16-106: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 16-107: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 16-108: Loss: 0.1446 Acc: 50.0000%\n",
      "\ttrain 16-109: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 16-110: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 16-111: Loss: 0.1259 Acc: 100.0000%\n",
      "\ttrain 16-112: Loss: 0.0441 Acc: 75.0000%\n",
      "\ttrain 16-113: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 16-114: Loss: 0.2705 Acc: 50.0000%\n",
      "\ttrain 16-115: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 16-116: Loss: 0.2913 Acc: 50.0000%\n",
      "\ttrain 16-117: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 16-118: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 16-119: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 16-120: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 16-121: Loss: 0.1105 Acc: 100.0000%\n",
      "\ttrain 16-122: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 16-123: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 16-124: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 16-125: Loss: 0.1980 Acc: 50.0000%\n",
      "\ttrain 16-126: Loss: 0.2166 Acc: 50.0000%\n",
      "\ttrain 16-127: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 16-128: Loss: 0.2421 Acc: 50.0000%\n",
      "\ttrain 16-129: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 16-130: Loss: 0.1053 Acc: 50.0000%\n",
      "\ttrain 16-131: Loss: 0.1479 Acc: 75.0000%\n",
      "\ttrain 16-132: Loss: 0.1718 Acc: 25.0000%\n",
      "\ttrain 16-133: Loss: 0.1716 Acc: 50.0000%\n",
      "\ttrain 16-134: Loss: 0.1365 Acc: 50.0000%\n",
      "\ttrain 16-135: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 16-136: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 16-137: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 16-138: Loss: 0.2605 Acc: 25.0000%\n",
      "\ttrain 16-139: Loss: 0.1774 Acc: 50.0000%\n",
      "\ttrain 16-140: Loss: 0.1595 Acc: 25.0000%\n",
      "\ttrain 16-141: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 16-142: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 16-143: Loss: 0.1587 Acc: 50.0000%\n",
      "\ttrain 16-144: Loss: 0.1658 Acc: 25.0000%\n",
      "\ttrain 16-145: Loss: 0.6396 Acc: 50.0000%\n",
      "\ttrain 16-146: Loss: 0.0998 Acc: 100.0000%\n",
      "\ttrain 16-147: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 16-148: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 16-149: Loss: 0.0863 Acc: 100.0000%\n",
      "\ttrain 16-150: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 16-151: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 16-152: Loss: 0.2246 Acc: 50.0000%\n",
      "\ttrain 16-153: Loss: 0.1226 Acc: 100.0000%\n",
      "\ttrain 16-154: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 16-155: Loss: 0.4359 Acc: 25.0000%\n",
      "\ttrain 16-156: Loss: 0.0978 Acc: 50.0000%\n",
      "\ttrain 16-157: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 16-158: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 16-159: Loss: 0.1133 Acc: 100.0000%\n",
      "\ttrain 16-160: Loss: 0.0786 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 16-161: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 16-162: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 16-163: Loss: 0.1428 Acc: 50.0000%\n",
      "\ttrain 16-164: Loss: 0.1334 Acc: 50.0000%\n",
      "\ttrain 16-165: Loss: 0.2429 Acc: 25.0000%\n",
      "\ttrain 16-166: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 16-167: Loss: 0.2799 Acc: 25.0000%\n",
      "\ttrain 16-168: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 16-169: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 16-170: Loss: 0.1440 Acc: 50.0000%\n",
      "\ttrain 16-171: Loss: 0.2725 Acc: 75.0000%\n",
      "\ttrain 16-172: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 16-173: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 16-174: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 16-175: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 16-176: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 16-177: Loss: 0.1208 Acc: 50.0000%\n",
      "\ttrain 16-178: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 16-179: Loss: 0.1809 Acc: 75.0000%\n",
      "\ttrain 16-180: Loss: 0.0943 Acc: 100.0000%\n",
      "\ttrain 16-181: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 16-182: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 16-183: Loss: 0.2149 Acc: 50.0000%\n",
      "\ttrain 16-184: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 16-185: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 16-186: Loss: 0.1219 Acc: 100.0000%\n",
      "\ttrain 16-187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-188: Loss: 0.0541 Acc: 75.0000%\n",
      "\ttrain 16-189: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 16-190: Loss: 0.0772 Acc: 100.0000%\n",
      "\ttrain 16-191: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 16-192: Loss: 0.1702 Acc: 50.0000%\n",
      "\ttrain 16-193: Loss: 0.1946 Acc: 75.0000%\n",
      "\ttrain 16-194: Loss: 0.1517 Acc: 75.0000%\n",
      "\ttrain 16-195: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 16-196: Loss: 0.1144 Acc: 100.0000%\n",
      "\ttrain 16-197: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 16-198: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 16-199: Loss: 0.2622 Acc: 25.0000%\n",
      "\ttrain 16-200: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 16-201: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 16-202: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 16-203: Loss: 0.0893 Acc: 50.0000%\n",
      "\ttrain 16-204: Loss: 0.1527 Acc: 50.0000%\n",
      "\ttrain 16-205: Loss: 0.1075 Acc: 50.0000%\n",
      "\ttrain 16-206: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 16-207: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 16-208: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 16-209: Loss: 0.1266 Acc: 50.0000%\n",
      "\ttrain 16-210: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 16-211: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 16-212: Loss: 0.1156 Acc: 100.0000%\n",
      "\ttrain 16-213: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 16-214: Loss: 0.1464 Acc: 25.0000%\n",
      "\ttrain 16-215: Loss: 0.1130 Acc: 100.0000%\n",
      "\ttrain 16-216: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 16-217: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 16-218: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 16-219: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 16-220: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 16-221: Loss: 0.1074 Acc: 100.0000%\n",
      "\ttrain 16-222: Loss: 0.2848 Acc: 75.0000%\n",
      "\ttrain 16-223: Loss: 0.1536 Acc: 50.0000%\n",
      "\ttrain 16-224: Loss: 0.1727 Acc: 50.0000%\n",
      "\ttrain 16-225: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 16-226: Loss: 0.1128 Acc: 50.0000%\n",
      "\ttrain 16-227: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 16-228: Loss: 0.1311 Acc: 100.0000%\n",
      "\ttrain 16-229: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 16-230: Loss: 0.2549 Acc: 25.0000%\n",
      "\ttrain 16-231: Loss: 0.2477 Acc: 50.0000%\n",
      "\ttrain 16-232: Loss: 0.2363 Acc: 25.0000%\n",
      "\ttrain 16-233: Loss: 0.1436 Acc: 50.0000%\n",
      "\ttrain 16-234: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 16-235: Loss: 0.2470 Acc: 50.0000%\n",
      "\ttrain 16-236: Loss: 0.2997 Acc: 75.0000%\n",
      "\ttrain 16-237: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 16-238: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 16-239: Loss: 0.2066 Acc: 25.0000%\n",
      "\ttrain 16-240: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 16-241: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 16-242: Loss: 0.1446 Acc: 50.0000%\n",
      "\ttrain 16-243: Loss: 0.1692 Acc: 50.0000%\n",
      "\ttrain 16-244: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 16-245: Loss: 0.0872 Acc: 75.0000%\n",
      "\tvalidation 16-1: Loss: 0.0450 Acc: 75.0000%\n",
      "\tvalidation 16-2: Loss: 0.1452 Acc: 50.0000%\n",
      "\tvalidation 16-3: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 16-4: Loss: 0.1238 Acc: 100.0000%\n",
      "\tvalidation 16-5: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 16-6: Loss: 0.1398 Acc: 75.0000%\n",
      "\tvalidation 16-7: Loss: 0.1686 Acc: 100.0000%\n",
      "\tvalidation 16-8: Loss: 0.0906 Acc: 100.0000%\n",
      "\tvalidation 16-9: Loss: 0.1336 Acc: 100.0000%\n",
      "\tvalidation 16-10: Loss: 0.1326 Acc: 75.0000%\n",
      "\tvalidation 16-11: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 16-12: Loss: 0.0450 Acc: 75.0000%\n",
      "\tvalidation 16-13: Loss: 0.0993 Acc: 75.0000%\n",
      "\tvalidation 16-14: Loss: 0.0896 Acc: 100.0000%\n",
      "\tvalidation 16-15: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 16-16: Loss: 0.1285 Acc: 100.0000%\n",
      "\tvalidation 16-17: Loss: 0.0470 Acc: 75.0000%\n",
      "\tvalidation 16-18: Loss: 0.0603 Acc: 75.0000%\n",
      "\tvalidation 16-19: Loss: 0.0909 Acc: 100.0000%\n",
      "\tvalidation 16-20: Loss: 0.1877 Acc: 25.0000%\n",
      "\tvalidation 16-21: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 16-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-23: Loss: 0.0460 Acc: 100.0000%\n",
      "\tvalidation 16-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-25: Loss: 0.1774 Acc: 50.0000%\n",
      "\tvalidation 16-26: Loss: 0.0933 Acc: 75.0000%\n",
      "\tvalidation 16-27: Loss: 0.0978 Acc: 100.0000%\n",
      "\tvalidation 16-28: Loss: 0.0872 Acc: 100.0000%\n",
      "\tvalidation 16-29: Loss: 0.1156 Acc: 75.0000%\n",
      "\tvalidation 16-30: Loss: 0.0966 Acc: 75.0000%\n",
      "\tvalidation 16-31: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 16-32: Loss: 0.0458 Acc: 100.0000%\n",
      "\tvalidation 16-33: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 16-34: Loss: 0.1652 Acc: 50.0000%\n",
      "\tvalidation 16-35: Loss: 0.0875 Acc: 100.0000%\n",
      "\tvalidation 16-36: Loss: 0.0865 Acc: 100.0000%\n",
      "\tvalidation 16-37: Loss: 0.1173 Acc: 100.0000%\n",
      "\tvalidation 16-38: Loss: 0.0901 Acc: 50.0000%\n",
      "\tvalidation 16-39: Loss: 0.1136 Acc: 100.0000%\n",
      "\tvalidation 16-40: Loss: 0.1841 Acc: 50.0000%\n",
      "\tvalidation 16-41: Loss: 0.1279 Acc: 100.0000%\n",
      "\tvalidation 16-42: Loss: 0.0878 Acc: 100.0000%\n",
      "\tvalidation 16-43: Loss: 0.0961 Acc: 75.0000%\n",
      "\tvalidation 16-44: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 16-45: Loss: 0.1068 Acc: 50.0000%\n",
      "\tvalidation 16-46: Loss: 0.0949 Acc: 100.0000%\n",
      "\tvalidation 16-47: Loss: 0.0839 Acc: 100.0000%\n",
      "\tvalidation 16-48: Loss: 0.0793 Acc: 100.0000%\n",
      "\tvalidation 16-49: Loss: 0.0864 Acc: 100.0000%\n",
      "\tvalidation 16-50: Loss: 0.0728 Acc: 100.0000%\n",
      "\tvalidation 16-51: Loss: 0.0853 Acc: 100.0000%\n",
      "\tvalidation 16-52: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 16-53: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 16-54: Loss: 0.0708 Acc: 100.0000%\n",
      "\tvalidation 16-55: Loss: 0.0817 Acc: 100.0000%\n",
      "\tvalidation 16-56: Loss: 0.0899 Acc: 75.0000%\n",
      "\tvalidation 16-57: Loss: 0.1314 Acc: 75.0000%\n",
      "\tvalidation 16-58: Loss: 0.1310 Acc: 100.0000%\n",
      "\tvalidation 16-59: Loss: 0.1275 Acc: 100.0000%\n",
      "\tvalidation 16-60: Loss: 0.0830 Acc: 75.0000%\n",
      "\tvalidation 16-61: Loss: 0.0452 Acc: 75.0000%\n",
      "\tvalidation 16-62: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 16-63: Loss: 0.1248 Acc: 75.0000%\n",
      "\tvalidation 16-64: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 16-65: Loss: 0.1032 Acc: 100.0000%\n",
      "\tvalidation 16-66: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 16-67: Loss: 0.0919 Acc: 100.0000%\n",
      "\tvalidation 16-68: Loss: 0.0824 Acc: 75.0000%\n",
      "\tvalidation 16-69: Loss: 0.0937 Acc: 75.0000%\n",
      "\tvalidation 16-70: Loss: 0.1349 Acc: 100.0000%\n",
      "\tvalidation 16-71: Loss: 0.1183 Acc: 100.0000%\n",
      "\tvalidation 16-72: Loss: 0.1730 Acc: 100.0000%\n",
      "\tvalidation 16-73: Loss: 0.0458 Acc: 75.0000%\n",
      "\tvalidation 16-74: Loss: 0.0468 Acc: 75.0000%\n",
      "\tvalidation 16-75: Loss: 0.1367 Acc: 75.0000%\n",
      "\tvalidation 16-76: Loss: 0.0883 Acc: 100.0000%\n",
      "\tvalidation 16-77: Loss: 0.0846 Acc: 100.0000%\n",
      "\tvalidation 16-78: Loss: 0.1808 Acc: 50.0000%\n",
      "\tvalidation 16-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-80: Loss: 0.1763 Acc: 25.0000%\n",
      "\tvalidation 16-81: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 16-82: Loss: 0.0835 Acc: 100.0000%\n",
      "\tvalidation 16-83: Loss: 0.0618 Acc: 75.0000%\n",
      "\tvalidation 16-84: Loss: 0.0874 Acc: 100.0000%\n",
      "\tvalidation 16-85: Loss: 0.1345 Acc: 75.0000%\n",
      "\tvalidation 16-86: Loss: 0.0937 Acc: 50.0000%\n",
      "\tvalidation 16-87: Loss: 0.0468 Acc: 75.0000%\n",
      "\tvalidation 16-88: Loss: 0.0892 Acc: 100.0000%\n",
      "\tvalidation 16-89: Loss: 0.0756 Acc: 100.0000%\n",
      "\tvalidation 16-90: Loss: 0.0989 Acc: 50.0000%\n",
      "\tvalidation 16-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-92: Loss: 0.0881 Acc: 100.0000%\n",
      "\tvalidation 16-93: Loss: 0.1324 Acc: 75.0000%\n",
      "\tvalidation 16-94: Loss: 0.1818 Acc: 50.0000%\n",
      "\tvalidation 16-95: Loss: 0.0926 Acc: 50.0000%\n",
      "\tvalidation 16-96: Loss: 0.1227 Acc: 100.0000%\n",
      "\tvalidation 16-97: Loss: 0.0881 Acc: 75.0000%\n",
      "\tvalidation 16-98: Loss: 0.0536 Acc: 75.0000%\n",
      "\tvalidation 16-99: Loss: 0.0841 Acc: 100.0000%\n",
      "\tvalidation 16-100: Loss: 0.0457 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 16-101: Loss: 0.0951 Acc: 50.0000%\n",
      "\tvalidation 16-102: Loss: 0.1421 Acc: 100.0000%\n",
      "\tvalidation 16-103: Loss: 0.0872 Acc: 100.0000%\n",
      "\tvalidation 16-104: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 16-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1209 Acc: 73.1633%\n",
      "\tvalidation Loss: 0.0901 Acc: 85.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 12m 30s\n",
      "--------------------\n",
      "Epoch [17/40]:\n",
      "\ttrain 17-1: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 17-2: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 17-3: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 17-4: Loss: 0.1716 Acc: 50.0000%\n",
      "\ttrain 17-5: Loss: 0.1504 Acc: 50.0000%\n",
      "\ttrain 17-6: Loss: 0.1011 Acc: 50.0000%\n",
      "\ttrain 17-7: Loss: 0.1357 Acc: 50.0000%\n",
      "\ttrain 17-8: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 17-9: Loss: 0.2162 Acc: 50.0000%\n",
      "\ttrain 17-10: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 17-11: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 17-12: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 17-13: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 17-14: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 17-15: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 17-16: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 17-17: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 17-18: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 17-19: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 17-20: Loss: 0.1882 Acc: 75.0000%\n",
      "\ttrain 17-21: Loss: 0.0906 Acc: 100.0000%\n",
      "\ttrain 17-22: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 17-23: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 17-24: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 17-25: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 17-26: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 17-27: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 17-28: Loss: 0.2421 Acc: 50.0000%\n",
      "\ttrain 17-29: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 17-30: Loss: 0.0713 Acc: 100.0000%\n",
      "\ttrain 17-31: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 17-32: Loss: 0.1268 Acc: 75.0000%\n",
      "\ttrain 17-33: Loss: 0.1203 Acc: 50.0000%\n",
      "\ttrain 17-34: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 17-35: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 17-36: Loss: 0.0981 Acc: 50.0000%\n",
      "\ttrain 17-37: Loss: 0.1749 Acc: 25.0000%\n",
      "\ttrain 17-38: Loss: 0.1225 Acc: 50.0000%\n",
      "\ttrain 17-39: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 17-40: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 17-41: Loss: 0.0772 Acc: 100.0000%\n",
      "\ttrain 17-42: Loss: 0.1615 Acc: 75.0000%\n",
      "\ttrain 17-43: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 17-44: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 17-45: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 17-46: Loss: 0.2083 Acc: 50.0000%\n",
      "\ttrain 17-47: Loss: 0.0464 Acc: 75.0000%\n",
      "\ttrain 17-48: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 17-49: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 17-50: Loss: 0.0919 Acc: 100.0000%\n",
      "\ttrain 17-51: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 17-52: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 17-53: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 17-54: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 17-55: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 17-56: Loss: 0.2048 Acc: 25.0000%\n",
      "\ttrain 17-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 17-58: Loss: 0.1720 Acc: 50.0000%\n",
      "\ttrain 17-59: Loss: 0.1934 Acc: 50.0000%\n",
      "\ttrain 17-60: Loss: 0.4291 Acc: 50.0000%\n",
      "\ttrain 17-61: Loss: 0.1525 Acc: 50.0000%\n",
      "\ttrain 17-62: Loss: 0.3058 Acc: 25.0000%\n",
      "\ttrain 17-63: Loss: 0.0792 Acc: 100.0000%\n",
      "\ttrain 17-64: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 17-65: Loss: 0.1640 Acc: 50.0000%\n",
      "\ttrain 17-66: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 17-67: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 17-68: Loss: 0.1601 Acc: 50.0000%\n",
      "\ttrain 17-69: Loss: 0.0691 Acc: 100.0000%\n",
      "\ttrain 17-70: Loss: 0.1130 Acc: 100.0000%\n",
      "\ttrain 17-71: Loss: 0.0785 Acc: 75.0000%\n",
      "\ttrain 17-72: Loss: 0.0613 Acc: 100.0000%\n",
      "\ttrain 17-73: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 17-74: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 17-75: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 17-76: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 17-77: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 17-78: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 17-79: Loss: 0.2275 Acc: 50.0000%\n",
      "\ttrain 17-80: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 17-81: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 17-82: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 17-83: Loss: 0.3082 Acc: 25.0000%\n",
      "\ttrain 17-84: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 17-85: Loss: 0.1522 Acc: 50.0000%\n",
      "\ttrain 17-86: Loss: 0.1406 Acc: 50.0000%\n",
      "\ttrain 17-87: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 17-88: Loss: 0.2137 Acc: 25.0000%\n",
      "\ttrain 17-89: Loss: 0.1755 Acc: 50.0000%\n",
      "\ttrain 17-90: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 17-91: Loss: 0.1367 Acc: 75.0000%\n",
      "\ttrain 17-92: Loss: 0.1441 Acc: 25.0000%\n",
      "\ttrain 17-93: Loss: 0.3219 Acc: 25.0000%\n",
      "\ttrain 17-94: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 17-95: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 17-96: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 17-97: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 17-98: Loss: 0.1300 Acc: 50.0000%\n",
      "\ttrain 17-99: Loss: 0.1578 Acc: 50.0000%\n",
      "\ttrain 17-100: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 17-101: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 17-102: Loss: 0.1264 Acc: 100.0000%\n",
      "\ttrain 17-103: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 17-104: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 17-105: Loss: 0.2596 Acc: 75.0000%\n",
      "\ttrain 17-106: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 17-107: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 17-108: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 17-109: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 17-110: Loss: 0.1297 Acc: 100.0000%\n",
      "\ttrain 17-111: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 17-112: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 17-113: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 17-114: Loss: 0.1316 Acc: 75.0000%\n",
      "\ttrain 17-115: Loss: 0.1619 Acc: 75.0000%\n",
      "\ttrain 17-116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 17-117: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 17-118: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 17-119: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 17-120: Loss: 0.2327 Acc: 50.0000%\n",
      "\ttrain 17-121: Loss: 0.0515 Acc: 75.0000%\n",
      "\ttrain 17-122: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 17-123: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 17-124: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 17-125: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 17-126: Loss: 0.1201 Acc: 50.0000%\n",
      "\ttrain 17-127: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 17-128: Loss: 0.1856 Acc: 50.0000%\n",
      "\ttrain 17-129: Loss: 0.5150 Acc: 50.0000%\n",
      "\ttrain 17-130: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 17-131: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 17-132: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 17-133: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 17-134: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 17-135: Loss: 0.0655 Acc: 100.0000%\n",
      "\ttrain 17-136: Loss: 0.2260 Acc: 25.0000%\n",
      "\ttrain 17-137: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 17-138: Loss: 0.1144 Acc: 50.0000%\n",
      "\ttrain 17-139: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 17-140: Loss: 0.1354 Acc: 50.0000%\n",
      "\ttrain 17-141: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 17-142: Loss: 0.3591 Acc: 50.0000%\n",
      "\ttrain 17-143: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 17-144: Loss: 0.1491 Acc: 25.0000%\n",
      "\ttrain 17-145: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 17-146: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 17-147: Loss: 0.1314 Acc: 50.0000%\n",
      "\ttrain 17-148: Loss: 0.1631 Acc: 50.0000%\n",
      "\ttrain 17-149: Loss: 0.0503 Acc: 75.0000%\n",
      "\ttrain 17-150: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 17-151: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 17-152: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 17-153: Loss: 0.0524 Acc: 75.0000%\n",
      "\ttrain 17-154: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 17-155: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 17-156: Loss: 0.0446 Acc: 75.0000%\n",
      "\ttrain 17-157: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 17-158: Loss: 0.1757 Acc: 75.0000%\n",
      "\ttrain 17-159: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 17-160: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 17-161: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 17-162: Loss: 0.1763 Acc: 75.0000%\n",
      "\ttrain 17-163: Loss: 0.2427 Acc: 50.0000%\n",
      "\ttrain 17-164: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 17-165: Loss: 0.1350 Acc: 75.0000%\n",
      "\ttrain 17-166: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 17-167: Loss: 0.1129 Acc: 50.0000%\n",
      "\ttrain 17-168: Loss: 0.1478 Acc: 50.0000%\n",
      "\ttrain 17-169: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 17-170: Loss: 0.0785 Acc: 100.0000%\n",
      "\ttrain 17-171: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 17-172: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 17-173: Loss: 0.1029 Acc: 50.0000%\n",
      "\ttrain 17-174: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 17-175: Loss: 0.1009 Acc: 50.0000%\n",
      "\ttrain 17-176: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 17-177: Loss: 0.1540 Acc: 50.0000%\n",
      "\ttrain 17-178: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 17-179: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 17-180: Loss: 0.1056 Acc: 100.0000%\n",
      "\ttrain 17-181: Loss: 0.1125 Acc: 50.0000%\n",
      "\ttrain 17-182: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 17-183: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 17-184: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 17-185: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 17-186: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 17-187: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 17-188: Loss: 0.1395 Acc: 100.0000%\n",
      "\ttrain 17-189: Loss: 0.0516 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-190: Loss: 0.0474 Acc: 75.0000%\n",
      "\ttrain 17-191: Loss: 0.0472 Acc: 75.0000%\n",
      "\ttrain 17-192: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 17-193: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 17-194: Loss: 0.2257 Acc: 25.0000%\n",
      "\ttrain 17-195: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 17-196: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 17-197: Loss: 0.1275 Acc: 50.0000%\n",
      "\ttrain 17-198: Loss: 0.1714 Acc: 50.0000%\n",
      "\ttrain 17-199: Loss: 0.1198 Acc: 50.0000%\n",
      "\ttrain 17-200: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 17-201: Loss: 0.1524 Acc: 75.0000%\n",
      "\ttrain 17-202: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 17-203: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 17-204: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 17-205: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 17-206: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 17-207: Loss: 0.1752 Acc: 50.0000%\n",
      "\ttrain 17-208: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 17-209: Loss: 0.1369 Acc: 100.0000%\n",
      "\ttrain 17-210: Loss: 0.1557 Acc: 50.0000%\n",
      "\ttrain 17-211: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 17-212: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 17-213: Loss: 0.0547 Acc: 75.0000%\n",
      "\ttrain 17-214: Loss: 0.0925 Acc: 100.0000%\n",
      "\ttrain 17-215: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 17-216: Loss: 0.1952 Acc: 50.0000%\n",
      "\ttrain 17-217: Loss: 0.1588 Acc: 50.0000%\n",
      "\ttrain 17-218: Loss: 0.1628 Acc: 50.0000%\n",
      "\ttrain 17-219: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 17-220: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 17-221: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 17-222: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 17-223: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 17-224: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 17-225: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 17-226: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 17-227: Loss: 0.1934 Acc: 75.0000%\n",
      "\ttrain 17-228: Loss: 0.0854 Acc: 100.0000%\n",
      "\ttrain 17-229: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 17-230: Loss: 0.2557 Acc: 50.0000%\n",
      "\ttrain 17-231: Loss: 0.1260 Acc: 50.0000%\n",
      "\ttrain 17-232: Loss: 0.1396 Acc: 50.0000%\n",
      "\ttrain 17-233: Loss: 0.1126 Acc: 50.0000%\n",
      "\ttrain 17-234: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 17-235: Loss: 0.1655 Acc: 25.0000%\n",
      "\ttrain 17-236: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 17-237: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 17-238: Loss: 0.1025 Acc: 50.0000%\n",
      "\ttrain 17-239: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 17-240: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 17-241: Loss: 0.0503 Acc: 75.0000%\n",
      "\ttrain 17-242: Loss: 0.0695 Acc: 100.0000%\n",
      "\ttrain 17-243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 17-244: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 17-245: Loss: 0.2044 Acc: 75.0000%\n",
      "\tvalidation 17-1: Loss: 0.0915 Acc: 75.0000%\n",
      "\tvalidation 17-2: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 17-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-4: Loss: 0.0480 Acc: 100.0000%\n",
      "\tvalidation 17-5: Loss: 0.0905 Acc: 75.0000%\n",
      "\tvalidation 17-6: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 17-7: Loss: 0.0844 Acc: 75.0000%\n",
      "\tvalidation 17-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-9: Loss: 0.1325 Acc: 50.0000%\n",
      "\tvalidation 17-10: Loss: 0.0508 Acc: 75.0000%\n",
      "\tvalidation 17-11: Loss: 0.1715 Acc: 50.0000%\n",
      "\tvalidation 17-12: Loss: 0.0878 Acc: 75.0000%\n",
      "\tvalidation 17-13: Loss: 0.0511 Acc: 100.0000%\n",
      "\tvalidation 17-14: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 17-15: Loss: 0.1322 Acc: 50.0000%\n",
      "\tvalidation 17-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-17: Loss: 0.0766 Acc: 100.0000%\n",
      "\tvalidation 17-18: Loss: 0.0855 Acc: 75.0000%\n",
      "\tvalidation 17-19: Loss: 0.0524 Acc: 75.0000%\n",
      "\tvalidation 17-20: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 17-21: Loss: 0.0621 Acc: 100.0000%\n",
      "\tvalidation 17-22: Loss: 0.1143 Acc: 50.0000%\n",
      "\tvalidation 17-23: Loss: 0.0913 Acc: 75.0000%\n",
      "\tvalidation 17-24: Loss: 0.1304 Acc: 75.0000%\n",
      "\tvalidation 17-25: Loss: 0.1487 Acc: 75.0000%\n",
      "\tvalidation 17-26: Loss: 0.1803 Acc: 50.0000%\n",
      "\tvalidation 17-27: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 17-28: Loss: 0.1435 Acc: 50.0000%\n",
      "\tvalidation 17-29: Loss: 0.1598 Acc: 75.0000%\n",
      "\tvalidation 17-30: Loss: 0.0612 Acc: 75.0000%\n",
      "\tvalidation 17-31: Loss: 0.1472 Acc: 50.0000%\n",
      "\tvalidation 17-32: Loss: 0.0899 Acc: 75.0000%\n",
      "\tvalidation 17-33: Loss: 0.0932 Acc: 100.0000%\n",
      "\tvalidation 17-34: Loss: 0.1237 Acc: 75.0000%\n",
      "\tvalidation 17-35: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 17-36: Loss: 0.1026 Acc: 50.0000%\n",
      "\tvalidation 17-37: Loss: 0.0501 Acc: 75.0000%\n",
      "\tvalidation 17-38: Loss: 0.0792 Acc: 75.0000%\n",
      "\tvalidation 17-39: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 17-40: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 17-41: Loss: 0.0761 Acc: 75.0000%\n",
      "\tvalidation 17-42: Loss: 0.0938 Acc: 100.0000%\n",
      "\tvalidation 17-43: Loss: 0.0656 Acc: 100.0000%\n",
      "\tvalidation 17-44: Loss: 0.0845 Acc: 75.0000%\n",
      "\tvalidation 17-45: Loss: 0.1757 Acc: 50.0000%\n",
      "\tvalidation 17-46: Loss: 0.1945 Acc: 50.0000%\n",
      "\tvalidation 17-47: Loss: 0.0577 Acc: 75.0000%\n",
      "\tvalidation 17-48: Loss: 0.1042 Acc: 100.0000%\n",
      "\tvalidation 17-49: Loss: 0.0868 Acc: 75.0000%\n",
      "\tvalidation 17-50: Loss: 0.1424 Acc: 50.0000%\n",
      "\tvalidation 17-51: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 17-52: Loss: 0.0552 Acc: 100.0000%\n",
      "\tvalidation 17-53: Loss: 0.0611 Acc: 100.0000%\n",
      "\tvalidation 17-54: Loss: 0.0817 Acc: 75.0000%\n",
      "\tvalidation 17-55: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 17-56: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 17-57: Loss: 0.0801 Acc: 75.0000%\n",
      "\tvalidation 17-58: Loss: 0.1630 Acc: 25.0000%\n",
      "\tvalidation 17-59: Loss: 0.1256 Acc: 75.0000%\n",
      "\tvalidation 17-60: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 17-61: Loss: 0.1007 Acc: 75.0000%\n",
      "\tvalidation 17-62: Loss: 0.1061 Acc: 75.0000%\n",
      "\tvalidation 17-63: Loss: 0.2815 Acc: 50.0000%\n",
      "\tvalidation 17-64: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 17-65: Loss: 0.1466 Acc: 50.0000%\n",
      "\tvalidation 17-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-67: Loss: 0.1417 Acc: 50.0000%\n",
      "\tvalidation 17-68: Loss: 0.1371 Acc: 75.0000%\n",
      "\tvalidation 17-69: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 17-70: Loss: 0.1869 Acc: 25.0000%\n",
      "\tvalidation 17-71: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 17-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-74: Loss: 0.0497 Acc: 75.0000%\n",
      "\tvalidation 17-75: Loss: 0.0607 Acc: 75.0000%\n",
      "\tvalidation 17-76: Loss: 0.0827 Acc: 75.0000%\n",
      "\tvalidation 17-77: Loss: 0.1113 Acc: 75.0000%\n",
      "\tvalidation 17-78: Loss: 0.1176 Acc: 75.0000%\n",
      "\tvalidation 17-79: Loss: 0.0915 Acc: 75.0000%\n",
      "\tvalidation 17-80: Loss: 0.1781 Acc: 25.0000%\n",
      "\tvalidation 17-81: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 17-82: Loss: 0.0832 Acc: 75.0000%\n",
      "\tvalidation 17-83: Loss: 0.0631 Acc: 75.0000%\n",
      "\tvalidation 17-84: Loss: 0.0849 Acc: 75.0000%\n",
      "\tvalidation 17-85: Loss: 0.1950 Acc: 25.0000%\n",
      "\tvalidation 17-86: Loss: 0.1075 Acc: 75.0000%\n",
      "\tvalidation 17-87: Loss: 0.1142 Acc: 75.0000%\n",
      "\tvalidation 17-88: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 17-89: Loss: 0.0586 Acc: 100.0000%\n",
      "\tvalidation 17-90: Loss: 0.0825 Acc: 75.0000%\n",
      "\tvalidation 17-91: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 17-92: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 17-93: Loss: 0.0931 Acc: 75.0000%\n",
      "\tvalidation 17-94: Loss: 0.1173 Acc: 75.0000%\n",
      "\tvalidation 17-95: Loss: 0.0884 Acc: 75.0000%\n",
      "\tvalidation 17-96: Loss: 0.0604 Acc: 100.0000%\n",
      "\tvalidation 17-97: Loss: 0.1210 Acc: 50.0000%\n",
      "\tvalidation 17-98: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 17-99: Loss: 0.0572 Acc: 100.0000%\n",
      "\tvalidation 17-100: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 17-101: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 17-102: Loss: 0.0439 Acc: 75.0000%\n",
      "\tvalidation 17-103: Loss: 0.1768 Acc: 25.0000%\n",
      "\tvalidation 17-104: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 17-105: Loss: 0.1007 Acc: 50.0000%\n",
      "\ttrain Loss: 0.1099 Acc: 74.8980%\n",
      "\tvalidation Loss: 0.0856 Acc: 77.8571%\n",
      "Time passed 0h 13m 15s\n",
      "--------------------\n",
      "Epoch [18/40]:\n",
      "\ttrain 18-1: Loss: 0.0904 Acc: 100.0000%\n",
      "\ttrain 18-2: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 18-3: Loss: 0.1300 Acc: 50.0000%\n",
      "\ttrain 18-4: Loss: 0.0460 Acc: 75.0000%\n",
      "\ttrain 18-5: Loss: 0.2168 Acc: 75.0000%\n",
      "\ttrain 18-6: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 18-7: Loss: 0.0834 Acc: 100.0000%\n",
      "\ttrain 18-8: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 18-9: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 18-10: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 18-11: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 18-12: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 18-13: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 18-14: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 18-15: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 18-16: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 18-17: Loss: 0.2667 Acc: 75.0000%\n",
      "\ttrain 18-18: Loss: 0.2601 Acc: 25.0000%\n",
      "\ttrain 18-19: Loss: 0.1522 Acc: 50.0000%\n",
      "\ttrain 18-20: Loss: 0.1896 Acc: 50.0000%\n",
      "\ttrain 18-21: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 18-22: Loss: 0.1027 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-23: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 18-24: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 18-25: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 18-26: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 18-27: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 18-28: Loss: 0.1339 Acc: 50.0000%\n",
      "\ttrain 18-29: Loss: 0.0579 Acc: 75.0000%\n",
      "\ttrain 18-30: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 18-31: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 18-32: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 18-33: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 18-34: Loss: 0.1342 Acc: 50.0000%\n",
      "\ttrain 18-35: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 18-36: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 18-37: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 18-38: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 18-39: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 18-40: Loss: 0.1461 Acc: 50.0000%\n",
      "\ttrain 18-41: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 18-42: Loss: 0.0771 Acc: 100.0000%\n",
      "\ttrain 18-43: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 18-44: Loss: 0.1402 Acc: 50.0000%\n",
      "\ttrain 18-45: Loss: 0.1130 Acc: 50.0000%\n",
      "\ttrain 18-46: Loss: 0.1076 Acc: 50.0000%\n",
      "\ttrain 18-47: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 18-48: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 18-49: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 18-50: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 18-51: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 18-52: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 18-53: Loss: 0.1590 Acc: 50.0000%\n",
      "\ttrain 18-54: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 18-55: Loss: 0.1066 Acc: 100.0000%\n",
      "\ttrain 18-56: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 18-57: Loss: 0.1224 Acc: 75.0000%\n",
      "\ttrain 18-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 18-59: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 18-60: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 18-61: Loss: 0.2354 Acc: 50.0000%\n",
      "\ttrain 18-62: Loss: 0.0943 Acc: 50.0000%\n",
      "\ttrain 18-63: Loss: 0.1287 Acc: 50.0000%\n",
      "\ttrain 18-64: Loss: 0.0766 Acc: 100.0000%\n",
      "\ttrain 18-65: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 18-66: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 18-67: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 18-68: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 18-69: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 18-70: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 18-71: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 18-72: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 18-73: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 18-74: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 18-75: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 18-76: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 18-77: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 18-78: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 18-79: Loss: 0.1331 Acc: 75.0000%\n",
      "\ttrain 18-80: Loss: 0.2714 Acc: 25.0000%\n",
      "\ttrain 18-81: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 18-82: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 18-83: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 18-84: Loss: 0.4227 Acc: 25.0000%\n",
      "\ttrain 18-85: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 18-86: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 18-87: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 18-88: Loss: 0.1342 Acc: 75.0000%\n",
      "\ttrain 18-89: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 18-90: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 18-91: Loss: 0.0484 Acc: 75.0000%\n",
      "\ttrain 18-92: Loss: 0.0913 Acc: 100.0000%\n",
      "\ttrain 18-93: Loss: 0.3149 Acc: 75.0000%\n",
      "\ttrain 18-94: Loss: 0.3732 Acc: 50.0000%\n",
      "\ttrain 18-95: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 18-96: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 18-97: Loss: 0.2252 Acc: 50.0000%\n",
      "\ttrain 18-98: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 18-99: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 18-100: Loss: 0.1018 Acc: 100.0000%\n",
      "\ttrain 18-101: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 18-102: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 18-103: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 18-104: Loss: 0.3065 Acc: 50.0000%\n",
      "\ttrain 18-105: Loss: 0.1290 Acc: 50.0000%\n",
      "\ttrain 18-106: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 18-107: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 18-108: Loss: 0.0695 Acc: 100.0000%\n",
      "\ttrain 18-109: Loss: 0.1328 Acc: 50.0000%\n",
      "\ttrain 18-110: Loss: 0.1478 Acc: 50.0000%\n",
      "\ttrain 18-111: Loss: 0.0814 Acc: 100.0000%\n",
      "\ttrain 18-112: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 18-113: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 18-114: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 18-115: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 18-116: Loss: 0.0660 Acc: 100.0000%\n",
      "\ttrain 18-117: Loss: 0.2378 Acc: 50.0000%\n",
      "\ttrain 18-118: Loss: 0.0800 Acc: 100.0000%\n",
      "\ttrain 18-119: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 18-120: Loss: 0.1134 Acc: 50.0000%\n",
      "\ttrain 18-121: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 18-122: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 18-123: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 18-124: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 18-125: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 18-126: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 18-127: Loss: 0.1183 Acc: 100.0000%\n",
      "\ttrain 18-128: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 18-129: Loss: 0.1799 Acc: 25.0000%\n",
      "\ttrain 18-130: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 18-131: Loss: 0.0506 Acc: 75.0000%\n",
      "\ttrain 18-132: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 18-133: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 18-134: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 18-135: Loss: 0.1406 Acc: 75.0000%\n",
      "\ttrain 18-136: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 18-137: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 18-138: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 18-139: Loss: 0.1581 Acc: 75.0000%\n",
      "\ttrain 18-140: Loss: 0.0529 Acc: 75.0000%\n",
      "\ttrain 18-141: Loss: 0.2625 Acc: 75.0000%\n",
      "\ttrain 18-142: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 18-143: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 18-144: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 18-145: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 18-146: Loss: 0.1628 Acc: 50.0000%\n",
      "\ttrain 18-147: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 18-148: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 18-149: Loss: 0.0877 Acc: 100.0000%\n",
      "\ttrain 18-150: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 18-151: Loss: 0.1162 Acc: 50.0000%\n",
      "\ttrain 18-152: Loss: 0.1279 Acc: 50.0000%\n",
      "\ttrain 18-153: Loss: 0.1529 Acc: 75.0000%\n",
      "\ttrain 18-154: Loss: 0.1377 Acc: 75.0000%\n",
      "\ttrain 18-155: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 18-156: Loss: 0.1650 Acc: 50.0000%\n",
      "\ttrain 18-157: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 18-158: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 18-159: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 18-160: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 18-161: Loss: 0.1285 Acc: 100.0000%\n",
      "\ttrain 18-162: Loss: 0.1293 Acc: 50.0000%\n",
      "\ttrain 18-163: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 18-164: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 18-165: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 18-166: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 18-167: Loss: 0.1513 Acc: 50.0000%\n",
      "\ttrain 18-168: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 18-169: Loss: 0.1300 Acc: 50.0000%\n",
      "\ttrain 18-170: Loss: 0.2148 Acc: 50.0000%\n",
      "\ttrain 18-171: Loss: 0.1649 Acc: 25.0000%\n",
      "\ttrain 18-172: Loss: 0.0879 Acc: 100.0000%\n",
      "\ttrain 18-173: Loss: 0.0824 Acc: 100.0000%\n",
      "\ttrain 18-174: Loss: 0.2459 Acc: 50.0000%\n",
      "\ttrain 18-175: Loss: 0.1296 Acc: 50.0000%\n",
      "\ttrain 18-176: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 18-177: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 18-178: Loss: 0.1409 Acc: 50.0000%\n",
      "\ttrain 18-179: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 18-180: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 18-181: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 18-182: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 18-183: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 18-184: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 18-185: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 18-186: Loss: 0.4670 Acc: 50.0000%\n",
      "\ttrain 18-187: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 18-188: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 18-189: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 18-190: Loss: 0.1754 Acc: 75.0000%\n",
      "\ttrain 18-191: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 18-192: Loss: 0.1154 Acc: 50.0000%\n",
      "\ttrain 18-193: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 18-194: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 18-195: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 18-196: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 18-197: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 18-198: Loss: 0.1178 Acc: 100.0000%\n",
      "\ttrain 18-199: Loss: 0.1310 Acc: 50.0000%\n",
      "\ttrain 18-200: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 18-201: Loss: 0.1403 Acc: 50.0000%\n",
      "\ttrain 18-202: Loss: 0.1670 Acc: 25.0000%\n",
      "\ttrain 18-203: Loss: 0.0832 Acc: 100.0000%\n",
      "\ttrain 18-204: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 18-205: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 18-206: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 18-207: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 18-208: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 18-209: Loss: 0.1436 Acc: 50.0000%\n",
      "\ttrain 18-210: Loss: 0.1293 Acc: 100.0000%\n",
      "\ttrain 18-211: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 18-212: Loss: 0.1214 Acc: 100.0000%\n",
      "\ttrain 18-213: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 18-214: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 18-215: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 18-216: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 18-217: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 18-218: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 18-219: Loss: 0.0935 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-220: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 18-221: Loss: 0.0776 Acc: 100.0000%\n",
      "\ttrain 18-222: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 18-223: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 18-224: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 18-225: Loss: 0.1944 Acc: 50.0000%\n",
      "\ttrain 18-226: Loss: 0.1311 Acc: 50.0000%\n",
      "\ttrain 18-227: Loss: 0.1047 Acc: 100.0000%\n",
      "\ttrain 18-228: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 18-229: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 18-230: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 18-231: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 18-232: Loss: 0.0508 Acc: 75.0000%\n",
      "\ttrain 18-233: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 18-234: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 18-235: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 18-236: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 18-237: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 18-238: Loss: 0.0952 Acc: 50.0000%\n",
      "\ttrain 18-239: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 18-240: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 18-241: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 18-242: Loss: 0.1475 Acc: 50.0000%\n",
      "\ttrain 18-243: Loss: 0.2484 Acc: 50.0000%\n",
      "\ttrain 18-244: Loss: 0.0917 Acc: 100.0000%\n",
      "\ttrain 18-245: Loss: 0.0475 Acc: 75.0000%\n",
      "\tvalidation 18-1: Loss: 0.1309 Acc: 50.0000%\n",
      "\tvalidation 18-2: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 18-3: Loss: 0.1384 Acc: 50.0000%\n",
      "\tvalidation 18-4: Loss: 0.1065 Acc: 100.0000%\n",
      "\tvalidation 18-5: Loss: 0.1191 Acc: 50.0000%\n",
      "\tvalidation 18-6: Loss: 0.0955 Acc: 75.0000%\n",
      "\tvalidation 18-7: Loss: 0.0381 Acc: 100.0000%\n",
      "\tvalidation 18-8: Loss: 0.1031 Acc: 75.0000%\n",
      "\tvalidation 18-9: Loss: 0.0739 Acc: 100.0000%\n",
      "\tvalidation 18-10: Loss: 0.0779 Acc: 100.0000%\n",
      "\tvalidation 18-11: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 18-12: Loss: 0.1469 Acc: 25.0000%\n",
      "\tvalidation 18-13: Loss: 0.3884 Acc: 75.0000%\n",
      "\tvalidation 18-14: Loss: 0.1032 Acc: 100.0000%\n",
      "\tvalidation 18-15: Loss: 0.1418 Acc: 50.0000%\n",
      "\tvalidation 18-16: Loss: 0.1153 Acc: 75.0000%\n",
      "\tvalidation 18-17: Loss: 0.1098 Acc: 75.0000%\n",
      "\tvalidation 18-18: Loss: 0.1588 Acc: 75.0000%\n",
      "\tvalidation 18-19: Loss: 0.1081 Acc: 100.0000%\n",
      "\tvalidation 18-20: Loss: 0.0469 Acc: 75.0000%\n",
      "\tvalidation 18-21: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 18-22: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 18-23: Loss: 0.1743 Acc: 50.0000%\n",
      "\tvalidation 18-24: Loss: 0.0729 Acc: 75.0000%\n",
      "\tvalidation 18-25: Loss: 0.0956 Acc: 100.0000%\n",
      "\tvalidation 18-26: Loss: 0.0675 Acc: 75.0000%\n",
      "\tvalidation 18-27: Loss: 0.0984 Acc: 75.0000%\n",
      "\tvalidation 18-28: Loss: 0.0444 Acc: 75.0000%\n",
      "\tvalidation 18-29: Loss: 0.0462 Acc: 75.0000%\n",
      "\tvalidation 18-30: Loss: 0.0837 Acc: 75.0000%\n",
      "\tvalidation 18-31: Loss: 0.0446 Acc: 75.0000%\n",
      "\tvalidation 18-32: Loss: 0.1093 Acc: 100.0000%\n",
      "\tvalidation 18-33: Loss: 0.1259 Acc: 50.0000%\n",
      "\tvalidation 18-34: Loss: 0.1011 Acc: 100.0000%\n",
      "\tvalidation 18-35: Loss: 0.0805 Acc: 100.0000%\n",
      "\tvalidation 18-36: Loss: 0.0861 Acc: 75.0000%\n",
      "\tvalidation 18-37: Loss: 0.0411 Acc: 100.0000%\n",
      "\tvalidation 18-38: Loss: 0.1698 Acc: 50.0000%\n",
      "\tvalidation 18-39: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 18-40: Loss: 0.0581 Acc: 100.0000%\n",
      "\tvalidation 18-41: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-42: Loss: 0.0813 Acc: 75.0000%\n",
      "\tvalidation 18-43: Loss: 0.0646 Acc: 75.0000%\n",
      "\tvalidation 18-44: Loss: 0.1337 Acc: 50.0000%\n",
      "\tvalidation 18-45: Loss: 0.0992 Acc: 75.0000%\n",
      "\tvalidation 18-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-47: Loss: 0.0781 Acc: 100.0000%\n",
      "\tvalidation 18-48: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 18-49: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 18-50: Loss: 0.0990 Acc: 75.0000%\n",
      "\tvalidation 18-51: Loss: 0.0922 Acc: 75.0000%\n",
      "\tvalidation 18-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-53: Loss: 0.0531 Acc: 75.0000%\n",
      "\tvalidation 18-54: Loss: 0.1829 Acc: 25.0000%\n",
      "\tvalidation 18-55: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 18-56: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 18-57: Loss: 0.0486 Acc: 100.0000%\n",
      "\tvalidation 18-58: Loss: 0.1102 Acc: 100.0000%\n",
      "\tvalidation 18-59: Loss: 0.1644 Acc: 75.0000%\n",
      "\tvalidation 18-60: Loss: 0.0669 Acc: 75.0000%\n",
      "\tvalidation 18-61: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 18-62: Loss: 0.0596 Acc: 100.0000%\n",
      "\tvalidation 18-63: Loss: 0.0989 Acc: 75.0000%\n",
      "\tvalidation 18-64: Loss: 0.0506 Acc: 75.0000%\n",
      "\tvalidation 18-65: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 18-66: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 18-67: Loss: 0.1202 Acc: 75.0000%\n",
      "\tvalidation 18-68: Loss: 0.0914 Acc: 75.0000%\n",
      "\tvalidation 18-69: Loss: 0.0446 Acc: 75.0000%\n",
      "\tvalidation 18-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-71: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 18-72: Loss: 0.1244 Acc: 75.0000%\n",
      "\tvalidation 18-73: Loss: 0.0863 Acc: 75.0000%\n",
      "\tvalidation 18-74: Loss: 0.1051 Acc: 100.0000%\n",
      "\tvalidation 18-75: Loss: 0.0870 Acc: 75.0000%\n",
      "\tvalidation 18-76: Loss: 0.1248 Acc: 75.0000%\n",
      "\tvalidation 18-77: Loss: 0.0990 Acc: 100.0000%\n",
      "\tvalidation 18-78: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 18-79: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 18-80: Loss: 0.0917 Acc: 50.0000%\n",
      "\tvalidation 18-81: Loss: 0.0882 Acc: 75.0000%\n",
      "\tvalidation 18-82: Loss: 0.0690 Acc: 100.0000%\n",
      "\tvalidation 18-83: Loss: 0.0991 Acc: 75.0000%\n",
      "\tvalidation 18-84: Loss: 0.0502 Acc: 75.0000%\n",
      "\tvalidation 18-85: Loss: 0.0893 Acc: 50.0000%\n",
      "\tvalidation 18-86: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 18-87: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 18-88: Loss: 0.1198 Acc: 50.0000%\n",
      "\tvalidation 18-89: Loss: 0.0610 Acc: 75.0000%\n",
      "\tvalidation 18-90: Loss: 0.1592 Acc: 75.0000%\n",
      "\tvalidation 18-91: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 18-92: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 18-93: Loss: 0.1247 Acc: 50.0000%\n",
      "\tvalidation 18-94: Loss: 0.1340 Acc: 75.0000%\n",
      "\tvalidation 18-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-96: Loss: 0.0987 Acc: 75.0000%\n",
      "\tvalidation 18-97: Loss: 0.1403 Acc: 50.0000%\n",
      "\tvalidation 18-98: Loss: 0.0324 Acc: 100.0000%\n",
      "\tvalidation 18-99: Loss: 0.1028 Acc: 100.0000%\n",
      "\tvalidation 18-100: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 18-101: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 18-102: Loss: 0.0438 Acc: 75.0000%\n",
      "\tvalidation 18-103: Loss: 0.1157 Acc: 75.0000%\n",
      "\tvalidation 18-104: Loss: 0.0800 Acc: 75.0000%\n",
      "\tvalidation 18-105: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1037 Acc: 77.8571%\n",
      "\tvalidation Loss: 0.0833 Acc: 81.1905%\n",
      "Time passed 0h 13m 59s\n",
      "--------------------\n",
      "Epoch [19/40]:\n",
      "\ttrain 19-1: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 19-2: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 19-3: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 19-4: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 19-5: Loss: 0.1072 Acc: 100.0000%\n",
      "\ttrain 19-6: Loss: 0.2996 Acc: 0.0000%\n",
      "\ttrain 19-7: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 19-8: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 19-9: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 19-10: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 19-11: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 19-12: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 19-13: Loss: 0.1947 Acc: 50.0000%\n",
      "\ttrain 19-14: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 19-15: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 19-16: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 19-17: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 19-18: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 19-19: Loss: 0.1926 Acc: 50.0000%\n",
      "\ttrain 19-20: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 19-21: Loss: 0.1840 Acc: 50.0000%\n",
      "\ttrain 19-22: Loss: 0.1057 Acc: 100.0000%\n",
      "\ttrain 19-23: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 19-24: Loss: 0.1105 Acc: 50.0000%\n",
      "\ttrain 19-25: Loss: 0.1727 Acc: 50.0000%\n",
      "\ttrain 19-26: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 19-27: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 19-28: Loss: 0.0960 Acc: 100.0000%\n",
      "\ttrain 19-29: Loss: 0.1516 Acc: 50.0000%\n",
      "\ttrain 19-30: Loss: 0.1405 Acc: 50.0000%\n",
      "\ttrain 19-31: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 19-32: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 19-33: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 19-34: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 19-35: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 19-36: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 19-37: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 19-38: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 19-39: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 19-40: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 19-41: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 19-42: Loss: 0.3314 Acc: 75.0000%\n",
      "\ttrain 19-43: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 19-44: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 19-45: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 19-46: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 19-47: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 19-48: Loss: 0.1329 Acc: 100.0000%\n",
      "\ttrain 19-49: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 19-50: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 19-51: Loss: 0.0533 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-52: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 19-53: Loss: 0.1449 Acc: 75.0000%\n",
      "\ttrain 19-54: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 19-55: Loss: 0.1353 Acc: 100.0000%\n",
      "\ttrain 19-56: Loss: 0.0812 Acc: 100.0000%\n",
      "\ttrain 19-57: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 19-58: Loss: 0.1997 Acc: 50.0000%\n",
      "\ttrain 19-59: Loss: 0.1610 Acc: 50.0000%\n",
      "\ttrain 19-60: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 19-61: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 19-62: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 19-63: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 19-64: Loss: 0.3190 Acc: 75.0000%\n",
      "\ttrain 19-65: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 19-66: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 19-67: Loss: 0.1234 Acc: 50.0000%\n",
      "\ttrain 19-68: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 19-69: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 19-70: Loss: 0.2209 Acc: 25.0000%\n",
      "\ttrain 19-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 19-72: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 19-73: Loss: 0.1771 Acc: 50.0000%\n",
      "\ttrain 19-74: Loss: 0.0773 Acc: 100.0000%\n",
      "\ttrain 19-75: Loss: 0.2230 Acc: 75.0000%\n",
      "\ttrain 19-76: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 19-77: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 19-78: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 19-79: Loss: 0.1180 Acc: 100.0000%\n",
      "\ttrain 19-80: Loss: 0.0908 Acc: 100.0000%\n",
      "\ttrain 19-81: Loss: 0.1060 Acc: 100.0000%\n",
      "\ttrain 19-82: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 19-83: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 19-84: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 19-85: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 19-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 19-87: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 19-88: Loss: 0.0645 Acc: 100.0000%\n",
      "\ttrain 19-89: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 19-90: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 19-91: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 19-92: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 19-93: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 19-94: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 19-95: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 19-96: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 19-97: Loss: 0.0746 Acc: 100.0000%\n",
      "\ttrain 19-98: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 19-99: Loss: 0.0694 Acc: 100.0000%\n",
      "\ttrain 19-100: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 19-101: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 19-102: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 19-103: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 19-104: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 19-105: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 19-106: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 19-107: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 19-108: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 19-109: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 19-110: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 19-111: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 19-112: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 19-113: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 19-114: Loss: 0.1696 Acc: 50.0000%\n",
      "\ttrain 19-115: Loss: 0.3081 Acc: 50.0000%\n",
      "\ttrain 19-116: Loss: 0.0879 Acc: 100.0000%\n",
      "\ttrain 19-117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 19-118: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 19-119: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 19-120: Loss: 0.3050 Acc: 25.0000%\n",
      "\ttrain 19-121: Loss: 0.2917 Acc: 25.0000%\n",
      "\ttrain 19-122: Loss: 0.1333 Acc: 50.0000%\n",
      "\ttrain 19-123: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 19-124: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 19-125: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 19-126: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 19-127: Loss: 0.1038 Acc: 100.0000%\n",
      "\ttrain 19-128: Loss: 0.1103 Acc: 50.0000%\n",
      "\ttrain 19-129: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 19-130: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 19-131: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 19-132: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 19-133: Loss: 0.5158 Acc: 50.0000%\n",
      "\ttrain 19-134: Loss: 0.1847 Acc: 50.0000%\n",
      "\ttrain 19-135: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 19-136: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 19-137: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 19-138: Loss: 0.1450 Acc: 25.0000%\n",
      "\ttrain 19-139: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 19-140: Loss: 0.1853 Acc: 50.0000%\n",
      "\ttrain 19-141: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 19-142: Loss: 0.4832 Acc: 75.0000%\n",
      "\ttrain 19-143: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 19-144: Loss: 0.1258 Acc: 100.0000%\n",
      "\ttrain 19-145: Loss: 0.1737 Acc: 75.0000%\n",
      "\ttrain 19-146: Loss: 0.1314 Acc: 50.0000%\n",
      "\ttrain 19-147: Loss: 0.3038 Acc: 50.0000%\n",
      "\ttrain 19-148: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 19-149: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 19-150: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 19-151: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 19-152: Loss: 0.3491 Acc: 50.0000%\n",
      "\ttrain 19-153: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 19-154: Loss: 0.1703 Acc: 50.0000%\n",
      "\ttrain 19-155: Loss: 0.1461 Acc: 25.0000%\n",
      "\ttrain 19-156: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 19-157: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 19-158: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 19-159: Loss: 0.0899 Acc: 100.0000%\n",
      "\ttrain 19-160: Loss: 0.2377 Acc: 75.0000%\n",
      "\ttrain 19-161: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 19-162: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 19-163: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 19-164: Loss: 0.1030 Acc: 100.0000%\n",
      "\ttrain 19-165: Loss: 0.1484 Acc: 50.0000%\n",
      "\ttrain 19-166: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 19-167: Loss: 0.1032 Acc: 100.0000%\n",
      "\ttrain 19-168: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 19-169: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 19-170: Loss: 0.1742 Acc: 100.0000%\n",
      "\ttrain 19-171: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 19-172: Loss: 0.0748 Acc: 100.0000%\n",
      "\ttrain 19-173: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 19-174: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 19-175: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 19-176: Loss: 0.0563 Acc: 75.0000%\n",
      "\ttrain 19-177: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 19-178: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 19-179: Loss: 0.2223 Acc: 25.0000%\n",
      "\ttrain 19-180: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 19-181: Loss: 0.1861 Acc: 50.0000%\n",
      "\ttrain 19-182: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 19-183: Loss: 0.1057 Acc: 100.0000%\n",
      "\ttrain 19-184: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 19-185: Loss: 0.1922 Acc: 50.0000%\n",
      "\ttrain 19-186: Loss: 0.0600 Acc: 100.0000%\n",
      "\ttrain 19-187: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 19-188: Loss: 0.1058 Acc: 50.0000%\n",
      "\ttrain 19-189: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 19-190: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 19-191: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 19-192: Loss: 0.1922 Acc: 50.0000%\n",
      "\ttrain 19-193: Loss: 0.1655 Acc: 75.0000%\n",
      "\ttrain 19-194: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 19-195: Loss: 0.1796 Acc: 50.0000%\n",
      "\ttrain 19-196: Loss: 0.1076 Acc: 100.0000%\n",
      "\ttrain 19-197: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 19-198: Loss: 0.1742 Acc: 50.0000%\n",
      "\ttrain 19-199: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-200: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 19-201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 19-202: Loss: 0.1087 Acc: 100.0000%\n",
      "\ttrain 19-203: Loss: 0.2855 Acc: 75.0000%\n",
      "\ttrain 19-204: Loss: 0.0493 Acc: 75.0000%\n",
      "\ttrain 19-205: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 19-206: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 19-207: Loss: 0.0524 Acc: 75.0000%\n",
      "\ttrain 19-208: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 19-209: Loss: 0.2937 Acc: 75.0000%\n",
      "\ttrain 19-210: Loss: 0.1541 Acc: 50.0000%\n",
      "\ttrain 19-211: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 19-212: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 19-213: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 19-214: Loss: 0.0492 Acc: 75.0000%\n",
      "\ttrain 19-215: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 19-216: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 19-217: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 19-218: Loss: 0.1621 Acc: 75.0000%\n",
      "\ttrain 19-219: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 19-220: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 19-221: Loss: 0.0965 Acc: 100.0000%\n",
      "\ttrain 19-222: Loss: 0.1326 Acc: 100.0000%\n",
      "\ttrain 19-223: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 19-224: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 19-225: Loss: 0.0868 Acc: 100.0000%\n",
      "\ttrain 19-226: Loss: 0.0974 Acc: 50.0000%\n",
      "\ttrain 19-227: Loss: 0.1290 Acc: 50.0000%\n",
      "\ttrain 19-228: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 19-229: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 19-230: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 19-231: Loss: 0.0953 Acc: 100.0000%\n",
      "\ttrain 19-232: Loss: 0.0713 Acc: 100.0000%\n",
      "\ttrain 19-233: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 19-234: Loss: 0.1000 Acc: 50.0000%\n",
      "\ttrain 19-235: Loss: 0.1426 Acc: 50.0000%\n",
      "\ttrain 19-236: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 19-237: Loss: 0.0997 Acc: 50.0000%\n",
      "\ttrain 19-238: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 19-239: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 19-240: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 19-241: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 19-242: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 19-243: Loss: 0.0786 Acc: 100.0000%\n",
      "\ttrain 19-244: Loss: 0.1419 Acc: 50.0000%\n",
      "\ttrain 19-245: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 19-1: Loss: 0.0731 Acc: 100.0000%\n",
      "\tvalidation 19-2: Loss: 0.1330 Acc: 100.0000%\n",
      "\tvalidation 19-3: Loss: 0.0612 Acc: 100.0000%\n",
      "\tvalidation 19-4: Loss: 0.0475 Acc: 100.0000%\n",
      "\tvalidation 19-5: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 19-6: Loss: 0.0487 Acc: 100.0000%\n",
      "\tvalidation 19-7: Loss: 0.0702 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 19-8: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 19-9: Loss: 0.0775 Acc: 100.0000%\n",
      "\tvalidation 19-10: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 19-11: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 19-12: Loss: 0.0729 Acc: 75.0000%\n",
      "\tvalidation 19-13: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 19-14: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 19-15: Loss: 0.0646 Acc: 100.0000%\n",
      "\tvalidation 19-16: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 19-17: Loss: 0.0663 Acc: 100.0000%\n",
      "\tvalidation 19-18: Loss: 0.1194 Acc: 75.0000%\n",
      "\tvalidation 19-19: Loss: 0.0959 Acc: 100.0000%\n",
      "\tvalidation 19-20: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 19-21: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 19-22: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 19-23: Loss: 0.0510 Acc: 100.0000%\n",
      "\tvalidation 19-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-25: Loss: 0.1434 Acc: 75.0000%\n",
      "\tvalidation 19-26: Loss: 0.0407 Acc: 100.0000%\n",
      "\tvalidation 19-27: Loss: 0.0622 Acc: 100.0000%\n",
      "\tvalidation 19-28: Loss: 0.0578 Acc: 100.0000%\n",
      "\tvalidation 19-29: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 19-30: Loss: 0.0716 Acc: 100.0000%\n",
      "\tvalidation 19-31: Loss: 0.0865 Acc: 100.0000%\n",
      "\tvalidation 19-32: Loss: 0.1079 Acc: 75.0000%\n",
      "\tvalidation 19-33: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 19-34: Loss: 0.0617 Acc: 75.0000%\n",
      "\tvalidation 19-35: Loss: 0.0709 Acc: 75.0000%\n",
      "\tvalidation 19-36: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 19-37: Loss: 0.0372 Acc: 100.0000%\n",
      "\tvalidation 19-38: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 19-39: Loss: 0.0410 Acc: 100.0000%\n",
      "\tvalidation 19-40: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 19-41: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 19-42: Loss: 0.0521 Acc: 100.0000%\n",
      "\tvalidation 19-43: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 19-44: Loss: 0.0919 Acc: 100.0000%\n",
      "\tvalidation 19-45: Loss: 0.0497 Acc: 100.0000%\n",
      "\tvalidation 19-46: Loss: 0.0781 Acc: 75.0000%\n",
      "\tvalidation 19-47: Loss: 0.0901 Acc: 75.0000%\n",
      "\tvalidation 19-48: Loss: 0.0683 Acc: 100.0000%\n",
      "\tvalidation 19-49: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 19-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-51: Loss: 0.0540 Acc: 100.0000%\n",
      "\tvalidation 19-52: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 19-53: Loss: 0.1072 Acc: 75.0000%\n",
      "\tvalidation 19-54: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 19-55: Loss: 0.0839 Acc: 100.0000%\n",
      "\tvalidation 19-56: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 19-57: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 19-58: Loss: 0.0472 Acc: 100.0000%\n",
      "\tvalidation 19-59: Loss: 0.1226 Acc: 75.0000%\n",
      "\tvalidation 19-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-61: Loss: 0.0990 Acc: 75.0000%\n",
      "\tvalidation 19-62: Loss: 0.0906 Acc: 75.0000%\n",
      "\tvalidation 19-63: Loss: 0.0376 Acc: 100.0000%\n",
      "\tvalidation 19-64: Loss: 0.0527 Acc: 100.0000%\n",
      "\tvalidation 19-65: Loss: 0.0793 Acc: 100.0000%\n",
      "\tvalidation 19-66: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 19-67: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 19-68: Loss: 0.0480 Acc: 100.0000%\n",
      "\tvalidation 19-69: Loss: 0.0642 Acc: 100.0000%\n",
      "\tvalidation 19-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-71: Loss: 0.0787 Acc: 75.0000%\n",
      "\tvalidation 19-72: Loss: 0.0631 Acc: 100.0000%\n",
      "\tvalidation 19-73: Loss: 0.0619 Acc: 100.0000%\n",
      "\tvalidation 19-74: Loss: 0.0424 Acc: 100.0000%\n",
      "\tvalidation 19-75: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 19-76: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 19-77: Loss: 0.1319 Acc: 100.0000%\n",
      "\tvalidation 19-78: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 19-79: Loss: 0.1626 Acc: 25.0000%\n",
      "\tvalidation 19-80: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 19-81: Loss: 0.0542 Acc: 75.0000%\n",
      "\tvalidation 19-82: Loss: 0.1036 Acc: 75.0000%\n",
      "\tvalidation 19-83: Loss: 0.1356 Acc: 50.0000%\n",
      "\tvalidation 19-84: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 19-85: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 19-86: Loss: 0.0548 Acc: 100.0000%\n",
      "\tvalidation 19-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-88: Loss: 0.0553 Acc: 75.0000%\n",
      "\tvalidation 19-89: Loss: 0.0818 Acc: 100.0000%\n",
      "\tvalidation 19-90: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 19-91: Loss: 0.0739 Acc: 100.0000%\n",
      "\tvalidation 19-92: Loss: 0.1196 Acc: 100.0000%\n",
      "\tvalidation 19-93: Loss: 0.0618 Acc: 100.0000%\n",
      "\tvalidation 19-94: Loss: 0.0783 Acc: 100.0000%\n",
      "\tvalidation 19-95: Loss: 0.0398 Acc: 100.0000%\n",
      "\tvalidation 19-96: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 19-97: Loss: 0.0898 Acc: 100.0000%\n",
      "\tvalidation 19-98: Loss: 0.0445 Acc: 75.0000%\n",
      "\tvalidation 19-99: Loss: 0.0841 Acc: 100.0000%\n",
      "\tvalidation 19-100: Loss: 0.0938 Acc: 75.0000%\n",
      "\tvalidation 19-101: Loss: 0.1063 Acc: 75.0000%\n",
      "\tvalidation 19-102: Loss: 0.0830 Acc: 75.0000%\n",
      "\tvalidation 19-103: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 19-104: Loss: 0.0541 Acc: 100.0000%\n",
      "\tvalidation 19-105: Loss: 0.0435 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1039 Acc: 81.0204%\n",
      "\tvalidation Loss: 0.0608 Acc: 93.0952%\n",
      "网络参数更新\n",
      "Time passed 0h 14m 47s\n",
      "--------------------\n",
      "Epoch [20/40]:\n",
      "\ttrain 20-1: Loss: 0.0660 Acc: 100.0000%\n",
      "\ttrain 20-2: Loss: 0.2316 Acc: 75.0000%\n",
      "\ttrain 20-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 20-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 20-5: Loss: 0.2587 Acc: 75.0000%\n",
      "\ttrain 20-6: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 20-7: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 20-8: Loss: 0.1467 Acc: 50.0000%\n",
      "\ttrain 20-9: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 20-10: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 20-11: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 20-12: Loss: 0.1018 Acc: 100.0000%\n",
      "\ttrain 20-13: Loss: 0.0841 Acc: 100.0000%\n",
      "\ttrain 20-14: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 20-15: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 20-16: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 20-17: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 20-18: Loss: 0.0693 Acc: 100.0000%\n",
      "\ttrain 20-19: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 20-20: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 20-21: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 20-22: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 20-23: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 20-24: Loss: 0.1900 Acc: 50.0000%\n",
      "\ttrain 20-25: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 20-26: Loss: 0.0725 Acc: 75.0000%\n",
      "\ttrain 20-27: Loss: 0.2611 Acc: 50.0000%\n",
      "\ttrain 20-28: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 20-29: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 20-30: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 20-31: Loss: 0.0729 Acc: 100.0000%\n",
      "\ttrain 20-32: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 20-33: Loss: 0.2227 Acc: 50.0000%\n",
      "\ttrain 20-34: Loss: 0.3110 Acc: 50.0000%\n",
      "\ttrain 20-35: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 20-36: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 20-37: Loss: 0.3637 Acc: 50.0000%\n",
      "\ttrain 20-38: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 20-39: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 20-40: Loss: 0.1314 Acc: 50.0000%\n",
      "\ttrain 20-41: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 20-42: Loss: 0.2419 Acc: 25.0000%\n",
      "\ttrain 20-43: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 20-44: Loss: 0.0691 Acc: 100.0000%\n",
      "\ttrain 20-45: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 20-46: Loss: 0.1332 Acc: 75.0000%\n",
      "\ttrain 20-47: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 20-48: Loss: 0.1663 Acc: 50.0000%\n",
      "\ttrain 20-49: Loss: 0.1694 Acc: 50.0000%\n",
      "\ttrain 20-50: Loss: 0.1715 Acc: 50.0000%\n",
      "\ttrain 20-51: Loss: 0.1735 Acc: 75.0000%\n",
      "\ttrain 20-52: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 20-53: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 20-54: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 20-55: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 20-56: Loss: 0.1462 Acc: 50.0000%\n",
      "\ttrain 20-57: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 20-58: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 20-59: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 20-60: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 20-61: Loss: 0.1580 Acc: 50.0000%\n",
      "\ttrain 20-62: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 20-63: Loss: 0.1025 Acc: 100.0000%\n",
      "\ttrain 20-64: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 20-65: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 20-66: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 20-67: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 20-68: Loss: 0.1498 Acc: 50.0000%\n",
      "\ttrain 20-69: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 20-70: Loss: 0.1335 Acc: 50.0000%\n",
      "\ttrain 20-71: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 20-72: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 20-73: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 20-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 20-75: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 20-76: Loss: 0.0445 Acc: 75.0000%\n",
      "\ttrain 20-77: Loss: 0.0907 Acc: 100.0000%\n",
      "\ttrain 20-78: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 20-79: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 20-80: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 20-81: Loss: 0.2105 Acc: 75.0000%\n",
      "\ttrain 20-82: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 20-83: Loss: 0.0794 Acc: 100.0000%\n",
      "\ttrain 20-84: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 20-85: Loss: 0.1659 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-86: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 20-87: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 20-88: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 20-89: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 20-90: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 20-91: Loss: 0.0780 Acc: 100.0000%\n",
      "\ttrain 20-92: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 20-93: Loss: 0.0652 Acc: 100.0000%\n",
      "\ttrain 20-94: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 20-95: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 20-96: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 20-97: Loss: 0.2765 Acc: 50.0000%\n",
      "\ttrain 20-98: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 20-99: Loss: 0.1163 Acc: 50.0000%\n",
      "\ttrain 20-100: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 20-101: Loss: 0.2710 Acc: 75.0000%\n",
      "\ttrain 20-102: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 20-103: Loss: 0.2007 Acc: 50.0000%\n",
      "\ttrain 20-104: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 20-105: Loss: 0.1100 Acc: 75.0000%\n",
      "\ttrain 20-106: Loss: 0.0802 Acc: 100.0000%\n",
      "\ttrain 20-107: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 20-108: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 20-109: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 20-110: Loss: 0.0899 Acc: 100.0000%\n",
      "\ttrain 20-111: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 20-112: Loss: 0.1625 Acc: 75.0000%\n",
      "\ttrain 20-113: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 20-114: Loss: 0.1428 Acc: 50.0000%\n",
      "\ttrain 20-115: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 20-116: Loss: 0.1374 Acc: 50.0000%\n",
      "\ttrain 20-117: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 20-118: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 20-119: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 20-120: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 20-121: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 20-122: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 20-123: Loss: 0.1185 Acc: 50.0000%\n",
      "\ttrain 20-124: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 20-125: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 20-126: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 20-127: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 20-128: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 20-129: Loss: 0.0976 Acc: 100.0000%\n",
      "\ttrain 20-130: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 20-131: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 20-132: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 20-133: Loss: 0.2555 Acc: 50.0000%\n",
      "\ttrain 20-134: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 20-135: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 20-136: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 20-137: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 20-138: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 20-139: Loss: 0.1278 Acc: 100.0000%\n",
      "\ttrain 20-140: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 20-141: Loss: 0.2127 Acc: 75.0000%\n",
      "\ttrain 20-142: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 20-143: Loss: 0.1600 Acc: 50.0000%\n",
      "\ttrain 20-144: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 20-145: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 20-146: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 20-147: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 20-148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 20-149: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 20-150: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 20-151: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 20-152: Loss: 0.2224 Acc: 50.0000%\n",
      "\ttrain 20-153: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 20-154: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 20-155: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 20-156: Loss: 0.0883 Acc: 100.0000%\n",
      "\ttrain 20-157: Loss: 0.2151 Acc: 50.0000%\n",
      "\ttrain 20-158: Loss: 0.0690 Acc: 100.0000%\n",
      "\ttrain 20-159: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 20-160: Loss: 0.2185 Acc: 75.0000%\n",
      "\ttrain 20-161: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 20-162: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 20-163: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 20-164: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 20-165: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 20-166: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 20-167: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 20-168: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 20-169: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 20-170: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 20-171: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 20-172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 20-173: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 20-174: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 20-175: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 20-176: Loss: 0.2397 Acc: 75.0000%\n",
      "\ttrain 20-177: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 20-178: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 20-179: Loss: 0.2312 Acc: 50.0000%\n",
      "\ttrain 20-180: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 20-181: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 20-182: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 20-183: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 20-184: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 20-185: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 20-186: Loss: 0.0652 Acc: 100.0000%\n",
      "\ttrain 20-187: Loss: 0.2058 Acc: 75.0000%\n",
      "\ttrain 20-188: Loss: 0.2988 Acc: 50.0000%\n",
      "\ttrain 20-189: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 20-190: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 20-191: Loss: 0.1380 Acc: 50.0000%\n",
      "\ttrain 20-192: Loss: 0.1924 Acc: 75.0000%\n",
      "\ttrain 20-193: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 20-194: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 20-195: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 20-196: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 20-197: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 20-198: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 20-199: Loss: 0.1206 Acc: 50.0000%\n",
      "\ttrain 20-200: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 20-201: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 20-202: Loss: 0.1230 Acc: 50.0000%\n",
      "\ttrain 20-203: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 20-204: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 20-205: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 20-206: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 20-207: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 20-208: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 20-209: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 20-210: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 20-211: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 20-212: Loss: 0.2512 Acc: 50.0000%\n",
      "\ttrain 20-213: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 20-214: Loss: 0.0529 Acc: 75.0000%\n",
      "\ttrain 20-215: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 20-216: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 20-217: Loss: 0.1849 Acc: 75.0000%\n",
      "\ttrain 20-218: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 20-219: Loss: 0.2055 Acc: 75.0000%\n",
      "\ttrain 20-220: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 20-221: Loss: 0.2053 Acc: 50.0000%\n",
      "\ttrain 20-222: Loss: 0.0435 Acc: 75.0000%\n",
      "\ttrain 20-223: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 20-224: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 20-225: Loss: 0.1326 Acc: 75.0000%\n",
      "\ttrain 20-226: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 20-227: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 20-228: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 20-229: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 20-230: Loss: 0.4386 Acc: 50.0000%\n",
      "\ttrain 20-231: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 20-232: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 20-233: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 20-234: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 20-235: Loss: 0.1240 Acc: 50.0000%\n",
      "\ttrain 20-236: Loss: 0.2014 Acc: 25.0000%\n",
      "\ttrain 20-237: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 20-238: Loss: 0.0792 Acc: 100.0000%\n",
      "\ttrain 20-239: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 20-240: Loss: 0.0767 Acc: 100.0000%\n",
      "\ttrain 20-241: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 20-242: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 20-243: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 20-244: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 20-245: Loss: 0.1593 Acc: 75.0000%\n",
      "\tvalidation 20-1: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 20-2: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 20-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 20-4: Loss: 0.0684 Acc: 100.0000%\n",
      "\tvalidation 20-5: Loss: 0.1164 Acc: 50.0000%\n",
      "\tvalidation 20-6: Loss: 0.0494 Acc: 100.0000%\n",
      "\tvalidation 20-7: Loss: 0.0700 Acc: 100.0000%\n",
      "\tvalidation 20-8: Loss: 0.0848 Acc: 100.0000%\n",
      "\tvalidation 20-9: Loss: 0.0481 Acc: 100.0000%\n",
      "\tvalidation 20-10: Loss: 0.0611 Acc: 75.0000%\n",
      "\tvalidation 20-11: Loss: 0.0691 Acc: 75.0000%\n",
      "\tvalidation 20-12: Loss: 0.0356 Acc: 100.0000%\n",
      "\tvalidation 20-13: Loss: 0.0677 Acc: 75.0000%\n",
      "\tvalidation 20-14: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 20-15: Loss: 0.0780 Acc: 75.0000%\n",
      "\tvalidation 20-16: Loss: 0.0463 Acc: 75.0000%\n",
      "\tvalidation 20-17: Loss: 0.0667 Acc: 100.0000%\n",
      "\tvalidation 20-18: Loss: 0.1368 Acc: 50.0000%\n",
      "\tvalidation 20-19: Loss: 0.1241 Acc: 75.0000%\n",
      "\tvalidation 20-20: Loss: 0.0699 Acc: 75.0000%\n",
      "\tvalidation 20-21: Loss: 0.0997 Acc: 75.0000%\n",
      "\tvalidation 20-22: Loss: 0.0607 Acc: 75.0000%\n",
      "\tvalidation 20-23: Loss: 0.1143 Acc: 75.0000%\n",
      "\tvalidation 20-24: Loss: 0.1450 Acc: 50.0000%\n",
      "\tvalidation 20-25: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 20-26: Loss: 0.1357 Acc: 50.0000%\n",
      "\tvalidation 20-27: Loss: 0.0453 Acc: 100.0000%\n",
      "\tvalidation 20-28: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 20-29: Loss: 0.0472 Acc: 100.0000%\n",
      "\tvalidation 20-30: Loss: 0.1373 Acc: 50.0000%\n",
      "\tvalidation 20-31: Loss: 0.0559 Acc: 100.0000%\n",
      "\tvalidation 20-32: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 20-33: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 20-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-35: Loss: 0.0542 Acc: 100.0000%\n",
      "\tvalidation 20-36: Loss: 0.0228 Acc: 100.0000%\n",
      "\tvalidation 20-37: Loss: 0.0765 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 20-38: Loss: 0.0619 Acc: 75.0000%\n",
      "\tvalidation 20-39: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 20-40: Loss: 0.0490 Acc: 75.0000%\n",
      "\tvalidation 20-41: Loss: 0.1266 Acc: 75.0000%\n",
      "\tvalidation 20-42: Loss: 0.1313 Acc: 75.0000%\n",
      "\tvalidation 20-43: Loss: 0.1225 Acc: 75.0000%\n",
      "\tvalidation 20-44: Loss: 0.0756 Acc: 75.0000%\n",
      "\tvalidation 20-45: Loss: 0.1439 Acc: 50.0000%\n",
      "\tvalidation 20-46: Loss: 0.1613 Acc: 75.0000%\n",
      "\tvalidation 20-47: Loss: 0.1006 Acc: 75.0000%\n",
      "\tvalidation 20-48: Loss: 0.0463 Acc: 100.0000%\n",
      "\tvalidation 20-49: Loss: 0.0621 Acc: 100.0000%\n",
      "\tvalidation 20-50: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 20-51: Loss: 0.1644 Acc: 50.0000%\n",
      "\tvalidation 20-52: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-53: Loss: 0.1912 Acc: 25.0000%\n",
      "\tvalidation 20-54: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 20-55: Loss: 0.1377 Acc: 75.0000%\n",
      "\tvalidation 20-56: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 20-57: Loss: 0.0766 Acc: 75.0000%\n",
      "\tvalidation 20-58: Loss: 0.0552 Acc: 100.0000%\n",
      "\tvalidation 20-59: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 20-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 20-61: Loss: 0.1181 Acc: 50.0000%\n",
      "\tvalidation 20-62: Loss: 0.1002 Acc: 75.0000%\n",
      "\tvalidation 20-63: Loss: 0.0488 Acc: 100.0000%\n",
      "\tvalidation 20-64: Loss: 0.0787 Acc: 100.0000%\n",
      "\tvalidation 20-65: Loss: 0.1169 Acc: 75.0000%\n",
      "\tvalidation 20-66: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 20-67: Loss: 0.0883 Acc: 75.0000%\n",
      "\tvalidation 20-68: Loss: 0.1156 Acc: 75.0000%\n",
      "\tvalidation 20-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-70: Loss: 0.0917 Acc: 100.0000%\n",
      "\tvalidation 20-71: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 20-72: Loss: 0.2497 Acc: 50.0000%\n",
      "\tvalidation 20-73: Loss: 0.1421 Acc: 75.0000%\n",
      "\tvalidation 20-74: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 20-75: Loss: 0.1769 Acc: 25.0000%\n",
      "\tvalidation 20-76: Loss: 0.1582 Acc: 50.0000%\n",
      "\tvalidation 20-77: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 20-78: Loss: 0.1458 Acc: 50.0000%\n",
      "\tvalidation 20-79: Loss: 0.1593 Acc: 50.0000%\n",
      "\tvalidation 20-80: Loss: 0.0908 Acc: 75.0000%\n",
      "\tvalidation 20-81: Loss: 0.1572 Acc: 50.0000%\n",
      "\tvalidation 20-82: Loss: 0.1700 Acc: 50.0000%\n",
      "\tvalidation 20-83: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 20-84: Loss: 0.0779 Acc: 75.0000%\n",
      "\tvalidation 20-85: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 20-86: Loss: 0.1870 Acc: 25.0000%\n",
      "\tvalidation 20-87: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 20-88: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 20-89: Loss: 0.1519 Acc: 50.0000%\n",
      "\tvalidation 20-90: Loss: 0.0622 Acc: 75.0000%\n",
      "\tvalidation 20-91: Loss: 0.0826 Acc: 75.0000%\n",
      "\tvalidation 20-92: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 20-93: Loss: 0.1928 Acc: 25.0000%\n",
      "\tvalidation 20-94: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 20-95: Loss: 0.0809 Acc: 75.0000%\n",
      "\tvalidation 20-96: Loss: 0.0727 Acc: 75.0000%\n",
      "\tvalidation 20-97: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 20-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-99: Loss: 0.0753 Acc: 75.0000%\n",
      "\tvalidation 20-100: Loss: 0.0826 Acc: 75.0000%\n",
      "\tvalidation 20-101: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 20-102: Loss: 0.0894 Acc: 50.0000%\n",
      "\tvalidation 20-103: Loss: 0.1182 Acc: 50.0000%\n",
      "\tvalidation 20-104: Loss: 0.0693 Acc: 75.0000%\n",
      "\tvalidation 20-105: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0950 Acc: 81.9388%\n",
      "\tvalidation Loss: 0.0807 Acc: 79.7619%\n",
      "Time passed 0h 15m 33s\n",
      "--------------------\n",
      "Epoch [21/40]:\n",
      "\ttrain 21-1: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 21-2: Loss: 0.1647 Acc: 50.0000%\n",
      "\ttrain 21-3: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 21-4: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 21-5: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 21-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-8: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 21-9: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 21-10: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 21-11: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 21-12: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 21-13: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 21-14: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 21-15: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 21-16: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 21-17: Loss: 0.1205 Acc: 100.0000%\n",
      "\ttrain 21-18: Loss: 0.2231 Acc: 75.0000%\n",
      "\ttrain 21-19: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 21-20: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 21-21: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 21-22: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 21-23: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 21-24: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 21-25: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 21-26: Loss: 0.4060 Acc: 50.0000%\n",
      "\ttrain 21-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-28: Loss: 0.0866 Acc: 100.0000%\n",
      "\ttrain 21-29: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 21-30: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 21-31: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 21-32: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 21-33: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 21-34: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 21-35: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 21-36: Loss: 0.0809 Acc: 100.0000%\n",
      "\ttrain 21-37: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 21-38: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 21-39: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 21-40: Loss: 0.1325 Acc: 50.0000%\n",
      "\ttrain 21-41: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-42: Loss: 0.1538 Acc: 75.0000%\n",
      "\ttrain 21-43: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 21-44: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 21-45: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 21-46: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 21-47: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 21-48: Loss: 0.1280 Acc: 75.0000%\n",
      "\ttrain 21-49: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 21-50: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 21-51: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 21-52: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 21-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-54: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 21-55: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 21-56: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 21-57: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 21-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-59: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 21-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-61: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 21-62: Loss: 0.0741 Acc: 75.0000%\n",
      "\ttrain 21-63: Loss: 0.9039 Acc: 25.0000%\n",
      "\ttrain 21-64: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 21-65: Loss: 0.1979 Acc: 75.0000%\n",
      "\ttrain 21-66: Loss: 0.5481 Acc: 50.0000%\n",
      "\ttrain 21-67: Loss: 0.3761 Acc: 50.0000%\n",
      "\ttrain 21-68: Loss: 0.3458 Acc: 25.0000%\n",
      "\ttrain 21-69: Loss: 0.3605 Acc: 75.0000%\n",
      "\ttrain 21-70: Loss: 0.4316 Acc: 25.0000%\n",
      "\ttrain 21-71: Loss: 0.2006 Acc: 50.0000%\n",
      "\ttrain 21-72: Loss: 0.2767 Acc: 50.0000%\n",
      "\ttrain 21-73: Loss: 0.2527 Acc: 25.0000%\n",
      "\ttrain 21-74: Loss: 0.2753 Acc: 25.0000%\n",
      "\ttrain 21-75: Loss: 0.2298 Acc: 50.0000%\n",
      "\ttrain 21-76: Loss: 0.1652 Acc: 50.0000%\n",
      "\ttrain 21-77: Loss: 0.1360 Acc: 50.0000%\n",
      "\ttrain 21-78: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 21-79: Loss: 0.0881 Acc: 100.0000%\n",
      "\ttrain 21-80: Loss: 0.1105 Acc: 100.0000%\n",
      "\ttrain 21-81: Loss: 0.0844 Acc: 100.0000%\n",
      "\ttrain 21-82: Loss: 0.3441 Acc: 50.0000%\n",
      "\ttrain 21-83: Loss: 0.1270 Acc: 100.0000%\n",
      "\ttrain 21-84: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 21-85: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 21-86: Loss: 0.1801 Acc: 75.0000%\n",
      "\ttrain 21-87: Loss: 0.1214 Acc: 50.0000%\n",
      "\ttrain 21-88: Loss: 0.2871 Acc: 25.0000%\n",
      "\ttrain 21-89: Loss: 0.2000 Acc: 75.0000%\n",
      "\ttrain 21-90: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 21-91: Loss: 0.1863 Acc: 75.0000%\n",
      "\ttrain 21-92: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 21-93: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 21-94: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 21-95: Loss: 0.1183 Acc: 100.0000%\n",
      "\ttrain 21-96: Loss: 0.1089 Acc: 75.0000%\n",
      "\ttrain 21-97: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 21-98: Loss: 0.1094 Acc: 100.0000%\n",
      "\ttrain 21-99: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 21-100: Loss: 0.1555 Acc: 50.0000%\n",
      "\ttrain 21-101: Loss: 0.1494 Acc: 50.0000%\n",
      "\ttrain 21-102: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 21-103: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 21-104: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 21-105: Loss: 0.2062 Acc: 75.0000%\n",
      "\ttrain 21-106: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 21-107: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 21-108: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 21-109: Loss: 0.1414 Acc: 50.0000%\n",
      "\ttrain 21-110: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 21-111: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 21-112: Loss: 0.1376 Acc: 50.0000%\n",
      "\ttrain 21-113: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 21-114: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 21-115: Loss: 0.1989 Acc: 0.0000%\n",
      "\ttrain 21-116: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-117: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 21-118: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 21-119: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 21-120: Loss: 0.1444 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-121: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 21-122: Loss: 0.0785 Acc: 75.0000%\n",
      "\ttrain 21-123: Loss: 0.1722 Acc: 50.0000%\n",
      "\ttrain 21-124: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 21-125: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 21-126: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 21-127: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 21-128: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 21-129: Loss: 0.0903 Acc: 100.0000%\n",
      "\ttrain 21-130: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 21-131: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 21-132: Loss: 0.1364 Acc: 100.0000%\n",
      "\ttrain 21-133: Loss: 0.1158 Acc: 75.0000%\n",
      "\ttrain 21-134: Loss: 0.1198 Acc: 50.0000%\n",
      "\ttrain 21-135: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 21-136: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 21-137: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 21-138: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 21-139: Loss: 0.1790 Acc: 50.0000%\n",
      "\ttrain 21-140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-141: Loss: 0.1121 Acc: 100.0000%\n",
      "\ttrain 21-142: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 21-143: Loss: 0.2228 Acc: 75.0000%\n",
      "\ttrain 21-144: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 21-145: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 21-146: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 21-147: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 21-148: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 21-149: Loss: 0.1732 Acc: 50.0000%\n",
      "\ttrain 21-150: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 21-151: Loss: 0.0776 Acc: 75.0000%\n",
      "\ttrain 21-152: Loss: 0.0721 Acc: 75.0000%\n",
      "\ttrain 21-153: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 21-154: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 21-155: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 21-156: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 21-157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-158: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 21-159: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 21-160: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-161: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 21-162: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 21-163: Loss: 0.0518 Acc: 75.0000%\n",
      "\ttrain 21-164: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 21-165: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 21-166: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 21-167: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 21-168: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 21-169: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 21-170: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 21-171: Loss: 0.1629 Acc: 50.0000%\n",
      "\ttrain 21-172: Loss: 0.1431 Acc: 75.0000%\n",
      "\ttrain 21-173: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 21-174: Loss: 0.0472 Acc: 75.0000%\n",
      "\ttrain 21-175: Loss: 0.0979 Acc: 100.0000%\n",
      "\ttrain 21-176: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-177: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 21-178: Loss: 0.1564 Acc: 50.0000%\n",
      "\ttrain 21-179: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 21-180: Loss: 0.1609 Acc: 50.0000%\n",
      "\ttrain 21-181: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 21-182: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 21-183: Loss: 0.0728 Acc: 100.0000%\n",
      "\ttrain 21-184: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 21-185: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 21-186: Loss: 0.2291 Acc: 75.0000%\n",
      "\ttrain 21-187: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 21-188: Loss: 0.1657 Acc: 50.0000%\n",
      "\ttrain 21-189: Loss: 0.2092 Acc: 75.0000%\n",
      "\ttrain 21-190: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 21-191: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 21-192: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 21-193: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 21-194: Loss: 0.1863 Acc: 50.0000%\n",
      "\ttrain 21-195: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 21-196: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 21-197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-198: Loss: 0.1944 Acc: 75.0000%\n",
      "\ttrain 21-199: Loss: 0.1643 Acc: 100.0000%\n",
      "\ttrain 21-200: Loss: 0.0920 Acc: 100.0000%\n",
      "\ttrain 21-201: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 21-202: Loss: 0.1685 Acc: 50.0000%\n",
      "\ttrain 21-203: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 21-204: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 21-205: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 21-206: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 21-207: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 21-208: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 21-209: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 21-210: Loss: 0.1328 Acc: 50.0000%\n",
      "\ttrain 21-211: Loss: 0.1376 Acc: 50.0000%\n",
      "\ttrain 21-212: Loss: 0.1503 Acc: 50.0000%\n",
      "\ttrain 21-213: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 21-214: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 21-215: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 21-216: Loss: 0.1777 Acc: 50.0000%\n",
      "\ttrain 21-217: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 21-218: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 21-219: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 21-220: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 21-221: Loss: 0.1185 Acc: 50.0000%\n",
      "\ttrain 21-222: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-223: Loss: 0.1715 Acc: 50.0000%\n",
      "\ttrain 21-224: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 21-225: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 21-226: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 21-227: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-228: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-229: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 21-230: Loss: 0.1836 Acc: 50.0000%\n",
      "\ttrain 21-231: Loss: 0.2325 Acc: 50.0000%\n",
      "\ttrain 21-232: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 21-233: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 21-234: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 21-235: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 21-236: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 21-237: Loss: 0.1241 Acc: 75.0000%\n",
      "\ttrain 21-238: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 21-239: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 21-240: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 21-241: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 21-242: Loss: 0.1204 Acc: 50.0000%\n",
      "\ttrain 21-243: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 21-244: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 21-245: Loss: 0.1174 Acc: 100.0000%\n",
      "\tvalidation 21-1: Loss: 0.0815 Acc: 75.0000%\n",
      "\tvalidation 21-2: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 21-3: Loss: 0.0662 Acc: 75.0000%\n",
      "\tvalidation 21-4: Loss: 0.1082 Acc: 100.0000%\n",
      "\tvalidation 21-5: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 21-6: Loss: 0.0884 Acc: 75.0000%\n",
      "\tvalidation 21-7: Loss: 0.0629 Acc: 75.0000%\n",
      "\tvalidation 21-8: Loss: 0.0553 Acc: 100.0000%\n",
      "\tvalidation 21-9: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 21-10: Loss: 0.1208 Acc: 75.0000%\n",
      "\tvalidation 21-11: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 21-12: Loss: 0.0688 Acc: 100.0000%\n",
      "\tvalidation 21-13: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 21-14: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 21-15: Loss: 0.0864 Acc: 75.0000%\n",
      "\tvalidation 21-16: Loss: 0.0907 Acc: 100.0000%\n",
      "\tvalidation 21-17: Loss: 0.1130 Acc: 100.0000%\n",
      "\tvalidation 21-18: Loss: 0.0509 Acc: 100.0000%\n",
      "\tvalidation 21-19: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 21-20: Loss: 0.1230 Acc: 75.0000%\n",
      "\tvalidation 21-21: Loss: 0.1746 Acc: 50.0000%\n",
      "\tvalidation 21-22: Loss: 0.0671 Acc: 100.0000%\n",
      "\tvalidation 21-23: Loss: 0.0792 Acc: 75.0000%\n",
      "\tvalidation 21-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-25: Loss: 0.0771 Acc: 75.0000%\n",
      "\tvalidation 21-26: Loss: 0.1116 Acc: 75.0000%\n",
      "\tvalidation 21-27: Loss: 0.0779 Acc: 75.0000%\n",
      "\tvalidation 21-28: Loss: 0.0821 Acc: 75.0000%\n",
      "\tvalidation 21-29: Loss: 0.0769 Acc: 100.0000%\n",
      "\tvalidation 21-30: Loss: 0.0464 Acc: 100.0000%\n",
      "\tvalidation 21-31: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 21-32: Loss: 0.0558 Acc: 100.0000%\n",
      "\tvalidation 21-33: Loss: 0.0708 Acc: 100.0000%\n",
      "\tvalidation 21-34: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 21-35: Loss: 0.0542 Acc: 100.0000%\n",
      "\tvalidation 21-36: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 21-37: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 21-38: Loss: 0.0501 Acc: 75.0000%\n",
      "\tvalidation 21-39: Loss: 0.0448 Acc: 75.0000%\n",
      "\tvalidation 21-40: Loss: 0.0916 Acc: 100.0000%\n",
      "\tvalidation 21-41: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 21-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-43: Loss: 0.1173 Acc: 75.0000%\n",
      "\tvalidation 21-44: Loss: 0.0523 Acc: 75.0000%\n",
      "\tvalidation 21-45: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 21-46: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 21-47: Loss: 0.0719 Acc: 75.0000%\n",
      "\tvalidation 21-48: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 21-49: Loss: 0.1137 Acc: 100.0000%\n",
      "\tvalidation 21-50: Loss: 0.1340 Acc: 75.0000%\n",
      "\tvalidation 21-51: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 21-52: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 21-53: Loss: 0.1377 Acc: 75.0000%\n",
      "\tvalidation 21-54: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 21-55: Loss: 0.0693 Acc: 75.0000%\n",
      "\tvalidation 21-56: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 21-57: Loss: 0.0631 Acc: 100.0000%\n",
      "\tvalidation 21-58: Loss: 0.0524 Acc: 100.0000%\n",
      "\tvalidation 21-59: Loss: 0.1058 Acc: 100.0000%\n",
      "\tvalidation 21-60: Loss: 0.0833 Acc: 75.0000%\n",
      "\tvalidation 21-61: Loss: 0.0537 Acc: 100.0000%\n",
      "\tvalidation 21-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-64: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 21-65: Loss: 0.0831 Acc: 100.0000%\n",
      "\tvalidation 21-66: Loss: 0.1255 Acc: 75.0000%\n",
      "\tvalidation 21-67: Loss: 0.0795 Acc: 100.0000%\n",
      "\tvalidation 21-68: Loss: 0.1185 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 21-69: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-70: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 21-71: Loss: 0.1164 Acc: 50.0000%\n",
      "\tvalidation 21-72: Loss: 0.1128 Acc: 50.0000%\n",
      "\tvalidation 21-73: Loss: 0.0593 Acc: 100.0000%\n",
      "\tvalidation 21-74: Loss: 0.0560 Acc: 75.0000%\n",
      "\tvalidation 21-75: Loss: 0.0786 Acc: 75.0000%\n",
      "\tvalidation 21-76: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 21-77: Loss: 0.1030 Acc: 75.0000%\n",
      "\tvalidation 21-78: Loss: 0.0536 Acc: 100.0000%\n",
      "\tvalidation 21-79: Loss: 0.0532 Acc: 100.0000%\n",
      "\tvalidation 21-80: Loss: 0.0661 Acc: 100.0000%\n",
      "\tvalidation 21-81: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 21-82: Loss: 0.0620 Acc: 100.0000%\n",
      "\tvalidation 21-83: Loss: 0.1292 Acc: 50.0000%\n",
      "\tvalidation 21-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-85: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 21-86: Loss: 0.1373 Acc: 75.0000%\n",
      "\tvalidation 21-87: Loss: 0.1022 Acc: 100.0000%\n",
      "\tvalidation 21-88: Loss: 0.0496 Acc: 100.0000%\n",
      "\tvalidation 21-89: Loss: 0.0867 Acc: 75.0000%\n",
      "\tvalidation 21-90: Loss: 0.1255 Acc: 75.0000%\n",
      "\tvalidation 21-91: Loss: 0.1024 Acc: 75.0000%\n",
      "\tvalidation 21-92: Loss: 0.1182 Acc: 75.0000%\n",
      "\tvalidation 21-93: Loss: 0.0949 Acc: 100.0000%\n",
      "\tvalidation 21-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-95: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 21-96: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 21-97: Loss: 0.0851 Acc: 100.0000%\n",
      "\tvalidation 21-98: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 21-99: Loss: 0.0714 Acc: 100.0000%\n",
      "\tvalidation 21-100: Loss: 0.1091 Acc: 75.0000%\n",
      "\tvalidation 21-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-102: Loss: 0.0873 Acc: 100.0000%\n",
      "\tvalidation 21-103: Loss: 0.0781 Acc: 100.0000%\n",
      "\tvalidation 21-104: Loss: 0.1319 Acc: 100.0000%\n",
      "\tvalidation 21-105: Loss: 0.0831 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1062 Acc: 80.3061%\n",
      "\tvalidation Loss: 0.0683 Acc: 89.2857%\n",
      "Time passed 0h 16m 17s\n",
      "--------------------\n",
      "Epoch [22/40]:\n",
      "\ttrain 22-1: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 22-2: Loss: 0.1959 Acc: 75.0000%\n",
      "\ttrain 22-3: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 22-4: Loss: 0.0547 Acc: 75.0000%\n",
      "\ttrain 22-5: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 22-6: Loss: 0.1569 Acc: 50.0000%\n",
      "\ttrain 22-7: Loss: 0.0491 Acc: 75.0000%\n",
      "\ttrain 22-8: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 22-9: Loss: 0.2272 Acc: 75.0000%\n",
      "\ttrain 22-10: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 22-11: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 22-12: Loss: 0.2717 Acc: 25.0000%\n",
      "\ttrain 22-13: Loss: 0.0897 Acc: 100.0000%\n",
      "\ttrain 22-14: Loss: 0.3198 Acc: 25.0000%\n",
      "\ttrain 22-15: Loss: 0.0895 Acc: 100.0000%\n",
      "\ttrain 22-16: Loss: 0.0734 Acc: 100.0000%\n",
      "\ttrain 22-17: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 22-18: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 22-19: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 22-20: Loss: 0.3966 Acc: 75.0000%\n",
      "\ttrain 22-21: Loss: 0.0772 Acc: 100.0000%\n",
      "\ttrain 22-22: Loss: 0.0659 Acc: 100.0000%\n",
      "\ttrain 22-23: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 22-24: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 22-25: Loss: 0.1943 Acc: 25.0000%\n",
      "\ttrain 22-26: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 22-27: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 22-28: Loss: 0.0899 Acc: 100.0000%\n",
      "\ttrain 22-29: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 22-30: Loss: 0.0876 Acc: 100.0000%\n",
      "\ttrain 22-31: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 22-32: Loss: 0.1928 Acc: 50.0000%\n",
      "\ttrain 22-33: Loss: 0.0939 Acc: 75.0000%\n",
      "\ttrain 22-34: Loss: 0.1167 Acc: 100.0000%\n",
      "\ttrain 22-35: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 22-36: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 22-37: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 22-38: Loss: 0.0889 Acc: 50.0000%\n",
      "\ttrain 22-39: Loss: 0.0545 Acc: 75.0000%\n",
      "\ttrain 22-40: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 22-41: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 22-42: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 22-43: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 22-44: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 22-45: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 22-46: Loss: 0.0789 Acc: 100.0000%\n",
      "\ttrain 22-47: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 22-48: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 22-49: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 22-50: Loss: 0.1396 Acc: 50.0000%\n",
      "\ttrain 22-51: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 22-52: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 22-53: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 22-54: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 22-55: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 22-56: Loss: 0.1221 Acc: 50.0000%\n",
      "\ttrain 22-57: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 22-58: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 22-59: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 22-60: Loss: 0.0722 Acc: 100.0000%\n",
      "\ttrain 22-61: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 22-62: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 22-63: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 22-64: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 22-65: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 22-66: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 22-67: Loss: 0.1907 Acc: 75.0000%\n",
      "\ttrain 22-68: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 22-69: Loss: 0.1785 Acc: 50.0000%\n",
      "\ttrain 22-70: Loss: 0.2292 Acc: 75.0000%\n",
      "\ttrain 22-71: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 22-72: Loss: 0.2900 Acc: 75.0000%\n",
      "\ttrain 22-73: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 22-74: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 22-75: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 22-76: Loss: 0.1840 Acc: 50.0000%\n",
      "\ttrain 22-77: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 22-78: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 22-79: Loss: 0.9419 Acc: 25.0000%\n",
      "\ttrain 22-80: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 22-81: Loss: 0.6006 Acc: 50.0000%\n",
      "\ttrain 22-82: Loss: 0.3065 Acc: 50.0000%\n",
      "\ttrain 22-83: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 22-84: Loss: 0.3646 Acc: 50.0000%\n",
      "\ttrain 22-85: Loss: 0.4447 Acc: 75.0000%\n",
      "\ttrain 22-86: Loss: 0.5578 Acc: 50.0000%\n",
      "\ttrain 22-87: Loss: 0.5724 Acc: 0.0000%\n",
      "\ttrain 22-88: Loss: 0.4534 Acc: 25.0000%\n",
      "\ttrain 22-89: Loss: 0.3094 Acc: 25.0000%\n",
      "\ttrain 22-90: Loss: 0.1763 Acc: 75.0000%\n",
      "\ttrain 22-91: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 22-92: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 22-93: Loss: 0.2570 Acc: 50.0000%\n",
      "\ttrain 22-94: Loss: 0.2737 Acc: 50.0000%\n",
      "\ttrain 22-95: Loss: 0.2922 Acc: 50.0000%\n",
      "\ttrain 22-96: Loss: 0.2621 Acc: 25.0000%\n",
      "\ttrain 22-97: Loss: 0.1030 Acc: 100.0000%\n",
      "\ttrain 22-98: Loss: 0.1606 Acc: 75.0000%\n",
      "\ttrain 22-99: Loss: 0.1886 Acc: 50.0000%\n",
      "\ttrain 22-100: Loss: 0.1768 Acc: 50.0000%\n",
      "\ttrain 22-101: Loss: 0.1415 Acc: 100.0000%\n",
      "\ttrain 22-102: Loss: 0.2172 Acc: 75.0000%\n",
      "\ttrain 22-103: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 22-104: Loss: 0.2403 Acc: 50.0000%\n",
      "\ttrain 22-105: Loss: 0.2866 Acc: 0.0000%\n",
      "\ttrain 22-106: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 22-107: Loss: 0.0769 Acc: 100.0000%\n",
      "\ttrain 22-108: Loss: 0.1566 Acc: 50.0000%\n",
      "\ttrain 22-109: Loss: 0.2155 Acc: 50.0000%\n",
      "\ttrain 22-110: Loss: 0.2239 Acc: 25.0000%\n",
      "\ttrain 22-111: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 22-112: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 22-113: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 22-114: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 22-115: Loss: 0.0926 Acc: 100.0000%\n",
      "\ttrain 22-116: Loss: 0.1010 Acc: 50.0000%\n",
      "\ttrain 22-117: Loss: 0.1149 Acc: 50.0000%\n",
      "\ttrain 22-118: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 22-119: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 22-120: Loss: 0.0833 Acc: 75.0000%\n",
      "\ttrain 22-121: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 22-122: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 22-123: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 22-124: Loss: 0.0906 Acc: 100.0000%\n",
      "\ttrain 22-125: Loss: 0.1679 Acc: 75.0000%\n",
      "\ttrain 22-126: Loss: 0.1838 Acc: 50.0000%\n",
      "\ttrain 22-127: Loss: 0.1764 Acc: 75.0000%\n",
      "\ttrain 22-128: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 22-129: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 22-130: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 22-131: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 22-132: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 22-133: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 22-134: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 22-135: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 22-136: Loss: 0.3956 Acc: 50.0000%\n",
      "\ttrain 22-137: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 22-138: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 22-139: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 22-140: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 22-141: Loss: 0.1277 Acc: 50.0000%\n",
      "\ttrain 22-142: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 22-143: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 22-144: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 22-145: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 22-146: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 22-147: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 22-148: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 22-149: Loss: 0.1434 Acc: 50.0000%\n",
      "\ttrain 22-150: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 22-151: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 22-152: Loss: 0.0822 Acc: 100.0000%\n",
      "\ttrain 22-153: Loss: 0.0681 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-154: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 22-155: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 22-156: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 22-157: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 22-158: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 22-159: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 22-160: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 22-161: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 22-162: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 22-163: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 22-164: Loss: 0.0913 Acc: 100.0000%\n",
      "\ttrain 22-165: Loss: 0.2362 Acc: 75.0000%\n",
      "\ttrain 22-166: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 22-167: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 22-168: Loss: 0.2501 Acc: 50.0000%\n",
      "\ttrain 22-169: Loss: 0.4572 Acc: 50.0000%\n",
      "\ttrain 22-170: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-171: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 22-172: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 22-173: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 22-174: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 22-175: Loss: 0.1869 Acc: 50.0000%\n",
      "\ttrain 22-176: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 22-177: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 22-178: Loss: 0.1575 Acc: 50.0000%\n",
      "\ttrain 22-179: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 22-180: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 22-181: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 22-182: Loss: 0.2077 Acc: 75.0000%\n",
      "\ttrain 22-183: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 22-184: Loss: 0.1003 Acc: 100.0000%\n",
      "\ttrain 22-185: Loss: 0.0996 Acc: 100.0000%\n",
      "\ttrain 22-186: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 22-187: Loss: 0.1030 Acc: 100.0000%\n",
      "\ttrain 22-188: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 22-189: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 22-190: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-191: Loss: 0.2246 Acc: 50.0000%\n",
      "\ttrain 22-192: Loss: 0.2726 Acc: 50.0000%\n",
      "\ttrain 22-193: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 22-194: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 22-195: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 22-196: Loss: 0.1882 Acc: 75.0000%\n",
      "\ttrain 22-197: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 22-198: Loss: 0.0701 Acc: 100.0000%\n",
      "\ttrain 22-199: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 22-200: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 22-201: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 22-202: Loss: 0.1157 Acc: 50.0000%\n",
      "\ttrain 22-203: Loss: 0.1003 Acc: 100.0000%\n",
      "\ttrain 22-204: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 22-205: Loss: 0.1485 Acc: 25.0000%\n",
      "\ttrain 22-206: Loss: 0.1357 Acc: 50.0000%\n",
      "\ttrain 22-207: Loss: 0.1721 Acc: 75.0000%\n",
      "\ttrain 22-208: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 22-209: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 22-210: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 22-211: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 22-212: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 22-213: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 22-214: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 22-215: Loss: 0.1055 Acc: 100.0000%\n",
      "\ttrain 22-216: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 22-217: Loss: 0.2169 Acc: 25.0000%\n",
      "\ttrain 22-218: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 22-219: Loss: 0.1108 Acc: 100.0000%\n",
      "\ttrain 22-220: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 22-221: Loss: 0.1480 Acc: 50.0000%\n",
      "\ttrain 22-222: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 22-223: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 22-224: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 22-225: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 22-226: Loss: 0.2792 Acc: 50.0000%\n",
      "\ttrain 22-227: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 22-228: Loss: 0.3155 Acc: 25.0000%\n",
      "\ttrain 22-229: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 22-230: Loss: 0.2096 Acc: 25.0000%\n",
      "\ttrain 22-231: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 22-232: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 22-233: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 22-234: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 22-235: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 22-236: Loss: 0.2604 Acc: 50.0000%\n",
      "\ttrain 22-237: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 22-238: Loss: 0.0990 Acc: 100.0000%\n",
      "\ttrain 22-239: Loss: 0.1616 Acc: 75.0000%\n",
      "\ttrain 22-240: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 22-241: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 22-242: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 22-243: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 22-244: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 22-245: Loss: 0.0847 Acc: 100.0000%\n",
      "\tvalidation 22-1: Loss: 0.1022 Acc: 75.0000%\n",
      "\tvalidation 22-2: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 22-3: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 22-4: Loss: 0.0553 Acc: 100.0000%\n",
      "\tvalidation 22-5: Loss: 0.1651 Acc: 50.0000%\n",
      "\tvalidation 22-6: Loss: 0.1181 Acc: 75.0000%\n",
      "\tvalidation 22-7: Loss: 0.0885 Acc: 75.0000%\n",
      "\tvalidation 22-8: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 22-9: Loss: 0.1244 Acc: 75.0000%\n",
      "\tvalidation 22-10: Loss: 0.1048 Acc: 75.0000%\n",
      "\tvalidation 22-11: Loss: 0.0897 Acc: 100.0000%\n",
      "\tvalidation 22-12: Loss: 0.0356 Acc: 100.0000%\n",
      "\tvalidation 22-13: Loss: 0.1920 Acc: 25.0000%\n",
      "\tvalidation 22-14: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 22-15: Loss: 0.0918 Acc: 75.0000%\n",
      "\tvalidation 22-16: Loss: 0.0873 Acc: 100.0000%\n",
      "\tvalidation 22-17: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 22-18: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 22-19: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 22-20: Loss: 0.1209 Acc: 75.0000%\n",
      "\tvalidation 22-21: Loss: 0.0548 Acc: 100.0000%\n",
      "\tvalidation 22-22: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 22-23: Loss: 0.1447 Acc: 50.0000%\n",
      "\tvalidation 22-24: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 22-25: Loss: 0.0808 Acc: 100.0000%\n",
      "\tvalidation 22-26: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 22-27: Loss: 0.1297 Acc: 75.0000%\n",
      "\tvalidation 22-28: Loss: 0.0836 Acc: 75.0000%\n",
      "\tvalidation 22-29: Loss: 0.1623 Acc: 75.0000%\n",
      "\tvalidation 22-30: Loss: 0.0850 Acc: 75.0000%\n",
      "\tvalidation 22-31: Loss: 0.0708 Acc: 100.0000%\n",
      "\tvalidation 22-32: Loss: 0.0627 Acc: 100.0000%\n",
      "\tvalidation 22-33: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 22-34: Loss: 0.0721 Acc: 75.0000%\n",
      "\tvalidation 22-35: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-36: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 22-37: Loss: 0.0764 Acc: 75.0000%\n",
      "\tvalidation 22-38: Loss: 0.1889 Acc: 25.0000%\n",
      "\tvalidation 22-39: Loss: 0.0594 Acc: 100.0000%\n",
      "\tvalidation 22-40: Loss: 0.1321 Acc: 50.0000%\n",
      "\tvalidation 22-41: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 22-42: Loss: 0.0499 Acc: 75.0000%\n",
      "\tvalidation 22-43: Loss: 0.1981 Acc: 25.0000%\n",
      "\tvalidation 22-44: Loss: 0.1029 Acc: 75.0000%\n",
      "\tvalidation 22-45: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 22-46: Loss: 0.0753 Acc: 75.0000%\n",
      "\tvalidation 22-47: Loss: 0.0728 Acc: 100.0000%\n",
      "\tvalidation 22-48: Loss: 0.1376 Acc: 75.0000%\n",
      "\tvalidation 22-49: Loss: 0.0733 Acc: 100.0000%\n",
      "\tvalidation 22-50: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 22-51: Loss: 0.0995 Acc: 75.0000%\n",
      "\tvalidation 22-52: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 22-53: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 22-54: Loss: 0.0734 Acc: 100.0000%\n",
      "\tvalidation 22-55: Loss: 0.1104 Acc: 50.0000%\n",
      "\tvalidation 22-56: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 22-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-58: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 22-59: Loss: 0.0555 Acc: 100.0000%\n",
      "\tvalidation 22-60: Loss: 0.0592 Acc: 100.0000%\n",
      "\tvalidation 22-61: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 22-62: Loss: 0.0711 Acc: 75.0000%\n",
      "\tvalidation 22-63: Loss: 0.1462 Acc: 50.0000%\n",
      "\tvalidation 22-64: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 22-65: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 22-66: Loss: 0.0672 Acc: 100.0000%\n",
      "\tvalidation 22-67: Loss: 0.0575 Acc: 75.0000%\n",
      "\tvalidation 22-68: Loss: 0.0964 Acc: 100.0000%\n",
      "\tvalidation 22-69: Loss: 0.0765 Acc: 75.0000%\n",
      "\tvalidation 22-70: Loss: 0.1341 Acc: 50.0000%\n",
      "\tvalidation 22-71: Loss: 0.0654 Acc: 75.0000%\n",
      "\tvalidation 22-72: Loss: 0.0765 Acc: 100.0000%\n",
      "\tvalidation 22-73: Loss: 0.0447 Acc: 75.0000%\n",
      "\tvalidation 22-74: Loss: 0.0675 Acc: 100.0000%\n",
      "\tvalidation 22-75: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 22-76: Loss: 0.0828 Acc: 75.0000%\n",
      "\tvalidation 22-77: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 22-78: Loss: 0.0672 Acc: 100.0000%\n",
      "\tvalidation 22-79: Loss: 0.0688 Acc: 75.0000%\n",
      "\tvalidation 22-80: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 22-81: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-82: Loss: 0.0715 Acc: 75.0000%\n",
      "\tvalidation 22-83: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 22-84: Loss: 0.0627 Acc: 100.0000%\n",
      "\tvalidation 22-85: Loss: 0.1547 Acc: 50.0000%\n",
      "\tvalidation 22-86: Loss: 0.0939 Acc: 75.0000%\n",
      "\tvalidation 22-87: Loss: 0.0701 Acc: 75.0000%\n",
      "\tvalidation 22-88: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 22-89: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 22-90: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 22-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 22-92: Loss: 0.0996 Acc: 50.0000%\n",
      "\tvalidation 22-93: Loss: 0.1054 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 22-94: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 22-95: Loss: 0.0634 Acc: 100.0000%\n",
      "\tvalidation 22-96: Loss: 0.0791 Acc: 75.0000%\n",
      "\tvalidation 22-97: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 22-98: Loss: 0.1073 Acc: 50.0000%\n",
      "\tvalidation 22-99: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 22-100: Loss: 0.0620 Acc: 100.0000%\n",
      "\tvalidation 22-101: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 22-102: Loss: 0.0979 Acc: 100.0000%\n",
      "\tvalidation 22-103: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 22-104: Loss: 0.0840 Acc: 100.0000%\n",
      "\tvalidation 22-105: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1209 Acc: 79.3878%\n",
      "\tvalidation Loss: 0.0705 Acc: 85.4762%\n",
      "Time passed 0h 17m 2s\n",
      "--------------------\n",
      "Epoch [23/40]:\n",
      "\ttrain 23-1: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 23-2: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 23-3: Loss: 0.1386 Acc: 75.0000%\n",
      "\ttrain 23-4: Loss: 0.1551 Acc: 50.0000%\n",
      "\ttrain 23-5: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 23-6: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 23-7: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 23-8: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 23-9: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 23-10: Loss: 0.2234 Acc: 50.0000%\n",
      "\ttrain 23-11: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 23-12: Loss: 0.0803 Acc: 100.0000%\n",
      "\ttrain 23-13: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 23-14: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 23-15: Loss: 0.0955 Acc: 50.0000%\n",
      "\ttrain 23-16: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 23-17: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 23-18: Loss: 0.1120 Acc: 100.0000%\n",
      "\ttrain 23-19: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 23-20: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 23-21: Loss: 0.1148 Acc: 100.0000%\n",
      "\ttrain 23-22: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 23-23: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 23-24: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 23-25: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 23-26: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 23-27: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 23-28: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 23-29: Loss: 0.2023 Acc: 75.0000%\n",
      "\ttrain 23-30: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 23-31: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 23-32: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 23-33: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 23-34: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 23-35: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 23-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 23-37: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 23-38: Loss: 0.0781 Acc: 100.0000%\n",
      "\ttrain 23-39: Loss: 0.2394 Acc: 75.0000%\n",
      "\ttrain 23-40: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 23-41: Loss: 0.1536 Acc: 75.0000%\n",
      "\ttrain 23-42: Loss: 0.0839 Acc: 100.0000%\n",
      "\ttrain 23-43: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 23-44: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 23-45: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 23-46: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 23-47: Loss: 0.2518 Acc: 25.0000%\n",
      "\ttrain 23-48: Loss: 0.1467 Acc: 50.0000%\n",
      "\ttrain 23-49: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-50: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 23-51: Loss: 0.1809 Acc: 75.0000%\n",
      "\ttrain 23-52: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 23-53: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 23-54: Loss: 0.1268 Acc: 75.0000%\n",
      "\ttrain 23-55: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 23-56: Loss: 0.1586 Acc: 75.0000%\n",
      "\ttrain 23-57: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 23-58: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 23-59: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 23-60: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 23-61: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 23-62: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 23-63: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 23-64: Loss: 0.4979 Acc: 50.0000%\n",
      "\ttrain 23-65: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 23-66: Loss: 0.1404 Acc: 50.0000%\n",
      "\ttrain 23-67: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 23-68: Loss: 0.1235 Acc: 50.0000%\n",
      "\ttrain 23-69: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 23-70: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 23-71: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 23-72: Loss: 0.2219 Acc: 75.0000%\n",
      "\ttrain 23-73: Loss: 0.1022 Acc: 100.0000%\n",
      "\ttrain 23-74: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 23-75: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 23-76: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 23-77: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 23-78: Loss: 0.0963 Acc: 100.0000%\n",
      "\ttrain 23-79: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 23-80: Loss: 0.1762 Acc: 50.0000%\n",
      "\ttrain 23-81: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 23-82: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 23-83: Loss: 0.1764 Acc: 25.0000%\n",
      "\ttrain 23-84: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 23-85: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 23-86: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 23-87: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 23-88: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 23-89: Loss: 0.0766 Acc: 100.0000%\n",
      "\ttrain 23-90: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 23-91: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 23-92: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 23-93: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 23-94: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 23-95: Loss: 0.0871 Acc: 100.0000%\n",
      "\ttrain 23-96: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 23-97: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 23-98: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 23-99: Loss: 0.1816 Acc: 50.0000%\n",
      "\ttrain 23-100: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 23-101: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 23-102: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 23-103: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 23-104: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 23-105: Loss: 0.2373 Acc: 50.0000%\n",
      "\ttrain 23-106: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 23-107: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 23-108: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 23-109: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 23-110: Loss: 0.2141 Acc: 50.0000%\n",
      "\ttrain 23-111: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 23-112: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 23-113: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 23-114: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 23-115: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 23-116: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 23-117: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 23-118: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 23-119: Loss: 0.2567 Acc: 50.0000%\n",
      "\ttrain 23-120: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 23-121: Loss: 0.2484 Acc: 75.0000%\n",
      "\ttrain 23-122: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 23-123: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 23-124: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 23-125: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 23-126: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 23-127: Loss: 0.1426 Acc: 50.0000%\n",
      "\ttrain 23-128: Loss: 0.1274 Acc: 50.0000%\n",
      "\ttrain 23-129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 23-130: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 23-131: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 23-132: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 23-133: Loss: 0.1060 Acc: 50.0000%\n",
      "\ttrain 23-134: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 23-135: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 23-136: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 23-137: Loss: 0.1794 Acc: 50.0000%\n",
      "\ttrain 23-138: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 23-139: Loss: 0.1049 Acc: 50.0000%\n",
      "\ttrain 23-140: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 23-141: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 23-142: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 23-143: Loss: 0.2801 Acc: 75.0000%\n",
      "\ttrain 23-144: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 23-145: Loss: 0.1918 Acc: 25.0000%\n",
      "\ttrain 23-146: Loss: 0.2380 Acc: 25.0000%\n",
      "\ttrain 23-147: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 23-148: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 23-149: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 23-150: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 23-151: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 23-152: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 23-153: Loss: 0.1984 Acc: 50.0000%\n",
      "\ttrain 23-154: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 23-155: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 23-156: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 23-157: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 23-158: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 23-159: Loss: 0.0779 Acc: 100.0000%\n",
      "\ttrain 23-160: Loss: 0.1281 Acc: 100.0000%\n",
      "\ttrain 23-161: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 23-162: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 23-163: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 23-164: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 23-165: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 23-166: Loss: 0.0834 Acc: 100.0000%\n",
      "\ttrain 23-167: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 23-168: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 23-169: Loss: 0.0933 Acc: 50.0000%\n",
      "\ttrain 23-170: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 23-171: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 23-172: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 23-173: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 23-174: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 23-175: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 23-176: Loss: 0.1142 Acc: 50.0000%\n",
      "\ttrain 23-177: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 23-178: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 23-179: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 23-180: Loss: 0.0275 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 23-181: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 23-182: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 23-183: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-184: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 23-185: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 23-186: Loss: 0.1393 Acc: 50.0000%\n",
      "\ttrain 23-187: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 23-188: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 23-189: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 23-190: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 23-191: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 23-192: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 23-193: Loss: 0.2323 Acc: 50.0000%\n",
      "\ttrain 23-194: Loss: 0.2535 Acc: 50.0000%\n",
      "\ttrain 23-195: Loss: 0.1814 Acc: 75.0000%\n",
      "\ttrain 23-196: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 23-197: Loss: 0.2584 Acc: 50.0000%\n",
      "\ttrain 23-198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 23-199: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 23-200: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 23-201: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 23-202: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 23-203: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 23-204: Loss: 0.1943 Acc: 50.0000%\n",
      "\ttrain 23-205: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 23-206: Loss: 0.0912 Acc: 100.0000%\n",
      "\ttrain 23-207: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 23-208: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 23-209: Loss: 0.1753 Acc: 75.0000%\n",
      "\ttrain 23-210: Loss: 0.1975 Acc: 50.0000%\n",
      "\ttrain 23-211: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 23-212: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 23-213: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 23-214: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 23-215: Loss: 0.1334 Acc: 50.0000%\n",
      "\ttrain 23-216: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 23-217: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 23-218: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 23-219: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 23-220: Loss: 0.1533 Acc: 50.0000%\n",
      "\ttrain 23-221: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 23-222: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 23-223: Loss: 0.0709 Acc: 100.0000%\n",
      "\ttrain 23-224: Loss: 0.1518 Acc: 50.0000%\n",
      "\ttrain 23-225: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 23-226: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 23-227: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 23-228: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 23-229: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 23-230: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 23-231: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 23-232: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 23-233: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 23-234: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 23-235: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 23-236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 23-237: Loss: 0.3573 Acc: 50.0000%\n",
      "\ttrain 23-238: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 23-239: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 23-240: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 23-241: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 23-242: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 23-243: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 23-244: Loss: 0.1803 Acc: 50.0000%\n",
      "\ttrain 23-245: Loss: 0.1515 Acc: 50.0000%\n",
      "\tvalidation 23-1: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 23-2: Loss: 0.0692 Acc: 100.0000%\n",
      "\tvalidation 23-3: Loss: 0.1084 Acc: 100.0000%\n",
      "\tvalidation 23-4: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 23-5: Loss: 0.0376 Acc: 100.0000%\n",
      "\tvalidation 23-6: Loss: 0.1297 Acc: 75.0000%\n",
      "\tvalidation 23-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-8: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 23-9: Loss: 0.0686 Acc: 75.0000%\n",
      "\tvalidation 23-10: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 23-11: Loss: 0.1054 Acc: 75.0000%\n",
      "\tvalidation 23-12: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 23-13: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 23-14: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 23-15: Loss: 0.0530 Acc: 100.0000%\n",
      "\tvalidation 23-16: Loss: 0.0536 Acc: 75.0000%\n",
      "\tvalidation 23-17: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 23-18: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 23-19: Loss: 0.0619 Acc: 100.0000%\n",
      "\tvalidation 23-20: Loss: 0.0567 Acc: 75.0000%\n",
      "\tvalidation 23-21: Loss: 0.0854 Acc: 75.0000%\n",
      "\tvalidation 23-22: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 23-23: Loss: 0.0613 Acc: 75.0000%\n",
      "\tvalidation 23-24: Loss: 0.1611 Acc: 50.0000%\n",
      "\tvalidation 23-25: Loss: 0.0410 Acc: 100.0000%\n",
      "\tvalidation 23-26: Loss: 0.0890 Acc: 75.0000%\n",
      "\tvalidation 23-27: Loss: 0.0584 Acc: 100.0000%\n",
      "\tvalidation 23-28: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 23-29: Loss: 0.0557 Acc: 100.0000%\n",
      "\tvalidation 23-30: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 23-31: Loss: 0.1057 Acc: 75.0000%\n",
      "\tvalidation 23-32: Loss: 0.0757 Acc: 75.0000%\n",
      "\tvalidation 23-33: Loss: 0.1924 Acc: 50.0000%\n",
      "\tvalidation 23-34: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 23-35: Loss: 0.0712 Acc: 75.0000%\n",
      "\tvalidation 23-36: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 23-37: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 23-38: Loss: 0.0871 Acc: 75.0000%\n",
      "\tvalidation 23-39: Loss: 0.0494 Acc: 75.0000%\n",
      "\tvalidation 23-40: Loss: 0.0998 Acc: 75.0000%\n",
      "\tvalidation 23-41: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 23-42: Loss: 0.0426 Acc: 100.0000%\n",
      "\tvalidation 23-43: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 23-44: Loss: 0.0691 Acc: 75.0000%\n",
      "\tvalidation 23-45: Loss: 0.0576 Acc: 75.0000%\n",
      "\tvalidation 23-46: Loss: 0.0543 Acc: 75.0000%\n",
      "\tvalidation 23-47: Loss: 0.0291 Acc: 100.0000%\n",
      "\tvalidation 23-48: Loss: 0.1277 Acc: 50.0000%\n",
      "\tvalidation 23-49: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 23-50: Loss: 0.0502 Acc: 100.0000%\n",
      "\tvalidation 23-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-52: Loss: 0.1256 Acc: 75.0000%\n",
      "\tvalidation 23-53: Loss: 0.0630 Acc: 75.0000%\n",
      "\tvalidation 23-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-55: Loss: 0.0829 Acc: 75.0000%\n",
      "\tvalidation 23-56: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 23-57: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 23-58: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 23-59: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 23-60: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 23-61: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 23-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-63: Loss: 0.0475 Acc: 100.0000%\n",
      "\tvalidation 23-64: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 23-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-66: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 23-67: Loss: 0.0770 Acc: 100.0000%\n",
      "\tvalidation 23-68: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 23-69: Loss: 0.0522 Acc: 100.0000%\n",
      "\tvalidation 23-70: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 23-71: Loss: 0.1109 Acc: 75.0000%\n",
      "\tvalidation 23-72: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 23-73: Loss: 0.0667 Acc: 75.0000%\n",
      "\tvalidation 23-74: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 23-75: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 23-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-77: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 23-78: Loss: 0.1244 Acc: 75.0000%\n",
      "\tvalidation 23-79: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 23-80: Loss: 0.0554 Acc: 100.0000%\n",
      "\tvalidation 23-81: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 23-82: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 23-83: Loss: 0.0561 Acc: 100.0000%\n",
      "\tvalidation 23-84: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 23-85: Loss: 0.0534 Acc: 100.0000%\n",
      "\tvalidation 23-86: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 23-87: Loss: 0.1596 Acc: 50.0000%\n",
      "\tvalidation 23-88: Loss: 0.0918 Acc: 100.0000%\n",
      "\tvalidation 23-89: Loss: 0.0728 Acc: 100.0000%\n",
      "\tvalidation 23-90: Loss: 0.1050 Acc: 75.0000%\n",
      "\tvalidation 23-91: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 23-92: Loss: 0.1113 Acc: 75.0000%\n",
      "\tvalidation 23-93: Loss: 0.0795 Acc: 100.0000%\n",
      "\tvalidation 23-94: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 23-95: Loss: 0.0511 Acc: 100.0000%\n",
      "\tvalidation 23-96: Loss: 0.0671 Acc: 75.0000%\n",
      "\tvalidation 23-97: Loss: 0.0846 Acc: 75.0000%\n",
      "\tvalidation 23-98: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 23-99: Loss: 0.0465 Acc: 100.0000%\n",
      "\tvalidation 23-100: Loss: 0.0746 Acc: 100.0000%\n",
      "\tvalidation 23-101: Loss: 0.1030 Acc: 75.0000%\n",
      "\tvalidation 23-102: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 23-103: Loss: 0.0361 Acc: 100.0000%\n",
      "\tvalidation 23-104: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 23-105: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0884 Acc: 84.7959%\n",
      "\tvalidation Loss: 0.0550 Acc: 90.7143%\n",
      "Time passed 0h 17m 47s\n",
      "--------------------\n",
      "Epoch [24/40]:\n",
      "\ttrain 24-1: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 24-2: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 24-3: Loss: 1.0078 Acc: 50.0000%\n",
      "\ttrain 24-4: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 24-5: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 24-6: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 24-7: Loss: 0.2570 Acc: 25.0000%\n",
      "\ttrain 24-8: Loss: 0.2705 Acc: 25.0000%\n",
      "\ttrain 24-9: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 24-10: Loss: 0.3438 Acc: 50.0000%\n",
      "\ttrain 24-11: Loss: 0.1342 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-12: Loss: 0.1080 Acc: 50.0000%\n",
      "\ttrain 24-13: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 24-14: Loss: 0.1516 Acc: 75.0000%\n",
      "\ttrain 24-15: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 24-16: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 24-17: Loss: 0.0885 Acc: 100.0000%\n",
      "\ttrain 24-18: Loss: 0.1705 Acc: 75.0000%\n",
      "\ttrain 24-19: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 24-20: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 24-21: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 24-22: Loss: 0.0920 Acc: 100.0000%\n",
      "\ttrain 24-23: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 24-24: Loss: 0.1480 Acc: 75.0000%\n",
      "\ttrain 24-25: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 24-26: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 24-27: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 24-28: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 24-29: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-30: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 24-31: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 24-32: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 24-33: Loss: 0.3022 Acc: 0.0000%\n",
      "\ttrain 24-34: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 24-35: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 24-36: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-37: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 24-38: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 24-39: Loss: 0.1347 Acc: 75.0000%\n",
      "\ttrain 24-40: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 24-41: Loss: 0.1126 Acc: 50.0000%\n",
      "\ttrain 24-42: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 24-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 24-44: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 24-45: Loss: 0.1396 Acc: 50.0000%\n",
      "\ttrain 24-46: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 24-47: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 24-48: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 24-49: Loss: 0.0975 Acc: 100.0000%\n",
      "\ttrain 24-50: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 24-51: Loss: 0.0663 Acc: 100.0000%\n",
      "\ttrain 24-52: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 24-53: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 24-54: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 24-55: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 24-56: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 24-57: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 24-58: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 24-59: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 24-60: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 24-61: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 24-62: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 24-63: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 24-64: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 24-65: Loss: 0.0721 Acc: 100.0000%\n",
      "\ttrain 24-66: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 24-67: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 24-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-69: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 24-70: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 24-71: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 24-72: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 24-73: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 24-74: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 24-75: Loss: 0.3164 Acc: 50.0000%\n",
      "\ttrain 24-76: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 24-77: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 24-78: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 24-79: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 24-80: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 24-81: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 24-82: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 24-83: Loss: 0.2891 Acc: 25.0000%\n",
      "\ttrain 24-84: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 24-85: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 24-86: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 24-87: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 24-88: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 24-89: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 24-90: Loss: 0.2399 Acc: 75.0000%\n",
      "\ttrain 24-91: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 24-92: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-93: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 24-94: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 24-95: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 24-96: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 24-97: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 24-98: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-99: Loss: 0.3709 Acc: 50.0000%\n",
      "\ttrain 24-100: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 24-101: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 24-102: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 24-103: Loss: 0.2086 Acc: 25.0000%\n",
      "\ttrain 24-104: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 24-105: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 24-106: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 24-107: Loss: 0.2032 Acc: 50.0000%\n",
      "\ttrain 24-108: Loss: 0.1588 Acc: 50.0000%\n",
      "\ttrain 24-109: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 24-110: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 24-111: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 24-112: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 24-113: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 24-114: Loss: 0.0779 Acc: 100.0000%\n",
      "\ttrain 24-115: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 24-116: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 24-117: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 24-118: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 24-119: Loss: 0.2419 Acc: 50.0000%\n",
      "\ttrain 24-120: Loss: 0.1482 Acc: 75.0000%\n",
      "\ttrain 24-121: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 24-122: Loss: 0.2118 Acc: 75.0000%\n",
      "\ttrain 24-123: Loss: 0.2534 Acc: 50.0000%\n",
      "\ttrain 24-124: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 24-125: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 24-126: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 24-127: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 24-128: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 24-129: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 24-130: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 24-131: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 24-132: Loss: 0.1999 Acc: 50.0000%\n",
      "\ttrain 24-133: Loss: 0.2537 Acc: 25.0000%\n",
      "\ttrain 24-134: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 24-135: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 24-136: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 24-137: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 24-138: Loss: 0.0746 Acc: 100.0000%\n",
      "\ttrain 24-139: Loss: 0.0697 Acc: 100.0000%\n",
      "\ttrain 24-140: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 24-141: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-142: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 24-143: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 24-144: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 24-145: Loss: 0.2189 Acc: 50.0000%\n",
      "\ttrain 24-146: Loss: 0.1676 Acc: 75.0000%\n",
      "\ttrain 24-147: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 24-148: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 24-149: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 24-150: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 24-151: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 24-152: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 24-153: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 24-154: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 24-155: Loss: 0.3035 Acc: 75.0000%\n",
      "\ttrain 24-156: Loss: 0.1595 Acc: 50.0000%\n",
      "\ttrain 24-157: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 24-158: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 24-159: Loss: 0.2118 Acc: 50.0000%\n",
      "\ttrain 24-160: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 24-161: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 24-162: Loss: 0.1705 Acc: 50.0000%\n",
      "\ttrain 24-163: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 24-164: Loss: 0.2034 Acc: 50.0000%\n",
      "\ttrain 24-165: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 24-166: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 24-167: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 24-168: Loss: 0.2581 Acc: 50.0000%\n",
      "\ttrain 24-169: Loss: 0.0830 Acc: 100.0000%\n",
      "\ttrain 24-170: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 24-171: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 24-172: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 24-173: Loss: 0.0729 Acc: 75.0000%\n",
      "\ttrain 24-174: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 24-175: Loss: 0.1689 Acc: 75.0000%\n",
      "\ttrain 24-176: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 24-177: Loss: 0.2688 Acc: 50.0000%\n",
      "\ttrain 24-178: Loss: 0.1376 Acc: 50.0000%\n",
      "\ttrain 24-179: Loss: 0.2145 Acc: 75.0000%\n",
      "\ttrain 24-180: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 24-181: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 24-182: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 24-183: Loss: 0.1280 Acc: 50.0000%\n",
      "\ttrain 24-184: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 24-185: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain 24-186: Loss: 0.1290 Acc: 75.0000%\n",
      "\ttrain 24-187: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 24-188: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 24-189: Loss: 0.1761 Acc: 75.0000%\n",
      "\ttrain 24-190: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 24-191: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 24-192: Loss: 0.0988 Acc: 75.0000%\n",
      "\ttrain 24-193: Loss: 0.1497 Acc: 75.0000%\n",
      "\ttrain 24-194: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 24-195: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 24-196: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 24-197: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 24-198: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 24-199: Loss: 0.1885 Acc: 50.0000%\n",
      "\ttrain 24-200: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 24-201: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 24-202: Loss: 0.0780 Acc: 75.0000%\n",
      "\ttrain 24-203: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 24-204: Loss: 0.2644 Acc: 50.0000%\n",
      "\ttrain 24-205: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 24-206: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 24-207: Loss: 0.0169 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-208: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 24-209: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 24-210: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 24-211: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 24-212: Loss: 0.1768 Acc: 50.0000%\n",
      "\ttrain 24-213: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 24-214: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 24-215: Loss: 0.2345 Acc: 50.0000%\n",
      "\ttrain 24-216: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 24-217: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 24-218: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 24-219: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 24-220: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 24-221: Loss: 0.4795 Acc: 25.0000%\n",
      "\ttrain 24-222: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 24-223: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-224: Loss: 0.1114 Acc: 100.0000%\n",
      "\ttrain 24-225: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 24-226: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 24-227: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 24-228: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 24-229: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 24-230: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 24-231: Loss: 0.1590 Acc: 50.0000%\n",
      "\ttrain 24-232: Loss: 0.2481 Acc: 75.0000%\n",
      "\ttrain 24-233: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-234: Loss: 0.1762 Acc: 50.0000%\n",
      "\ttrain 24-235: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 24-236: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 24-237: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 24-238: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 24-239: Loss: 0.1332 Acc: 75.0000%\n",
      "\ttrain 24-240: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 24-241: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 24-242: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 24-243: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 24-244: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 24-245: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 24-1: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 24-2: Loss: 0.1515 Acc: 50.0000%\n",
      "\tvalidation 24-3: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-4: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 24-5: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 24-6: Loss: 0.0574 Acc: 75.0000%\n",
      "\tvalidation 24-7: Loss: 0.0812 Acc: 75.0000%\n",
      "\tvalidation 24-8: Loss: 0.0736 Acc: 75.0000%\n",
      "\tvalidation 24-9: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 24-10: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 24-11: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 24-12: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-13: Loss: 0.0424 Acc: 100.0000%\n",
      "\tvalidation 24-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-15: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 24-16: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 24-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-18: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 24-19: Loss: 0.0510 Acc: 100.0000%\n",
      "\tvalidation 24-20: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 24-21: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 24-22: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 24-23: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 24-24: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 24-25: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 24-26: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 24-27: Loss: 0.1375 Acc: 75.0000%\n",
      "\tvalidation 24-28: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 24-29: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 24-30: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 24-31: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 24-32: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 24-33: Loss: 0.0476 Acc: 100.0000%\n",
      "\tvalidation 24-34: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 24-35: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 24-36: Loss: 0.0889 Acc: 75.0000%\n",
      "\tvalidation 24-37: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 24-38: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 24-39: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 24-40: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 24-41: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 24-42: Loss: 0.0558 Acc: 75.0000%\n",
      "\tvalidation 24-43: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 24-44: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 24-45: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 24-46: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 24-47: Loss: 0.1048 Acc: 75.0000%\n",
      "\tvalidation 24-48: Loss: 0.0576 Acc: 100.0000%\n",
      "\tvalidation 24-49: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 24-50: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 24-51: Loss: 0.1777 Acc: 50.0000%\n",
      "\tvalidation 24-52: Loss: 0.0593 Acc: 100.0000%\n",
      "\tvalidation 24-53: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 24-54: Loss: 0.0729 Acc: 75.0000%\n",
      "\tvalidation 24-55: Loss: 0.0565 Acc: 100.0000%\n",
      "\tvalidation 24-56: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 24-57: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 24-58: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 24-59: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-60: Loss: 0.1138 Acc: 75.0000%\n",
      "\tvalidation 24-61: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 24-62: Loss: 0.0524 Acc: 75.0000%\n",
      "\tvalidation 24-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-64: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 24-65: Loss: 0.1243 Acc: 50.0000%\n",
      "\tvalidation 24-66: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 24-67: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 24-68: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 24-69: Loss: 0.0523 Acc: 100.0000%\n",
      "\tvalidation 24-70: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 24-71: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 24-72: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 24-73: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 24-74: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 24-75: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 24-76: Loss: 0.1052 Acc: 75.0000%\n",
      "\tvalidation 24-77: Loss: 0.1095 Acc: 75.0000%\n",
      "\tvalidation 24-78: Loss: 0.0599 Acc: 75.0000%\n",
      "\tvalidation 24-79: Loss: 0.0839 Acc: 75.0000%\n",
      "\tvalidation 24-80: Loss: 0.0449 Acc: 100.0000%\n",
      "\tvalidation 24-81: Loss: 0.0544 Acc: 100.0000%\n",
      "\tvalidation 24-82: Loss: 0.0662 Acc: 75.0000%\n",
      "\tvalidation 24-83: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 24-84: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 24-85: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 24-86: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 24-87: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 24-88: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 24-89: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 24-90: Loss: 0.0880 Acc: 100.0000%\n",
      "\tvalidation 24-91: Loss: 0.0573 Acc: 100.0000%\n",
      "\tvalidation 24-92: Loss: 0.0870 Acc: 75.0000%\n",
      "\tvalidation 24-93: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 24-94: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 24-95: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-96: Loss: 0.0871 Acc: 100.0000%\n",
      "\tvalidation 24-97: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 24-98: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 24-99: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 24-100: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 24-101: Loss: 0.0686 Acc: 75.0000%\n",
      "\tvalidation 24-102: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 24-103: Loss: 0.0411 Acc: 100.0000%\n",
      "\tvalidation 24-104: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 24-105: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0933 Acc: 83.5714%\n",
      "\tvalidation Loss: 0.0423 Acc: 93.8095%\n",
      "网络参数更新\n",
      "Time passed 0h 18m 35s\n",
      "--------------------\n",
      "Epoch [25/40]:\n",
      "\ttrain 25-1: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 25-2: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 25-3: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 25-4: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 25-5: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 25-6: Loss: 0.0541 Acc: 75.0000%\n",
      "\ttrain 25-7: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 25-8: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 25-9: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 25-10: Loss: 0.1350 Acc: 50.0000%\n",
      "\ttrain 25-11: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 25-12: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 25-13: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 25-14: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 25-15: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 25-16: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 25-17: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 25-18: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 25-19: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 25-20: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 25-21: Loss: 0.1694 Acc: 50.0000%\n",
      "\ttrain 25-22: Loss: 0.0826 Acc: 100.0000%\n",
      "\ttrain 25-23: Loss: 0.2936 Acc: 50.0000%\n",
      "\ttrain 25-24: Loss: 0.2250 Acc: 50.0000%\n",
      "\ttrain 25-25: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 25-26: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 25-27: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 25-28: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 25-29: Loss: 0.1820 Acc: 75.0000%\n",
      "\ttrain 25-30: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-31: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 25-32: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 25-33: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 25-34: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 25-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-36: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 25-37: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 25-38: Loss: 0.1106 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-39: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-40: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 25-41: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 25-42: Loss: 0.1012 Acc: 100.0000%\n",
      "\ttrain 25-43: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 25-44: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 25-45: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 25-46: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 25-47: Loss: 0.2219 Acc: 50.0000%\n",
      "\ttrain 25-48: Loss: 0.2365 Acc: 50.0000%\n",
      "\ttrain 25-49: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-50: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 25-51: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 25-52: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 25-53: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-54: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 25-55: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 25-56: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 25-57: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 25-58: Loss: 0.0603 Acc: 100.0000%\n",
      "\ttrain 25-59: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-60: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 25-61: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 25-62: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 25-63: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 25-64: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 25-65: Loss: 0.2823 Acc: 25.0000%\n",
      "\ttrain 25-66: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 25-67: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 25-68: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 25-69: Loss: 0.2563 Acc: 75.0000%\n",
      "\ttrain 25-70: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 25-71: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 25-72: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 25-73: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-74: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 25-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-76: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 25-77: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 25-78: Loss: 0.3218 Acc: 75.0000%\n",
      "\ttrain 25-79: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 25-80: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 25-81: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 25-82: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 25-83: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 25-84: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 25-85: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 25-86: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 25-87: Loss: 0.4203 Acc: 50.0000%\n",
      "\ttrain 25-88: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 25-89: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 25-90: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 25-91: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 25-92: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 25-93: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 25-94: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 25-95: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 25-96: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 25-97: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 25-98: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 25-99: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 25-100: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 25-101: Loss: 0.1861 Acc: 50.0000%\n",
      "\ttrain 25-102: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 25-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-104: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 25-105: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 25-106: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 25-107: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 25-108: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 25-109: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 25-110: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 25-111: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-112: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 25-113: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 25-114: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 25-115: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 25-116: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 25-117: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 25-118: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 25-119: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 25-120: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 25-121: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 25-122: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 25-123: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 25-124: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 25-125: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 25-126: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 25-127: Loss: 0.5291 Acc: 50.0000%\n",
      "\ttrain 25-128: Loss: 0.3038 Acc: 50.0000%\n",
      "\ttrain 25-129: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-130: Loss: 0.2033 Acc: 75.0000%\n",
      "\ttrain 25-131: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 25-132: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 25-133: Loss: 0.2084 Acc: 50.0000%\n",
      "\ttrain 25-134: Loss: 0.1781 Acc: 75.0000%\n",
      "\ttrain 25-135: Loss: 0.0754 Acc: 100.0000%\n",
      "\ttrain 25-136: Loss: 0.2478 Acc: 75.0000%\n",
      "\ttrain 25-137: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 25-138: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 25-139: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 25-140: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 25-141: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 25-142: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 25-143: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 25-144: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 25-145: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 25-146: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 25-147: Loss: 0.1740 Acc: 50.0000%\n",
      "\ttrain 25-148: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 25-149: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 25-150: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 25-151: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 25-152: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 25-153: Loss: 0.1073 Acc: 100.0000%\n",
      "\ttrain 25-154: Loss: 0.3652 Acc: 50.0000%\n",
      "\ttrain 25-155: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 25-156: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 25-157: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 25-158: Loss: 0.1169 Acc: 50.0000%\n",
      "\ttrain 25-159: Loss: 0.0708 Acc: 75.0000%\n",
      "\ttrain 25-160: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 25-161: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 25-162: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 25-163: Loss: 0.2231 Acc: 75.0000%\n",
      "\ttrain 25-164: Loss: 0.1663 Acc: 75.0000%\n",
      "\ttrain 25-165: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 25-166: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 25-167: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 25-168: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 25-169: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 25-170: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-171: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 25-172: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 25-173: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-174: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 25-175: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 25-176: Loss: 0.1432 Acc: 75.0000%\n",
      "\ttrain 25-177: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 25-178: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 25-179: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 25-180: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 25-181: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 25-182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-183: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 25-184: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 25-185: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 25-186: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 25-187: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 25-188: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 25-189: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 25-190: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 25-191: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 25-192: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 25-193: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 25-194: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 25-195: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 25-196: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 25-197: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-198: Loss: 0.1807 Acc: 75.0000%\n",
      "\ttrain 25-199: Loss: 0.1969 Acc: 50.0000%\n",
      "\ttrain 25-200: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 25-201: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 25-202: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 25-203: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 25-204: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 25-205: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 25-206: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 25-207: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 25-208: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 25-209: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 25-210: Loss: 0.2576 Acc: 25.0000%\n",
      "\ttrain 25-211: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 25-212: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 25-213: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 25-214: Loss: 0.2215 Acc: 50.0000%\n",
      "\ttrain 25-215: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 25-216: Loss: 0.1422 Acc: 50.0000%\n",
      "\ttrain 25-217: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 25-218: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 25-219: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 25-220: Loss: 0.1359 Acc: 75.0000%\n",
      "\ttrain 25-221: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 25-222: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 25-223: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 25-224: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 25-225: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 25-226: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 25-227: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 25-228: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 25-229: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 25-230: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 25-231: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 25-232: Loss: 0.3773 Acc: 50.0000%\n",
      "\ttrain 25-233: Loss: 0.0889 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-234: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 25-235: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 25-236: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-237: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 25-238: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 25-239: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 25-240: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 25-241: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 25-242: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 25-243: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 25-244: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 25-245: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 25-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 25-2: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 25-3: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 25-4: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 25-5: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 25-6: Loss: 0.0654 Acc: 75.0000%\n",
      "\tvalidation 25-7: Loss: 0.0450 Acc: 100.0000%\n",
      "\tvalidation 25-8: Loss: 0.0566 Acc: 75.0000%\n",
      "\tvalidation 25-9: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 25-10: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 25-11: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 25-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-14: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 25-15: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 25-16: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 25-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-18: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 25-19: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 25-20: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 25-21: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 25-22: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 25-23: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 25-24: Loss: 0.0399 Acc: 100.0000%\n",
      "\tvalidation 25-25: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 25-26: Loss: 0.0372 Acc: 100.0000%\n",
      "\tvalidation 25-27: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 25-28: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-29: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 25-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-31: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 25-32: Loss: 0.0682 Acc: 75.0000%\n",
      "\tvalidation 25-33: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 25-34: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 25-35: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 25-36: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 25-37: Loss: 0.0576 Acc: 100.0000%\n",
      "\tvalidation 25-38: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 25-39: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-40: Loss: 0.0976 Acc: 75.0000%\n",
      "\tvalidation 25-41: Loss: 0.0591 Acc: 100.0000%\n",
      "\tvalidation 25-42: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 25-43: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 25-44: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 25-45: Loss: 0.1119 Acc: 75.0000%\n",
      "\tvalidation 25-46: Loss: 0.1608 Acc: 75.0000%\n",
      "\tvalidation 25-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-48: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 25-49: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 25-50: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 25-51: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 25-52: Loss: 0.1635 Acc: 75.0000%\n",
      "\tvalidation 25-53: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 25-54: Loss: 0.0491 Acc: 100.0000%\n",
      "\tvalidation 25-55: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 25-56: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-57: Loss: 0.2651 Acc: 75.0000%\n",
      "\tvalidation 25-58: Loss: 0.0432 Acc: 100.0000%\n",
      "\tvalidation 25-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-60: Loss: 0.0401 Acc: 100.0000%\n",
      "\tvalidation 25-61: Loss: 0.1085 Acc: 75.0000%\n",
      "\tvalidation 25-62: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 25-63: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 25-64: Loss: 0.3314 Acc: 75.0000%\n",
      "\tvalidation 25-65: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 25-66: Loss: 0.0929 Acc: 75.0000%\n",
      "\tvalidation 25-67: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 25-68: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 25-69: Loss: 0.1165 Acc: 75.0000%\n",
      "\tvalidation 25-70: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 25-71: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 25-72: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 25-73: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 25-74: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 25-75: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 25-76: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 25-77: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 25-78: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 25-79: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 25-80: Loss: 0.0852 Acc: 100.0000%\n",
      "\tvalidation 25-81: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 25-82: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 25-83: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 25-84: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 25-85: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 25-86: Loss: 0.0750 Acc: 75.0000%\n",
      "\tvalidation 25-87: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-88: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 25-89: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 25-90: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 25-91: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 25-92: Loss: 0.0993 Acc: 75.0000%\n",
      "\tvalidation 25-93: Loss: 0.0774 Acc: 75.0000%\n",
      "\tvalidation 25-94: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 25-95: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 25-96: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 25-97: Loss: 0.1418 Acc: 75.0000%\n",
      "\tvalidation 25-98: Loss: 0.1141 Acc: 75.0000%\n",
      "\tvalidation 25-99: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 25-100: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 25-101: Loss: 0.1019 Acc: 75.0000%\n",
      "\tvalidation 25-102: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 25-103: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 25-104: Loss: 0.0802 Acc: 75.0000%\n",
      "\tvalidation 25-105: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0727 Acc: 88.5714%\n",
      "\tvalidation Loss: 0.0395 Acc: 95.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 19m 23s\n",
      "--------------------\n",
      "Epoch [26/40]:\n",
      "\ttrain 26-1: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 26-2: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 26-3: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 26-4: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 26-5: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 26-6: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 26-7: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 26-8: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 26-9: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 26-10: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 26-11: Loss: 0.9208 Acc: 50.0000%\n",
      "\ttrain 26-12: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 26-13: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 26-14: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 26-15: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 26-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 26-17: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 26-18: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 26-19: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 26-20: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 26-21: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 26-22: Loss: 0.2092 Acc: 50.0000%\n",
      "\ttrain 26-23: Loss: 0.1490 Acc: 50.0000%\n",
      "\ttrain 26-24: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 26-25: Loss: 0.2112 Acc: 50.0000%\n",
      "\ttrain 26-26: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 26-27: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 26-28: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 26-29: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 26-30: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 26-31: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 26-32: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 26-33: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 26-34: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 26-35: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 26-36: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 26-37: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 26-38: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 26-39: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 26-40: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 26-41: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 26-42: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 26-43: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 26-44: Loss: 0.1371 Acc: 75.0000%\n",
      "\ttrain 26-45: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 26-46: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 26-47: Loss: 0.3181 Acc: 50.0000%\n",
      "\ttrain 26-48: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-49: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 26-50: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 26-51: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 26-52: Loss: 0.2397 Acc: 50.0000%\n",
      "\ttrain 26-53: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 26-54: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 26-55: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 26-56: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 26-57: Loss: 0.1910 Acc: 75.0000%\n",
      "\ttrain 26-58: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 26-59: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 26-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-61: Loss: 0.1990 Acc: 75.0000%\n",
      "\ttrain 26-62: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 26-63: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 26-64: Loss: 0.0485 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-65: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 26-66: Loss: 0.1646 Acc: 75.0000%\n",
      "\ttrain 26-67: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 26-68: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 26-69: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 26-70: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 26-71: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 26-72: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 26-73: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 26-74: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 26-75: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 26-76: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 26-77: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 26-78: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 26-79: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 26-80: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 26-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 26-82: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 26-83: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 26-84: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 26-85: Loss: 0.1728 Acc: 75.0000%\n",
      "\ttrain 26-86: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 26-87: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 26-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-89: Loss: 0.3432 Acc: 75.0000%\n",
      "\ttrain 26-90: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 26-91: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 26-92: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 26-93: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 26-94: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 26-95: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 26-96: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 26-97: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 26-98: Loss: 0.3612 Acc: 25.0000%\n",
      "\ttrain 26-99: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 26-100: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 26-101: Loss: 0.4646 Acc: 50.0000%\n",
      "\ttrain 26-102: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 26-103: Loss: 0.1689 Acc: 75.0000%\n",
      "\ttrain 26-104: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 26-105: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 26-106: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 26-107: Loss: 0.0725 Acc: 100.0000%\n",
      "\ttrain 26-108: Loss: 0.2800 Acc: 50.0000%\n",
      "\ttrain 26-109: Loss: 0.0853 Acc: 100.0000%\n",
      "\ttrain 26-110: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 26-111: Loss: 0.1535 Acc: 75.0000%\n",
      "\ttrain 26-112: Loss: 0.1921 Acc: 25.0000%\n",
      "\ttrain 26-113: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 26-114: Loss: 0.2010 Acc: 50.0000%\n",
      "\ttrain 26-115: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 26-116: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 26-117: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 26-118: Loss: 0.1504 Acc: 50.0000%\n",
      "\ttrain 26-119: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 26-120: Loss: 0.2149 Acc: 50.0000%\n",
      "\ttrain 26-121: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 26-122: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 26-123: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 26-124: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 26-125: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 26-126: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 26-127: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 26-128: Loss: 0.0701 Acc: 75.0000%\n",
      "\ttrain 26-129: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 26-130: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 26-131: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 26-132: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 26-133: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 26-134: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 26-135: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 26-136: Loss: 0.2397 Acc: 75.0000%\n",
      "\ttrain 26-137: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 26-138: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 26-139: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 26-140: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 26-141: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 26-142: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 26-143: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 26-144: Loss: 0.1090 Acc: 100.0000%\n",
      "\ttrain 26-145: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 26-146: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 26-147: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 26-148: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 26-149: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 26-150: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 26-151: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 26-152: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 26-153: Loss: 0.2331 Acc: 50.0000%\n",
      "\ttrain 26-154: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 26-155: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 26-156: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 26-157: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 26-158: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 26-159: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 26-160: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 26-161: Loss: 0.0696 Acc: 75.0000%\n",
      "\ttrain 26-162: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 26-163: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 26-164: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 26-165: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 26-166: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 26-167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 26-168: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 26-169: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 26-170: Loss: 0.2918 Acc: 75.0000%\n",
      "\ttrain 26-171: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 26-172: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 26-173: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 26-174: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 26-175: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 26-176: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 26-177: Loss: 0.0734 Acc: 100.0000%\n",
      "\ttrain 26-178: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 26-179: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 26-180: Loss: 0.1485 Acc: 50.0000%\n",
      "\ttrain 26-181: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 26-182: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 26-183: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 26-184: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 26-185: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-186: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 26-187: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 26-188: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 26-189: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 26-190: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 26-191: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 26-192: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 26-193: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 26-194: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 26-195: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 26-196: Loss: 0.0775 Acc: 100.0000%\n",
      "\ttrain 26-197: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 26-198: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 26-199: Loss: 0.1381 Acc: 50.0000%\n",
      "\ttrain 26-200: Loss: 0.2012 Acc: 75.0000%\n",
      "\ttrain 26-201: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 26-202: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 26-203: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 26-204: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 26-205: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 26-206: Loss: 0.1511 Acc: 50.0000%\n",
      "\ttrain 26-207: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 26-208: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 26-209: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 26-210: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 26-211: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 26-212: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 26-213: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 26-214: Loss: 0.1261 Acc: 50.0000%\n",
      "\ttrain 26-215: Loss: 0.2262 Acc: 50.0000%\n",
      "\ttrain 26-216: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 26-217: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 26-218: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 26-219: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 26-220: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 26-221: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 26-222: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 26-223: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 26-224: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 26-225: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 26-226: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-227: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 26-228: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 26-229: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 26-230: Loss: 0.0833 Acc: 75.0000%\n",
      "\ttrain 26-231: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 26-232: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 26-233: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-234: Loss: 0.2303 Acc: 75.0000%\n",
      "\ttrain 26-235: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 26-236: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 26-237: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 26-238: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 26-239: Loss: 0.2308 Acc: 75.0000%\n",
      "\ttrain 26-240: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 26-241: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 26-242: Loss: 0.1911 Acc: 75.0000%\n",
      "\ttrain 26-243: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 26-244: Loss: 0.0832 Acc: 100.0000%\n",
      "\ttrain 26-245: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 26-1: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 26-2: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 26-3: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 26-4: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 26-5: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 26-6: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 26-7: Loss: 0.0478 Acc: 100.0000%\n",
      "\tvalidation 26-8: Loss: 0.0817 Acc: 100.0000%\n",
      "\tvalidation 26-9: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 26-10: Loss: 0.0607 Acc: 100.0000%\n",
      "\tvalidation 26-11: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 26-12: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 26-13: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 26-14: Loss: 0.0767 Acc: 100.0000%\n",
      "\tvalidation 26-15: Loss: 0.0465 Acc: 100.0000%\n",
      "\tvalidation 26-16: Loss: 0.1531 Acc: 75.0000%\n",
      "\tvalidation 26-17: Loss: 0.0061 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 26-18: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 26-19: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 26-20: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 26-21: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 26-22: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 26-23: Loss: 0.0939 Acc: 75.0000%\n",
      "\tvalidation 26-24: Loss: 0.0694 Acc: 100.0000%\n",
      "\tvalidation 26-25: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 26-26: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 26-27: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 26-28: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 26-29: Loss: 0.0728 Acc: 100.0000%\n",
      "\tvalidation 26-30: Loss: 0.0631 Acc: 75.0000%\n",
      "\tvalidation 26-31: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 26-32: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 26-33: Loss: 0.0531 Acc: 100.0000%\n",
      "\tvalidation 26-34: Loss: 0.0563 Acc: 75.0000%\n",
      "\tvalidation 26-35: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 26-36: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 26-37: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 26-38: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 26-39: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 26-40: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 26-41: Loss: 0.0291 Acc: 100.0000%\n",
      "\tvalidation 26-42: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 26-43: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 26-44: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 26-45: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 26-46: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 26-47: Loss: 0.0834 Acc: 75.0000%\n",
      "\tvalidation 26-48: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 26-49: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 26-50: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 26-51: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 26-52: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 26-53: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 26-54: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-55: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 26-56: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-57: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 26-58: Loss: 0.0356 Acc: 100.0000%\n",
      "\tvalidation 26-59: Loss: 0.0809 Acc: 75.0000%\n",
      "\tvalidation 26-60: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 26-61: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 26-62: Loss: 0.0692 Acc: 75.0000%\n",
      "\tvalidation 26-63: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 26-64: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 26-65: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 26-66: Loss: 0.0839 Acc: 75.0000%\n",
      "\tvalidation 26-67: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 26-68: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 26-69: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 26-70: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 26-71: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 26-72: Loss: 0.1062 Acc: 75.0000%\n",
      "\tvalidation 26-73: Loss: 0.0475 Acc: 100.0000%\n",
      "\tvalidation 26-74: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 26-75: Loss: 0.0814 Acc: 75.0000%\n",
      "\tvalidation 26-76: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 26-77: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-78: Loss: 0.0608 Acc: 75.0000%\n",
      "\tvalidation 26-79: Loss: 0.0361 Acc: 100.0000%\n",
      "\tvalidation 26-80: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 26-81: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 26-82: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 26-83: Loss: 0.0605 Acc: 100.0000%\n",
      "\tvalidation 26-84: Loss: 0.0732 Acc: 75.0000%\n",
      "\tvalidation 26-85: Loss: 0.0895 Acc: 75.0000%\n",
      "\tvalidation 26-86: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 26-87: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 26-88: Loss: 0.0649 Acc: 100.0000%\n",
      "\tvalidation 26-89: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 26-90: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 26-91: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 26-92: Loss: 0.0837 Acc: 100.0000%\n",
      "\tvalidation 26-93: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 26-94: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 26-95: Loss: 0.1105 Acc: 75.0000%\n",
      "\tvalidation 26-96: Loss: 0.0277 Acc: 100.0000%\n",
      "\tvalidation 26-97: Loss: 0.0886 Acc: 75.0000%\n",
      "\tvalidation 26-98: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 26-99: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 26-100: Loss: 0.0913 Acc: 75.0000%\n",
      "\tvalidation 26-101: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 26-102: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 26-103: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 26-104: Loss: 0.0562 Acc: 100.0000%\n",
      "\tvalidation 26-105: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0729 Acc: 88.8776%\n",
      "\tvalidation Loss: 0.0386 Acc: 95.7143%\n",
      "网络参数更新\n",
      "Time passed 0h 20m 13s\n",
      "--------------------\n",
      "Epoch [27/40]:\n",
      "\ttrain 27-1: Loss: 0.1069 Acc: 50.0000%\n",
      "\ttrain 27-2: Loss: 0.2061 Acc: 50.0000%\n",
      "\ttrain 27-3: Loss: 0.0630 Acc: 100.0000%\n",
      "\ttrain 27-4: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 27-5: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 27-6: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 27-7: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 27-8: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 27-9: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 27-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 27-11: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 27-12: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 27-13: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 27-14: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 27-15: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 27-16: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 27-17: Loss: 0.1970 Acc: 75.0000%\n",
      "\ttrain 27-18: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 27-19: Loss: 0.1728 Acc: 75.0000%\n",
      "\ttrain 27-20: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 27-21: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 27-22: Loss: 0.1877 Acc: 50.0000%\n",
      "\ttrain 27-23: Loss: 0.1291 Acc: 50.0000%\n",
      "\ttrain 27-24: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 27-25: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 27-26: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 27-27: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 27-28: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 27-29: Loss: 0.7776 Acc: 50.0000%\n",
      "\ttrain 27-30: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 27-31: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 27-32: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 27-33: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 27-34: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 27-35: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 27-36: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 27-37: Loss: 0.1188 Acc: 75.0000%\n",
      "\ttrain 27-38: Loss: 0.1048 Acc: 100.0000%\n",
      "\ttrain 27-39: Loss: 0.0852 Acc: 100.0000%\n",
      "\ttrain 27-40: Loss: 0.1340 Acc: 50.0000%\n",
      "\ttrain 27-41: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 27-42: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 27-43: Loss: 0.2383 Acc: 50.0000%\n",
      "\ttrain 27-44: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 27-45: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 27-46: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 27-47: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 27-48: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 27-49: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 27-50: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 27-51: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 27-52: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-53: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 27-54: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 27-55: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 27-56: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 27-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-58: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 27-59: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 27-60: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 27-61: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 27-62: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 27-63: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 27-64: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 27-65: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 27-66: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-67: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 27-68: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 27-69: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 27-70: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 27-71: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 27-72: Loss: 0.1656 Acc: 75.0000%\n",
      "\ttrain 27-73: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 27-74: Loss: 0.0626 Acc: 75.0000%\n",
      "\ttrain 27-75: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-76: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-77: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 27-78: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 27-79: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 27-80: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 27-81: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 27-82: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 27-83: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 27-84: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 27-85: Loss: 0.1625 Acc: 75.0000%\n",
      "\ttrain 27-86: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 27-87: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 27-88: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 27-89: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 27-90: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 27-91: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 27-92: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 27-93: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 27-94: Loss: 0.2854 Acc: 75.0000%\n",
      "\ttrain 27-95: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 27-96: Loss: 0.0659 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-98: Loss: 0.3827 Acc: 75.0000%\n",
      "\ttrain 27-99: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 27-100: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 27-101: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 27-102: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 27-103: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 27-104: Loss: 0.1350 Acc: 75.0000%\n",
      "\ttrain 27-105: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 27-106: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 27-107: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 27-108: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 27-109: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 27-110: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 27-111: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 27-112: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 27-113: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 27-114: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 27-115: Loss: 0.1956 Acc: 50.0000%\n",
      "\ttrain 27-116: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 27-117: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 27-118: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-119: Loss: 0.3490 Acc: 50.0000%\n",
      "\ttrain 27-120: Loss: 0.2101 Acc: 75.0000%\n",
      "\ttrain 27-121: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 27-122: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 27-123: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 27-124: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 27-125: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 27-126: Loss: 0.2403 Acc: 50.0000%\n",
      "\ttrain 27-127: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 27-128: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 27-129: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 27-130: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 27-131: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 27-132: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 27-133: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 27-134: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 27-135: Loss: 0.1410 Acc: 50.0000%\n",
      "\ttrain 27-136: Loss: 0.2370 Acc: 50.0000%\n",
      "\ttrain 27-137: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 27-138: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 27-139: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 27-140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-141: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 27-142: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 27-143: Loss: 0.0762 Acc: 100.0000%\n",
      "\ttrain 27-144: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 27-145: Loss: 0.1586 Acc: 75.0000%\n",
      "\ttrain 27-146: Loss: 0.4298 Acc: 50.0000%\n",
      "\ttrain 27-147: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 27-148: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 27-149: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 27-150: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 27-151: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 27-152: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 27-153: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 27-154: Loss: 0.1444 Acc: 50.0000%\n",
      "\ttrain 27-155: Loss: 0.0674 Acc: 100.0000%\n",
      "\ttrain 27-156: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 27-157: Loss: 0.2021 Acc: 75.0000%\n",
      "\ttrain 27-158: Loss: 0.1902 Acc: 75.0000%\n",
      "\ttrain 27-159: Loss: 0.0756 Acc: 100.0000%\n",
      "\ttrain 27-160: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 27-161: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 27-162: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 27-163: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 27-164: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 27-165: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 27-166: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 27-167: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 27-168: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 27-169: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 27-170: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 27-171: Loss: 0.2126 Acc: 75.0000%\n",
      "\ttrain 27-172: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 27-173: Loss: 0.1631 Acc: 75.0000%\n",
      "\ttrain 27-174: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 27-175: Loss: 0.0697 Acc: 100.0000%\n",
      "\ttrain 27-176: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 27-177: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 27-178: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 27-179: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 27-180: Loss: 0.2402 Acc: 75.0000%\n",
      "\ttrain 27-181: Loss: 0.2851 Acc: 75.0000%\n",
      "\ttrain 27-182: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 27-183: Loss: 0.0946 Acc: 100.0000%\n",
      "\ttrain 27-184: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 27-185: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 27-186: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 27-187: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 27-188: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 27-189: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 27-190: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 27-191: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 27-192: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 27-193: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 27-194: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 27-195: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 27-196: Loss: 0.1889 Acc: 75.0000%\n",
      "\ttrain 27-197: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 27-198: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 27-199: Loss: 0.0480 Acc: 75.0000%\n",
      "\ttrain 27-200: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 27-201: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 27-202: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 27-203: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 27-204: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 27-205: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 27-206: Loss: 0.0465 Acc: 75.0000%\n",
      "\ttrain 27-207: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 27-208: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 27-209: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 27-210: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 27-211: Loss: 0.3595 Acc: 50.0000%\n",
      "\ttrain 27-212: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 27-213: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 27-214: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 27-215: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 27-216: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 27-217: Loss: 0.2849 Acc: 75.0000%\n",
      "\ttrain 27-218: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 27-219: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 27-220: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 27-221: Loss: 0.1934 Acc: 75.0000%\n",
      "\ttrain 27-222: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-223: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 27-224: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 27-225: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 27-226: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 27-227: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 27-228: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 27-229: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 27-230: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 27-231: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 27-232: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 27-233: Loss: 0.0674 Acc: 100.0000%\n",
      "\ttrain 27-234: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 27-235: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 27-236: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 27-237: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 27-238: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 27-239: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-240: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 27-241: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-242: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 27-243: Loss: 0.2477 Acc: 50.0000%\n",
      "\ttrain 27-244: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 27-245: Loss: 0.1044 Acc: 75.0000%\n",
      "\tvalidation 27-1: Loss: 0.1500 Acc: 75.0000%\n",
      "\tvalidation 27-2: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 27-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-4: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 27-5: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 27-6: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 27-7: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 27-8: Loss: 0.0788 Acc: 75.0000%\n",
      "\tvalidation 27-9: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 27-10: Loss: 0.0858 Acc: 75.0000%\n",
      "\tvalidation 27-11: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 27-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 27-13: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 27-14: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 27-15: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 27-16: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 27-17: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 27-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-19: Loss: 0.1433 Acc: 75.0000%\n",
      "\tvalidation 27-20: Loss: 0.0930 Acc: 75.0000%\n",
      "\tvalidation 27-21: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 27-22: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 27-23: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 27-24: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 27-25: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-26: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 27-27: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-28: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 27-29: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 27-30: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 27-31: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 27-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 27-33: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 27-34: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 27-35: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 27-36: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 27-37: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 27-38: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 27-39: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 27-40: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 27-41: Loss: 0.1013 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 27-42: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 27-43: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 27-44: Loss: 0.4113 Acc: 50.0000%\n",
      "\tvalidation 27-45: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 27-46: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 27-47: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 27-48: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 27-49: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 27-50: Loss: 0.0634 Acc: 75.0000%\n",
      "\tvalidation 27-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-52: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 27-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-54: Loss: 0.0384 Acc: 100.0000%\n",
      "\tvalidation 27-55: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-57: Loss: 0.0656 Acc: 75.0000%\n",
      "\tvalidation 27-58: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 27-59: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 27-60: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 27-61: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 27-62: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 27-63: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-64: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 27-65: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 27-66: Loss: 0.0733 Acc: 75.0000%\n",
      "\tvalidation 27-67: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 27-68: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 27-69: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 27-70: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 27-71: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 27-72: Loss: 0.0508 Acc: 75.0000%\n",
      "\tvalidation 27-73: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 27-74: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 27-75: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 27-76: Loss: 0.0572 Acc: 75.0000%\n",
      "\tvalidation 27-77: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 27-78: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 27-79: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 27-80: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 27-81: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 27-82: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 27-83: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 27-84: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 27-85: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 27-86: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-87: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 27-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-89: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 27-90: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 27-91: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 27-92: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-93: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 27-94: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 27-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-96: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 27-97: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 27-98: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 27-99: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 27-100: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 27-101: Loss: 0.0538 Acc: 75.0000%\n",
      "\tvalidation 27-102: Loss: 0.0746 Acc: 75.0000%\n",
      "\tvalidation 27-103: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-104: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 27-105: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0763 Acc: 88.2653%\n",
      "\tvalidation Loss: 0.0242 Acc: 96.1905%\n",
      "网络参数更新\n",
      "Time passed 0h 21m 2s\n",
      "--------------------\n",
      "Epoch [28/40]:\n",
      "\ttrain 28-1: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 28-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-3: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 28-4: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 28-5: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 28-6: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 28-7: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 28-8: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 28-9: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 28-10: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 28-11: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 28-12: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 28-13: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 28-14: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 28-15: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 28-16: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 28-17: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 28-18: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 28-19: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 28-20: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 28-21: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 28-22: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 28-23: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 28-24: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 28-25: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 28-26: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 28-27: Loss: 0.2201 Acc: 50.0000%\n",
      "\ttrain 28-28: Loss: 0.1692 Acc: 25.0000%\n",
      "\ttrain 28-29: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 28-30: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 28-31: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 28-32: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 28-33: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 28-34: Loss: 0.1937 Acc: 75.0000%\n",
      "\ttrain 28-35: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 28-36: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-37: Loss: 0.1652 Acc: 50.0000%\n",
      "\ttrain 28-38: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 28-39: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 28-40: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 28-41: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 28-42: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 28-43: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 28-44: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 28-45: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 28-46: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 28-47: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 28-48: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 28-49: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 28-50: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-51: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 28-52: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 28-53: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-54: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 28-55: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 28-56: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 28-57: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 28-58: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 28-59: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-60: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 28-61: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 28-62: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 28-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-64: Loss: 0.1915 Acc: 75.0000%\n",
      "\ttrain 28-65: Loss: 0.3629 Acc: 75.0000%\n",
      "\ttrain 28-66: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 28-67: Loss: 0.3522 Acc: 75.0000%\n",
      "\ttrain 28-68: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 28-69: Loss: 0.2653 Acc: 75.0000%\n",
      "\ttrain 28-70: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 28-71: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 28-72: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 28-73: Loss: 0.2255 Acc: 75.0000%\n",
      "\ttrain 28-74: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 28-75: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 28-76: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 28-77: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 28-78: Loss: 0.1477 Acc: 75.0000%\n",
      "\ttrain 28-79: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 28-80: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 28-81: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 28-82: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 28-83: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 28-84: Loss: 0.2427 Acc: 25.0000%\n",
      "\ttrain 28-85: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 28-86: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 28-87: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 28-88: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 28-89: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 28-90: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 28-91: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 28-92: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 28-93: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 28-94: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 28-95: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 28-96: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 28-97: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 28-98: Loss: 0.1620 Acc: 50.0000%\n",
      "\ttrain 28-99: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 28-100: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 28-101: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 28-102: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 28-103: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 28-104: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 28-105: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 28-106: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 28-107: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 28-108: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 28-109: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 28-110: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 28-111: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 28-112: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 28-113: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 28-114: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 28-115: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-116: Loss: 0.4235 Acc: 75.0000%\n",
      "\ttrain 28-117: Loss: 0.2630 Acc: 50.0000%\n",
      "\ttrain 28-118: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 28-119: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 28-120: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 28-121: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 28-122: Loss: 0.0050 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-123: Loss: 0.2551 Acc: 75.0000%\n",
      "\ttrain 28-124: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 28-125: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 28-126: Loss: 0.2065 Acc: 75.0000%\n",
      "\ttrain 28-127: Loss: 0.1026 Acc: 100.0000%\n",
      "\ttrain 28-128: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 28-129: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 28-130: Loss: 0.1765 Acc: 50.0000%\n",
      "\ttrain 28-131: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 28-132: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 28-133: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 28-134: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 28-135: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 28-136: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 28-137: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 28-138: Loss: 0.2385 Acc: 75.0000%\n",
      "\ttrain 28-139: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 28-140: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 28-141: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 28-142: Loss: 0.1484 Acc: 50.0000%\n",
      "\ttrain 28-143: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 28-144: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 28-145: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 28-146: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 28-147: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 28-148: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 28-149: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 28-150: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 28-151: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 28-152: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 28-153: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 28-154: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-155: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 28-156: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 28-157: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 28-158: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 28-159: Loss: 0.1687 Acc: 75.0000%\n",
      "\ttrain 28-160: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 28-161: Loss: 0.1445 Acc: 50.0000%\n",
      "\ttrain 28-162: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-163: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 28-164: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 28-165: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 28-166: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 28-167: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-168: Loss: 0.4980 Acc: 25.0000%\n",
      "\ttrain 28-169: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 28-170: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 28-171: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 28-172: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 28-173: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 28-174: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 28-175: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 28-176: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 28-177: Loss: 0.2387 Acc: 75.0000%\n",
      "\ttrain 28-178: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 28-179: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 28-180: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-181: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 28-182: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 28-183: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 28-184: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 28-185: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 28-186: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 28-187: Loss: 0.2677 Acc: 50.0000%\n",
      "\ttrain 28-188: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 28-189: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 28-190: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-191: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 28-192: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 28-193: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 28-194: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 28-195: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 28-196: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-197: Loss: 0.3094 Acc: 50.0000%\n",
      "\ttrain 28-198: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 28-199: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 28-200: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 28-201: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 28-202: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 28-203: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 28-204: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 28-205: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 28-206: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 28-207: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 28-208: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 28-209: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 28-210: Loss: 0.2240 Acc: 75.0000%\n",
      "\ttrain 28-211: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 28-212: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 28-213: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 28-214: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 28-215: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-216: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 28-217: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 28-218: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 28-219: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 28-220: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 28-221: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 28-222: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 28-223: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 28-224: Loss: 0.1875 Acc: 75.0000%\n",
      "\ttrain 28-225: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 28-226: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 28-227: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 28-228: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 28-229: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 28-230: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 28-231: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 28-232: Loss: 0.1814 Acc: 75.0000%\n",
      "\ttrain 28-233: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 28-235: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 28-236: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 28-237: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 28-238: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 28-239: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 28-240: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 28-241: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-242: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 28-243: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 28-244: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 28-245: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 28-1: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 28-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-3: Loss: 0.1012 Acc: 75.0000%\n",
      "\tvalidation 28-4: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 28-5: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 28-6: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 28-7: Loss: 0.2358 Acc: 50.0000%\n",
      "\tvalidation 28-8: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 28-9: Loss: 0.0606 Acc: 75.0000%\n",
      "\tvalidation 28-10: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 28-11: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 28-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-13: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 28-14: Loss: 0.0572 Acc: 75.0000%\n",
      "\tvalidation 28-15: Loss: 0.1405 Acc: 75.0000%\n",
      "\tvalidation 28-16: Loss: 0.0592 Acc: 100.0000%\n",
      "\tvalidation 28-17: Loss: 0.0510 Acc: 100.0000%\n",
      "\tvalidation 28-18: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 28-19: Loss: 0.0729 Acc: 75.0000%\n",
      "\tvalidation 28-20: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 28-21: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-22: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 28-23: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 28-24: Loss: 0.1520 Acc: 50.0000%\n",
      "\tvalidation 28-25: Loss: 0.0511 Acc: 100.0000%\n",
      "\tvalidation 28-26: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 28-27: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 28-28: Loss: 0.0785 Acc: 75.0000%\n",
      "\tvalidation 28-29: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 28-30: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 28-31: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 28-32: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-33: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 28-34: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-35: Loss: 0.1629 Acc: 75.0000%\n",
      "\tvalidation 28-36: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 28-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-38: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 28-39: Loss: 0.0662 Acc: 75.0000%\n",
      "\tvalidation 28-40: Loss: 0.0615 Acc: 75.0000%\n",
      "\tvalidation 28-41: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 28-42: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 28-43: Loss: 0.0992 Acc: 75.0000%\n",
      "\tvalidation 28-44: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 28-45: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-46: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 28-47: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-49: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 28-50: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 28-51: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 28-52: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 28-53: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 28-54: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 28-55: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 28-56: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 28-57: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 28-58: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 28-59: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 28-60: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 28-61: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 28-62: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 28-63: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 28-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-65: Loss: 0.1682 Acc: 75.0000%\n",
      "\tvalidation 28-66: Loss: 0.0346 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 28-67: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 28-68: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 28-69: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 28-70: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 28-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-72: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 28-73: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 28-74: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 28-75: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 28-76: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 28-77: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 28-78: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-79: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 28-80: Loss: 0.0808 Acc: 75.0000%\n",
      "\tvalidation 28-81: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 28-82: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 28-83: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 28-84: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 28-85: Loss: 0.0568 Acc: 75.0000%\n",
      "\tvalidation 28-86: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 28-87: Loss: 0.1009 Acc: 75.0000%\n",
      "\tvalidation 28-88: Loss: 0.0836 Acc: 75.0000%\n",
      "\tvalidation 28-89: Loss: 0.1604 Acc: 50.0000%\n",
      "\tvalidation 28-90: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 28-91: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-92: Loss: 0.1266 Acc: 50.0000%\n",
      "\tvalidation 28-93: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 28-94: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 28-95: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 28-96: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 28-97: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 28-98: Loss: 0.1391 Acc: 75.0000%\n",
      "\tvalidation 28-99: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 28-100: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 28-101: Loss: 0.0704 Acc: 100.0000%\n",
      "\tvalidation 28-102: Loss: 0.0334 Acc: 100.0000%\n",
      "\tvalidation 28-103: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 28-104: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 28-105: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0723 Acc: 88.2653%\n",
      "\tvalidation Loss: 0.0333 Acc: 93.8095%\n",
      "Time passed 0h 21m 47s\n",
      "--------------------\n",
      "Epoch [29/40]:\n",
      "\ttrain 29-1: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 29-2: Loss: 0.2088 Acc: 50.0000%\n",
      "\ttrain 29-3: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 29-4: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-5: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 29-6: Loss: 0.2207 Acc: 75.0000%\n",
      "\ttrain 29-7: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 29-8: Loss: 0.2637 Acc: 50.0000%\n",
      "\ttrain 29-9: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 29-10: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 29-11: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 29-12: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 29-13: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 29-14: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 29-15: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 29-16: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 29-17: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 29-18: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 29-19: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 29-20: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-21: Loss: 0.0826 Acc: 100.0000%\n",
      "\ttrain 29-22: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 29-23: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 29-24: Loss: 0.0567 Acc: 75.0000%\n",
      "\ttrain 29-25: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-26: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-27: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-28: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 29-29: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 29-30: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 29-31: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 29-32: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 29-33: Loss: 0.0728 Acc: 100.0000%\n",
      "\ttrain 29-34: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 29-35: Loss: 0.3083 Acc: 75.0000%\n",
      "\ttrain 29-36: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 29-37: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 29-38: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 29-39: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 29-40: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 29-41: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 29-42: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 29-43: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 29-44: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 29-45: Loss: 0.3719 Acc: 25.0000%\n",
      "\ttrain 29-46: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 29-47: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 29-48: Loss: 0.2966 Acc: 75.0000%\n",
      "\ttrain 29-49: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 29-50: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-51: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 29-52: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 29-53: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 29-54: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 29-55: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 29-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 29-57: Loss: 0.1562 Acc: 75.0000%\n",
      "\ttrain 29-58: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 29-59: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-60: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 29-61: Loss: 0.3337 Acc: 50.0000%\n",
      "\ttrain 29-62: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 29-63: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 29-64: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 29-65: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 29-66: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 29-67: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 29-68: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 29-69: Loss: 0.1856 Acc: 50.0000%\n",
      "\ttrain 29-70: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 29-71: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 29-72: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 29-73: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-74: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 29-75: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 29-76: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 29-77: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 29-78: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 29-79: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 29-80: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 29-81: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 29-82: Loss: 0.0756 Acc: 75.0000%\n",
      "\ttrain 29-83: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 29-84: Loss: 0.0707 Acc: 75.0000%\n",
      "\ttrain 29-85: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 29-86: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-87: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 29-88: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 29-89: Loss: 0.0805 Acc: 100.0000%\n",
      "\ttrain 29-90: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 29-91: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 29-92: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 29-93: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 29-94: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 29-95: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 29-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-97: Loss: 0.2506 Acc: 75.0000%\n",
      "\ttrain 29-98: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 29-99: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 29-100: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 29-101: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 29-102: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 29-103: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 29-104: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 29-105: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 29-106: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 29-107: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 29-108: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 29-109: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 29-110: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 29-111: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 29-112: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 29-113: Loss: 0.0543 Acc: 75.0000%\n",
      "\ttrain 29-114: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 29-115: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-116: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 29-117: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 29-118: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 29-119: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 29-120: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-121: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 29-122: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 29-123: Loss: 0.2674 Acc: 50.0000%\n",
      "\ttrain 29-124: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 29-125: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 29-126: Loss: 0.0587 Acc: 75.0000%\n",
      "\ttrain 29-127: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 29-128: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 29-129: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 29-130: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 29-131: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 29-132: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 29-133: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 29-134: Loss: 0.2006 Acc: 75.0000%\n",
      "\ttrain 29-135: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 29-136: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 29-137: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 29-138: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 29-139: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 29-140: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 29-141: Loss: 0.1470 Acc: 75.0000%\n",
      "\ttrain 29-142: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 29-143: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 29-144: Loss: 0.1551 Acc: 50.0000%\n",
      "\ttrain 29-145: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 29-146: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 29-147: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 29-148: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-149: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 29-150: Loss: 0.2121 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-151: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 29-152: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 29-153: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 29-154: Loss: 0.3814 Acc: 75.0000%\n",
      "\ttrain 29-155: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-156: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 29-157: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 29-158: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 29-159: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 29-160: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 29-161: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 29-162: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 29-163: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 29-164: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 29-165: Loss: 0.0498 Acc: 75.0000%\n",
      "\ttrain 29-166: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 29-167: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 29-168: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 29-169: Loss: 0.1082 Acc: 75.0000%\n",
      "\ttrain 29-170: Loss: 0.0729 Acc: 75.0000%\n",
      "\ttrain 29-171: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 29-172: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 29-173: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 29-174: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 29-175: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 29-176: Loss: 0.1767 Acc: 75.0000%\n",
      "\ttrain 29-177: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 29-178: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 29-179: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-180: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 29-181: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 29-182: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 29-183: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 29-184: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 29-185: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 29-186: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-187: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 29-188: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 29-189: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 29-190: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-191: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-192: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 29-193: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 29-194: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 29-195: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 29-196: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 29-197: Loss: 0.1245 Acc: 75.0000%\n",
      "\ttrain 29-198: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-199: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 29-200: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-201: Loss: 0.3873 Acc: 25.0000%\n",
      "\ttrain 29-202: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 29-203: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 29-204: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 29-205: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 29-206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 29-207: Loss: 0.2129 Acc: 50.0000%\n",
      "\ttrain 29-208: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-209: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 29-210: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 29-211: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 29-212: Loss: 0.1936 Acc: 75.0000%\n",
      "\ttrain 29-213: Loss: 0.0442 Acc: 75.0000%\n",
      "\ttrain 29-214: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 29-215: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 29-216: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 29-217: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 29-218: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-219: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 29-220: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 29-221: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 29-222: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 29-223: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 29-224: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 29-225: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 29-226: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 29-227: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 29-228: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 29-229: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 29-230: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 29-231: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 29-232: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 29-233: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 29-234: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 29-235: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 29-236: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 29-237: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 29-238: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 29-239: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 29-240: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 29-241: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 29-242: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 29-243: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 29-244: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-245: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 29-1: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 29-2: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 29-3: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 29-4: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-5: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 29-6: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 29-7: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 29-8: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 29-9: Loss: 0.0743 Acc: 75.0000%\n",
      "\tvalidation 29-10: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 29-11: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 29-12: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 29-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-14: Loss: 0.3735 Acc: 75.0000%\n",
      "\tvalidation 29-15: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 29-16: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 29-17: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 29-18: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 29-19: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 29-20: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 29-21: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 29-22: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 29-23: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-24: Loss: 0.2021 Acc: 75.0000%\n",
      "\tvalidation 29-25: Loss: 0.0821 Acc: 75.0000%\n",
      "\tvalidation 29-26: Loss: 0.0463 Acc: 100.0000%\n",
      "\tvalidation 29-27: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 29-28: Loss: 0.1166 Acc: 75.0000%\n",
      "\tvalidation 29-29: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-31: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-32: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 29-33: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-34: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 29-35: Loss: 0.0476 Acc: 75.0000%\n",
      "\tvalidation 29-36: Loss: 0.2320 Acc: 75.0000%\n",
      "\tvalidation 29-37: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 29-38: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-39: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 29-40: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 29-41: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 29-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-43: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-44: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-45: Loss: 0.1941 Acc: 75.0000%\n",
      "\tvalidation 29-46: Loss: 0.0612 Acc: 75.0000%\n",
      "\tvalidation 29-47: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-48: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 29-49: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 29-50: Loss: 0.0525 Acc: 75.0000%\n",
      "\tvalidation 29-51: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 29-52: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 29-53: Loss: 0.1765 Acc: 75.0000%\n",
      "\tvalidation 29-54: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 29-55: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 29-56: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 29-57: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-59: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 29-60: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-61: Loss: 0.1002 Acc: 75.0000%\n",
      "\tvalidation 29-62: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 29-63: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-65: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-66: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 29-67: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-69: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-70: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 29-71: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-72: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 29-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-74: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-75: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 29-76: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 29-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-79: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 29-80: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-82: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-84: Loss: 0.0503 Acc: 75.0000%\n",
      "\tvalidation 29-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-86: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-87: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-88: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 29-89: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-90: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 29-91: Loss: 0.1931 Acc: 75.0000%\n",
      "\tvalidation 29-92: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-93: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-94: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-95: Loss: 0.0517 Acc: 75.0000%\n",
      "\tvalidation 29-96: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 29-97: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 29-98: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-99: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 29-100: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-101: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 29-102: Loss: 0.1141 Acc: 75.0000%\n",
      "\tvalidation 29-103: Loss: 0.1290 Acc: 75.0000%\n",
      "\tvalidation 29-104: Loss: 0.0613 Acc: 75.0000%\n",
      "\tvalidation 29-105: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0586 Acc: 90.3061%\n",
      "\tvalidation Loss: 0.0287 Acc: 95.0000%\n",
      "Time passed 0h 22m 32s\n",
      "--------------------\n",
      "Epoch [30/40]:\n",
      "\ttrain 30-1: Loss: 0.0693 Acc: 75.0000%\n",
      "\ttrain 30-2: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-3: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 30-4: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 30-5: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 30-6: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 30-7: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 30-8: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-9: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 30-10: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 30-11: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-12: Loss: 0.3410 Acc: 50.0000%\n",
      "\ttrain 30-13: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-14: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 30-15: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 30-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-17: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-18: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-19: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 30-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 30-21: Loss: 0.1932 Acc: 75.0000%\n",
      "\ttrain 30-22: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-23: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-24: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 30-25: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 30-26: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 30-27: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 30-28: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 30-29: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 30-30: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 30-31: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-32: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-33: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 30-34: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 30-35: Loss: 0.1333 Acc: 50.0000%\n",
      "\ttrain 30-36: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-37: Loss: 0.1429 Acc: 50.0000%\n",
      "\ttrain 30-38: Loss: 0.2014 Acc: 75.0000%\n",
      "\ttrain 30-39: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 30-40: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 30-41: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 30-42: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 30-43: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 30-44: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 30-45: Loss: 0.1445 Acc: 75.0000%\n",
      "\ttrain 30-46: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 30-47: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 30-48: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 30-49: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 30-50: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 30-51: Loss: 0.2246 Acc: 50.0000%\n",
      "\ttrain 30-52: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 30-53: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 30-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-55: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 30-56: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 30-57: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 30-58: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 30-59: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 30-60: Loss: 0.2640 Acc: 75.0000%\n",
      "\ttrain 30-61: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 30-62: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 30-63: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 30-64: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 30-65: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 30-66: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 30-67: Loss: 0.3078 Acc: 75.0000%\n",
      "\ttrain 30-68: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 30-69: Loss: 0.3184 Acc: 50.0000%\n",
      "\ttrain 30-70: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 30-71: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 30-72: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 30-73: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 30-74: Loss: 0.0826 Acc: 100.0000%\n",
      "\ttrain 30-75: Loss: 0.1903 Acc: 75.0000%\n",
      "\ttrain 30-76: Loss: 0.2906 Acc: 50.0000%\n",
      "\ttrain 30-77: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 30-78: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 30-79: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 30-80: Loss: 0.2067 Acc: 50.0000%\n",
      "\ttrain 30-81: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 30-82: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 30-83: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 30-84: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 30-85: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 30-86: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 30-87: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 30-88: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-89: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 30-90: Loss: 0.0853 Acc: 100.0000%\n",
      "\ttrain 30-91: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 30-92: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 30-93: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 30-94: Loss: 0.1537 Acc: 50.0000%\n",
      "\ttrain 30-95: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 30-96: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 30-97: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 30-98: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 30-99: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 30-100: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 30-101: Loss: 0.0472 Acc: 75.0000%\n",
      "\ttrain 30-102: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 30-103: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 30-104: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 30-105: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-106: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-107: Loss: 0.1412 Acc: 50.0000%\n",
      "\ttrain 30-108: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 30-109: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 30-110: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 30-111: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 30-112: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 30-113: Loss: 0.0526 Acc: 75.0000%\n",
      "\ttrain 30-114: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-115: Loss: 0.1951 Acc: 75.0000%\n",
      "\ttrain 30-116: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 30-117: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-118: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 30-119: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 30-120: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-121: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-122: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 30-123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-124: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 30-125: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 30-126: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 30-127: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 30-128: Loss: 0.1482 Acc: 75.0000%\n",
      "\ttrain 30-129: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 30-130: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 30-131: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 30-132: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 30-133: Loss: 0.3600 Acc: 75.0000%\n",
      "\ttrain 30-134: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 30-135: Loss: 0.1372 Acc: 50.0000%\n",
      "\ttrain 30-136: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 30-137: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 30-138: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 30-139: Loss: 0.1865 Acc: 75.0000%\n",
      "\ttrain 30-140: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 30-141: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 30-142: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 30-143: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 30-144: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 30-145: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 30-146: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 30-147: Loss: 0.2401 Acc: 75.0000%\n",
      "\ttrain 30-148: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 30-149: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 30-150: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 30-151: Loss: 0.1927 Acc: 75.0000%\n",
      "\ttrain 30-152: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 30-153: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-154: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 30-155: Loss: 0.0607 Acc: 75.0000%\n",
      "\ttrain 30-156: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 30-157: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 30-158: Loss: 0.0564 Acc: 100.0000%\n",
      "\ttrain 30-159: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 30-160: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 30-161: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 30-162: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 30-163: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 30-164: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 30-165: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 30-166: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 30-167: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 30-168: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 30-169: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 30-170: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 30-171: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 30-172: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 30-173: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 30-174: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-175: Loss: 0.0450 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 30-176: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 30-177: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-178: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 30-179: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 30-180: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 30-181: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 30-182: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-183: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 30-184: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 30-185: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 30-186: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 30-187: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 30-188: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 30-189: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 30-190: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 30-191: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 30-192: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 30-193: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 30-194: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 30-195: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 30-196: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 30-197: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 30-198: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 30-199: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-200: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-201: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 30-202: Loss: 0.0785 Acc: 75.0000%\n",
      "\ttrain 30-203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-204: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 30-205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-206: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 30-207: Loss: 0.2322 Acc: 75.0000%\n",
      "\ttrain 30-208: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-209: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-210: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 30-211: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-212: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 30-213: Loss: 0.2161 Acc: 75.0000%\n",
      "\ttrain 30-214: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 30-215: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 30-216: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 30-217: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 30-218: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-219: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 30-220: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 30-221: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 30-222: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-223: Loss: 0.2821 Acc: 75.0000%\n",
      "\ttrain 30-224: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 30-225: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 30-226: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-227: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 30-228: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 30-229: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 30-230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-231: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-232: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 30-233: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 30-234: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 30-235: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 30-236: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-237: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 30-238: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 30-239: Loss: 0.1923 Acc: 50.0000%\n",
      "\ttrain 30-240: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 30-241: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 30-242: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-243: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 30-244: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 30-245: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 30-1: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 30-2: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 30-3: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 30-4: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 30-5: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 30-6: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 30-7: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-9: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 30-10: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 30-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-12: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 30-13: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 30-14: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 30-15: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 30-16: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 30-17: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 30-18: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 30-19: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 30-20: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 30-21: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 30-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-23: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 30-24: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 30-25: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 30-26: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 30-27: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 30-28: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 30-29: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 30-30: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 30-31: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 30-32: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 30-33: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 30-34: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 30-35: Loss: 0.0502 Acc: 100.0000%\n",
      "\tvalidation 30-36: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 30-37: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 30-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-39: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 30-40: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 30-41: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 30-42: Loss: 0.0398 Acc: 100.0000%\n",
      "\tvalidation 30-43: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-44: Loss: 0.0612 Acc: 100.0000%\n",
      "\tvalidation 30-45: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 30-46: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 30-47: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 30-48: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 30-49: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 30-50: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 30-51: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 30-52: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 30-53: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 30-54: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 30-55: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 30-56: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 30-57: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 30-58: Loss: 0.0531 Acc: 75.0000%\n",
      "\tvalidation 30-59: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 30-60: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 30-61: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 30-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-63: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 30-64: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 30-65: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 30-66: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 30-67: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 30-68: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 30-69: Loss: 0.0725 Acc: 75.0000%\n",
      "\tvalidation 30-70: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 30-71: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 30-72: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 30-73: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 30-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-75: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 30-76: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 30-77: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 30-78: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 30-79: Loss: 0.0572 Acc: 75.0000%\n",
      "\tvalidation 30-80: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 30-81: Loss: 0.0747 Acc: 100.0000%\n",
      "\tvalidation 30-82: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 30-83: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 30-84: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 30-85: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 30-86: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 30-87: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 30-88: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 30-89: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-90: Loss: 0.0833 Acc: 75.0000%\n",
      "\tvalidation 30-91: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 30-92: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 30-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-94: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 30-95: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 30-96: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-98: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 30-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 30-100: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 30-101: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 30-102: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-103: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 30-104: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 30-105: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0593 Acc: 91.2245%\n",
      "\tvalidation Loss: 0.0179 Acc: 99.0476%\n",
      "网络参数更新\n",
      "Time passed 0h 23m 20s\n",
      "--------------------\n",
      "Epoch [31/40]:\n",
      "\ttrain 31-1: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 31-2: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 31-3: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-4: Loss: 0.0047 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-5: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 31-6: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 31-7: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 31-8: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-9: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 31-10: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 31-11: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 31-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-13: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 31-14: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 31-15: Loss: 0.2336 Acc: 50.0000%\n",
      "\ttrain 31-16: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 31-17: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 31-18: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 31-19: Loss: 0.0564 Acc: 100.0000%\n",
      "\ttrain 31-20: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 31-21: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 31-22: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 31-23: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 31-24: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 31-25: Loss: 0.3709 Acc: 50.0000%\n",
      "\ttrain 31-26: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 31-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-28: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 31-29: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 31-30: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 31-31: Loss: 0.3352 Acc: 50.0000%\n",
      "\ttrain 31-32: Loss: 0.4026 Acc: 50.0000%\n",
      "\ttrain 31-33: Loss: 0.3486 Acc: 50.0000%\n",
      "\ttrain 31-34: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 31-35: Loss: 0.1332 Acc: 50.0000%\n",
      "\ttrain 31-36: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 31-37: Loss: 0.0823 Acc: 100.0000%\n",
      "\ttrain 31-38: Loss: 0.1299 Acc: 50.0000%\n",
      "\ttrain 31-39: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 31-40: Loss: 0.0812 Acc: 100.0000%\n",
      "\ttrain 31-41: Loss: 0.0671 Acc: 100.0000%\n",
      "\ttrain 31-42: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 31-43: Loss: 0.2319 Acc: 75.0000%\n",
      "\ttrain 31-44: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 31-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-46: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 31-47: Loss: 0.1482 Acc: 50.0000%\n",
      "\ttrain 31-48: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 31-49: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 31-50: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 31-51: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 31-52: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 31-53: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 31-54: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 31-55: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-56: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 31-57: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 31-58: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 31-59: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 31-60: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 31-61: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-62: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 31-63: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 31-64: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 31-65: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 31-66: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 31-67: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 31-68: Loss: 0.2322 Acc: 75.0000%\n",
      "\ttrain 31-69: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 31-70: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 31-71: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 31-72: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 31-73: Loss: 0.2100 Acc: 75.0000%\n",
      "\ttrain 31-74: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 31-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-76: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 31-77: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-78: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 31-79: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 31-80: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 31-81: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 31-82: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 31-83: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 31-84: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 31-85: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 31-86: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 31-87: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 31-88: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 31-89: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 31-90: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 31-91: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-92: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-94: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 31-95: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 31-96: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 31-97: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-98: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 31-99: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 31-100: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 31-101: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 31-102: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 31-103: Loss: 0.1673 Acc: 75.0000%\n",
      "\ttrain 31-104: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 31-105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-106: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 31-107: Loss: 0.1789 Acc: 50.0000%\n",
      "\ttrain 31-108: Loss: 0.2249 Acc: 75.0000%\n",
      "\ttrain 31-109: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 31-110: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 31-111: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 31-112: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 31-113: Loss: 0.2092 Acc: 75.0000%\n",
      "\ttrain 31-114: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 31-115: Loss: 0.1463 Acc: 100.0000%\n",
      "\ttrain 31-116: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 31-117: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 31-118: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 31-119: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 31-120: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 31-121: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 31-122: Loss: 0.2679 Acc: 75.0000%\n",
      "\ttrain 31-123: Loss: 0.3967 Acc: 25.0000%\n",
      "\ttrain 31-124: Loss: 0.1441 Acc: 75.0000%\n",
      "\ttrain 31-125: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 31-126: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 31-127: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 31-128: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 31-129: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 31-130: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 31-131: Loss: 0.5124 Acc: 25.0000%\n",
      "\ttrain 31-132: Loss: 0.3161 Acc: 50.0000%\n",
      "\ttrain 31-133: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 31-134: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 31-135: Loss: 0.0857 Acc: 100.0000%\n",
      "\ttrain 31-136: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 31-137: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 31-138: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 31-139: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 31-140: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 31-141: Loss: 0.4239 Acc: 50.0000%\n",
      "\ttrain 31-142: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 31-143: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 31-144: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 31-145: Loss: 0.1331 Acc: 75.0000%\n",
      "\ttrain 31-146: Loss: 0.1619 Acc: 75.0000%\n",
      "\ttrain 31-147: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 31-148: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 31-149: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 31-150: Loss: 0.0663 Acc: 100.0000%\n",
      "\ttrain 31-151: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 31-152: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 31-153: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 31-154: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 31-155: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 31-156: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 31-157: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 31-158: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 31-159: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 31-160: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 31-161: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 31-162: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 31-163: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 31-164: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 31-165: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 31-166: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 31-167: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 31-168: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 31-169: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 31-170: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 31-171: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 31-172: Loss: 0.0825 Acc: 75.0000%\n",
      "\ttrain 31-173: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 31-174: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 31-175: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 31-176: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 31-177: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 31-178: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 31-179: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 31-180: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 31-181: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 31-182: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-183: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 31-184: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 31-185: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 31-186: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 31-187: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 31-188: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 31-189: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-190: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 31-191: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 31-192: Loss: 0.1553 Acc: 75.0000%\n",
      "\ttrain 31-193: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 31-194: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 31-195: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 31-196: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 31-197: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-198: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-199: Loss: 0.0061 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-200: Loss: 0.4230 Acc: 75.0000%\n",
      "\ttrain 31-201: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 31-202: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 31-203: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 31-204: Loss: 0.1915 Acc: 50.0000%\n",
      "\ttrain 31-205: Loss: 0.3146 Acc: 50.0000%\n",
      "\ttrain 31-206: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 31-207: Loss: 0.0746 Acc: 100.0000%\n",
      "\ttrain 31-208: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 31-209: Loss: 0.3046 Acc: 75.0000%\n",
      "\ttrain 31-210: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 31-211: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 31-212: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 31-213: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 31-214: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-215: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 31-216: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 31-217: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 31-218: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 31-219: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 31-220: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-221: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-223: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 31-224: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 31-225: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 31-226: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 31-227: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 31-228: Loss: 0.0518 Acc: 75.0000%\n",
      "\ttrain 31-229: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 31-230: Loss: 0.1488 Acc: 50.0000%\n",
      "\ttrain 31-231: Loss: 0.1230 Acc: 100.0000%\n",
      "\ttrain 31-232: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 31-233: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 31-234: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 31-235: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 31-236: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 31-237: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-238: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 31-239: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 31-240: Loss: 0.3552 Acc: 75.0000%\n",
      "\ttrain 31-241: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 31-242: Loss: 0.2526 Acc: 75.0000%\n",
      "\ttrain 31-243: Loss: 0.1468 Acc: 75.0000%\n",
      "\ttrain 31-244: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 31-245: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 31-1: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-2: Loss: 0.1106 Acc: 75.0000%\n",
      "\tvalidation 31-3: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 31-4: Loss: 0.0639 Acc: 75.0000%\n",
      "\tvalidation 31-5: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 31-6: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 31-7: Loss: 0.0980 Acc: 75.0000%\n",
      "\tvalidation 31-8: Loss: 0.0616 Acc: 100.0000%\n",
      "\tvalidation 31-9: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-10: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 31-11: Loss: 0.1785 Acc: 75.0000%\n",
      "\tvalidation 31-12: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 31-13: Loss: 0.1085 Acc: 75.0000%\n",
      "\tvalidation 31-14: Loss: 0.1424 Acc: 75.0000%\n",
      "\tvalidation 31-15: Loss: 0.1124 Acc: 75.0000%\n",
      "\tvalidation 31-16: Loss: 0.0941 Acc: 75.0000%\n",
      "\tvalidation 31-17: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-18: Loss: 0.1798 Acc: 50.0000%\n",
      "\tvalidation 31-19: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 31-20: Loss: 0.1204 Acc: 75.0000%\n",
      "\tvalidation 31-21: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 31-22: Loss: 0.0493 Acc: 100.0000%\n",
      "\tvalidation 31-23: Loss: 0.0861 Acc: 75.0000%\n",
      "\tvalidation 31-24: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 31-25: Loss: 0.0664 Acc: 75.0000%\n",
      "\tvalidation 31-26: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 31-27: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 31-28: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 31-29: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 31-30: Loss: 0.0426 Acc: 100.0000%\n",
      "\tvalidation 31-31: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 31-32: Loss: 0.0618 Acc: 75.0000%\n",
      "\tvalidation 31-33: Loss: 0.1010 Acc: 75.0000%\n",
      "\tvalidation 31-34: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 31-35: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 31-36: Loss: 0.0315 Acc: 100.0000%\n",
      "\tvalidation 31-37: Loss: 0.1224 Acc: 75.0000%\n",
      "\tvalidation 31-38: Loss: 0.1126 Acc: 75.0000%\n",
      "\tvalidation 31-39: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 31-40: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 31-41: Loss: 0.0677 Acc: 75.0000%\n",
      "\tvalidation 31-42: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 31-43: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 31-44: Loss: 0.0614 Acc: 100.0000%\n",
      "\tvalidation 31-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-46: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 31-47: Loss: 0.0437 Acc: 100.0000%\n",
      "\tvalidation 31-48: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 31-49: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-50: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 31-51: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-52: Loss: 0.0379 Acc: 100.0000%\n",
      "\tvalidation 31-53: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-54: Loss: 0.0832 Acc: 75.0000%\n",
      "\tvalidation 31-55: Loss: 0.0354 Acc: 100.0000%\n",
      "\tvalidation 31-56: Loss: 0.2703 Acc: 50.0000%\n",
      "\tvalidation 31-57: Loss: 0.0502 Acc: 75.0000%\n",
      "\tvalidation 31-58: Loss: 0.0587 Acc: 75.0000%\n",
      "\tvalidation 31-59: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 31-60: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 31-61: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 31-62: Loss: 0.1923 Acc: 75.0000%\n",
      "\tvalidation 31-63: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-64: Loss: 0.0930 Acc: 75.0000%\n",
      "\tvalidation 31-65: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-66: Loss: 0.1063 Acc: 75.0000%\n",
      "\tvalidation 31-67: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 31-68: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 31-69: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 31-70: Loss: 0.0593 Acc: 75.0000%\n",
      "\tvalidation 31-71: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 31-72: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 31-73: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 31-74: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 31-75: Loss: 0.1558 Acc: 50.0000%\n",
      "\tvalidation 31-76: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 31-77: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 31-78: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-79: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 31-80: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 31-81: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 31-82: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 31-83: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 31-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-85: Loss: 0.1332 Acc: 75.0000%\n",
      "\tvalidation 31-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-87: Loss: 0.0534 Acc: 75.0000%\n",
      "\tvalidation 31-88: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 31-89: Loss: 0.0868 Acc: 75.0000%\n",
      "\tvalidation 31-90: Loss: 0.0686 Acc: 100.0000%\n",
      "\tvalidation 31-91: Loss: 0.0558 Acc: 75.0000%\n",
      "\tvalidation 31-92: Loss: 0.1444 Acc: 75.0000%\n",
      "\tvalidation 31-93: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 31-94: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 31-95: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 31-96: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 31-97: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 31-98: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 31-99: Loss: 0.1486 Acc: 75.0000%\n",
      "\tvalidation 31-100: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 31-101: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-102: Loss: 0.1321 Acc: 75.0000%\n",
      "\tvalidation 31-103: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 31-104: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 31-105: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0730 Acc: 88.6735%\n",
      "\tvalidation Loss: 0.0510 Acc: 89.7619%\n",
      "Time passed 0h 24m 5s\n",
      "--------------------\n",
      "Epoch [32/40]:\n",
      "\ttrain 32-1: Loss: 0.1723 Acc: 75.0000%\n",
      "\ttrain 32-2: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 32-3: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 32-4: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 32-5: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 32-6: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 32-7: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 32-8: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 32-9: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-10: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 32-11: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 32-12: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 32-13: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 32-14: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 32-15: Loss: 0.2817 Acc: 75.0000%\n",
      "\ttrain 32-16: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 32-17: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 32-18: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 32-19: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 32-20: Loss: 0.2573 Acc: 50.0000%\n",
      "\ttrain 32-21: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 32-22: Loss: 0.0994 Acc: 100.0000%\n",
      "\ttrain 32-23: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 32-24: Loss: 0.1801 Acc: 75.0000%\n",
      "\ttrain 32-25: Loss: 0.2365 Acc: 75.0000%\n",
      "\ttrain 32-26: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 32-27: Loss: 0.4560 Acc: 25.0000%\n",
      "\ttrain 32-28: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 32-29: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 32-30: Loss: 0.0075 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-31: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 32-32: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 32-33: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 32-34: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 32-35: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 32-36: Loss: 0.1239 Acc: 75.0000%\n",
      "\ttrain 32-37: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 32-38: Loss: 0.2691 Acc: 75.0000%\n",
      "\ttrain 32-39: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 32-40: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 32-41: Loss: 0.1448 Acc: 75.0000%\n",
      "\ttrain 32-42: Loss: 0.1317 Acc: 75.0000%\n",
      "\ttrain 32-43: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 32-44: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 32-45: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 32-46: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 32-47: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 32-48: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 32-49: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 32-50: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 32-51: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 32-52: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 32-53: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 32-54: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 32-55: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 32-56: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 32-57: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 32-58: Loss: 0.2790 Acc: 75.0000%\n",
      "\ttrain 32-59: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 32-60: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 32-61: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 32-62: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 32-63: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 32-64: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 32-65: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 32-66: Loss: 0.1086 Acc: 50.0000%\n",
      "\ttrain 32-67: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 32-68: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 32-69: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 32-70: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-71: Loss: 0.2289 Acc: 50.0000%\n",
      "\ttrain 32-72: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 32-73: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-74: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 32-75: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 32-76: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 32-77: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 32-78: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 32-79: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-80: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 32-81: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 32-82: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 32-83: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 32-84: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 32-85: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 32-86: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 32-87: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 32-88: Loss: 0.2111 Acc: 75.0000%\n",
      "\ttrain 32-89: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 32-90: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 32-91: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 32-92: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 32-93: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-94: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 32-95: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 32-96: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 32-97: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 32-98: Loss: 0.1251 Acc: 50.0000%\n",
      "\ttrain 32-99: Loss: 0.2626 Acc: 75.0000%\n",
      "\ttrain 32-100: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 32-101: Loss: 0.1599 Acc: 75.0000%\n",
      "\ttrain 32-102: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 32-103: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-104: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 32-105: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 32-106: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 32-107: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 32-108: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 32-109: Loss: 0.2103 Acc: 75.0000%\n",
      "\ttrain 32-110: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 32-111: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-112: Loss: 0.1710 Acc: 50.0000%\n",
      "\ttrain 32-113: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 32-114: Loss: 0.0958 Acc: 50.0000%\n",
      "\ttrain 32-115: Loss: 0.3321 Acc: 50.0000%\n",
      "\ttrain 32-116: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-117: Loss: 0.0833 Acc: 75.0000%\n",
      "\ttrain 32-118: Loss: 0.2124 Acc: 75.0000%\n",
      "\ttrain 32-119: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 32-120: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 32-121: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 32-122: Loss: 0.2061 Acc: 50.0000%\n",
      "\ttrain 32-123: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-124: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 32-125: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 32-126: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 32-127: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 32-128: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-129: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 32-130: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-131: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 32-132: Loss: 0.2137 Acc: 75.0000%\n",
      "\ttrain 32-133: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-134: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 32-135: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 32-136: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 32-137: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 32-138: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 32-139: Loss: 0.2322 Acc: 50.0000%\n",
      "\ttrain 32-140: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 32-141: Loss: 0.1822 Acc: 75.0000%\n",
      "\ttrain 32-142: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 32-143: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 32-144: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 32-145: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 32-146: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 32-147: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 32-148: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-149: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 32-150: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 32-151: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 32-152: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 32-153: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 32-154: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 32-155: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 32-156: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 32-157: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 32-158: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 32-159: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 32-160: Loss: 0.2078 Acc: 75.0000%\n",
      "\ttrain 32-161: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 32-162: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 32-163: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 32-164: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 32-165: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 32-166: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 32-167: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-168: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 32-169: Loss: 0.2355 Acc: 75.0000%\n",
      "\ttrain 32-170: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 32-171: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 32-172: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 32-173: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 32-174: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 32-175: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 32-176: Loss: 0.4889 Acc: 75.0000%\n",
      "\ttrain 32-177: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 32-178: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 32-179: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-180: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 32-181: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 32-182: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 32-183: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 32-184: Loss: 0.2776 Acc: 50.0000%\n",
      "\ttrain 32-185: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-186: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 32-187: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-188: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 32-189: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-190: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 32-191: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 32-192: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 32-193: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 32-194: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 32-195: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 32-196: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 32-197: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 32-198: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 32-199: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 32-200: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-201: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 32-202: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 32-203: Loss: 0.0751 Acc: 100.0000%\n",
      "\ttrain 32-204: Loss: 0.1677 Acc: 50.0000%\n",
      "\ttrain 32-205: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 32-206: Loss: 0.2016 Acc: 50.0000%\n",
      "\ttrain 32-207: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 32-208: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 32-209: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 32-210: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 32-211: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 32-212: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 32-213: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 32-214: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 32-215: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 32-216: Loss: 0.2197 Acc: 75.0000%\n",
      "\ttrain 32-217: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 32-218: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 32-219: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 32-220: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-221: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 32-222: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-223: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 32-224: Loss: 0.0159 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-225: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 32-226: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 32-227: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 32-228: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 32-229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-230: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 32-231: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 32-232: Loss: 0.1661 Acc: 75.0000%\n",
      "\ttrain 32-233: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 32-234: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-235: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 32-236: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 32-237: Loss: 0.2197 Acc: 75.0000%\n",
      "\ttrain 32-238: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 32-239: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 32-240: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 32-241: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 32-242: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 32-243: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 32-244: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 32-245: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 32-1: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 32-2: Loss: 0.1140 Acc: 75.0000%\n",
      "\tvalidation 32-3: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 32-4: Loss: 0.1743 Acc: 75.0000%\n",
      "\tvalidation 32-5: Loss: 0.0907 Acc: 75.0000%\n",
      "\tvalidation 32-6: Loss: 0.1656 Acc: 75.0000%\n",
      "\tvalidation 32-7: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 32-8: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 32-9: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 32-10: Loss: 0.0810 Acc: 75.0000%\n",
      "\tvalidation 32-11: Loss: 0.0645 Acc: 75.0000%\n",
      "\tvalidation 32-12: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 32-13: Loss: 0.0470 Acc: 100.0000%\n",
      "\tvalidation 32-14: Loss: 0.2049 Acc: 75.0000%\n",
      "\tvalidation 32-15: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 32-16: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 32-17: Loss: 0.0531 Acc: 100.0000%\n",
      "\tvalidation 32-18: Loss: 0.2046 Acc: 75.0000%\n",
      "\tvalidation 32-19: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 32-20: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 32-21: Loss: 0.1296 Acc: 75.0000%\n",
      "\tvalidation 32-22: Loss: 0.2611 Acc: 75.0000%\n",
      "\tvalidation 32-23: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 32-24: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 32-25: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 32-26: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 32-27: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 32-28: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 32-29: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 32-30: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 32-31: Loss: 0.1169 Acc: 75.0000%\n",
      "\tvalidation 32-32: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 32-33: Loss: 0.2036 Acc: 75.0000%\n",
      "\tvalidation 32-34: Loss: 0.0738 Acc: 75.0000%\n",
      "\tvalidation 32-35: Loss: 0.1684 Acc: 50.0000%\n",
      "\tvalidation 32-36: Loss: 0.0410 Acc: 100.0000%\n",
      "\tvalidation 32-37: Loss: 0.1320 Acc: 75.0000%\n",
      "\tvalidation 32-38: Loss: 0.0736 Acc: 75.0000%\n",
      "\tvalidation 32-39: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 32-40: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 32-41: Loss: 0.1925 Acc: 50.0000%\n",
      "\tvalidation 32-42: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 32-43: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 32-44: Loss: 0.0788 Acc: 75.0000%\n",
      "\tvalidation 32-45: Loss: 0.1500 Acc: 50.0000%\n",
      "\tvalidation 32-46: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 32-47: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 32-48: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-49: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 32-50: Loss: 0.1103 Acc: 75.0000%\n",
      "\tvalidation 32-51: Loss: 0.1418 Acc: 75.0000%\n",
      "\tvalidation 32-52: Loss: 0.0379 Acc: 100.0000%\n",
      "\tvalidation 32-53: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 32-54: Loss: 0.0907 Acc: 75.0000%\n",
      "\tvalidation 32-55: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 32-56: Loss: 0.1465 Acc: 75.0000%\n",
      "\tvalidation 32-57: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 32-58: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 32-59: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 32-60: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 32-61: Loss: 0.0919 Acc: 75.0000%\n",
      "\tvalidation 32-62: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 32-63: Loss: 0.2270 Acc: 50.0000%\n",
      "\tvalidation 32-64: Loss: 0.0508 Acc: 100.0000%\n",
      "\tvalidation 32-65: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 32-66: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 32-67: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 32-68: Loss: 0.1674 Acc: 75.0000%\n",
      "\tvalidation 32-69: Loss: 0.1465 Acc: 75.0000%\n",
      "\tvalidation 32-70: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 32-71: Loss: 0.1567 Acc: 75.0000%\n",
      "\tvalidation 32-72: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 32-73: Loss: 0.0547 Acc: 75.0000%\n",
      "\tvalidation 32-74: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 32-75: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-76: Loss: 0.1336 Acc: 75.0000%\n",
      "\tvalidation 32-77: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 32-78: Loss: 0.0642 Acc: 75.0000%\n",
      "\tvalidation 32-79: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 32-80: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 32-81: Loss: 0.1054 Acc: 75.0000%\n",
      "\tvalidation 32-82: Loss: 0.0890 Acc: 75.0000%\n",
      "\tvalidation 32-83: Loss: 0.1558 Acc: 75.0000%\n",
      "\tvalidation 32-84: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-85: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 32-86: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 32-87: Loss: 0.1839 Acc: 75.0000%\n",
      "\tvalidation 32-88: Loss: 0.1670 Acc: 75.0000%\n",
      "\tvalidation 32-89: Loss: 0.2391 Acc: 25.0000%\n",
      "\tvalidation 32-90: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 32-91: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 32-92: Loss: 0.1176 Acc: 75.0000%\n",
      "\tvalidation 32-93: Loss: 0.0646 Acc: 100.0000%\n",
      "\tvalidation 32-94: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 32-95: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 32-96: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 32-97: Loss: 0.1647 Acc: 75.0000%\n",
      "\tvalidation 32-98: Loss: 0.0826 Acc: 75.0000%\n",
      "\tvalidation 32-99: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 32-100: Loss: 0.0811 Acc: 75.0000%\n",
      "\tvalidation 32-101: Loss: 0.0503 Acc: 75.0000%\n",
      "\tvalidation 32-102: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 32-103: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 32-104: Loss: 0.1095 Acc: 75.0000%\n",
      "\tvalidation 32-105: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0679 Acc: 89.8980%\n",
      "\tvalidation Loss: 0.0674 Acc: 87.3810%\n",
      "Time passed 0h 24m 50s\n",
      "--------------------\n",
      "Epoch [33/40]:\n",
      "\ttrain 33-1: Loss: 0.0515 Acc: 75.0000%\n",
      "\ttrain 33-2: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 33-3: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 33-4: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 33-5: Loss: 0.4044 Acc: 25.0000%\n",
      "\ttrain 33-6: Loss: 0.2295 Acc: 25.0000%\n",
      "\ttrain 33-7: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 33-8: Loss: 0.2336 Acc: 50.0000%\n",
      "\ttrain 33-9: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 33-10: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 33-11: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 33-12: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 33-13: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 33-14: Loss: 0.3549 Acc: 75.0000%\n",
      "\ttrain 33-15: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 33-16: Loss: 0.2280 Acc: 50.0000%\n",
      "\ttrain 33-17: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 33-18: Loss: 0.2344 Acc: 75.0000%\n",
      "\ttrain 33-19: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 33-20: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 33-21: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 33-22: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 33-23: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 33-24: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 33-25: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 33-26: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 33-27: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 33-28: Loss: 0.1645 Acc: 50.0000%\n",
      "\ttrain 33-29: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-30: Loss: 0.0844 Acc: 100.0000%\n",
      "\ttrain 33-31: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 33-32: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 33-33: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 33-34: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 33-35: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 33-36: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 33-37: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 33-38: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 33-39: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 33-40: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 33-41: Loss: 0.2676 Acc: 50.0000%\n",
      "\ttrain 33-42: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 33-43: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 33-44: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 33-45: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 33-46: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 33-47: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 33-48: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 33-49: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 33-50: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 33-51: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 33-52: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 33-53: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-54: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 33-55: Loss: 0.0083 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-56: Loss: 0.0501 Acc: 75.0000%\n",
      "\ttrain 33-57: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 33-58: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 33-59: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 33-60: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 33-61: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 33-62: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 33-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-64: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-65: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 33-66: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 33-67: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 33-68: Loss: 0.1468 Acc: 75.0000%\n",
      "\ttrain 33-69: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 33-70: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 33-71: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 33-72: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 33-73: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-74: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 33-75: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 33-76: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-77: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 33-78: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 33-79: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 33-80: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 33-81: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 33-82: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-83: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 33-84: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 33-85: Loss: 0.0966 Acc: 50.0000%\n",
      "\ttrain 33-86: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 33-87: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 33-88: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 33-89: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 33-90: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 33-91: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 33-92: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 33-93: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-94: Loss: 0.0672 Acc: 100.0000%\n",
      "\ttrain 33-95: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 33-96: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 33-97: Loss: 0.1706 Acc: 75.0000%\n",
      "\ttrain 33-98: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 33-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-100: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 33-101: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-102: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 33-103: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 33-104: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 33-105: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 33-106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-107: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 33-108: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-109: Loss: 0.3430 Acc: 50.0000%\n",
      "\ttrain 33-110: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 33-111: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 33-112: Loss: 0.4880 Acc: 75.0000%\n",
      "\ttrain 33-113: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-114: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-115: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 33-116: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 33-117: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 33-118: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 33-119: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 33-120: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 33-121: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 33-122: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 33-123: Loss: 0.2192 Acc: 75.0000%\n",
      "\ttrain 33-124: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 33-125: Loss: 0.2334 Acc: 75.0000%\n",
      "\ttrain 33-126: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 33-127: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 33-128: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 33-129: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 33-130: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 33-131: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 33-132: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 33-133: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 33-134: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 33-135: Loss: 0.3082 Acc: 75.0000%\n",
      "\ttrain 33-136: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 33-137: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 33-138: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 33-139: Loss: 0.2581 Acc: 75.0000%\n",
      "\ttrain 33-140: Loss: 0.1491 Acc: 50.0000%\n",
      "\ttrain 33-141: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 33-142: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 33-143: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 33-144: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 33-145: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 33-146: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 33-147: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 33-148: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 33-149: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 33-150: Loss: 0.1707 Acc: 75.0000%\n",
      "\ttrain 33-151: Loss: 0.1382 Acc: 50.0000%\n",
      "\ttrain 33-152: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 33-153: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 33-154: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 33-155: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 33-156: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 33-157: Loss: 0.2094 Acc: 50.0000%\n",
      "\ttrain 33-158: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 33-159: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 33-160: Loss: 0.3331 Acc: 50.0000%\n",
      "\ttrain 33-161: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 33-162: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 33-163: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 33-164: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 33-165: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 33-166: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 33-167: Loss: 0.1517 Acc: 50.0000%\n",
      "\ttrain 33-168: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 33-169: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 33-170: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 33-171: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 33-172: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 33-173: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 33-174: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 33-175: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 33-176: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 33-177: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 33-178: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 33-179: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-180: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-181: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 33-182: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 33-183: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 33-184: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 33-185: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 33-186: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 33-187: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 33-188: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 33-189: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 33-190: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 33-191: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 33-192: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 33-193: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 33-194: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 33-195: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 33-196: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 33-197: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 33-198: Loss: 0.1131 Acc: 50.0000%\n",
      "\ttrain 33-199: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 33-200: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 33-201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-202: Loss: 0.1889 Acc: 50.0000%\n",
      "\ttrain 33-203: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 33-204: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 33-205: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 33-206: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-207: Loss: 0.2135 Acc: 75.0000%\n",
      "\ttrain 33-208: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 33-209: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 33-210: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-211: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 33-212: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-213: Loss: 0.1045 Acc: 75.0000%\n",
      "\ttrain 33-214: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 33-215: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 33-216: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 33-217: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-218: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 33-219: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 33-220: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 33-221: Loss: 0.1875 Acc: 75.0000%\n",
      "\ttrain 33-222: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 33-223: Loss: 0.1833 Acc: 75.0000%\n",
      "\ttrain 33-224: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 33-225: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 33-226: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 33-227: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 33-228: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 33-229: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 33-230: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 33-231: Loss: 0.1640 Acc: 50.0000%\n",
      "\ttrain 33-232: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-233: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 33-234: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 33-235: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 33-236: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 33-237: Loss: 0.2655 Acc: 75.0000%\n",
      "\ttrain 33-238: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 33-239: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 33-240: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 33-241: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-242: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 33-243: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 33-244: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-245: Loss: 0.1205 Acc: 75.0000%\n",
      "\tvalidation 33-1: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 33-2: Loss: 0.0783 Acc: 75.0000%\n",
      "\tvalidation 33-3: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 33-4: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 33-5: Loss: 0.0223 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 33-6: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 33-7: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 33-8: Loss: 0.1869 Acc: 75.0000%\n",
      "\tvalidation 33-9: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-10: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 33-11: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 33-12: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 33-13: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 33-14: Loss: 0.0588 Acc: 75.0000%\n",
      "\tvalidation 33-15: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 33-16: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 33-17: Loss: 0.1878 Acc: 50.0000%\n",
      "\tvalidation 33-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-19: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 33-20: Loss: 0.0789 Acc: 75.0000%\n",
      "\tvalidation 33-21: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 33-22: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 33-23: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 33-24: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 33-25: Loss: 0.0542 Acc: 100.0000%\n",
      "\tvalidation 33-26: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 33-27: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 33-28: Loss: 0.1138 Acc: 75.0000%\n",
      "\tvalidation 33-29: Loss: 0.0796 Acc: 75.0000%\n",
      "\tvalidation 33-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-31: Loss: 0.0662 Acc: 75.0000%\n",
      "\tvalidation 33-32: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 33-33: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 33-34: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 33-35: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 33-36: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 33-37: Loss: 0.1043 Acc: 100.0000%\n",
      "\tvalidation 33-38: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 33-39: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 33-40: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 33-41: Loss: 0.0654 Acc: 75.0000%\n",
      "\tvalidation 33-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-43: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 33-44: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 33-45: Loss: 0.0867 Acc: 75.0000%\n",
      "\tvalidation 33-46: Loss: 0.1215 Acc: 50.0000%\n",
      "\tvalidation 33-47: Loss: 0.1304 Acc: 75.0000%\n",
      "\tvalidation 33-48: Loss: 0.0898 Acc: 75.0000%\n",
      "\tvalidation 33-49: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 33-50: Loss: 0.0505 Acc: 100.0000%\n",
      "\tvalidation 33-51: Loss: 0.1803 Acc: 50.0000%\n",
      "\tvalidation 33-52: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 33-53: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 33-54: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 33-55: Loss: 0.0777 Acc: 75.0000%\n",
      "\tvalidation 33-56: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 33-57: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 33-58: Loss: 0.2546 Acc: 75.0000%\n",
      "\tvalidation 33-59: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 33-60: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-61: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 33-62: Loss: 0.1383 Acc: 75.0000%\n",
      "\tvalidation 33-63: Loss: 0.1582 Acc: 75.0000%\n",
      "\tvalidation 33-64: Loss: 0.1277 Acc: 50.0000%\n",
      "\tvalidation 33-65: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 33-66: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 33-67: Loss: 0.1074 Acc: 75.0000%\n",
      "\tvalidation 33-68: Loss: 0.0649 Acc: 75.0000%\n",
      "\tvalidation 33-69: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 33-70: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 33-71: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 33-72: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 33-73: Loss: 0.1554 Acc: 75.0000%\n",
      "\tvalidation 33-74: Loss: 0.1146 Acc: 75.0000%\n",
      "\tvalidation 33-75: Loss: 0.0762 Acc: 100.0000%\n",
      "\tvalidation 33-76: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 33-77: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 33-78: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 33-79: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 33-80: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 33-81: Loss: 0.1687 Acc: 75.0000%\n",
      "\tvalidation 33-82: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 33-83: Loss: 0.0449 Acc: 100.0000%\n",
      "\tvalidation 33-84: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 33-85: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 33-86: Loss: 0.0527 Acc: 100.0000%\n",
      "\tvalidation 33-87: Loss: 0.1400 Acc: 75.0000%\n",
      "\tvalidation 33-88: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-89: Loss: 0.0741 Acc: 75.0000%\n",
      "\tvalidation 33-90: Loss: 0.1889 Acc: 50.0000%\n",
      "\tvalidation 33-91: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 33-92: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 33-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-94: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 33-95: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 33-96: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 33-97: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 33-98: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 33-99: Loss: 0.1223 Acc: 75.0000%\n",
      "\tvalidation 33-100: Loss: 0.1973 Acc: 50.0000%\n",
      "\tvalidation 33-101: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 33-102: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 33-103: Loss: 0.0241 Acc: 100.0000%\n",
      "\tvalidation 33-104: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 33-105: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0688 Acc: 89.1837%\n",
      "\tvalidation Loss: 0.0489 Acc: 91.1905%\n",
      "Time passed 0h 25m 35s\n",
      "--------------------\n",
      "Epoch [34/40]:\n",
      "\ttrain 34-1: Loss: 0.0802 Acc: 100.0000%\n",
      "\ttrain 34-2: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 34-3: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 34-4: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 34-5: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 34-6: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 34-7: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 34-8: Loss: 0.4129 Acc: 50.0000%\n",
      "\ttrain 34-9: Loss: 0.1679 Acc: 75.0000%\n",
      "\ttrain 34-10: Loss: 0.4073 Acc: 25.0000%\n",
      "\ttrain 34-11: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 34-12: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 34-13: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 34-14: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 34-15: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 34-16: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 34-17: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 34-18: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 34-19: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 34-20: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 34-21: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 34-22: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 34-23: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 34-24: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 34-25: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 34-26: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 34-27: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 34-28: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 34-29: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 34-30: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 34-31: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 34-32: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 34-33: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 34-34: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 34-35: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-36: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 34-37: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 34-38: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 34-39: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 34-40: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-41: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 34-42: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 34-43: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 34-44: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 34-45: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 34-46: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 34-47: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 34-48: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 34-49: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 34-50: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-51: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 34-52: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 34-53: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 34-54: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 34-55: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 34-56: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 34-57: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 34-58: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 34-59: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 34-60: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-61: Loss: 0.1826 Acc: 75.0000%\n",
      "\ttrain 34-62: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 34-63: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 34-64: Loss: 0.0526 Acc: 75.0000%\n",
      "\ttrain 34-65: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 34-66: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 34-67: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 34-68: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 34-69: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 34-70: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 34-71: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 34-72: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 34-73: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 34-74: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 34-75: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-76: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 34-77: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 34-78: Loss: 0.1143 Acc: 50.0000%\n",
      "\ttrain 34-79: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 34-80: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 34-81: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 34-82: Loss: 0.0217 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-83: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-84: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 34-85: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 34-86: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 34-87: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 34-88: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 34-89: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 34-90: Loss: 0.2100 Acc: 75.0000%\n",
      "\ttrain 34-91: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 34-92: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 34-93: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 34-94: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 34-95: Loss: 0.1994 Acc: 75.0000%\n",
      "\ttrain 34-96: Loss: 0.3092 Acc: 75.0000%\n",
      "\ttrain 34-97: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 34-98: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 34-99: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 34-100: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-101: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 34-102: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 34-103: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 34-104: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 34-105: Loss: 0.2380 Acc: 75.0000%\n",
      "\ttrain 34-106: Loss: 0.1523 Acc: 75.0000%\n",
      "\ttrain 34-107: Loss: 0.3119 Acc: 25.0000%\n",
      "\ttrain 34-108: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-109: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 34-110: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 34-111: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 34-112: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 34-113: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 34-114: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 34-115: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 34-116: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-117: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 34-118: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 34-119: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 34-120: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 34-121: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 34-122: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 34-123: Loss: 0.1820 Acc: 75.0000%\n",
      "\ttrain 34-124: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 34-125: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 34-126: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 34-127: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 34-128: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-129: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 34-130: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 34-131: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 34-132: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 34-133: Loss: 0.2695 Acc: 50.0000%\n",
      "\ttrain 34-134: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 34-135: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 34-136: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 34-137: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 34-138: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 34-139: Loss: 0.1637 Acc: 75.0000%\n",
      "\ttrain 34-140: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-141: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 34-142: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 34-143: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 34-144: Loss: 0.1883 Acc: 75.0000%\n",
      "\ttrain 34-145: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-146: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 34-147: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 34-148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-149: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 34-150: Loss: 0.1040 Acc: 75.0000%\n",
      "\ttrain 34-151: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 34-152: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 34-153: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 34-154: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 34-155: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 34-156: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 34-157: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 34-158: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 34-159: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 34-160: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-161: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 34-162: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 34-163: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 34-164: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 34-165: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 34-166: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 34-167: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 34-168: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-169: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 34-170: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 34-171: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-172: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 34-173: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 34-174: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-176: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-177: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 34-178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-179: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-180: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 34-181: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 34-182: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-183: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 34-184: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 34-185: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 34-186: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-187: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 34-188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-189: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 34-190: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 34-191: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 34-192: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 34-193: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 34-194: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-195: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 34-196: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 34-197: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-198: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 34-199: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-200: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 34-201: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 34-202: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 34-203: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 34-204: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-205: Loss: 0.0477 Acc: 75.0000%\n",
      "\ttrain 34-206: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 34-207: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 34-208: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 34-209: Loss: 0.2298 Acc: 75.0000%\n",
      "\ttrain 34-210: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-211: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 34-212: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-213: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 34-214: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-215: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 34-216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-217: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 34-218: Loss: 0.2193 Acc: 75.0000%\n",
      "\ttrain 34-219: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 34-220: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 34-221: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 34-222: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 34-223: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-224: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 34-225: Loss: 0.4650 Acc: 50.0000%\n",
      "\ttrain 34-226: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 34-227: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 34-228: Loss: 0.0612 Acc: 100.0000%\n",
      "\ttrain 34-229: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 34-230: Loss: 0.1396 Acc: 75.0000%\n",
      "\ttrain 34-231: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 34-232: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-233: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 34-234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-235: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-236: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 34-237: Loss: 0.2939 Acc: 75.0000%\n",
      "\ttrain 34-238: Loss: 0.1947 Acc: 75.0000%\n",
      "\ttrain 34-239: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 34-240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-241: Loss: 0.1972 Acc: 50.0000%\n",
      "\ttrain 34-242: Loss: 0.1380 Acc: 75.0000%\n",
      "\ttrain 34-243: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 34-244: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 34-245: Loss: 0.0538 Acc: 100.0000%\n",
      "\tvalidation 34-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-2: Loss: 0.0507 Acc: 100.0000%\n",
      "\tvalidation 34-3: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 34-4: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 34-5: Loss: 0.0869 Acc: 75.0000%\n",
      "\tvalidation 34-6: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 34-7: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 34-8: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 34-9: Loss: 0.1089 Acc: 75.0000%\n",
      "\tvalidation 34-10: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 34-11: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 34-12: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 34-13: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 34-14: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 34-15: Loss: 0.1118 Acc: 75.0000%\n",
      "\tvalidation 34-16: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 34-17: Loss: 0.2369 Acc: 50.0000%\n",
      "\tvalidation 34-18: Loss: 0.1191 Acc: 75.0000%\n",
      "\tvalidation 34-19: Loss: 0.1086 Acc: 50.0000%\n",
      "\tvalidation 34-20: Loss: 0.0525 Acc: 100.0000%\n",
      "\tvalidation 34-21: Loss: 0.0590 Acc: 100.0000%\n",
      "\tvalidation 34-22: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 34-23: Loss: 0.1462 Acc: 75.0000%\n",
      "\tvalidation 34-24: Loss: 0.0765 Acc: 75.0000%\n",
      "\tvalidation 34-25: Loss: 0.0487 Acc: 100.0000%\n",
      "\tvalidation 34-26: Loss: 0.0710 Acc: 75.0000%\n",
      "\tvalidation 34-27: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 34-28: Loss: 0.0323 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 34-29: Loss: 0.0947 Acc: 75.0000%\n",
      "\tvalidation 34-30: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 34-31: Loss: 0.0512 Acc: 100.0000%\n",
      "\tvalidation 34-32: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 34-33: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 34-34: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 34-35: Loss: 0.0698 Acc: 100.0000%\n",
      "\tvalidation 34-36: Loss: 0.0842 Acc: 75.0000%\n",
      "\tvalidation 34-37: Loss: 0.0631 Acc: 75.0000%\n",
      "\tvalidation 34-38: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 34-39: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 34-40: Loss: 0.1670 Acc: 50.0000%\n",
      "\tvalidation 34-41: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 34-42: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 34-43: Loss: 0.0900 Acc: 100.0000%\n",
      "\tvalidation 34-44: Loss: 0.0488 Acc: 100.0000%\n",
      "\tvalidation 34-45: Loss: 0.0419 Acc: 100.0000%\n",
      "\tvalidation 34-46: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 34-47: Loss: 0.0367 Acc: 100.0000%\n",
      "\tvalidation 34-48: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 34-49: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 34-50: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 34-51: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 34-52: Loss: 0.0706 Acc: 75.0000%\n",
      "\tvalidation 34-53: Loss: 0.0667 Acc: 100.0000%\n",
      "\tvalidation 34-54: Loss: 0.0972 Acc: 75.0000%\n",
      "\tvalidation 34-55: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 34-56: Loss: 0.0625 Acc: 75.0000%\n",
      "\tvalidation 34-57: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 34-58: Loss: 0.0491 Acc: 100.0000%\n",
      "\tvalidation 34-59: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 34-60: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 34-61: Loss: 0.0824 Acc: 75.0000%\n",
      "\tvalidation 34-62: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 34-63: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 34-64: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 34-65: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 34-66: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 34-67: Loss: 0.0928 Acc: 75.0000%\n",
      "\tvalidation 34-68: Loss: 0.1412 Acc: 75.0000%\n",
      "\tvalidation 34-69: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 34-70: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 34-71: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 34-72: Loss: 0.0692 Acc: 100.0000%\n",
      "\tvalidation 34-73: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 34-74: Loss: 0.0884 Acc: 75.0000%\n",
      "\tvalidation 34-75: Loss: 0.1006 Acc: 75.0000%\n",
      "\tvalidation 34-76: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 34-77: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 34-78: Loss: 0.1395 Acc: 50.0000%\n",
      "\tvalidation 34-79: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 34-80: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 34-81: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 34-82: Loss: 0.0798 Acc: 75.0000%\n",
      "\tvalidation 34-83: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 34-84: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 34-85: Loss: 0.1325 Acc: 75.0000%\n",
      "\tvalidation 34-86: Loss: 0.0792 Acc: 75.0000%\n",
      "\tvalidation 34-87: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 34-88: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 34-89: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 34-90: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 34-91: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 34-92: Loss: 0.1068 Acc: 75.0000%\n",
      "\tvalidation 34-93: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 34-94: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 34-95: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 34-96: Loss: 0.0487 Acc: 100.0000%\n",
      "\tvalidation 34-97: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-98: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 34-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-100: Loss: 0.1981 Acc: 75.0000%\n",
      "\tvalidation 34-101: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 34-102: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 34-103: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 34-104: Loss: 0.1061 Acc: 75.0000%\n",
      "\tvalidation 34-105: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0579 Acc: 91.1224%\n",
      "\tvalidation Loss: 0.0523 Acc: 91.4286%\n",
      "Time passed 0h 26m 19s\n",
      "--------------------\n",
      "Epoch [35/40]:\n",
      "\ttrain 35-1: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 35-2: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 35-3: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 35-4: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 35-5: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 35-6: Loss: 0.0699 Acc: 100.0000%\n",
      "\ttrain 35-7: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 35-8: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 35-9: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-10: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-11: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 35-12: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-13: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 35-14: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 35-15: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 35-16: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 35-17: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 35-18: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-19: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 35-20: Loss: 0.1457 Acc: 50.0000%\n",
      "\ttrain 35-21: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 35-22: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 35-23: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 35-24: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 35-25: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 35-26: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 35-27: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 35-28: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 35-29: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 35-30: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 35-31: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 35-32: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 35-33: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 35-34: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 35-35: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-36: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 35-37: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 35-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-39: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-40: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-41: Loss: 0.1514 Acc: 75.0000%\n",
      "\ttrain 35-42: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 35-43: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 35-44: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 35-45: Loss: 0.2116 Acc: 75.0000%\n",
      "\ttrain 35-46: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 35-47: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 35-48: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 35-49: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 35-50: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-51: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 35-52: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 35-53: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 35-54: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 35-55: Loss: 0.1485 Acc: 75.0000%\n",
      "\ttrain 35-56: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 35-57: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 35-58: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 35-59: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 35-60: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 35-61: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 35-62: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 35-63: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 35-64: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 35-65: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 35-66: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 35-67: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 35-68: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 35-69: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 35-70: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 35-71: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 35-72: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 35-73: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 35-74: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 35-75: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 35-76: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-77: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 35-78: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 35-79: Loss: 0.2131 Acc: 75.0000%\n",
      "\ttrain 35-80: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 35-81: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-82: Loss: 0.1018 Acc: 50.0000%\n",
      "\ttrain 35-83: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-84: Loss: 0.2401 Acc: 75.0000%\n",
      "\ttrain 35-85: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-86: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 35-87: Loss: 0.3620 Acc: 50.0000%\n",
      "\ttrain 35-88: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 35-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 35-90: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 35-91: Loss: 0.3043 Acc: 50.0000%\n",
      "\ttrain 35-92: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 35-93: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 35-94: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 35-95: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 35-96: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 35-97: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 35-98: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 35-99: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 35-100: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 35-101: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 35-102: Loss: 0.5834 Acc: 50.0000%\n",
      "\ttrain 35-103: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 35-104: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 35-105: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 35-106: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 35-107: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 35-108: Loss: 0.0235 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-109: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-110: Loss: 0.2213 Acc: 75.0000%\n",
      "\ttrain 35-111: Loss: 0.1646 Acc: 75.0000%\n",
      "\ttrain 35-112: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 35-113: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-114: Loss: 0.2064 Acc: 50.0000%\n",
      "\ttrain 35-115: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 35-116: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 35-117: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 35-118: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 35-119: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 35-120: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 35-121: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 35-122: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 35-123: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 35-124: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 35-125: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 35-126: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 35-127: Loss: 0.1604 Acc: 75.0000%\n",
      "\ttrain 35-128: Loss: 0.1863 Acc: 75.0000%\n",
      "\ttrain 35-129: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 35-130: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-131: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 35-132: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 35-133: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 35-134: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-135: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 35-136: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 35-137: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 35-138: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-139: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-140: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 35-141: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 35-142: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 35-143: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 35-144: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 35-145: Loss: 0.0506 Acc: 75.0000%\n",
      "\ttrain 35-146: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 35-147: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 35-148: Loss: 0.1637 Acc: 50.0000%\n",
      "\ttrain 35-149: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 35-150: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 35-151: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-152: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 35-153: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 35-154: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 35-155: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 35-156: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 35-157: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 35-158: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 35-159: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 35-160: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 35-161: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 35-162: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 35-163: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 35-164: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 35-165: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 35-166: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 35-167: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 35-168: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 35-169: Loss: 0.2489 Acc: 50.0000%\n",
      "\ttrain 35-170: Loss: 0.1637 Acc: 75.0000%\n",
      "\ttrain 35-171: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 35-172: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 35-173: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 35-174: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-175: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 35-176: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 35-177: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 35-178: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 35-179: Loss: 0.2883 Acc: 75.0000%\n",
      "\ttrain 35-180: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 35-181: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 35-182: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 35-183: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 35-184: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 35-185: Loss: 0.0536 Acc: 75.0000%\n",
      "\ttrain 35-186: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-187: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-188: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 35-189: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-190: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 35-191: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 35-192: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 35-193: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 35-194: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 35-195: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 35-196: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 35-197: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 35-198: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 35-199: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 35-200: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 35-201: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 35-202: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 35-203: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 35-204: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 35-205: Loss: 0.2732 Acc: 75.0000%\n",
      "\ttrain 35-206: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 35-207: Loss: 0.1855 Acc: 75.0000%\n",
      "\ttrain 35-208: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 35-209: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 35-210: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 35-211: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 35-212: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 35-213: Loss: 0.3366 Acc: 25.0000%\n",
      "\ttrain 35-214: Loss: 0.0898 Acc: 100.0000%\n",
      "\ttrain 35-215: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 35-216: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 35-217: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 35-218: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 35-219: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 35-220: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 35-221: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 35-222: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 35-223: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 35-224: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 35-225: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 35-226: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 35-227: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-228: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 35-229: Loss: 0.1077 Acc: 50.0000%\n",
      "\ttrain 35-230: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 35-231: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 35-232: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 35-233: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 35-234: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 35-235: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-236: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 35-237: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-238: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 35-239: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-240: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-241: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-242: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 35-243: Loss: 0.3426 Acc: 50.0000%\n",
      "\ttrain 35-244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 35-245: Loss: 0.0757 Acc: 75.0000%\n",
      "\tvalidation 35-1: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-2: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 35-3: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 35-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-5: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-6: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 35-7: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 35-8: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 35-9: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-10: Loss: 0.0482 Acc: 100.0000%\n",
      "\tvalidation 35-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-12: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 35-13: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 35-14: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-15: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 35-16: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-17: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 35-18: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-19: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 35-20: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-21: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 35-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-23: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-25: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 35-26: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 35-27: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 35-28: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-29: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 35-30: Loss: 0.0998 Acc: 75.0000%\n",
      "\tvalidation 35-31: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-32: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 35-33: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 35-34: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-35: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 35-36: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 35-37: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 35-38: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-39: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-40: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 35-41: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-43: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 35-44: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-46: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 35-47: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-49: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-50: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 35-51: Loss: 0.2463 Acc: 75.0000%\n",
      "\tvalidation 35-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-53: Loss: 0.0540 Acc: 100.0000%\n",
      "\tvalidation 35-54: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 35-55: Loss: 0.0128 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 35-56: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 35-57: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 35-58: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 35-59: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 35-60: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-61: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 35-62: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 35-63: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 35-64: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-65: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 35-66: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-67: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-68: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 35-69: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 35-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-72: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 35-73: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 35-74: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 35-75: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 35-76: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 35-77: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 35-78: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-79: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 35-80: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-81: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 35-82: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-83: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-85: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 35-86: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 35-87: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 35-88: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-89: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 35-90: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 35-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-92: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-93: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 35-94: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 35-95: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 35-96: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 35-97: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 35-98: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 35-99: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 35-100: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 35-101: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 35-102: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 35-103: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 35-104: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 35-105: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0550 Acc: 91.4286%\n",
      "\tvalidation Loss: 0.0112 Acc: 99.2857%\n",
      "网络参数更新\n",
      "Time passed 0h 27m 7s\n",
      "--------------------\n",
      "Epoch [36/40]:\n",
      "\ttrain 36-1: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 36-2: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 36-3: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 36-4: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-5: Loss: 0.1335 Acc: 75.0000%\n",
      "\ttrain 36-6: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 36-7: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-8: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 36-9: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 36-10: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 36-11: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 36-12: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-13: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-15: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-16: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 36-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-19: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-20: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-21: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 36-22: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 36-23: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 36-24: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 36-25: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 36-26: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-27: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-28: Loss: 0.3342 Acc: 75.0000%\n",
      "\ttrain 36-29: Loss: 0.1823 Acc: 75.0000%\n",
      "\ttrain 36-30: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 36-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-33: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 36-34: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 36-35: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 36-36: Loss: 0.1808 Acc: 75.0000%\n",
      "\ttrain 36-37: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-38: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 36-39: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 36-40: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 36-41: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 36-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-43: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 36-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-45: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-46: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-47: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 36-48: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 36-49: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 36-50: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 36-51: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 36-52: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 36-53: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 36-54: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 36-55: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 36-56: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 36-57: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 36-58: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 36-59: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 36-60: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 36-61: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 36-62: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 36-63: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-64: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-65: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 36-66: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 36-67: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 36-68: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 36-69: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 36-70: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 36-71: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 36-72: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 36-73: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 36-74: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 36-75: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 36-76: Loss: 0.1129 Acc: 50.0000%\n",
      "\ttrain 36-77: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 36-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-79: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-80: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 36-81: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-82: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 36-83: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-84: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 36-85: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-86: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-87: Loss: 0.2716 Acc: 75.0000%\n",
      "\ttrain 36-88: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 36-89: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 36-90: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-91: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 36-92: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 36-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-94: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 36-95: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 36-96: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-97: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-98: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 36-99: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 36-100: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 36-101: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 36-102: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-103: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-104: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 36-105: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 36-106: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 36-107: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-108: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 36-109: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 36-110: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 36-111: Loss: 0.1241 Acc: 75.0000%\n",
      "\ttrain 36-112: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 36-113: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 36-114: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 36-115: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 36-116: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 36-117: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 36-118: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 36-119: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 36-120: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 36-121: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-122: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-123: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-124: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 36-125: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 36-126: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 36-127: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-128: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 36-129: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 36-130: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 36-131: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 36-132: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 36-133: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 36-134: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-135: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 36-136: Loss: 0.0473 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-137: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-138: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-139: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-140: Loss: 0.2268 Acc: 75.0000%\n",
      "\ttrain 36-141: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 36-142: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-143: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-144: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-145: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 36-146: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-147: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 36-148: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 36-149: Loss: 0.1416 Acc: 75.0000%\n",
      "\ttrain 36-150: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-151: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-152: Loss: 0.0754 Acc: 100.0000%\n",
      "\ttrain 36-153: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 36-154: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 36-155: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-156: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-157: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 36-158: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-159: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-160: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-161: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 36-162: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 36-163: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-164: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-165: Loss: 0.0468 Acc: 75.0000%\n",
      "\ttrain 36-166: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 36-167: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-168: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-169: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-170: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 36-171: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 36-172: Loss: 0.7655 Acc: 50.0000%\n",
      "\ttrain 36-173: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 36-174: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-175: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-176: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-177: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 36-178: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 36-179: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-180: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 36-181: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 36-182: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-183: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 36-184: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-185: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 36-186: Loss: 0.0547 Acc: 75.0000%\n",
      "\ttrain 36-187: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-188: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 36-189: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 36-190: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 36-191: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 36-192: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-193: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 36-194: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 36-195: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-196: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 36-197: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 36-198: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 36-199: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 36-200: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-201: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 36-202: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-203: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 36-204: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 36-205: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-206: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-207: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-208: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 36-209: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 36-210: Loss: 0.1386 Acc: 75.0000%\n",
      "\ttrain 36-211: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 36-212: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 36-213: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 36-214: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 36-215: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-216: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-217: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 36-218: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-219: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-220: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-221: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 36-222: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 36-223: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-224: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-225: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 36-226: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 36-227: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-228: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 36-229: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-230: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 36-231: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 36-232: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-233: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-234: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-235: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-236: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 36-237: Loss: 0.2705 Acc: 50.0000%\n",
      "\ttrain 36-238: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 36-239: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-240: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 36-241: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 36-242: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-243: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-244: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 36-245: Loss: 0.1704 Acc: 75.0000%\n",
      "\tvalidation 36-1: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 36-2: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-4: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-5: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 36-6: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-8: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 36-9: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-11: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 36-12: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-13: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-14: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 36-15: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 36-16: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 36-17: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-19: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-20: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 36-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-22: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-23: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-24: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 36-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-26: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 36-27: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 36-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-30: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-31: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-33: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 36-34: Loss: 0.0621 Acc: 75.0000%\n",
      "\tvalidation 36-35: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-36: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 36-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-38: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 36-39: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 36-40: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 36-41: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-43: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-44: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 36-45: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 36-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-49: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 36-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-52: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 36-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-54: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-57: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 36-58: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 36-59: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 36-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-61: Loss: 0.1233 Acc: 75.0000%\n",
      "\tvalidation 36-62: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-65: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 36-66: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 36-67: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 36-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-70: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 36-71: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-73: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-74: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 36-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-76: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 36-77: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 36-78: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-80: Loss: 0.0025 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 36-81: Loss: 0.0710 Acc: 75.0000%\n",
      "\tvalidation 36-82: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 36-83: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-84: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 36-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-86: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 36-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-88: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 36-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-90: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-91: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-93: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-95: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 36-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-98: Loss: 0.0619 Acc: 75.0000%\n",
      "\tvalidation 36-99: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 36-100: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 36-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-102: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 36-103: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 36-104: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 36-105: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0365 Acc: 94.7959%\n",
      "\tvalidation Loss: 0.0064 Acc: 99.0476%\n",
      "Time passed 0h 27m 52s\n",
      "--------------------\n",
      "Epoch [37/40]:\n",
      "\ttrain 37-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-2: Loss: 0.1633 Acc: 75.0000%\n",
      "\ttrain 37-3: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 37-4: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 37-5: Loss: 0.2222 Acc: 75.0000%\n",
      "\ttrain 37-6: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 37-7: Loss: 0.0562 Acc: 75.0000%\n",
      "\ttrain 37-8: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 37-9: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 37-10: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 37-11: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 37-12: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 37-13: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 37-14: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 37-15: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 37-16: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 37-17: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 37-18: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-20: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 37-21: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 37-22: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 37-23: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 37-24: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-25: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-28: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 37-29: Loss: 0.3337 Acc: 75.0000%\n",
      "\ttrain 37-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-31: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 37-32: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-33: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 37-34: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 37-35: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-36: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 37-37: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 37-38: Loss: 0.1806 Acc: 75.0000%\n",
      "\ttrain 37-39: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 37-40: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 37-41: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 37-42: Loss: 0.2473 Acc: 50.0000%\n",
      "\ttrain 37-43: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 37-44: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 37-45: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 37-46: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 37-47: Loss: 0.1564 Acc: 50.0000%\n",
      "\ttrain 37-48: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-49: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 37-50: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 37-51: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 37-52: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-53: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 37-54: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 37-55: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 37-56: Loss: 0.0543 Acc: 75.0000%\n",
      "\ttrain 37-57: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 37-58: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 37-59: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 37-60: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 37-61: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 37-62: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 37-63: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 37-64: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 37-65: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 37-66: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 37-67: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 37-68: Loss: 0.1860 Acc: 75.0000%\n",
      "\ttrain 37-69: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 37-70: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 37-71: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 37-72: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-73: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 37-74: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 37-75: Loss: 0.3013 Acc: 50.0000%\n",
      "\ttrain 37-76: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 37-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-78: Loss: 0.2243 Acc: 50.0000%\n",
      "\ttrain 37-79: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 37-80: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 37-81: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 37-82: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 37-83: Loss: 0.2293 Acc: 75.0000%\n",
      "\ttrain 37-84: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 37-85: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 37-86: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 37-87: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 37-88: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 37-89: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 37-90: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 37-91: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 37-92: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 37-93: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 37-94: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 37-95: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 37-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-97: Loss: 0.2775 Acc: 50.0000%\n",
      "\ttrain 37-98: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 37-99: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-100: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 37-101: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 37-102: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 37-103: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 37-104: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 37-105: Loss: 0.1479 Acc: 75.0000%\n",
      "\ttrain 37-106: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-107: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 37-108: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 37-109: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 37-110: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 37-111: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 37-112: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 37-113: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-114: Loss: 0.0488 Acc: 75.0000%\n",
      "\ttrain 37-115: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 37-116: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 37-117: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 37-118: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 37-119: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 37-120: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 37-121: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 37-122: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 37-123: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-124: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 37-125: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 37-126: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 37-127: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 37-128: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 37-129: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 37-130: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 37-131: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 37-132: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-133: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-134: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-135: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-136: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-137: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-138: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-140: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-141: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 37-142: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 37-143: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-144: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 37-145: Loss: 0.1582 Acc: 75.0000%\n",
      "\ttrain 37-146: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-147: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 37-148: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 37-149: Loss: 0.2620 Acc: 75.0000%\n",
      "\ttrain 37-150: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 37-151: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-152: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 37-153: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 37-154: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 37-155: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 37-156: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 37-157: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-158: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 37-159: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-160: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 37-161: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 37-162: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-163: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 37-164: Loss: 0.0232 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-165: Loss: 0.0613 Acc: 100.0000%\n",
      "\ttrain 37-166: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 37-167: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-168: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 37-169: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 37-170: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 37-171: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 37-172: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 37-173: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-174: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 37-175: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-176: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 37-177: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 37-178: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 37-179: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 37-180: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 37-181: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-182: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-183: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 37-184: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-185: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-186: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 37-187: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 37-188: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-189: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 37-190: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-191: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-192: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 37-193: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 37-194: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 37-195: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-196: Loss: 0.2985 Acc: 75.0000%\n",
      "\ttrain 37-197: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 37-198: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 37-199: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 37-200: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 37-201: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-202: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-203: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 37-204: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 37-205: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-206: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 37-207: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 37-208: Loss: 0.0761 Acc: 75.0000%\n",
      "\ttrain 37-209: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 37-210: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 37-211: Loss: 0.2225 Acc: 75.0000%\n",
      "\ttrain 37-212: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 37-213: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 37-214: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 37-215: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 37-216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-217: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 37-218: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 37-219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-220: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 37-221: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-222: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-223: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 37-224: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 37-225: Loss: 0.0607 Acc: 75.0000%\n",
      "\ttrain 37-226: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 37-227: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-228: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 37-229: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-230: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 37-231: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-232: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 37-233: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 37-234: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 37-235: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-236: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 37-237: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-238: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-239: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-240: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 37-241: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 37-242: Loss: 0.1729 Acc: 75.0000%\n",
      "\ttrain 37-243: Loss: 0.1585 Acc: 75.0000%\n",
      "\ttrain 37-244: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-245: Loss: 0.0805 Acc: 100.0000%\n",
      "\tvalidation 37-1: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 37-2: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 37-3: Loss: 0.0977 Acc: 75.0000%\n",
      "\tvalidation 37-4: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 37-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-6: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 37-7: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 37-8: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 37-9: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 37-10: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 37-11: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 37-12: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-13: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 37-14: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-15: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 37-16: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-17: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-18: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 37-19: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 37-20: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 37-21: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-22: Loss: 0.0674 Acc: 75.0000%\n",
      "\tvalidation 37-23: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 37-24: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 37-25: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 37-26: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 37-27: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 37-28: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 37-29: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 37-30: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 37-31: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 37-32: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 37-33: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 37-34: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 37-35: Loss: 0.0845 Acc: 75.0000%\n",
      "\tvalidation 37-36: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 37-37: Loss: 0.0481 Acc: 100.0000%\n",
      "\tvalidation 37-38: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-39: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-40: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 37-41: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-42: Loss: 0.0741 Acc: 75.0000%\n",
      "\tvalidation 37-43: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 37-44: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-45: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 37-46: Loss: 0.0537 Acc: 100.0000%\n",
      "\tvalidation 37-47: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-48: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-49: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 37-50: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 37-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-52: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 37-53: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 37-54: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 37-55: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 37-56: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 37-57: Loss: 0.0624 Acc: 75.0000%\n",
      "\tvalidation 37-58: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 37-59: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 37-60: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 37-61: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 37-62: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 37-63: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 37-64: Loss: 0.0517 Acc: 100.0000%\n",
      "\tvalidation 37-65: Loss: 0.0356 Acc: 100.0000%\n",
      "\tvalidation 37-66: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 37-67: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 37-68: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 37-69: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 37-70: Loss: 0.1441 Acc: 75.0000%\n",
      "\tvalidation 37-71: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 37-72: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 37-73: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 37-74: Loss: 0.1492 Acc: 50.0000%\n",
      "\tvalidation 37-75: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 37-76: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-77: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 37-78: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 37-79: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 37-80: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 37-81: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 37-82: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 37-83: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 37-84: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 37-85: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 37-86: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 37-87: Loss: 0.0878 Acc: 75.0000%\n",
      "\tvalidation 37-88: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-90: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 37-91: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 37-92: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 37-93: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-94: Loss: 0.1204 Acc: 75.0000%\n",
      "\tvalidation 37-95: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 37-96: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 37-97: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 37-98: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 37-99: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 37-100: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 37-101: Loss: 0.0202 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 37-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-103: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 37-104: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 37-105: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0486 Acc: 91.8367%\n",
      "\tvalidation Loss: 0.0192 Acc: 97.6190%\n",
      "Time passed 0h 28m 37s\n",
      "--------------------\n",
      "Epoch [38/40]:\n",
      "\ttrain 38-1: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 38-2: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 38-3: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 38-4: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 38-5: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 38-6: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 38-7: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 38-8: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 38-9: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 38-10: Loss: 0.2134 Acc: 75.0000%\n",
      "\ttrain 38-11: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 38-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-13: Loss: 0.2045 Acc: 75.0000%\n",
      "\ttrain 38-14: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 38-15: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-16: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-17: Loss: 0.3664 Acc: 75.0000%\n",
      "\ttrain 38-18: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-20: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 38-21: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-22: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 38-23: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 38-24: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 38-25: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 38-26: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 38-27: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-28: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 38-29: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 38-30: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 38-31: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 38-32: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 38-33: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 38-34: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 38-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-36: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 38-37: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 38-38: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-39: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 38-40: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 38-41: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 38-42: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 38-43: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 38-44: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 38-45: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 38-46: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-47: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-48: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 38-49: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 38-50: Loss: 0.2877 Acc: 50.0000%\n",
      "\ttrain 38-51: Loss: 0.1647 Acc: 50.0000%\n",
      "\ttrain 38-52: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 38-53: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 38-54: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 38-55: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 38-56: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 38-57: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-58: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 38-59: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 38-60: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 38-61: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-62: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 38-63: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 38-64: Loss: 0.2139 Acc: 75.0000%\n",
      "\ttrain 38-65: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 38-66: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 38-67: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-68: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 38-69: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-70: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 38-71: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 38-72: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 38-73: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 38-74: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 38-75: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 38-76: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 38-77: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-78: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 38-79: Loss: 0.0729 Acc: 75.0000%\n",
      "\ttrain 38-80: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 38-81: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 38-82: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-83: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 38-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-85: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 38-86: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 38-87: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 38-88: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-89: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 38-90: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-92: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 38-93: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-94: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-95: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 38-96: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 38-97: Loss: 0.1171 Acc: 50.0000%\n",
      "\ttrain 38-98: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-99: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 38-100: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 38-101: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 38-102: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 38-103: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 38-104: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-105: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 38-106: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 38-107: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 38-108: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 38-109: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 38-110: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 38-111: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 38-112: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 38-113: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-114: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 38-115: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-116: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-117: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 38-118: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-119: Loss: 0.1737 Acc: 75.0000%\n",
      "\ttrain 38-120: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 38-121: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-122: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 38-123: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 38-124: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 38-125: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-126: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 38-127: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 38-128: Loss: 0.1468 Acc: 75.0000%\n",
      "\ttrain 38-129: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 38-130: Loss: 0.2564 Acc: 50.0000%\n",
      "\ttrain 38-131: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 38-132: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 38-133: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-134: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 38-135: Loss: 0.3597 Acc: 75.0000%\n",
      "\ttrain 38-136: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-137: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 38-138: Loss: 0.2988 Acc: 50.0000%\n",
      "\ttrain 38-139: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 38-140: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-141: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 38-142: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 38-143: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 38-144: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 38-145: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 38-146: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 38-147: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 38-148: Loss: 0.1089 Acc: 75.0000%\n",
      "\ttrain 38-149: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-150: Loss: 0.1176 Acc: 100.0000%\n",
      "\ttrain 38-151: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 38-152: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 38-153: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 38-154: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-155: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 38-156: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-157: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 38-158: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 38-159: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 38-160: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 38-161: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 38-162: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-163: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 38-164: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-165: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-166: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-167: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 38-168: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 38-169: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-170: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 38-171: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 38-172: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 38-173: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-174: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-175: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-176: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-177: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-178: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-179: Loss: 0.2004 Acc: 75.0000%\n",
      "\ttrain 38-180: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 38-181: Loss: 0.2833 Acc: 75.0000%\n",
      "\ttrain 38-182: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 38-183: Loss: 0.1760 Acc: 75.0000%\n",
      "\ttrain 38-184: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 38-185: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 38-186: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 38-187: Loss: 0.0706 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 38-188: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 38-189: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 38-190: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 38-191: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-192: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 38-193: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-194: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-195: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-196: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-197: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-198: Loss: 0.3271 Acc: 75.0000%\n",
      "\ttrain 38-199: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-200: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-201: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 38-202: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-203: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-204: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 38-205: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 38-206: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 38-207: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 38-208: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 38-209: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-210: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 38-211: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-212: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 38-213: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 38-214: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-215: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 38-216: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 38-217: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 38-218: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 38-219: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 38-220: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 38-221: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 38-222: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-223: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 38-224: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 38-225: Loss: 0.1277 Acc: 50.0000%\n",
      "\ttrain 38-226: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 38-227: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 38-228: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-229: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-230: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-231: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 38-232: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 38-233: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 38-234: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 38-235: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 38-236: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 38-237: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 38-238: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 38-239: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 38-240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-241: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 38-242: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 38-243: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 38-244: Loss: 0.2054 Acc: 75.0000%\n",
      "\ttrain 38-245: Loss: 0.0621 Acc: 75.0000%\n",
      "\tvalidation 38-1: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 38-2: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 38-3: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 38-4: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-5: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-6: Loss: 0.1784 Acc: 75.0000%\n",
      "\tvalidation 38-7: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 38-8: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 38-9: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-10: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 38-11: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 38-12: Loss: 0.2489 Acc: 75.0000%\n",
      "\tvalidation 38-13: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 38-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-15: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-17: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 38-18: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 38-19: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 38-20: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 38-21: Loss: 0.0509 Acc: 75.0000%\n",
      "\tvalidation 38-22: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 38-23: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-24: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 38-25: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 38-26: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 38-27: Loss: 0.0567 Acc: 75.0000%\n",
      "\tvalidation 38-28: Loss: 0.1617 Acc: 75.0000%\n",
      "\tvalidation 38-29: Loss: 0.0459 Acc: 100.0000%\n",
      "\tvalidation 38-30: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 38-31: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 38-32: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-33: Loss: 0.0683 Acc: 75.0000%\n",
      "\tvalidation 38-34: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 38-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-36: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 38-37: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 38-38: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 38-39: Loss: 0.0557 Acc: 75.0000%\n",
      "\tvalidation 38-40: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 38-41: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 38-42: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 38-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-44: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 38-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-46: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 38-47: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 38-48: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 38-49: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-50: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-51: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-52: Loss: 0.0708 Acc: 75.0000%\n",
      "\tvalidation 38-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-55: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 38-56: Loss: 0.1952 Acc: 75.0000%\n",
      "\tvalidation 38-57: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 38-58: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 38-59: Loss: 0.0726 Acc: 100.0000%\n",
      "\tvalidation 38-60: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 38-61: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 38-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-63: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-64: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 38-65: Loss: 0.1396 Acc: 50.0000%\n",
      "\tvalidation 38-66: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-67: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 38-68: Loss: 0.0769 Acc: 75.0000%\n",
      "\tvalidation 38-69: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-70: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-71: Loss: 0.0628 Acc: 75.0000%\n",
      "\tvalidation 38-72: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 38-73: Loss: 0.0588 Acc: 100.0000%\n",
      "\tvalidation 38-74: Loss: 0.1569 Acc: 75.0000%\n",
      "\tvalidation 38-75: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-76: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 38-77: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 38-78: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-79: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 38-80: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 38-81: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-82: Loss: 0.1223 Acc: 50.0000%\n",
      "\tvalidation 38-83: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 38-84: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-85: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 38-86: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 38-87: Loss: 0.0612 Acc: 100.0000%\n",
      "\tvalidation 38-88: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 38-89: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-90: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 38-91: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 38-92: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-93: Loss: 0.0915 Acc: 75.0000%\n",
      "\tvalidation 38-94: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 38-95: Loss: 0.0634 Acc: 75.0000%\n",
      "\tvalidation 38-96: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 38-97: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 38-98: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-99: Loss: 0.0587 Acc: 75.0000%\n",
      "\tvalidation 38-100: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 38-101: Loss: 0.1093 Acc: 75.0000%\n",
      "\tvalidation 38-102: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 38-103: Loss: 0.1316 Acc: 75.0000%\n",
      "\tvalidation 38-104: Loss: 0.1391 Acc: 75.0000%\n",
      "\tvalidation 38-105: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0457 Acc: 93.4694%\n",
      "\tvalidation Loss: 0.0325 Acc: 94.5238%\n",
      "Time passed 0h 29m 20s\n",
      "--------------------\n",
      "Epoch [39/40]:\n",
      "\ttrain 39-1: Loss: 0.1839 Acc: 50.0000%\n",
      "\ttrain 39-2: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 39-3: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 39-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-5: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-6: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-7: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 39-8: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 39-9: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-10: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 39-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-12: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-13: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 39-14: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 39-15: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 39-16: Loss: 0.1996 Acc: 50.0000%\n",
      "\ttrain 39-17: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 39-18: Loss: 0.0462 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-19: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-20: Loss: 0.2060 Acc: 50.0000%\n",
      "\ttrain 39-21: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-22: Loss: 0.2739 Acc: 75.0000%\n",
      "\ttrain 39-23: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 39-24: Loss: 0.2795 Acc: 75.0000%\n",
      "\ttrain 39-25: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 39-26: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 39-27: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 39-28: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-29: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 39-30: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 39-31: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-32: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 39-33: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 39-34: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 39-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-36: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 39-37: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 39-38: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 39-39: Loss: 0.1789 Acc: 50.0000%\n",
      "\ttrain 39-40: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 39-41: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 39-42: Loss: 0.1788 Acc: 75.0000%\n",
      "\ttrain 39-43: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 39-44: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 39-45: Loss: 0.1861 Acc: 75.0000%\n",
      "\ttrain 39-46: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 39-47: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 39-48: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 39-49: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 39-50: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 39-51: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 39-52: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 39-53: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 39-54: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 39-55: Loss: 0.1539 Acc: 50.0000%\n",
      "\ttrain 39-56: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 39-57: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 39-58: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-59: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 39-60: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 39-61: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 39-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-63: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 39-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-65: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-66: Loss: 0.1646 Acc: 75.0000%\n",
      "\ttrain 39-67: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-68: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-69: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 39-70: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 39-71: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 39-72: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 39-73: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 39-74: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 39-75: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 39-76: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-77: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-78: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 39-79: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 39-80: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 39-81: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 39-82: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 39-83: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 39-84: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-85: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 39-86: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 39-87: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-88: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-89: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-90: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-91: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 39-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-93: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 39-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-95: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 39-96: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 39-97: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 39-98: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-99: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-100: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-101: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 39-102: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-103: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 39-104: Loss: 0.0503 Acc: 75.0000%\n",
      "\ttrain 39-105: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-106: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 39-107: Loss: 0.1352 Acc: 75.0000%\n",
      "\ttrain 39-108: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 39-109: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 39-110: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-111: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 39-112: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-113: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 39-114: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-115: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 39-116: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 39-117: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 39-118: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 39-119: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-120: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-121: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 39-122: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 39-123: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 39-124: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 39-125: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-126: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 39-127: Loss: 0.2011 Acc: 50.0000%\n",
      "\ttrain 39-128: Loss: 0.2293 Acc: 50.0000%\n",
      "\ttrain 39-129: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 39-130: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-131: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-132: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 39-133: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-134: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 39-135: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 39-136: Loss: 0.0860 Acc: 100.0000%\n",
      "\ttrain 39-137: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-138: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 39-139: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 39-140: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 39-141: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 39-142: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 39-143: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 39-144: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 39-145: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-146: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 39-147: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-148: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-149: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-150: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 39-151: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 39-152: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 39-153: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 39-154: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-155: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 39-156: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-157: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-158: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 39-159: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 39-160: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 39-161: Loss: 0.2093 Acc: 75.0000%\n",
      "\ttrain 39-162: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-163: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-164: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 39-165: Loss: 0.5278 Acc: 75.0000%\n",
      "\ttrain 39-166: Loss: 0.2960 Acc: 50.0000%\n",
      "\ttrain 39-167: Loss: 0.6626 Acc: 25.0000%\n",
      "\ttrain 39-168: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 39-169: Loss: 0.2459 Acc: 75.0000%\n",
      "\ttrain 39-170: Loss: 0.3775 Acc: 50.0000%\n",
      "\ttrain 39-171: Loss: 0.3173 Acc: 25.0000%\n",
      "\ttrain 39-172: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 39-173: Loss: 0.2204 Acc: 75.0000%\n",
      "\ttrain 39-174: Loss: 0.3377 Acc: 50.0000%\n",
      "\ttrain 39-175: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 39-176: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 39-177: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 39-178: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 39-179: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 39-180: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 39-181: Loss: 0.2760 Acc: 50.0000%\n",
      "\ttrain 39-182: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 39-183: Loss: 0.1422 Acc: 50.0000%\n",
      "\ttrain 39-184: Loss: 0.1715 Acc: 50.0000%\n",
      "\ttrain 39-185: Loss: 0.1376 Acc: 50.0000%\n",
      "\ttrain 39-186: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 39-187: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 39-188: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 39-189: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 39-190: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 39-191: Loss: 0.0699 Acc: 100.0000%\n",
      "\ttrain 39-192: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 39-193: Loss: 0.1333 Acc: 50.0000%\n",
      "\ttrain 39-194: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 39-195: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 39-196: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 39-197: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 39-198: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 39-199: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 39-200: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 39-201: Loss: 0.0693 Acc: 75.0000%\n",
      "\ttrain 39-202: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 39-203: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 39-204: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 39-205: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 39-206: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 39-207: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 39-208: Loss: 0.1765 Acc: 75.0000%\n",
      "\ttrain 39-209: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 39-210: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 39-211: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 39-212: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 39-213: Loss: 0.0372 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-214: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 39-215: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 39-216: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 39-217: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-218: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-219: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 39-220: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 39-221: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 39-222: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 39-223: Loss: 0.0543 Acc: 75.0000%\n",
      "\ttrain 39-224: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 39-225: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 39-226: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 39-227: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 39-228: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 39-229: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 39-230: Loss: 0.2664 Acc: 75.0000%\n",
      "\ttrain 39-231: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 39-232: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 39-233: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 39-234: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 39-235: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 39-236: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 39-237: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 39-238: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 39-239: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 39-240: Loss: 0.1673 Acc: 75.0000%\n",
      "\ttrain 39-241: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 39-242: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-243: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 39-244: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 39-245: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 39-1: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 39-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-3: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 39-4: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-5: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 39-6: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 39-7: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 39-8: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 39-9: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 39-10: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 39-11: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 39-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-13: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 39-14: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 39-15: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 39-16: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-17: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 39-18: Loss: 0.0480 Acc: 100.0000%\n",
      "\tvalidation 39-19: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-20: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 39-21: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 39-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-23: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 39-24: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 39-25: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 39-26: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 39-27: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 39-28: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 39-29: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-30: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 39-31: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-32: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 39-33: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 39-34: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 39-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-36: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-37: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 39-38: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 39-39: Loss: 0.0526 Acc: 100.0000%\n",
      "\tvalidation 39-40: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 39-41: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 39-42: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 39-43: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 39-44: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-45: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 39-46: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 39-47: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-48: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-49: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 39-50: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-52: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 39-53: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 39-54: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 39-55: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 39-56: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 39-57: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-58: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-59: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 39-60: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 39-61: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 39-62: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 39-63: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 39-64: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 39-65: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 39-66: Loss: 0.0690 Acc: 75.0000%\n",
      "\tvalidation 39-67: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 39-68: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 39-69: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 39-70: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 39-71: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-72: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 39-73: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 39-74: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 39-75: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 39-76: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 39-77: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 39-78: Loss: 0.2353 Acc: 75.0000%\n",
      "\tvalidation 39-79: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 39-80: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-81: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 39-82: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 39-83: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 39-84: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 39-85: Loss: 0.1235 Acc: 75.0000%\n",
      "\tvalidation 39-86: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 39-87: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 39-88: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-89: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-90: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 39-91: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 39-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-93: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 39-94: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 39-95: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 39-96: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-97: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-99: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 39-100: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-102: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 39-103: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 39-104: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 39-105: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0582 Acc: 91.1224%\n",
      "\tvalidation Loss: 0.0117 Acc: 99.0476%\n",
      "Time passed 0h 30m 3s\n",
      "--------------------\n",
      "Epoch [40/40]:\n",
      "\ttrain 40-1: Loss: 0.0594 Acc: 75.0000%\n",
      "\ttrain 40-2: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-3: Loss: 0.0794 Acc: 100.0000%\n",
      "\ttrain 40-4: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-5: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 40-6: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 40-7: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-8: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 40-9: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 40-10: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-11: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 40-12: Loss: 0.2752 Acc: 75.0000%\n",
      "\ttrain 40-13: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 40-14: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-15: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 40-16: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-17: Loss: 0.1738 Acc: 50.0000%\n",
      "\ttrain 40-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-19: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 40-20: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 40-21: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-22: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 40-23: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 40-24: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-25: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 40-26: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 40-27: Loss: 0.1633 Acc: 75.0000%\n",
      "\ttrain 40-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-29: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 40-30: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 40-31: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 40-32: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 40-33: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 40-34: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-35: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 40-36: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 40-37: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 40-38: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 40-39: Loss: 0.5410 Acc: 75.0000%\n",
      "\ttrain 40-40: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-41: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 40-42: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-43: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-44: Loss: 0.1073 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-45: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 40-46: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 40-47: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 40-48: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 40-49: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 40-50: Loss: 0.1639 Acc: 50.0000%\n",
      "\ttrain 40-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-52: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 40-53: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 40-54: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 40-55: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 40-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-57: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 40-58: Loss: 0.1681 Acc: 50.0000%\n",
      "\ttrain 40-59: Loss: 0.2147 Acc: 50.0000%\n",
      "\ttrain 40-60: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 40-61: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 40-62: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 40-63: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 40-64: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 40-65: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 40-66: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 40-67: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 40-68: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 40-69: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 40-70: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-71: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-72: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 40-73: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 40-74: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-75: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 40-76: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 40-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-78: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 40-79: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 40-80: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 40-81: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 40-82: Loss: 0.2841 Acc: 75.0000%\n",
      "\ttrain 40-83: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 40-84: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-85: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 40-86: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 40-87: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 40-88: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 40-89: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 40-90: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 40-91: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 40-92: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 40-93: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 40-94: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-95: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 40-96: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 40-97: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 40-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-99: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 40-100: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 40-101: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-102: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 40-103: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-104: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-105: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 40-106: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 40-107: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-108: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 40-109: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 40-110: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 40-111: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 40-112: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-113: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 40-114: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-115: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-116: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 40-117: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-118: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 40-119: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 40-120: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 40-121: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-122: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 40-123: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-124: Loss: 0.2883 Acc: 50.0000%\n",
      "\ttrain 40-125: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 40-126: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-127: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-128: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-129: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 40-130: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 40-131: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 40-132: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-133: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-134: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 40-135: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 40-136: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 40-137: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-138: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 40-139: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 40-140: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-141: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-142: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 40-143: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-144: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-145: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 40-146: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-147: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 40-148: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 40-149: Loss: 0.1733 Acc: 75.0000%\n",
      "\ttrain 40-150: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 40-151: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 40-152: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 40-153: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-154: Loss: 0.4167 Acc: 50.0000%\n",
      "\ttrain 40-155: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-156: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 40-157: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 40-158: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-159: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 40-160: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-161: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-162: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 40-163: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 40-164: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 40-165: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 40-166: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 40-167: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 40-168: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 40-169: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 40-170: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 40-171: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 40-172: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-173: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 40-174: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 40-175: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-176: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-177: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-178: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-179: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 40-180: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 40-181: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 40-182: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-183: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 40-184: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 40-185: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 40-186: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-187: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 40-188: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 40-189: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 40-190: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-191: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-192: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-193: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 40-194: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 40-195: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 40-196: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 40-197: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 40-198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-199: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-200: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 40-201: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-202: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 40-203: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 40-204: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-205: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-206: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 40-207: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 40-208: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-209: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 40-210: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 40-211: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 40-212: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-213: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 40-214: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-215: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-216: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-217: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 40-218: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-219: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 40-220: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 40-221: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-222: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 40-223: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 40-224: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-225: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-226: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-227: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 40-228: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-229: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-230: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-231: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-232: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-233: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 40-234: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 40-235: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 40-236: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-237: Loss: 0.0020 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-238: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-239: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 40-240: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-241: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-242: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-243: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 40-244: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-245: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 40-1: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 40-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-3: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 40-4: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 40-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-7: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-9: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-11: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-12: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-13: Loss: 0.0709 Acc: 75.0000%\n",
      "\tvalidation 40-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-15: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 40-16: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 40-17: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-21: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-22: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 40-23: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 40-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-27: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 40-28: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-29: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-30: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 40-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-36: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 40-37: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-38: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-39: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-40: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-41: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 40-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-43: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-46: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-47: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-49: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-50: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-51: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-52: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 40-53: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-56: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-57: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 40-58: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 40-59: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 40-60: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 40-61: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-65: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 40-66: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 40-67: Loss: 0.0514 Acc: 75.0000%\n",
      "\tvalidation 40-68: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 40-69: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 40-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-71: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-72: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-73: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 40-74: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-75: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 40-76: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 40-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-78: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-79: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-84: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-85: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 40-86: Loss: 0.0973 Acc: 75.0000%\n",
      "\tvalidation 40-87: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-88: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-89: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-90: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-92: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-93: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 40-94: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 40-95: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-96: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-97: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 40-98: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 40-99: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 40-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-103: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0376 Acc: 94.1837%\n",
      "\tvalidation Loss: 0.0053 Acc: 99.0476%\n",
      "Time passed 0h 30m 48s\n",
      "--------------------\n",
      "Training complete in 0h 30m 48s\n",
      "Best validation Acc: 0.992857\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0\n",
    "loss_train = [] # 训练集loss\n",
    "acc_train = [] # 训练集正确率\n",
    "loss_val = [] # 验证集loss\n",
    "acc_val = [] # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "\n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            i = 1\n",
    "            j = 1\n",
    "            # exp_lr_scheduler.step()\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            i = 1\n",
    "            j = 2\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            # if use_gpu:\n",
    "            #     inputs = inputs.cuda()\n",
    "            #     labels = labels.cuda()\n",
    "            # else:\n",
    "            #     inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            # '_'就是一个变量，换成a也是可以的，没有特别的意思，不过一般用_表示的变量好像都是没什么用的一个临时变量，大概是\n",
    "            # 一个编程习惯吧。所以这边'_,'没有特殊的含义，'_'就是一个变量，只是为了让preds取到max函数返回值的第二项，\n",
    "            # 即找到的最大值的索引位置（对应到这里就是类别标签）\n",
    "            # （max函数解释见https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max）\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, num_classes):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "                if epoch == 0:\n",
    "                    best_matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "            \n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, i, loss.item()/4, torch.sum(preds == labels.data).item()/4.0*100))\n",
    "            i = i + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if j == 1:\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and j == 2:\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'validation' and epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"网络参数更新\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/params_vgg16.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "#             print(\"Model's state_dict:\")\n",
    "#             for param_tensor in best_model_wts:\n",
    "#                 print(param_tensor, \"\\t\", best_model_wts[param_tensor].size())\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.3464272992951529, 0.33426138034888675, 0.3308206625130712, 0.32140405524750143, 0.329051221633444, 0.2521992862224579, 0.18099784692939447, 0.15530880593827792, 0.14408472099778605, 0.12469666977317966, 0.14140987904096136, 0.12799398119048197, 0.11141784157680006, 0.13855716435580837, 0.1129585033624756, 0.12093840934792344, 0.10990033101062385, 0.10371951378729878, 0.1038858054851999, 0.09504867402874694, 0.1061586358565457, 0.12089689323792652, 0.08840940089858308, 0.09330101086168872, 0.0726868027327012, 0.07285755453061084, 0.07634355799884213, 0.07225829362869263, 0.05857820161143128, 0.05927208082712426, 0.07304056244237082, 0.06790246729339872, 0.06878630753074373, 0.05785060518858384, 0.05499632002747789, 0.03654719366102802, 0.048616392788838364, 0.04569940840711399, 0.05821519089596612, 0.037554356334160786]\n",
      "loss_val: [0.3447688230446407, 0.26659693945021856, 0.34415291036878315, 0.34656843287604194, 0.3048674668584551, 0.24883185759896323, 0.10418887539278893, 0.08930366237958272, 0.09061352096143223, 0.2238106471442041, 0.09927451894396827, 0.09905412466753097, 0.11854176443247567, 0.09864291626782644, 0.09191565698101407, 0.09013352876617794, 0.0856394921030317, 0.08333332950160617, 0.06084629048903783, 0.08066685944795608, 0.0683184483221599, 0.07050706630661374, 0.05501626857689449, 0.04227692853836786, 0.039543200390679496, 0.03861177223069327, 0.024207034636111485, 0.033266854286193845, 0.028748819090071178, 0.017869769036769866, 0.0509852144689787, 0.06742099069413685, 0.04894436250130336, 0.05230670819679896, 0.011207101387637003, 0.006418155204682123, 0.019203059304328193, 0.032485922035716826, 0.011655289786202568, 0.005305402406624385]\n",
      "acc_train: [0.24387755102040817, 0.29591836734693877, 0.3112244897959184, 0.35714285714285715, 0.34591836734693876, 0.5224489795918368, 0.6306122448979592, 0.6775510204081633, 0.6857142857142857, 0.7244897959183674, 0.6744897959183673, 0.7163265306122449, 0.736734693877551, 0.6908163265306122, 0.75, 0.7316326530612245, 0.7489795918367347, 0.7785714285714286, 0.810204081632653, 0.8193877551020409, 0.8030612244897959, 0.7938775510204081, 0.8479591836734693, 0.8357142857142857, 0.8857142857142857, 0.8887755102040816, 0.8826530612244898, 0.8826530612244898, 0.9030612244897959, 0.9122448979591836, 0.886734693877551, 0.8989795918367347, 0.8918367346938776, 0.9112244897959184, 0.9142857142857143, 0.9479591836734694, 0.9183673469387755, 0.9346938775510204, 0.9112244897959184, 0.9418367346938775]\n",
      "acc_val: [0.26666666666666666, 0.5238095238095238, 0.3119047619047619, 0.25, 0.580952380952381, 0.5, 0.75, 0.7428571428571429, 0.7595238095238095, 0.6309523809523809, 0.7476190476190476, 0.75, 0.7666666666666667, 0.7476190476190476, 0.8285714285714286, 0.85, 0.7785714285714286, 0.8119047619047619, 0.930952380952381, 0.7976190476190477, 0.8928571428571429, 0.8547619047619047, 0.9071428571428571, 0.9380952380952381, 0.95, 0.9571428571428572, 0.9619047619047619, 0.9380952380952381, 0.95, 0.9904761904761905, 0.8976190476190476, 0.8738095238095238, 0.9119047619047619, 0.9142857142857143, 0.9928571428571429, 0.9904761904761905, 0.9761904761904762, 0.9452380952380952, 0.9904761904761905, 0.9904761904761905]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss(VGG16)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy(VGG16)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "GroundTruth:     79    77    75    77\n",
      "Predicted:     79    77    75    77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('75', '77', '79', '81')\n",
    "\n",
    "dataiter = iter(dataloders['validation'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[z]] for z in range(4)))\n",
    "\n",
    "# test\n",
    "outputs = model(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[z]] for z in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   Predicted\n",
      "\n",
      "\t   75\t77\t79\t81\n",
      "\n",
      "Actual 75  103\t2\t0\t0\t\n",
      "\n",
      "Actual 77  0\t104\t0\t1\t\n",
      "\n",
      "Actual 79  0\t0\t105\t0\t\n",
      "\n",
      "Actual 81  0\t0\t0\t105\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conc = {\n",
    "    '0': '75  ',\n",
    "    '1': '77  ',\n",
    "    '2': '79  ',\n",
    "    '3': '81  '\n",
    "}\n",
    "\n",
    "print(\"\\t   Predicted\\n\")\n",
    "print(\"\\t   75\\t77\\t79\\t81\\n\")\n",
    "for i in range(0, num_classes):\n",
    "    print(\"Actual \", end='')\n",
    "    print(conc[str(i)], end='')\n",
    "    for j in range(0, num_classes):\n",
    "        print(str(best_matrix[i][j]) + '\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
