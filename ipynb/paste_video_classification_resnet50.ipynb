{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 这个代码每个epoch都跑一遍训练集和验证集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "shuffle = True\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载resnet50预训练模型\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=10) for x in ['train', 'validation']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]:\n",
      "\ttrain 1-1: Loss: 0.3985 Acc: 50.0000%\n",
      "\ttrain 1-2: Loss: 0.3681 Acc: 25.0000%\n",
      "\ttrain 1-3: Loss: 0.3415 Acc: 25.0000%\n",
      "\ttrain 1-4: Loss: 0.3119 Acc: 25.0000%\n",
      "\ttrain 1-5: Loss: 0.6948 Acc: 0.0000%\n",
      "\ttrain 1-6: Loss: 0.7431 Acc: 25.0000%\n",
      "\ttrain 1-7: Loss: 0.3366 Acc: 25.0000%\n",
      "\ttrain 1-8: Loss: 0.2764 Acc: 25.0000%\n",
      "\ttrain 1-9: Loss: 0.5398 Acc: 25.0000%\n",
      "\ttrain 1-10: Loss: 0.3672 Acc: 25.0000%\n",
      "\ttrain 1-11: Loss: 0.4566 Acc: 25.0000%\n",
      "\ttrain 1-12: Loss: 0.5587 Acc: 25.0000%\n",
      "\ttrain 1-13: Loss: 1.0350 Acc: 0.0000%\n",
      "\ttrain 1-14: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 1-15: Loss: 0.6508 Acc: 25.0000%\n",
      "\ttrain 1-16: Loss: 0.5681 Acc: 0.0000%\n",
      "\ttrain 1-17: Loss: 0.4862 Acc: 25.0000%\n",
      "\ttrain 1-18: Loss: 0.6147 Acc: 25.0000%\n",
      "\ttrain 1-19: Loss: 0.2842 Acc: 50.0000%\n",
      "\ttrain 1-20: Loss: 0.8313 Acc: 25.0000%\n",
      "\ttrain 1-21: Loss: 0.7242 Acc: 25.0000%\n",
      "\ttrain 1-22: Loss: 0.2329 Acc: 75.0000%\n",
      "\ttrain 1-23: Loss: 0.4601 Acc: 50.0000%\n",
      "\ttrain 1-24: Loss: 1.0274 Acc: 0.0000%\n",
      "\ttrain 1-25: Loss: 0.8134 Acc: 0.0000%\n",
      "\ttrain 1-26: Loss: 0.4168 Acc: 25.0000%\n",
      "\ttrain 1-27: Loss: 0.5722 Acc: 25.0000%\n",
      "\ttrain 1-28: Loss: 0.7258 Acc: 25.0000%\n",
      "\ttrain 1-29: Loss: 0.9207 Acc: 25.0000%\n",
      "\ttrain 1-30: Loss: 0.8953 Acc: 0.0000%\n",
      "\ttrain 1-31: Loss: 0.2490 Acc: 75.0000%\n",
      "\ttrain 1-32: Loss: 0.5831 Acc: 50.0000%\n",
      "\ttrain 1-33: Loss: 1.2808 Acc: 25.0000%\n",
      "\ttrain 1-34: Loss: 0.9373 Acc: 0.0000%\n",
      "\ttrain 1-35: Loss: 1.2092 Acc: 25.0000%\n",
      "\ttrain 1-36: Loss: 1.1335 Acc: 0.0000%\n",
      "\ttrain 1-37: Loss: 0.5595 Acc: 0.0000%\n",
      "\ttrain 1-38: Loss: 0.2733 Acc: 75.0000%\n",
      "\ttrain 1-39: Loss: 0.7126 Acc: 50.0000%\n",
      "\ttrain 1-40: Loss: 1.0546 Acc: 0.0000%\n",
      "\ttrain 1-41: Loss: 0.7427 Acc: 50.0000%\n",
      "\ttrain 1-42: Loss: 0.8339 Acc: 50.0000%\n",
      "\ttrain 1-43: Loss: 1.1804 Acc: 50.0000%\n",
      "\ttrain 1-44: Loss: 1.8126 Acc: 0.0000%\n",
      "\ttrain 1-45: Loss: 0.9369 Acc: 25.0000%\n",
      "\ttrain 1-46: Loss: 0.8212 Acc: 25.0000%\n",
      "\ttrain 1-47: Loss: 0.3078 Acc: 25.0000%\n",
      "\ttrain 1-48: Loss: 0.2118 Acc: 50.0000%\n",
      "\ttrain 1-49: Loss: 0.5295 Acc: 25.0000%\n",
      "\ttrain 1-50: Loss: 1.2474 Acc: 0.0000%\n",
      "\ttrain 1-51: Loss: 0.7058 Acc: 25.0000%\n",
      "\ttrain 1-52: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 1-53: Loss: 0.1776 Acc: 75.0000%\n",
      "\ttrain 1-54: Loss: 0.7135 Acc: 25.0000%\n",
      "\ttrain 1-55: Loss: 0.6874 Acc: 0.0000%\n",
      "\ttrain 1-56: Loss: 0.4460 Acc: 50.0000%\n",
      "\ttrain 1-57: Loss: 0.7877 Acc: 25.0000%\n",
      "\ttrain 1-58: Loss: 0.8830 Acc: 0.0000%\n",
      "\ttrain 1-59: Loss: 0.4545 Acc: 25.0000%\n",
      "\ttrain 1-60: Loss: 0.2503 Acc: 50.0000%\n",
      "\ttrain 1-61: Loss: 0.1951 Acc: 75.0000%\n",
      "\ttrain 1-62: Loss: 1.9111 Acc: 0.0000%\n",
      "\ttrain 1-63: Loss: 1.6721 Acc: 0.0000%\n",
      "\ttrain 1-64: Loss: 0.9102 Acc: 0.0000%\n",
      "\ttrain 1-65: Loss: 0.2410 Acc: 50.0000%\n",
      "\ttrain 1-66: Loss: 0.8164 Acc: 50.0000%\n",
      "\ttrain 1-67: Loss: 1.3542 Acc: 0.0000%\n",
      "\ttrain 1-68: Loss: 1.0568 Acc: 0.0000%\n",
      "\ttrain 1-69: Loss: 0.8628 Acc: 50.0000%\n",
      "\ttrain 1-70: Loss: 0.6579 Acc: 0.0000%\n",
      "\ttrain 1-71: Loss: 1.0512 Acc: 25.0000%\n",
      "\ttrain 1-72: Loss: 0.4245 Acc: 25.0000%\n",
      "\ttrain 1-73: Loss: 0.9484 Acc: 25.0000%\n",
      "\ttrain 1-74: Loss: 0.8133 Acc: 25.0000%\n",
      "\ttrain 1-75: Loss: 0.3218 Acc: 25.0000%\n",
      "\ttrain 1-76: Loss: 0.6790 Acc: 50.0000%\n",
      "\ttrain 1-77: Loss: 0.2994 Acc: 50.0000%\n",
      "\ttrain 1-78: Loss: 0.4240 Acc: 25.0000%\n",
      "\ttrain 1-79: Loss: 0.4848 Acc: 0.0000%\n",
      "\ttrain 1-80: Loss: 0.6179 Acc: 0.0000%\n",
      "\ttrain 1-81: Loss: 0.2484 Acc: 50.0000%\n",
      "\ttrain 1-82: Loss: 0.7352 Acc: 0.0000%\n",
      "\ttrain 1-83: Loss: 0.6823 Acc: 25.0000%\n",
      "\ttrain 1-84: Loss: 0.2816 Acc: 50.0000%\n",
      "\ttrain 1-85: Loss: 0.7808 Acc: 25.0000%\n",
      "\ttrain 1-86: Loss: 0.2750 Acc: 50.0000%\n",
      "\ttrain 1-87: Loss: 0.4336 Acc: 50.0000%\n",
      "\ttrain 1-88: Loss: 0.7075 Acc: 25.0000%\n",
      "\ttrain 1-89: Loss: 0.8365 Acc: 25.0000%\n",
      "\ttrain 1-90: Loss: 0.8379 Acc: 0.0000%\n",
      "\ttrain 1-91: Loss: 0.3973 Acc: 25.0000%\n",
      "\ttrain 1-92: Loss: 0.9239 Acc: 0.0000%\n",
      "\ttrain 1-93: Loss: 0.3649 Acc: 50.0000%\n",
      "\ttrain 1-94: Loss: 0.1728 Acc: 75.0000%\n",
      "\ttrain 1-95: Loss: 0.2135 Acc: 50.0000%\n",
      "\ttrain 1-96: Loss: 0.7543 Acc: 50.0000%\n",
      "\ttrain 1-97: Loss: 0.7926 Acc: 25.0000%\n",
      "\ttrain 1-98: Loss: 0.5926 Acc: 50.0000%\n",
      "\ttrain 1-99: Loss: 1.1070 Acc: 25.0000%\n",
      "\ttrain 1-100: Loss: 0.6172 Acc: 0.0000%\n",
      "\ttrain 1-101: Loss: 0.2772 Acc: 75.0000%\n",
      "\ttrain 1-102: Loss: 0.5847 Acc: 50.0000%\n",
      "\ttrain 1-103: Loss: 0.7120 Acc: 25.0000%\n",
      "\ttrain 1-104: Loss: 0.5467 Acc: 25.0000%\n",
      "\ttrain 1-105: Loss: 0.2835 Acc: 25.0000%\n",
      "\ttrain 1-106: Loss: 0.2652 Acc: 50.0000%\n",
      "\ttrain 1-107: Loss: 0.2843 Acc: 25.0000%\n",
      "\ttrain 1-108: Loss: 0.7248 Acc: 50.0000%\n",
      "\ttrain 1-109: Loss: 0.2432 Acc: 75.0000%\n",
      "\ttrain 1-110: Loss: 0.2574 Acc: 50.0000%\n",
      "\ttrain 1-111: Loss: 0.8260 Acc: 50.0000%\n",
      "\ttrain 1-112: Loss: 1.2889 Acc: 0.0000%\n",
      "\ttrain 1-113: Loss: 0.7573 Acc: 25.0000%\n",
      "\ttrain 1-114: Loss: 0.8136 Acc: 50.0000%\n",
      "\ttrain 1-115: Loss: 1.0451 Acc: 25.0000%\n",
      "\ttrain 1-116: Loss: 1.0000 Acc: 0.0000%\n",
      "\ttrain 1-117: Loss: 0.9663 Acc: 0.0000%\n",
      "\ttrain 1-118: Loss: 0.4620 Acc: 25.0000%\n",
      "\ttrain 1-119: Loss: 0.4765 Acc: 25.0000%\n",
      "\ttrain 1-120: Loss: 1.7947 Acc: 0.0000%\n",
      "\ttrain 1-121: Loss: 0.7534 Acc: 50.0000%\n",
      "\ttrain 1-122: Loss: 0.3399 Acc: 75.0000%\n",
      "\ttrain 1-123: Loss: 1.3091 Acc: 25.0000%\n",
      "\ttrain 1-124: Loss: 0.3799 Acc: 50.0000%\n",
      "\ttrain 1-125: Loss: 0.6264 Acc: 50.0000%\n",
      "\ttrain 1-126: Loss: 0.1897 Acc: 75.0000%\n",
      "\ttrain 1-127: Loss: 1.2185 Acc: 0.0000%\n",
      "\ttrain 1-128: Loss: 0.7512 Acc: 50.0000%\n",
      "\ttrain 1-129: Loss: 0.7188 Acc: 50.0000%\n",
      "\ttrain 1-130: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 1-131: Loss: 0.7197 Acc: 0.0000%\n",
      "\ttrain 1-132: Loss: 0.5644 Acc: 25.0000%\n",
      "\ttrain 1-133: Loss: 0.6067 Acc: 25.0000%\n",
      "\ttrain 1-134: Loss: 0.3999 Acc: 50.0000%\n",
      "\ttrain 1-135: Loss: 0.6181 Acc: 25.0000%\n",
      "\ttrain 1-136: Loss: 0.7247 Acc: 25.0000%\n",
      "\ttrain 1-137: Loss: 0.3020 Acc: 50.0000%\n",
      "\ttrain 1-138: Loss: 0.2210 Acc: 50.0000%\n",
      "\ttrain 1-139: Loss: 0.3741 Acc: 50.0000%\n",
      "\ttrain 1-140: Loss: 0.7745 Acc: 25.0000%\n",
      "\ttrain 1-141: Loss: 0.8515 Acc: 25.0000%\n",
      "\ttrain 1-142: Loss: 0.5137 Acc: 25.0000%\n",
      "\ttrain 1-143: Loss: 0.7599 Acc: 0.0000%\n",
      "\ttrain 1-144: Loss: 0.4936 Acc: 25.0000%\n",
      "\ttrain 1-145: Loss: 0.5492 Acc: 0.0000%\n",
      "\ttrain 1-146: Loss: 0.2784 Acc: 75.0000%\n",
      "\ttrain 1-147: Loss: 0.4159 Acc: 25.0000%\n",
      "\ttrain 1-148: Loss: 0.4523 Acc: 25.0000%\n",
      "\ttrain 1-149: Loss: 0.7882 Acc: 25.0000%\n",
      "\ttrain 1-150: Loss: 1.0402 Acc: 0.0000%\n",
      "\ttrain 1-151: Loss: 0.4315 Acc: 25.0000%\n",
      "\ttrain 1-152: Loss: 0.5750 Acc: 0.0000%\n",
      "\ttrain 1-153: Loss: 0.2743 Acc: 50.0000%\n",
      "\ttrain 1-154: Loss: 0.3566 Acc: 75.0000%\n",
      "\ttrain 1-155: Loss: 0.8753 Acc: 25.0000%\n",
      "\ttrain 1-156: Loss: 0.6321 Acc: 0.0000%\n",
      "\ttrain 1-157: Loss: 0.8254 Acc: 25.0000%\n",
      "\ttrain 1-158: Loss: 0.6932 Acc: 0.0000%\n",
      "\ttrain 1-159: Loss: 0.3223 Acc: 50.0000%\n",
      "\ttrain 1-160: Loss: 0.5722 Acc: 0.0000%\n",
      "\ttrain 1-161: Loss: 0.6541 Acc: 25.0000%\n",
      "\ttrain 1-162: Loss: 0.3972 Acc: 50.0000%\n",
      "\ttrain 1-163: Loss: 0.3893 Acc: 50.0000%\n",
      "\ttrain 1-164: Loss: 1.4396 Acc: 0.0000%\n",
      "\ttrain 1-165: Loss: 0.4752 Acc: 25.0000%\n",
      "\ttrain 1-166: Loss: 0.5567 Acc: 0.0000%\n",
      "\ttrain 1-167: Loss: 0.3972 Acc: 25.0000%\n",
      "\ttrain 1-168: Loss: 0.5806 Acc: 25.0000%\n",
      "\ttrain 1-169: Loss: 1.2094 Acc: 0.0000%\n",
      "\ttrain 1-170: Loss: 0.2839 Acc: 50.0000%\n",
      "\ttrain 1-171: Loss: 0.2984 Acc: 25.0000%\n",
      "\ttrain 1-172: Loss: 0.3687 Acc: 50.0000%\n",
      "\ttrain 1-173: Loss: 0.4257 Acc: 25.0000%\n",
      "\ttrain 1-174: Loss: 0.3577 Acc: 25.0000%\n",
      "\ttrain 1-175: Loss: 0.2643 Acc: 75.0000%\n",
      "\ttrain 1-176: Loss: 0.3584 Acc: 50.0000%\n",
      "\ttrain 1-177: Loss: 0.6925 Acc: 25.0000%\n",
      "\ttrain 1-178: Loss: 0.1185 Acc: 100.0000%\n",
      "\ttrain 1-179: Loss: 0.5316 Acc: 0.0000%\n",
      "\ttrain 1-180: Loss: 0.4272 Acc: 25.0000%\n",
      "\ttrain 1-181: Loss: 0.4175 Acc: 25.0000%\n",
      "\ttrain 1-182: Loss: 0.7595 Acc: 25.0000%\n",
      "\ttrain 1-183: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 1-184: Loss: 0.4328 Acc: 0.0000%\n",
      "\ttrain 1-185: Loss: 0.3121 Acc: 50.0000%\n",
      "\ttrain 1-186: Loss: 0.8671 Acc: 0.0000%\n",
      "\ttrain 1-187: Loss: 0.7273 Acc: 25.0000%\n",
      "\ttrain 1-188: Loss: 0.2970 Acc: 25.0000%\n",
      "\ttrain 1-189: Loss: 0.2430 Acc: 75.0000%\n",
      "\ttrain 1-190: Loss: 0.3302 Acc: 25.0000%\n",
      "\ttrain 1-191: Loss: 0.2241 Acc: 50.0000%\n",
      "\ttrain 1-192: Loss: 0.1604 Acc: 75.0000%\n",
      "\ttrain 1-193: Loss: 1.0139 Acc: 25.0000%\n",
      "\ttrain 1-194: Loss: 0.8865 Acc: 75.0000%\n",
      "\ttrain 1-195: Loss: 0.6220 Acc: 0.0000%\n",
      "\ttrain 1-196: Loss: 0.6392 Acc: 75.0000%\n",
      "\ttrain 1-197: Loss: 1.3023 Acc: 0.0000%\n",
      "\ttrain 1-198: Loss: 0.8035 Acc: 25.0000%\n",
      "\ttrain 1-199: Loss: 0.4120 Acc: 50.0000%\n",
      "\ttrain 1-200: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 1-201: Loss: 0.2578 Acc: 50.0000%\n",
      "\ttrain 1-202: Loss: 0.3540 Acc: 25.0000%\n",
      "\ttrain 1-203: Loss: 0.9959 Acc: 25.0000%\n",
      "\ttrain 1-204: Loss: 0.7140 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-205: Loss: 1.4402 Acc: 25.0000%\n",
      "\ttrain 1-206: Loss: 0.5844 Acc: 50.0000%\n",
      "\ttrain 1-207: Loss: 0.9270 Acc: 0.0000%\n",
      "\ttrain 1-208: Loss: 0.3975 Acc: 25.0000%\n",
      "\ttrain 1-209: Loss: 1.6915 Acc: 0.0000%\n",
      "\ttrain 1-210: Loss: 1.7320 Acc: 0.0000%\n",
      "\ttrain 1-211: Loss: 1.2863 Acc: 0.0000%\n",
      "\ttrain 1-212: Loss: 0.5276 Acc: 75.0000%\n",
      "\ttrain 1-213: Loss: 0.4804 Acc: 50.0000%\n",
      "\ttrain 1-214: Loss: 0.4845 Acc: 25.0000%\n",
      "\ttrain 1-215: Loss: 0.3570 Acc: 25.0000%\n",
      "\ttrain 1-216: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 1-217: Loss: 1.0701 Acc: 50.0000%\n",
      "\ttrain 1-218: Loss: 0.8449 Acc: 25.0000%\n",
      "\ttrain 1-219: Loss: 0.3611 Acc: 75.0000%\n",
      "\ttrain 1-220: Loss: 0.3919 Acc: 50.0000%\n",
      "\ttrain 1-221: Loss: 1.5537 Acc: 0.0000%\n",
      "\ttrain 1-222: Loss: 1.2480 Acc: 50.0000%\n",
      "\ttrain 1-223: Loss: 1.1094 Acc: 25.0000%\n",
      "\ttrain 1-224: Loss: 0.5961 Acc: 50.0000%\n",
      "\ttrain 1-225: Loss: 0.2903 Acc: 25.0000%\n",
      "\ttrain 1-226: Loss: 1.0364 Acc: 25.0000%\n",
      "\ttrain 1-227: Loss: 0.5888 Acc: 50.0000%\n",
      "\ttrain 1-228: Loss: 1.1653 Acc: 25.0000%\n",
      "\ttrain 1-229: Loss: 0.5133 Acc: 75.0000%\n",
      "\ttrain 1-230: Loss: 0.9285 Acc: 0.0000%\n",
      "\ttrain 1-231: Loss: 0.3419 Acc: 25.0000%\n",
      "\ttrain 1-232: Loss: 0.4252 Acc: 25.0000%\n",
      "\ttrain 1-233: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 1-234: Loss: 0.0871 Acc: 100.0000%\n",
      "\ttrain 1-235: Loss: 0.2614 Acc: 75.0000%\n",
      "\ttrain 1-236: Loss: 1.2477 Acc: 0.0000%\n",
      "\ttrain 1-237: Loss: 0.7500 Acc: 50.0000%\n",
      "\ttrain 1-238: Loss: 0.7364 Acc: 25.0000%\n",
      "\ttrain 1-239: Loss: 0.3439 Acc: 50.0000%\n",
      "\ttrain 1-240: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 1-241: Loss: 1.2921 Acc: 0.0000%\n",
      "\ttrain 1-242: Loss: 0.4763 Acc: 25.0000%\n",
      "\ttrain 1-243: Loss: 0.4854 Acc: 50.0000%\n",
      "\ttrain 1-244: Loss: 1.5637 Acc: 0.0000%\n",
      "\ttrain 1-245: Loss: 0.0760 Acc: 100.0000%\n",
      "\tvalidation 1-1: Loss: 0.0991 Acc: 75.0000%\n",
      "\tvalidation 1-2: Loss: 0.5576 Acc: 50.0000%\n",
      "\tvalidation 1-3: Loss: 0.4562 Acc: 25.0000%\n",
      "\tvalidation 1-4: Loss: 2.0387 Acc: 50.0000%\n",
      "\tvalidation 1-5: Loss: 0.2353 Acc: 75.0000%\n",
      "\tvalidation 1-6: Loss: 0.0684 Acc: 100.0000%\n",
      "\tvalidation 1-7: Loss: 1.0184 Acc: 0.0000%\n",
      "\tvalidation 1-8: Loss: 0.8548 Acc: 50.0000%\n",
      "\tvalidation 1-9: Loss: 0.6664 Acc: 25.0000%\n",
      "\tvalidation 1-10: Loss: 0.7492 Acc: 50.0000%\n",
      "\tvalidation 1-11: Loss: 1.0223 Acc: 50.0000%\n",
      "\tvalidation 1-12: Loss: 0.3048 Acc: 75.0000%\n",
      "\tvalidation 1-13: Loss: 0.5557 Acc: 25.0000%\n",
      "\tvalidation 1-14: Loss: 0.4134 Acc: 75.0000%\n",
      "\tvalidation 1-15: Loss: 0.7233 Acc: 50.0000%\n",
      "\tvalidation 1-16: Loss: 0.0831 Acc: 100.0000%\n",
      "\tvalidation 1-17: Loss: 0.6237 Acc: 25.0000%\n",
      "\tvalidation 1-18: Loss: 0.9421 Acc: 50.0000%\n",
      "\tvalidation 1-19: Loss: 0.2553 Acc: 75.0000%\n",
      "\tvalidation 1-20: Loss: 0.5355 Acc: 50.0000%\n",
      "\tvalidation 1-21: Loss: 0.4395 Acc: 50.0000%\n",
      "\tvalidation 1-22: Loss: 1.3960 Acc: 50.0000%\n",
      "\tvalidation 1-23: Loss: 0.7751 Acc: 25.0000%\n",
      "\tvalidation 1-24: Loss: 0.5812 Acc: 50.0000%\n",
      "\tvalidation 1-25: Loss: 6.2947 Acc: 0.0000%\n",
      "\tvalidation 1-26: Loss: 0.8116 Acc: 50.0000%\n",
      "\tvalidation 1-27: Loss: 0.1035 Acc: 75.0000%\n",
      "\tvalidation 1-28: Loss: 0.0605 Acc: 100.0000%\n",
      "\tvalidation 1-29: Loss: 0.3622 Acc: 50.0000%\n",
      "\tvalidation 1-30: Loss: 0.2231 Acc: 75.0000%\n",
      "\tvalidation 1-31: Loss: 0.7852 Acc: 50.0000%\n",
      "\tvalidation 1-32: Loss: 1.8363 Acc: 75.0000%\n",
      "\tvalidation 1-33: Loss: 0.6108 Acc: 50.0000%\n",
      "\tvalidation 1-34: Loss: 1.2343 Acc: 50.0000%\n",
      "\tvalidation 1-35: Loss: 0.9762 Acc: 50.0000%\n",
      "\tvalidation 1-36: Loss: 0.3825 Acc: 50.0000%\n",
      "\tvalidation 1-37: Loss: 0.2598 Acc: 75.0000%\n",
      "\tvalidation 1-38: Loss: 0.8841 Acc: 25.0000%\n",
      "\tvalidation 1-39: Loss: 0.6502 Acc: 50.0000%\n",
      "\tvalidation 1-40: Loss: 0.5044 Acc: 50.0000%\n",
      "\tvalidation 1-41: Loss: 0.6745 Acc: 25.0000%\n",
      "\tvalidation 1-42: Loss: 0.6264 Acc: 75.0000%\n",
      "\tvalidation 1-43: Loss: 2.1147 Acc: 0.0000%\n",
      "\tvalidation 1-44: Loss: 1.8375 Acc: 50.0000%\n",
      "\tvalidation 1-45: Loss: 1.2810 Acc: 25.0000%\n",
      "\tvalidation 1-46: Loss: 0.8596 Acc: 50.0000%\n",
      "\tvalidation 1-47: Loss: 1.0937 Acc: 0.0000%\n",
      "\tvalidation 1-48: Loss: 1.5840 Acc: 0.0000%\n",
      "\tvalidation 1-49: Loss: 0.8601 Acc: 25.0000%\n",
      "\tvalidation 1-50: Loss: 0.8708 Acc: 50.0000%\n",
      "\tvalidation 1-51: Loss: 2.0813 Acc: 50.0000%\n",
      "\tvalidation 1-52: Loss: 0.2364 Acc: 75.0000%\n",
      "\tvalidation 1-53: Loss: 0.6631 Acc: 25.0000%\n",
      "\tvalidation 1-54: Loss: 0.7010 Acc: 25.0000%\n",
      "\tvalidation 1-55: Loss: 1.1578 Acc: 25.0000%\n",
      "\tvalidation 1-56: Loss: 2.4917 Acc: 25.0000%\n",
      "\tvalidation 1-57: Loss: 1.9021 Acc: 25.0000%\n",
      "\tvalidation 1-58: Loss: 0.3028 Acc: 50.0000%\n",
      "\tvalidation 1-59: Loss: 1.0393 Acc: 0.0000%\n",
      "\tvalidation 1-60: Loss: 1.8466 Acc: 25.0000%\n",
      "\tvalidation 1-61: Loss: 3.6381 Acc: 50.0000%\n",
      "\tvalidation 1-62: Loss: 0.4529 Acc: 50.0000%\n",
      "\tvalidation 1-63: Loss: 1.1685 Acc: 25.0000%\n",
      "\tvalidation 1-64: Loss: 5.0093 Acc: 25.0000%\n",
      "\tvalidation 1-65: Loss: 0.3443 Acc: 75.0000%\n",
      "\tvalidation 1-66: Loss: 1.8044 Acc: 50.0000%\n",
      "\tvalidation 1-67: Loss: 2.7588 Acc: 25.0000%\n",
      "\tvalidation 1-68: Loss: 0.7306 Acc: 50.0000%\n",
      "\tvalidation 1-69: Loss: 0.3815 Acc: 50.0000%\n",
      "\tvalidation 1-70: Loss: 2.7121 Acc: 50.0000%\n",
      "\tvalidation 1-71: Loss: 2.2104 Acc: 25.0000%\n",
      "\tvalidation 1-72: Loss: 2.0901 Acc: 50.0000%\n",
      "\tvalidation 1-73: Loss: 3.0243 Acc: 25.0000%\n",
      "\tvalidation 1-74: Loss: 0.0850 Acc: 100.0000%\n",
      "\tvalidation 1-75: Loss: 1.7123 Acc: 50.0000%\n",
      "\tvalidation 1-76: Loss: 0.2283 Acc: 50.0000%\n",
      "\tvalidation 1-77: Loss: 3.4111 Acc: 75.0000%\n",
      "\tvalidation 1-78: Loss: 1.5702 Acc: 0.0000%\n",
      "\tvalidation 1-79: Loss: 0.8065 Acc: 50.0000%\n",
      "\tvalidation 1-80: Loss: 1.3213 Acc: 50.0000%\n",
      "\tvalidation 1-81: Loss: 0.1153 Acc: 75.0000%\n",
      "\tvalidation 1-82: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 1-83: Loss: 0.2654 Acc: 75.0000%\n",
      "\tvalidation 1-84: Loss: 0.4999 Acc: 50.0000%\n",
      "\tvalidation 1-85: Loss: 0.5416 Acc: 75.0000%\n",
      "\tvalidation 1-86: Loss: 1.1699 Acc: 50.0000%\n",
      "\tvalidation 1-87: Loss: 2.6430 Acc: 25.0000%\n",
      "\tvalidation 1-88: Loss: 3.2741 Acc: 0.0000%\n",
      "\tvalidation 1-89: Loss: 0.2815 Acc: 75.0000%\n",
      "\tvalidation 1-90: Loss: 1.0266 Acc: 25.0000%\n",
      "\tvalidation 1-91: Loss: 0.4852 Acc: 50.0000%\n",
      "\tvalidation 1-92: Loss: 0.2837 Acc: 75.0000%\n",
      "\tvalidation 1-93: Loss: 0.5025 Acc: 50.0000%\n",
      "\tvalidation 1-94: Loss: 3.1387 Acc: 0.0000%\n",
      "\tvalidation 1-95: Loss: 0.9339 Acc: 50.0000%\n",
      "\tvalidation 1-96: Loss: 1.4790 Acc: 50.0000%\n",
      "\tvalidation 1-97: Loss: 1.3269 Acc: 25.0000%\n",
      "\tvalidation 1-98: Loss: 0.2821 Acc: 75.0000%\n",
      "\tvalidation 1-99: Loss: 0.9449 Acc: 25.0000%\n",
      "\tvalidation 1-100: Loss: 0.8707 Acc: 25.0000%\n",
      "\tvalidation 1-101: Loss: 0.7024 Acc: 50.0000%\n",
      "\tvalidation 1-102: Loss: 0.3786 Acc: 50.0000%\n",
      "\tvalidation 1-103: Loss: 0.9054 Acc: 0.0000%\n",
      "\tvalidation 1-104: Loss: 0.7280 Acc: 25.0000%\n",
      "\tvalidation 1-105: Loss: 0.3239 Acc: 50.0000%\n",
      "\ttrain Loss: 0.6392 Acc: 32.2449%\n",
      "\tvalidation Loss: 1.0874 Acc: 45.9524%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 2s\n",
      "--------------------\n",
      "Epoch [2/40]:\n",
      "\ttrain 2-1: Loss: 0.8453 Acc: 50.0000%\n",
      "\ttrain 2-2: Loss: 0.6078 Acc: 0.0000%\n",
      "\ttrain 2-3: Loss: 0.2145 Acc: 75.0000%\n",
      "\ttrain 2-4: Loss: 0.2893 Acc: 75.0000%\n",
      "\ttrain 2-5: Loss: 0.4454 Acc: 25.0000%\n",
      "\ttrain 2-6: Loss: 0.2981 Acc: 50.0000%\n",
      "\ttrain 2-7: Loss: 0.9715 Acc: 0.0000%\n",
      "\ttrain 2-8: Loss: 1.8051 Acc: 25.0000%\n",
      "\ttrain 2-9: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 2-10: Loss: 0.4555 Acc: 25.0000%\n",
      "\ttrain 2-11: Loss: 0.4239 Acc: 0.0000%\n",
      "\ttrain 2-12: Loss: 0.3024 Acc: 50.0000%\n",
      "\ttrain 2-13: Loss: 0.6383 Acc: 25.0000%\n",
      "\ttrain 2-14: Loss: 0.5925 Acc: 25.0000%\n",
      "\ttrain 2-15: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 2-16: Loss: 0.6525 Acc: 25.0000%\n",
      "\ttrain 2-17: Loss: 0.5443 Acc: 50.0000%\n",
      "\ttrain 2-18: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 2-19: Loss: 0.3941 Acc: 50.0000%\n",
      "\ttrain 2-20: Loss: 0.2109 Acc: 75.0000%\n",
      "\ttrain 2-21: Loss: 0.6407 Acc: 25.0000%\n",
      "\ttrain 2-22: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 2-23: Loss: 0.6506 Acc: 25.0000%\n",
      "\ttrain 2-24: Loss: 0.2620 Acc: 50.0000%\n",
      "\ttrain 2-25: Loss: 0.5397 Acc: 0.0000%\n",
      "\ttrain 2-26: Loss: 0.2064 Acc: 75.0000%\n",
      "\ttrain 2-27: Loss: 0.5693 Acc: 25.0000%\n",
      "\ttrain 2-28: Loss: 0.1468 Acc: 75.0000%\n",
      "\ttrain 2-29: Loss: 0.5802 Acc: 25.0000%\n",
      "\ttrain 2-30: Loss: 0.5596 Acc: 0.0000%\n",
      "\ttrain 2-31: Loss: 0.3474 Acc: 50.0000%\n",
      "\ttrain 2-32: Loss: 0.3547 Acc: 25.0000%\n",
      "\ttrain 2-33: Loss: 0.3571 Acc: 50.0000%\n",
      "\ttrain 2-34: Loss: 0.2927 Acc: 50.0000%\n",
      "\ttrain 2-35: Loss: 0.3727 Acc: 25.0000%\n",
      "\ttrain 2-36: Loss: 0.4326 Acc: 0.0000%\n",
      "\ttrain 2-37: Loss: 0.2037 Acc: 75.0000%\n",
      "\ttrain 2-38: Loss: 0.3519 Acc: 25.0000%\n",
      "\ttrain 2-39: Loss: 0.3288 Acc: 50.0000%\n",
      "\ttrain 2-40: Loss: 0.2993 Acc: 50.0000%\n",
      "\ttrain 2-41: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 2-42: Loss: 0.3080 Acc: 50.0000%\n",
      "\ttrain 2-43: Loss: 0.2294 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-44: Loss: 0.2388 Acc: 50.0000%\n",
      "\ttrain 2-45: Loss: 0.2871 Acc: 50.0000%\n",
      "\ttrain 2-46: Loss: 0.4620 Acc: 0.0000%\n",
      "\ttrain 2-47: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 2-48: Loss: 0.3745 Acc: 50.0000%\n",
      "\ttrain 2-49: Loss: 0.3931 Acc: 25.0000%\n",
      "\ttrain 2-50: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 2-51: Loss: 0.2752 Acc: 75.0000%\n",
      "\ttrain 2-52: Loss: 0.3627 Acc: 50.0000%\n",
      "\ttrain 2-53: Loss: 0.2466 Acc: 50.0000%\n",
      "\ttrain 2-54: Loss: 0.9414 Acc: 25.0000%\n",
      "\ttrain 2-55: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 2-56: Loss: 1.1586 Acc: 25.0000%\n",
      "\ttrain 2-57: Loss: 0.3060 Acc: 50.0000%\n",
      "\ttrain 2-58: Loss: 1.1800 Acc: 0.0000%\n",
      "\ttrain 2-59: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 2-60: Loss: 0.7091 Acc: 25.0000%\n",
      "\ttrain 2-61: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 2-62: Loss: 0.3694 Acc: 0.0000%\n",
      "\ttrain 2-63: Loss: 0.1854 Acc: 50.0000%\n",
      "\ttrain 2-64: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 2-65: Loss: 0.2372 Acc: 50.0000%\n",
      "\ttrain 2-66: Loss: 0.1932 Acc: 75.0000%\n",
      "\ttrain 2-67: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 2-68: Loss: 0.3385 Acc: 50.0000%\n",
      "\ttrain 2-69: Loss: 0.9877 Acc: 25.0000%\n",
      "\ttrain 2-70: Loss: 0.3195 Acc: 50.0000%\n",
      "\ttrain 2-71: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 2-72: Loss: 0.4822 Acc: 50.0000%\n",
      "\ttrain 2-73: Loss: 0.1437 Acc: 75.0000%\n",
      "\ttrain 2-74: Loss: 0.2584 Acc: 50.0000%\n",
      "\ttrain 2-75: Loss: 1.4207 Acc: 25.0000%\n",
      "\ttrain 2-76: Loss: 1.2747 Acc: 50.0000%\n",
      "\ttrain 2-77: Loss: 0.5541 Acc: 25.0000%\n",
      "\ttrain 2-78: Loss: 0.5282 Acc: 50.0000%\n",
      "\ttrain 2-79: Loss: 0.4246 Acc: 50.0000%\n",
      "\ttrain 2-80: Loss: 0.7279 Acc: 0.0000%\n",
      "\ttrain 2-81: Loss: 0.4430 Acc: 25.0000%\n",
      "\ttrain 2-82: Loss: 0.3859 Acc: 75.0000%\n",
      "\ttrain 2-83: Loss: 0.4272 Acc: 25.0000%\n",
      "\ttrain 2-84: Loss: 0.2950 Acc: 50.0000%\n",
      "\ttrain 2-85: Loss: 0.5675 Acc: 25.0000%\n",
      "\ttrain 2-86: Loss: 0.4811 Acc: 25.0000%\n",
      "\ttrain 2-87: Loss: 0.2091 Acc: 75.0000%\n",
      "\ttrain 2-88: Loss: 0.6384 Acc: 50.0000%\n",
      "\ttrain 2-89: Loss: 0.2387 Acc: 25.0000%\n",
      "\ttrain 2-90: Loss: 0.2730 Acc: 25.0000%\n",
      "\ttrain 2-91: Loss: 0.5531 Acc: 0.0000%\n",
      "\ttrain 2-92: Loss: 0.1128 Acc: 100.0000%\n",
      "\ttrain 2-93: Loss: 0.1462 Acc: 50.0000%\n",
      "\ttrain 2-94: Loss: 0.4018 Acc: 50.0000%\n",
      "\ttrain 2-95: Loss: 0.3627 Acc: 50.0000%\n",
      "\ttrain 2-96: Loss: 0.3048 Acc: 75.0000%\n",
      "\ttrain 2-97: Loss: 0.3983 Acc: 0.0000%\n",
      "\ttrain 2-98: Loss: 0.1890 Acc: 75.0000%\n",
      "\ttrain 2-99: Loss: 0.3181 Acc: 50.0000%\n",
      "\ttrain 2-100: Loss: 0.4257 Acc: 50.0000%\n",
      "\ttrain 2-101: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 2-102: Loss: 0.2964 Acc: 50.0000%\n",
      "\ttrain 2-103: Loss: 0.5112 Acc: 50.0000%\n",
      "\ttrain 2-104: Loss: 0.4523 Acc: 0.0000%\n",
      "\ttrain 2-105: Loss: 0.3907 Acc: 50.0000%\n",
      "\ttrain 2-106: Loss: 0.4645 Acc: 50.0000%\n",
      "\ttrain 2-107: Loss: 0.3300 Acc: 75.0000%\n",
      "\ttrain 2-108: Loss: 0.4848 Acc: 25.0000%\n",
      "\ttrain 2-109: Loss: 0.2510 Acc: 50.0000%\n",
      "\ttrain 2-110: Loss: 0.4807 Acc: 25.0000%\n",
      "\ttrain 2-111: Loss: 0.1777 Acc: 50.0000%\n",
      "\ttrain 2-112: Loss: 0.8695 Acc: 25.0000%\n",
      "\ttrain 2-113: Loss: 0.2440 Acc: 75.0000%\n",
      "\ttrain 2-114: Loss: 0.1513 Acc: 100.0000%\n",
      "\ttrain 2-115: Loss: 0.4130 Acc: 0.0000%\n",
      "\ttrain 2-116: Loss: 0.1909 Acc: 75.0000%\n",
      "\ttrain 2-117: Loss: 0.3960 Acc: 0.0000%\n",
      "\ttrain 2-118: Loss: 0.3336 Acc: 25.0000%\n",
      "\ttrain 2-119: Loss: 0.6548 Acc: 25.0000%\n",
      "\ttrain 2-120: Loss: 0.3369 Acc: 0.0000%\n",
      "\ttrain 2-121: Loss: 0.1737 Acc: 50.0000%\n",
      "\ttrain 2-122: Loss: 0.5357 Acc: 25.0000%\n",
      "\ttrain 2-123: Loss: 0.1767 Acc: 75.0000%\n",
      "\ttrain 2-124: Loss: 0.3685 Acc: 50.0000%\n",
      "\ttrain 2-125: Loss: 0.2586 Acc: 75.0000%\n",
      "\ttrain 2-126: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 2-127: Loss: 0.3966 Acc: 50.0000%\n",
      "\ttrain 2-128: Loss: 0.2665 Acc: 75.0000%\n",
      "\ttrain 2-129: Loss: 0.2507 Acc: 50.0000%\n",
      "\ttrain 2-130: Loss: 0.4463 Acc: 50.0000%\n",
      "\ttrain 2-131: Loss: 0.7335 Acc: 25.0000%\n",
      "\ttrain 2-132: Loss: 0.2236 Acc: 25.0000%\n",
      "\ttrain 2-133: Loss: 0.2404 Acc: 75.0000%\n",
      "\ttrain 2-134: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 2-135: Loss: 0.7124 Acc: 50.0000%\n",
      "\ttrain 2-136: Loss: 0.3742 Acc: 25.0000%\n",
      "\ttrain 2-137: Loss: 0.4311 Acc: 25.0000%\n",
      "\ttrain 2-138: Loss: 0.2497 Acc: 50.0000%\n",
      "\ttrain 2-139: Loss: 0.2879 Acc: 50.0000%\n",
      "\ttrain 2-140: Loss: 0.4251 Acc: 50.0000%\n",
      "\ttrain 2-141: Loss: 0.4382 Acc: 50.0000%\n",
      "\ttrain 2-142: Loss: 0.5373 Acc: 0.0000%\n",
      "\ttrain 2-143: Loss: 0.2060 Acc: 50.0000%\n",
      "\ttrain 2-144: Loss: 1.0366 Acc: 50.0000%\n",
      "\ttrain 2-145: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 2-146: Loss: 1.0351 Acc: 25.0000%\n",
      "\ttrain 2-147: Loss: 0.2238 Acc: 75.0000%\n",
      "\ttrain 2-148: Loss: 0.9180 Acc: 0.0000%\n",
      "\ttrain 2-149: Loss: 0.2757 Acc: 50.0000%\n",
      "\ttrain 2-150: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 2-151: Loss: 0.7160 Acc: 0.0000%\n",
      "\ttrain 2-152: Loss: 0.4187 Acc: 50.0000%\n",
      "\ttrain 2-153: Loss: 0.4365 Acc: 50.0000%\n",
      "\ttrain 2-154: Loss: 0.4012 Acc: 50.0000%\n",
      "\ttrain 2-155: Loss: 0.3365 Acc: 25.0000%\n",
      "\ttrain 2-156: Loss: 0.3804 Acc: 25.0000%\n",
      "\ttrain 2-157: Loss: 0.3719 Acc: 25.0000%\n",
      "\ttrain 2-158: Loss: 0.2520 Acc: 25.0000%\n",
      "\ttrain 2-159: Loss: 0.1577 Acc: 50.0000%\n",
      "\ttrain 2-160: Loss: 0.1226 Acc: 100.0000%\n",
      "\ttrain 2-161: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 2-162: Loss: 0.1645 Acc: 50.0000%\n",
      "\ttrain 2-163: Loss: 0.3348 Acc: 25.0000%\n",
      "\ttrain 2-164: Loss: 0.4463 Acc: 0.0000%\n",
      "\ttrain 2-165: Loss: 0.2001 Acc: 50.0000%\n",
      "\ttrain 2-166: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 2-167: Loss: 0.2283 Acc: 25.0000%\n",
      "\ttrain 2-168: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 2-169: Loss: 1.2622 Acc: 50.0000%\n",
      "\ttrain 2-170: Loss: 0.4026 Acc: 25.0000%\n",
      "\ttrain 2-171: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 2-172: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 2-173: Loss: 0.5964 Acc: 25.0000%\n",
      "\ttrain 2-174: Loss: 0.1928 Acc: 50.0000%\n",
      "\ttrain 2-175: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 2-176: Loss: 0.4683 Acc: 0.0000%\n",
      "\ttrain 2-177: Loss: 0.3409 Acc: 50.0000%\n",
      "\ttrain 2-178: Loss: 0.3361 Acc: 50.0000%\n",
      "\ttrain 2-179: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 2-180: Loss: 0.8231 Acc: 25.0000%\n",
      "\ttrain 2-181: Loss: 0.7738 Acc: 50.0000%\n",
      "\ttrain 2-182: Loss: 0.3608 Acc: 75.0000%\n",
      "\ttrain 2-183: Loss: 0.2871 Acc: 50.0000%\n",
      "\ttrain 2-184: Loss: 0.0841 Acc: 100.0000%\n",
      "\ttrain 2-185: Loss: 0.2899 Acc: 75.0000%\n",
      "\ttrain 2-186: Loss: 0.3192 Acc: 25.0000%\n",
      "\ttrain 2-187: Loss: 0.1885 Acc: 50.0000%\n",
      "\ttrain 2-188: Loss: 0.3862 Acc: 50.0000%\n",
      "\ttrain 2-189: Loss: 0.1557 Acc: 50.0000%\n",
      "\ttrain 2-190: Loss: 0.4818 Acc: 25.0000%\n",
      "\ttrain 2-191: Loss: 0.6150 Acc: 25.0000%\n",
      "\ttrain 2-192: Loss: 0.5507 Acc: 25.0000%\n",
      "\ttrain 2-193: Loss: 0.1786 Acc: 50.0000%\n",
      "\ttrain 2-194: Loss: 0.3254 Acc: 50.0000%\n",
      "\ttrain 2-195: Loss: 0.2060 Acc: 75.0000%\n",
      "\ttrain 2-196: Loss: 0.4718 Acc: 50.0000%\n",
      "\ttrain 2-197: Loss: 0.1617 Acc: 75.0000%\n",
      "\ttrain 2-198: Loss: 0.3684 Acc: 50.0000%\n",
      "\ttrain 2-199: Loss: 0.4123 Acc: 25.0000%\n",
      "\ttrain 2-200: Loss: 0.3759 Acc: 50.0000%\n",
      "\ttrain 2-201: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 2-202: Loss: 0.3532 Acc: 75.0000%\n",
      "\ttrain 2-203: Loss: 0.3402 Acc: 50.0000%\n",
      "\ttrain 2-204: Loss: 0.0998 Acc: 100.0000%\n",
      "\ttrain 2-205: Loss: 0.1824 Acc: 75.0000%\n",
      "\ttrain 2-206: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 2-207: Loss: 0.3376 Acc: 50.0000%\n",
      "\ttrain 2-208: Loss: 0.3433 Acc: 25.0000%\n",
      "\ttrain 2-209: Loss: 0.3024 Acc: 25.0000%\n",
      "\ttrain 2-210: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 2-211: Loss: 0.2991 Acc: 50.0000%\n",
      "\ttrain 2-212: Loss: 0.4867 Acc: 25.0000%\n",
      "\ttrain 2-213: Loss: 0.3212 Acc: 0.0000%\n",
      "\ttrain 2-214: Loss: 0.3654 Acc: 50.0000%\n",
      "\ttrain 2-215: Loss: 0.3877 Acc: 25.0000%\n",
      "\ttrain 2-216: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 2-217: Loss: 0.4122 Acc: 25.0000%\n",
      "\ttrain 2-218: Loss: 0.1871 Acc: 50.0000%\n",
      "\ttrain 2-219: Loss: 0.1658 Acc: 75.0000%\n",
      "\ttrain 2-220: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 2-221: Loss: 0.5563 Acc: 50.0000%\n",
      "\ttrain 2-222: Loss: 0.4809 Acc: 25.0000%\n",
      "\ttrain 2-223: Loss: 0.3693 Acc: 50.0000%\n",
      "\ttrain 2-224: Loss: 0.0945 Acc: 100.0000%\n",
      "\ttrain 2-225: Loss: 0.1604 Acc: 50.0000%\n",
      "\ttrain 2-226: Loss: 0.4872 Acc: 25.0000%\n",
      "\ttrain 2-227: Loss: 0.3157 Acc: 25.0000%\n",
      "\ttrain 2-228: Loss: 0.1713 Acc: 50.0000%\n",
      "\ttrain 2-229: Loss: 0.2451 Acc: 75.0000%\n",
      "\ttrain 2-230: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 2-231: Loss: 0.2284 Acc: 50.0000%\n",
      "\ttrain 2-232: Loss: 0.1988 Acc: 50.0000%\n",
      "\ttrain 2-233: Loss: 0.3029 Acc: 50.0000%\n",
      "\ttrain 2-234: Loss: 0.6064 Acc: 25.0000%\n",
      "\ttrain 2-235: Loss: 0.3736 Acc: 25.0000%\n",
      "\ttrain 2-236: Loss: 0.5328 Acc: 25.0000%\n",
      "\ttrain 2-237: Loss: 0.2086 Acc: 75.0000%\n",
      "\ttrain 2-238: Loss: 0.3218 Acc: 50.0000%\n",
      "\ttrain 2-239: Loss: 0.3440 Acc: 50.0000%\n",
      "\ttrain 2-240: Loss: 0.0937 Acc: 100.0000%\n",
      "\ttrain 2-241: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 2-242: Loss: 0.5416 Acc: 25.0000%\n",
      "\ttrain 2-243: Loss: 0.3571 Acc: 50.0000%\n",
      "\ttrain 2-244: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 2-245: Loss: 0.1141 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-1: Loss: 0.0595 Acc: 100.0000%\n",
      "\tvalidation 2-2: Loss: 0.2770 Acc: 50.0000%\n",
      "\tvalidation 2-3: Loss: 0.3188 Acc: 25.0000%\n",
      "\tvalidation 2-4: Loss: 0.6193 Acc: 75.0000%\n",
      "\tvalidation 2-5: Loss: 1.2537 Acc: 50.0000%\n",
      "\tvalidation 2-6: Loss: 0.1362 Acc: 75.0000%\n",
      "\tvalidation 2-7: Loss: 0.9163 Acc: 75.0000%\n",
      "\tvalidation 2-8: Loss: 0.1212 Acc: 50.0000%\n",
      "\tvalidation 2-9: Loss: 0.3252 Acc: 25.0000%\n",
      "\tvalidation 2-10: Loss: 0.3290 Acc: 75.0000%\n",
      "\tvalidation 2-11: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 2-12: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 2-13: Loss: 0.1989 Acc: 75.0000%\n",
      "\tvalidation 2-14: Loss: 0.1166 Acc: 75.0000%\n",
      "\tvalidation 2-15: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 2-16: Loss: 0.2424 Acc: 50.0000%\n",
      "\tvalidation 2-17: Loss: 0.1819 Acc: 50.0000%\n",
      "\tvalidation 2-18: Loss: 0.2041 Acc: 75.0000%\n",
      "\tvalidation 2-19: Loss: 0.2093 Acc: 75.0000%\n",
      "\tvalidation 2-20: Loss: 0.3212 Acc: 50.0000%\n",
      "\tvalidation 2-21: Loss: 0.0792 Acc: 100.0000%\n",
      "\tvalidation 2-22: Loss: 0.1898 Acc: 50.0000%\n",
      "\tvalidation 2-23: Loss: 0.1837 Acc: 75.0000%\n",
      "\tvalidation 2-24: Loss: 0.0748 Acc: 75.0000%\n",
      "\tvalidation 2-25: Loss: 0.2574 Acc: 50.0000%\n",
      "\tvalidation 2-26: Loss: 0.4911 Acc: 25.0000%\n",
      "\tvalidation 2-27: Loss: 0.7632 Acc: 50.0000%\n",
      "\tvalidation 2-28: Loss: 0.0514 Acc: 100.0000%\n",
      "\tvalidation 2-29: Loss: 0.0960 Acc: 75.0000%\n",
      "\tvalidation 2-30: Loss: 0.0734 Acc: 75.0000%\n",
      "\tvalidation 2-31: Loss: 0.1590 Acc: 75.0000%\n",
      "\tvalidation 2-32: Loss: 1.0622 Acc: 75.0000%\n",
      "\tvalidation 2-33: Loss: 0.1173 Acc: 75.0000%\n",
      "\tvalidation 2-34: Loss: 0.4002 Acc: 25.0000%\n",
      "\tvalidation 2-35: Loss: 0.1718 Acc: 75.0000%\n",
      "\tvalidation 2-36: Loss: 0.3637 Acc: 75.0000%\n",
      "\tvalidation 2-37: Loss: 0.1410 Acc: 75.0000%\n",
      "\tvalidation 2-38: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 2-39: Loss: 0.1292 Acc: 75.0000%\n",
      "\tvalidation 2-40: Loss: 0.1997 Acc: 50.0000%\n",
      "\tvalidation 2-41: Loss: 0.1333 Acc: 50.0000%\n",
      "\tvalidation 2-42: Loss: 0.9127 Acc: 50.0000%\n",
      "\tvalidation 2-43: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 2-44: Loss: 0.8995 Acc: 25.0000%\n",
      "\tvalidation 2-45: Loss: 0.3317 Acc: 50.0000%\n",
      "\tvalidation 2-46: Loss: 0.7904 Acc: 50.0000%\n",
      "\tvalidation 2-47: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 2-48: Loss: 0.2195 Acc: 75.0000%\n",
      "\tvalidation 2-49: Loss: 0.3484 Acc: 50.0000%\n",
      "\tvalidation 2-50: Loss: 0.2751 Acc: 50.0000%\n",
      "\tvalidation 2-51: Loss: 0.2409 Acc: 50.0000%\n",
      "\tvalidation 2-52: Loss: 0.2039 Acc: 75.0000%\n",
      "\tvalidation 2-53: Loss: 0.2825 Acc: 25.0000%\n",
      "\tvalidation 2-54: Loss: 0.6463 Acc: 50.0000%\n",
      "\tvalidation 2-55: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 2-56: Loss: 0.0656 Acc: 100.0000%\n",
      "\tvalidation 2-57: Loss: 0.1448 Acc: 75.0000%\n",
      "\tvalidation 2-58: Loss: 0.6622 Acc: 50.0000%\n",
      "\tvalidation 2-59: Loss: 2.8312 Acc: 50.0000%\n",
      "\tvalidation 2-60: Loss: 0.2601 Acc: 75.0000%\n",
      "\tvalidation 2-61: Loss: 0.0646 Acc: 100.0000%\n",
      "\tvalidation 2-62: Loss: 0.3283 Acc: 75.0000%\n",
      "\tvalidation 2-63: Loss: 0.1057 Acc: 75.0000%\n",
      "\tvalidation 2-64: Loss: 0.2111 Acc: 75.0000%\n",
      "\tvalidation 2-65: Loss: 0.0563 Acc: 100.0000%\n",
      "\tvalidation 2-66: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 2-67: Loss: 0.1473 Acc: 50.0000%\n",
      "\tvalidation 2-68: Loss: 0.5804 Acc: 50.0000%\n",
      "\tvalidation 2-69: Loss: 0.3000 Acc: 75.0000%\n",
      "\tvalidation 2-70: Loss: 0.0789 Acc: 75.0000%\n",
      "\tvalidation 2-71: Loss: 0.3373 Acc: 50.0000%\n",
      "\tvalidation 2-72: Loss: 0.1524 Acc: 75.0000%\n",
      "\tvalidation 2-73: Loss: 0.6005 Acc: 50.0000%\n",
      "\tvalidation 2-74: Loss: 0.2266 Acc: 50.0000%\n",
      "\tvalidation 2-75: Loss: 0.3271 Acc: 75.0000%\n",
      "\tvalidation 2-76: Loss: 0.1889 Acc: 75.0000%\n",
      "\tvalidation 2-77: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 2-78: Loss: 0.0915 Acc: 100.0000%\n",
      "\tvalidation 2-79: Loss: 0.1564 Acc: 75.0000%\n",
      "\tvalidation 2-80: Loss: 0.0810 Acc: 100.0000%\n",
      "\tvalidation 2-81: Loss: 0.2666 Acc: 50.0000%\n",
      "\tvalidation 2-82: Loss: 0.4543 Acc: 0.0000%\n",
      "\tvalidation 2-83: Loss: 0.0962 Acc: 100.0000%\n",
      "\tvalidation 2-84: Loss: 1.2698 Acc: 50.0000%\n",
      "\tvalidation 2-85: Loss: 0.1452 Acc: 50.0000%\n",
      "\tvalidation 2-86: Loss: 0.5095 Acc: 50.0000%\n",
      "\tvalidation 2-87: Loss: 1.1510 Acc: 0.0000%\n",
      "\tvalidation 2-88: Loss: 0.3610 Acc: 25.0000%\n",
      "\tvalidation 2-89: Loss: 0.1316 Acc: 100.0000%\n",
      "\tvalidation 2-90: Loss: 0.3839 Acc: 75.0000%\n",
      "\tvalidation 2-91: Loss: 1.1380 Acc: 75.0000%\n",
      "\tvalidation 2-92: Loss: 0.0593 Acc: 100.0000%\n",
      "\tvalidation 2-93: Loss: 0.3003 Acc: 50.0000%\n",
      "\tvalidation 2-94: Loss: 0.6100 Acc: 50.0000%\n",
      "\tvalidation 2-95: Loss: 0.4393 Acc: 75.0000%\n",
      "\tvalidation 2-96: Loss: 0.1051 Acc: 100.0000%\n",
      "\tvalidation 2-97: Loss: 0.0989 Acc: 100.0000%\n",
      "\tvalidation 2-98: Loss: 0.1000 Acc: 75.0000%\n",
      "\tvalidation 2-99: Loss: 0.9018 Acc: 0.0000%\n",
      "\tvalidation 2-100: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 2-101: Loss: 0.0334 Acc: 100.0000%\n",
      "\tvalidation 2-102: Loss: 0.0521 Acc: 100.0000%\n",
      "\tvalidation 2-103: Loss: 0.1404 Acc: 75.0000%\n",
      "\tvalidation 2-104: Loss: 0.0558 Acc: 100.0000%\n",
      "\tvalidation 2-105: Loss: 0.5833 Acc: 75.0000%\n",
      "\ttrain Loss: 0.3744 Acc: 47.1429%\n",
      "\tvalidation Loss: 0.3237 Acc: 67.6190%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 60s\n",
      "--------------------\n",
      "Epoch [3/40]:\n",
      "\ttrain 3-1: Loss: 0.8882 Acc: 25.0000%\n",
      "\ttrain 3-2: Loss: 0.0931 Acc: 100.0000%\n",
      "\ttrain 3-3: Loss: 0.6322 Acc: 25.0000%\n",
      "\ttrain 3-4: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 3-5: Loss: 0.2101 Acc: 50.0000%\n",
      "\ttrain 3-6: Loss: 0.5095 Acc: 75.0000%\n",
      "\ttrain 3-7: Loss: 0.6290 Acc: 75.0000%\n",
      "\ttrain 3-8: Loss: 0.6700 Acc: 50.0000%\n",
      "\ttrain 3-9: Loss: 0.1792 Acc: 50.0000%\n",
      "\ttrain 3-10: Loss: 0.2029 Acc: 50.0000%\n",
      "\ttrain 3-11: Loss: 0.3938 Acc: 25.0000%\n",
      "\ttrain 3-12: Loss: 0.4739 Acc: 0.0000%\n",
      "\ttrain 3-13: Loss: 0.2283 Acc: 75.0000%\n",
      "\ttrain 3-14: Loss: 0.1933 Acc: 75.0000%\n",
      "\ttrain 3-15: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 3-16: Loss: 0.4855 Acc: 0.0000%\n",
      "\ttrain 3-17: Loss: 0.4853 Acc: 25.0000%\n",
      "\ttrain 3-18: Loss: 0.3125 Acc: 50.0000%\n",
      "\ttrain 3-19: Loss: 0.2766 Acc: 50.0000%\n",
      "\ttrain 3-20: Loss: 0.1051 Acc: 100.0000%\n",
      "\ttrain 3-21: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 3-22: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 3-23: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 3-24: Loss: 0.7448 Acc: 25.0000%\n",
      "\ttrain 3-25: Loss: 0.5162 Acc: 25.0000%\n",
      "\ttrain 3-26: Loss: 0.3002 Acc: 50.0000%\n",
      "\ttrain 3-27: Loss: 0.2433 Acc: 75.0000%\n",
      "\ttrain 3-28: Loss: 0.2367 Acc: 25.0000%\n",
      "\ttrain 3-29: Loss: 0.3117 Acc: 50.0000%\n",
      "\ttrain 3-30: Loss: 0.9307 Acc: 0.0000%\n",
      "\ttrain 3-31: Loss: 0.8395 Acc: 50.0000%\n",
      "\ttrain 3-32: Loss: 0.6126 Acc: 75.0000%\n",
      "\ttrain 3-33: Loss: 0.1101 Acc: 75.0000%\n",
      "\ttrain 3-34: Loss: 0.8131 Acc: 50.0000%\n",
      "\ttrain 3-35: Loss: 0.2085 Acc: 75.0000%\n",
      "\ttrain 3-36: Loss: 0.3900 Acc: 50.0000%\n",
      "\ttrain 3-37: Loss: 0.3895 Acc: 50.0000%\n",
      "\ttrain 3-38: Loss: 0.1870 Acc: 75.0000%\n",
      "\ttrain 3-39: Loss: 0.2386 Acc: 75.0000%\n",
      "\ttrain 3-40: Loss: 0.3423 Acc: 75.0000%\n",
      "\ttrain 3-41: Loss: 0.3148 Acc: 50.0000%\n",
      "\ttrain 3-42: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 3-43: Loss: 0.2549 Acc: 50.0000%\n",
      "\ttrain 3-44: Loss: 0.4004 Acc: 75.0000%\n",
      "\ttrain 3-45: Loss: 0.2279 Acc: 25.0000%\n",
      "\ttrain 3-46: Loss: 0.2956 Acc: 25.0000%\n",
      "\ttrain 3-47: Loss: 0.2701 Acc: 75.0000%\n",
      "\ttrain 3-48: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 3-49: Loss: 0.0701 Acc: 100.0000%\n",
      "\ttrain 3-50: Loss: 0.4220 Acc: 50.0000%\n",
      "\ttrain 3-51: Loss: 0.1799 Acc: 50.0000%\n",
      "\ttrain 3-52: Loss: 0.0802 Acc: 100.0000%\n",
      "\ttrain 3-53: Loss: 0.2919 Acc: 50.0000%\n",
      "\ttrain 3-54: Loss: 0.2436 Acc: 50.0000%\n",
      "\ttrain 3-55: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 3-56: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 3-57: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 3-58: Loss: 0.1839 Acc: 75.0000%\n",
      "\ttrain 3-59: Loss: 0.5815 Acc: 50.0000%\n",
      "\ttrain 3-60: Loss: 0.4152 Acc: 0.0000%\n",
      "\ttrain 3-61: Loss: 0.1854 Acc: 50.0000%\n",
      "\ttrain 3-62: Loss: 0.1366 Acc: 50.0000%\n",
      "\ttrain 3-63: Loss: 0.3363 Acc: 75.0000%\n",
      "\ttrain 3-64: Loss: 0.3248 Acc: 75.0000%\n",
      "\ttrain 3-65: Loss: 0.0847 Acc: 100.0000%\n",
      "\ttrain 3-66: Loss: 0.5488 Acc: 75.0000%\n",
      "\ttrain 3-67: Loss: 0.5523 Acc: 25.0000%\n",
      "\ttrain 3-68: Loss: 0.6682 Acc: 0.0000%\n",
      "\ttrain 3-69: Loss: 0.2151 Acc: 50.0000%\n",
      "\ttrain 3-70: Loss: 0.7592 Acc: 50.0000%\n",
      "\ttrain 3-71: Loss: 0.4797 Acc: 50.0000%\n",
      "\ttrain 3-72: Loss: 0.6058 Acc: 75.0000%\n",
      "\ttrain 3-73: Loss: 0.2744 Acc: 50.0000%\n",
      "\ttrain 3-74: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 3-75: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 3-76: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 3-77: Loss: 0.3102 Acc: 25.0000%\n",
      "\ttrain 3-78: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 3-79: Loss: 0.1601 Acc: 75.0000%\n",
      "\ttrain 3-80: Loss: 0.2243 Acc: 50.0000%\n",
      "\ttrain 3-81: Loss: 0.3671 Acc: 50.0000%\n",
      "\ttrain 3-82: Loss: 0.3684 Acc: 25.0000%\n",
      "\ttrain 3-83: Loss: 0.1458 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-84: Loss: 0.3447 Acc: 50.0000%\n",
      "\ttrain 3-85: Loss: 0.5081 Acc: 50.0000%\n",
      "\ttrain 3-86: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 3-87: Loss: 0.3298 Acc: 75.0000%\n",
      "\ttrain 3-88: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 3-89: Loss: 0.1966 Acc: 75.0000%\n",
      "\ttrain 3-90: Loss: 0.2688 Acc: 50.0000%\n",
      "\ttrain 3-91: Loss: 0.3879 Acc: 25.0000%\n",
      "\ttrain 3-92: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 3-93: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 3-94: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 3-95: Loss: 0.2591 Acc: 75.0000%\n",
      "\ttrain 3-96: Loss: 0.1720 Acc: 50.0000%\n",
      "\ttrain 3-97: Loss: 0.2332 Acc: 50.0000%\n",
      "\ttrain 3-98: Loss: 0.3786 Acc: 50.0000%\n",
      "\ttrain 3-99: Loss: 0.3828 Acc: 50.0000%\n",
      "\ttrain 3-100: Loss: 0.2646 Acc: 50.0000%\n",
      "\ttrain 3-101: Loss: 0.1957 Acc: 50.0000%\n",
      "\ttrain 3-102: Loss: 0.3813 Acc: 25.0000%\n",
      "\ttrain 3-103: Loss: 0.3145 Acc: 25.0000%\n",
      "\ttrain 3-104: Loss: 0.1690 Acc: 50.0000%\n",
      "\ttrain 3-105: Loss: 0.2406 Acc: 25.0000%\n",
      "\ttrain 3-106: Loss: 0.3700 Acc: 25.0000%\n",
      "\ttrain 3-107: Loss: 0.3392 Acc: 50.0000%\n",
      "\ttrain 3-108: Loss: 0.1916 Acc: 75.0000%\n",
      "\ttrain 3-109: Loss: 0.4664 Acc: 0.0000%\n",
      "\ttrain 3-110: Loss: 0.1599 Acc: 50.0000%\n",
      "\ttrain 3-111: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 3-112: Loss: 0.4217 Acc: 25.0000%\n",
      "\ttrain 3-113: Loss: 0.5802 Acc: 25.0000%\n",
      "\ttrain 3-114: Loss: 0.1879 Acc: 75.0000%\n",
      "\ttrain 3-115: Loss: 0.1659 Acc: 50.0000%\n",
      "\ttrain 3-116: Loss: 0.1016 Acc: 100.0000%\n",
      "\ttrain 3-117: Loss: 0.2141 Acc: 75.0000%\n",
      "\ttrain 3-118: Loss: 0.1514 Acc: 75.0000%\n",
      "\ttrain 3-119: Loss: 0.5317 Acc: 0.0000%\n",
      "\ttrain 3-120: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 3-121: Loss: 0.2710 Acc: 50.0000%\n",
      "\ttrain 3-122: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 3-123: Loss: 0.3736 Acc: 50.0000%\n",
      "\ttrain 3-124: Loss: 0.1585 Acc: 75.0000%\n",
      "\ttrain 3-125: Loss: 0.1392 Acc: 75.0000%\n",
      "\ttrain 3-126: Loss: 0.1209 Acc: 100.0000%\n",
      "\ttrain 3-127: Loss: 0.2951 Acc: 75.0000%\n",
      "\ttrain 3-128: Loss: 0.2272 Acc: 50.0000%\n",
      "\ttrain 3-129: Loss: 0.1220 Acc: 100.0000%\n",
      "\ttrain 3-130: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 3-131: Loss: 0.2003 Acc: 75.0000%\n",
      "\ttrain 3-132: Loss: 0.6190 Acc: 50.0000%\n",
      "\ttrain 3-133: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 3-134: Loss: 0.7856 Acc: 25.0000%\n",
      "\ttrain 3-135: Loss: 0.6540 Acc: 50.0000%\n",
      "\ttrain 3-136: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 3-137: Loss: 0.0894 Acc: 100.0000%\n",
      "\ttrain 3-138: Loss: 0.2282 Acc: 50.0000%\n",
      "\ttrain 3-139: Loss: 0.3116 Acc: 75.0000%\n",
      "\ttrain 3-140: Loss: 0.2157 Acc: 50.0000%\n",
      "\ttrain 3-141: Loss: 0.4438 Acc: 50.0000%\n",
      "\ttrain 3-142: Loss: 0.3969 Acc: 50.0000%\n",
      "\ttrain 3-143: Loss: 0.2013 Acc: 50.0000%\n",
      "\ttrain 3-144: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 3-145: Loss: 0.2453 Acc: 50.0000%\n",
      "\ttrain 3-146: Loss: 0.1925 Acc: 50.0000%\n",
      "\ttrain 3-147: Loss: 0.4387 Acc: 25.0000%\n",
      "\ttrain 3-148: Loss: 0.2794 Acc: 50.0000%\n",
      "\ttrain 3-149: Loss: 0.2936 Acc: 75.0000%\n",
      "\ttrain 3-150: Loss: 0.0827 Acc: 100.0000%\n",
      "\ttrain 3-151: Loss: 0.3102 Acc: 75.0000%\n",
      "\ttrain 3-152: Loss: 0.2453 Acc: 75.0000%\n",
      "\ttrain 3-153: Loss: 0.1290 Acc: 100.0000%\n",
      "\ttrain 3-154: Loss: 0.1655 Acc: 75.0000%\n",
      "\ttrain 3-155: Loss: 0.4689 Acc: 25.0000%\n",
      "\ttrain 3-156: Loss: 0.1044 Acc: 100.0000%\n",
      "\ttrain 3-157: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 3-158: Loss: 0.2663 Acc: 50.0000%\n",
      "\ttrain 3-159: Loss: 0.6733 Acc: 0.0000%\n",
      "\ttrain 3-160: Loss: 0.2769 Acc: 50.0000%\n",
      "\ttrain 3-161: Loss: 0.2769 Acc: 50.0000%\n",
      "\ttrain 3-162: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 3-163: Loss: 0.2192 Acc: 25.0000%\n",
      "\ttrain 3-164: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 3-165: Loss: 0.1831 Acc: 75.0000%\n",
      "\ttrain 3-166: Loss: 0.2520 Acc: 50.0000%\n",
      "\ttrain 3-167: Loss: 0.4068 Acc: 25.0000%\n",
      "\ttrain 3-168: Loss: 0.2777 Acc: 50.0000%\n",
      "\ttrain 3-169: Loss: 1.0519 Acc: 0.0000%\n",
      "\ttrain 3-170: Loss: 0.4875 Acc: 25.0000%\n",
      "\ttrain 3-171: Loss: 0.2365 Acc: 50.0000%\n",
      "\ttrain 3-172: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 3-173: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 3-174: Loss: 0.3020 Acc: 50.0000%\n",
      "\ttrain 3-175: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 3-176: Loss: 0.1022 Acc: 100.0000%\n",
      "\ttrain 3-177: Loss: 0.1957 Acc: 50.0000%\n",
      "\ttrain 3-178: Loss: 0.2862 Acc: 50.0000%\n",
      "\ttrain 3-179: Loss: 1.0462 Acc: 0.0000%\n",
      "\ttrain 3-180: Loss: 0.5018 Acc: 50.0000%\n",
      "\ttrain 3-181: Loss: 0.1992 Acc: 50.0000%\n",
      "\ttrain 3-182: Loss: 0.2435 Acc: 50.0000%\n",
      "\ttrain 3-183: Loss: 0.4416 Acc: 25.0000%\n",
      "\ttrain 3-184: Loss: 0.5161 Acc: 50.0000%\n",
      "\ttrain 3-185: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 3-186: Loss: 0.4795 Acc: 75.0000%\n",
      "\ttrain 3-187: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 3-188: Loss: 0.1829 Acc: 75.0000%\n",
      "\ttrain 3-189: Loss: 0.3481 Acc: 75.0000%\n",
      "\ttrain 3-190: Loss: 0.3217 Acc: 50.0000%\n",
      "\ttrain 3-191: Loss: 0.0957 Acc: 100.0000%\n",
      "\ttrain 3-192: Loss: 0.2123 Acc: 50.0000%\n",
      "\ttrain 3-193: Loss: 0.8454 Acc: 25.0000%\n",
      "\ttrain 3-194: Loss: 0.4991 Acc: 50.0000%\n",
      "\ttrain 3-195: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 3-196: Loss: 0.7096 Acc: 50.0000%\n",
      "\ttrain 3-197: Loss: 0.2196 Acc: 75.0000%\n",
      "\ttrain 3-198: Loss: 0.6088 Acc: 50.0000%\n",
      "\ttrain 3-199: Loss: 0.2379 Acc: 50.0000%\n",
      "\ttrain 3-200: Loss: 0.4691 Acc: 0.0000%\n",
      "\ttrain 3-201: Loss: 0.2161 Acc: 75.0000%\n",
      "\ttrain 3-202: Loss: 0.5375 Acc: 25.0000%\n",
      "\ttrain 3-203: Loss: 0.6209 Acc: 25.0000%\n",
      "\ttrain 3-204: Loss: 0.6666 Acc: 0.0000%\n",
      "\ttrain 3-205: Loss: 0.1888 Acc: 75.0000%\n",
      "\ttrain 3-206: Loss: 0.2029 Acc: 50.0000%\n",
      "\ttrain 3-207: Loss: 0.1051 Acc: 100.0000%\n",
      "\ttrain 3-208: Loss: 0.4881 Acc: 50.0000%\n",
      "\ttrain 3-209: Loss: 0.3689 Acc: 25.0000%\n",
      "\ttrain 3-210: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 3-211: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 3-212: Loss: 0.2158 Acc: 75.0000%\n",
      "\ttrain 3-213: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 3-214: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 3-215: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 3-216: Loss: 0.4765 Acc: 50.0000%\n",
      "\ttrain 3-217: Loss: 1.0580 Acc: 25.0000%\n",
      "\ttrain 3-218: Loss: 0.9322 Acc: 0.0000%\n",
      "\ttrain 3-219: Loss: 0.7663 Acc: 0.0000%\n",
      "\ttrain 3-220: Loss: 0.1999 Acc: 50.0000%\n",
      "\ttrain 3-221: Loss: 0.2779 Acc: 25.0000%\n",
      "\ttrain 3-222: Loss: 0.1792 Acc: 75.0000%\n",
      "\ttrain 3-223: Loss: 0.2311 Acc: 75.0000%\n",
      "\ttrain 3-224: Loss: 0.1475 Acc: 100.0000%\n",
      "\ttrain 3-225: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 3-226: Loss: 0.1997 Acc: 50.0000%\n",
      "\ttrain 3-227: Loss: 0.2761 Acc: 75.0000%\n",
      "\ttrain 3-228: Loss: 0.3574 Acc: 50.0000%\n",
      "\ttrain 3-229: Loss: 0.3817 Acc: 25.0000%\n",
      "\ttrain 3-230: Loss: 0.2358 Acc: 50.0000%\n",
      "\ttrain 3-231: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 3-232: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 3-233: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 3-234: Loss: 0.4664 Acc: 50.0000%\n",
      "\ttrain 3-235: Loss: 0.2192 Acc: 50.0000%\n",
      "\ttrain 3-236: Loss: 0.5720 Acc: 50.0000%\n",
      "\ttrain 3-237: Loss: 1.0151 Acc: 75.0000%\n",
      "\ttrain 3-238: Loss: 0.2101 Acc: 50.0000%\n",
      "\ttrain 3-239: Loss: 0.4349 Acc: 25.0000%\n",
      "\ttrain 3-240: Loss: 0.2349 Acc: 25.0000%\n",
      "\ttrain 3-241: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 3-242: Loss: 0.2306 Acc: 75.0000%\n",
      "\ttrain 3-243: Loss: 0.3064 Acc: 50.0000%\n",
      "\ttrain 3-244: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 3-245: Loss: 0.7452 Acc: 25.0000%\n",
      "\tvalidation 3-1: Loss: 0.1273 Acc: 75.0000%\n",
      "\tvalidation 3-2: Loss: 0.2197 Acc: 50.0000%\n",
      "\tvalidation 3-3: Loss: 0.1970 Acc: 50.0000%\n",
      "\tvalidation 3-4: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 3-5: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 3-6: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 3-7: Loss: 0.2532 Acc: 50.0000%\n",
      "\tvalidation 3-8: Loss: 0.0878 Acc: 75.0000%\n",
      "\tvalidation 3-9: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 3-10: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 3-11: Loss: 0.2701 Acc: 50.0000%\n",
      "\tvalidation 3-12: Loss: 0.1147 Acc: 75.0000%\n",
      "\tvalidation 3-13: Loss: 0.3339 Acc: 25.0000%\n",
      "\tvalidation 3-14: Loss: 0.2189 Acc: 50.0000%\n",
      "\tvalidation 3-15: Loss: 0.1576 Acc: 75.0000%\n",
      "\tvalidation 3-16: Loss: 0.1096 Acc: 75.0000%\n",
      "\tvalidation 3-17: Loss: 0.1065 Acc: 75.0000%\n",
      "\tvalidation 3-18: Loss: 0.1388 Acc: 75.0000%\n",
      "\tvalidation 3-19: Loss: 0.2455 Acc: 50.0000%\n",
      "\tvalidation 3-20: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 3-21: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 3-22: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 3-23: Loss: 0.2108 Acc: 50.0000%\n",
      "\tvalidation 3-24: Loss: 0.1331 Acc: 75.0000%\n",
      "\tvalidation 3-25: Loss: 0.1859 Acc: 50.0000%\n",
      "\tvalidation 3-26: Loss: 0.1433 Acc: 75.0000%\n",
      "\tvalidation 3-27: Loss: 0.3529 Acc: 25.0000%\n",
      "\tvalidation 3-28: Loss: 0.2376 Acc: 50.0000%\n",
      "\tvalidation 3-29: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 3-30: Loss: 0.2860 Acc: 75.0000%\n",
      "\tvalidation 3-31: Loss: 0.1021 Acc: 75.0000%\n",
      "\tvalidation 3-32: Loss: 0.0716 Acc: 75.0000%\n",
      "\tvalidation 3-33: Loss: 0.0962 Acc: 75.0000%\n",
      "\tvalidation 3-34: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 3-35: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 3-36: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 3-37: Loss: 0.3296 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-38: Loss: 0.1386 Acc: 75.0000%\n",
      "\tvalidation 3-39: Loss: 0.1988 Acc: 50.0000%\n",
      "\tvalidation 3-40: Loss: 0.2076 Acc: 50.0000%\n",
      "\tvalidation 3-41: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 3-42: Loss: 0.5144 Acc: 75.0000%\n",
      "\tvalidation 3-43: Loss: 0.2296 Acc: 50.0000%\n",
      "\tvalidation 3-44: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 3-45: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 3-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-47: Loss: 0.1439 Acc: 75.0000%\n",
      "\tvalidation 3-48: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 3-49: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 3-50: Loss: 0.0525 Acc: 100.0000%\n",
      "\tvalidation 3-51: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 3-52: Loss: 0.1399 Acc: 75.0000%\n",
      "\tvalidation 3-53: Loss: 0.1184 Acc: 75.0000%\n",
      "\tvalidation 3-54: Loss: 0.1291 Acc: 75.0000%\n",
      "\tvalidation 3-55: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 3-56: Loss: 0.1069 Acc: 75.0000%\n",
      "\tvalidation 3-57: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 3-58: Loss: 0.1254 Acc: 75.0000%\n",
      "\tvalidation 3-59: Loss: 0.2395 Acc: 50.0000%\n",
      "\tvalidation 3-60: Loss: 0.1162 Acc: 75.0000%\n",
      "\tvalidation 3-61: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 3-62: Loss: 0.1968 Acc: 50.0000%\n",
      "\tvalidation 3-63: Loss: 0.1348 Acc: 75.0000%\n",
      "\tvalidation 3-64: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 3-65: Loss: 0.1431 Acc: 75.0000%\n",
      "\tvalidation 3-66: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 3-67: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 3-68: Loss: 0.1658 Acc: 75.0000%\n",
      "\tvalidation 3-69: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 3-70: Loss: 0.0995 Acc: 75.0000%\n",
      "\tvalidation 3-71: Loss: 0.1126 Acc: 75.0000%\n",
      "\tvalidation 3-72: Loss: 0.1438 Acc: 75.0000%\n",
      "\tvalidation 3-73: Loss: 0.0983 Acc: 75.0000%\n",
      "\tvalidation 3-74: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 3-75: Loss: 0.1579 Acc: 75.0000%\n",
      "\tvalidation 3-76: Loss: 0.2446 Acc: 50.0000%\n",
      "\tvalidation 3-77: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 3-78: Loss: 0.1396 Acc: 75.0000%\n",
      "\tvalidation 3-79: Loss: 0.1551 Acc: 75.0000%\n",
      "\tvalidation 3-80: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 3-81: Loss: 0.2583 Acc: 50.0000%\n",
      "\tvalidation 3-82: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 3-83: Loss: 0.2164 Acc: 50.0000%\n",
      "\tvalidation 3-84: Loss: 0.4309 Acc: 25.0000%\n",
      "\tvalidation 3-85: Loss: 0.4398 Acc: 50.0000%\n",
      "\tvalidation 3-86: Loss: 0.1116 Acc: 75.0000%\n",
      "\tvalidation 3-87: Loss: 0.2407 Acc: 50.0000%\n",
      "\tvalidation 3-88: Loss: 0.1012 Acc: 75.0000%\n",
      "\tvalidation 3-89: Loss: 0.2345 Acc: 50.0000%\n",
      "\tvalidation 3-90: Loss: 0.1210 Acc: 75.0000%\n",
      "\tvalidation 3-91: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 3-92: Loss: 0.2517 Acc: 50.0000%\n",
      "\tvalidation 3-93: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 3-94: Loss: 0.1602 Acc: 75.0000%\n",
      "\tvalidation 3-95: Loss: 0.0989 Acc: 75.0000%\n",
      "\tvalidation 3-96: Loss: 0.4049 Acc: 50.0000%\n",
      "\tvalidation 3-97: Loss: 0.1030 Acc: 75.0000%\n",
      "\tvalidation 3-98: Loss: 0.2222 Acc: 50.0000%\n",
      "\tvalidation 3-99: Loss: 0.0986 Acc: 75.0000%\n",
      "\tvalidation 3-100: Loss: 0.0972 Acc: 75.0000%\n",
      "\tvalidation 3-101: Loss: 0.0562 Acc: 100.0000%\n",
      "\tvalidation 3-102: Loss: 0.2975 Acc: 25.0000%\n",
      "\tvalidation 3-103: Loss: 0.4425 Acc: 75.0000%\n",
      "\tvalidation 3-104: Loss: 0.0814 Acc: 100.0000%\n",
      "\tvalidation 3-105: Loss: 0.2431 Acc: 50.0000%\n",
      "\ttrain Loss: 0.3095 Acc: 57.5510%\n",
      "\tvalidation Loss: 0.1388 Acc: 74.2857%\n",
      "网络参数更新\n",
      "Time passed 0h 2m 59s\n",
      "--------------------\n",
      "Epoch [4/40]:\n",
      "\ttrain 4-1: Loss: 0.6148 Acc: 50.0000%\n",
      "\ttrain 4-2: Loss: 0.2067 Acc: 75.0000%\n",
      "\ttrain 4-3: Loss: 0.1017 Acc: 75.0000%\n",
      "\ttrain 4-4: Loss: 0.6026 Acc: 0.0000%\n",
      "\ttrain 4-5: Loss: 0.1082 Acc: 75.0000%\n",
      "\ttrain 4-6: Loss: 0.1416 Acc: 50.0000%\n",
      "\ttrain 4-7: Loss: 0.0996 Acc: 100.0000%\n",
      "\ttrain 4-8: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 4-9: Loss: 0.5494 Acc: 0.0000%\n",
      "\ttrain 4-10: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 4-11: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 4-12: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 4-13: Loss: 0.3308 Acc: 50.0000%\n",
      "\ttrain 4-14: Loss: 0.1464 Acc: 50.0000%\n",
      "\ttrain 4-15: Loss: 0.0819 Acc: 100.0000%\n",
      "\ttrain 4-16: Loss: 0.3370 Acc: 50.0000%\n",
      "\ttrain 4-17: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 4-18: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 4-19: Loss: 0.4477 Acc: 50.0000%\n",
      "\ttrain 4-20: Loss: 0.1655 Acc: 50.0000%\n",
      "\ttrain 4-21: Loss: 0.1408 Acc: 50.0000%\n",
      "\ttrain 4-22: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 4-23: Loss: 0.4002 Acc: 25.0000%\n",
      "\ttrain 4-24: Loss: 0.1450 Acc: 75.0000%\n",
      "\ttrain 4-25: Loss: 0.6447 Acc: 50.0000%\n",
      "\ttrain 4-26: Loss: 0.2415 Acc: 75.0000%\n",
      "\ttrain 4-27: Loss: 0.3866 Acc: 25.0000%\n",
      "\ttrain 4-28: Loss: 0.2760 Acc: 25.0000%\n",
      "\ttrain 4-29: Loss: 0.2231 Acc: 75.0000%\n",
      "\ttrain 4-30: Loss: 0.2338 Acc: 75.0000%\n",
      "\ttrain 4-31: Loss: 0.3495 Acc: 50.0000%\n",
      "\ttrain 4-32: Loss: 0.3078 Acc: 75.0000%\n",
      "\ttrain 4-33: Loss: 0.3544 Acc: 50.0000%\n",
      "\ttrain 4-34: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 4-35: Loss: 0.3610 Acc: 25.0000%\n",
      "\ttrain 4-36: Loss: 0.7009 Acc: 25.0000%\n",
      "\ttrain 4-37: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 4-38: Loss: 0.2713 Acc: 75.0000%\n",
      "\ttrain 4-39: Loss: 0.5362 Acc: 25.0000%\n",
      "\ttrain 4-40: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 4-41: Loss: 0.4097 Acc: 25.0000%\n",
      "\ttrain 4-42: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 4-43: Loss: 0.3072 Acc: 50.0000%\n",
      "\ttrain 4-44: Loss: 0.1834 Acc: 75.0000%\n",
      "\ttrain 4-45: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 4-46: Loss: 0.5027 Acc: 25.0000%\n",
      "\ttrain 4-47: Loss: 0.4375 Acc: 25.0000%\n",
      "\ttrain 4-48: Loss: 0.4143 Acc: 25.0000%\n",
      "\ttrain 4-49: Loss: 0.5187 Acc: 25.0000%\n",
      "\ttrain 4-50: Loss: 0.3452 Acc: 75.0000%\n",
      "\ttrain 4-51: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 4-52: Loss: 0.4743 Acc: 50.0000%\n",
      "\ttrain 4-53: Loss: 0.6117 Acc: 0.0000%\n",
      "\ttrain 4-54: Loss: 0.2560 Acc: 75.0000%\n",
      "\ttrain 4-55: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 4-56: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 4-57: Loss: 0.3102 Acc: 50.0000%\n",
      "\ttrain 4-58: Loss: 0.2193 Acc: 50.0000%\n",
      "\ttrain 4-59: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 4-60: Loss: 0.3313 Acc: 50.0000%\n",
      "\ttrain 4-61: Loss: 0.2303 Acc: 50.0000%\n",
      "\ttrain 4-62: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 4-63: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 4-64: Loss: 0.2150 Acc: 50.0000%\n",
      "\ttrain 4-65: Loss: 0.2740 Acc: 50.0000%\n",
      "\ttrain 4-66: Loss: 0.3909 Acc: 25.0000%\n",
      "\ttrain 4-67: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 4-68: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 4-69: Loss: 0.2389 Acc: 75.0000%\n",
      "\ttrain 4-70: Loss: 0.5934 Acc: 25.0000%\n",
      "\ttrain 4-71: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 4-72: Loss: 0.3496 Acc: 25.0000%\n",
      "\ttrain 4-73: Loss: 0.3311 Acc: 25.0000%\n",
      "\ttrain 4-74: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 4-75: Loss: 0.2987 Acc: 50.0000%\n",
      "\ttrain 4-76: Loss: 0.3443 Acc: 50.0000%\n",
      "\ttrain 4-77: Loss: 0.4790 Acc: 50.0000%\n",
      "\ttrain 4-78: Loss: 0.4982 Acc: 50.0000%\n",
      "\ttrain 4-79: Loss: 0.3088 Acc: 50.0000%\n",
      "\ttrain 4-80: Loss: 0.2800 Acc: 50.0000%\n",
      "\ttrain 4-81: Loss: 0.3151 Acc: 50.0000%\n",
      "\ttrain 4-82: Loss: 0.3540 Acc: 75.0000%\n",
      "\ttrain 4-83: Loss: 0.9355 Acc: 0.0000%\n",
      "\ttrain 4-84: Loss: 0.1618 Acc: 75.0000%\n",
      "\ttrain 4-85: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 4-86: Loss: 0.7477 Acc: 25.0000%\n",
      "\ttrain 4-87: Loss: 0.3196 Acc: 25.0000%\n",
      "\ttrain 4-88: Loss: 0.1838 Acc: 50.0000%\n",
      "\ttrain 4-89: Loss: 0.4632 Acc: 50.0000%\n",
      "\ttrain 4-90: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 4-91: Loss: 0.2046 Acc: 50.0000%\n",
      "\ttrain 4-92: Loss: 0.1688 Acc: 75.0000%\n",
      "\ttrain 4-93: Loss: 0.2251 Acc: 75.0000%\n",
      "\ttrain 4-94: Loss: 0.3828 Acc: 50.0000%\n",
      "\ttrain 4-95: Loss: 0.3902 Acc: 50.0000%\n",
      "\ttrain 4-96: Loss: 0.2141 Acc: 50.0000%\n",
      "\ttrain 4-97: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 4-98: Loss: 0.3151 Acc: 50.0000%\n",
      "\ttrain 4-99: Loss: 0.2190 Acc: 50.0000%\n",
      "\ttrain 4-100: Loss: 0.2600 Acc: 75.0000%\n",
      "\ttrain 4-101: Loss: 0.2323 Acc: 75.0000%\n",
      "\ttrain 4-102: Loss: 0.2455 Acc: 50.0000%\n",
      "\ttrain 4-103: Loss: 0.3118 Acc: 75.0000%\n",
      "\ttrain 4-104: Loss: 0.1836 Acc: 50.0000%\n",
      "\ttrain 4-105: Loss: 0.2011 Acc: 50.0000%\n",
      "\ttrain 4-106: Loss: 0.1974 Acc: 50.0000%\n",
      "\ttrain 4-107: Loss: 0.3299 Acc: 50.0000%\n",
      "\ttrain 4-108: Loss: 0.1377 Acc: 75.0000%\n",
      "\ttrain 4-109: Loss: 0.4529 Acc: 50.0000%\n",
      "\ttrain 4-110: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 4-111: Loss: 0.5338 Acc: 25.0000%\n",
      "\ttrain 4-112: Loss: 0.3114 Acc: 50.0000%\n",
      "\ttrain 4-113: Loss: 0.2258 Acc: 75.0000%\n",
      "\ttrain 4-114: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 4-115: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 4-116: Loss: 0.0825 Acc: 100.0000%\n",
      "\ttrain 4-117: Loss: 0.2299 Acc: 50.0000%\n",
      "\ttrain 4-118: Loss: 0.3571 Acc: 50.0000%\n",
      "\ttrain 4-119: Loss: 0.2214 Acc: 50.0000%\n",
      "\ttrain 4-120: Loss: 0.7400 Acc: 50.0000%\n",
      "\ttrain 4-121: Loss: 0.7721 Acc: 50.0000%\n",
      "\ttrain 4-122: Loss: 0.2065 Acc: 50.0000%\n",
      "\ttrain 4-123: Loss: 0.3469 Acc: 50.0000%\n",
      "\ttrain 4-124: Loss: 0.1205 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-125: Loss: 0.4255 Acc: 0.0000%\n",
      "\ttrain 4-126: Loss: 0.2420 Acc: 75.0000%\n",
      "\ttrain 4-127: Loss: 0.2029 Acc: 50.0000%\n",
      "\ttrain 4-128: Loss: 0.1088 Acc: 100.0000%\n",
      "\ttrain 4-129: Loss: 0.1127 Acc: 100.0000%\n",
      "\ttrain 4-130: Loss: 0.2816 Acc: 25.0000%\n",
      "\ttrain 4-131: Loss: 0.3445 Acc: 50.0000%\n",
      "\ttrain 4-132: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 4-133: Loss: 0.1816 Acc: 75.0000%\n",
      "\ttrain 4-134: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 4-135: Loss: 0.3353 Acc: 25.0000%\n",
      "\ttrain 4-136: Loss: 0.2852 Acc: 25.0000%\n",
      "\ttrain 4-137: Loss: 0.1027 Acc: 50.0000%\n",
      "\ttrain 4-138: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 4-139: Loss: 0.6374 Acc: 25.0000%\n",
      "\ttrain 4-140: Loss: 0.2289 Acc: 25.0000%\n",
      "\ttrain 4-141: Loss: 0.1133 Acc: 100.0000%\n",
      "\ttrain 4-142: Loss: 0.5250 Acc: 25.0000%\n",
      "\ttrain 4-143: Loss: 0.2376 Acc: 75.0000%\n",
      "\ttrain 4-144: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 4-145: Loss: 0.3209 Acc: 50.0000%\n",
      "\ttrain 4-146: Loss: 0.2617 Acc: 75.0000%\n",
      "\ttrain 4-147: Loss: 0.3474 Acc: 50.0000%\n",
      "\ttrain 4-148: Loss: 0.2858 Acc: 25.0000%\n",
      "\ttrain 4-149: Loss: 0.2917 Acc: 25.0000%\n",
      "\ttrain 4-150: Loss: 0.4158 Acc: 25.0000%\n",
      "\ttrain 4-151: Loss: 0.4203 Acc: 50.0000%\n",
      "\ttrain 4-152: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 4-153: Loss: 0.2587 Acc: 50.0000%\n",
      "\ttrain 4-154: Loss: 0.3722 Acc: 25.0000%\n",
      "\ttrain 4-155: Loss: 0.2375 Acc: 50.0000%\n",
      "\ttrain 4-156: Loss: 0.7951 Acc: 25.0000%\n",
      "\ttrain 4-157: Loss: 0.6117 Acc: 50.0000%\n",
      "\ttrain 4-158: Loss: 0.1691 Acc: 50.0000%\n",
      "\ttrain 4-159: Loss: 0.3915 Acc: 50.0000%\n",
      "\ttrain 4-160: Loss: 0.3240 Acc: 75.0000%\n",
      "\ttrain 4-161: Loss: 0.3489 Acc: 50.0000%\n",
      "\ttrain 4-162: Loss: 0.2570 Acc: 75.0000%\n",
      "\ttrain 4-163: Loss: 0.4757 Acc: 25.0000%\n",
      "\ttrain 4-164: Loss: 0.2258 Acc: 50.0000%\n",
      "\ttrain 4-165: Loss: 0.3468 Acc: 50.0000%\n",
      "\ttrain 4-166: Loss: 0.2292 Acc: 75.0000%\n",
      "\ttrain 4-167: Loss: 0.4595 Acc: 50.0000%\n",
      "\ttrain 4-168: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 4-169: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 4-170: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 4-171: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 4-172: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 4-173: Loss: 0.5328 Acc: 25.0000%\n",
      "\ttrain 4-174: Loss: 0.5984 Acc: 25.0000%\n",
      "\ttrain 4-175: Loss: 0.1985 Acc: 50.0000%\n",
      "\ttrain 4-176: Loss: 0.1667 Acc: 50.0000%\n",
      "\ttrain 4-177: Loss: 0.1579 Acc: 75.0000%\n",
      "\ttrain 4-178: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 4-179: Loss: 0.1950 Acc: 50.0000%\n",
      "\ttrain 4-180: Loss: 0.5710 Acc: 50.0000%\n",
      "\ttrain 4-181: Loss: 0.5996 Acc: 75.0000%\n",
      "\ttrain 4-182: Loss: 0.2955 Acc: 50.0000%\n",
      "\ttrain 4-183: Loss: 0.4394 Acc: 25.0000%\n",
      "\ttrain 4-184: Loss: 0.1824 Acc: 50.0000%\n",
      "\ttrain 4-185: Loss: 0.3264 Acc: 25.0000%\n",
      "\ttrain 4-186: Loss: 0.0932 Acc: 100.0000%\n",
      "\ttrain 4-187: Loss: 0.4784 Acc: 75.0000%\n",
      "\ttrain 4-188: Loss: 0.1672 Acc: 75.0000%\n",
      "\ttrain 4-189: Loss: 0.2382 Acc: 75.0000%\n",
      "\ttrain 4-190: Loss: 0.6331 Acc: 25.0000%\n",
      "\ttrain 4-191: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 4-192: Loss: 0.3499 Acc: 75.0000%\n",
      "\ttrain 4-193: Loss: 0.3797 Acc: 50.0000%\n",
      "\ttrain 4-194: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 4-195: Loss: 0.5454 Acc: 50.0000%\n",
      "\ttrain 4-196: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 4-197: Loss: 0.2082 Acc: 50.0000%\n",
      "\ttrain 4-198: Loss: 1.1879 Acc: 25.0000%\n",
      "\ttrain 4-199: Loss: 0.2194 Acc: 25.0000%\n",
      "\ttrain 4-200: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 4-201: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 4-202: Loss: 0.3778 Acc: 25.0000%\n",
      "\ttrain 4-203: Loss: 0.5187 Acc: 0.0000%\n",
      "\ttrain 4-204: Loss: 0.2669 Acc: 75.0000%\n",
      "\ttrain 4-205: Loss: 0.4228 Acc: 25.0000%\n",
      "\ttrain 4-206: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 4-207: Loss: 0.1837 Acc: 50.0000%\n",
      "\ttrain 4-208: Loss: 0.1761 Acc: 50.0000%\n",
      "\ttrain 4-209: Loss: 0.2650 Acc: 25.0000%\n",
      "\ttrain 4-210: Loss: 0.0976 Acc: 100.0000%\n",
      "\ttrain 4-211: Loss: 0.2911 Acc: 75.0000%\n",
      "\ttrain 4-212: Loss: 0.1557 Acc: 75.0000%\n",
      "\ttrain 4-213: Loss: 0.2879 Acc: 50.0000%\n",
      "\ttrain 4-214: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 4-215: Loss: 0.2613 Acc: 50.0000%\n",
      "\ttrain 4-216: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 4-217: Loss: 0.4575 Acc: 50.0000%\n",
      "\ttrain 4-218: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 4-219: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 4-220: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 4-221: Loss: 0.2465 Acc: 50.0000%\n",
      "\ttrain 4-222: Loss: 0.1707 Acc: 50.0000%\n",
      "\ttrain 4-223: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 4-224: Loss: 0.3942 Acc: 25.0000%\n",
      "\ttrain 4-225: Loss: 0.1086 Acc: 100.0000%\n",
      "\ttrain 4-226: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 4-227: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 4-228: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 4-229: Loss: 0.4674 Acc: 50.0000%\n",
      "\ttrain 4-230: Loss: 0.3274 Acc: 50.0000%\n",
      "\ttrain 4-231: Loss: 0.2959 Acc: 50.0000%\n",
      "\ttrain 4-232: Loss: 0.2250 Acc: 50.0000%\n",
      "\ttrain 4-233: Loss: 0.2824 Acc: 50.0000%\n",
      "\ttrain 4-234: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 4-235: Loss: 0.2123 Acc: 50.0000%\n",
      "\ttrain 4-236: Loss: 0.2854 Acc: 75.0000%\n",
      "\ttrain 4-237: Loss: 0.2433 Acc: 25.0000%\n",
      "\ttrain 4-238: Loss: 0.3708 Acc: 25.0000%\n",
      "\ttrain 4-239: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 4-240: Loss: 0.2194 Acc: 75.0000%\n",
      "\ttrain 4-241: Loss: 0.3140 Acc: 75.0000%\n",
      "\ttrain 4-242: Loss: 0.1698 Acc: 50.0000%\n",
      "\ttrain 4-243: Loss: 0.3730 Acc: 25.0000%\n",
      "\ttrain 4-244: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 4-245: Loss: 0.0579 Acc: 100.0000%\n",
      "\tvalidation 4-1: Loss: 0.1334 Acc: 75.0000%\n",
      "\tvalidation 4-2: Loss: 0.1033 Acc: 75.0000%\n",
      "\tvalidation 4-3: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 4-4: Loss: 0.2120 Acc: 75.0000%\n",
      "\tvalidation 4-5: Loss: 0.3284 Acc: 75.0000%\n",
      "\tvalidation 4-6: Loss: 0.9985 Acc: 50.0000%\n",
      "\tvalidation 4-7: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 4-8: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 4-9: Loss: 2.7268 Acc: 25.0000%\n",
      "\tvalidation 4-10: Loss: 0.3825 Acc: 50.0000%\n",
      "\tvalidation 4-11: Loss: 1.4256 Acc: 75.0000%\n",
      "\tvalidation 4-12: Loss: 0.1137 Acc: 75.0000%\n",
      "\tvalidation 4-13: Loss: 0.3626 Acc: 50.0000%\n",
      "\tvalidation 4-14: Loss: 0.7921 Acc: 75.0000%\n",
      "\tvalidation 4-15: Loss: 1.0285 Acc: 50.0000%\n",
      "\tvalidation 4-16: Loss: 0.0856 Acc: 75.0000%\n",
      "\tvalidation 4-17: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 4-18: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 4-19: Loss: 0.0768 Acc: 75.0000%\n",
      "\tvalidation 4-20: Loss: 0.0695 Acc: 75.0000%\n",
      "\tvalidation 4-21: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 4-22: Loss: 0.1088 Acc: 75.0000%\n",
      "\tvalidation 4-23: Loss: 0.0914 Acc: 75.0000%\n",
      "\tvalidation 4-24: Loss: 0.4514 Acc: 50.0000%\n",
      "\tvalidation 4-25: Loss: 1.0303 Acc: 75.0000%\n",
      "\tvalidation 4-26: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 4-27: Loss: 0.2727 Acc: 75.0000%\n",
      "\tvalidation 4-28: Loss: 0.2940 Acc: 50.0000%\n",
      "\tvalidation 4-29: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 4-30: Loss: 1.2611 Acc: 50.0000%\n",
      "\tvalidation 4-31: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 4-32: Loss: 1.9280 Acc: 25.0000%\n",
      "\tvalidation 4-33: Loss: 0.2034 Acc: 75.0000%\n",
      "\tvalidation 4-34: Loss: 0.0549 Acc: 100.0000%\n",
      "\tvalidation 4-35: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 4-36: Loss: 0.2567 Acc: 75.0000%\n",
      "\tvalidation 4-37: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 4-38: Loss: 0.5002 Acc: 75.0000%\n",
      "\tvalidation 4-39: Loss: 1.0001 Acc: 75.0000%\n",
      "\tvalidation 4-40: Loss: 0.0706 Acc: 75.0000%\n",
      "\tvalidation 4-41: Loss: 0.3276 Acc: 50.0000%\n",
      "\tvalidation 4-42: Loss: 0.5224 Acc: 75.0000%\n",
      "\tvalidation 4-43: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 4-44: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 4-45: Loss: 0.0532 Acc: 100.0000%\n",
      "\tvalidation 4-46: Loss: 0.3391 Acc: 50.0000%\n",
      "\tvalidation 4-47: Loss: 0.0790 Acc: 75.0000%\n",
      "\tvalidation 4-48: Loss: 0.0784 Acc: 75.0000%\n",
      "\tvalidation 4-49: Loss: 0.1658 Acc: 50.0000%\n",
      "\tvalidation 4-50: Loss: 0.0826 Acc: 75.0000%\n",
      "\tvalidation 4-51: Loss: 0.0537 Acc: 100.0000%\n",
      "\tvalidation 4-52: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 4-53: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 4-54: Loss: 0.1376 Acc: 50.0000%\n",
      "\tvalidation 4-55: Loss: 0.1582 Acc: 50.0000%\n",
      "\tvalidation 4-56: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 4-57: Loss: 0.1547 Acc: 75.0000%\n",
      "\tvalidation 4-58: Loss: 0.0864 Acc: 75.0000%\n",
      "\tvalidation 4-59: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 4-60: Loss: 0.0794 Acc: 75.0000%\n",
      "\tvalidation 4-61: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 4-62: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 4-63: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 4-64: Loss: 0.3312 Acc: 50.0000%\n",
      "\tvalidation 4-65: Loss: 0.1504 Acc: 75.0000%\n",
      "\tvalidation 4-66: Loss: 1.1391 Acc: 50.0000%\n",
      "\tvalidation 4-67: Loss: 0.1239 Acc: 75.0000%\n",
      "\tvalidation 4-68: Loss: 0.0707 Acc: 75.0000%\n",
      "\tvalidation 4-69: Loss: 0.2589 Acc: 50.0000%\n",
      "\tvalidation 4-70: Loss: 1.0912 Acc: 50.0000%\n",
      "\tvalidation 4-71: Loss: 0.1056 Acc: 75.0000%\n",
      "\tvalidation 4-72: Loss: 0.1459 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 4-73: Loss: 0.2756 Acc: 50.0000%\n",
      "\tvalidation 4-74: Loss: 0.2139 Acc: 50.0000%\n",
      "\tvalidation 4-75: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 4-76: Loss: 0.1643 Acc: 75.0000%\n",
      "\tvalidation 4-77: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 4-78: Loss: 0.2219 Acc: 50.0000%\n",
      "\tvalidation 4-79: Loss: 0.6182 Acc: 50.0000%\n",
      "\tvalidation 4-80: Loss: 0.0812 Acc: 75.0000%\n",
      "\tvalidation 4-81: Loss: 0.6233 Acc: 50.0000%\n",
      "\tvalidation 4-82: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 4-83: Loss: 0.7041 Acc: 50.0000%\n",
      "\tvalidation 4-84: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 4-85: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 4-86: Loss: 0.8888 Acc: 50.0000%\n",
      "\tvalidation 4-87: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 4-88: Loss: 0.2272 Acc: 50.0000%\n",
      "\tvalidation 4-89: Loss: 0.2735 Acc: 75.0000%\n",
      "\tvalidation 4-90: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 4-91: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 4-92: Loss: 0.0763 Acc: 75.0000%\n",
      "\tvalidation 4-93: Loss: 0.0885 Acc: 75.0000%\n",
      "\tvalidation 4-94: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 4-95: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 4-96: Loss: 0.0865 Acc: 75.0000%\n",
      "\tvalidation 4-97: Loss: 0.4912 Acc: 75.0000%\n",
      "\tvalidation 4-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 4-99: Loss: 0.1992 Acc: 50.0000%\n",
      "\tvalidation 4-100: Loss: 0.7226 Acc: 75.0000%\n",
      "\tvalidation 4-101: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 4-102: Loss: 0.1162 Acc: 75.0000%\n",
      "\tvalidation 4-103: Loss: 0.1320 Acc: 75.0000%\n",
      "\tvalidation 4-104: Loss: 0.6385 Acc: 50.0000%\n",
      "\tvalidation 4-105: Loss: 0.3078 Acc: 50.0000%\n",
      "\ttrain Loss: 0.2755 Acc: 58.1633%\n",
      "\tvalidation Loss: 0.2856 Acc: 74.7619%\n",
      "网络参数更新\n",
      "Time passed 0h 3m 59s\n",
      "--------------------\n",
      "Epoch [5/40]:\n",
      "\ttrain 5-1: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 5-2: Loss: 0.3611 Acc: 50.0000%\n",
      "\ttrain 5-3: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 5-4: Loss: 0.4406 Acc: 50.0000%\n",
      "\ttrain 5-5: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 5-6: Loss: 0.3132 Acc: 75.0000%\n",
      "\ttrain 5-7: Loss: 0.4490 Acc: 50.0000%\n",
      "\ttrain 5-8: Loss: 0.4165 Acc: 75.0000%\n",
      "\ttrain 5-9: Loss: 0.2740 Acc: 25.0000%\n",
      "\ttrain 5-10: Loss: 0.1441 Acc: 100.0000%\n",
      "\ttrain 5-11: Loss: 0.1158 Acc: 75.0000%\n",
      "\ttrain 5-12: Loss: 0.1538 Acc: 75.0000%\n",
      "\ttrain 5-13: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 5-14: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 5-15: Loss: 0.5432 Acc: 25.0000%\n",
      "\ttrain 5-16: Loss: 0.1455 Acc: 75.0000%\n",
      "\ttrain 5-17: Loss: 0.3592 Acc: 50.0000%\n",
      "\ttrain 5-18: Loss: 0.2756 Acc: 25.0000%\n",
      "\ttrain 5-19: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 5-20: Loss: 0.5136 Acc: 25.0000%\n",
      "\ttrain 5-21: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 5-22: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 5-23: Loss: 0.3364 Acc: 50.0000%\n",
      "\ttrain 5-24: Loss: 0.6443 Acc: 50.0000%\n",
      "\ttrain 5-25: Loss: 0.4463 Acc: 25.0000%\n",
      "\ttrain 5-26: Loss: 0.0865 Acc: 100.0000%\n",
      "\ttrain 5-27: Loss: 0.2198 Acc: 75.0000%\n",
      "\ttrain 5-28: Loss: 0.1643 Acc: 50.0000%\n",
      "\ttrain 5-29: Loss: 0.1581 Acc: 50.0000%\n",
      "\ttrain 5-30: Loss: 0.2832 Acc: 25.0000%\n",
      "\ttrain 5-31: Loss: 0.4104 Acc: 25.0000%\n",
      "\ttrain 5-32: Loss: 0.1872 Acc: 50.0000%\n",
      "\ttrain 5-33: Loss: 0.3734 Acc: 50.0000%\n",
      "\ttrain 5-34: Loss: 0.4230 Acc: 50.0000%\n",
      "\ttrain 5-35: Loss: 0.1628 Acc: 75.0000%\n",
      "\ttrain 5-36: Loss: 0.3253 Acc: 75.0000%\n",
      "\ttrain 5-37: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 5-38: Loss: 0.3340 Acc: 50.0000%\n",
      "\ttrain 5-39: Loss: 0.2370 Acc: 75.0000%\n",
      "\ttrain 5-40: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 5-41: Loss: 0.3128 Acc: 75.0000%\n",
      "\ttrain 5-42: Loss: 0.2084 Acc: 50.0000%\n",
      "\ttrain 5-43: Loss: 0.2275 Acc: 75.0000%\n",
      "\ttrain 5-44: Loss: 0.3163 Acc: 25.0000%\n",
      "\ttrain 5-45: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 5-46: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 5-47: Loss: 0.5281 Acc: 50.0000%\n",
      "\ttrain 5-48: Loss: 0.2679 Acc: 75.0000%\n",
      "\ttrain 5-49: Loss: 0.0868 Acc: 100.0000%\n",
      "\ttrain 5-50: Loss: 0.4601 Acc: 50.0000%\n",
      "\ttrain 5-51: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 5-52: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 5-53: Loss: 0.4996 Acc: 75.0000%\n",
      "\ttrain 5-54: Loss: 0.0748 Acc: 100.0000%\n",
      "\ttrain 5-55: Loss: 0.3724 Acc: 50.0000%\n",
      "\ttrain 5-56: Loss: 0.3597 Acc: 50.0000%\n",
      "\ttrain 5-57: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 5-58: Loss: 0.2996 Acc: 50.0000%\n",
      "\ttrain 5-59: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 5-60: Loss: 0.2044 Acc: 50.0000%\n",
      "\ttrain 5-61: Loss: 0.2799 Acc: 50.0000%\n",
      "\ttrain 5-62: Loss: 0.2635 Acc: 50.0000%\n",
      "\ttrain 5-63: Loss: 0.2986 Acc: 50.0000%\n",
      "\ttrain 5-64: Loss: 0.4313 Acc: 75.0000%\n",
      "\ttrain 5-65: Loss: 0.2814 Acc: 75.0000%\n",
      "\ttrain 5-66: Loss: 0.3644 Acc: 75.0000%\n",
      "\ttrain 5-67: Loss: 0.2217 Acc: 50.0000%\n",
      "\ttrain 5-68: Loss: 0.2273 Acc: 50.0000%\n",
      "\ttrain 5-69: Loss: 0.4409 Acc: 50.0000%\n",
      "\ttrain 5-70: Loss: 0.2859 Acc: 50.0000%\n",
      "\ttrain 5-71: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 5-72: Loss: 0.2140 Acc: 25.0000%\n",
      "\ttrain 5-73: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 5-74: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 5-75: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 5-76: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 5-77: Loss: 0.1860 Acc: 50.0000%\n",
      "\ttrain 5-78: Loss: 0.1847 Acc: 75.0000%\n",
      "\ttrain 5-79: Loss: 0.2934 Acc: 50.0000%\n",
      "\ttrain 5-80: Loss: 0.1864 Acc: 75.0000%\n",
      "\ttrain 5-81: Loss: 0.2151 Acc: 25.0000%\n",
      "\ttrain 5-82: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 5-83: Loss: 0.8284 Acc: 50.0000%\n",
      "\ttrain 5-84: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 5-85: Loss: 0.5025 Acc: 75.0000%\n",
      "\ttrain 5-86: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 5-87: Loss: 0.3719 Acc: 25.0000%\n",
      "\ttrain 5-88: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 5-89: Loss: 0.3173 Acc: 50.0000%\n",
      "\ttrain 5-90: Loss: 0.1211 Acc: 50.0000%\n",
      "\ttrain 5-91: Loss: 0.2055 Acc: 75.0000%\n",
      "\ttrain 5-92: Loss: 0.2149 Acc: 50.0000%\n",
      "\ttrain 5-93: Loss: 0.4465 Acc: 25.0000%\n",
      "\ttrain 5-94: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 5-95: Loss: 0.1529 Acc: 50.0000%\n",
      "\ttrain 5-96: Loss: 0.2298 Acc: 25.0000%\n",
      "\ttrain 5-97: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 5-98: Loss: 0.1298 Acc: 50.0000%\n",
      "\ttrain 5-99: Loss: 0.3598 Acc: 50.0000%\n",
      "\ttrain 5-100: Loss: 0.1994 Acc: 75.0000%\n",
      "\ttrain 5-101: Loss: 0.1724 Acc: 50.0000%\n",
      "\ttrain 5-102: Loss: 0.1924 Acc: 25.0000%\n",
      "\ttrain 5-103: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 5-104: Loss: 0.4665 Acc: 0.0000%\n",
      "\ttrain 5-105: Loss: 0.3790 Acc: 25.0000%\n",
      "\ttrain 5-106: Loss: 0.1970 Acc: 50.0000%\n",
      "\ttrain 5-107: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 5-108: Loss: 0.5145 Acc: 25.0000%\n",
      "\ttrain 5-109: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 5-110: Loss: 0.0764 Acc: 100.0000%\n",
      "\ttrain 5-111: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 5-112: Loss: 0.0508 Acc: 75.0000%\n",
      "\ttrain 5-113: Loss: 0.3777 Acc: 75.0000%\n",
      "\ttrain 5-114: Loss: 0.6575 Acc: 25.0000%\n",
      "\ttrain 5-115: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 5-116: Loss: 0.3948 Acc: 50.0000%\n",
      "\ttrain 5-117: Loss: 0.5359 Acc: 50.0000%\n",
      "\ttrain 5-118: Loss: 0.1158 Acc: 75.0000%\n",
      "\ttrain 5-119: Loss: 0.2534 Acc: 50.0000%\n",
      "\ttrain 5-120: Loss: 0.1657 Acc: 50.0000%\n",
      "\ttrain 5-121: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 5-122: Loss: 0.5263 Acc: 50.0000%\n",
      "\ttrain 5-123: Loss: 0.7827 Acc: 25.0000%\n",
      "\ttrain 5-124: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 5-125: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 5-126: Loss: 0.2831 Acc: 50.0000%\n",
      "\ttrain 5-127: Loss: 0.3296 Acc: 75.0000%\n",
      "\ttrain 5-128: Loss: 0.1237 Acc: 100.0000%\n",
      "\ttrain 5-129: Loss: 0.5653 Acc: 0.0000%\n",
      "\ttrain 5-130: Loss: 0.1940 Acc: 50.0000%\n",
      "\ttrain 5-131: Loss: 0.2962 Acc: 50.0000%\n",
      "\ttrain 5-132: Loss: 0.4280 Acc: 50.0000%\n",
      "\ttrain 5-133: Loss: 0.2457 Acc: 25.0000%\n",
      "\ttrain 5-134: Loss: 0.1750 Acc: 50.0000%\n",
      "\ttrain 5-135: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 5-136: Loss: 0.1416 Acc: 50.0000%\n",
      "\ttrain 5-137: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 5-138: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 5-139: Loss: 0.5647 Acc: 25.0000%\n",
      "\ttrain 5-140: Loss: 0.2741 Acc: 50.0000%\n",
      "\ttrain 5-141: Loss: 0.1740 Acc: 75.0000%\n",
      "\ttrain 5-142: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 5-143: Loss: 0.3043 Acc: 50.0000%\n",
      "\ttrain 5-144: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 5-145: Loss: 0.4424 Acc: 50.0000%\n",
      "\ttrain 5-146: Loss: 0.2721 Acc: 75.0000%\n",
      "\ttrain 5-147: Loss: 0.7027 Acc: 25.0000%\n",
      "\ttrain 5-148: Loss: 0.3030 Acc: 75.0000%\n",
      "\ttrain 5-149: Loss: 0.3561 Acc: 50.0000%\n",
      "\ttrain 5-150: Loss: 0.2145 Acc: 50.0000%\n",
      "\ttrain 5-151: Loss: 0.3501 Acc: 25.0000%\n",
      "\ttrain 5-152: Loss: 0.3763 Acc: 0.0000%\n",
      "\ttrain 5-153: Loss: 0.1302 Acc: 75.0000%\n",
      "\ttrain 5-154: Loss: 0.3560 Acc: 50.0000%\n",
      "\ttrain 5-155: Loss: 0.2107 Acc: 50.0000%\n",
      "\ttrain 5-156: Loss: 0.6221 Acc: 25.0000%\n",
      "\ttrain 5-157: Loss: 0.6063 Acc: 50.0000%\n",
      "\ttrain 5-158: Loss: 0.3646 Acc: 50.0000%\n",
      "\ttrain 5-159: Loss: 0.2588 Acc: 50.0000%\n",
      "\ttrain 5-160: Loss: 0.5235 Acc: 25.0000%\n",
      "\ttrain 5-161: Loss: 0.1104 Acc: 100.0000%\n",
      "\ttrain 5-162: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 5-163: Loss: 0.1899 Acc: 25.0000%\n",
      "\ttrain 5-164: Loss: 0.0477 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 5-165: Loss: 0.2823 Acc: 50.0000%\n",
      "\ttrain 5-166: Loss: 0.2432 Acc: 75.0000%\n",
      "\ttrain 5-167: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 5-168: Loss: 0.1584 Acc: 75.0000%\n",
      "\ttrain 5-169: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 5-170: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 5-171: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 5-172: Loss: 0.4760 Acc: 0.0000%\n",
      "\ttrain 5-173: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 5-174: Loss: 0.2765 Acc: 50.0000%\n",
      "\ttrain 5-175: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 5-176: Loss: 0.2319 Acc: 75.0000%\n",
      "\ttrain 5-177: Loss: 0.2802 Acc: 50.0000%\n",
      "\ttrain 5-178: Loss: 0.2472 Acc: 50.0000%\n",
      "\ttrain 5-179: Loss: 0.1802 Acc: 50.0000%\n",
      "\ttrain 5-180: Loss: 0.1455 Acc: 50.0000%\n",
      "\ttrain 5-181: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 5-182: Loss: 0.3879 Acc: 25.0000%\n",
      "\ttrain 5-183: Loss: 0.2498 Acc: 50.0000%\n",
      "\ttrain 5-184: Loss: 0.5215 Acc: 25.0000%\n",
      "\ttrain 5-185: Loss: 0.3136 Acc: 50.0000%\n",
      "\ttrain 5-186: Loss: 0.2324 Acc: 50.0000%\n",
      "\ttrain 5-187: Loss: 0.5224 Acc: 25.0000%\n",
      "\ttrain 5-188: Loss: 0.2330 Acc: 25.0000%\n",
      "\ttrain 5-189: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 5-190: Loss: 0.1384 Acc: 50.0000%\n",
      "\ttrain 5-191: Loss: 0.6497 Acc: 25.0000%\n",
      "\ttrain 5-192: Loss: 0.3674 Acc: 25.0000%\n",
      "\ttrain 5-193: Loss: 0.2848 Acc: 50.0000%\n",
      "\ttrain 5-194: Loss: 0.4385 Acc: 50.0000%\n",
      "\ttrain 5-195: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 5-196: Loss: 0.2583 Acc: 50.0000%\n",
      "\ttrain 5-197: Loss: 0.4355 Acc: 25.0000%\n",
      "\ttrain 5-198: Loss: 0.1994 Acc: 50.0000%\n",
      "\ttrain 5-199: Loss: 0.2408 Acc: 50.0000%\n",
      "\ttrain 5-200: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 5-201: Loss: 0.2987 Acc: 50.0000%\n",
      "\ttrain 5-202: Loss: 0.2771 Acc: 75.0000%\n",
      "\ttrain 5-203: Loss: 0.5101 Acc: 0.0000%\n",
      "\ttrain 5-204: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 5-205: Loss: 0.6903 Acc: 25.0000%\n",
      "\ttrain 5-206: Loss: 0.4020 Acc: 25.0000%\n",
      "\ttrain 5-207: Loss: 0.5102 Acc: 25.0000%\n",
      "\ttrain 5-208: Loss: 0.3578 Acc: 0.0000%\n",
      "\ttrain 5-209: Loss: 0.4052 Acc: 75.0000%\n",
      "\ttrain 5-210: Loss: 0.2088 Acc: 50.0000%\n",
      "\ttrain 5-211: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 5-212: Loss: 0.2856 Acc: 75.0000%\n",
      "\ttrain 5-213: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 5-214: Loss: 0.4850 Acc: 50.0000%\n",
      "\ttrain 5-215: Loss: 0.3931 Acc: 75.0000%\n",
      "\ttrain 5-216: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 5-217: Loss: 0.4734 Acc: 50.0000%\n",
      "\ttrain 5-218: Loss: 0.2385 Acc: 75.0000%\n",
      "\ttrain 5-219: Loss: 0.0820 Acc: 100.0000%\n",
      "\ttrain 5-220: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 5-221: Loss: 0.0755 Acc: 100.0000%\n",
      "\ttrain 5-222: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 5-223: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 5-224: Loss: 0.2359 Acc: 75.0000%\n",
      "\ttrain 5-225: Loss: 0.2797 Acc: 25.0000%\n",
      "\ttrain 5-226: Loss: 0.3350 Acc: 25.0000%\n",
      "\ttrain 5-227: Loss: 0.3947 Acc: 50.0000%\n",
      "\ttrain 5-228: Loss: 0.3864 Acc: 0.0000%\n",
      "\ttrain 5-229: Loss: 0.4467 Acc: 25.0000%\n",
      "\ttrain 5-230: Loss: 0.3736 Acc: 50.0000%\n",
      "\ttrain 5-231: Loss: 0.1863 Acc: 75.0000%\n",
      "\ttrain 5-232: Loss: 0.2126 Acc: 75.0000%\n",
      "\ttrain 5-233: Loss: 0.4766 Acc: 50.0000%\n",
      "\ttrain 5-234: Loss: 0.4809 Acc: 25.0000%\n",
      "\ttrain 5-235: Loss: 0.4167 Acc: 0.0000%\n",
      "\ttrain 5-236: Loss: 0.1788 Acc: 75.0000%\n",
      "\ttrain 5-237: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 5-238: Loss: 0.2062 Acc: 50.0000%\n",
      "\ttrain 5-239: Loss: 0.3620 Acc: 50.0000%\n",
      "\ttrain 5-240: Loss: 0.1542 Acc: 50.0000%\n",
      "\ttrain 5-241: Loss: 0.3750 Acc: 50.0000%\n",
      "\ttrain 5-242: Loss: 0.3220 Acc: 75.0000%\n",
      "\ttrain 5-243: Loss: 0.3002 Acc: 50.0000%\n",
      "\ttrain 5-244: Loss: 0.4230 Acc: 50.0000%\n",
      "\ttrain 5-245: Loss: 0.2836 Acc: 75.0000%\n",
      "\tvalidation 5-1: Loss: 0.3087 Acc: 25.0000%\n",
      "\tvalidation 5-2: Loss: 0.0767 Acc: 100.0000%\n",
      "\tvalidation 5-3: Loss: 0.2253 Acc: 75.0000%\n",
      "\tvalidation 5-4: Loss: 0.0955 Acc: 75.0000%\n",
      "\tvalidation 5-5: Loss: 0.0605 Acc: 75.0000%\n",
      "\tvalidation 5-6: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 5-7: Loss: 0.1371 Acc: 75.0000%\n",
      "\tvalidation 5-8: Loss: 0.3878 Acc: 50.0000%\n",
      "\tvalidation 5-9: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 5-10: Loss: 0.2791 Acc: 75.0000%\n",
      "\tvalidation 5-11: Loss: 0.7547 Acc: 50.0000%\n",
      "\tvalidation 5-12: Loss: 0.2034 Acc: 75.0000%\n",
      "\tvalidation 5-13: Loss: 0.0673 Acc: 100.0000%\n",
      "\tvalidation 5-14: Loss: 0.0507 Acc: 100.0000%\n",
      "\tvalidation 5-15: Loss: 0.0797 Acc: 75.0000%\n",
      "\tvalidation 5-16: Loss: 0.5180 Acc: 50.0000%\n",
      "\tvalidation 5-17: Loss: 0.1015 Acc: 75.0000%\n",
      "\tvalidation 5-18: Loss: 0.1323 Acc: 50.0000%\n",
      "\tvalidation 5-19: Loss: 2.7560 Acc: 75.0000%\n",
      "\tvalidation 5-20: Loss: 0.1552 Acc: 50.0000%\n",
      "\tvalidation 5-21: Loss: 0.0618 Acc: 100.0000%\n",
      "\tvalidation 5-22: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 5-23: Loss: 0.0679 Acc: 100.0000%\n",
      "\tvalidation 5-24: Loss: 1.8899 Acc: 75.0000%\n",
      "\tvalidation 5-25: Loss: 0.0948 Acc: 100.0000%\n",
      "\tvalidation 5-26: Loss: 0.0740 Acc: 75.0000%\n",
      "\tvalidation 5-27: Loss: 0.0755 Acc: 100.0000%\n",
      "\tvalidation 5-28: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 5-29: Loss: 0.1084 Acc: 75.0000%\n",
      "\tvalidation 5-30: Loss: 0.0618 Acc: 100.0000%\n",
      "\tvalidation 5-31: Loss: 0.1686 Acc: 50.0000%\n",
      "\tvalidation 5-32: Loss: 0.2705 Acc: 75.0000%\n",
      "\tvalidation 5-33: Loss: 0.0789 Acc: 100.0000%\n",
      "\tvalidation 5-34: Loss: 0.1601 Acc: 50.0000%\n",
      "\tvalidation 5-35: Loss: 0.0569 Acc: 100.0000%\n",
      "\tvalidation 5-36: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 5-37: Loss: 0.1924 Acc: 75.0000%\n",
      "\tvalidation 5-38: Loss: 0.1208 Acc: 75.0000%\n",
      "\tvalidation 5-39: Loss: 0.3925 Acc: 75.0000%\n",
      "\tvalidation 5-40: Loss: 0.0716 Acc: 75.0000%\n",
      "\tvalidation 5-41: Loss: 0.0569 Acc: 75.0000%\n",
      "\tvalidation 5-42: Loss: 0.6655 Acc: 50.0000%\n",
      "\tvalidation 5-43: Loss: 0.0630 Acc: 75.0000%\n",
      "\tvalidation 5-44: Loss: 0.1664 Acc: 50.0000%\n",
      "\tvalidation 5-45: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 5-46: Loss: 0.1134 Acc: 75.0000%\n",
      "\tvalidation 5-47: Loss: 0.1025 Acc: 75.0000%\n",
      "\tvalidation 5-48: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 5-49: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 5-50: Loss: 0.0850 Acc: 100.0000%\n",
      "\tvalidation 5-51: Loss: 0.2341 Acc: 50.0000%\n",
      "\tvalidation 5-52: Loss: 0.1379 Acc: 75.0000%\n",
      "\tvalidation 5-53: Loss: 0.0470 Acc: 100.0000%\n",
      "\tvalidation 5-54: Loss: 0.0599 Acc: 75.0000%\n",
      "\tvalidation 5-55: Loss: 0.0677 Acc: 100.0000%\n",
      "\tvalidation 5-56: Loss: 0.1036 Acc: 75.0000%\n",
      "\tvalidation 5-57: Loss: 0.1256 Acc: 100.0000%\n",
      "\tvalidation 5-58: Loss: 0.1430 Acc: 75.0000%\n",
      "\tvalidation 5-59: Loss: 0.0456 Acc: 100.0000%\n",
      "\tvalidation 5-60: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 5-61: Loss: 0.1643 Acc: 75.0000%\n",
      "\tvalidation 5-62: Loss: 0.6512 Acc: 25.0000%\n",
      "\tvalidation 5-63: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 5-64: Loss: 0.1181 Acc: 75.0000%\n",
      "\tvalidation 5-65: Loss: 0.0626 Acc: 75.0000%\n",
      "\tvalidation 5-66: Loss: 0.2506 Acc: 50.0000%\n",
      "\tvalidation 5-67: Loss: 0.1194 Acc: 75.0000%\n",
      "\tvalidation 5-68: Loss: 0.0882 Acc: 100.0000%\n",
      "\tvalidation 5-69: Loss: 0.1635 Acc: 50.0000%\n",
      "\tvalidation 5-70: Loss: 0.1126 Acc: 75.0000%\n",
      "\tvalidation 5-71: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 5-72: Loss: 0.2031 Acc: 25.0000%\n",
      "\tvalidation 5-73: Loss: 0.0966 Acc: 75.0000%\n",
      "\tvalidation 5-74: Loss: 0.3265 Acc: 75.0000%\n",
      "\tvalidation 5-75: Loss: 0.2850 Acc: 75.0000%\n",
      "\tvalidation 5-76: Loss: 0.1102 Acc: 50.0000%\n",
      "\tvalidation 5-77: Loss: 0.2443 Acc: 50.0000%\n",
      "\tvalidation 5-78: Loss: 0.0532 Acc: 100.0000%\n",
      "\tvalidation 5-79: Loss: 0.7105 Acc: 75.0000%\n",
      "\tvalidation 5-80: Loss: 0.1651 Acc: 75.0000%\n",
      "\tvalidation 5-81: Loss: 0.1330 Acc: 75.0000%\n",
      "\tvalidation 5-82: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 5-83: Loss: 0.1918 Acc: 50.0000%\n",
      "\tvalidation 5-84: Loss: 3.1645 Acc: 50.0000%\n",
      "\tvalidation 5-85: Loss: 0.1228 Acc: 50.0000%\n",
      "\tvalidation 5-86: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 5-87: Loss: 0.0636 Acc: 75.0000%\n",
      "\tvalidation 5-88: Loss: 0.2597 Acc: 50.0000%\n",
      "\tvalidation 5-89: Loss: 0.0776 Acc: 100.0000%\n",
      "\tvalidation 5-90: Loss: 0.1498 Acc: 50.0000%\n",
      "\tvalidation 5-91: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 5-92: Loss: 0.2610 Acc: 25.0000%\n",
      "\tvalidation 5-93: Loss: 0.0859 Acc: 75.0000%\n",
      "\tvalidation 5-94: Loss: 0.4545 Acc: 75.0000%\n",
      "\tvalidation 5-95: Loss: 0.3867 Acc: 75.0000%\n",
      "\tvalidation 5-96: Loss: 0.1089 Acc: 50.0000%\n",
      "\tvalidation 5-97: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 5-98: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 5-99: Loss: 0.1358 Acc: 75.0000%\n",
      "\tvalidation 5-100: Loss: 0.4906 Acc: 75.0000%\n",
      "\tvalidation 5-101: Loss: 0.0601 Acc: 100.0000%\n",
      "\tvalidation 5-102: Loss: 0.1220 Acc: 75.0000%\n",
      "\tvalidation 5-103: Loss: 0.1284 Acc: 75.0000%\n",
      "\tvalidation 5-104: Loss: 0.9058 Acc: 25.0000%\n",
      "\tvalidation 5-105: Loss: 0.4455 Acc: 25.0000%\n",
      "\ttrain Loss: 0.2624 Acc: 58.8776%\n",
      "\tvalidation Loss: 0.2362 Acc: 74.7619%\n",
      "Time passed 0h 4m 59s\n",
      "--------------------\n",
      "Epoch [6/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-1: Loss: 0.2106 Acc: 75.0000%\n",
      "\ttrain 6-2: Loss: 0.2137 Acc: 25.0000%\n",
      "\ttrain 6-3: Loss: 0.2939 Acc: 50.0000%\n",
      "\ttrain 6-4: Loss: 0.4173 Acc: 25.0000%\n",
      "\ttrain 6-5: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 6-6: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 6-7: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 6-8: Loss: 0.3861 Acc: 75.0000%\n",
      "\ttrain 6-9: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 6-10: Loss: 0.0693 Acc: 75.0000%\n",
      "\ttrain 6-11: Loss: 0.5297 Acc: 25.0000%\n",
      "\ttrain 6-12: Loss: 0.4198 Acc: 50.0000%\n",
      "\ttrain 6-13: Loss: 0.2261 Acc: 50.0000%\n",
      "\ttrain 6-14: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 6-15: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 6-16: Loss: 0.2144 Acc: 50.0000%\n",
      "\ttrain 6-17: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 6-18: Loss: 0.4902 Acc: 25.0000%\n",
      "\ttrain 6-19: Loss: 0.3361 Acc: 50.0000%\n",
      "\ttrain 6-20: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 6-21: Loss: 0.2070 Acc: 75.0000%\n",
      "\ttrain 6-22: Loss: 0.2568 Acc: 50.0000%\n",
      "\ttrain 6-23: Loss: 0.0899 Acc: 100.0000%\n",
      "\ttrain 6-24: Loss: 0.1395 Acc: 50.0000%\n",
      "\ttrain 6-25: Loss: 0.1074 Acc: 50.0000%\n",
      "\ttrain 6-26: Loss: 0.1905 Acc: 75.0000%\n",
      "\ttrain 6-27: Loss: 0.1960 Acc: 50.0000%\n",
      "\ttrain 6-28: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 6-29: Loss: 0.6507 Acc: 50.0000%\n",
      "\ttrain 6-30: Loss: 0.2135 Acc: 75.0000%\n",
      "\ttrain 6-31: Loss: 0.2263 Acc: 50.0000%\n",
      "\ttrain 6-32: Loss: 0.2097 Acc: 50.0000%\n",
      "\ttrain 6-33: Loss: 0.2809 Acc: 50.0000%\n",
      "\ttrain 6-34: Loss: 0.2483 Acc: 50.0000%\n",
      "\ttrain 6-35: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 6-36: Loss: 0.0786 Acc: 100.0000%\n",
      "\ttrain 6-37: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 6-38: Loss: 0.2405 Acc: 75.0000%\n",
      "\ttrain 6-39: Loss: 0.3626 Acc: 50.0000%\n",
      "\ttrain 6-40: Loss: 0.4948 Acc: 50.0000%\n",
      "\ttrain 6-41: Loss: 0.4906 Acc: 50.0000%\n",
      "\ttrain 6-42: Loss: 0.2635 Acc: 50.0000%\n",
      "\ttrain 6-43: Loss: 0.3677 Acc: 50.0000%\n",
      "\ttrain 6-44: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 6-45: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 6-46: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 6-47: Loss: 0.4562 Acc: 50.0000%\n",
      "\ttrain 6-48: Loss: 0.4587 Acc: 50.0000%\n",
      "\ttrain 6-49: Loss: 0.2495 Acc: 50.0000%\n",
      "\ttrain 6-50: Loss: 0.2758 Acc: 25.0000%\n",
      "\ttrain 6-51: Loss: 0.5107 Acc: 25.0000%\n",
      "\ttrain 6-52: Loss: 0.4613 Acc: 25.0000%\n",
      "\ttrain 6-53: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 6-54: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 6-55: Loss: 0.2806 Acc: 75.0000%\n",
      "\ttrain 6-56: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 6-57: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 6-58: Loss: 0.3478 Acc: 50.0000%\n",
      "\ttrain 6-59: Loss: 0.6068 Acc: 50.0000%\n",
      "\ttrain 6-60: Loss: 0.4168 Acc: 50.0000%\n",
      "\ttrain 6-61: Loss: 0.1584 Acc: 75.0000%\n",
      "\ttrain 6-62: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 6-63: Loss: 0.2620 Acc: 50.0000%\n",
      "\ttrain 6-64: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 6-65: Loss: 0.2786 Acc: 50.0000%\n",
      "\ttrain 6-66: Loss: 0.2013 Acc: 75.0000%\n",
      "\ttrain 6-67: Loss: 0.1927 Acc: 50.0000%\n",
      "\ttrain 6-68: Loss: 0.2711 Acc: 50.0000%\n",
      "\ttrain 6-69: Loss: 0.0458 Acc: 75.0000%\n",
      "\ttrain 6-70: Loss: 0.1294 Acc: 100.0000%\n",
      "\ttrain 6-71: Loss: 0.2620 Acc: 25.0000%\n",
      "\ttrain 6-72: Loss: 0.5327 Acc: 50.0000%\n",
      "\ttrain 6-73: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 6-74: Loss: 0.2504 Acc: 75.0000%\n",
      "\ttrain 6-75: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 6-76: Loss: 0.1856 Acc: 75.0000%\n",
      "\ttrain 6-77: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 6-78: Loss: 0.4520 Acc: 50.0000%\n",
      "\ttrain 6-79: Loss: 0.2931 Acc: 50.0000%\n",
      "\ttrain 6-80: Loss: 0.2716 Acc: 50.0000%\n",
      "\ttrain 6-81: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 6-82: Loss: 0.2435 Acc: 50.0000%\n",
      "\ttrain 6-83: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 6-84: Loss: 0.1046 Acc: 100.0000%\n",
      "\ttrain 6-85: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 6-86: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 6-87: Loss: 0.1973 Acc: 50.0000%\n",
      "\ttrain 6-88: Loss: 0.1666 Acc: 75.0000%\n",
      "\ttrain 6-89: Loss: 0.3763 Acc: 75.0000%\n",
      "\ttrain 6-90: Loss: 0.2922 Acc: 50.0000%\n",
      "\ttrain 6-91: Loss: 0.3574 Acc: 50.0000%\n",
      "\ttrain 6-92: Loss: 0.3225 Acc: 75.0000%\n",
      "\ttrain 6-93: Loss: 0.2783 Acc: 75.0000%\n",
      "\ttrain 6-94: Loss: 0.1154 Acc: 100.0000%\n",
      "\ttrain 6-95: Loss: 0.2831 Acc: 50.0000%\n",
      "\ttrain 6-96: Loss: 0.5878 Acc: 25.0000%\n",
      "\ttrain 6-97: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 6-98: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 6-99: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 6-100: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 6-101: Loss: 0.5314 Acc: 0.0000%\n",
      "\ttrain 6-102: Loss: 0.2889 Acc: 50.0000%\n",
      "\ttrain 6-103: Loss: 0.5360 Acc: 50.0000%\n",
      "\ttrain 6-104: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 6-105: Loss: 0.7614 Acc: 0.0000%\n",
      "\ttrain 6-106: Loss: 0.2838 Acc: 50.0000%\n",
      "\ttrain 6-107: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 6-108: Loss: 0.2611 Acc: 50.0000%\n",
      "\ttrain 6-109: Loss: 0.0771 Acc: 100.0000%\n",
      "\ttrain 6-110: Loss: 0.5131 Acc: 50.0000%\n",
      "\ttrain 6-111: Loss: 0.3454 Acc: 75.0000%\n",
      "\ttrain 6-112: Loss: 0.2390 Acc: 75.0000%\n",
      "\ttrain 6-113: Loss: 0.3495 Acc: 50.0000%\n",
      "\ttrain 6-114: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 6-115: Loss: 0.3384 Acc: 25.0000%\n",
      "\ttrain 6-116: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 6-117: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 6-118: Loss: 0.5665 Acc: 50.0000%\n",
      "\ttrain 6-119: Loss: 0.6220 Acc: 50.0000%\n",
      "\ttrain 6-120: Loss: 0.7418 Acc: 25.0000%\n",
      "\ttrain 6-121: Loss: 0.7563 Acc: 0.0000%\n",
      "\ttrain 6-122: Loss: 0.2882 Acc: 50.0000%\n",
      "\ttrain 6-123: Loss: 0.4307 Acc: 50.0000%\n",
      "\ttrain 6-124: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 6-125: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 6-126: Loss: 0.4203 Acc: 50.0000%\n",
      "\ttrain 6-127: Loss: 0.1494 Acc: 50.0000%\n",
      "\ttrain 6-128: Loss: 0.4073 Acc: 25.0000%\n",
      "\ttrain 6-129: Loss: 0.1922 Acc: 50.0000%\n",
      "\ttrain 6-130: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 6-131: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 6-132: Loss: 0.3258 Acc: 75.0000%\n",
      "\ttrain 6-133: Loss: 0.5758 Acc: 0.0000%\n",
      "\ttrain 6-134: Loss: 0.1258 Acc: 100.0000%\n",
      "\ttrain 6-135: Loss: 0.1754 Acc: 75.0000%\n",
      "\ttrain 6-136: Loss: 0.1048 Acc: 100.0000%\n",
      "\ttrain 6-137: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 6-138: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 6-139: Loss: 0.0829 Acc: 100.0000%\n",
      "\ttrain 6-140: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 6-141: Loss: 0.2158 Acc: 50.0000%\n",
      "\ttrain 6-142: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 6-143: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 6-144: Loss: 0.1380 Acc: 75.0000%\n",
      "\ttrain 6-145: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 6-146: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 6-147: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 6-148: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 6-149: Loss: 0.0744 Acc: 100.0000%\n",
      "\ttrain 6-150: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 6-151: Loss: 0.1663 Acc: 50.0000%\n",
      "\ttrain 6-152: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 6-153: Loss: 0.1475 Acc: 100.0000%\n",
      "\ttrain 6-154: Loss: 0.3024 Acc: 75.0000%\n",
      "\ttrain 6-155: Loss: 0.2810 Acc: 50.0000%\n",
      "\ttrain 6-156: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 6-157: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 6-158: Loss: 0.2817 Acc: 25.0000%\n",
      "\ttrain 6-159: Loss: 0.2338 Acc: 75.0000%\n",
      "\ttrain 6-160: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 6-161: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 6-162: Loss: 0.2375 Acc: 50.0000%\n",
      "\ttrain 6-163: Loss: 0.1778 Acc: 75.0000%\n",
      "\ttrain 6-164: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 6-165: Loss: 0.4474 Acc: 0.0000%\n",
      "\ttrain 6-166: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 6-167: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 6-168: Loss: 0.3558 Acc: 50.0000%\n",
      "\ttrain 6-169: Loss: 0.1995 Acc: 50.0000%\n",
      "\ttrain 6-170: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 6-171: Loss: 0.3108 Acc: 75.0000%\n",
      "\ttrain 6-172: Loss: 0.3348 Acc: 0.0000%\n",
      "\ttrain 6-173: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 6-174: Loss: 0.5033 Acc: 25.0000%\n",
      "\ttrain 6-175: Loss: 0.1719 Acc: 75.0000%\n",
      "\ttrain 6-176: Loss: 0.2416 Acc: 50.0000%\n",
      "\ttrain 6-177: Loss: 0.3193 Acc: 50.0000%\n",
      "\ttrain 6-178: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 6-179: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 6-180: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 6-181: Loss: 0.0728 Acc: 100.0000%\n",
      "\ttrain 6-182: Loss: 0.6480 Acc: 50.0000%\n",
      "\ttrain 6-183: Loss: 0.2700 Acc: 50.0000%\n",
      "\ttrain 6-184: Loss: 0.4189 Acc: 25.0000%\n",
      "\ttrain 6-185: Loss: 0.3514 Acc: 25.0000%\n",
      "\ttrain 6-186: Loss: 0.2473 Acc: 25.0000%\n",
      "\ttrain 6-187: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 6-188: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 6-189: Loss: 0.2317 Acc: 50.0000%\n",
      "\ttrain 6-190: Loss: 0.3866 Acc: 50.0000%\n",
      "\ttrain 6-191: Loss: 0.2639 Acc: 50.0000%\n",
      "\ttrain 6-192: Loss: 0.3061 Acc: 50.0000%\n",
      "\ttrain 6-193: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 6-194: Loss: 0.1241 Acc: 75.0000%\n",
      "\ttrain 6-195: Loss: 0.2060 Acc: 50.0000%\n",
      "\ttrain 6-196: Loss: 0.1568 Acc: 50.0000%\n",
      "\ttrain 6-197: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 6-198: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 6-199: Loss: 0.2061 Acc: 75.0000%\n",
      "\ttrain 6-200: Loss: 0.2821 Acc: 50.0000%\n",
      "\ttrain 6-201: Loss: 0.3262 Acc: 75.0000%\n",
      "\ttrain 6-202: Loss: 0.3313 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-203: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 6-204: Loss: 0.3306 Acc: 25.0000%\n",
      "\ttrain 6-205: Loss: 0.2886 Acc: 50.0000%\n",
      "\ttrain 6-206: Loss: 0.4021 Acc: 25.0000%\n",
      "\ttrain 6-207: Loss: 0.3134 Acc: 50.0000%\n",
      "\ttrain 6-208: Loss: 0.1424 Acc: 50.0000%\n",
      "\ttrain 6-209: Loss: 0.1846 Acc: 50.0000%\n",
      "\ttrain 6-210: Loss: 0.2935 Acc: 50.0000%\n",
      "\ttrain 6-211: Loss: 0.2103 Acc: 75.0000%\n",
      "\ttrain 6-212: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 6-213: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 6-214: Loss: 0.0992 Acc: 100.0000%\n",
      "\ttrain 6-215: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 6-216: Loss: 0.0952 Acc: 100.0000%\n",
      "\ttrain 6-217: Loss: 0.4489 Acc: 50.0000%\n",
      "\ttrain 6-218: Loss: 0.2899 Acc: 50.0000%\n",
      "\ttrain 6-219: Loss: 0.1052 Acc: 50.0000%\n",
      "\ttrain 6-220: Loss: 0.2490 Acc: 25.0000%\n",
      "\ttrain 6-221: Loss: 0.1570 Acc: 50.0000%\n",
      "\ttrain 6-222: Loss: 0.1740 Acc: 50.0000%\n",
      "\ttrain 6-223: Loss: 0.3400 Acc: 75.0000%\n",
      "\ttrain 6-224: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 6-225: Loss: 0.1436 Acc: 75.0000%\n",
      "\ttrain 6-226: Loss: 0.2087 Acc: 25.0000%\n",
      "\ttrain 6-227: Loss: 0.4424 Acc: 25.0000%\n",
      "\ttrain 6-228: Loss: 0.1828 Acc: 25.0000%\n",
      "\ttrain 6-229: Loss: 0.1819 Acc: 75.0000%\n",
      "\ttrain 6-230: Loss: 0.4004 Acc: 75.0000%\n",
      "\ttrain 6-231: Loss: 0.2383 Acc: 75.0000%\n",
      "\ttrain 6-232: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 6-233: Loss: 0.2051 Acc: 50.0000%\n",
      "\ttrain 6-234: Loss: 0.2266 Acc: 50.0000%\n",
      "\ttrain 6-235: Loss: 0.4059 Acc: 25.0000%\n",
      "\ttrain 6-236: Loss: 0.2267 Acc: 50.0000%\n",
      "\ttrain 6-237: Loss: 0.4212 Acc: 25.0000%\n",
      "\ttrain 6-238: Loss: 0.1828 Acc: 50.0000%\n",
      "\ttrain 6-239: Loss: 0.4262 Acc: 50.0000%\n",
      "\ttrain 6-240: Loss: 0.2011 Acc: 75.0000%\n",
      "\ttrain 6-241: Loss: 0.2912 Acc: 50.0000%\n",
      "\ttrain 6-242: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 6-243: Loss: 0.2426 Acc: 75.0000%\n",
      "\ttrain 6-244: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 6-245: Loss: 0.1183 Acc: 75.0000%\n",
      "\tvalidation 6-1: Loss: 0.2583 Acc: 50.0000%\n",
      "\tvalidation 6-2: Loss: 0.1606 Acc: 75.0000%\n",
      "\tvalidation 6-3: Loss: 0.1115 Acc: 75.0000%\n",
      "\tvalidation 6-4: Loss: 0.1612 Acc: 75.0000%\n",
      "\tvalidation 6-5: Loss: 0.1164 Acc: 75.0000%\n",
      "\tvalidation 6-6: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 6-7: Loss: 0.1406 Acc: 75.0000%\n",
      "\tvalidation 6-8: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 6-9: Loss: 0.1423 Acc: 75.0000%\n",
      "\tvalidation 6-10: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 6-11: Loss: 0.1350 Acc: 75.0000%\n",
      "\tvalidation 6-12: Loss: 0.2136 Acc: 50.0000%\n",
      "\tvalidation 6-13: Loss: 0.1405 Acc: 75.0000%\n",
      "\tvalidation 6-14: Loss: 0.2140 Acc: 50.0000%\n",
      "\tvalidation 6-15: Loss: 0.1298 Acc: 75.0000%\n",
      "\tvalidation 6-16: Loss: 0.1638 Acc: 75.0000%\n",
      "\tvalidation 6-17: Loss: 0.2246 Acc: 50.0000%\n",
      "\tvalidation 6-18: Loss: 0.1453 Acc: 75.0000%\n",
      "\tvalidation 6-19: Loss: 0.1413 Acc: 75.0000%\n",
      "\tvalidation 6-20: Loss: 0.1283 Acc: 75.0000%\n",
      "\tvalidation 6-21: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 6-22: Loss: 0.2441 Acc: 50.0000%\n",
      "\tvalidation 6-23: Loss: 0.2467 Acc: 50.0000%\n",
      "\tvalidation 6-24: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 6-25: Loss: 0.1756 Acc: 75.0000%\n",
      "\tvalidation 6-26: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 6-27: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 6-28: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 6-29: Loss: 0.1446 Acc: 75.0000%\n",
      "\tvalidation 6-30: Loss: 0.1499 Acc: 75.0000%\n",
      "\tvalidation 6-31: Loss: 0.2152 Acc: 50.0000%\n",
      "\tvalidation 6-32: Loss: 0.1129 Acc: 75.0000%\n",
      "\tvalidation 6-33: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 6-34: Loss: 0.1330 Acc: 75.0000%\n",
      "\tvalidation 6-35: Loss: 0.1158 Acc: 75.0000%\n",
      "\tvalidation 6-36: Loss: 0.1045 Acc: 75.0000%\n",
      "\tvalidation 6-37: Loss: 0.1143 Acc: 75.0000%\n",
      "\tvalidation 6-38: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 6-39: Loss: 0.1439 Acc: 75.0000%\n",
      "\tvalidation 6-40: Loss: 0.1202 Acc: 75.0000%\n",
      "\tvalidation 6-41: Loss: 0.0303 Acc: 100.0000%\n",
      "\tvalidation 6-42: Loss: 0.2782 Acc: 50.0000%\n",
      "\tvalidation 6-43: Loss: 0.2328 Acc: 50.0000%\n",
      "\tvalidation 6-44: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 6-45: Loss: 0.1431 Acc: 75.0000%\n",
      "\tvalidation 6-46: Loss: 0.4902 Acc: 25.0000%\n",
      "\tvalidation 6-47: Loss: 0.1573 Acc: 75.0000%\n",
      "\tvalidation 6-48: Loss: 0.1183 Acc: 75.0000%\n",
      "\tvalidation 6-49: Loss: 0.2158 Acc: 50.0000%\n",
      "\tvalidation 6-50: Loss: 0.1529 Acc: 75.0000%\n",
      "\tvalidation 6-51: Loss: 0.3775 Acc: 50.0000%\n",
      "\tvalidation 6-52: Loss: 0.1240 Acc: 75.0000%\n",
      "\tvalidation 6-53: Loss: 0.1453 Acc: 75.0000%\n",
      "\tvalidation 6-54: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 6-55: Loss: 0.3634 Acc: 25.0000%\n",
      "\tvalidation 6-56: Loss: 0.0881 Acc: 75.0000%\n",
      "\tvalidation 6-57: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 6-58: Loss: 0.1199 Acc: 75.0000%\n",
      "\tvalidation 6-59: Loss: 0.1157 Acc: 75.0000%\n",
      "\tvalidation 6-60: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 6-61: Loss: 0.1111 Acc: 75.0000%\n",
      "\tvalidation 6-62: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 6-63: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 6-64: Loss: 0.1084 Acc: 75.0000%\n",
      "\tvalidation 6-65: Loss: 0.2214 Acc: 50.0000%\n",
      "\tvalidation 6-66: Loss: 0.2275 Acc: 50.0000%\n",
      "\tvalidation 6-67: Loss: 0.1517 Acc: 75.0000%\n",
      "\tvalidation 6-68: Loss: 0.1227 Acc: 75.0000%\n",
      "\tvalidation 6-69: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 6-70: Loss: 0.1537 Acc: 75.0000%\n",
      "\tvalidation 6-71: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 6-72: Loss: 0.1413 Acc: 75.0000%\n",
      "\tvalidation 6-73: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 6-74: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 6-75: Loss: 0.3213 Acc: 50.0000%\n",
      "\tvalidation 6-76: Loss: 0.1726 Acc: 75.0000%\n",
      "\tvalidation 6-77: Loss: 0.1046 Acc: 75.0000%\n",
      "\tvalidation 6-78: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 6-79: Loss: 0.3247 Acc: 25.0000%\n",
      "\tvalidation 6-80: Loss: 0.2246 Acc: 50.0000%\n",
      "\tvalidation 6-81: Loss: 0.0946 Acc: 75.0000%\n",
      "\tvalidation 6-82: Loss: 0.2910 Acc: 25.0000%\n",
      "\tvalidation 6-83: Loss: 0.1491 Acc: 75.0000%\n",
      "\tvalidation 6-84: Loss: 0.2119 Acc: 50.0000%\n",
      "\tvalidation 6-85: Loss: 0.1509 Acc: 75.0000%\n",
      "\tvalidation 6-86: Loss: 0.1207 Acc: 75.0000%\n",
      "\tvalidation 6-87: Loss: 0.0870 Acc: 75.0000%\n",
      "\tvalidation 6-88: Loss: 0.1355 Acc: 75.0000%\n",
      "\tvalidation 6-89: Loss: 0.1693 Acc: 50.0000%\n",
      "\tvalidation 6-90: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 6-91: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 6-92: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 6-93: Loss: 0.3478 Acc: 25.0000%\n",
      "\tvalidation 6-94: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 6-95: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 6-96: Loss: 0.0352 Acc: 100.0000%\n",
      "\tvalidation 6-97: Loss: 0.1289 Acc: 75.0000%\n",
      "\tvalidation 6-98: Loss: 0.1364 Acc: 75.0000%\n",
      "\tvalidation 6-99: Loss: 0.1300 Acc: 75.0000%\n",
      "\tvalidation 6-100: Loss: 0.2804 Acc: 50.0000%\n",
      "\tvalidation 6-101: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 6-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 6-103: Loss: 0.2389 Acc: 50.0000%\n",
      "\tvalidation 6-104: Loss: 0.1350 Acc: 75.0000%\n",
      "\tvalidation 6-105: Loss: 0.1564 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2319 Acc: 63.2653%\n",
      "\tvalidation Loss: 0.1351 Acc: 74.5238%\n",
      "Time passed 0h 5m 60s\n",
      "--------------------\n",
      "Epoch [7/40]:\n",
      "\ttrain 7-1: Loss: 0.2423 Acc: 50.0000%\n",
      "\ttrain 7-2: Loss: 0.2910 Acc: 50.0000%\n",
      "\ttrain 7-3: Loss: 0.6571 Acc: 50.0000%\n",
      "\ttrain 7-4: Loss: 0.1788 Acc: 75.0000%\n",
      "\ttrain 7-5: Loss: 0.2470 Acc: 50.0000%\n",
      "\ttrain 7-6: Loss: 0.1878 Acc: 75.0000%\n",
      "\ttrain 7-7: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 7-8: Loss: 0.1686 Acc: 25.0000%\n",
      "\ttrain 7-9: Loss: 0.1294 Acc: 50.0000%\n",
      "\ttrain 7-10: Loss: 0.1302 Acc: 100.0000%\n",
      "\ttrain 7-11: Loss: 0.2202 Acc: 50.0000%\n",
      "\ttrain 7-12: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 7-13: Loss: 0.2687 Acc: 75.0000%\n",
      "\ttrain 7-14: Loss: 0.4221 Acc: 50.0000%\n",
      "\ttrain 7-15: Loss: 0.2638 Acc: 50.0000%\n",
      "\ttrain 7-16: Loss: 0.1908 Acc: 50.0000%\n",
      "\ttrain 7-17: Loss: 0.1327 Acc: 100.0000%\n",
      "\ttrain 7-18: Loss: 0.3831 Acc: 0.0000%\n",
      "\ttrain 7-19: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 7-20: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 7-21: Loss: 0.4262 Acc: 25.0000%\n",
      "\ttrain 7-22: Loss: 0.0882 Acc: 100.0000%\n",
      "\ttrain 7-23: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 7-24: Loss: 0.3083 Acc: 50.0000%\n",
      "\ttrain 7-25: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 7-26: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 7-27: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 7-28: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 7-29: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 7-30: Loss: 0.1914 Acc: 50.0000%\n",
      "\ttrain 7-31: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 7-32: Loss: 0.2260 Acc: 25.0000%\n",
      "\ttrain 7-33: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 7-34: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 7-35: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 7-36: Loss: 0.1916 Acc: 75.0000%\n",
      "\ttrain 7-37: Loss: 0.3971 Acc: 25.0000%\n",
      "\ttrain 7-38: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 7-39: Loss: 0.3988 Acc: 25.0000%\n",
      "\ttrain 7-40: Loss: 0.0770 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-41: Loss: 0.2512 Acc: 75.0000%\n",
      "\ttrain 7-42: Loss: 0.3888 Acc: 25.0000%\n",
      "\ttrain 7-43: Loss: 0.2830 Acc: 50.0000%\n",
      "\ttrain 7-44: Loss: 0.2125 Acc: 50.0000%\n",
      "\ttrain 7-45: Loss: 0.2055 Acc: 75.0000%\n",
      "\ttrain 7-46: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 7-47: Loss: 0.2575 Acc: 50.0000%\n",
      "\ttrain 7-48: Loss: 0.5610 Acc: 25.0000%\n",
      "\ttrain 7-49: Loss: 0.2891 Acc: 75.0000%\n",
      "\ttrain 7-50: Loss: 0.1606 Acc: 50.0000%\n",
      "\ttrain 7-51: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 7-52: Loss: 0.3550 Acc: 50.0000%\n",
      "\ttrain 7-53: Loss: 0.4653 Acc: 75.0000%\n",
      "\ttrain 7-54: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 7-55: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 7-56: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 7-57: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 7-58: Loss: 0.1463 Acc: 50.0000%\n",
      "\ttrain 7-59: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 7-60: Loss: 0.5192 Acc: 50.0000%\n",
      "\ttrain 7-61: Loss: 0.3781 Acc: 25.0000%\n",
      "\ttrain 7-62: Loss: 0.9118 Acc: 50.0000%\n",
      "\ttrain 7-63: Loss: 0.2668 Acc: 50.0000%\n",
      "\ttrain 7-64: Loss: 0.1911 Acc: 25.0000%\n",
      "\ttrain 7-65: Loss: 0.3253 Acc: 25.0000%\n",
      "\ttrain 7-66: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 7-67: Loss: 0.1985 Acc: 50.0000%\n",
      "\ttrain 7-68: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 7-69: Loss: 0.2811 Acc: 50.0000%\n",
      "\ttrain 7-70: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 7-71: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 7-72: Loss: 0.2498 Acc: 50.0000%\n",
      "\ttrain 7-73: Loss: 0.3390 Acc: 25.0000%\n",
      "\ttrain 7-74: Loss: 0.2142 Acc: 50.0000%\n",
      "\ttrain 7-75: Loss: 0.2125 Acc: 75.0000%\n",
      "\ttrain 7-76: Loss: 0.2937 Acc: 50.0000%\n",
      "\ttrain 7-77: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 7-78: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 7-79: Loss: 0.2303 Acc: 50.0000%\n",
      "\ttrain 7-80: Loss: 0.1481 Acc: 50.0000%\n",
      "\ttrain 7-81: Loss: 0.2972 Acc: 75.0000%\n",
      "\ttrain 7-82: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 7-83: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 7-84: Loss: 0.4761 Acc: 25.0000%\n",
      "\ttrain 7-85: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 7-86: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 7-87: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 7-88: Loss: 0.6621 Acc: 0.0000%\n",
      "\ttrain 7-89: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 7-90: Loss: 0.1596 Acc: 50.0000%\n",
      "\ttrain 7-91: Loss: 0.2843 Acc: 50.0000%\n",
      "\ttrain 7-92: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 7-93: Loss: 0.2143 Acc: 50.0000%\n",
      "\ttrain 7-94: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 7-95: Loss: 0.1850 Acc: 50.0000%\n",
      "\ttrain 7-96: Loss: 0.1926 Acc: 50.0000%\n",
      "\ttrain 7-97: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 7-98: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 7-99: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 7-100: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 7-101: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 7-102: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 7-103: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 7-104: Loss: 0.2800 Acc: 75.0000%\n",
      "\ttrain 7-105: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 7-106: Loss: 0.5621 Acc: 50.0000%\n",
      "\ttrain 7-107: Loss: 0.5436 Acc: 25.0000%\n",
      "\ttrain 7-108: Loss: 0.4498 Acc: 0.0000%\n",
      "\ttrain 7-109: Loss: 0.1362 Acc: 50.0000%\n",
      "\ttrain 7-110: Loss: 0.1988 Acc: 25.0000%\n",
      "\ttrain 7-111: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 7-112: Loss: 0.2596 Acc: 25.0000%\n",
      "\ttrain 7-113: Loss: 0.1001 Acc: 75.0000%\n",
      "\ttrain 7-114: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 7-115: Loss: 0.1751 Acc: 75.0000%\n",
      "\ttrain 7-116: Loss: 0.2672 Acc: 50.0000%\n",
      "\ttrain 7-117: Loss: 0.1133 Acc: 100.0000%\n",
      "\ttrain 7-118: Loss: 0.2193 Acc: 50.0000%\n",
      "\ttrain 7-119: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 7-120: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 7-121: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 7-122: Loss: 0.0854 Acc: 100.0000%\n",
      "\ttrain 7-123: Loss: 0.3799 Acc: 75.0000%\n",
      "\ttrain 7-124: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 7-125: Loss: 0.1658 Acc: 75.0000%\n",
      "\ttrain 7-126: Loss: 0.2113 Acc: 50.0000%\n",
      "\ttrain 7-127: Loss: 0.1959 Acc: 50.0000%\n",
      "\ttrain 7-128: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 7-129: Loss: 0.1128 Acc: 50.0000%\n",
      "\ttrain 7-130: Loss: 0.1896 Acc: 75.0000%\n",
      "\ttrain 7-131: Loss: 0.3307 Acc: 25.0000%\n",
      "\ttrain 7-132: Loss: 0.3719 Acc: 25.0000%\n",
      "\ttrain 7-133: Loss: 0.2209 Acc: 50.0000%\n",
      "\ttrain 7-134: Loss: 0.3608 Acc: 50.0000%\n",
      "\ttrain 7-135: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 7-136: Loss: 0.1760 Acc: 75.0000%\n",
      "\ttrain 7-137: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 7-138: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 7-139: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 7-140: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 7-141: Loss: 0.3738 Acc: 50.0000%\n",
      "\ttrain 7-142: Loss: 0.1876 Acc: 75.0000%\n",
      "\ttrain 7-143: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 7-144: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 7-145: Loss: 0.1867 Acc: 75.0000%\n",
      "\ttrain 7-146: Loss: 0.2635 Acc: 75.0000%\n",
      "\ttrain 7-147: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 7-148: Loss: 0.3752 Acc: 25.0000%\n",
      "\ttrain 7-149: Loss: 0.5032 Acc: 25.0000%\n",
      "\ttrain 7-150: Loss: 0.2585 Acc: 50.0000%\n",
      "\ttrain 7-151: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 7-152: Loss: 0.1949 Acc: 50.0000%\n",
      "\ttrain 7-153: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 7-154: Loss: 0.1003 Acc: 100.0000%\n",
      "\ttrain 7-155: Loss: 0.2574 Acc: 75.0000%\n",
      "\ttrain 7-156: Loss: 0.3155 Acc: 50.0000%\n",
      "\ttrain 7-157: Loss: 0.1800 Acc: 50.0000%\n",
      "\ttrain 7-158: Loss: 0.4755 Acc: 25.0000%\n",
      "\ttrain 7-159: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 7-160: Loss: 0.1634 Acc: 50.0000%\n",
      "\ttrain 7-161: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 7-162: Loss: 0.3629 Acc: 25.0000%\n",
      "\ttrain 7-163: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 7-164: Loss: 0.6680 Acc: 0.0000%\n",
      "\ttrain 7-165: Loss: 0.1670 Acc: 75.0000%\n",
      "\ttrain 7-166: Loss: 0.1164 Acc: 100.0000%\n",
      "\ttrain 7-167: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 7-168: Loss: 0.5543 Acc: 50.0000%\n",
      "\ttrain 7-169: Loss: 0.3481 Acc: 25.0000%\n",
      "\ttrain 7-170: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 7-171: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 7-172: Loss: 0.8761 Acc: 0.0000%\n",
      "\ttrain 7-173: Loss: 0.2892 Acc: 75.0000%\n",
      "\ttrain 7-174: Loss: 0.3732 Acc: 50.0000%\n",
      "\ttrain 7-175: Loss: 0.5962 Acc: 50.0000%\n",
      "\ttrain 7-176: Loss: 0.3867 Acc: 50.0000%\n",
      "\ttrain 7-177: Loss: 0.3798 Acc: 75.0000%\n",
      "\ttrain 7-178: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 7-179: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 7-180: Loss: 0.3169 Acc: 75.0000%\n",
      "\ttrain 7-181: Loss: 0.3813 Acc: 50.0000%\n",
      "\ttrain 7-182: Loss: 0.2512 Acc: 50.0000%\n",
      "\ttrain 7-183: Loss: 0.6690 Acc: 25.0000%\n",
      "\ttrain 7-184: Loss: 0.6905 Acc: 0.0000%\n",
      "\ttrain 7-185: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 7-186: Loss: 0.2007 Acc: 50.0000%\n",
      "\ttrain 7-187: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 7-188: Loss: 0.2834 Acc: 25.0000%\n",
      "\ttrain 7-189: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 7-190: Loss: 0.1051 Acc: 75.0000%\n",
      "\ttrain 7-191: Loss: 0.2217 Acc: 75.0000%\n",
      "\ttrain 7-192: Loss: 0.2497 Acc: 50.0000%\n",
      "\ttrain 7-193: Loss: 0.2102 Acc: 50.0000%\n",
      "\ttrain 7-194: Loss: 0.2254 Acc: 50.0000%\n",
      "\ttrain 7-195: Loss: 0.4095 Acc: 50.0000%\n",
      "\ttrain 7-196: Loss: 0.2804 Acc: 75.0000%\n",
      "\ttrain 7-197: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 7-198: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 7-199: Loss: 0.2238 Acc: 75.0000%\n",
      "\ttrain 7-200: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 7-201: Loss: 0.2765 Acc: 50.0000%\n",
      "\ttrain 7-202: Loss: 0.2870 Acc: 50.0000%\n",
      "\ttrain 7-203: Loss: 0.1557 Acc: 75.0000%\n",
      "\ttrain 7-204: Loss: 0.2302 Acc: 50.0000%\n",
      "\ttrain 7-205: Loss: 0.1654 Acc: 50.0000%\n",
      "\ttrain 7-206: Loss: 0.2630 Acc: 25.0000%\n",
      "\ttrain 7-207: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 7-208: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 7-209: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 7-210: Loss: 0.2011 Acc: 75.0000%\n",
      "\ttrain 7-211: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 7-212: Loss: 0.3306 Acc: 50.0000%\n",
      "\ttrain 7-213: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 7-214: Loss: 0.2820 Acc: 50.0000%\n",
      "\ttrain 7-215: Loss: 0.1290 Acc: 75.0000%\n",
      "\ttrain 7-216: Loss: 0.3504 Acc: 50.0000%\n",
      "\ttrain 7-217: Loss: 0.1693 Acc: 75.0000%\n",
      "\ttrain 7-218: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 7-219: Loss: 0.2613 Acc: 50.0000%\n",
      "\ttrain 7-220: Loss: 0.4530 Acc: 50.0000%\n",
      "\ttrain 7-221: Loss: 0.3164 Acc: 50.0000%\n",
      "\ttrain 7-222: Loss: 0.4937 Acc: 25.0000%\n",
      "\ttrain 7-223: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 7-224: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 7-225: Loss: 0.2728 Acc: 50.0000%\n",
      "\ttrain 7-226: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 7-227: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 7-228: Loss: 0.4397 Acc: 25.0000%\n",
      "\ttrain 7-229: Loss: 0.2633 Acc: 50.0000%\n",
      "\ttrain 7-230: Loss: 0.2024 Acc: 50.0000%\n",
      "\ttrain 7-231: Loss: 0.3906 Acc: 25.0000%\n",
      "\ttrain 7-232: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 7-233: Loss: 0.1500 Acc: 50.0000%\n",
      "\ttrain 7-234: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 7-235: Loss: 0.3165 Acc: 75.0000%\n",
      "\ttrain 7-236: Loss: 0.1869 Acc: 75.0000%\n",
      "\ttrain 7-237: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 7-238: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 7-239: Loss: 0.1596 Acc: 50.0000%\n",
      "\ttrain 7-240: Loss: 0.1164 Acc: 100.0000%\n",
      "\ttrain 7-241: Loss: 0.1546 Acc: 50.0000%\n",
      "\ttrain 7-242: Loss: 0.1802 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-243: Loss: 0.6888 Acc: 25.0000%\n",
      "\ttrain 7-244: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 7-245: Loss: 0.4343 Acc: 50.0000%\n",
      "\tvalidation 7-1: Loss: 0.7546 Acc: 25.0000%\n",
      "\tvalidation 7-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-3: Loss: 0.0682 Acc: 100.0000%\n",
      "\tvalidation 7-4: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 7-5: Loss: 0.1248 Acc: 75.0000%\n",
      "\tvalidation 7-6: Loss: 0.3544 Acc: 75.0000%\n",
      "\tvalidation 7-7: Loss: 0.2742 Acc: 75.0000%\n",
      "\tvalidation 7-8: Loss: 0.3470 Acc: 50.0000%\n",
      "\tvalidation 7-9: Loss: 0.1920 Acc: 75.0000%\n",
      "\tvalidation 7-10: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 7-11: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 7-12: Loss: 0.1509 Acc: 50.0000%\n",
      "\tvalidation 7-13: Loss: 0.4927 Acc: 50.0000%\n",
      "\tvalidation 7-14: Loss: 0.2836 Acc: 50.0000%\n",
      "\tvalidation 7-15: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 7-16: Loss: 0.1717 Acc: 50.0000%\n",
      "\tvalidation 7-17: Loss: 0.1394 Acc: 75.0000%\n",
      "\tvalidation 7-18: Loss: 0.1570 Acc: 50.0000%\n",
      "\tvalidation 7-19: Loss: 0.1130 Acc: 75.0000%\n",
      "\tvalidation 7-20: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 7-21: Loss: 0.0241 Acc: 100.0000%\n",
      "\tvalidation 7-22: Loss: 0.6547 Acc: 0.0000%\n",
      "\tvalidation 7-23: Loss: 0.0979 Acc: 75.0000%\n",
      "\tvalidation 7-24: Loss: 0.1764 Acc: 50.0000%\n",
      "\tvalidation 7-25: Loss: 0.3650 Acc: 25.0000%\n",
      "\tvalidation 7-26: Loss: 0.0473 Acc: 100.0000%\n",
      "\tvalidation 7-27: Loss: 0.2833 Acc: 75.0000%\n",
      "\tvalidation 7-28: Loss: 0.1694 Acc: 50.0000%\n",
      "\tvalidation 7-29: Loss: 0.2446 Acc: 50.0000%\n",
      "\tvalidation 7-30: Loss: 0.1941 Acc: 50.0000%\n",
      "\tvalidation 7-31: Loss: 0.1757 Acc: 75.0000%\n",
      "\tvalidation 7-32: Loss: 0.1736 Acc: 75.0000%\n",
      "\tvalidation 7-33: Loss: 0.9266 Acc: 75.0000%\n",
      "\tvalidation 7-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 7-35: Loss: 0.1211 Acc: 75.0000%\n",
      "\tvalidation 7-36: Loss: 0.2530 Acc: 50.0000%\n",
      "\tvalidation 7-37: Loss: 0.1465 Acc: 75.0000%\n",
      "\tvalidation 7-38: Loss: 0.1023 Acc: 75.0000%\n",
      "\tvalidation 7-39: Loss: 0.1503 Acc: 75.0000%\n",
      "\tvalidation 7-40: Loss: 0.1580 Acc: 50.0000%\n",
      "\tvalidation 7-41: Loss: 0.1305 Acc: 75.0000%\n",
      "\tvalidation 7-42: Loss: 0.1772 Acc: 50.0000%\n",
      "\tvalidation 7-43: Loss: 0.2649 Acc: 50.0000%\n",
      "\tvalidation 7-44: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 7-45: Loss: 0.3547 Acc: 25.0000%\n",
      "\tvalidation 7-46: Loss: 0.9517 Acc: 50.0000%\n",
      "\tvalidation 7-47: Loss: 0.2625 Acc: 50.0000%\n",
      "\tvalidation 7-48: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 7-49: Loss: 0.0903 Acc: 75.0000%\n",
      "\tvalidation 7-50: Loss: 0.1704 Acc: 75.0000%\n",
      "\tvalidation 7-51: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 7-52: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 7-53: Loss: 0.0846 Acc: 75.0000%\n",
      "\tvalidation 7-54: Loss: 0.1218 Acc: 75.0000%\n",
      "\tvalidation 7-55: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 7-56: Loss: 0.1176 Acc: 75.0000%\n",
      "\tvalidation 7-57: Loss: 0.5912 Acc: 75.0000%\n",
      "\tvalidation 7-58: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 7-59: Loss: 0.4479 Acc: 50.0000%\n",
      "\tvalidation 7-60: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 7-61: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 7-62: Loss: 0.1148 Acc: 75.0000%\n",
      "\tvalidation 7-63: Loss: 0.2591 Acc: 50.0000%\n",
      "\tvalidation 7-64: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 7-65: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 7-66: Loss: 0.1086 Acc: 75.0000%\n",
      "\tvalidation 7-67: Loss: 0.2243 Acc: 75.0000%\n",
      "\tvalidation 7-68: Loss: 0.4415 Acc: 75.0000%\n",
      "\tvalidation 7-69: Loss: 0.0809 Acc: 75.0000%\n",
      "\tvalidation 7-70: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 7-71: Loss: 0.0982 Acc: 75.0000%\n",
      "\tvalidation 7-72: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 7-73: Loss: 0.0956 Acc: 75.0000%\n",
      "\tvalidation 7-74: Loss: 0.5730 Acc: 50.0000%\n",
      "\tvalidation 7-75: Loss: 0.0742 Acc: 75.0000%\n",
      "\tvalidation 7-76: Loss: 0.1802 Acc: 50.0000%\n",
      "\tvalidation 7-77: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 7-78: Loss: 0.4474 Acc: 75.0000%\n",
      "\tvalidation 7-79: Loss: 0.3516 Acc: 75.0000%\n",
      "\tvalidation 7-80: Loss: 0.0999 Acc: 75.0000%\n",
      "\tvalidation 7-81: Loss: 0.1146 Acc: 75.0000%\n",
      "\tvalidation 7-82: Loss: 0.2384 Acc: 75.0000%\n",
      "\tvalidation 7-83: Loss: 0.2373 Acc: 50.0000%\n",
      "\tvalidation 7-84: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 7-85: Loss: 0.1320 Acc: 50.0000%\n",
      "\tvalidation 7-86: Loss: 0.2288 Acc: 50.0000%\n",
      "\tvalidation 7-87: Loss: 0.0568 Acc: 100.0000%\n",
      "\tvalidation 7-88: Loss: 0.0753 Acc: 75.0000%\n",
      "\tvalidation 7-89: Loss: 0.0610 Acc: 100.0000%\n",
      "\tvalidation 7-90: Loss: 0.0350 Acc: 100.0000%\n",
      "\tvalidation 7-91: Loss: 0.5345 Acc: 0.0000%\n",
      "\tvalidation 7-92: Loss: 0.5815 Acc: 50.0000%\n",
      "\tvalidation 7-93: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 7-94: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 7-95: Loss: 0.0659 Acc: 75.0000%\n",
      "\tvalidation 7-96: Loss: 0.2170 Acc: 75.0000%\n",
      "\tvalidation 7-97: Loss: 0.0756 Acc: 75.0000%\n",
      "\tvalidation 7-98: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 7-99: Loss: 0.0457 Acc: 100.0000%\n",
      "\tvalidation 7-100: Loss: 0.2045 Acc: 50.0000%\n",
      "\tvalidation 7-101: Loss: 0.1153 Acc: 75.0000%\n",
      "\tvalidation 7-102: Loss: 0.1987 Acc: 50.0000%\n",
      "\tvalidation 7-103: Loss: 0.2086 Acc: 75.0000%\n",
      "\tvalidation 7-104: Loss: 0.3360 Acc: 25.0000%\n",
      "\tvalidation 7-105: Loss: 0.1833 Acc: 50.0000%\n",
      "\ttrain Loss: 0.2233 Acc: 62.1429%\n",
      "\tvalidation Loss: 0.1858 Acc: 72.1429%\n",
      "Time passed 0h 7m 1s\n",
      "--------------------\n",
      "Epoch [8/40]:\n",
      "\ttrain 8-1: Loss: 0.1682 Acc: 75.0000%\n",
      "\ttrain 8-2: Loss: 0.2649 Acc: 75.0000%\n",
      "\ttrain 8-3: Loss: 0.3863 Acc: 25.0000%\n",
      "\ttrain 8-4: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 8-5: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 8-6: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 8-7: Loss: 0.2513 Acc: 50.0000%\n",
      "\ttrain 8-8: Loss: 0.2531 Acc: 50.0000%\n",
      "\ttrain 8-9: Loss: 0.2595 Acc: 25.0000%\n",
      "\ttrain 8-10: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 8-11: Loss: 0.2024 Acc: 25.0000%\n",
      "\ttrain 8-12: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 8-13: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 8-14: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 8-15: Loss: 0.3485 Acc: 25.0000%\n",
      "\ttrain 8-16: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 8-17: Loss: 0.4450 Acc: 75.0000%\n",
      "\ttrain 8-18: Loss: 0.3809 Acc: 50.0000%\n",
      "\ttrain 8-19: Loss: 0.3218 Acc: 50.0000%\n",
      "\ttrain 8-20: Loss: 0.5146 Acc: 50.0000%\n",
      "\ttrain 8-21: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 8-22: Loss: 0.1197 Acc: 50.0000%\n",
      "\ttrain 8-23: Loss: 0.1416 Acc: 50.0000%\n",
      "\ttrain 8-24: Loss: 0.2922 Acc: 75.0000%\n",
      "\ttrain 8-25: Loss: 0.4325 Acc: 50.0000%\n",
      "\ttrain 8-26: Loss: 0.2994 Acc: 50.0000%\n",
      "\ttrain 8-27: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 8-28: Loss: 0.1908 Acc: 50.0000%\n",
      "\ttrain 8-29: Loss: 0.3302 Acc: 50.0000%\n",
      "\ttrain 8-30: Loss: 0.1831 Acc: 50.0000%\n",
      "\ttrain 8-31: Loss: 0.4075 Acc: 50.0000%\n",
      "\ttrain 8-32: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 8-33: Loss: 0.2210 Acc: 50.0000%\n",
      "\ttrain 8-34: Loss: 0.2590 Acc: 25.0000%\n",
      "\ttrain 8-35: Loss: 0.6775 Acc: 50.0000%\n",
      "\ttrain 8-36: Loss: 0.2792 Acc: 50.0000%\n",
      "\ttrain 8-37: Loss: 0.2000 Acc: 50.0000%\n",
      "\ttrain 8-38: Loss: 0.2778 Acc: 25.0000%\n",
      "\ttrain 8-39: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 8-40: Loss: 0.2512 Acc: 25.0000%\n",
      "\ttrain 8-41: Loss: 0.1938 Acc: 75.0000%\n",
      "\ttrain 8-42: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 8-43: Loss: 0.2915 Acc: 50.0000%\n",
      "\ttrain 8-44: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 8-45: Loss: 0.2593 Acc: 50.0000%\n",
      "\ttrain 8-46: Loss: 0.1005 Acc: 100.0000%\n",
      "\ttrain 8-47: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 8-48: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 8-49: Loss: 0.1707 Acc: 50.0000%\n",
      "\ttrain 8-50: Loss: 0.2639 Acc: 50.0000%\n",
      "\ttrain 8-51: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 8-52: Loss: 0.3872 Acc: 0.0000%\n",
      "\ttrain 8-53: Loss: 0.1596 Acc: 50.0000%\n",
      "\ttrain 8-54: Loss: 0.2384 Acc: 75.0000%\n",
      "\ttrain 8-55: Loss: 0.3329 Acc: 50.0000%\n",
      "\ttrain 8-56: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 8-57: Loss: 0.4008 Acc: 25.0000%\n",
      "\ttrain 8-58: Loss: 0.1462 Acc: 100.0000%\n",
      "\ttrain 8-59: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 8-60: Loss: 0.0918 Acc: 100.0000%\n",
      "\ttrain 8-61: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 8-62: Loss: 0.2208 Acc: 75.0000%\n",
      "\ttrain 8-63: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 8-64: Loss: 0.1693 Acc: 75.0000%\n",
      "\ttrain 8-65: Loss: 0.3570 Acc: 50.0000%\n",
      "\ttrain 8-66: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 8-67: Loss: 0.2584 Acc: 75.0000%\n",
      "\ttrain 8-68: Loss: 0.1347 Acc: 75.0000%\n",
      "\ttrain 8-69: Loss: 0.2295 Acc: 75.0000%\n",
      "\ttrain 8-70: Loss: 0.1632 Acc: 50.0000%\n",
      "\ttrain 8-71: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 8-72: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 8-73: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 8-74: Loss: 0.2962 Acc: 50.0000%\n",
      "\ttrain 8-75: Loss: 0.2047 Acc: 75.0000%\n",
      "\ttrain 8-76: Loss: 0.4255 Acc: 50.0000%\n",
      "\ttrain 8-77: Loss: 0.3290 Acc: 75.0000%\n",
      "\ttrain 8-78: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 8-79: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 8-80: Loss: 0.1477 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 8-81: Loss: 0.1701 Acc: 75.0000%\n",
      "\ttrain 8-82: Loss: 0.1957 Acc: 50.0000%\n",
      "\ttrain 8-83: Loss: 0.2087 Acc: 50.0000%\n",
      "\ttrain 8-84: Loss: 0.1835 Acc: 25.0000%\n",
      "\ttrain 8-85: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 8-86: Loss: 0.1699 Acc: 50.0000%\n",
      "\ttrain 8-87: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 8-88: Loss: 0.4279 Acc: 50.0000%\n",
      "\ttrain 8-89: Loss: 0.3466 Acc: 50.0000%\n",
      "\ttrain 8-90: Loss: 0.2365 Acc: 75.0000%\n",
      "\ttrain 8-91: Loss: 0.5194 Acc: 25.0000%\n",
      "\ttrain 8-92: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 8-93: Loss: 0.5006 Acc: 25.0000%\n",
      "\ttrain 8-94: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 8-95: Loss: 0.3437 Acc: 25.0000%\n",
      "\ttrain 8-96: Loss: 0.1041 Acc: 100.0000%\n",
      "\ttrain 8-97: Loss: 0.2159 Acc: 50.0000%\n",
      "\ttrain 8-98: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 8-99: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 8-100: Loss: 0.4254 Acc: 50.0000%\n",
      "\ttrain 8-101: Loss: 0.5705 Acc: 25.0000%\n",
      "\ttrain 8-102: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 8-103: Loss: 0.3233 Acc: 50.0000%\n",
      "\ttrain 8-104: Loss: 0.1663 Acc: 50.0000%\n",
      "\ttrain 8-105: Loss: 0.1451 Acc: 75.0000%\n",
      "\ttrain 8-106: Loss: 0.1826 Acc: 50.0000%\n",
      "\ttrain 8-107: Loss: 0.3677 Acc: 25.0000%\n",
      "\ttrain 8-108: Loss: 0.2115 Acc: 75.0000%\n",
      "\ttrain 8-109: Loss: 0.2115 Acc: 50.0000%\n",
      "\ttrain 8-110: Loss: 0.1739 Acc: 50.0000%\n",
      "\ttrain 8-111: Loss: 0.3756 Acc: 25.0000%\n",
      "\ttrain 8-112: Loss: 0.2592 Acc: 25.0000%\n",
      "\ttrain 8-113: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 8-114: Loss: 0.1215 Acc: 50.0000%\n",
      "\ttrain 8-115: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 8-116: Loss: 0.2719 Acc: 50.0000%\n",
      "\ttrain 8-117: Loss: 0.4080 Acc: 0.0000%\n",
      "\ttrain 8-118: Loss: 0.3167 Acc: 25.0000%\n",
      "\ttrain 8-119: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 8-120: Loss: 0.1999 Acc: 50.0000%\n",
      "\ttrain 8-121: Loss: 0.1477 Acc: 50.0000%\n",
      "\ttrain 8-122: Loss: 0.1155 Acc: 100.0000%\n",
      "\ttrain 8-123: Loss: 0.6296 Acc: 50.0000%\n",
      "\ttrain 8-124: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 8-125: Loss: 0.7521 Acc: 0.0000%\n",
      "\ttrain 8-126: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 8-127: Loss: 0.0901 Acc: 100.0000%\n",
      "\ttrain 8-128: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 8-129: Loss: 0.2469 Acc: 50.0000%\n",
      "\ttrain 8-130: Loss: 0.3418 Acc: 25.0000%\n",
      "\ttrain 8-131: Loss: 0.4280 Acc: 50.0000%\n",
      "\ttrain 8-132: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 8-133: Loss: 0.2302 Acc: 75.0000%\n",
      "\ttrain 8-134: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 8-135: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 8-136: Loss: 0.6406 Acc: 0.0000%\n",
      "\ttrain 8-137: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 8-138: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 8-139: Loss: 0.3639 Acc: 50.0000%\n",
      "\ttrain 8-140: Loss: 0.2296 Acc: 75.0000%\n",
      "\ttrain 8-141: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 8-142: Loss: 0.1979 Acc: 75.0000%\n",
      "\ttrain 8-143: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 8-144: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 8-145: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 8-146: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 8-147: Loss: 0.2990 Acc: 25.0000%\n",
      "\ttrain 8-148: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 8-149: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 8-150: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 8-151: Loss: 0.2698 Acc: 75.0000%\n",
      "\ttrain 8-152: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 8-153: Loss: 0.2515 Acc: 25.0000%\n",
      "\ttrain 8-154: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 8-155: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 8-156: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 8-157: Loss: 0.2503 Acc: 50.0000%\n",
      "\ttrain 8-158: Loss: 0.1560 Acc: 50.0000%\n",
      "\ttrain 8-159: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 8-160: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 8-161: Loss: 0.1483 Acc: 50.0000%\n",
      "\ttrain 8-162: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 8-163: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 8-164: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 8-165: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 8-166: Loss: 0.4994 Acc: 25.0000%\n",
      "\ttrain 8-167: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 8-168: Loss: 0.2358 Acc: 50.0000%\n",
      "\ttrain 8-169: Loss: 0.0746 Acc: 100.0000%\n",
      "\ttrain 8-170: Loss: 0.3491 Acc: 50.0000%\n",
      "\ttrain 8-171: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 8-172: Loss: 0.2221 Acc: 50.0000%\n",
      "\ttrain 8-173: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 8-174: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 8-175: Loss: 0.1626 Acc: 50.0000%\n",
      "\ttrain 8-176: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 8-177: Loss: 0.1450 Acc: 75.0000%\n",
      "\ttrain 8-178: Loss: 0.2328 Acc: 25.0000%\n",
      "\ttrain 8-179: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 8-180: Loss: 0.1193 Acc: 50.0000%\n",
      "\ttrain 8-181: Loss: 0.5419 Acc: 50.0000%\n",
      "\ttrain 8-182: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 8-183: Loss: 0.2291 Acc: 50.0000%\n",
      "\ttrain 8-184: Loss: 0.0803 Acc: 100.0000%\n",
      "\ttrain 8-185: Loss: 0.1137 Acc: 100.0000%\n",
      "\ttrain 8-186: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 8-187: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 8-188: Loss: 0.0645 Acc: 100.0000%\n",
      "\ttrain 8-189: Loss: 0.0697 Acc: 100.0000%\n",
      "\ttrain 8-190: Loss: 0.1772 Acc: 75.0000%\n",
      "\ttrain 8-191: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 8-192: Loss: 0.1670 Acc: 50.0000%\n",
      "\ttrain 8-193: Loss: 0.3009 Acc: 50.0000%\n",
      "\ttrain 8-194: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 8-195: Loss: 0.5918 Acc: 0.0000%\n",
      "\ttrain 8-196: Loss: 0.3596 Acc: 75.0000%\n",
      "\ttrain 8-197: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 8-198: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 8-199: Loss: 0.1638 Acc: 75.0000%\n",
      "\ttrain 8-200: Loss: 0.3759 Acc: 75.0000%\n",
      "\ttrain 8-201: Loss: 0.2865 Acc: 50.0000%\n",
      "\ttrain 8-202: Loss: 0.3723 Acc: 75.0000%\n",
      "\ttrain 8-203: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 8-204: Loss: 0.2911 Acc: 50.0000%\n",
      "\ttrain 8-205: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 8-206: Loss: 0.2529 Acc: 75.0000%\n",
      "\ttrain 8-207: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 8-208: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 8-209: Loss: 0.4626 Acc: 25.0000%\n",
      "\ttrain 8-210: Loss: 0.1510 Acc: 50.0000%\n",
      "\ttrain 8-211: Loss: 0.7291 Acc: 50.0000%\n",
      "\ttrain 8-212: Loss: 0.2278 Acc: 25.0000%\n",
      "\ttrain 8-213: Loss: 0.1857 Acc: 75.0000%\n",
      "\ttrain 8-214: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 8-215: Loss: 0.2180 Acc: 75.0000%\n",
      "\ttrain 8-216: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 8-217: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 8-218: Loss: 0.5147 Acc: 50.0000%\n",
      "\ttrain 8-219: Loss: 0.2084 Acc: 75.0000%\n",
      "\ttrain 8-220: Loss: 0.1798 Acc: 50.0000%\n",
      "\ttrain 8-221: Loss: 0.3191 Acc: 75.0000%\n",
      "\ttrain 8-222: Loss: 0.2321 Acc: 75.0000%\n",
      "\ttrain 8-223: Loss: 0.1640 Acc: 75.0000%\n",
      "\ttrain 8-224: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 8-225: Loss: 0.2990 Acc: 25.0000%\n",
      "\ttrain 8-226: Loss: 0.2850 Acc: 50.0000%\n",
      "\ttrain 8-227: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 8-228: Loss: 0.1485 Acc: 50.0000%\n",
      "\ttrain 8-229: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 8-230: Loss: 0.1367 Acc: 75.0000%\n",
      "\ttrain 8-231: Loss: 0.7838 Acc: 25.0000%\n",
      "\ttrain 8-232: Loss: 0.1742 Acc: 75.0000%\n",
      "\ttrain 8-233: Loss: 0.3287 Acc: 50.0000%\n",
      "\ttrain 8-234: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 8-235: Loss: 0.2557 Acc: 50.0000%\n",
      "\ttrain 8-236: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 8-237: Loss: 0.6322 Acc: 0.0000%\n",
      "\ttrain 8-238: Loss: 0.3725 Acc: 25.0000%\n",
      "\ttrain 8-239: Loss: 0.2056 Acc: 75.0000%\n",
      "\ttrain 8-240: Loss: 0.2679 Acc: 50.0000%\n",
      "\ttrain 8-241: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 8-242: Loss: 0.3813 Acc: 25.0000%\n",
      "\ttrain 8-243: Loss: 0.2777 Acc: 75.0000%\n",
      "\ttrain 8-244: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 8-245: Loss: 0.1774 Acc: 75.0000%\n",
      "\tvalidation 8-1: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 8-2: Loss: 0.0589 Acc: 75.0000%\n",
      "\tvalidation 8-3: Loss: 0.1283 Acc: 75.0000%\n",
      "\tvalidation 8-4: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 8-5: Loss: 0.1636 Acc: 50.0000%\n",
      "\tvalidation 8-6: Loss: 0.2274 Acc: 75.0000%\n",
      "\tvalidation 8-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-8: Loss: 0.1136 Acc: 75.0000%\n",
      "\tvalidation 8-9: Loss: 0.2855 Acc: 75.0000%\n",
      "\tvalidation 8-10: Loss: 0.1840 Acc: 50.0000%\n",
      "\tvalidation 8-11: Loss: 0.1716 Acc: 75.0000%\n",
      "\tvalidation 8-12: Loss: 0.1838 Acc: 50.0000%\n",
      "\tvalidation 8-13: Loss: 0.1430 Acc: 75.0000%\n",
      "\tvalidation 8-14: Loss: 0.2699 Acc: 75.0000%\n",
      "\tvalidation 8-15: Loss: 0.2130 Acc: 50.0000%\n",
      "\tvalidation 8-16: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 8-17: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 8-18: Loss: 0.0713 Acc: 100.0000%\n",
      "\tvalidation 8-19: Loss: 0.1169 Acc: 75.0000%\n",
      "\tvalidation 8-20: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 8-21: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 8-22: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 8-23: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 8-24: Loss: 0.1694 Acc: 50.0000%\n",
      "\tvalidation 8-25: Loss: 0.0878 Acc: 75.0000%\n",
      "\tvalidation 8-26: Loss: 0.0586 Acc: 75.0000%\n",
      "\tvalidation 8-27: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 8-28: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 8-29: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 8-30: Loss: 0.1499 Acc: 50.0000%\n",
      "\tvalidation 8-31: Loss: 0.1846 Acc: 50.0000%\n",
      "\tvalidation 8-32: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 8-33: Loss: 0.1397 Acc: 75.0000%\n",
      "\tvalidation 8-34: Loss: 0.2144 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 8-35: Loss: 0.2752 Acc: 50.0000%\n",
      "\tvalidation 8-36: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 8-37: Loss: 0.2093 Acc: 50.0000%\n",
      "\tvalidation 8-38: Loss: 0.3980 Acc: 75.0000%\n",
      "\tvalidation 8-39: Loss: 0.2871 Acc: 50.0000%\n",
      "\tvalidation 8-40: Loss: 0.2103 Acc: 75.0000%\n",
      "\tvalidation 8-41: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 8-42: Loss: 0.1549 Acc: 50.0000%\n",
      "\tvalidation 8-43: Loss: 0.0553 Acc: 100.0000%\n",
      "\tvalidation 8-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-45: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 8-46: Loss: 0.0576 Acc: 100.0000%\n",
      "\tvalidation 8-47: Loss: 1.2700 Acc: 75.0000%\n",
      "\tvalidation 8-48: Loss: 0.0530 Acc: 75.0000%\n",
      "\tvalidation 8-49: Loss: 0.0752 Acc: 75.0000%\n",
      "\tvalidation 8-50: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 8-51: Loss: 0.0616 Acc: 100.0000%\n",
      "\tvalidation 8-52: Loss: 0.1671 Acc: 50.0000%\n",
      "\tvalidation 8-53: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 8-54: Loss: 0.2072 Acc: 50.0000%\n",
      "\tvalidation 8-55: Loss: 0.2848 Acc: 25.0000%\n",
      "\tvalidation 8-56: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 8-57: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 8-58: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 8-59: Loss: 0.0994 Acc: 75.0000%\n",
      "\tvalidation 8-60: Loss: 0.3589 Acc: 50.0000%\n",
      "\tvalidation 8-61: Loss: 0.3176 Acc: 25.0000%\n",
      "\tvalidation 8-62: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 8-63: Loss: 0.5687 Acc: 25.0000%\n",
      "\tvalidation 8-64: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 8-65: Loss: 0.2027 Acc: 50.0000%\n",
      "\tvalidation 8-66: Loss: 0.4462 Acc: 75.0000%\n",
      "\tvalidation 8-67: Loss: 0.1405 Acc: 75.0000%\n",
      "\tvalidation 8-68: Loss: 0.0598 Acc: 75.0000%\n",
      "\tvalidation 8-69: Loss: 0.5053 Acc: 50.0000%\n",
      "\tvalidation 8-70: Loss: 0.2850 Acc: 25.0000%\n",
      "\tvalidation 8-71: Loss: 0.1252 Acc: 75.0000%\n",
      "\tvalidation 8-72: Loss: 0.1244 Acc: 75.0000%\n",
      "\tvalidation 8-73: Loss: 0.1894 Acc: 50.0000%\n",
      "\tvalidation 8-74: Loss: 0.1009 Acc: 75.0000%\n",
      "\tvalidation 8-75: Loss: 0.1458 Acc: 75.0000%\n",
      "\tvalidation 8-76: Loss: 0.7625 Acc: 50.0000%\n",
      "\tvalidation 8-77: Loss: 0.1231 Acc: 50.0000%\n",
      "\tvalidation 8-78: Loss: 0.0612 Acc: 100.0000%\n",
      "\tvalidation 8-79: Loss: 0.1091 Acc: 75.0000%\n",
      "\tvalidation 8-80: Loss: 0.0885 Acc: 75.0000%\n",
      "\tvalidation 8-81: Loss: 0.1418 Acc: 50.0000%\n",
      "\tvalidation 8-82: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 8-83: Loss: 0.0558 Acc: 100.0000%\n",
      "\tvalidation 8-84: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 8-85: Loss: 0.0679 Acc: 75.0000%\n",
      "\tvalidation 8-86: Loss: 2.1849 Acc: 25.0000%\n",
      "\tvalidation 8-87: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 8-88: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 8-89: Loss: 0.4752 Acc: 50.0000%\n",
      "\tvalidation 8-90: Loss: 0.0770 Acc: 75.0000%\n",
      "\tvalidation 8-91: Loss: 0.1638 Acc: 75.0000%\n",
      "\tvalidation 8-92: Loss: 0.0645 Acc: 75.0000%\n",
      "\tvalidation 8-93: Loss: 0.1478 Acc: 50.0000%\n",
      "\tvalidation 8-94: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 8-95: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 8-96: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 8-97: Loss: 0.1317 Acc: 75.0000%\n",
      "\tvalidation 8-98: Loss: 0.0867 Acc: 75.0000%\n",
      "\tvalidation 8-99: Loss: 1.6374 Acc: 50.0000%\n",
      "\tvalidation 8-100: Loss: 0.1079 Acc: 75.0000%\n",
      "\tvalidation 8-101: Loss: 0.1157 Acc: 75.0000%\n",
      "\tvalidation 8-102: Loss: 0.3775 Acc: 75.0000%\n",
      "\tvalidation 8-103: Loss: 0.0505 Acc: 100.0000%\n",
      "\tvalidation 8-104: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 8-105: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2139 Acc: 64.7959%\n",
      "\tvalidation Loss: 0.1775 Acc: 75.2381%\n",
      "网络参数更新\n",
      "Time passed 0h 8m 2s\n",
      "--------------------\n",
      "Epoch [9/40]:\n",
      "\ttrain 9-1: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 9-2: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 9-3: Loss: 0.3850 Acc: 25.0000%\n",
      "\ttrain 9-4: Loss: 0.1590 Acc: 50.0000%\n",
      "\ttrain 9-5: Loss: 0.3834 Acc: 50.0000%\n",
      "\ttrain 9-6: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 9-7: Loss: 0.1445 Acc: 75.0000%\n",
      "\ttrain 9-8: Loss: 0.2096 Acc: 50.0000%\n",
      "\ttrain 9-9: Loss: 0.2357 Acc: 50.0000%\n",
      "\ttrain 9-10: Loss: 0.2083 Acc: 75.0000%\n",
      "\ttrain 9-11: Loss: 0.2320 Acc: 50.0000%\n",
      "\ttrain 9-12: Loss: 0.1112 Acc: 100.0000%\n",
      "\ttrain 9-13: Loss: 0.1460 Acc: 50.0000%\n",
      "\ttrain 9-14: Loss: 0.3220 Acc: 25.0000%\n",
      "\ttrain 9-15: Loss: 0.4107 Acc: 25.0000%\n",
      "\ttrain 9-16: Loss: 0.4230 Acc: 50.0000%\n",
      "\ttrain 9-17: Loss: 0.2256 Acc: 75.0000%\n",
      "\ttrain 9-18: Loss: 0.3713 Acc: 50.0000%\n",
      "\ttrain 9-19: Loss: 0.2272 Acc: 50.0000%\n",
      "\ttrain 9-20: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 9-21: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 9-22: Loss: 0.3595 Acc: 50.0000%\n",
      "\ttrain 9-23: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 9-24: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 9-25: Loss: 0.3389 Acc: 50.0000%\n",
      "\ttrain 9-26: Loss: 0.4494 Acc: 50.0000%\n",
      "\ttrain 9-27: Loss: 0.1430 Acc: 50.0000%\n",
      "\ttrain 9-28: Loss: 0.3150 Acc: 75.0000%\n",
      "\ttrain 9-29: Loss: 0.1961 Acc: 75.0000%\n",
      "\ttrain 9-30: Loss: 0.2009 Acc: 75.0000%\n",
      "\ttrain 9-31: Loss: 0.2581 Acc: 50.0000%\n",
      "\ttrain 9-32: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 9-33: Loss: 0.2072 Acc: 50.0000%\n",
      "\ttrain 9-34: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 9-35: Loss: 0.1905 Acc: 50.0000%\n",
      "\ttrain 9-36: Loss: 0.3512 Acc: 75.0000%\n",
      "\ttrain 9-37: Loss: 0.6605 Acc: 25.0000%\n",
      "\ttrain 9-38: Loss: 0.4160 Acc: 50.0000%\n",
      "\ttrain 9-39: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 9-40: Loss: 0.2330 Acc: 75.0000%\n",
      "\ttrain 9-41: Loss: 0.6253 Acc: 50.0000%\n",
      "\ttrain 9-42: Loss: 0.1885 Acc: 75.0000%\n",
      "\ttrain 9-43: Loss: 0.1435 Acc: 75.0000%\n",
      "\ttrain 9-44: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 9-45: Loss: 0.2621 Acc: 75.0000%\n",
      "\ttrain 9-46: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 9-47: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 9-48: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 9-49: Loss: 0.1902 Acc: 75.0000%\n",
      "\ttrain 9-50: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 9-51: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 9-52: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 9-53: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 9-54: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 9-55: Loss: 0.1281 Acc: 50.0000%\n",
      "\ttrain 9-56: Loss: 0.1027 Acc: 100.0000%\n",
      "\ttrain 9-57: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 9-58: Loss: 0.2453 Acc: 50.0000%\n",
      "\ttrain 9-59: Loss: 0.3650 Acc: 50.0000%\n",
      "\ttrain 9-60: Loss: 0.1923 Acc: 50.0000%\n",
      "\ttrain 9-61: Loss: 0.1927 Acc: 50.0000%\n",
      "\ttrain 9-62: Loss: 0.1955 Acc: 75.0000%\n",
      "\ttrain 9-63: Loss: 0.2154 Acc: 75.0000%\n",
      "\ttrain 9-64: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 9-65: Loss: 0.3466 Acc: 0.0000%\n",
      "\ttrain 9-66: Loss: 0.1809 Acc: 25.0000%\n",
      "\ttrain 9-67: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 9-68: Loss: 0.5038 Acc: 25.0000%\n",
      "\ttrain 9-69: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 9-70: Loss: 0.4317 Acc: 25.0000%\n",
      "\ttrain 9-71: Loss: 0.3440 Acc: 50.0000%\n",
      "\ttrain 9-72: Loss: 0.2799 Acc: 50.0000%\n",
      "\ttrain 9-73: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 9-74: Loss: 0.2353 Acc: 50.0000%\n",
      "\ttrain 9-75: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 9-76: Loss: 0.2125 Acc: 50.0000%\n",
      "\ttrain 9-77: Loss: 0.1514 Acc: 75.0000%\n",
      "\ttrain 9-78: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 9-79: Loss: 0.2765 Acc: 50.0000%\n",
      "\ttrain 9-80: Loss: 0.4101 Acc: 25.0000%\n",
      "\ttrain 9-81: Loss: 0.4803 Acc: 25.0000%\n",
      "\ttrain 9-82: Loss: 0.1317 Acc: 100.0000%\n",
      "\ttrain 9-83: Loss: 0.2590 Acc: 50.0000%\n",
      "\ttrain 9-84: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 9-85: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 9-86: Loss: 0.0981 Acc: 100.0000%\n",
      "\ttrain 9-87: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 9-88: Loss: 0.2480 Acc: 50.0000%\n",
      "\ttrain 9-89: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 9-90: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 9-91: Loss: 0.2911 Acc: 50.0000%\n",
      "\ttrain 9-92: Loss: 0.4519 Acc: 0.0000%\n",
      "\ttrain 9-93: Loss: 0.2522 Acc: 75.0000%\n",
      "\ttrain 9-94: Loss: 0.3625 Acc: 50.0000%\n",
      "\ttrain 9-95: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 9-96: Loss: 0.2365 Acc: 75.0000%\n",
      "\ttrain 9-97: Loss: 0.7552 Acc: 25.0000%\n",
      "\ttrain 9-98: Loss: 0.2358 Acc: 50.0000%\n",
      "\ttrain 9-99: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 9-100: Loss: 0.1519 Acc: 50.0000%\n",
      "\ttrain 9-101: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 9-102: Loss: 0.2789 Acc: 50.0000%\n",
      "\ttrain 9-103: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 9-104: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 9-105: Loss: 0.2769 Acc: 75.0000%\n",
      "\ttrain 9-106: Loss: 0.5678 Acc: 50.0000%\n",
      "\ttrain 9-107: Loss: 0.2604 Acc: 50.0000%\n",
      "\ttrain 9-108: Loss: 0.2151 Acc: 50.0000%\n",
      "\ttrain 9-109: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 9-110: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 9-111: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 9-112: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 9-113: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 9-114: Loss: 0.1240 Acc: 50.0000%\n",
      "\ttrain 9-115: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 9-116: Loss: 0.3530 Acc: 75.0000%\n",
      "\ttrain 9-117: Loss: 0.3784 Acc: 50.0000%\n",
      "\ttrain 9-118: Loss: 0.1312 Acc: 50.0000%\n",
      "\ttrain 9-119: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 9-120: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 9-121: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 9-122: Loss: 0.0785 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 9-123: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 9-124: Loss: 0.1787 Acc: 75.0000%\n",
      "\ttrain 9-125: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 9-126: Loss: 0.2332 Acc: 75.0000%\n",
      "\ttrain 9-127: Loss: 0.2368 Acc: 75.0000%\n",
      "\ttrain 9-128: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 9-129: Loss: 0.0895 Acc: 100.0000%\n",
      "\ttrain 9-130: Loss: 0.2891 Acc: 75.0000%\n",
      "\ttrain 9-131: Loss: 0.4669 Acc: 25.0000%\n",
      "\ttrain 9-132: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 9-133: Loss: 0.3796 Acc: 50.0000%\n",
      "\ttrain 9-134: Loss: 0.1912 Acc: 75.0000%\n",
      "\ttrain 9-135: Loss: 0.3402 Acc: 50.0000%\n",
      "\ttrain 9-136: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 9-137: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 9-138: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 9-139: Loss: 0.1429 Acc: 50.0000%\n",
      "\ttrain 9-140: Loss: 0.2555 Acc: 75.0000%\n",
      "\ttrain 9-141: Loss: 0.6097 Acc: 0.0000%\n",
      "\ttrain 9-142: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 9-143: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 9-144: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 9-145: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 9-146: Loss: 0.2472 Acc: 25.0000%\n",
      "\ttrain 9-147: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 9-148: Loss: 0.2461 Acc: 50.0000%\n",
      "\ttrain 9-149: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 9-150: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 9-151: Loss: 0.1380 Acc: 50.0000%\n",
      "\ttrain 9-152: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 9-153: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 9-154: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 9-155: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 9-156: Loss: 0.3963 Acc: 50.0000%\n",
      "\ttrain 9-157: Loss: 0.3997 Acc: 25.0000%\n",
      "\ttrain 9-158: Loss: 0.3432 Acc: 50.0000%\n",
      "\ttrain 9-159: Loss: 0.2236 Acc: 50.0000%\n",
      "\ttrain 9-160: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 9-161: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 9-162: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 9-163: Loss: 0.2159 Acc: 50.0000%\n",
      "\ttrain 9-164: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 9-165: Loss: 0.0837 Acc: 100.0000%\n",
      "\ttrain 9-166: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 9-167: Loss: 0.5499 Acc: 25.0000%\n",
      "\ttrain 9-168: Loss: 0.1836 Acc: 50.0000%\n",
      "\ttrain 9-169: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 9-170: Loss: 0.7440 Acc: 25.0000%\n",
      "\ttrain 9-171: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 9-172: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 9-173: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 9-174: Loss: 0.2072 Acc: 25.0000%\n",
      "\ttrain 9-175: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 9-176: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 9-177: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 9-178: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 9-179: Loss: 0.2650 Acc: 75.0000%\n",
      "\ttrain 9-180: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 9-181: Loss: 0.4492 Acc: 25.0000%\n",
      "\ttrain 9-182: Loss: 0.1286 Acc: 50.0000%\n",
      "\ttrain 9-183: Loss: 0.0871 Acc: 100.0000%\n",
      "\ttrain 9-184: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 9-185: Loss: 0.1134 Acc: 100.0000%\n",
      "\ttrain 9-186: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 9-187: Loss: 0.5672 Acc: 50.0000%\n",
      "\ttrain 9-188: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 9-189: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 9-190: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 9-191: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 9-192: Loss: 0.1777 Acc: 50.0000%\n",
      "\ttrain 9-193: Loss: 1.1481 Acc: 0.0000%\n",
      "\ttrain 9-194: Loss: 0.4152 Acc: 0.0000%\n",
      "\ttrain 9-195: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 9-196: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 9-197: Loss: 0.3284 Acc: 25.0000%\n",
      "\ttrain 9-198: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 9-199: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 9-200: Loss: 0.0699 Acc: 100.0000%\n",
      "\ttrain 9-201: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 9-202: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 9-203: Loss: 0.0769 Acc: 100.0000%\n",
      "\ttrain 9-204: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 9-205: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 9-206: Loss: 0.3351 Acc: 25.0000%\n",
      "\ttrain 9-207: Loss: 0.2594 Acc: 50.0000%\n",
      "\ttrain 9-208: Loss: 0.5508 Acc: 0.0000%\n",
      "\ttrain 9-209: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 9-210: Loss: 0.1736 Acc: 75.0000%\n",
      "\ttrain 9-211: Loss: 0.2442 Acc: 50.0000%\n",
      "\ttrain 9-212: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 9-213: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 9-214: Loss: 0.1470 Acc: 75.0000%\n",
      "\ttrain 9-215: Loss: 0.2063 Acc: 50.0000%\n",
      "\ttrain 9-216: Loss: 0.1428 Acc: 100.0000%\n",
      "\ttrain 9-217: Loss: 0.3102 Acc: 75.0000%\n",
      "\ttrain 9-218: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 9-219: Loss: 0.2045 Acc: 50.0000%\n",
      "\ttrain 9-220: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 9-221: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 9-222: Loss: 0.2956 Acc: 25.0000%\n",
      "\ttrain 9-223: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 9-224: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 9-225: Loss: 0.1809 Acc: 50.0000%\n",
      "\ttrain 9-226: Loss: 0.1857 Acc: 75.0000%\n",
      "\ttrain 9-227: Loss: 0.3620 Acc: 25.0000%\n",
      "\ttrain 9-228: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 9-229: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 9-230: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 9-231: Loss: 0.2751 Acc: 75.0000%\n",
      "\ttrain 9-232: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 9-233: Loss: 0.7284 Acc: 25.0000%\n",
      "\ttrain 9-234: Loss: 0.4223 Acc: 50.0000%\n",
      "\ttrain 9-235: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 9-236: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 9-237: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 9-238: Loss: 0.3352 Acc: 50.0000%\n",
      "\ttrain 9-239: Loss: 0.2158 Acc: 75.0000%\n",
      "\ttrain 9-240: Loss: 0.2614 Acc: 75.0000%\n",
      "\ttrain 9-241: Loss: 0.4019 Acc: 25.0000%\n",
      "\ttrain 9-242: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 9-243: Loss: 0.3412 Acc: 75.0000%\n",
      "\ttrain 9-244: Loss: 0.5126 Acc: 50.0000%\n",
      "\ttrain 9-245: Loss: 0.2454 Acc: 50.0000%\n",
      "\tvalidation 9-1: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 9-2: Loss: 0.1251 Acc: 75.0000%\n",
      "\tvalidation 9-3: Loss: 0.1148 Acc: 50.0000%\n",
      "\tvalidation 9-4: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 9-5: Loss: 0.0350 Acc: 100.0000%\n",
      "\tvalidation 9-6: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 9-7: Loss: 0.1297 Acc: 75.0000%\n",
      "\tvalidation 9-8: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 9-9: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 9-10: Loss: 0.1049 Acc: 100.0000%\n",
      "\tvalidation 9-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-12: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 9-13: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 9-14: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 9-15: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 9-16: Loss: 0.1784 Acc: 50.0000%\n",
      "\tvalidation 9-17: Loss: 0.0983 Acc: 75.0000%\n",
      "\tvalidation 9-18: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 9-19: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 9-20: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 9-21: Loss: 0.1067 Acc: 75.0000%\n",
      "\tvalidation 9-22: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 9-23: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 9-24: Loss: 0.0718 Acc: 100.0000%\n",
      "\tvalidation 9-25: Loss: 0.0775 Acc: 100.0000%\n",
      "\tvalidation 9-26: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 9-27: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 9-28: Loss: 0.1117 Acc: 75.0000%\n",
      "\tvalidation 9-29: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 9-30: Loss: 0.1569 Acc: 50.0000%\n",
      "\tvalidation 9-31: Loss: 0.0847 Acc: 75.0000%\n",
      "\tvalidation 9-32: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 9-33: Loss: 0.0480 Acc: 100.0000%\n",
      "\tvalidation 9-34: Loss: 0.1039 Acc: 75.0000%\n",
      "\tvalidation 9-35: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 9-36: Loss: 0.0782 Acc: 75.0000%\n",
      "\tvalidation 9-37: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 9-38: Loss: 0.0520 Acc: 100.0000%\n",
      "\tvalidation 9-39: Loss: 0.1496 Acc: 75.0000%\n",
      "\tvalidation 9-40: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 9-41: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 9-42: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 9-43: Loss: 0.1120 Acc: 75.0000%\n",
      "\tvalidation 9-44: Loss: 0.1451 Acc: 75.0000%\n",
      "\tvalidation 9-45: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 9-46: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 9-47: Loss: 0.0591 Acc: 100.0000%\n",
      "\tvalidation 9-48: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 9-49: Loss: 0.1023 Acc: 75.0000%\n",
      "\tvalidation 9-50: Loss: 0.0819 Acc: 100.0000%\n",
      "\tvalidation 9-51: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 9-52: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 9-53: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 9-54: Loss: 0.0520 Acc: 100.0000%\n",
      "\tvalidation 9-55: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 9-56: Loss: 0.0591 Acc: 75.0000%\n",
      "\tvalidation 9-57: Loss: 0.1896 Acc: 75.0000%\n",
      "\tvalidation 9-58: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 9-59: Loss: 0.0511 Acc: 75.0000%\n",
      "\tvalidation 9-60: Loss: 0.0416 Acc: 100.0000%\n",
      "\tvalidation 9-61: Loss: 0.0724 Acc: 100.0000%\n",
      "\tvalidation 9-62: Loss: 0.1501 Acc: 50.0000%\n",
      "\tvalidation 9-63: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 9-64: Loss: 0.0627 Acc: 100.0000%\n",
      "\tvalidation 9-65: Loss: 0.0552 Acc: 100.0000%\n",
      "\tvalidation 9-66: Loss: 0.0933 Acc: 75.0000%\n",
      "\tvalidation 9-67: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 9-68: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 9-69: Loss: 0.1672 Acc: 50.0000%\n",
      "\tvalidation 9-70: Loss: 0.0403 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 9-71: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 9-72: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 9-73: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 9-74: Loss: 0.1048 Acc: 75.0000%\n",
      "\tvalidation 9-75: Loss: 0.0778 Acc: 75.0000%\n",
      "\tvalidation 9-76: Loss: 0.0437 Acc: 100.0000%\n",
      "\tvalidation 9-77: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 9-78: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 9-79: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 9-80: Loss: 0.0865 Acc: 75.0000%\n",
      "\tvalidation 9-81: Loss: 0.0841 Acc: 100.0000%\n",
      "\tvalidation 9-82: Loss: 0.0493 Acc: 100.0000%\n",
      "\tvalidation 9-83: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 9-84: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 9-85: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 9-86: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 9-87: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 9-88: Loss: 0.1099 Acc: 75.0000%\n",
      "\tvalidation 9-89: Loss: 0.1232 Acc: 50.0000%\n",
      "\tvalidation 9-90: Loss: 0.1615 Acc: 50.0000%\n",
      "\tvalidation 9-91: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 9-92: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 9-93: Loss: 0.1247 Acc: 50.0000%\n",
      "\tvalidation 9-94: Loss: 0.1307 Acc: 75.0000%\n",
      "\tvalidation 9-95: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 9-96: Loss: 0.0869 Acc: 75.0000%\n",
      "\tvalidation 9-97: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 9-98: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 9-99: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 9-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-101: Loss: 0.0756 Acc: 100.0000%\n",
      "\tvalidation 9-102: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 9-103: Loss: 0.0508 Acc: 100.0000%\n",
      "\tvalidation 9-104: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 9-105: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain Loss: 0.2020 Acc: 67.6531%\n",
      "\tvalidation Loss: 0.0591 Acc: 90.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 9m 5s\n",
      "--------------------\n",
      "Epoch [10/40]:\n",
      "\ttrain 10-1: Loss: 0.1215 Acc: 75.0000%\n",
      "\ttrain 10-2: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 10-3: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 10-4: Loss: 0.2873 Acc: 50.0000%\n",
      "\ttrain 10-5: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 10-6: Loss: 0.1266 Acc: 50.0000%\n",
      "\ttrain 10-7: Loss: 0.1151 Acc: 100.0000%\n",
      "\ttrain 10-8: Loss: 0.6157 Acc: 50.0000%\n",
      "\ttrain 10-9: Loss: 0.2274 Acc: 50.0000%\n",
      "\ttrain 10-10: Loss: 0.2720 Acc: 50.0000%\n",
      "\ttrain 10-11: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 10-12: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 10-13: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 10-14: Loss: 0.0522 Acc: 75.0000%\n",
      "\ttrain 10-15: Loss: 0.1855 Acc: 75.0000%\n",
      "\ttrain 10-16: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 10-17: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 10-18: Loss: 0.3758 Acc: 25.0000%\n",
      "\ttrain 10-19: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 10-20: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 10-21: Loss: 0.0824 Acc: 100.0000%\n",
      "\ttrain 10-22: Loss: 0.4528 Acc: 50.0000%\n",
      "\ttrain 10-23: Loss: 0.2671 Acc: 75.0000%\n",
      "\ttrain 10-24: Loss: 0.2118 Acc: 75.0000%\n",
      "\ttrain 10-25: Loss: 0.2079 Acc: 50.0000%\n",
      "\ttrain 10-26: Loss: 0.1942 Acc: 50.0000%\n",
      "\ttrain 10-27: Loss: 0.2727 Acc: 50.0000%\n",
      "\ttrain 10-28: Loss: 0.2254 Acc: 50.0000%\n",
      "\ttrain 10-29: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 10-30: Loss: 0.2865 Acc: 25.0000%\n",
      "\ttrain 10-31: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 10-32: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 10-33: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 10-34: Loss: 0.2381 Acc: 25.0000%\n",
      "\ttrain 10-35: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 10-36: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 10-37: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 10-38: Loss: 0.1408 Acc: 50.0000%\n",
      "\ttrain 10-39: Loss: 0.0696 Acc: 75.0000%\n",
      "\ttrain 10-40: Loss: 0.4128 Acc: 25.0000%\n",
      "\ttrain 10-41: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 10-42: Loss: 0.5138 Acc: 50.0000%\n",
      "\ttrain 10-43: Loss: 0.3396 Acc: 50.0000%\n",
      "\ttrain 10-44: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 10-45: Loss: 0.5406 Acc: 25.0000%\n",
      "\ttrain 10-46: Loss: 0.3153 Acc: 75.0000%\n",
      "\ttrain 10-47: Loss: 0.1757 Acc: 50.0000%\n",
      "\ttrain 10-48: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 10-49: Loss: 0.2343 Acc: 75.0000%\n",
      "\ttrain 10-50: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 10-51: Loss: 0.3506 Acc: 50.0000%\n",
      "\ttrain 10-52: Loss: 0.1344 Acc: 50.0000%\n",
      "\ttrain 10-53: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 10-54: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 10-55: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 10-56: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 10-57: Loss: 0.1784 Acc: 50.0000%\n",
      "\ttrain 10-58: Loss: 0.1721 Acc: 50.0000%\n",
      "\ttrain 10-59: Loss: 0.2074 Acc: 50.0000%\n",
      "\ttrain 10-60: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 10-61: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 10-62: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 10-63: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 10-64: Loss: 0.4262 Acc: 50.0000%\n",
      "\ttrain 10-65: Loss: 0.3333 Acc: 50.0000%\n",
      "\ttrain 10-66: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 10-67: Loss: 0.4106 Acc: 50.0000%\n",
      "\ttrain 10-68: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 10-69: Loss: 0.0693 Acc: 75.0000%\n",
      "\ttrain 10-70: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 10-71: Loss: 0.2060 Acc: 75.0000%\n",
      "\ttrain 10-72: Loss: 0.3150 Acc: 75.0000%\n",
      "\ttrain 10-73: Loss: 0.1072 Acc: 100.0000%\n",
      "\ttrain 10-74: Loss: 0.2727 Acc: 25.0000%\n",
      "\ttrain 10-75: Loss: 0.1582 Acc: 50.0000%\n",
      "\ttrain 10-76: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 10-77: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 10-78: Loss: 0.1972 Acc: 50.0000%\n",
      "\ttrain 10-79: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 10-80: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 10-81: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 10-82: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 10-83: Loss: 0.1688 Acc: 50.0000%\n",
      "\ttrain 10-84: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 10-85: Loss: 0.6291 Acc: 50.0000%\n",
      "\ttrain 10-86: Loss: 0.1791 Acc: 75.0000%\n",
      "\ttrain 10-87: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 10-88: Loss: 0.0672 Acc: 100.0000%\n",
      "\ttrain 10-89: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 10-90: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 10-91: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 10-92: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 10-93: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 10-94: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 10-95: Loss: 0.1672 Acc: 75.0000%\n",
      "\ttrain 10-96: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 10-97: Loss: 0.2202 Acc: 75.0000%\n",
      "\ttrain 10-98: Loss: 0.2332 Acc: 50.0000%\n",
      "\ttrain 10-99: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 10-100: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 10-101: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 10-102: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 10-103: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 10-104: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 10-105: Loss: 0.3357 Acc: 25.0000%\n",
      "\ttrain 10-106: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 10-107: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 10-108: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 10-109: Loss: 0.2657 Acc: 50.0000%\n",
      "\ttrain 10-110: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 10-111: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 10-112: Loss: 0.2274 Acc: 50.0000%\n",
      "\ttrain 10-113: Loss: 0.1845 Acc: 50.0000%\n",
      "\ttrain 10-114: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 10-115: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 10-116: Loss: 0.1583 Acc: 75.0000%\n",
      "\ttrain 10-117: Loss: 0.1025 Acc: 50.0000%\n",
      "\ttrain 10-118: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 10-119: Loss: 0.4655 Acc: 25.0000%\n",
      "\ttrain 10-120: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 10-121: Loss: 0.1569 Acc: 50.0000%\n",
      "\ttrain 10-122: Loss: 0.2738 Acc: 25.0000%\n",
      "\ttrain 10-123: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 10-124: Loss: 0.2084 Acc: 75.0000%\n",
      "\ttrain 10-125: Loss: 0.5214 Acc: 0.0000%\n",
      "\ttrain 10-126: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 10-127: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 10-128: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 10-129: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 10-130: Loss: 0.1531 Acc: 75.0000%\n",
      "\ttrain 10-131: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 10-132: Loss: 0.4764 Acc: 50.0000%\n",
      "\ttrain 10-133: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 10-134: Loss: 0.3064 Acc: 25.0000%\n",
      "\ttrain 10-135: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 10-136: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 10-137: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 10-138: Loss: 0.4552 Acc: 25.0000%\n",
      "\ttrain 10-139: Loss: 0.2864 Acc: 50.0000%\n",
      "\ttrain 10-140: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 10-141: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 10-142: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 10-143: Loss: 0.2899 Acc: 50.0000%\n",
      "\ttrain 10-144: Loss: 0.1973 Acc: 50.0000%\n",
      "\ttrain 10-145: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 10-146: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 10-147: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 10-148: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 10-149: Loss: 0.1528 Acc: 75.0000%\n",
      "\ttrain 10-150: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 10-151: Loss: 0.7850 Acc: 0.0000%\n",
      "\ttrain 10-152: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 10-153: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 10-154: Loss: 0.1763 Acc: 50.0000%\n",
      "\ttrain 10-155: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 10-156: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 10-157: Loss: 0.2003 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 10-158: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 10-159: Loss: 0.1815 Acc: 75.0000%\n",
      "\ttrain 10-160: Loss: 0.2314 Acc: 75.0000%\n",
      "\ttrain 10-161: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 10-162: Loss: 0.1660 Acc: 75.0000%\n",
      "\ttrain 10-163: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 10-164: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 10-165: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 10-166: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 10-167: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 10-168: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 10-169: Loss: 0.2183 Acc: 50.0000%\n",
      "\ttrain 10-170: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 10-171: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 10-172: Loss: 0.1668 Acc: 50.0000%\n",
      "\ttrain 10-173: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 10-174: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 10-175: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 10-176: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 10-177: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 10-178: Loss: 0.0484 Acc: 75.0000%\n",
      "\ttrain 10-179: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 10-180: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 10-181: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 10-182: Loss: 0.5179 Acc: 0.0000%\n",
      "\ttrain 10-183: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 10-184: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 10-185: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 10-186: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 10-187: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 10-188: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 10-189: Loss: 0.1224 Acc: 75.0000%\n",
      "\ttrain 10-190: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 10-191: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 10-192: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 10-193: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 10-194: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 10-195: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 10-196: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 10-197: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 10-198: Loss: 0.3830 Acc: 50.0000%\n",
      "\ttrain 10-199: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 10-200: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 10-201: Loss: 0.5234 Acc: 50.0000%\n",
      "\ttrain 10-202: Loss: 0.4026 Acc: 75.0000%\n",
      "\ttrain 10-203: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 10-204: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 10-205: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 10-206: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 10-207: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 10-208: Loss: 0.1854 Acc: 75.0000%\n",
      "\ttrain 10-209: Loss: 0.1761 Acc: 75.0000%\n",
      "\ttrain 10-210: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 10-211: Loss: 0.3096 Acc: 75.0000%\n",
      "\ttrain 10-212: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 10-213: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 10-214: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 10-215: Loss: 0.1695 Acc: 50.0000%\n",
      "\ttrain 10-216: Loss: 0.1811 Acc: 50.0000%\n",
      "\ttrain 10-217: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 10-218: Loss: 0.3418 Acc: 25.0000%\n",
      "\ttrain 10-219: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 10-220: Loss: 0.2538 Acc: 75.0000%\n",
      "\ttrain 10-221: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 10-222: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 10-223: Loss: 0.4835 Acc: 25.0000%\n",
      "\ttrain 10-224: Loss: 0.4775 Acc: 50.0000%\n",
      "\ttrain 10-225: Loss: 0.5559 Acc: 50.0000%\n",
      "\ttrain 10-226: Loss: 0.6242 Acc: 25.0000%\n",
      "\ttrain 10-227: Loss: 0.2168 Acc: 50.0000%\n",
      "\ttrain 10-228: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 10-229: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 10-230: Loss: 0.1867 Acc: 75.0000%\n",
      "\ttrain 10-231: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 10-232: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 10-233: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 10-234: Loss: 0.3200 Acc: 75.0000%\n",
      "\ttrain 10-235: Loss: 0.1514 Acc: 50.0000%\n",
      "\ttrain 10-236: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 10-237: Loss: 1.0262 Acc: 0.0000%\n",
      "\ttrain 10-238: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 10-239: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 10-240: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 10-241: Loss: 0.1853 Acc: 75.0000%\n",
      "\ttrain 10-242: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 10-243: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 10-244: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 10-245: Loss: 0.2401 Acc: 75.0000%\n",
      "\tvalidation 10-1: Loss: 0.2619 Acc: 50.0000%\n",
      "\tvalidation 10-2: Loss: 0.6956 Acc: 50.0000%\n",
      "\tvalidation 10-3: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 10-4: Loss: 0.0410 Acc: 100.0000%\n",
      "\tvalidation 10-5: Loss: 0.2054 Acc: 75.0000%\n",
      "\tvalidation 10-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 10-7: Loss: 0.2434 Acc: 75.0000%\n",
      "\tvalidation 10-8: Loss: 0.7827 Acc: 75.0000%\n",
      "\tvalidation 10-9: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 10-10: Loss: 0.4324 Acc: 50.0000%\n",
      "\tvalidation 10-11: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 10-12: Loss: 0.1168 Acc: 75.0000%\n",
      "\tvalidation 10-13: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 10-14: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 10-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 10-16: Loss: 0.1486 Acc: 50.0000%\n",
      "\tvalidation 10-17: Loss: 0.3161 Acc: 50.0000%\n",
      "\tvalidation 10-18: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 10-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 10-20: Loss: 0.1437 Acc: 75.0000%\n",
      "\tvalidation 10-21: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 10-22: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 10-23: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 10-24: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 10-25: Loss: 0.1216 Acc: 75.0000%\n",
      "\tvalidation 10-26: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 10-27: Loss: 0.1529 Acc: 75.0000%\n",
      "\tvalidation 10-28: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 10-29: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 10-30: Loss: 0.1870 Acc: 75.0000%\n",
      "\tvalidation 10-31: Loss: 0.2731 Acc: 50.0000%\n",
      "\tvalidation 10-32: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 10-33: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 10-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 10-35: Loss: 0.1159 Acc: 75.0000%\n",
      "\tvalidation 10-36: Loss: 0.1085 Acc: 75.0000%\n",
      "\tvalidation 10-37: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 10-38: Loss: 0.1865 Acc: 50.0000%\n",
      "\tvalidation 10-39: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 10-40: Loss: 0.5141 Acc: 75.0000%\n",
      "\tvalidation 10-41: Loss: 0.6206 Acc: 50.0000%\n",
      "\tvalidation 10-42: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 10-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 10-44: Loss: 0.1742 Acc: 75.0000%\n",
      "\tvalidation 10-45: Loss: 0.2064 Acc: 75.0000%\n",
      "\tvalidation 10-46: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 10-47: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 10-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 10-49: Loss: 0.1373 Acc: 75.0000%\n",
      "\tvalidation 10-50: Loss: 0.1211 Acc: 75.0000%\n",
      "\tvalidation 10-51: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 10-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 10-53: Loss: 0.2529 Acc: 75.0000%\n",
      "\tvalidation 10-54: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 10-55: Loss: 0.9414 Acc: 25.0000%\n",
      "\tvalidation 10-56: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 10-57: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 10-58: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 10-59: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 10-60: Loss: 0.6460 Acc: 25.0000%\n",
      "\tvalidation 10-61: Loss: 0.1897 Acc: 75.0000%\n",
      "\tvalidation 10-62: Loss: 0.7065 Acc: 75.0000%\n",
      "\tvalidation 10-63: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 10-64: Loss: 0.3402 Acc: 75.0000%\n",
      "\tvalidation 10-65: Loss: 1.2654 Acc: 25.0000%\n",
      "\tvalidation 10-66: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 10-67: Loss: 0.1462 Acc: 75.0000%\n",
      "\tvalidation 10-68: Loss: 1.5026 Acc: 50.0000%\n",
      "\tvalidation 10-69: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 10-70: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 10-71: Loss: 0.1864 Acc: 75.0000%\n",
      "\tvalidation 10-72: Loss: 0.0876 Acc: 75.0000%\n",
      "\tvalidation 10-73: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 10-74: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 10-75: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 10-76: Loss: 0.1097 Acc: 75.0000%\n",
      "\tvalidation 10-77: Loss: 0.6381 Acc: 50.0000%\n",
      "\tvalidation 10-78: Loss: 0.2755 Acc: 50.0000%\n",
      "\tvalidation 10-79: Loss: 0.3972 Acc: 50.0000%\n",
      "\tvalidation 10-80: Loss: 0.2029 Acc: 50.0000%\n",
      "\tvalidation 10-81: Loss: 0.5025 Acc: 25.0000%\n",
      "\tvalidation 10-82: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 10-83: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 10-84: Loss: 0.3236 Acc: 75.0000%\n",
      "\tvalidation 10-85: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 10-86: Loss: 0.7797 Acc: 50.0000%\n",
      "\tvalidation 10-87: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 10-88: Loss: 0.2550 Acc: 50.0000%\n",
      "\tvalidation 10-89: Loss: 0.4587 Acc: 50.0000%\n",
      "\tvalidation 10-90: Loss: 0.3651 Acc: 75.0000%\n",
      "\tvalidation 10-91: Loss: 0.3038 Acc: 75.0000%\n",
      "\tvalidation 10-92: Loss: 0.2385 Acc: 50.0000%\n",
      "\tvalidation 10-93: Loss: 0.0565 Acc: 75.0000%\n",
      "\tvalidation 10-94: Loss: 0.4265 Acc: 75.0000%\n",
      "\tvalidation 10-95: Loss: 0.2484 Acc: 75.0000%\n",
      "\tvalidation 10-96: Loss: 0.1455 Acc: 75.0000%\n",
      "\tvalidation 10-97: Loss: 0.0361 Acc: 100.0000%\n",
      "\tvalidation 10-98: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 10-99: Loss: 0.1415 Acc: 75.0000%\n",
      "\tvalidation 10-100: Loss: 0.1245 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 10-101: Loss: 0.6365 Acc: 75.0000%\n",
      "\tvalidation 10-102: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 10-103: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 10-104: Loss: 0.2097 Acc: 75.0000%\n",
      "\tvalidation 10-105: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1558 Acc: 74.8980%\n",
      "\tvalidation Loss: 0.1920 Acc: 80.0000%\n",
      "Time passed 0h 10m 17s\n",
      "--------------------\n",
      "Epoch [11/40]:\n",
      "\ttrain 11-1: Loss: 0.7342 Acc: 25.0000%\n",
      "\ttrain 11-2: Loss: 0.5789 Acc: 25.0000%\n",
      "\ttrain 11-3: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 11-4: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 11-5: Loss: 0.3562 Acc: 50.0000%\n",
      "\ttrain 11-6: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 11-7: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 11-8: Loss: 0.3542 Acc: 50.0000%\n",
      "\ttrain 11-9: Loss: 0.3788 Acc: 75.0000%\n",
      "\ttrain 11-10: Loss: 0.5357 Acc: 50.0000%\n",
      "\ttrain 11-11: Loss: 0.3651 Acc: 50.0000%\n",
      "\ttrain 11-12: Loss: 0.2400 Acc: 75.0000%\n",
      "\ttrain 11-13: Loss: 0.1523 Acc: 100.0000%\n",
      "\ttrain 11-14: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 11-15: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 11-16: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 11-17: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 11-18: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 11-19: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 11-20: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 11-21: Loss: 0.2707 Acc: 75.0000%\n",
      "\ttrain 11-22: Loss: 0.1553 Acc: 75.0000%\n",
      "\ttrain 11-23: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 11-24: Loss: 0.5012 Acc: 50.0000%\n",
      "\ttrain 11-25: Loss: 0.1986 Acc: 50.0000%\n",
      "\ttrain 11-26: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 11-27: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 11-28: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 11-29: Loss: 0.3291 Acc: 50.0000%\n",
      "\ttrain 11-30: Loss: 0.3979 Acc: 50.0000%\n",
      "\ttrain 11-31: Loss: 0.3357 Acc: 75.0000%\n",
      "\ttrain 11-32: Loss: 0.2029 Acc: 75.0000%\n",
      "\ttrain 11-33: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 11-34: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 11-35: Loss: 0.2502 Acc: 50.0000%\n",
      "\ttrain 11-36: Loss: 0.2604 Acc: 50.0000%\n",
      "\ttrain 11-37: Loss: 0.2551 Acc: 75.0000%\n",
      "\ttrain 11-38: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 11-39: Loss: 0.4035 Acc: 50.0000%\n",
      "\ttrain 11-40: Loss: 0.2821 Acc: 50.0000%\n",
      "\ttrain 11-41: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 11-42: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 11-43: Loss: 0.7747 Acc: 25.0000%\n",
      "\ttrain 11-44: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 11-45: Loss: 0.2286 Acc: 75.0000%\n",
      "\ttrain 11-46: Loss: 0.2878 Acc: 25.0000%\n",
      "\ttrain 11-47: Loss: 0.1353 Acc: 50.0000%\n",
      "\ttrain 11-48: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 11-49: Loss: 0.6510 Acc: 25.0000%\n",
      "\ttrain 11-50: Loss: 0.2654 Acc: 50.0000%\n",
      "\ttrain 11-51: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 11-52: Loss: 0.1985 Acc: 50.0000%\n",
      "\ttrain 11-53: Loss: 0.1931 Acc: 75.0000%\n",
      "\ttrain 11-54: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 11-55: Loss: 0.4372 Acc: 50.0000%\n",
      "\ttrain 11-56: Loss: 0.3062 Acc: 75.0000%\n",
      "\ttrain 11-57: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 11-58: Loss: 0.2922 Acc: 75.0000%\n",
      "\ttrain 11-59: Loss: 0.5356 Acc: 25.0000%\n",
      "\ttrain 11-60: Loss: 0.6076 Acc: 25.0000%\n",
      "\ttrain 11-61: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 11-62: Loss: 0.2794 Acc: 50.0000%\n",
      "\ttrain 11-63: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 11-64: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 11-65: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 11-66: Loss: 0.0737 Acc: 75.0000%\n",
      "\ttrain 11-67: Loss: 0.5892 Acc: 50.0000%\n",
      "\ttrain 11-68: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 11-69: Loss: 0.2152 Acc: 75.0000%\n",
      "\ttrain 11-70: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 11-71: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 11-72: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 11-73: Loss: 0.1165 Acc: 50.0000%\n",
      "\ttrain 11-74: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 11-75: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 11-76: Loss: 0.1100 Acc: 75.0000%\n",
      "\ttrain 11-77: Loss: 0.1766 Acc: 75.0000%\n",
      "\ttrain 11-78: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 11-79: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 11-80: Loss: 0.1594 Acc: 50.0000%\n",
      "\ttrain 11-81: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 11-82: Loss: 0.0778 Acc: 100.0000%\n",
      "\ttrain 11-83: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 11-84: Loss: 0.2272 Acc: 50.0000%\n",
      "\ttrain 11-85: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 11-86: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 11-87: Loss: 0.4675 Acc: 50.0000%\n",
      "\ttrain 11-88: Loss: 0.1469 Acc: 75.0000%\n",
      "\ttrain 11-89: Loss: 0.2014 Acc: 75.0000%\n",
      "\ttrain 11-90: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 11-91: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 11-92: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 11-93: Loss: 0.2366 Acc: 75.0000%\n",
      "\ttrain 11-94: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 11-95: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 11-96: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 11-97: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 11-98: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 11-99: Loss: 0.1455 Acc: 50.0000%\n",
      "\ttrain 11-100: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 11-101: Loss: 0.5782 Acc: 25.0000%\n",
      "\ttrain 11-102: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 11-103: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 11-104: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 11-105: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 11-106: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 11-107: Loss: 0.1974 Acc: 75.0000%\n",
      "\ttrain 11-108: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 11-109: Loss: 0.1371 Acc: 75.0000%\n",
      "\ttrain 11-110: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 11-111: Loss: 0.2148 Acc: 75.0000%\n",
      "\ttrain 11-112: Loss: 0.3317 Acc: 75.0000%\n",
      "\ttrain 11-113: Loss: 0.2379 Acc: 75.0000%\n",
      "\ttrain 11-114: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 11-115: Loss: 0.5109 Acc: 25.0000%\n",
      "\ttrain 11-116: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 11-117: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 11-118: Loss: 0.1771 Acc: 75.0000%\n",
      "\ttrain 11-119: Loss: 0.1453 Acc: 75.0000%\n",
      "\ttrain 11-120: Loss: 0.1235 Acc: 75.0000%\n",
      "\ttrain 11-121: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 11-122: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 11-123: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 11-124: Loss: 0.0774 Acc: 100.0000%\n",
      "\ttrain 11-125: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 11-126: Loss: 0.2593 Acc: 50.0000%\n",
      "\ttrain 11-127: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 11-128: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 11-129: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 11-130: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 11-131: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 11-132: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 11-133: Loss: 0.2977 Acc: 75.0000%\n",
      "\ttrain 11-134: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 11-135: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 11-136: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 11-137: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 11-138: Loss: 0.3779 Acc: 75.0000%\n",
      "\ttrain 11-139: Loss: 0.1600 Acc: 50.0000%\n",
      "\ttrain 11-140: Loss: 0.1405 Acc: 75.0000%\n",
      "\ttrain 11-141: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 11-142: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 11-143: Loss: 0.1674 Acc: 50.0000%\n",
      "\ttrain 11-144: Loss: 0.1958 Acc: 75.0000%\n",
      "\ttrain 11-145: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 11-146: Loss: 0.1358 Acc: 75.0000%\n",
      "\ttrain 11-147: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 11-148: Loss: 0.2066 Acc: 75.0000%\n",
      "\ttrain 11-149: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 11-150: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 11-151: Loss: 0.0687 Acc: 100.0000%\n",
      "\ttrain 11-152: Loss: 0.4097 Acc: 50.0000%\n",
      "\ttrain 11-153: Loss: 0.1067 Acc: 100.0000%\n",
      "\ttrain 11-154: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 11-155: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 11-156: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 11-157: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 11-158: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 11-159: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 11-160: Loss: 0.2849 Acc: 25.0000%\n",
      "\ttrain 11-161: Loss: 0.1986 Acc: 50.0000%\n",
      "\ttrain 11-162: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 11-163: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 11-164: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 11-165: Loss: 0.2289 Acc: 75.0000%\n",
      "\ttrain 11-166: Loss: 0.3263 Acc: 50.0000%\n",
      "\ttrain 11-167: Loss: 0.1768 Acc: 75.0000%\n",
      "\ttrain 11-168: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 11-169: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 11-170: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 11-171: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 11-172: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 11-173: Loss: 0.3602 Acc: 50.0000%\n",
      "\ttrain 11-174: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 11-175: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 11-176: Loss: 0.2363 Acc: 75.0000%\n",
      "\ttrain 11-177: Loss: 0.1522 Acc: 50.0000%\n",
      "\ttrain 11-178: Loss: 0.1052 Acc: 100.0000%\n",
      "\ttrain 11-179: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 11-180: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 11-181: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 11-182: Loss: 0.2640 Acc: 50.0000%\n",
      "\ttrain 11-183: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 11-184: Loss: 0.1141 Acc: 100.0000%\n",
      "\ttrain 11-185: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 11-186: Loss: 0.4468 Acc: 50.0000%\n",
      "\ttrain 11-187: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 11-188: Loss: 0.1243 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-189: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 11-190: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 11-191: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 11-192: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 11-193: Loss: 0.2116 Acc: 50.0000%\n",
      "\ttrain 11-194: Loss: 0.1766 Acc: 75.0000%\n",
      "\ttrain 11-195: Loss: 0.4432 Acc: 75.0000%\n",
      "\ttrain 11-196: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 11-197: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 11-198: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 11-199: Loss: 0.6425 Acc: 50.0000%\n",
      "\ttrain 11-200: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 11-201: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 11-202: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 11-203: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 11-204: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 11-205: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 11-206: Loss: 0.5937 Acc: 25.0000%\n",
      "\ttrain 11-207: Loss: 0.2172 Acc: 75.0000%\n",
      "\ttrain 11-208: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 11-209: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 11-210: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 11-211: Loss: 0.1791 Acc: 75.0000%\n",
      "\ttrain 11-212: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 11-213: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 11-214: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 11-215: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 11-216: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 11-217: Loss: 0.3153 Acc: 50.0000%\n",
      "\ttrain 11-218: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 11-219: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 11-220: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 11-221: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 11-222: Loss: 0.2861 Acc: 75.0000%\n",
      "\ttrain 11-223: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 11-224: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 11-225: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 11-226: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 11-227: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 11-228: Loss: 0.0787 Acc: 100.0000%\n",
      "\ttrain 11-229: Loss: 0.2397 Acc: 75.0000%\n",
      "\ttrain 11-230: Loss: 0.1522 Acc: 50.0000%\n",
      "\ttrain 11-231: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 11-232: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 11-233: Loss: 0.2515 Acc: 50.0000%\n",
      "\ttrain 11-234: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 11-235: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 11-236: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 11-237: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 11-238: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 11-239: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 11-240: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 11-241: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 11-242: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 11-243: Loss: 0.2178 Acc: 75.0000%\n",
      "\ttrain 11-244: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 11-245: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 11-1: Loss: 0.0962 Acc: 75.0000%\n",
      "\tvalidation 11-2: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 11-3: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 11-4: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 11-5: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 11-6: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 11-7: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 11-8: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-9: Loss: 0.3622 Acc: 75.0000%\n",
      "\tvalidation 11-10: Loss: 0.2599 Acc: 75.0000%\n",
      "\tvalidation 11-11: Loss: 0.1920 Acc: 75.0000%\n",
      "\tvalidation 11-12: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 11-13: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 11-14: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 11-15: Loss: 0.0838 Acc: 75.0000%\n",
      "\tvalidation 11-16: Loss: 0.3177 Acc: 75.0000%\n",
      "\tvalidation 11-17: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 11-18: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 11-19: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 11-20: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 11-21: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 11-22: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 11-23: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-24: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 11-25: Loss: 0.8228 Acc: 75.0000%\n",
      "\tvalidation 11-26: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 11-27: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 11-28: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 11-29: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 11-30: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 11-31: Loss: 0.2347 Acc: 75.0000%\n",
      "\tvalidation 11-32: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 11-33: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 11-34: Loss: 0.0605 Acc: 100.0000%\n",
      "\tvalidation 11-35: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 11-36: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 11-37: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-38: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 11-39: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 11-40: Loss: 0.7796 Acc: 75.0000%\n",
      "\tvalidation 11-41: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 11-42: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 11-43: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 11-44: Loss: 0.0956 Acc: 75.0000%\n",
      "\tvalidation 11-45: Loss: 1.5463 Acc: 75.0000%\n",
      "\tvalidation 11-46: Loss: 0.2462 Acc: 75.0000%\n",
      "\tvalidation 11-47: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-48: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 11-49: Loss: 0.5421 Acc: 75.0000%\n",
      "\tvalidation 11-50: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-51: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 11-52: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 11-53: Loss: 0.0361 Acc: 100.0000%\n",
      "\tvalidation 11-54: Loss: 0.1346 Acc: 50.0000%\n",
      "\tvalidation 11-55: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 11-56: Loss: 0.2712 Acc: 50.0000%\n",
      "\tvalidation 11-57: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 11-58: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 11-59: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 11-60: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-61: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 11-62: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 11-63: Loss: 2.9208 Acc: 75.0000%\n",
      "\tvalidation 11-64: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 11-65: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 11-66: Loss: 0.0467 Acc: 75.0000%\n",
      "\tvalidation 11-67: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-69: Loss: 0.3902 Acc: 75.0000%\n",
      "\tvalidation 11-70: Loss: 0.6704 Acc: 75.0000%\n",
      "\tvalidation 11-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 11-72: Loss: 0.0522 Acc: 100.0000%\n",
      "\tvalidation 11-73: Loss: 0.5863 Acc: 75.0000%\n",
      "\tvalidation 11-74: Loss: 0.3783 Acc: 75.0000%\n",
      "\tvalidation 11-75: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 11-76: Loss: 0.1234 Acc: 75.0000%\n",
      "\tvalidation 11-77: Loss: 0.0622 Acc: 100.0000%\n",
      "\tvalidation 11-78: Loss: 0.4246 Acc: 75.0000%\n",
      "\tvalidation 11-79: Loss: 0.3025 Acc: 75.0000%\n",
      "\tvalidation 11-80: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 11-81: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-82: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 11-83: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 11-84: Loss: 0.3498 Acc: 75.0000%\n",
      "\tvalidation 11-85: Loss: 0.1395 Acc: 75.0000%\n",
      "\tvalidation 11-86: Loss: 0.2670 Acc: 75.0000%\n",
      "\tvalidation 11-87: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 11-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 11-89: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 11-90: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 11-91: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 11-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 11-93: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 11-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 11-95: Loss: 0.2594 Acc: 75.0000%\n",
      "\tvalidation 11-96: Loss: 2.0497 Acc: 75.0000%\n",
      "\tvalidation 11-97: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 11-98: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 11-99: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 11-100: Loss: 0.4038 Acc: 50.0000%\n",
      "\tvalidation 11-101: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 11-102: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 11-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 11-104: Loss: 0.8150 Acc: 75.0000%\n",
      "\tvalidation 11-105: Loss: 2.5676 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1459 Acc: 79.6939%\n",
      "\tvalidation Loss: 0.1855 Acc: 91.6667%\n",
      "网络参数更新\n",
      "Time passed 0h 11m 33s\n",
      "--------------------\n",
      "Epoch [12/40]:\n",
      "\ttrain 12-1: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 12-2: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 12-3: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 12-4: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 12-5: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 12-6: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 12-7: Loss: 0.3043 Acc: 50.0000%\n",
      "\ttrain 12-8: Loss: 0.2491 Acc: 50.0000%\n",
      "\ttrain 12-9: Loss: 0.3809 Acc: 75.0000%\n",
      "\ttrain 12-10: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 12-11: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 12-12: Loss: 0.1939 Acc: 75.0000%\n",
      "\ttrain 12-13: Loss: 0.0996 Acc: 100.0000%\n",
      "\ttrain 12-14: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 12-15: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 12-16: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 12-17: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 12-18: Loss: 0.0221 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-19: Loss: 0.1700 Acc: 75.0000%\n",
      "\ttrain 12-20: Loss: 0.4156 Acc: 75.0000%\n",
      "\ttrain 12-21: Loss: 0.4694 Acc: 50.0000%\n",
      "\ttrain 12-22: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 12-23: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 12-24: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 12-25: Loss: 0.2705 Acc: 75.0000%\n",
      "\ttrain 12-26: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 12-27: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 12-28: Loss: 0.2370 Acc: 50.0000%\n",
      "\ttrain 12-29: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 12-30: Loss: 0.2295 Acc: 75.0000%\n",
      "\ttrain 12-31: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 12-32: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 12-33: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 12-34: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 12-35: Loss: 0.4569 Acc: 50.0000%\n",
      "\ttrain 12-36: Loss: 0.1489 Acc: 50.0000%\n",
      "\ttrain 12-37: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 12-38: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 12-39: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 12-40: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 12-41: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 12-42: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 12-43: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 12-44: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 12-45: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 12-46: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 12-47: Loss: 0.3108 Acc: 75.0000%\n",
      "\ttrain 12-48: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 12-49: Loss: 0.1649 Acc: 75.0000%\n",
      "\ttrain 12-50: Loss: 0.1683 Acc: 75.0000%\n",
      "\ttrain 12-51: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 12-52: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 12-53: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 12-54: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 12-55: Loss: 0.3434 Acc: 75.0000%\n",
      "\ttrain 12-56: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 12-57: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 12-58: Loss: 0.3349 Acc: 75.0000%\n",
      "\ttrain 12-59: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 12-60: Loss: 0.3116 Acc: 75.0000%\n",
      "\ttrain 12-61: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 12-62: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 12-63: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 12-64: Loss: 0.3043 Acc: 25.0000%\n",
      "\ttrain 12-65: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 12-66: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 12-67: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 12-68: Loss: 0.2240 Acc: 75.0000%\n",
      "\ttrain 12-69: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 12-70: Loss: 0.3182 Acc: 75.0000%\n",
      "\ttrain 12-71: Loss: 0.1376 Acc: 75.0000%\n",
      "\ttrain 12-72: Loss: 0.7815 Acc: 25.0000%\n",
      "\ttrain 12-73: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 12-74: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 12-75: Loss: 0.3553 Acc: 50.0000%\n",
      "\ttrain 12-76: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 12-77: Loss: 0.2911 Acc: 75.0000%\n",
      "\ttrain 12-78: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 12-79: Loss: 0.3467 Acc: 50.0000%\n",
      "\ttrain 12-80: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 12-81: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 12-82: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 12-83: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 12-84: Loss: 0.1877 Acc: 50.0000%\n",
      "\ttrain 12-85: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 12-86: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 12-87: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 12-88: Loss: 0.5419 Acc: 50.0000%\n",
      "\ttrain 12-89: Loss: 0.2844 Acc: 75.0000%\n",
      "\ttrain 12-90: Loss: 0.4518 Acc: 25.0000%\n",
      "\ttrain 12-91: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 12-92: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 12-93: Loss: 0.2063 Acc: 50.0000%\n",
      "\ttrain 12-94: Loss: 0.3013 Acc: 50.0000%\n",
      "\ttrain 12-95: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 12-96: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 12-97: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 12-98: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 12-99: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 12-100: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 12-101: Loss: 0.0983 Acc: 75.0000%\n",
      "\ttrain 12-102: Loss: 0.0960 Acc: 50.0000%\n",
      "\ttrain 12-103: Loss: 0.3136 Acc: 50.0000%\n",
      "\ttrain 12-104: Loss: 0.5303 Acc: 50.0000%\n",
      "\ttrain 12-105: Loss: 0.3309 Acc: 25.0000%\n",
      "\ttrain 12-106: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 12-107: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 12-108: Loss: 0.3097 Acc: 75.0000%\n",
      "\ttrain 12-109: Loss: 0.2896 Acc: 50.0000%\n",
      "\ttrain 12-110: Loss: 0.2170 Acc: 50.0000%\n",
      "\ttrain 12-111: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 12-112: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 12-113: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 12-114: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 12-115: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 12-116: Loss: 0.2018 Acc: 50.0000%\n",
      "\ttrain 12-117: Loss: 0.4230 Acc: 50.0000%\n",
      "\ttrain 12-118: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 12-119: Loss: 0.0697 Acc: 100.0000%\n",
      "\ttrain 12-120: Loss: 0.5206 Acc: 25.0000%\n",
      "\ttrain 12-121: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 12-122: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 12-123: Loss: 1.1905 Acc: 0.0000%\n",
      "\ttrain 12-124: Loss: 0.3944 Acc: 50.0000%\n",
      "\ttrain 12-125: Loss: 0.2748 Acc: 50.0000%\n",
      "\ttrain 12-126: Loss: 0.2071 Acc: 50.0000%\n",
      "\ttrain 12-127: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 12-128: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 12-129: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 12-130: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 12-131: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 12-132: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 12-133: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 12-134: Loss: 0.5009 Acc: 25.0000%\n",
      "\ttrain 12-135: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 12-136: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 12-137: Loss: 0.3362 Acc: 50.0000%\n",
      "\ttrain 12-138: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 12-139: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 12-140: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 12-141: Loss: 0.4222 Acc: 50.0000%\n",
      "\ttrain 12-142: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 12-143: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 12-144: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 12-145: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 12-146: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 12-147: Loss: 0.4189 Acc: 25.0000%\n",
      "\ttrain 12-148: Loss: 0.2817 Acc: 50.0000%\n",
      "\ttrain 12-149: Loss: 0.0734 Acc: 100.0000%\n",
      "\ttrain 12-150: Loss: 0.1682 Acc: 75.0000%\n",
      "\ttrain 12-151: Loss: 0.2312 Acc: 50.0000%\n",
      "\ttrain 12-152: Loss: 0.0555 Acc: 75.0000%\n",
      "\ttrain 12-153: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 12-154: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 12-155: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 12-156: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 12-157: Loss: 0.2937 Acc: 50.0000%\n",
      "\ttrain 12-158: Loss: 0.0603 Acc: 75.0000%\n",
      "\ttrain 12-159: Loss: 0.1934 Acc: 50.0000%\n",
      "\ttrain 12-160: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 12-161: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 12-162: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 12-163: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 12-164: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 12-165: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 12-166: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 12-167: Loss: 0.8882 Acc: 0.0000%\n",
      "\ttrain 12-168: Loss: 0.2955 Acc: 50.0000%\n",
      "\ttrain 12-169: Loss: 0.0629 Acc: 75.0000%\n",
      "\ttrain 12-170: Loss: 0.0894 Acc: 100.0000%\n",
      "\ttrain 12-171: Loss: 0.1867 Acc: 50.0000%\n",
      "\ttrain 12-172: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 12-173: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 12-174: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 12-175: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 12-176: Loss: 0.2366 Acc: 75.0000%\n",
      "\ttrain 12-177: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 12-178: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 12-179: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 12-180: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 12-181: Loss: 0.1257 Acc: 50.0000%\n",
      "\ttrain 12-182: Loss: 0.2267 Acc: 75.0000%\n",
      "\ttrain 12-183: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 12-184: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 12-185: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 12-186: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 12-187: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 12-188: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 12-189: Loss: 0.5262 Acc: 25.0000%\n",
      "\ttrain 12-190: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 12-191: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 12-192: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 12-193: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 12-194: Loss: 0.2399 Acc: 50.0000%\n",
      "\ttrain 12-195: Loss: 0.1432 Acc: 75.0000%\n",
      "\ttrain 12-196: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 12-197: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 12-198: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 12-199: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 12-200: Loss: 0.2215 Acc: 75.0000%\n",
      "\ttrain 12-201: Loss: 0.1609 Acc: 50.0000%\n",
      "\ttrain 12-202: Loss: 0.3153 Acc: 50.0000%\n",
      "\ttrain 12-203: Loss: 0.2385 Acc: 50.0000%\n",
      "\ttrain 12-204: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 12-205: Loss: 0.2446 Acc: 75.0000%\n",
      "\ttrain 12-206: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 12-207: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 12-208: Loss: 0.0906 Acc: 100.0000%\n",
      "\ttrain 12-209: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 12-210: Loss: 0.1628 Acc: 75.0000%\n",
      "\ttrain 12-211: Loss: 0.3406 Acc: 75.0000%\n",
      "\ttrain 12-212: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 12-213: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 12-214: Loss: 0.1091 Acc: 100.0000%\n",
      "\ttrain 12-215: Loss: 0.1759 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-216: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 12-217: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 12-218: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 12-219: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 12-220: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 12-221: Loss: 0.0772 Acc: 75.0000%\n",
      "\ttrain 12-222: Loss: 0.2384 Acc: 75.0000%\n",
      "\ttrain 12-223: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 12-224: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 12-225: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 12-226: Loss: 0.3627 Acc: 75.0000%\n",
      "\ttrain 12-227: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 12-228: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 12-229: Loss: 0.3662 Acc: 25.0000%\n",
      "\ttrain 12-230: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 12-231: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 12-232: Loss: 0.1581 Acc: 50.0000%\n",
      "\ttrain 12-233: Loss: 0.1845 Acc: 50.0000%\n",
      "\ttrain 12-234: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 12-235: Loss: 0.2532 Acc: 25.0000%\n",
      "\ttrain 12-236: Loss: 0.0780 Acc: 100.0000%\n",
      "\ttrain 12-237: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 12-238: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 12-239: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 12-240: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 12-241: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 12-242: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 12-243: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 12-244: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 12-245: Loss: 0.0566 Acc: 100.0000%\n",
      "\tvalidation 12-1: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 12-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 12-3: Loss: 0.3916 Acc: 50.0000%\n",
      "\tvalidation 12-4: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 12-5: Loss: 0.0542 Acc: 75.0000%\n",
      "\tvalidation 12-6: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 12-7: Loss: 0.3498 Acc: 75.0000%\n",
      "\tvalidation 12-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 12-9: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 12-10: Loss: 0.2652 Acc: 50.0000%\n",
      "\tvalidation 12-11: Loss: 0.0616 Acc: 75.0000%\n",
      "\tvalidation 12-12: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 12-13: Loss: 0.3660 Acc: 75.0000%\n",
      "\tvalidation 12-14: Loss: 0.0997 Acc: 75.0000%\n",
      "\tvalidation 12-15: Loss: 0.3009 Acc: 75.0000%\n",
      "\tvalidation 12-16: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 12-17: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 12-18: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 12-19: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 12-20: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 12-21: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 12-22: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 12-23: Loss: 0.0672 Acc: 75.0000%\n",
      "\tvalidation 12-24: Loss: 0.6310 Acc: 75.0000%\n",
      "\tvalidation 12-25: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 12-26: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 12-27: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 12-28: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 12-29: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 12-30: Loss: 0.0364 Acc: 100.0000%\n",
      "\tvalidation 12-31: Loss: 0.0581 Acc: 100.0000%\n",
      "\tvalidation 12-32: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 12-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 12-34: Loss: 0.1343 Acc: 50.0000%\n",
      "\tvalidation 12-35: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 12-36: Loss: 0.1641 Acc: 75.0000%\n",
      "\tvalidation 12-37: Loss: 0.1613 Acc: 75.0000%\n",
      "\tvalidation 12-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 12-39: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 12-40: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 12-41: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 12-42: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 12-43: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 12-44: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 12-45: Loss: 0.2309 Acc: 50.0000%\n",
      "\tvalidation 12-46: Loss: 0.0437 Acc: 100.0000%\n",
      "\tvalidation 12-47: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 12-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 12-49: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 12-50: Loss: 0.4100 Acc: 75.0000%\n",
      "\tvalidation 12-51: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 12-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 12-53: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 12-54: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 12-55: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 12-56: Loss: 0.0659 Acc: 75.0000%\n",
      "\tvalidation 12-57: Loss: 0.1856 Acc: 50.0000%\n",
      "\tvalidation 12-58: Loss: 0.1033 Acc: 75.0000%\n",
      "\tvalidation 12-59: Loss: 1.4816 Acc: 75.0000%\n",
      "\tvalidation 12-60: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 12-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 12-62: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 12-63: Loss: 0.5561 Acc: 75.0000%\n",
      "\tvalidation 12-64: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 12-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 12-66: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 12-67: Loss: 0.0543 Acc: 75.0000%\n",
      "\tvalidation 12-68: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 12-69: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 12-70: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 12-71: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 12-72: Loss: 0.2925 Acc: 50.0000%\n",
      "\tvalidation 12-73: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 12-74: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 12-75: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 12-76: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 12-77: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 12-78: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 12-79: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 12-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 12-81: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 12-82: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 12-83: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 12-84: Loss: 0.0412 Acc: 100.0000%\n",
      "\tvalidation 12-85: Loss: 0.2873 Acc: 75.0000%\n",
      "\tvalidation 12-86: Loss: 0.2724 Acc: 75.0000%\n",
      "\tvalidation 12-87: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 12-88: Loss: 0.2788 Acc: 75.0000%\n",
      "\tvalidation 12-89: Loss: 0.1322 Acc: 75.0000%\n",
      "\tvalidation 12-90: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 12-91: Loss: 0.1350 Acc: 75.0000%\n",
      "\tvalidation 12-92: Loss: 1.5722 Acc: 75.0000%\n",
      "\tvalidation 12-93: Loss: 2.1953 Acc: 25.0000%\n",
      "\tvalidation 12-94: Loss: 0.3106 Acc: 75.0000%\n",
      "\tvalidation 12-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 12-96: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 12-97: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 12-98: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 12-99: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 12-100: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 12-101: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 12-102: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 12-103: Loss: 0.0350 Acc: 100.0000%\n",
      "\tvalidation 12-104: Loss: 0.0941 Acc: 75.0000%\n",
      "\tvalidation 12-105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1381 Acc: 79.8980%\n",
      "\tvalidation Loss: 0.1222 Acc: 89.7619%\n",
      "Time passed 0h 12m 31s\n",
      "--------------------\n",
      "Epoch [13/40]:\n",
      "\ttrain 13-1: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 13-2: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 13-3: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 13-4: Loss: 0.1848 Acc: 50.0000%\n",
      "\ttrain 13-5: Loss: 0.4402 Acc: 50.0000%\n",
      "\ttrain 13-6: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 13-7: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 13-8: Loss: 0.3698 Acc: 25.0000%\n",
      "\ttrain 13-9: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 13-10: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 13-11: Loss: 0.4132 Acc: 25.0000%\n",
      "\ttrain 13-12: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 13-13: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 13-14: Loss: 0.2305 Acc: 75.0000%\n",
      "\ttrain 13-15: Loss: 0.3891 Acc: 75.0000%\n",
      "\ttrain 13-16: Loss: 0.3623 Acc: 50.0000%\n",
      "\ttrain 13-17: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 13-18: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 13-19: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 13-20: Loss: 0.2635 Acc: 50.0000%\n",
      "\ttrain 13-21: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 13-22: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 13-23: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 13-24: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 13-25: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 13-26: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 13-27: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 13-28: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 13-29: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 13-30: Loss: 0.3130 Acc: 75.0000%\n",
      "\ttrain 13-31: Loss: 0.2122 Acc: 75.0000%\n",
      "\ttrain 13-32: Loss: 0.4635 Acc: 75.0000%\n",
      "\ttrain 13-33: Loss: 0.1538 Acc: 75.0000%\n",
      "\ttrain 13-34: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 13-35: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 13-36: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 13-37: Loss: 0.4421 Acc: 75.0000%\n",
      "\ttrain 13-38: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 13-39: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 13-40: Loss: 0.2426 Acc: 75.0000%\n",
      "\ttrain 13-41: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 13-42: Loss: 0.5376 Acc: 50.0000%\n",
      "\ttrain 13-43: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 13-44: Loss: 0.3212 Acc: 75.0000%\n",
      "\ttrain 13-45: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 13-46: Loss: 0.2593 Acc: 50.0000%\n",
      "\ttrain 13-47: Loss: 0.0495 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-48: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 13-49: Loss: 0.2178 Acc: 50.0000%\n",
      "\ttrain 13-50: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 13-51: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 13-52: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 13-53: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 13-54: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 13-55: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 13-56: Loss: 0.2199 Acc: 50.0000%\n",
      "\ttrain 13-57: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 13-58: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 13-59: Loss: 0.2293 Acc: 50.0000%\n",
      "\ttrain 13-60: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 13-61: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 13-62: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 13-63: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 13-64: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 13-65: Loss: 0.0761 Acc: 75.0000%\n",
      "\ttrain 13-66: Loss: 0.4185 Acc: 50.0000%\n",
      "\ttrain 13-67: Loss: 0.2784 Acc: 50.0000%\n",
      "\ttrain 13-68: Loss: 0.1786 Acc: 75.0000%\n",
      "\ttrain 13-69: Loss: 0.2860 Acc: 50.0000%\n",
      "\ttrain 13-70: Loss: 0.2174 Acc: 75.0000%\n",
      "\ttrain 13-71: Loss: 0.4673 Acc: 25.0000%\n",
      "\ttrain 13-72: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 13-73: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 13-74: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 13-75: Loss: 0.3711 Acc: 50.0000%\n",
      "\ttrain 13-76: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 13-77: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 13-78: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 13-79: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 13-80: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 13-81: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 13-82: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 13-83: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 13-84: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 13-85: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 13-86: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 13-87: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 13-88: Loss: 0.3768 Acc: 50.0000%\n",
      "\ttrain 13-89: Loss: 0.2205 Acc: 75.0000%\n",
      "\ttrain 13-90: Loss: 0.2246 Acc: 75.0000%\n",
      "\ttrain 13-91: Loss: 0.3323 Acc: 75.0000%\n",
      "\ttrain 13-92: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 13-93: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 13-94: Loss: 0.2035 Acc: 50.0000%\n",
      "\ttrain 13-95: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 13-96: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 13-97: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 13-98: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 13-99: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 13-100: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 13-101: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 13-102: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 13-103: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 13-104: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 13-105: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 13-106: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 13-107: Loss: 0.1666 Acc: 75.0000%\n",
      "\ttrain 13-108: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 13-109: Loss: 0.4279 Acc: 50.0000%\n",
      "\ttrain 13-110: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 13-111: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 13-112: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 13-113: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 13-114: Loss: 0.2087 Acc: 50.0000%\n",
      "\ttrain 13-115: Loss: 0.2550 Acc: 75.0000%\n",
      "\ttrain 13-116: Loss: 0.2459 Acc: 50.0000%\n",
      "\ttrain 13-117: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 13-118: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 13-119: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 13-120: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 13-121: Loss: 0.2260 Acc: 50.0000%\n",
      "\ttrain 13-122: Loss: 0.2045 Acc: 75.0000%\n",
      "\ttrain 13-123: Loss: 0.2356 Acc: 75.0000%\n",
      "\ttrain 13-124: Loss: 0.1979 Acc: 75.0000%\n",
      "\ttrain 13-125: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 13-126: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 13-127: Loss: 0.2278 Acc: 75.0000%\n",
      "\ttrain 13-128: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 13-129: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 13-130: Loss: 0.2173 Acc: 50.0000%\n",
      "\ttrain 13-131: Loss: 0.2285 Acc: 75.0000%\n",
      "\ttrain 13-132: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 13-133: Loss: 0.1520 Acc: 50.0000%\n",
      "\ttrain 13-134: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 13-135: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 13-136: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 13-137: Loss: 0.2881 Acc: 50.0000%\n",
      "\ttrain 13-138: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 13-139: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 13-140: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 13-141: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 13-142: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 13-143: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 13-144: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 13-145: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 13-146: Loss: 0.2390 Acc: 75.0000%\n",
      "\ttrain 13-147: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 13-148: Loss: 0.1215 Acc: 75.0000%\n",
      "\ttrain 13-149: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 13-150: Loss: 0.1405 Acc: 75.0000%\n",
      "\ttrain 13-151: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 13-152: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 13-153: Loss: 0.2669 Acc: 75.0000%\n",
      "\ttrain 13-154: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 13-155: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 13-156: Loss: 0.3714 Acc: 50.0000%\n",
      "\ttrain 13-157: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 13-158: Loss: 0.3384 Acc: 50.0000%\n",
      "\ttrain 13-159: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 13-160: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 13-161: Loss: 0.1637 Acc: 75.0000%\n",
      "\ttrain 13-162: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 13-163: Loss: 0.0693 Acc: 100.0000%\n",
      "\ttrain 13-164: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 13-165: Loss: 0.2589 Acc: 75.0000%\n",
      "\ttrain 13-166: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 13-167: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 13-168: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 13-169: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 13-170: Loss: 0.2003 Acc: 75.0000%\n",
      "\ttrain 13-171: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 13-172: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 13-173: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 13-174: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 13-175: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 13-176: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 13-177: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 13-178: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 13-179: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 13-180: Loss: 0.4733 Acc: 50.0000%\n",
      "\ttrain 13-181: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 13-182: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 13-183: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 13-184: Loss: 0.3899 Acc: 25.0000%\n",
      "\ttrain 13-185: Loss: 0.2083 Acc: 75.0000%\n",
      "\ttrain 13-186: Loss: 0.3411 Acc: 50.0000%\n",
      "\ttrain 13-187: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 13-188: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 13-189: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 13-190: Loss: 0.2898 Acc: 50.0000%\n",
      "\ttrain 13-191: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 13-192: Loss: 0.1959 Acc: 50.0000%\n",
      "\ttrain 13-193: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 13-194: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 13-195: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 13-196: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 13-197: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 13-198: Loss: 0.1915 Acc: 75.0000%\n",
      "\ttrain 13-199: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 13-200: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 13-201: Loss: 0.1377 Acc: 75.0000%\n",
      "\ttrain 13-202: Loss: 0.0850 Acc: 100.0000%\n",
      "\ttrain 13-203: Loss: 0.3848 Acc: 50.0000%\n",
      "\ttrain 13-204: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 13-205: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 13-206: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 13-207: Loss: 0.0997 Acc: 100.0000%\n",
      "\ttrain 13-208: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 13-209: Loss: 0.3277 Acc: 50.0000%\n",
      "\ttrain 13-210: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 13-211: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 13-212: Loss: 0.1931 Acc: 50.0000%\n",
      "\ttrain 13-213: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 13-214: Loss: 0.1221 Acc: 50.0000%\n",
      "\ttrain 13-215: Loss: 0.2965 Acc: 50.0000%\n",
      "\ttrain 13-216: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 13-217: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 13-218: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 13-219: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 13-220: Loss: 0.3223 Acc: 50.0000%\n",
      "\ttrain 13-221: Loss: 0.1719 Acc: 50.0000%\n",
      "\ttrain 13-222: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 13-223: Loss: 0.2979 Acc: 50.0000%\n",
      "\ttrain 13-224: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 13-225: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 13-226: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 13-227: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 13-228: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 13-229: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 13-230: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 13-231: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 13-232: Loss: 0.3627 Acc: 75.0000%\n",
      "\ttrain 13-233: Loss: 0.1477 Acc: 75.0000%\n",
      "\ttrain 13-234: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 13-235: Loss: 0.3524 Acc: 75.0000%\n",
      "\ttrain 13-236: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 13-237: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 13-238: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 13-239: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 13-240: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 13-241: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 13-242: Loss: 0.0322 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-243: Loss: 0.2851 Acc: 75.0000%\n",
      "\ttrain 13-244: Loss: 0.2614 Acc: 50.0000%\n",
      "\ttrain 13-245: Loss: 0.2327 Acc: 75.0000%\n",
      "\tvalidation 13-1: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 13-2: Loss: 0.1454 Acc: 50.0000%\n",
      "\tvalidation 13-3: Loss: 0.0715 Acc: 75.0000%\n",
      "\tvalidation 13-4: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 13-5: Loss: 0.1752 Acc: 75.0000%\n",
      "\tvalidation 13-6: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 13-7: Loss: 0.0666 Acc: 75.0000%\n",
      "\tvalidation 13-8: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 13-9: Loss: 0.1733 Acc: 75.0000%\n",
      "\tvalidation 13-10: Loss: 0.1817 Acc: 50.0000%\n",
      "\tvalidation 13-11: Loss: 0.3722 Acc: 75.0000%\n",
      "\tvalidation 13-12: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 13-13: Loss: 0.1252 Acc: 75.0000%\n",
      "\tvalidation 13-14: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 13-15: Loss: 0.0488 Acc: 100.0000%\n",
      "\tvalidation 13-16: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 13-17: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 13-18: Loss: 0.2847 Acc: 50.0000%\n",
      "\tvalidation 13-19: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 13-20: Loss: 0.0667 Acc: 75.0000%\n",
      "\tvalidation 13-21: Loss: 1.0012 Acc: 75.0000%\n",
      "\tvalidation 13-22: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 13-23: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 13-24: Loss: 0.4504 Acc: 50.0000%\n",
      "\tvalidation 13-25: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 13-26: Loss: 0.1062 Acc: 75.0000%\n",
      "\tvalidation 13-27: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 13-28: Loss: 0.4661 Acc: 75.0000%\n",
      "\tvalidation 13-29: Loss: 0.1044 Acc: 75.0000%\n",
      "\tvalidation 13-30: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 13-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-32: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 13-33: Loss: 0.0786 Acc: 75.0000%\n",
      "\tvalidation 13-34: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 13-35: Loss: 0.0476 Acc: 100.0000%\n",
      "\tvalidation 13-36: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 13-37: Loss: 0.2310 Acc: 50.0000%\n",
      "\tvalidation 13-38: Loss: 0.0508 Acc: 100.0000%\n",
      "\tvalidation 13-39: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 13-40: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 13-41: Loss: 0.2065 Acc: 50.0000%\n",
      "\tvalidation 13-42: Loss: 1.4236 Acc: 50.0000%\n",
      "\tvalidation 13-43: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 13-44: Loss: 0.1842 Acc: 50.0000%\n",
      "\tvalidation 13-45: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 13-46: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 13-47: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 13-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-49: Loss: 0.1118 Acc: 75.0000%\n",
      "\tvalidation 13-50: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 13-51: Loss: 0.1655 Acc: 50.0000%\n",
      "\tvalidation 13-52: Loss: 0.1040 Acc: 75.0000%\n",
      "\tvalidation 13-53: Loss: 0.1303 Acc: 75.0000%\n",
      "\tvalidation 13-54: Loss: 0.1731 Acc: 75.0000%\n",
      "\tvalidation 13-55: Loss: 0.5916 Acc: 50.0000%\n",
      "\tvalidation 13-56: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 13-57: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 13-58: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 13-59: Loss: 0.4101 Acc: 50.0000%\n",
      "\tvalidation 13-60: Loss: 0.2770 Acc: 75.0000%\n",
      "\tvalidation 13-61: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 13-62: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 13-63: Loss: 0.1231 Acc: 75.0000%\n",
      "\tvalidation 13-64: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 13-65: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 13-66: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 13-67: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 13-68: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 13-69: Loss: 0.0789 Acc: 75.0000%\n",
      "\tvalidation 13-70: Loss: 0.0979 Acc: 75.0000%\n",
      "\tvalidation 13-71: Loss: 0.0631 Acc: 75.0000%\n",
      "\tvalidation 13-72: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 13-73: Loss: 0.0732 Acc: 75.0000%\n",
      "\tvalidation 13-74: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 13-75: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 13-76: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 13-77: Loss: 0.2135 Acc: 75.0000%\n",
      "\tvalidation 13-78: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 13-79: Loss: 0.0863 Acc: 75.0000%\n",
      "\tvalidation 13-80: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 13-81: Loss: 0.1789 Acc: 75.0000%\n",
      "\tvalidation 13-82: Loss: 0.3294 Acc: 50.0000%\n",
      "\tvalidation 13-83: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 13-84: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 13-85: Loss: 0.1867 Acc: 50.0000%\n",
      "\tvalidation 13-86: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 13-87: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 13-88: Loss: 0.0702 Acc: 75.0000%\n",
      "\tvalidation 13-89: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 13-90: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 13-91: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 13-92: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 13-93: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 13-94: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 13-95: Loss: 0.1477 Acc: 75.0000%\n",
      "\tvalidation 13-96: Loss: 0.0793 Acc: 75.0000%\n",
      "\tvalidation 13-97: Loss: 0.8853 Acc: 75.0000%\n",
      "\tvalidation 13-98: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 13-99: Loss: 0.0342 Acc: 100.0000%\n",
      "\tvalidation 13-100: Loss: 0.0658 Acc: 100.0000%\n",
      "\tvalidation 13-101: Loss: 0.1015 Acc: 75.0000%\n",
      "\tvalidation 13-102: Loss: 0.0508 Acc: 100.0000%\n",
      "\tvalidation 13-103: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 13-104: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 13-105: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1234 Acc: 82.2449%\n",
      "\tvalidation Loss: 0.1134 Acc: 85.9524%\n",
      "Time passed 0h 13m 25s\n",
      "--------------------\n",
      "Epoch [14/40]:\n",
      "\ttrain 14-1: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 14-2: Loss: 0.0890 Acc: 100.0000%\n",
      "\ttrain 14-3: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 14-4: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 14-5: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 14-6: Loss: 0.1670 Acc: 75.0000%\n",
      "\ttrain 14-7: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 14-8: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 14-9: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 14-10: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 14-11: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 14-12: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 14-13: Loss: 0.2091 Acc: 75.0000%\n",
      "\ttrain 14-14: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 14-15: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 14-16: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 14-17: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 14-18: Loss: 0.3829 Acc: 75.0000%\n",
      "\ttrain 14-19: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 14-20: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 14-21: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 14-22: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 14-23: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 14-24: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 14-25: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 14-26: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 14-27: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 14-28: Loss: 0.0912 Acc: 100.0000%\n",
      "\ttrain 14-29: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 14-30: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 14-31: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 14-32: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 14-33: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 14-34: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 14-35: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 14-36: Loss: 0.0788 Acc: 100.0000%\n",
      "\ttrain 14-37: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 14-38: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 14-39: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 14-40: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 14-41: Loss: 0.2001 Acc: 50.0000%\n",
      "\ttrain 14-42: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 14-43: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 14-44: Loss: 0.3043 Acc: 50.0000%\n",
      "\ttrain 14-45: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 14-46: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 14-47: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 14-48: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 14-49: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 14-50: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 14-51: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 14-52: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 14-53: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 14-54: Loss: 0.2877 Acc: 50.0000%\n",
      "\ttrain 14-55: Loss: 0.2874 Acc: 75.0000%\n",
      "\ttrain 14-56: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 14-57: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 14-58: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 14-59: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 14-60: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 14-61: Loss: 0.2667 Acc: 75.0000%\n",
      "\ttrain 14-62: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 14-63: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 14-64: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 14-65: Loss: 0.0630 Acc: 100.0000%\n",
      "\ttrain 14-66: Loss: 0.1060 Acc: 100.0000%\n",
      "\ttrain 14-67: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 14-68: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 14-69: Loss: 0.5174 Acc: 25.0000%\n",
      "\ttrain 14-70: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 14-71: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 14-72: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 14-73: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 14-74: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 14-75: Loss: 0.0140 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-76: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 14-77: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 14-78: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 14-79: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 14-80: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 14-81: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 14-82: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 14-83: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 14-84: Loss: 0.1209 Acc: 50.0000%\n",
      "\ttrain 14-85: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 14-86: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 14-87: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 14-88: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 14-89: Loss: 0.9947 Acc: 25.0000%\n",
      "\ttrain 14-90: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 14-91: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 14-92: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 14-93: Loss: 0.1822 Acc: 50.0000%\n",
      "\ttrain 14-94: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 14-95: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 14-96: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 14-97: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 14-98: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 14-99: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 14-100: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 14-101: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 14-102: Loss: 0.0612 Acc: 100.0000%\n",
      "\ttrain 14-103: Loss: 0.1235 Acc: 75.0000%\n",
      "\ttrain 14-104: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 14-105: Loss: 0.3672 Acc: 50.0000%\n",
      "\ttrain 14-106: Loss: 0.2661 Acc: 75.0000%\n",
      "\ttrain 14-107: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 14-108: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 14-109: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 14-110: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 14-111: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 14-112: Loss: 0.5155 Acc: 50.0000%\n",
      "\ttrain 14-113: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 14-114: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 14-115: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 14-116: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 14-117: Loss: 0.2383 Acc: 75.0000%\n",
      "\ttrain 14-118: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 14-119: Loss: 0.1638 Acc: 75.0000%\n",
      "\ttrain 14-120: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 14-121: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 14-122: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 14-123: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 14-124: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 14-125: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 14-126: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 14-127: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 14-128: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 14-129: Loss: 0.3398 Acc: 75.0000%\n",
      "\ttrain 14-130: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 14-131: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 14-132: Loss: 0.1225 Acc: 75.0000%\n",
      "\ttrain 14-133: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 14-134: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 14-135: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 14-136: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 14-137: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 14-138: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 14-139: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 14-140: Loss: 0.1359 Acc: 75.0000%\n",
      "\ttrain 14-141: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 14-142: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 14-143: Loss: 0.2809 Acc: 75.0000%\n",
      "\ttrain 14-144: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 14-145: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 14-146: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 14-147: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 14-148: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 14-149: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 14-150: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 14-151: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 14-152: Loss: 0.1409 Acc: 50.0000%\n",
      "\ttrain 14-153: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 14-154: Loss: 0.0842 Acc: 100.0000%\n",
      "\ttrain 14-155: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 14-156: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 14-157: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 14-158: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 14-159: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 14-160: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 14-161: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 14-162: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 14-163: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 14-164: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 14-165: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 14-166: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 14-167: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 14-168: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 14-169: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 14-170: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 14-171: Loss: 0.2082 Acc: 75.0000%\n",
      "\ttrain 14-172: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 14-173: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 14-174: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 14-175: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 14-176: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 14-177: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 14-178: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 14-179: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 14-180: Loss: 0.3664 Acc: 75.0000%\n",
      "\ttrain 14-181: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 14-182: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 14-183: Loss: 0.1903 Acc: 75.0000%\n",
      "\ttrain 14-184: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 14-185: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 14-186: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 14-187: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 14-188: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 14-189: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 14-190: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 14-191: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 14-192: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 14-193: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 14-194: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 14-195: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 14-196: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 14-197: Loss: 0.0658 Acc: 75.0000%\n",
      "\ttrain 14-198: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 14-199: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 14-200: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 14-201: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 14-202: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 14-203: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 14-204: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 14-205: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 14-206: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 14-207: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 14-208: Loss: 0.1670 Acc: 50.0000%\n",
      "\ttrain 14-209: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 14-210: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 14-211: Loss: 0.2296 Acc: 75.0000%\n",
      "\ttrain 14-212: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 14-213: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 14-214: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 14-215: Loss: 0.4336 Acc: 25.0000%\n",
      "\ttrain 14-216: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 14-217: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 14-218: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 14-219: Loss: 0.2079 Acc: 50.0000%\n",
      "\ttrain 14-220: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 14-221: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 14-222: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 14-223: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 14-224: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 14-225: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 14-226: Loss: 0.1834 Acc: 75.0000%\n",
      "\ttrain 14-227: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 14-228: Loss: 0.2474 Acc: 75.0000%\n",
      "\ttrain 14-229: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 14-230: Loss: 1.2833 Acc: 50.0000%\n",
      "\ttrain 14-231: Loss: 0.1884 Acc: 75.0000%\n",
      "\ttrain 14-232: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 14-233: Loss: 0.1803 Acc: 75.0000%\n",
      "\ttrain 14-234: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 14-235: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 14-236: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 14-237: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 14-238: Loss: 0.0462 Acc: 75.0000%\n",
      "\ttrain 14-239: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 14-240: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 14-241: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 14-242: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 14-243: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 14-244: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 14-245: Loss: 0.0660 Acc: 75.0000%\n",
      "\tvalidation 14-1: Loss: 0.0468 Acc: 75.0000%\n",
      "\tvalidation 14-2: Loss: 0.2279 Acc: 50.0000%\n",
      "\tvalidation 14-3: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 14-4: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 14-5: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 14-6: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 14-7: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 14-8: Loss: 0.0709 Acc: 75.0000%\n",
      "\tvalidation 14-9: Loss: 0.3690 Acc: 50.0000%\n",
      "\tvalidation 14-10: Loss: 0.0528 Acc: 75.0000%\n",
      "\tvalidation 14-11: Loss: 0.0724 Acc: 100.0000%\n",
      "\tvalidation 14-12: Loss: 0.1314 Acc: 75.0000%\n",
      "\tvalidation 14-13: Loss: 0.1835 Acc: 50.0000%\n",
      "\tvalidation 14-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 14-15: Loss: 0.3064 Acc: 75.0000%\n",
      "\tvalidation 14-16: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 14-17: Loss: 0.0527 Acc: 75.0000%\n",
      "\tvalidation 14-18: Loss: 0.2197 Acc: 75.0000%\n",
      "\tvalidation 14-19: Loss: 0.4833 Acc: 75.0000%\n",
      "\tvalidation 14-20: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 14-21: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 14-22: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 14-23: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 14-24: Loss: 0.2311 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 14-25: Loss: 0.1662 Acc: 75.0000%\n",
      "\tvalidation 14-26: Loss: 0.4603 Acc: 50.0000%\n",
      "\tvalidation 14-27: Loss: 0.1089 Acc: 75.0000%\n",
      "\tvalidation 14-28: Loss: 0.1697 Acc: 75.0000%\n",
      "\tvalidation 14-29: Loss: 0.2378 Acc: 75.0000%\n",
      "\tvalidation 14-30: Loss: 0.0749 Acc: 75.0000%\n",
      "\tvalidation 14-31: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 14-32: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 14-33: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 14-34: Loss: 0.4526 Acc: 50.0000%\n",
      "\tvalidation 14-35: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 14-36: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 14-37: Loss: 0.2459 Acc: 75.0000%\n",
      "\tvalidation 14-38: Loss: 0.2757 Acc: 50.0000%\n",
      "\tvalidation 14-39: Loss: 0.1636 Acc: 75.0000%\n",
      "\tvalidation 14-40: Loss: 0.2256 Acc: 75.0000%\n",
      "\tvalidation 14-41: Loss: 0.2058 Acc: 75.0000%\n",
      "\tvalidation 14-42: Loss: 0.0766 Acc: 75.0000%\n",
      "\tvalidation 14-43: Loss: 0.1056 Acc: 75.0000%\n",
      "\tvalidation 14-44: Loss: 0.0576 Acc: 75.0000%\n",
      "\tvalidation 14-45: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 14-46: Loss: 0.1634 Acc: 75.0000%\n",
      "\tvalidation 14-47: Loss: 0.1940 Acc: 75.0000%\n",
      "\tvalidation 14-48: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 14-49: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 14-50: Loss: 0.0643 Acc: 75.0000%\n",
      "\tvalidation 14-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-52: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 14-53: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 14-54: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 14-55: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 14-56: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 14-57: Loss: 0.5619 Acc: 25.0000%\n",
      "\tvalidation 14-58: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 14-59: Loss: 0.0825 Acc: 75.0000%\n",
      "\tvalidation 14-60: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 14-61: Loss: 0.0504 Acc: 75.0000%\n",
      "\tvalidation 14-62: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 14-63: Loss: 0.3692 Acc: 75.0000%\n",
      "\tvalidation 14-64: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 14-65: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 14-66: Loss: 0.0775 Acc: 75.0000%\n",
      "\tvalidation 14-67: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-68: Loss: 0.5669 Acc: 50.0000%\n",
      "\tvalidation 14-69: Loss: 0.6077 Acc: 25.0000%\n",
      "\tvalidation 14-70: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 14-71: Loss: 0.0929 Acc: 75.0000%\n",
      "\tvalidation 14-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-73: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 14-74: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-75: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 14-76: Loss: 0.0548 Acc: 75.0000%\n",
      "\tvalidation 14-77: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 14-78: Loss: 0.2183 Acc: 50.0000%\n",
      "\tvalidation 14-79: Loss: 0.5067 Acc: 25.0000%\n",
      "\tvalidation 14-80: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 14-81: Loss: 0.2293 Acc: 75.0000%\n",
      "\tvalidation 14-82: Loss: 0.0764 Acc: 75.0000%\n",
      "\tvalidation 14-83: Loss: 0.0485 Acc: 100.0000%\n",
      "\tvalidation 14-84: Loss: 0.0502 Acc: 100.0000%\n",
      "\tvalidation 14-85: Loss: 0.1575 Acc: 75.0000%\n",
      "\tvalidation 14-86: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 14-87: Loss: 0.4025 Acc: 50.0000%\n",
      "\tvalidation 14-88: Loss: 0.1088 Acc: 75.0000%\n",
      "\tvalidation 14-89: Loss: 0.2064 Acc: 50.0000%\n",
      "\tvalidation 14-90: Loss: 0.3735 Acc: 50.0000%\n",
      "\tvalidation 14-91: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 14-92: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 14-93: Loss: 0.1631 Acc: 75.0000%\n",
      "\tvalidation 14-94: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 14-95: Loss: 0.0384 Acc: 100.0000%\n",
      "\tvalidation 14-96: Loss: 0.1208 Acc: 75.0000%\n",
      "\tvalidation 14-97: Loss: 0.5504 Acc: 50.0000%\n",
      "\tvalidation 14-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 14-99: Loss: 0.2759 Acc: 75.0000%\n",
      "\tvalidation 14-100: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 14-101: Loss: 0.1198 Acc: 75.0000%\n",
      "\tvalidation 14-102: Loss: 0.2473 Acc: 75.0000%\n",
      "\tvalidation 14-103: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 14-104: Loss: 0.1548 Acc: 50.0000%\n",
      "\tvalidation 14-105: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0808 Acc: 89.4898%\n",
      "\tvalidation Loss: 0.1251 Acc: 81.9048%\n",
      "Time passed 0h 14m 22s\n",
      "--------------------\n",
      "Epoch [15/40]:\n",
      "\ttrain 15-1: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 15-2: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 15-3: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 15-4: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 15-5: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 15-6: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 15-7: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 15-8: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 15-9: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 15-10: Loss: 0.2958 Acc: 75.0000%\n",
      "\ttrain 15-11: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 15-12: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 15-13: Loss: 0.2253 Acc: 75.0000%\n",
      "\ttrain 15-14: Loss: 0.3489 Acc: 75.0000%\n",
      "\ttrain 15-15: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 15-16: Loss: 0.3183 Acc: 50.0000%\n",
      "\ttrain 15-17: Loss: 0.3026 Acc: 75.0000%\n",
      "\ttrain 15-18: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 15-19: Loss: 0.2400 Acc: 75.0000%\n",
      "\ttrain 15-20: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 15-21: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 15-22: Loss: 0.2141 Acc: 50.0000%\n",
      "\ttrain 15-23: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 15-24: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 15-25: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 15-26: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 15-27: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 15-28: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 15-29: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 15-30: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 15-31: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 15-32: Loss: 0.1543 Acc: 50.0000%\n",
      "\ttrain 15-33: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 15-34: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 15-35: Loss: 0.2504 Acc: 50.0000%\n",
      "\ttrain 15-36: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 15-37: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 15-38: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 15-39: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 15-40: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 15-41: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 15-42: Loss: 0.2427 Acc: 75.0000%\n",
      "\ttrain 15-43: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 15-44: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 15-45: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 15-46: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 15-47: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 15-48: Loss: 0.0963 Acc: 100.0000%\n",
      "\ttrain 15-49: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 15-50: Loss: 0.1638 Acc: 75.0000%\n",
      "\ttrain 15-51: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 15-52: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 15-53: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 15-54: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 15-55: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 15-56: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 15-57: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 15-58: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 15-59: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 15-60: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 15-61: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 15-62: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 15-63: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 15-64: Loss: 0.1383 Acc: 50.0000%\n",
      "\ttrain 15-65: Loss: 0.1375 Acc: 75.0000%\n",
      "\ttrain 15-66: Loss: 0.1431 Acc: 75.0000%\n",
      "\ttrain 15-67: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 15-68: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 15-69: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 15-70: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 15-71: Loss: 0.2458 Acc: 75.0000%\n",
      "\ttrain 15-72: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 15-73: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 15-74: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 15-75: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 15-76: Loss: 0.2988 Acc: 75.0000%\n",
      "\ttrain 15-77: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 15-78: Loss: 0.3183 Acc: 75.0000%\n",
      "\ttrain 15-79: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 15-80: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 15-81: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 15-82: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 15-83: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 15-84: Loss: 0.1735 Acc: 75.0000%\n",
      "\ttrain 15-85: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 15-86: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 15-87: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 15-88: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 15-89: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 15-90: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 15-91: Loss: 0.3517 Acc: 50.0000%\n",
      "\ttrain 15-92: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 15-93: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 15-94: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 15-95: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 15-96: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 15-97: Loss: 0.2354 Acc: 75.0000%\n",
      "\ttrain 15-98: Loss: 0.3459 Acc: 75.0000%\n",
      "\ttrain 15-99: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 15-100: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 15-101: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 15-102: Loss: 0.5710 Acc: 25.0000%\n",
      "\ttrain 15-103: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 15-104: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 15-105: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 15-106: Loss: 0.0400 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 15-107: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 15-108: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 15-109: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 15-110: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 15-111: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 15-112: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 15-113: Loss: 0.4063 Acc: 25.0000%\n",
      "\ttrain 15-114: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 15-115: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 15-116: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 15-117: Loss: 0.3261 Acc: 75.0000%\n",
      "\ttrain 15-118: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 15-119: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 15-120: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 15-121: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 15-122: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 15-123: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 15-124: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 15-125: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 15-126: Loss: 0.2075 Acc: 50.0000%\n",
      "\ttrain 15-127: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 15-128: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 15-129: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 15-130: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 15-131: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 15-132: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 15-133: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 15-134: Loss: 0.1499 Acc: 75.0000%\n",
      "\ttrain 15-135: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 15-136: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 15-137: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 15-138: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 15-139: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 15-140: Loss: 0.2642 Acc: 75.0000%\n",
      "\ttrain 15-141: Loss: 0.7380 Acc: 50.0000%\n",
      "\ttrain 15-142: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 15-143: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 15-144: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 15-145: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 15-146: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 15-147: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 15-148: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 15-149: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 15-150: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 15-151: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 15-152: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 15-153: Loss: 0.0567 Acc: 75.0000%\n",
      "\ttrain 15-154: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 15-155: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 15-156: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 15-157: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 15-158: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 15-159: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 15-160: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 15-161: Loss: 0.1930 Acc: 75.0000%\n",
      "\ttrain 15-162: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 15-163: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 15-164: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 15-165: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 15-166: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 15-167: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 15-168: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 15-169: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 15-170: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 15-171: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 15-172: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 15-173: Loss: 0.2025 Acc: 75.0000%\n",
      "\ttrain 15-174: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 15-175: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 15-176: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 15-177: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 15-178: Loss: 0.1383 Acc: 75.0000%\n",
      "\ttrain 15-179: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 15-180: Loss: 0.1794 Acc: 50.0000%\n",
      "\ttrain 15-181: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 15-182: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 15-183: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 15-184: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 15-185: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 15-186: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 15-187: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 15-188: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 15-189: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 15-190: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 15-191: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 15-192: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 15-193: Loss: 0.2608 Acc: 75.0000%\n",
      "\ttrain 15-194: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 15-195: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 15-196: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 15-197: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 15-198: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 15-199: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 15-200: Loss: 0.1469 Acc: 75.0000%\n",
      "\ttrain 15-201: Loss: 0.3462 Acc: 75.0000%\n",
      "\ttrain 15-202: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 15-203: Loss: 0.4668 Acc: 50.0000%\n",
      "\ttrain 15-204: Loss: 0.2189 Acc: 50.0000%\n",
      "\ttrain 15-205: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 15-206: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 15-207: Loss: 0.6231 Acc: 25.0000%\n",
      "\ttrain 15-208: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 15-209: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 15-210: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 15-211: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 15-212: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 15-213: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 15-214: Loss: 0.2349 Acc: 50.0000%\n",
      "\ttrain 15-215: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 15-216: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 15-217: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 15-218: Loss: 0.0536 Acc: 75.0000%\n",
      "\ttrain 15-219: Loss: 0.3615 Acc: 50.0000%\n",
      "\ttrain 15-220: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 15-221: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 15-222: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 15-223: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 15-224: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 15-225: Loss: 0.2129 Acc: 75.0000%\n",
      "\ttrain 15-226: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 15-227: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 15-228: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 15-229: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 15-230: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 15-231: Loss: 0.0462 Acc: 75.0000%\n",
      "\ttrain 15-232: Loss: 0.2612 Acc: 50.0000%\n",
      "\ttrain 15-233: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 15-234: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 15-235: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 15-236: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 15-237: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 15-238: Loss: 0.1403 Acc: 50.0000%\n",
      "\ttrain 15-239: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 15-240: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 15-241: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 15-242: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 15-243: Loss: 0.2412 Acc: 50.0000%\n",
      "\ttrain 15-244: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 15-245: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 15-1: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 15-2: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 15-3: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 15-4: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 15-5: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 15-6: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 15-7: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 15-8: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 15-9: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 15-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-11: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 15-12: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 15-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 15-14: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-15: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 15-16: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 15-17: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 15-18: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 15-19: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 15-20: Loss: 0.0673 Acc: 75.0000%\n",
      "\tvalidation 15-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-22: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 15-23: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 15-24: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 15-25: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 15-26: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-27: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 15-28: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 15-29: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 15-30: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 15-31: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 15-32: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 15-33: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 15-34: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 15-35: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 15-36: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-37: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 15-38: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 15-39: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-40: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 15-41: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 15-42: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 15-43: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 15-44: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 15-45: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 15-46: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 15-47: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 15-48: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 15-49: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 15-50: Loss: 0.0054 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 15-51: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 15-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-53: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 15-54: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 15-55: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 15-56: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 15-57: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 15-58: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 15-59: Loss: 0.0769 Acc: 75.0000%\n",
      "\tvalidation 15-60: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 15-61: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 15-62: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 15-63: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 15-64: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 15-65: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 15-66: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-67: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 15-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 15-69: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 15-70: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 15-71: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 15-72: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 15-73: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-74: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 15-75: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 15-76: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 15-77: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 15-78: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 15-79: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 15-80: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 15-81: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 15-82: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 15-83: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 15-84: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 15-85: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 15-86: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 15-87: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 15-88: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 15-89: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 15-90: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 15-91: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 15-92: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 15-93: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 15-94: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-95: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 15-96: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 15-97: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-98: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 15-99: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 15-100: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 15-101: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 15-102: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 15-103: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 15-104: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 15-105: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0832 Acc: 87.9592%\n",
      "\tvalidation Loss: 0.0091 Acc: 99.5238%\n",
      "网络参数更新\n",
      "Time passed 0h 15m 27s\n",
      "--------------------\n",
      "Epoch [16/40]:\n",
      "\ttrain 16-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 16-2: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 16-3: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 16-4: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 16-5: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 16-6: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 16-7: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 16-8: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 16-9: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 16-10: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 16-11: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 16-12: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 16-13: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 16-14: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 16-15: Loss: 0.2108 Acc: 50.0000%\n",
      "\ttrain 16-16: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 16-17: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 16-18: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 16-19: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 16-20: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 16-21: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 16-22: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 16-23: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 16-24: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 16-25: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 16-26: Loss: 0.2789 Acc: 75.0000%\n",
      "\ttrain 16-27: Loss: 0.2387 Acc: 50.0000%\n",
      "\ttrain 16-28: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 16-29: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 16-30: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 16-31: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 16-32: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 16-33: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 16-34: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 16-35: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 16-36: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 16-37: Loss: 0.2407 Acc: 75.0000%\n",
      "\ttrain 16-38: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 16-39: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 16-40: Loss: 0.0587 Acc: 75.0000%\n",
      "\ttrain 16-41: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 16-42: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 16-43: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 16-44: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 16-45: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 16-46: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 16-47: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 16-48: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 16-49: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 16-50: Loss: 0.1802 Acc: 75.0000%\n",
      "\ttrain 16-51: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 16-52: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 16-53: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 16-54: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 16-55: Loss: 0.3507 Acc: 50.0000%\n",
      "\ttrain 16-56: Loss: 0.5007 Acc: 50.0000%\n",
      "\ttrain 16-57: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 16-58: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 16-59: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 16-60: Loss: 0.3801 Acc: 50.0000%\n",
      "\ttrain 16-61: Loss: 0.3284 Acc: 75.0000%\n",
      "\ttrain 16-62: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 16-63: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 16-64: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 16-65: Loss: 0.1449 Acc: 75.0000%\n",
      "\ttrain 16-66: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 16-67: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 16-68: Loss: 0.2664 Acc: 50.0000%\n",
      "\ttrain 16-69: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 16-70: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 16-71: Loss: 0.2733 Acc: 75.0000%\n",
      "\ttrain 16-72: Loss: 0.3316 Acc: 50.0000%\n",
      "\ttrain 16-73: Loss: 0.0671 Acc: 100.0000%\n",
      "\ttrain 16-74: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 16-75: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 16-76: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 16-77: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 16-78: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 16-79: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 16-80: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 16-81: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 16-82: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 16-83: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 16-84: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 16-85: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 16-86: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 16-87: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 16-88: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 16-89: Loss: 0.4446 Acc: 25.0000%\n",
      "\ttrain 16-90: Loss: 0.1808 Acc: 50.0000%\n",
      "\ttrain 16-91: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 16-92: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 16-93: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 16-94: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 16-95: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 16-96: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 16-97: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 16-98: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 16-99: Loss: 0.2077 Acc: 75.0000%\n",
      "\ttrain 16-100: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 16-101: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 16-102: Loss: 0.2302 Acc: 50.0000%\n",
      "\ttrain 16-103: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 16-104: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 16-105: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 16-106: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 16-107: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 16-108: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 16-109: Loss: 0.0526 Acc: 75.0000%\n",
      "\ttrain 16-110: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 16-111: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 16-112: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 16-113: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 16-114: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 16-115: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 16-116: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 16-117: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 16-118: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 16-119: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 16-120: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 16-121: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 16-122: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 16-123: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 16-124: Loss: 0.1985 Acc: 75.0000%\n",
      "\ttrain 16-125: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 16-126: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 16-127: Loss: 0.0947 Acc: 100.0000%\n",
      "\ttrain 16-128: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 16-129: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 16-130: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 16-131: Loss: 0.0098 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 16-132: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 16-133: Loss: 0.3072 Acc: 50.0000%\n",
      "\ttrain 16-134: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 16-135: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 16-136: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 16-137: Loss: 0.8588 Acc: 25.0000%\n",
      "\ttrain 16-138: Loss: 0.1649 Acc: 75.0000%\n",
      "\ttrain 16-139: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 16-140: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 16-141: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 16-142: Loss: 0.2506 Acc: 50.0000%\n",
      "\ttrain 16-143: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 16-144: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 16-145: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 16-146: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 16-147: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 16-148: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 16-149: Loss: 0.2796 Acc: 50.0000%\n",
      "\ttrain 16-150: Loss: 0.1094 Acc: 100.0000%\n",
      "\ttrain 16-151: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 16-152: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 16-153: Loss: 0.3223 Acc: 75.0000%\n",
      "\ttrain 16-154: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 16-155: Loss: 0.1864 Acc: 75.0000%\n",
      "\ttrain 16-156: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 16-157: Loss: 0.0830 Acc: 100.0000%\n",
      "\ttrain 16-158: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 16-159: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 16-160: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 16-161: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 16-162: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 16-163: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 16-164: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 16-165: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 16-166: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 16-167: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 16-168: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 16-169: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 16-170: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 16-171: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 16-172: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 16-173: Loss: 0.3386 Acc: 50.0000%\n",
      "\ttrain 16-174: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 16-175: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 16-176: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 16-177: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 16-178: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 16-179: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 16-180: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 16-181: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 16-182: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 16-183: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 16-184: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 16-185: Loss: 0.2411 Acc: 75.0000%\n",
      "\ttrain 16-186: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 16-187: Loss: 0.3536 Acc: 50.0000%\n",
      "\ttrain 16-188: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 16-189: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 16-190: Loss: 0.0721 Acc: 100.0000%\n",
      "\ttrain 16-191: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 16-192: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 16-193: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 16-194: Loss: 0.1938 Acc: 50.0000%\n",
      "\ttrain 16-195: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 16-196: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 16-197: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 16-198: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 16-199: Loss: 0.1793 Acc: 25.0000%\n",
      "\ttrain 16-200: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 16-201: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 16-202: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 16-203: Loss: 0.2195 Acc: 75.0000%\n",
      "\ttrain 16-204: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 16-205: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 16-206: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 16-207: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 16-208: Loss: 0.1805 Acc: 50.0000%\n",
      "\ttrain 16-209: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 16-210: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 16-211: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 16-212: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 16-213: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 16-214: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 16-215: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 16-216: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 16-217: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 16-218: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 16-219: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 16-220: Loss: 0.3979 Acc: 25.0000%\n",
      "\ttrain 16-221: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 16-222: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 16-223: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 16-224: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 16-225: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 16-226: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 16-227: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 16-228: Loss: 0.2680 Acc: 50.0000%\n",
      "\ttrain 16-229: Loss: 0.0446 Acc: 75.0000%\n",
      "\ttrain 16-230: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 16-231: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 16-232: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 16-233: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 16-234: Loss: 0.2483 Acc: 75.0000%\n",
      "\ttrain 16-235: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 16-236: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 16-237: Loss: 0.3377 Acc: 50.0000%\n",
      "\ttrain 16-238: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 16-239: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 16-240: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 16-241: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 16-242: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 16-243: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 16-244: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 16-245: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-1: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 16-2: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 16-3: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 16-4: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 16-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-6: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 16-7: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 16-8: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-9: Loss: 0.2761 Acc: 75.0000%\n",
      "\tvalidation 16-10: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 16-11: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 16-12: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 16-13: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 16-14: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 16-15: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 16-16: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 16-17: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 16-18: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 16-19: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 16-20: Loss: 0.1084 Acc: 75.0000%\n",
      "\tvalidation 16-21: Loss: 0.0372 Acc: 100.0000%\n",
      "\tvalidation 16-22: Loss: 0.0599 Acc: 75.0000%\n",
      "\tvalidation 16-23: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 16-24: Loss: 0.0614 Acc: 75.0000%\n",
      "\tvalidation 16-25: Loss: 0.0879 Acc: 75.0000%\n",
      "\tvalidation 16-26: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 16-27: Loss: 0.1094 Acc: 75.0000%\n",
      "\tvalidation 16-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-29: Loss: 0.0890 Acc: 75.0000%\n",
      "\tvalidation 16-30: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 16-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-32: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 16-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-34: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 16-35: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 16-36: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 16-37: Loss: 0.0580 Acc: 100.0000%\n",
      "\tvalidation 16-38: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 16-39: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-40: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 16-41: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 16-42: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 16-43: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-44: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 16-45: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 16-46: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 16-47: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 16-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-49: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 16-50: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 16-51: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 16-52: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 16-53: Loss: 0.0705 Acc: 75.0000%\n",
      "\tvalidation 16-54: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 16-55: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 16-56: Loss: 0.0504 Acc: 100.0000%\n",
      "\tvalidation 16-57: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 16-58: Loss: 0.0502 Acc: 100.0000%\n",
      "\tvalidation 16-59: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 16-60: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 16-61: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 16-62: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-64: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 16-65: Loss: 0.0681 Acc: 100.0000%\n",
      "\tvalidation 16-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-67: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 16-68: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-69: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 16-70: Loss: 0.0405 Acc: 100.0000%\n",
      "\tvalidation 16-71: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 16-72: Loss: 0.1609 Acc: 75.0000%\n",
      "\tvalidation 16-73: Loss: 0.0148 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 16-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-75: Loss: 0.1834 Acc: 75.0000%\n",
      "\tvalidation 16-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-77: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 16-78: Loss: 0.1451 Acc: 75.0000%\n",
      "\tvalidation 16-79: Loss: 0.0635 Acc: 75.0000%\n",
      "\tvalidation 16-80: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 16-81: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 16-82: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 16-83: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 16-84: Loss: 0.1311 Acc: 75.0000%\n",
      "\tvalidation 16-85: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 16-86: Loss: 0.1018 Acc: 75.0000%\n",
      "\tvalidation 16-87: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-88: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-89: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 16-90: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 16-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-92: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 16-93: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 16-94: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 16-95: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 16-96: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 16-97: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 16-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-99: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 16-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-101: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 16-102: Loss: 0.0467 Acc: 100.0000%\n",
      "\tvalidation 16-103: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 16-104: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 16-105: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0792 Acc: 87.9592%\n",
      "\tvalidation Loss: 0.0265 Acc: 96.4286%\n",
      "Time passed 0h 16m 30s\n",
      "--------------------\n",
      "Epoch [17/40]:\n",
      "\ttrain 17-1: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 17-2: Loss: 0.2441 Acc: 75.0000%\n",
      "\ttrain 17-3: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 17-4: Loss: 0.2241 Acc: 50.0000%\n",
      "\ttrain 17-5: Loss: 0.2216 Acc: 50.0000%\n",
      "\ttrain 17-6: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 17-7: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 17-8: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 17-9: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 17-10: Loss: 0.2093 Acc: 50.0000%\n",
      "\ttrain 17-11: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 17-12: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 17-13: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 17-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 17-15: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 17-16: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 17-17: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 17-18: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 17-19: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 17-20: Loss: 0.2388 Acc: 50.0000%\n",
      "\ttrain 17-21: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 17-22: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 17-23: Loss: 0.2377 Acc: 50.0000%\n",
      "\ttrain 17-24: Loss: 0.1653 Acc: 50.0000%\n",
      "\ttrain 17-25: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 17-26: Loss: 0.1083 Acc: 50.0000%\n",
      "\ttrain 17-27: Loss: 0.2045 Acc: 50.0000%\n",
      "\ttrain 17-28: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 17-29: Loss: 0.2447 Acc: 50.0000%\n",
      "\ttrain 17-30: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 17-31: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 17-32: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 17-33: Loss: 0.5670 Acc: 25.0000%\n",
      "\ttrain 17-34: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-35: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 17-36: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 17-37: Loss: 0.2089 Acc: 50.0000%\n",
      "\ttrain 17-38: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 17-39: Loss: 0.2491 Acc: 75.0000%\n",
      "\ttrain 17-40: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 17-41: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 17-42: Loss: 0.1166 Acc: 50.0000%\n",
      "\ttrain 17-43: Loss: 0.1652 Acc: 75.0000%\n",
      "\ttrain 17-44: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 17-45: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 17-46: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 17-47: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 17-48: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 17-49: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 17-50: Loss: 0.4037 Acc: 50.0000%\n",
      "\ttrain 17-51: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 17-52: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 17-53: Loss: 0.1560 Acc: 50.0000%\n",
      "\ttrain 17-54: Loss: 0.2240 Acc: 75.0000%\n",
      "\ttrain 17-55: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 17-56: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 17-57: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 17-58: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 17-59: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 17-60: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 17-61: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 17-62: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 17-63: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 17-64: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 17-65: Loss: 0.2479 Acc: 75.0000%\n",
      "\ttrain 17-66: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 17-67: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 17-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-69: Loss: 0.2428 Acc: 50.0000%\n",
      "\ttrain 17-70: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 17-71: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 17-72: Loss: 0.2080 Acc: 50.0000%\n",
      "\ttrain 17-73: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 17-74: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 17-75: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 17-76: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 17-77: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 17-78: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 17-79: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 17-80: Loss: 0.0725 Acc: 75.0000%\n",
      "\ttrain 17-81: Loss: 0.1560 Acc: 75.0000%\n",
      "\ttrain 17-82: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 17-83: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 17-84: Loss: 0.5899 Acc: 50.0000%\n",
      "\ttrain 17-85: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 17-86: Loss: 0.2889 Acc: 25.0000%\n",
      "\ttrain 17-87: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 17-88: Loss: 0.2331 Acc: 25.0000%\n",
      "\ttrain 17-89: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 17-90: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 17-91: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 17-92: Loss: 0.5728 Acc: 75.0000%\n",
      "\ttrain 17-93: Loss: 0.4465 Acc: 75.0000%\n",
      "\ttrain 17-94: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 17-95: Loss: 0.4226 Acc: 25.0000%\n",
      "\ttrain 17-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 17-97: Loss: 0.0603 Acc: 100.0000%\n",
      "\ttrain 17-98: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 17-99: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 17-100: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 17-101: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-102: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 17-103: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 17-104: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 17-105: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 17-106: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 17-107: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-108: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 17-109: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-110: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-111: Loss: 0.4376 Acc: 75.0000%\n",
      "\ttrain 17-112: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 17-113: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 17-114: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 17-115: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 17-116: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 17-117: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 17-118: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 17-119: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 17-120: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 17-121: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 17-122: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 17-123: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 17-124: Loss: 0.4038 Acc: 75.0000%\n",
      "\ttrain 17-125: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 17-126: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-127: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 17-128: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 17-129: Loss: 0.8350 Acc: 50.0000%\n",
      "\ttrain 17-130: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 17-131: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 17-132: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 17-133: Loss: 0.6066 Acc: 50.0000%\n",
      "\ttrain 17-134: Loss: 0.2843 Acc: 75.0000%\n",
      "\ttrain 17-135: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 17-136: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 17-137: Loss: 0.2791 Acc: 75.0000%\n",
      "\ttrain 17-138: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-139: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 17-140: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 17-141: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 17-142: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 17-143: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 17-144: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 17-145: Loss: 0.5715 Acc: 75.0000%\n",
      "\ttrain 17-146: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 17-147: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-148: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 17-149: Loss: 0.2254 Acc: 75.0000%\n",
      "\ttrain 17-150: Loss: 0.2221 Acc: 50.0000%\n",
      "\ttrain 17-151: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 17-152: Loss: 0.4966 Acc: 50.0000%\n",
      "\ttrain 17-153: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 17-154: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 17-155: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 17-156: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 17-157: Loss: 0.0302 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-158: Loss: 0.0529 Acc: 75.0000%\n",
      "\ttrain 17-159: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 17-160: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 17-161: Loss: 0.1191 Acc: 50.0000%\n",
      "\ttrain 17-162: Loss: 0.2335 Acc: 75.0000%\n",
      "\ttrain 17-163: Loss: 0.2162 Acc: 75.0000%\n",
      "\ttrain 17-164: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 17-165: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 17-166: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 17-167: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 17-168: Loss: 0.1772 Acc: 75.0000%\n",
      "\ttrain 17-169: Loss: 0.2555 Acc: 50.0000%\n",
      "\ttrain 17-170: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 17-171: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 17-172: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 17-173: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 17-174: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 17-175: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 17-176: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 17-177: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 17-178: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 17-179: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 17-180: Loss: 0.1919 Acc: 75.0000%\n",
      "\ttrain 17-181: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 17-182: Loss: 0.4707 Acc: 50.0000%\n",
      "\ttrain 17-183: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 17-184: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 17-185: Loss: 0.3602 Acc: 25.0000%\n",
      "\ttrain 17-186: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 17-187: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 17-188: Loss: 0.1513 Acc: 75.0000%\n",
      "\ttrain 17-189: Loss: 0.2542 Acc: 50.0000%\n",
      "\ttrain 17-190: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 17-191: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 17-192: Loss: 0.2647 Acc: 75.0000%\n",
      "\ttrain 17-193: Loss: 0.2860 Acc: 50.0000%\n",
      "\ttrain 17-194: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 17-195: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 17-196: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 17-197: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 17-198: Loss: 0.3023 Acc: 50.0000%\n",
      "\ttrain 17-199: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 17-200: Loss: 0.5794 Acc: 25.0000%\n",
      "\ttrain 17-201: Loss: 0.2260 Acc: 75.0000%\n",
      "\ttrain 17-202: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 17-203: Loss: 0.1597 Acc: 75.0000%\n",
      "\ttrain 17-204: Loss: 0.4203 Acc: 25.0000%\n",
      "\ttrain 17-205: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 17-206: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 17-207: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 17-208: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 17-209: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 17-210: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 17-211: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 17-212: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 17-213: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 17-214: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 17-215: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 17-216: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 17-217: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 17-218: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 17-219: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 17-220: Loss: 0.1706 Acc: 50.0000%\n",
      "\ttrain 17-221: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 17-222: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 17-223: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 17-224: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 17-225: Loss: 0.5490 Acc: 25.0000%\n",
      "\ttrain 17-226: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 17-227: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 17-228: Loss: 0.4325 Acc: 50.0000%\n",
      "\ttrain 17-229: Loss: 0.3894 Acc: 75.0000%\n",
      "\ttrain 17-230: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 17-231: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 17-232: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 17-233: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 17-234: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 17-235: Loss: 0.0484 Acc: 75.0000%\n",
      "\ttrain 17-236: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 17-237: Loss: 0.1550 Acc: 75.0000%\n",
      "\ttrain 17-238: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 17-239: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 17-240: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 17-241: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 17-242: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 17-243: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 17-244: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 17-245: Loss: 0.8610 Acc: 50.0000%\n",
      "\tvalidation 17-1: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 17-2: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-3: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 17-4: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-5: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 17-6: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 17-7: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 17-8: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 17-9: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 17-10: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 17-11: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-12: Loss: 0.0477 Acc: 75.0000%\n",
      "\tvalidation 17-13: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 17-14: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 17-15: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 17-16: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 17-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-18: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 17-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-20: Loss: 0.0520 Acc: 75.0000%\n",
      "\tvalidation 17-21: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 17-22: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 17-23: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 17-24: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 17-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-26: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 17-27: Loss: 0.0994 Acc: 75.0000%\n",
      "\tvalidation 17-28: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 17-29: Loss: 0.0424 Acc: 100.0000%\n",
      "\tvalidation 17-30: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 17-31: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 17-32: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-33: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 17-34: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 17-35: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 17-36: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 17-37: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 17-38: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-39: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 17-40: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 17-41: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 17-42: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 17-43: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 17-44: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 17-45: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 17-46: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 17-47: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 17-48: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 17-49: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-50: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 17-51: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-52: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-53: Loss: 0.0725 Acc: 75.0000%\n",
      "\tvalidation 17-54: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 17-55: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 17-56: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 17-57: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 17-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-59: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-60: Loss: 0.1082 Acc: 75.0000%\n",
      "\tvalidation 17-61: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-62: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 17-63: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 17-64: Loss: 0.2342 Acc: 75.0000%\n",
      "\tvalidation 17-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-66: Loss: 0.0713 Acc: 75.0000%\n",
      "\tvalidation 17-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-68: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 17-69: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 17-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-71: Loss: 0.0494 Acc: 100.0000%\n",
      "\tvalidation 17-72: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 17-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-74: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 17-75: Loss: 0.0464 Acc: 100.0000%\n",
      "\tvalidation 17-76: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-77: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 17-78: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 17-79: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-80: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-81: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 17-82: Loss: 0.0783 Acc: 75.0000%\n",
      "\tvalidation 17-83: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 17-84: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-85: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 17-86: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 17-87: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 17-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-89: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 17-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-92: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 17-93: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 17-94: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 17-95: Loss: 0.1855 Acc: 50.0000%\n",
      "\tvalidation 17-96: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 17-97: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 17-98: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 17-99: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 17-100: Loss: 0.0103 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 17-101: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 17-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-103: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 17-104: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 17-105: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1096 Acc: 84.4898%\n",
      "\tvalidation Loss: 0.0167 Acc: 97.6190%\n",
      "Time passed 0h 17m 13s\n",
      "--------------------\n",
      "Epoch [18/40]:\n",
      "\ttrain 18-1: Loss: 0.3587 Acc: 75.0000%\n",
      "\ttrain 18-2: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 18-3: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 18-4: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 18-5: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 18-6: Loss: 0.2415 Acc: 75.0000%\n",
      "\ttrain 18-7: Loss: 0.2918 Acc: 75.0000%\n",
      "\ttrain 18-8: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 18-9: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 18-10: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 18-11: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 18-12: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 18-13: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 18-14: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 18-15: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 18-16: Loss: 0.1781 Acc: 50.0000%\n",
      "\ttrain 18-17: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 18-18: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 18-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 18-20: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 18-21: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 18-22: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 18-23: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 18-24: Loss: 0.2380 Acc: 50.0000%\n",
      "\ttrain 18-25: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 18-26: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 18-27: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 18-28: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 18-29: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 18-30: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 18-31: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 18-32: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 18-33: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 18-34: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 18-35: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 18-36: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 18-37: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-38: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 18-39: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 18-40: Loss: 0.2778 Acc: 50.0000%\n",
      "\ttrain 18-41: Loss: 0.1701 Acc: 50.0000%\n",
      "\ttrain 18-42: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 18-43: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 18-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 18-45: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 18-46: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 18-47: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 18-48: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 18-49: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 18-50: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 18-51: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 18-52: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 18-53: Loss: 0.3561 Acc: 25.0000%\n",
      "\ttrain 18-54: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 18-55: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 18-56: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 18-57: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 18-58: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 18-59: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 18-60: Loss: 0.1892 Acc: 75.0000%\n",
      "\ttrain 18-61: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 18-62: Loss: 0.0493 Acc: 75.0000%\n",
      "\ttrain 18-63: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 18-64: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 18-65: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 18-66: Loss: 0.2867 Acc: 75.0000%\n",
      "\ttrain 18-67: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 18-68: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 18-69: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 18-70: Loss: 0.1305 Acc: 50.0000%\n",
      "\ttrain 18-71: Loss: 0.7370 Acc: 0.0000%\n",
      "\ttrain 18-72: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 18-73: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 18-74: Loss: 0.2706 Acc: 75.0000%\n",
      "\ttrain 18-75: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 18-76: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 18-77: Loss: 0.3020 Acc: 75.0000%\n",
      "\ttrain 18-78: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 18-79: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 18-80: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 18-81: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 18-82: Loss: 0.0611 Acc: 75.0000%\n",
      "\ttrain 18-83: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 18-84: Loss: 0.1885 Acc: 75.0000%\n",
      "\ttrain 18-85: Loss: 0.1878 Acc: 75.0000%\n",
      "\ttrain 18-86: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 18-87: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 18-88: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 18-89: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 18-90: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 18-91: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 18-92: Loss: 0.5255 Acc: 50.0000%\n",
      "\ttrain 18-93: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 18-94: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 18-95: Loss: 0.1474 Acc: 50.0000%\n",
      "\ttrain 18-96: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 18-97: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 18-98: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 18-99: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 18-100: Loss: 0.2279 Acc: 75.0000%\n",
      "\ttrain 18-101: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 18-102: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 18-103: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 18-104: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 18-105: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 18-106: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 18-107: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 18-108: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 18-109: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 18-110: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 18-111: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 18-112: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 18-113: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 18-114: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 18-115: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 18-116: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 18-117: Loss: 0.3515 Acc: 75.0000%\n",
      "\ttrain 18-118: Loss: 0.1908 Acc: 75.0000%\n",
      "\ttrain 18-119: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 18-120: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 18-121: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 18-122: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 18-123: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 18-124: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 18-125: Loss: 0.2770 Acc: 75.0000%\n",
      "\ttrain 18-126: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 18-127: Loss: 0.1428 Acc: 50.0000%\n",
      "\ttrain 18-128: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 18-129: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 18-130: Loss: 0.1707 Acc: 50.0000%\n",
      "\ttrain 18-131: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 18-132: Loss: 0.2814 Acc: 75.0000%\n",
      "\ttrain 18-133: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 18-134: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 18-135: Loss: 0.0934 Acc: 100.0000%\n",
      "\ttrain 18-136: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 18-137: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 18-138: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 18-139: Loss: 0.1274 Acc: 50.0000%\n",
      "\ttrain 18-140: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 18-141: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 18-142: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 18-143: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 18-144: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 18-145: Loss: 0.1505 Acc: 50.0000%\n",
      "\ttrain 18-146: Loss: 0.0683 Acc: 100.0000%\n",
      "\ttrain 18-147: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 18-148: Loss: 0.2094 Acc: 75.0000%\n",
      "\ttrain 18-149: Loss: 0.5059 Acc: 50.0000%\n",
      "\ttrain 18-150: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 18-151: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 18-152: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 18-153: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 18-154: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 18-155: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-156: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 18-157: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 18-158: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 18-159: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 18-160: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 18-161: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 18-162: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-163: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 18-164: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 18-165: Loss: 0.4106 Acc: 50.0000%\n",
      "\ttrain 18-166: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 18-167: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 18-168: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 18-169: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 18-170: Loss: 0.0751 Acc: 100.0000%\n",
      "\ttrain 18-171: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 18-172: Loss: 0.2498 Acc: 75.0000%\n",
      "\ttrain 18-173: Loss: 0.0983 Acc: 75.0000%\n",
      "\ttrain 18-174: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 18-175: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 18-176: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 18-177: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 18-178: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 18-179: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 18-180: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 18-181: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 18-182: Loss: 0.4887 Acc: 25.0000%\n",
      "\ttrain 18-183: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 18-184: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 18-185: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 18-186: Loss: 0.1757 Acc: 75.0000%\n",
      "\ttrain 18-187: Loss: 0.2059 Acc: 75.0000%\n",
      "\ttrain 18-188: Loss: 0.2264 Acc: 50.0000%\n",
      "\ttrain 18-189: Loss: 0.0226 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-190: Loss: 0.2672 Acc: 75.0000%\n",
      "\ttrain 18-191: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-192: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 18-193: Loss: 1.0270 Acc: 0.0000%\n",
      "\ttrain 18-194: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 18-195: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 18-196: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 18-197: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 18-198: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 18-199: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 18-200: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 18-201: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 18-202: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 18-203: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 18-204: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 18-205: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 18-206: Loss: 0.2784 Acc: 75.0000%\n",
      "\ttrain 18-207: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 18-208: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 18-209: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 18-210: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 18-211: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 18-212: Loss: 0.5871 Acc: 50.0000%\n",
      "\ttrain 18-213: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 18-214: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 18-215: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 18-216: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 18-217: Loss: 0.2214 Acc: 50.0000%\n",
      "\ttrain 18-218: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 18-219: Loss: 0.2403 Acc: 50.0000%\n",
      "\ttrain 18-220: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 18-221: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 18-222: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 18-223: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 18-224: Loss: 0.0563 Acc: 75.0000%\n",
      "\ttrain 18-225: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 18-226: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 18-227: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 18-228: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 18-229: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 18-230: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 18-231: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 18-232: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 18-233: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 18-234: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-235: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 18-236: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 18-237: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 18-238: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 18-239: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-240: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 18-241: Loss: 0.1272 Acc: 50.0000%\n",
      "\ttrain 18-242: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 18-243: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 18-244: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 18-245: Loss: 0.3207 Acc: 50.0000%\n",
      "\tvalidation 18-1: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 18-2: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 18-3: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-4: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 18-5: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 18-6: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 18-7: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 18-8: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 18-9: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 18-10: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 18-11: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 18-12: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 18-13: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 18-14: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 18-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-16: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 18-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-18: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 18-19: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 18-20: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-21: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 18-22: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 18-23: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 18-24: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 18-25: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 18-26: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 18-27: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 18-28: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-29: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 18-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-31: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 18-32: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 18-33: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 18-34: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 18-35: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-36: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 18-37: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-38: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 18-39: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 18-40: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 18-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 18-42: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 18-43: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 18-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-45: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 18-46: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 18-47: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 18-48: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 18-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-50: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 18-51: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 18-52: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 18-53: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 18-54: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 18-55: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 18-56: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 18-57: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-58: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-59: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 18-60: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 18-61: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 18-62: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 18-63: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 18-64: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 18-65: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 18-66: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-67: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 18-68: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 18-69: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 18-70: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 18-71: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 18-72: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 18-73: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 18-74: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 18-75: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 18-76: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-77: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 18-78: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 18-79: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 18-80: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-81: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 18-82: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 18-83: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 18-84: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 18-85: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 18-86: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 18-87: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 18-88: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 18-89: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 18-90: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 18-91: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 18-92: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 18-93: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-94: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 18-95: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-96: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-97: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 18-98: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 18-99: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 18-100: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 18-101: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 18-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 18-103: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 18-104: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 18-105: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0869 Acc: 86.9388%\n",
      "\tvalidation Loss: 0.0063 Acc: 100.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 17m 54s\n",
      "--------------------\n",
      "Epoch [19/40]:\n",
      "\ttrain 19-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 19-2: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 19-3: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 19-4: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 19-5: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 19-6: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 19-7: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 19-8: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 19-9: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-10: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 19-11: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 19-12: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 19-13: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 19-14: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 19-15: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 19-16: Loss: 0.0825 Acc: 100.0000%\n",
      "\ttrain 19-17: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 19-18: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 19-19: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 19-20: Loss: 0.0053 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-21: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 19-22: Loss: 0.2412 Acc: 50.0000%\n",
      "\ttrain 19-23: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 19-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 19-25: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 19-26: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 19-27: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 19-28: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 19-29: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 19-30: Loss: 0.3088 Acc: 75.0000%\n",
      "\ttrain 19-31: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 19-32: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 19-33: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 19-34: Loss: 0.0786 Acc: 100.0000%\n",
      "\ttrain 19-35: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 19-36: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 19-37: Loss: 0.3556 Acc: 50.0000%\n",
      "\ttrain 19-38: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 19-39: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 19-40: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 19-41: Loss: 0.1529 Acc: 75.0000%\n",
      "\ttrain 19-42: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 19-43: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 19-44: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 19-45: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 19-46: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 19-47: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 19-48: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 19-49: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 19-50: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 19-51: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 19-52: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 19-53: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 19-54: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 19-55: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 19-56: Loss: 0.0562 Acc: 75.0000%\n",
      "\ttrain 19-57: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 19-58: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 19-59: Loss: 0.2435 Acc: 50.0000%\n",
      "\ttrain 19-60: Loss: 0.4000 Acc: 50.0000%\n",
      "\ttrain 19-61: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 19-62: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 19-63: Loss: 0.2507 Acc: 50.0000%\n",
      "\ttrain 19-64: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 19-65: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 19-66: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 19-67: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 19-68: Loss: 0.2161 Acc: 75.0000%\n",
      "\ttrain 19-69: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 19-70: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 19-71: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 19-72: Loss: 0.5785 Acc: 75.0000%\n",
      "\ttrain 19-73: Loss: 0.0801 Acc: 100.0000%\n",
      "\ttrain 19-74: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 19-75: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 19-76: Loss: 0.1150 Acc: 50.0000%\n",
      "\ttrain 19-77: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 19-78: Loss: 0.2862 Acc: 75.0000%\n",
      "\ttrain 19-79: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 19-80: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 19-81: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 19-82: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 19-83: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 19-84: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 19-85: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 19-86: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 19-87: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 19-88: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 19-89: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 19-90: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 19-91: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 19-92: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 19-93: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 19-94: Loss: 0.2678 Acc: 50.0000%\n",
      "\ttrain 19-95: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 19-96: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 19-97: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 19-98: Loss: 0.2170 Acc: 50.0000%\n",
      "\ttrain 19-99: Loss: 0.0600 Acc: 100.0000%\n",
      "\ttrain 19-100: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 19-101: Loss: 0.1774 Acc: 50.0000%\n",
      "\ttrain 19-102: Loss: 0.6898 Acc: 25.0000%\n",
      "\ttrain 19-103: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 19-104: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 19-105: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 19-106: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 19-107: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 19-108: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 19-109: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 19-110: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 19-111: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 19-112: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 19-113: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 19-114: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 19-115: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 19-116: Loss: 0.6203 Acc: 25.0000%\n",
      "\ttrain 19-117: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 19-118: Loss: 0.2780 Acc: 50.0000%\n",
      "\ttrain 19-119: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 19-120: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 19-121: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 19-122: Loss: 0.2650 Acc: 50.0000%\n",
      "\ttrain 19-123: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 19-124: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 19-125: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 19-126: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 19-127: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 19-128: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 19-129: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 19-130: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 19-131: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 19-132: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 19-133: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 19-134: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 19-135: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 19-136: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 19-137: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 19-138: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 19-139: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 19-140: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 19-141: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 19-142: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 19-143: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 19-144: Loss: 0.1521 Acc: 50.0000%\n",
      "\ttrain 19-145: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 19-146: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 19-147: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 19-148: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 19-149: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 19-150: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 19-151: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 19-152: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 19-153: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 19-154: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 19-155: Loss: 0.3203 Acc: 50.0000%\n",
      "\ttrain 19-156: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 19-157: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 19-158: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 19-159: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 19-160: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 19-161: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 19-162: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 19-163: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 19-164: Loss: 0.2291 Acc: 75.0000%\n",
      "\ttrain 19-165: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 19-166: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 19-167: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 19-168: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 19-169: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 19-170: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 19-171: Loss: 0.1393 Acc: 50.0000%\n",
      "\ttrain 19-172: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 19-173: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 19-174: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 19-175: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 19-176: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 19-177: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 19-178: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 19-179: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 19-180: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 19-181: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 19-182: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 19-183: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 19-184: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 19-185: Loss: 0.2916 Acc: 75.0000%\n",
      "\ttrain 19-186: Loss: 0.0979 Acc: 50.0000%\n",
      "\ttrain 19-187: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 19-188: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 19-189: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 19-190: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 19-191: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 19-192: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 19-193: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 19-194: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 19-195: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 19-196: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 19-197: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 19-198: Loss: 0.1750 Acc: 75.0000%\n",
      "\ttrain 19-199: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 19-200: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 19-201: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 19-202: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 19-203: Loss: 0.2603 Acc: 75.0000%\n",
      "\ttrain 19-204: Loss: 0.4010 Acc: 75.0000%\n",
      "\ttrain 19-205: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 19-206: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-207: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-208: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 19-209: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 19-210: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 19-211: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 19-212: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 19-213: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 19-214: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 19-215: Loss: 0.0027 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-216: Loss: 0.1690 Acc: 75.0000%\n",
      "\ttrain 19-217: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 19-218: Loss: 0.3923 Acc: 50.0000%\n",
      "\ttrain 19-219: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-220: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 19-221: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 19-222: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 19-223: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 19-224: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 19-225: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 19-226: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 19-227: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 19-228: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 19-229: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 19-230: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 19-231: Loss: 0.1804 Acc: 75.0000%\n",
      "\ttrain 19-232: Loss: 0.2670 Acc: 50.0000%\n",
      "\ttrain 19-233: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 19-234: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-235: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 19-236: Loss: 0.4680 Acc: 75.0000%\n",
      "\ttrain 19-237: Loss: 0.3171 Acc: 50.0000%\n",
      "\ttrain 19-238: Loss: 0.2313 Acc: 50.0000%\n",
      "\ttrain 19-239: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 19-240: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 19-241: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 19-242: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 19-243: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 19-244: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 19-245: Loss: 0.0473 Acc: 100.0000%\n",
      "\tvalidation 19-1: Loss: 0.1858 Acc: 75.0000%\n",
      "\tvalidation 19-2: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 19-3: Loss: 0.5998 Acc: 50.0000%\n",
      "\tvalidation 19-4: Loss: 0.2960 Acc: 75.0000%\n",
      "\tvalidation 19-5: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 19-6: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 19-7: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 19-8: Loss: 0.3681 Acc: 50.0000%\n",
      "\tvalidation 19-9: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 19-10: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 19-11: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-12: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 19-13: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 19-14: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 19-15: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 19-16: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 19-17: Loss: 0.0985 Acc: 75.0000%\n",
      "\tvalidation 19-18: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-19: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 19-20: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 19-21: Loss: 0.0506 Acc: 75.0000%\n",
      "\tvalidation 19-22: Loss: 0.1350 Acc: 75.0000%\n",
      "\tvalidation 19-23: Loss: 0.4029 Acc: 50.0000%\n",
      "\tvalidation 19-24: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 19-25: Loss: 0.3685 Acc: 50.0000%\n",
      "\tvalidation 19-26: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 19-27: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 19-28: Loss: 0.2001 Acc: 50.0000%\n",
      "\tvalidation 19-29: Loss: 0.1218 Acc: 50.0000%\n",
      "\tvalidation 19-30: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 19-31: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 19-32: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 19-33: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 19-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-35: Loss: 0.1864 Acc: 75.0000%\n",
      "\tvalidation 19-36: Loss: 0.0993 Acc: 75.0000%\n",
      "\tvalidation 19-37: Loss: 0.3595 Acc: 50.0000%\n",
      "\tvalidation 19-38: Loss: 0.1007 Acc: 75.0000%\n",
      "\tvalidation 19-39: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 19-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-41: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 19-42: Loss: 0.0513 Acc: 75.0000%\n",
      "\tvalidation 19-43: Loss: 0.1887 Acc: 75.0000%\n",
      "\tvalidation 19-44: Loss: 0.0586 Acc: 75.0000%\n",
      "\tvalidation 19-45: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 19-46: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 19-47: Loss: 0.3094 Acc: 50.0000%\n",
      "\tvalidation 19-48: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 19-49: Loss: 0.1716 Acc: 75.0000%\n",
      "\tvalidation 19-50: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 19-51: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 19-52: Loss: 0.3319 Acc: 75.0000%\n",
      "\tvalidation 19-53: Loss: 0.0552 Acc: 75.0000%\n",
      "\tvalidation 19-54: Loss: 0.0541 Acc: 75.0000%\n",
      "\tvalidation 19-55: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-56: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-58: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 19-59: Loss: 0.2752 Acc: 75.0000%\n",
      "\tvalidation 19-60: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 19-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-62: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 19-63: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 19-64: Loss: 0.2641 Acc: 50.0000%\n",
      "\tvalidation 19-65: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 19-66: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 19-67: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 19-68: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 19-69: Loss: 0.0917 Acc: 75.0000%\n",
      "\tvalidation 19-70: Loss: 0.0717 Acc: 75.0000%\n",
      "\tvalidation 19-71: Loss: 0.2512 Acc: 50.0000%\n",
      "\tvalidation 19-72: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 19-73: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 19-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-75: Loss: 0.2515 Acc: 50.0000%\n",
      "\tvalidation 19-76: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 19-77: Loss: 0.2638 Acc: 50.0000%\n",
      "\tvalidation 19-78: Loss: 0.1239 Acc: 75.0000%\n",
      "\tvalidation 19-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-81: Loss: 0.1376 Acc: 75.0000%\n",
      "\tvalidation 19-82: Loss: 0.2844 Acc: 75.0000%\n",
      "\tvalidation 19-83: Loss: 0.2702 Acc: 50.0000%\n",
      "\tvalidation 19-84: Loss: 0.0195 Acc: 100.0000%\n",
      "\tvalidation 19-85: Loss: 0.1522 Acc: 75.0000%\n",
      "\tvalidation 19-86: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 19-87: Loss: 0.1874 Acc: 75.0000%\n",
      "\tvalidation 19-88: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 19-89: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-90: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-92: Loss: 0.1853 Acc: 75.0000%\n",
      "\tvalidation 19-93: Loss: 0.0913 Acc: 75.0000%\n",
      "\tvalidation 19-94: Loss: 0.2242 Acc: 75.0000%\n",
      "\tvalidation 19-95: Loss: 0.6309 Acc: 25.0000%\n",
      "\tvalidation 19-96: Loss: 0.1274 Acc: 75.0000%\n",
      "\tvalidation 19-97: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 19-98: Loss: 0.3606 Acc: 50.0000%\n",
      "\tvalidation 19-99: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 19-100: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 19-101: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 19-102: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 19-103: Loss: 0.2746 Acc: 75.0000%\n",
      "\tvalidation 19-104: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-105: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0690 Acc: 90.7143%\n",
      "\tvalidation Loss: 0.0978 Acc: 85.0000%\n",
      "Time passed 0h 18m 35s\n",
      "--------------------\n",
      "Epoch [20/40]:\n",
      "\ttrain 20-1: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 20-2: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 20-3: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 20-4: Loss: 0.2009 Acc: 50.0000%\n",
      "\ttrain 20-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 20-6: Loss: 0.2689 Acc: 75.0000%\n",
      "\ttrain 20-7: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 20-8: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 20-9: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 20-10: Loss: 0.2427 Acc: 75.0000%\n",
      "\ttrain 20-11: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 20-12: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 20-13: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 20-14: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 20-15: Loss: 0.2166 Acc: 75.0000%\n",
      "\ttrain 20-16: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 20-17: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 20-18: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 20-19: Loss: 0.1186 Acc: 75.0000%\n",
      "\ttrain 20-20: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 20-21: Loss: 0.0706 Acc: 100.0000%\n",
      "\ttrain 20-22: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 20-24: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 20-25: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 20-26: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 20-27: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 20-28: Loss: 0.1330 Acc: 50.0000%\n",
      "\ttrain 20-29: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 20-30: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 20-31: Loss: 0.3060 Acc: 50.0000%\n",
      "\ttrain 20-32: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 20-33: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 20-34: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-35: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 20-36: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 20-37: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 20-38: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 20-39: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 20-40: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 20-41: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 20-42: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 20-43: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 20-44: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 20-45: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 20-46: Loss: 0.0742 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-47: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 20-48: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 20-49: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 20-50: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 20-51: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 20-52: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 20-53: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 20-54: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 20-55: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 20-56: Loss: 0.0500 Acc: 75.0000%\n",
      "\ttrain 20-57: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 20-58: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 20-59: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 20-60: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 20-61: Loss: 0.1677 Acc: 75.0000%\n",
      "\ttrain 20-62: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 20-63: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 20-64: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 20-65: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 20-66: Loss: 0.8111 Acc: 25.0000%\n",
      "\ttrain 20-67: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 20-68: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 20-69: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 20-70: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 20-71: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 20-72: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 20-73: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 20-74: Loss: 0.0785 Acc: 75.0000%\n",
      "\ttrain 20-75: Loss: 0.4477 Acc: 75.0000%\n",
      "\ttrain 20-76: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 20-77: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 20-78: Loss: 0.4050 Acc: 50.0000%\n",
      "\ttrain 20-79: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 20-80: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 20-81: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 20-82: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 20-83: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 20-84: Loss: 0.1241 Acc: 75.0000%\n",
      "\ttrain 20-85: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 20-86: Loss: 0.2224 Acc: 75.0000%\n",
      "\ttrain 20-87: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 20-88: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-89: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-90: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 20-91: Loss: 0.2880 Acc: 75.0000%\n",
      "\ttrain 20-92: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 20-93: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 20-94: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-95: Loss: 0.1959 Acc: 75.0000%\n",
      "\ttrain 20-96: Loss: 0.6292 Acc: 50.0000%\n",
      "\ttrain 20-97: Loss: 0.0441 Acc: 75.0000%\n",
      "\ttrain 20-98: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 20-99: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 20-100: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 20-101: Loss: 0.1906 Acc: 50.0000%\n",
      "\ttrain 20-102: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 20-103: Loss: 0.1985 Acc: 50.0000%\n",
      "\ttrain 20-104: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 20-105: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 20-106: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 20-107: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 20-108: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 20-109: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 20-110: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 20-111: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 20-112: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 20-113: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 20-114: Loss: 0.3919 Acc: 50.0000%\n",
      "\ttrain 20-115: Loss: 0.0967 Acc: 50.0000%\n",
      "\ttrain 20-116: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 20-117: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 20-118: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 20-119: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 20-120: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 20-121: Loss: 0.3112 Acc: 75.0000%\n",
      "\ttrain 20-122: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 20-123: Loss: 0.3057 Acc: 75.0000%\n",
      "\ttrain 20-124: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 20-125: Loss: 0.1490 Acc: 75.0000%\n",
      "\ttrain 20-126: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 20-127: Loss: 0.5497 Acc: 75.0000%\n",
      "\ttrain 20-128: Loss: 0.1631 Acc: 75.0000%\n",
      "\ttrain 20-129: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 20-130: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 20-131: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 20-132: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 20-133: Loss: 0.1667 Acc: 75.0000%\n",
      "\ttrain 20-134: Loss: 0.2684 Acc: 50.0000%\n",
      "\ttrain 20-135: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 20-136: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 20-137: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 20-138: Loss: 0.2608 Acc: 50.0000%\n",
      "\ttrain 20-139: Loss: 0.3914 Acc: 50.0000%\n",
      "\ttrain 20-140: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 20-141: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 20-142: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 20-143: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-144: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-145: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 20-146: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 20-147: Loss: 0.1822 Acc: 50.0000%\n",
      "\ttrain 20-148: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 20-149: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 20-150: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 20-151: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 20-152: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 20-153: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 20-154: Loss: 0.3551 Acc: 25.0000%\n",
      "\ttrain 20-155: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 20-156: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 20-157: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 20-158: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 20-159: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 20-160: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 20-161: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 20-162: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 20-163: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 20-164: Loss: 0.2473 Acc: 75.0000%\n",
      "\ttrain 20-165: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 20-166: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 20-167: Loss: 0.4013 Acc: 25.0000%\n",
      "\ttrain 20-168: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 20-169: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 20-170: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 20-171: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 20-172: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 20-173: Loss: 0.3038 Acc: 75.0000%\n",
      "\ttrain 20-174: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 20-175: Loss: 0.1825 Acc: 50.0000%\n",
      "\ttrain 20-176: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 20-177: Loss: 0.3129 Acc: 75.0000%\n",
      "\ttrain 20-178: Loss: 0.1826 Acc: 50.0000%\n",
      "\ttrain 20-179: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 20-180: Loss: 0.1793 Acc: 75.0000%\n",
      "\ttrain 20-181: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 20-182: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 20-183: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 20-184: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 20-185: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 20-186: Loss: 0.1910 Acc: 75.0000%\n",
      "\ttrain 20-187: Loss: 0.5325 Acc: 75.0000%\n",
      "\ttrain 20-188: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-189: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 20-190: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 20-191: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 20-192: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 20-193: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 20-194: Loss: 0.8923 Acc: 50.0000%\n",
      "\ttrain 20-195: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 20-196: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 20-197: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 20-198: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 20-199: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 20-200: Loss: 0.1972 Acc: 75.0000%\n",
      "\ttrain 20-201: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 20-202: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 20-203: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 20-204: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 20-205: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-206: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 20-207: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 20-208: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 20-209: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-210: Loss: 0.2448 Acc: 75.0000%\n",
      "\ttrain 20-211: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 20-212: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 20-213: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 20-214: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 20-215: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 20-216: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 20-217: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 20-218: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 20-219: Loss: 0.1844 Acc: 75.0000%\n",
      "\ttrain 20-220: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 20-221: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 20-222: Loss: 0.1284 Acc: 50.0000%\n",
      "\ttrain 20-223: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 20-224: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 20-225: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 20-226: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 20-227: Loss: 0.4738 Acc: 75.0000%\n",
      "\ttrain 20-228: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 20-229: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 20-230: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 20-231: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 20-232: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 20-233: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 20-234: Loss: 0.1905 Acc: 75.0000%\n",
      "\ttrain 20-235: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 20-236: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 20-237: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 20-238: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 20-239: Loss: 0.2827 Acc: 50.0000%\n",
      "\ttrain 20-240: Loss: 0.2575 Acc: 75.0000%\n",
      "\ttrain 20-241: Loss: 0.2625 Acc: 75.0000%\n",
      "\ttrain 20-242: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 20-243: Loss: 0.0120 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-244: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 20-245: Loss: 0.0852 Acc: 75.0000%\n",
      "\tvalidation 20-1: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 20-2: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 20-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-4: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 20-5: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 20-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-7: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 20-8: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 20-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-10: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 20-11: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-13: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 20-14: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 20-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-16: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-17: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-18: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 20-19: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-20: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 20-21: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-22: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 20-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-24: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-25: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-26: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-27: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 20-28: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-29: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 20-30: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-31: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 20-32: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-33: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 20-34: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 20-35: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 20-36: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 20-37: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 20-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-39: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-40: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 20-41: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-42: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-43: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 20-44: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 20-45: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 20-46: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-48: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 20-49: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 20-50: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-51: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-52: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 20-53: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-54: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 20-55: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-56: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-57: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 20-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-59: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-60: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 20-61: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 20-62: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-65: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 20-66: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 20-67: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 20-68: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 20-69: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-70: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 20-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-72: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-73: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-74: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 20-75: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 20-76: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 20-77: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 20-78: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-79: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 20-80: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 20-81: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 20-82: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-83: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-84: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 20-85: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 20-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-88: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 20-89: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 20-90: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-92: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 20-93: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-94: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-95: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 20-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-97: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 20-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-99: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 20-100: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-101: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-102: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 20-104: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-105: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0839 Acc: 88.4694%\n",
      "\tvalidation Loss: 0.0028 Acc: 100.0000%\n",
      "Time passed 0h 19m 13s\n",
      "--------------------\n",
      "Epoch [21/40]:\n",
      "\ttrain 21-1: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-2: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 21-3: Loss: 0.3637 Acc: 50.0000%\n",
      "\ttrain 21-4: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 21-5: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 21-6: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 21-7: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 21-8: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 21-9: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 21-10: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 21-11: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 21-12: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 21-13: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 21-14: Loss: 0.1931 Acc: 75.0000%\n",
      "\ttrain 21-15: Loss: 0.1932 Acc: 50.0000%\n",
      "\ttrain 21-16: Loss: 0.2099 Acc: 50.0000%\n",
      "\ttrain 21-17: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 21-18: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 21-19: Loss: 0.1916 Acc: 75.0000%\n",
      "\ttrain 21-20: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 21-21: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 21-22: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 21-23: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 21-24: Loss: 0.2602 Acc: 75.0000%\n",
      "\ttrain 21-25: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 21-26: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 21-27: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 21-28: Loss: 0.5043 Acc: 75.0000%\n",
      "\ttrain 21-29: Loss: 0.2330 Acc: 50.0000%\n",
      "\ttrain 21-30: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 21-31: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 21-32: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 21-33: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 21-34: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 21-35: Loss: 0.2946 Acc: 50.0000%\n",
      "\ttrain 21-36: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 21-37: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 21-38: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 21-39: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 21-40: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 21-41: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 21-42: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 21-43: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 21-44: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 21-45: Loss: 0.1058 Acc: 100.0000%\n",
      "\ttrain 21-46: Loss: 0.1859 Acc: 75.0000%\n",
      "\ttrain 21-47: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 21-48: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 21-49: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 21-50: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 21-51: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 21-52: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 21-53: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 21-54: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 21-55: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 21-56: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 21-57: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 21-58: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 21-59: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 21-60: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-61: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 21-62: Loss: 0.1929 Acc: 50.0000%\n",
      "\ttrain 21-63: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 21-64: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 21-65: Loss: 0.4876 Acc: 50.0000%\n",
      "\ttrain 21-66: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 21-67: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 21-68: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 21-69: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 21-70: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 21-71: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 21-72: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 21-73: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 21-74: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 21-75: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-76: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 21-77: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-78: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 21-79: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 21-80: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 21-81: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 21-82: Loss: 0.3754 Acc: 75.0000%\n",
      "\ttrain 21-83: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-84: Loss: 0.2045 Acc: 75.0000%\n",
      "\ttrain 21-85: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 21-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-87: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 21-88: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 21-89: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 21-90: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 21-91: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 21-92: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 21-93: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 21-94: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 21-95: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-96: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 21-97: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 21-98: Loss: 0.4142 Acc: 50.0000%\n",
      "\ttrain 21-99: Loss: 0.0929 Acc: 100.0000%\n",
      "\ttrain 21-100: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 21-101: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 21-102: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 21-103: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 21-104: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 21-105: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-106: Loss: 0.0825 Acc: 75.0000%\n",
      "\ttrain 21-107: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 21-108: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 21-109: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 21-110: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 21-111: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 21-112: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-113: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 21-114: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 21-115: Loss: 0.4332 Acc: 75.0000%\n",
      "\ttrain 21-116: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 21-117: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 21-118: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-119: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 21-120: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 21-121: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 21-122: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 21-123: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 21-124: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 21-125: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-126: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 21-127: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 21-128: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 21-129: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-130: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 21-131: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-132: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 21-133: Loss: 0.3242 Acc: 75.0000%\n",
      "\ttrain 21-134: Loss: 0.1897 Acc: 75.0000%\n",
      "\ttrain 21-135: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 21-136: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 21-137: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 21-138: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 21-139: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 21-140: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 21-141: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 21-142: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 21-143: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 21-144: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 21-145: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 21-146: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 21-147: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 21-148: Loss: 0.2310 Acc: 75.0000%\n",
      "\ttrain 21-149: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 21-150: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 21-151: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 21-152: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 21-153: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 21-154: Loss: 0.1731 Acc: 75.0000%\n",
      "\ttrain 21-155: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 21-156: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 21-157: Loss: 0.0699 Acc: 75.0000%\n",
      "\ttrain 21-158: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 21-159: Loss: 0.1558 Acc: 75.0000%\n",
      "\ttrain 21-160: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 21-161: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 21-162: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 21-163: Loss: 0.1154 Acc: 50.0000%\n",
      "\ttrain 21-164: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 21-165: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 21-166: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-167: Loss: 0.2203 Acc: 75.0000%\n",
      "\ttrain 21-168: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 21-169: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 21-170: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 21-171: Loss: 0.8423 Acc: 25.0000%\n",
      "\ttrain 21-172: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 21-173: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 21-174: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 21-175: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 21-176: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 21-177: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 21-178: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 21-179: Loss: 0.4541 Acc: 25.0000%\n",
      "\ttrain 21-180: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 21-181: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 21-182: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 21-183: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 21-184: Loss: 0.2451 Acc: 75.0000%\n",
      "\ttrain 21-185: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 21-186: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 21-187: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 21-188: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 21-189: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 21-190: Loss: 0.3426 Acc: 50.0000%\n",
      "\ttrain 21-191: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-192: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 21-193: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 21-194: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 21-195: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 21-196: Loss: 0.1709 Acc: 75.0000%\n",
      "\ttrain 21-197: Loss: 0.3416 Acc: 75.0000%\n",
      "\ttrain 21-198: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 21-199: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 21-200: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 21-201: Loss: 0.2951 Acc: 75.0000%\n",
      "\ttrain 21-202: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 21-203: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 21-204: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 21-205: Loss: 0.3017 Acc: 75.0000%\n",
      "\ttrain 21-206: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 21-207: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 21-208: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 21-209: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-210: Loss: 0.2486 Acc: 50.0000%\n",
      "\ttrain 21-211: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 21-212: Loss: 0.5632 Acc: 0.0000%\n",
      "\ttrain 21-213: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 21-214: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 21-215: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 21-216: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 21-217: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-218: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 21-219: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 21-220: Loss: 0.2497 Acc: 75.0000%\n",
      "\ttrain 21-221: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 21-222: Loss: 0.2579 Acc: 50.0000%\n",
      "\ttrain 21-223: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 21-224: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 21-225: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 21-226: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 21-227: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 21-228: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 21-229: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 21-230: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 21-231: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 21-232: Loss: 0.3383 Acc: 75.0000%\n",
      "\ttrain 21-233: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 21-234: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 21-235: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 21-236: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 21-237: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 21-238: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 21-239: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 21-240: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 21-241: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 21-242: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 21-243: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 21-244: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 21-245: Loss: 0.1160 Acc: 75.0000%\n",
      "\tvalidation 21-1: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 21-2: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 21-3: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 21-4: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 21-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-6: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 21-7: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 21-8: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 21-9: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 21-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-11: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 21-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-13: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-15: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 21-16: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-17: Loss: 0.0786 Acc: 100.0000%\n",
      "\tvalidation 21-18: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-19: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 21-20: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 21-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-22: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 21-23: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-24: Loss: 0.0004 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 21-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-27: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 21-28: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 21-29: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 21-30: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 21-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-32: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 21-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-35: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 21-36: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-38: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 21-39: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-40: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-42: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 21-43: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 21-44: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 21-45: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 21-46: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 21-47: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-48: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 21-49: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 21-50: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 21-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-53: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 21-54: Loss: 0.0652 Acc: 75.0000%\n",
      "\tvalidation 21-55: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 21-56: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 21-57: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-58: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 21-59: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 21-60: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 21-61: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 21-62: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 21-63: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 21-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-65: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-66: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-67: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 21-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-70: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-71: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 21-72: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-74: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-76: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 21-77: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 21-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-79: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 21-80: Loss: 0.1448 Acc: 75.0000%\n",
      "\tvalidation 21-81: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-82: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-84: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 21-85: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-86: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 21-87: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-90: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 21-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-92: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 21-93: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 21-94: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-95: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-96: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 21-97: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-98: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 21-99: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 21-100: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 21-101: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-102: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-103: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 21-104: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 21-105: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0737 Acc: 89.8980%\n",
      "\tvalidation Loss: 0.0077 Acc: 99.2857%\n",
      "Time passed 0h 19m 57s\n",
      "--------------------\n",
      "Epoch [22/40]:\n",
      "\ttrain 22-1: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 22-2: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 22-3: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 22-4: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 22-5: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 22-6: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 22-7: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 22-8: Loss: 0.2304 Acc: 50.0000%\n",
      "\ttrain 22-9: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 22-10: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 22-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 22-12: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 22-13: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 22-14: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-15: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 22-16: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 22-17: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 22-18: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 22-19: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 22-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 22-21: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 22-22: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 22-23: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 22-24: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 22-25: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 22-26: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-27: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 22-28: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 22-29: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 22-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 22-31: Loss: 0.4092 Acc: 75.0000%\n",
      "\ttrain 22-32: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 22-33: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 22-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 22-36: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-37: Loss: 0.3777 Acc: 75.0000%\n",
      "\ttrain 22-38: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 22-39: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 22-40: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 22-41: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-42: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 22-43: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-44: Loss: 0.0833 Acc: 75.0000%\n",
      "\ttrain 22-45: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 22-46: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 22-47: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 22-48: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 22-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 22-50: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 22-51: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 22-52: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 22-53: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 22-54: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 22-55: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 22-56: Loss: 0.0800 Acc: 100.0000%\n",
      "\ttrain 22-57: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 22-58: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 22-59: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 22-60: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 22-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 22-62: Loss: 0.4305 Acc: 50.0000%\n",
      "\ttrain 22-63: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 22-64: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 22-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 22-66: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 22-67: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 22-68: Loss: 0.2348 Acc: 50.0000%\n",
      "\ttrain 22-69: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 22-70: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 22-71: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 22-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 22-73: Loss: 0.1906 Acc: 75.0000%\n",
      "\ttrain 22-74: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 22-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-76: Loss: 0.3496 Acc: 75.0000%\n",
      "\ttrain 22-77: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 22-78: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 22-79: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-80: Loss: 1.0815 Acc: 25.0000%\n",
      "\ttrain 22-81: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 22-82: Loss: 0.1825 Acc: 75.0000%\n",
      "\ttrain 22-83: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 22-84: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 22-85: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 22-86: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-87: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-88: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 22-89: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-90: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 22-91: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 22-92: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 22-93: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 22-94: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 22-95: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 22-96: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 22-97: Loss: 0.0988 Acc: 75.0000%\n",
      "\ttrain 22-98: Loss: 0.2507 Acc: 75.0000%\n",
      "\ttrain 22-99: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 22-100: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 22-101: Loss: 0.2554 Acc: 50.0000%\n",
      "\ttrain 22-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 22-103: Loss: 0.0066 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-104: Loss: 0.3622 Acc: 50.0000%\n",
      "\ttrain 22-105: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 22-106: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 22-107: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 22-108: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 22-109: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 22-110: Loss: 0.2433 Acc: 50.0000%\n",
      "\ttrain 22-111: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 22-112: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 22-113: Loss: 0.3031 Acc: 50.0000%\n",
      "\ttrain 22-114: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 22-115: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 22-116: Loss: 0.2410 Acc: 75.0000%\n",
      "\ttrain 22-117: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 22-118: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 22-119: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 22-120: Loss: 0.8705 Acc: 0.0000%\n",
      "\ttrain 22-121: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 22-122: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 22-123: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 22-124: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-125: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 22-126: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 22-127: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 22-128: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 22-129: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 22-130: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 22-131: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 22-132: Loss: 0.3069 Acc: 75.0000%\n",
      "\ttrain 22-133: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 22-134: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 22-135: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 22-136: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 22-137: Loss: 0.2408 Acc: 50.0000%\n",
      "\ttrain 22-138: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 22-139: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 22-140: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 22-141: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 22-142: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 22-143: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 22-144: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 22-145: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 22-146: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 22-147: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 22-148: Loss: 0.0781 Acc: 100.0000%\n",
      "\ttrain 22-149: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 22-150: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 22-151: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 22-152: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 22-153: Loss: 0.3552 Acc: 50.0000%\n",
      "\ttrain 22-154: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 22-155: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 22-156: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 22-157: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 22-158: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 22-159: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 22-160: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 22-161: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 22-162: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 22-163: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 22-164: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 22-165: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 22-166: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 22-167: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 22-168: Loss: 0.3254 Acc: 75.0000%\n",
      "\ttrain 22-169: Loss: 0.2362 Acc: 75.0000%\n",
      "\ttrain 22-170: Loss: 0.2885 Acc: 75.0000%\n",
      "\ttrain 22-171: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 22-172: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-173: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 22-174: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 22-175: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 22-176: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-177: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 22-178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 22-179: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 22-180: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 22-181: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 22-182: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 22-183: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 22-184: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 22-185: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-186: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 22-187: Loss: 0.2836 Acc: 50.0000%\n",
      "\ttrain 22-188: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 22-189: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 22-190: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 22-191: Loss: 0.1833 Acc: 75.0000%\n",
      "\ttrain 22-192: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 22-193: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 22-194: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 22-195: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 22-196: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 22-197: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 22-198: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 22-199: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 22-200: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 22-201: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 22-202: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 22-203: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 22-204: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 22-205: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 22-206: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 22-207: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 22-208: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 22-209: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-210: Loss: 0.0719 Acc: 75.0000%\n",
      "\ttrain 22-211: Loss: 0.1598 Acc: 75.0000%\n",
      "\ttrain 22-212: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 22-213: Loss: 0.0463 Acc: 75.0000%\n",
      "\ttrain 22-214: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 22-215: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 22-216: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 22-217: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 22-218: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-219: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 22-220: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 22-221: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 22-222: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 22-223: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 22-224: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 22-225: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 22-226: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 22-227: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 22-228: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 22-229: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 22-230: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-231: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-232: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 22-233: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 22-234: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 22-235: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 22-236: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 22-237: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 22-238: Loss: 0.1596 Acc: 75.0000%\n",
      "\ttrain 22-239: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 22-240: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 22-241: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-242: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 22-243: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-244: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-245: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 22-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-3: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-4: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 22-5: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 22-6: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 22-7: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 22-8: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 22-9: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-10: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-12: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 22-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-15: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-16: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-18: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 22-19: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 22-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-21: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-24: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 22-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-26: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-27: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 22-28: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-29: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 22-30: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-31: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-32: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-33: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-34: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 22-35: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 22-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-40: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 22-42: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 22-43: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-50: Loss: 0.0006 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 22-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-53: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 22-54: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 22-55: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 22-56: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 22-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-60: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-62: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-65: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 22-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-68: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 22-69: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-74: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 22-75: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 22-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-77: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-79: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 22-80: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 22-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-83: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-84: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-86: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 22-87: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-89: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 22-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-91: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 22-92: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-97: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 22-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-99: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-101: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-102: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-103: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 22-104: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 22-105: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0624 Acc: 91.4286%\n",
      "\tvalidation Loss: 0.0016 Acc: 100.0000%\n",
      "Time passed 0h 20m 38s\n",
      "--------------------\n",
      "Epoch [23/40]:\n",
      "\ttrain 23-1: Loss: 0.2071 Acc: 75.0000%\n",
      "\ttrain 23-2: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 23-3: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 23-4: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 23-5: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 23-6: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 23-7: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 23-8: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 23-9: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 23-10: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-11: Loss: 0.1483 Acc: 50.0000%\n",
      "\ttrain 23-12: Loss: 0.2194 Acc: 75.0000%\n",
      "\ttrain 23-13: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 23-14: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 23-15: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 23-16: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 23-17: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 23-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-19: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 23-20: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 23-21: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 23-22: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 23-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 23-24: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 23-25: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 23-26: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 23-27: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 23-28: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 23-29: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 23-30: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 23-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 23-32: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-33: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-34: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-35: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 23-36: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 23-37: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 23-38: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 23-39: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 23-40: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 23-41: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 23-42: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 23-43: Loss: 0.6031 Acc: 50.0000%\n",
      "\ttrain 23-44: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 23-45: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 23-46: Loss: 0.3812 Acc: 50.0000%\n",
      "\ttrain 23-47: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-48: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 23-49: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 23-50: Loss: 0.1085 Acc: 50.0000%\n",
      "\ttrain 23-51: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 23-52: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 23-53: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 23-54: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 23-55: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 23-56: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 23-57: Loss: 0.3708 Acc: 25.0000%\n",
      "\ttrain 23-58: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 23-59: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 23-60: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 23-61: Loss: 0.1593 Acc: 75.0000%\n",
      "\ttrain 23-62: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 23-63: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 23-64: Loss: 0.6184 Acc: 50.0000%\n",
      "\ttrain 23-65: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 23-66: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 23-67: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 23-68: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 23-69: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 23-70: Loss: 0.1801 Acc: 75.0000%\n",
      "\ttrain 23-71: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 23-72: Loss: 0.1732 Acc: 50.0000%\n",
      "\ttrain 23-73: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 23-74: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 23-75: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 23-76: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 23-77: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 23-78: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 23-79: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 23-80: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 23-81: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 23-82: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 23-83: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 23-84: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 23-85: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 23-86: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 23-87: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 23-88: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 23-89: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 23-90: Loss: 0.1448 Acc: 75.0000%\n",
      "\ttrain 23-91: Loss: 0.2776 Acc: 25.0000%\n",
      "\ttrain 23-92: Loss: 0.2997 Acc: 75.0000%\n",
      "\ttrain 23-93: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 23-94: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 23-95: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 23-96: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 23-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 23-98: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 23-99: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 23-100: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 23-101: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 23-102: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 23-103: Loss: 0.2537 Acc: 75.0000%\n",
      "\ttrain 23-104: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 23-105: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 23-106: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 23-107: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 23-108: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 23-109: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 23-110: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 23-111: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 23-112: Loss: 0.7056 Acc: 25.0000%\n",
      "\ttrain 23-113: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 23-114: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 23-115: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-116: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 23-117: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 23-118: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 23-119: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 23-120: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 23-121: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 23-122: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 23-123: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 23-124: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 23-125: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 23-126: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 23-127: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 23-128: Loss: 0.2810 Acc: 50.0000%\n",
      "\ttrain 23-129: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 23-130: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 23-131: Loss: 0.1502 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 23-132: Loss: 0.2649 Acc: 50.0000%\n",
      "\ttrain 23-133: Loss: 0.2198 Acc: 75.0000%\n",
      "\ttrain 23-134: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 23-135: Loss: 0.7176 Acc: 50.0000%\n",
      "\ttrain 23-136: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 23-137: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 23-138: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 23-139: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 23-140: Loss: 0.3972 Acc: 75.0000%\n",
      "\ttrain 23-141: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-142: Loss: 0.3396 Acc: 50.0000%\n",
      "\ttrain 23-143: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 23-144: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-145: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 23-146: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 23-147: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-148: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 23-149: Loss: 0.3779 Acc: 50.0000%\n",
      "\ttrain 23-150: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 23-151: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 23-152: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 23-153: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 23-154: Loss: 0.3938 Acc: 75.0000%\n",
      "\ttrain 23-155: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 23-156: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 23-157: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-158: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 23-159: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 23-160: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 23-161: Loss: 0.1587 Acc: 50.0000%\n",
      "\ttrain 23-162: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 23-163: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-164: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-165: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 23-166: Loss: 0.3739 Acc: 75.0000%\n",
      "\ttrain 23-167: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 23-168: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 23-169: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 23-170: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 23-171: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-172: Loss: 0.1163 Acc: 50.0000%\n",
      "\ttrain 23-173: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-174: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 23-175: Loss: 0.5086 Acc: 75.0000%\n",
      "\ttrain 23-176: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 23-177: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 23-178: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 23-179: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 23-180: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 23-181: Loss: 0.2766 Acc: 75.0000%\n",
      "\ttrain 23-182: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 23-183: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 23-184: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 23-185: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 23-186: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-187: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 23-188: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 23-189: Loss: 0.4589 Acc: 50.0000%\n",
      "\ttrain 23-190: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 23-191: Loss: 0.1692 Acc: 75.0000%\n",
      "\ttrain 23-192: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 23-193: Loss: 0.1911 Acc: 75.0000%\n",
      "\ttrain 23-194: Loss: 0.1911 Acc: 75.0000%\n",
      "\ttrain 23-195: Loss: 0.1376 Acc: 75.0000%\n",
      "\ttrain 23-196: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 23-197: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 23-198: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 23-199: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 23-200: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 23-201: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 23-202: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 23-203: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-204: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 23-205: Loss: 0.6423 Acc: 0.0000%\n",
      "\ttrain 23-206: Loss: 0.0652 Acc: 100.0000%\n",
      "\ttrain 23-207: Loss: 0.4014 Acc: 50.0000%\n",
      "\ttrain 23-208: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 23-209: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 23-210: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 23-211: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 23-212: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 23-213: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 23-214: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 23-215: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 23-216: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 23-217: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 23-218: Loss: 0.0721 Acc: 75.0000%\n",
      "\ttrain 23-219: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 23-220: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 23-221: Loss: 0.2373 Acc: 75.0000%\n",
      "\ttrain 23-222: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 23-223: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 23-224: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 23-225: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 23-226: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 23-227: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 23-228: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 23-229: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 23-230: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 23-231: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 23-232: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 23-233: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 23-234: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 23-235: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 23-236: Loss: 0.1859 Acc: 75.0000%\n",
      "\ttrain 23-237: Loss: 0.3625 Acc: 75.0000%\n",
      "\ttrain 23-238: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 23-239: Loss: 0.3125 Acc: 50.0000%\n",
      "\ttrain 23-240: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 23-241: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-242: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 23-243: Loss: 0.4736 Acc: 50.0000%\n",
      "\ttrain 23-244: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 23-245: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 23-1: Loss: 0.0899 Acc: 75.0000%\n",
      "\tvalidation 23-2: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 23-3: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 23-4: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 23-5: Loss: 0.0669 Acc: 75.0000%\n",
      "\tvalidation 23-6: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 23-7: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 23-8: Loss: 0.0837 Acc: 75.0000%\n",
      "\tvalidation 23-9: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 23-10: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 23-11: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 23-12: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-13: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-14: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 23-15: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 23-16: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 23-17: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 23-18: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 23-19: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 23-20: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 23-21: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 23-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-23: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 23-24: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 23-25: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-26: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 23-27: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 23-28: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 23-29: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 23-30: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-32: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 23-33: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 23-34: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-35: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 23-36: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 23-37: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 23-38: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 23-39: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 23-40: Loss: 0.1231 Acc: 75.0000%\n",
      "\tvalidation 23-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-42: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 23-43: Loss: 0.1685 Acc: 75.0000%\n",
      "\tvalidation 23-44: Loss: 0.0425 Acc: 100.0000%\n",
      "\tvalidation 23-45: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-46: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 23-47: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 23-48: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 23-49: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 23-50: Loss: 0.0647 Acc: 75.0000%\n",
      "\tvalidation 23-51: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-52: Loss: 0.0870 Acc: 75.0000%\n",
      "\tvalidation 23-53: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 23-54: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 23-55: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 23-56: Loss: 0.1636 Acc: 75.0000%\n",
      "\tvalidation 23-57: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 23-58: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-59: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 23-60: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 23-61: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 23-62: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 23-63: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 23-64: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 23-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-66: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 23-67: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 23-68: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 23-69: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-70: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 23-71: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 23-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 23-73: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 23-74: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 23-75: Loss: 0.0296 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 23-76: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 23-77: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 23-78: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-79: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 23-80: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 23-81: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 23-82: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 23-83: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 23-84: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 23-85: Loss: 0.0933 Acc: 75.0000%\n",
      "\tvalidation 23-86: Loss: 0.0685 Acc: 75.0000%\n",
      "\tvalidation 23-87: Loss: 0.0370 Acc: 100.0000%\n",
      "\tvalidation 23-88: Loss: 0.1002 Acc: 75.0000%\n",
      "\tvalidation 23-89: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 23-90: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 23-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-93: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 23-94: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 23-95: Loss: 0.0596 Acc: 75.0000%\n",
      "\tvalidation 23-96: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 23-97: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-98: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 23-99: Loss: 0.0825 Acc: 75.0000%\n",
      "\tvalidation 23-100: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 23-101: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 23-102: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 23-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 23-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0833 Acc: 88.5714%\n",
      "\tvalidation Loss: 0.0212 Acc: 96.4286%\n",
      "Time passed 0h 21m 15s\n",
      "--------------------\n",
      "Epoch [24/40]:\n",
      "\ttrain 24-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 24-2: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 24-3: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-4: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 24-5: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 24-6: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 24-7: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 24-8: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-9: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 24-10: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-11: Loss: 0.1531 Acc: 50.0000%\n",
      "\ttrain 24-12: Loss: 0.0564 Acc: 75.0000%\n",
      "\ttrain 24-13: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 24-14: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 24-15: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 24-16: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-17: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 24-18: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 24-19: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 24-20: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 24-21: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 24-22: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 24-23: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 24-24: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 24-25: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-26: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 24-27: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-28: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 24-29: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 24-30: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 24-31: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 24-32: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 24-33: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-35: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 24-36: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-37: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 24-38: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 24-39: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 24-40: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 24-41: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 24-42: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 24-43: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-44: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 24-45: Loss: 0.1754 Acc: 75.0000%\n",
      "\ttrain 24-46: Loss: 0.3444 Acc: 75.0000%\n",
      "\ttrain 24-47: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 24-48: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-49: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 24-50: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 24-51: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 24-52: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 24-53: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 24-54: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 24-55: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 24-56: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 24-57: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 24-58: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 24-59: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 24-60: Loss: 0.2769 Acc: 50.0000%\n",
      "\ttrain 24-61: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 24-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-63: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-64: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 24-65: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 24-66: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 24-67: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 24-68: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 24-69: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 24-70: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 24-71: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 24-72: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 24-73: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 24-74: Loss: 0.3585 Acc: 75.0000%\n",
      "\ttrain 24-75: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 24-76: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 24-77: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 24-78: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 24-79: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 24-80: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 24-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-82: Loss: 0.2814 Acc: 50.0000%\n",
      "\ttrain 24-83: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 24-84: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 24-85: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 24-86: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 24-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 24-88: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 24-89: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-90: Loss: 0.1836 Acc: 75.0000%\n",
      "\ttrain 24-91: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 24-92: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 24-93: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 24-94: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 24-95: Loss: 0.2558 Acc: 50.0000%\n",
      "\ttrain 24-96: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-97: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 24-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-99: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 24-100: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-101: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-102: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-103: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 24-104: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-105: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-106: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 24-107: Loss: 0.1696 Acc: 75.0000%\n",
      "\ttrain 24-108: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 24-109: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 24-110: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 24-111: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 24-112: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 24-113: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 24-114: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 24-115: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-116: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-117: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 24-118: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 24-119: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 24-120: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 24-121: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 24-122: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-123: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-124: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-125: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-126: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-127: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 24-128: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-129: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 24-130: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 24-131: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 24-132: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-133: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 24-134: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 24-135: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 24-136: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 24-137: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 24-138: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 24-139: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-140: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 24-141: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 24-142: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 24-143: Loss: 0.2389 Acc: 75.0000%\n",
      "\ttrain 24-144: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-145: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 24-146: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 24-147: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 24-148: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 24-149: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 24-150: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 24-151: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 24-152: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 24-153: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-154: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-155: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 24-156: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 24-157: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 24-158: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 24-159: Loss: 0.0645 Acc: 100.0000%\n",
      "\ttrain 24-160: Loss: 0.0061 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-161: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-162: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-163: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 24-164: Loss: 0.6608 Acc: 50.0000%\n",
      "\ttrain 24-165: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 24-166: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 24-167: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 24-168: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 24-169: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-170: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-171: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 24-172: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-173: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 24-174: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-175: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 24-176: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-177: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-178: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 24-179: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 24-180: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 24-181: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 24-182: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-183: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 24-184: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 24-185: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 24-186: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 24-187: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 24-188: Loss: 0.9598 Acc: 50.0000%\n",
      "\ttrain 24-189: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 24-190: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 24-191: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-192: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-193: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 24-194: Loss: 0.1458 Acc: 50.0000%\n",
      "\ttrain 24-195: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 24-196: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 24-197: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 24-198: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 24-199: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 24-200: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 24-201: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 24-202: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 24-203: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-204: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 24-205: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 24-206: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 24-207: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 24-208: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 24-209: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-210: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-211: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-212: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-213: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 24-214: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 24-215: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-216: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 24-217: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-218: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-219: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-220: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 24-221: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 24-222: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 24-223: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-224: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-225: Loss: 1.0494 Acc: 25.0000%\n",
      "\ttrain 24-226: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 24-227: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 24-228: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-229: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 24-230: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-231: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-232: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 24-233: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 24-234: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 24-235: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-236: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 24-237: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 24-238: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-239: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 24-240: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 24-241: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 24-242: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-243: Loss: 0.1742 Acc: 50.0000%\n",
      "\ttrain 24-244: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-245: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 24-1: Loss: 0.0515 Acc: 100.0000%\n",
      "\tvalidation 24-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-4: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 24-5: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-7: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 24-8: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-9: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 24-10: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 24-11: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-12: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 24-13: Loss: 0.0317 Acc: 100.0000%\n",
      "\tvalidation 24-14: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 24-15: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 24-16: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 24-17: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 24-18: Loss: 0.0457 Acc: 100.0000%\n",
      "\tvalidation 24-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-20: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 24-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-22: Loss: 0.1475 Acc: 75.0000%\n",
      "\tvalidation 24-23: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 24-24: Loss: 0.1335 Acc: 75.0000%\n",
      "\tvalidation 24-25: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 24-26: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-27: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 24-28: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 24-29: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 24-30: Loss: 0.0496 Acc: 75.0000%\n",
      "\tvalidation 24-31: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 24-32: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-33: Loss: 0.0737 Acc: 75.0000%\n",
      "\tvalidation 24-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-35: Loss: 0.0698 Acc: 75.0000%\n",
      "\tvalidation 24-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-37: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 24-38: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-39: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 24-40: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 24-41: Loss: 0.0468 Acc: 75.0000%\n",
      "\tvalidation 24-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-43: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-44: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 24-45: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 24-46: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 24-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-48: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 24-49: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 24-50: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 24-51: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 24-52: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 24-53: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 24-54: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 24-55: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-56: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 24-57: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-58: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 24-59: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 24-60: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 24-61: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 24-62: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 24-63: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-65: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 24-66: Loss: 0.2752 Acc: 75.0000%\n",
      "\tvalidation 24-67: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 24-68: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 24-69: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 24-70: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 24-71: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 24-72: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 24-73: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 24-74: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 24-75: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 24-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-77: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-78: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 24-79: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 24-80: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 24-81: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-82: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 24-83: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 24-84: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 24-85: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-86: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 24-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-88: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-89: Loss: 0.0467 Acc: 100.0000%\n",
      "\tvalidation 24-90: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-91: Loss: 0.0676 Acc: 75.0000%\n",
      "\tvalidation 24-92: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 24-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-94: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 24-95: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-96: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 24-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-98: Loss: 0.2546 Acc: 50.0000%\n",
      "\tvalidation 24-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-100: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 24-101: Loss: 0.0644 Acc: 75.0000%\n",
      "\tvalidation 24-102: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-103: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 24-104: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 24-105: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0436 Acc: 94.7959%\n",
      "\tvalidation Loss: 0.0220 Acc: 96.9048%\n",
      "Time passed 0h 21m 52s\n",
      "--------------------\n",
      "Epoch [25/40]:\n",
      "\ttrain 25-1: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 25-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-3: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-4: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 25-5: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 25-6: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 25-7: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 25-8: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 25-9: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-10: Loss: 0.2605 Acc: 75.0000%\n",
      "\ttrain 25-11: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-13: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 25-14: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 25-15: Loss: 0.2486 Acc: 75.0000%\n",
      "\ttrain 25-16: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 25-17: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 25-18: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-19: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 25-20: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 25-21: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 25-22: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 25-23: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 25-24: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 25-25: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 25-26: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 25-27: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 25-28: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 25-29: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 25-30: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 25-31: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-32: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 25-33: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-34: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-35: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 25-36: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 25-37: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-38: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 25-39: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 25-40: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-41: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-42: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-43: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-44: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-45: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 25-46: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 25-47: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-48: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 25-49: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 25-50: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-51: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-52: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 25-53: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 25-54: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 25-55: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 25-56: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-57: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 25-58: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 25-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-60: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 25-61: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 25-62: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 25-63: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 25-64: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 25-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 25-66: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 25-67: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 25-68: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 25-69: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 25-70: Loss: 0.0781 Acc: 100.0000%\n",
      "\ttrain 25-71: Loss: 0.0494 Acc: 75.0000%\n",
      "\ttrain 25-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 25-73: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 25-74: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 25-75: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 25-76: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 25-77: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-78: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 25-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-80: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 25-81: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 25-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-84: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 25-85: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-86: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 25-87: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-88: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 25-89: Loss: 0.1375 Acc: 75.0000%\n",
      "\ttrain 25-90: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 25-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-92: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-93: Loss: 0.2028 Acc: 75.0000%\n",
      "\ttrain 25-94: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 25-95: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-96: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-97: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-98: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 25-99: Loss: 0.5900 Acc: 50.0000%\n",
      "\ttrain 25-100: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-101: Loss: 0.6096 Acc: 75.0000%\n",
      "\ttrain 25-102: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 25-103: Loss: 0.3762 Acc: 50.0000%\n",
      "\ttrain 25-104: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 25-105: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 25-106: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-107: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 25-108: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-109: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 25-110: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 25-111: Loss: 0.0673 Acc: 100.0000%\n",
      "\ttrain 25-112: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-113: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 25-114: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 25-115: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 25-116: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 25-117: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 25-118: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 25-119: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 25-120: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 25-121: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 25-122: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 25-123: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 25-124: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 25-125: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 25-126: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 25-127: Loss: 0.0454 Acc: 75.0000%\n",
      "\ttrain 25-128: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-129: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 25-130: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-131: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 25-132: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 25-133: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-134: Loss: 0.6060 Acc: 25.0000%\n",
      "\ttrain 25-135: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 25-136: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 25-137: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 25-138: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 25-139: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 25-140: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 25-141: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-142: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-143: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 25-144: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-145: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-146: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 25-147: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 25-148: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 25-149: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 25-150: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 25-151: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-152: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-153: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 25-154: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 25-155: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 25-156: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 25-157: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-158: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 25-159: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-160: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 25-161: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 25-162: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-163: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 25-164: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-165: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 25-166: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-167: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 25-168: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 25-169: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 25-170: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 25-171: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-172: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 25-173: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-174: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 25-175: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 25-176: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-177: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-178: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 25-179: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-180: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 25-181: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-182: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-183: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 25-184: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 25-185: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-186: Loss: 0.1389 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-187: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 25-188: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-189: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 25-190: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-191: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-192: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 25-193: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 25-194: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-195: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 25-196: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 25-197: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 25-198: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 25-199: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-200: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 25-201: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 25-202: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 25-203: Loss: 0.2408 Acc: 75.0000%\n",
      "\ttrain 25-204: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 25-205: Loss: 0.4638 Acc: 75.0000%\n",
      "\ttrain 25-206: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-207: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 25-208: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 25-209: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-210: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 25-211: Loss: 0.5968 Acc: 50.0000%\n",
      "\ttrain 25-212: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 25-213: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 25-214: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 25-215: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 25-216: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 25-217: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 25-218: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 25-219: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 25-220: Loss: 0.0517 Acc: 75.0000%\n",
      "\ttrain 25-221: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 25-222: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 25-223: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 25-224: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-225: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-226: Loss: 0.7072 Acc: 50.0000%\n",
      "\ttrain 25-227: Loss: 0.2450 Acc: 75.0000%\n",
      "\ttrain 25-228: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 25-229: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 25-230: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-231: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 25-232: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 25-233: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain 25-234: Loss: 0.2957 Acc: 50.0000%\n",
      "\ttrain 25-235: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 25-236: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 25-237: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-238: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 25-239: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 25-240: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 25-241: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 25-242: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-243: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 25-244: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-245: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 25-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 25-2: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-3: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-6: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-7: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-8: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-9: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 25-10: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 25-11: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 25-12: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 25-13: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-14: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 25-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-18: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-19: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 25-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-21: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-22: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-23: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 25-24: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 25-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-27: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-29: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-30: Loss: 0.0364 Acc: 100.0000%\n",
      "\tvalidation 25-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-32: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 25-33: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-34: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-35: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 25-36: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-38: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 25-39: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-40: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-41: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 25-42: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 25-43: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 25-44: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 25-45: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 25-46: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 25-47: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 25-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-49: Loss: 0.0717 Acc: 75.0000%\n",
      "\tvalidation 25-50: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-51: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-52: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-53: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-54: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-55: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-56: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 25-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-59: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 25-60: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 25-61: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 25-62: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 25-63: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-64: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 25-65: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-66: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 25-67: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-68: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 25-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-71: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-73: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 25-74: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-75: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 25-76: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-77: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-79: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-80: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 25-81: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-82: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-84: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-85: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 25-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-87: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 25-88: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 25-89: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 25-90: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 25-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-92: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-93: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 25-94: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 25-95: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-96: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 25-97: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-100: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 25-101: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 25-102: Loss: 0.0742 Acc: 75.0000%\n",
      "\tvalidation 25-103: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 25-104: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-105: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0472 Acc: 94.0816%\n",
      "\tvalidation Loss: 0.0062 Acc: 99.2857%\n",
      "Time passed 0h 22m 37s\n",
      "--------------------\n",
      "Epoch [26/40]:\n",
      "\ttrain 26-1: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 26-2: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-3: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-4: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-5: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 26-6: Loss: 0.2008 Acc: 25.0000%\n",
      "\ttrain 26-7: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 26-8: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-9: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-10: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-11: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 26-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-13: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 26-14: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 26-15: Loss: 0.0162 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-16: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 26-17: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 26-18: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 26-19: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 26-20: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 26-21: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-22: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 26-23: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 26-24: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 26-25: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 26-26: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-27: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 26-28: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 26-29: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 26-30: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 26-31: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 26-32: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-33: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 26-34: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 26-35: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 26-36: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 26-37: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-38: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 26-39: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-40: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 26-41: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 26-42: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 26-43: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 26-44: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 26-45: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-46: Loss: 0.1672 Acc: 75.0000%\n",
      "\ttrain 26-47: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 26-48: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-49: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 26-50: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 26-51: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-52: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 26-53: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-54: Loss: 0.5960 Acc: 50.0000%\n",
      "\ttrain 26-55: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 26-56: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 26-57: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 26-58: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 26-59: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 26-60: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 26-61: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 26-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 26-63: Loss: 0.2112 Acc: 25.0000%\n",
      "\ttrain 26-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 26-66: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 26-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-68: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-69: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 26-70: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 26-71: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 26-72: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-73: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 26-74: Loss: 0.1819 Acc: 75.0000%\n",
      "\ttrain 26-75: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 26-76: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 26-77: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 26-78: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 26-79: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 26-80: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-81: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-82: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 26-83: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 26-84: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 26-85: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 26-86: Loss: 0.3098 Acc: 75.0000%\n",
      "\ttrain 26-87: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 26-88: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 26-89: Loss: 0.0528 Acc: 75.0000%\n",
      "\ttrain 26-90: Loss: 0.2689 Acc: 50.0000%\n",
      "\ttrain 26-91: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 26-92: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 26-93: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 26-94: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-95: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 26-96: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 26-97: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 26-98: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 26-99: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 26-100: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 26-101: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-102: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 26-103: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 26-104: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 26-105: Loss: 0.2806 Acc: 50.0000%\n",
      "\ttrain 26-106: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 26-107: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 26-108: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 26-109: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 26-110: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-111: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 26-112: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 26-113: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 26-114: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-115: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 26-116: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 26-117: Loss: 0.1517 Acc: 75.0000%\n",
      "\ttrain 26-118: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 26-119: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 26-120: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 26-121: Loss: 0.2949 Acc: 75.0000%\n",
      "\ttrain 26-122: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 26-123: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 26-124: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 26-125: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 26-126: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 26-127: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-128: Loss: 1.0081 Acc: 50.0000%\n",
      "\ttrain 26-129: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 26-130: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 26-131: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 26-132: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 26-133: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 26-134: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 26-135: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-136: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 26-137: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 26-138: Loss: 0.2098 Acc: 50.0000%\n",
      "\ttrain 26-139: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-140: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 26-141: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 26-142: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 26-143: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-144: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 26-145: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-146: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 26-147: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 26-148: Loss: 0.0687 Acc: 100.0000%\n",
      "\ttrain 26-149: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 26-150: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 26-151: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 26-152: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 26-153: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 26-154: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 26-155: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 26-156: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 26-157: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 26-158: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-159: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 26-160: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 26-161: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 26-162: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 26-163: Loss: 0.1697 Acc: 50.0000%\n",
      "\ttrain 26-164: Loss: 0.4215 Acc: 50.0000%\n",
      "\ttrain 26-165: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-166: Loss: 0.3129 Acc: 50.0000%\n",
      "\ttrain 26-167: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 26-168: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 26-169: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 26-170: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 26-171: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 26-172: Loss: 0.3158 Acc: 75.0000%\n",
      "\ttrain 26-173: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 26-174: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 26-175: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 26-176: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 26-177: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 26-178: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 26-179: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 26-180: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 26-181: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 26-182: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 26-183: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-184: Loss: 0.4720 Acc: 50.0000%\n",
      "\ttrain 26-185: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 26-186: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 26-187: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-188: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 26-189: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 26-190: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 26-191: Loss: 0.0694 Acc: 100.0000%\n",
      "\ttrain 26-192: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 26-193: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 26-194: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 26-195: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 26-196: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 26-197: Loss: 0.2137 Acc: 50.0000%\n",
      "\ttrain 26-198: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 26-199: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 26-200: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 26-201: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 26-202: Loss: 0.1840 Acc: 25.0000%\n",
      "\ttrain 26-203: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 26-204: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 26-205: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 26-206: Loss: 0.1867 Acc: 75.0000%\n",
      "\ttrain 26-207: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 26-208: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-209: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 26-210: Loss: 0.0093 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-211: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-212: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 26-213: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 26-214: Loss: 0.2366 Acc: 75.0000%\n",
      "\ttrain 26-215: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 26-216: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 26-217: Loss: 0.2153 Acc: 75.0000%\n",
      "\ttrain 26-218: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 26-219: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 26-220: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 26-221: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 26-222: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 26-223: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 26-224: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 26-225: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 26-226: Loss: 0.1780 Acc: 75.0000%\n",
      "\ttrain 26-227: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-228: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 26-229: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 26-230: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 26-231: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 26-232: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 26-233: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 26-234: Loss: 0.3397 Acc: 50.0000%\n",
      "\ttrain 26-235: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 26-236: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 26-237: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 26-238: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 26-239: Loss: 0.1553 Acc: 75.0000%\n",
      "\ttrain 26-240: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 26-241: Loss: 0.5737 Acc: 0.0000%\n",
      "\ttrain 26-242: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-243: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-244: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-245: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 26-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-2: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 26-3: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 26-4: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 26-5: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 26-6: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 26-7: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 26-8: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 26-9: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 26-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-11: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 26-12: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 26-13: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 26-14: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 26-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-16: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-17: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 26-18: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-21: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 26-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-23: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 26-24: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 26-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-26: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-27: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 26-28: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 26-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-30: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-31: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-34: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-35: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 26-36: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 26-37: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 26-38: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-39: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 26-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-41: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 26-42: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 26-43: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 26-44: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-45: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-46: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 26-47: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 26-48: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 26-49: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-50: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-51: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-52: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 26-53: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-54: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-55: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 26-56: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 26-57: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 26-58: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-59: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-61: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 26-62: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 26-63: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-64: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-66: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-67: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-68: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-69: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-70: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-71: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-72: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 26-73: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 26-74: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 26-75: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 26-76: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 26-77: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-78: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-79: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-81: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-84: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 26-85: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 26-86: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 26-87: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 26-88: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-89: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 26-90: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-91: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 26-92: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-95: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-96: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-97: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 26-98: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 26-99: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-100: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 26-101: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 26-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 26-103: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 26-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-105: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0604 Acc: 90.8163%\n",
      "\tvalidation Loss: 0.0046 Acc: 100.0000%\n",
      "Time passed 0h 23m 18s\n",
      "--------------------\n",
      "Epoch [27/40]:\n",
      "\ttrain 27-1: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 27-2: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 27-3: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 27-4: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 27-5: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 27-6: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 27-7: Loss: 0.2827 Acc: 75.0000%\n",
      "\ttrain 27-8: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 27-9: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 27-10: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 27-11: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-12: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 27-13: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 27-14: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 27-15: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 27-16: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 27-17: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 27-18: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 27-19: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-20: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-21: Loss: 1.5093 Acc: 50.0000%\n",
      "\ttrain 27-22: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 27-23: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-24: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 27-25: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 27-26: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 27-27: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 27-28: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 27-29: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 27-30: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 27-31: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 27-32: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 27-33: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 27-34: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-35: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 27-36: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-37: Loss: 0.2664 Acc: 25.0000%\n",
      "\ttrain 27-38: Loss: 0.2420 Acc: 50.0000%\n",
      "\ttrain 27-39: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 27-40: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 27-41: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 27-42: Loss: 0.0741 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-43: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-44: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 27-45: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 27-46: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 27-47: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 27-48: Loss: 0.3357 Acc: 25.0000%\n",
      "\ttrain 27-49: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 27-50: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 27-51: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-52: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 27-53: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 27-54: Loss: 0.0603 Acc: 100.0000%\n",
      "\ttrain 27-55: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 27-56: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 27-57: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-58: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 27-59: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 27-60: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 27-61: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 27-62: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 27-63: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 27-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-65: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-66: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-67: Loss: 0.2063 Acc: 75.0000%\n",
      "\ttrain 27-68: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 27-69: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 27-70: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 27-71: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 27-72: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 27-73: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 27-74: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 27-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 27-76: Loss: 0.1615 Acc: 75.0000%\n",
      "\ttrain 27-77: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 27-78: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 27-79: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 27-80: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 27-81: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-82: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-83: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 27-84: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 27-85: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-86: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-87: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-88: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 27-89: Loss: 0.5613 Acc: 50.0000%\n",
      "\ttrain 27-90: Loss: 0.1916 Acc: 75.0000%\n",
      "\ttrain 27-91: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 27-92: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 27-93: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 27-94: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 27-95: Loss: 0.4025 Acc: 50.0000%\n",
      "\ttrain 27-96: Loss: 0.0800 Acc: 100.0000%\n",
      "\ttrain 27-97: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 27-98: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 27-99: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-100: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 27-101: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 27-102: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 27-103: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 27-104: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 27-105: Loss: 0.4758 Acc: 50.0000%\n",
      "\ttrain 27-106: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 27-107: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 27-108: Loss: 0.2619 Acc: 75.0000%\n",
      "\ttrain 27-109: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 27-110: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 27-111: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 27-112: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 27-113: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 27-114: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 27-115: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 27-116: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 27-117: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 27-118: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 27-119: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 27-120: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 27-121: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 27-122: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 27-123: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 27-124: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 27-125: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 27-126: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-127: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 27-128: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 27-129: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 27-130: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 27-131: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 27-132: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 27-133: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-134: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 27-135: Loss: 0.1878 Acc: 75.0000%\n",
      "\ttrain 27-136: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-137: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 27-138: Loss: 0.1730 Acc: 50.0000%\n",
      "\ttrain 27-139: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 27-140: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 27-141: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 27-142: Loss: 0.4175 Acc: 25.0000%\n",
      "\ttrain 27-143: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 27-144: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-145: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 27-146: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 27-147: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 27-148: Loss: 0.1524 Acc: 75.0000%\n",
      "\ttrain 27-149: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 27-150: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 27-151: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 27-152: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-153: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 27-154: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 27-155: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 27-156: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-157: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 27-158: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-159: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-160: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 27-161: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 27-162: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 27-163: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 27-164: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 27-165: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 27-166: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 27-167: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-168: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 27-169: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 27-170: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 27-171: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 27-172: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 27-173: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-174: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-175: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-176: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 27-177: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 27-178: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-179: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 27-180: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 27-181: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 27-182: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 27-183: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 27-184: Loss: 0.2614 Acc: 75.0000%\n",
      "\ttrain 27-185: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-186: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-187: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 27-188: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 27-189: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-190: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-191: Loss: 0.4754 Acc: 75.0000%\n",
      "\ttrain 27-192: Loss: 0.2385 Acc: 50.0000%\n",
      "\ttrain 27-193: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 27-194: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 27-195: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 27-196: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 27-197: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-198: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 27-199: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 27-200: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 27-201: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 27-202: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 27-203: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 27-204: Loss: 0.7476 Acc: 25.0000%\n",
      "\ttrain 27-205: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 27-206: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 27-207: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-208: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 27-209: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 27-210: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 27-211: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 27-212: Loss: 0.1390 Acc: 75.0000%\n",
      "\ttrain 27-213: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 27-214: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 27-215: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 27-216: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 27-217: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 27-218: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 27-219: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-220: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-221: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 27-222: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 27-223: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 27-224: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 27-225: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 27-226: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 27-227: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 27-228: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 27-229: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 27-230: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 27-231: Loss: 0.0460 Acc: 75.0000%\n",
      "\ttrain 27-232: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 27-233: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 27-234: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 27-235: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 27-236: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 27-237: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 27-238: Loss: 0.0329 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-239: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 27-240: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 27-241: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 27-242: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 27-243: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-244: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-245: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 27-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-2: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-3: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 27-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-6: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-8: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-9: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-11: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-12: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 27-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-18: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-19: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-21: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 27-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-28: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-30: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-32: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-33: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 27-34: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 27-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-36: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-38: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-41: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 27-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-44: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 27-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-49: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-53: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-55: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-56: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-59: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-60: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-61: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 27-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-63: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 27-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-65: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-67: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 27-68: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 27-69: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-70: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-72: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-73: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-76: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-77: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-79: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-80: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-81: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 27-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-84: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-85: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-86: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-88: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-89: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 27-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-91: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 27-92: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 27-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-100: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 27-101: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-103: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 27-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-105: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0590 Acc: 92.1429%\n",
      "\tvalidation Loss: 0.0008 Acc: 100.0000%\n",
      "Time passed 0h 23m 55s\n",
      "--------------------\n",
      "Epoch [28/40]:\n",
      "\ttrain 28-1: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 28-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-3: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 28-4: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 28-5: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-6: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 28-7: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 28-8: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-9: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 28-10: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 28-11: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 28-12: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-13: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 28-14: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 28-15: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 28-16: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 28-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-18: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-19: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-20: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 28-21: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-22: Loss: 0.3684 Acc: 75.0000%\n",
      "\ttrain 28-23: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-24: Loss: 0.2720 Acc: 25.0000%\n",
      "\ttrain 28-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 28-26: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 28-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 28-28: Loss: 0.0618 Acc: 100.0000%\n",
      "\ttrain 28-29: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 28-30: Loss: 0.2266 Acc: 75.0000%\n",
      "\ttrain 28-31: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 28-32: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 28-33: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 28-34: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-35: Loss: 0.5711 Acc: 50.0000%\n",
      "\ttrain 28-36: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 28-37: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 28-38: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-39: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 28-40: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 28-41: Loss: 0.0746 Acc: 75.0000%\n",
      "\ttrain 28-42: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-43: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-44: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 28-45: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 28-46: Loss: 0.0516 Acc: 75.0000%\n",
      "\ttrain 28-47: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 28-48: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-49: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 28-50: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 28-51: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 28-52: Loss: 0.1176 Acc: 75.0000%\n",
      "\ttrain 28-53: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 28-54: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 28-55: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 28-56: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 28-57: Loss: 0.2109 Acc: 75.0000%\n",
      "\ttrain 28-58: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 28-59: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-60: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 28-61: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 28-62: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 28-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-64: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 28-65: Loss: 0.2582 Acc: 50.0000%\n",
      "\ttrain 28-66: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 28-67: Loss: 0.2344 Acc: 75.0000%\n",
      "\ttrain 28-68: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 28-69: Loss: 0.3071 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-70: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 28-71: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 28-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-73: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 28-74: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 28-75: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 28-76: Loss: 0.5270 Acc: 50.0000%\n",
      "\ttrain 28-77: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-78: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 28-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 28-80: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 28-81: Loss: 0.2790 Acc: 50.0000%\n",
      "\ttrain 28-82: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 28-83: Loss: 0.0440 Acc: 75.0000%\n",
      "\ttrain 28-84: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 28-85: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 28-86: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 28-87: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 28-88: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 28-89: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 28-90: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 28-91: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 28-92: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 28-93: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 28-94: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 28-95: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-96: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 28-97: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 28-98: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 28-99: Loss: 0.0449 Acc: 75.0000%\n",
      "\ttrain 28-100: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 28-101: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-103: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 28-104: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 28-105: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-106: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 28-107: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 28-108: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-109: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 28-110: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 28-111: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 28-112: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-113: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 28-114: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 28-115: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 28-116: Loss: 0.0780 Acc: 75.0000%\n",
      "\ttrain 28-117: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 28-118: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-119: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 28-121: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 28-122: Loss: 0.1731 Acc: 75.0000%\n",
      "\ttrain 28-123: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 28-124: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 28-125: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-126: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-127: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 28-128: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-129: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 28-130: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 28-131: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-132: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 28-133: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 28-134: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 28-135: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 28-136: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 28-137: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-138: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 28-139: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 28-140: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 28-141: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 28-142: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 28-143: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 28-144: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 28-145: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 28-146: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 28-147: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 28-148: Loss: 0.2459 Acc: 50.0000%\n",
      "\ttrain 28-149: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 28-150: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 28-151: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 28-152: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 28-153: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 28-154: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 28-155: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 28-156: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 28-157: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 28-158: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 28-159: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 28-160: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 28-161: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-162: Loss: 0.2127 Acc: 75.0000%\n",
      "\ttrain 28-163: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 28-164: Loss: 0.2354 Acc: 75.0000%\n",
      "\ttrain 28-165: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 28-166: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 28-167: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 28-168: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 28-169: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 28-170: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 28-171: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 28-172: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 28-173: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 28-174: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 28-175: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 28-176: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-177: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 28-178: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 28-179: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-180: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 28-181: Loss: 0.4661 Acc: 50.0000%\n",
      "\ttrain 28-182: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 28-183: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-184: Loss: 0.2011 Acc: 75.0000%\n",
      "\ttrain 28-185: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-186: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 28-187: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-188: Loss: 0.4366 Acc: 75.0000%\n",
      "\ttrain 28-189: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 28-190: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 28-191: Loss: 0.2926 Acc: 50.0000%\n",
      "\ttrain 28-192: Loss: 0.2889 Acc: 75.0000%\n",
      "\ttrain 28-193: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 28-194: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 28-195: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 28-196: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 28-197: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 28-198: Loss: 0.1994 Acc: 75.0000%\n",
      "\ttrain 28-199: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 28-200: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 28-201: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 28-202: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 28-203: Loss: 0.3135 Acc: 50.0000%\n",
      "\ttrain 28-204: Loss: 0.2067 Acc: 75.0000%\n",
      "\ttrain 28-205: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-206: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 28-207: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-208: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 28-209: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 28-210: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 28-211: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-212: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 28-213: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 28-214: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-215: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 28-216: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 28-217: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 28-218: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 28-219: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 28-220: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-221: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 28-222: Loss: 0.1057 Acc: 50.0000%\n",
      "\ttrain 28-223: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 28-224: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-225: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 28-226: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-227: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 28-228: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 28-229: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 28-230: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-231: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 28-232: Loss: 0.1702 Acc: 75.0000%\n",
      "\ttrain 28-233: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-234: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 28-235: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 28-236: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 28-237: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 28-238: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-239: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 28-240: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-241: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-242: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-243: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-244: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 28-245: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-1: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-2: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-3: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 28-4: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-9: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-12: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 28-13: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-14: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 28-15: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-16: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 28-17: Loss: 0.0022 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 28-18: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-19: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 28-20: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-21: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 28-22: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-25: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-27: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-29: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 28-30: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-32: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-34: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-36: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 28-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-38: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-40: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 28-41: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-43: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 28-44: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 28-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-46: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-47: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-49: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-50: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-51: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 28-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-53: Loss: 0.0782 Acc: 75.0000%\n",
      "\tvalidation 28-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-55: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 28-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-57: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 28-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-59: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 28-60: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 28-61: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 28-62: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 28-63: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 28-64: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 28-65: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-66: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 28-67: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 28-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-69: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-72: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-73: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-74: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 28-75: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 28-76: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 28-77: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 28-78: Loss: 0.0838 Acc: 75.0000%\n",
      "\tvalidation 28-79: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 28-80: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-81: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 28-82: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-90: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-91: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-97: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-99: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 28-100: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 28-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-102: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 28-103: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0503 Acc: 92.6531%\n",
      "\tvalidation Loss: 0.0035 Acc: 99.5238%\n",
      "Time passed 0h 24m 34s\n",
      "--------------------\n",
      "Epoch [29/40]:\n",
      "\ttrain 29-1: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-2: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 29-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-4: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-5: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 29-6: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 29-7: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 29-8: Loss: 0.5082 Acc: 75.0000%\n",
      "\ttrain 29-9: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 29-10: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 29-11: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 29-12: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 29-13: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-14: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-15: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-16: Loss: 0.8449 Acc: 25.0000%\n",
      "\ttrain 29-17: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 29-18: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-19: Loss: 0.3725 Acc: 50.0000%\n",
      "\ttrain 29-20: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 29-21: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-22: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 29-23: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-24: Loss: 0.1938 Acc: 75.0000%\n",
      "\ttrain 29-25: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 29-26: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 29-27: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 29-28: Loss: 1.1576 Acc: 75.0000%\n",
      "\ttrain 29-29: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-30: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-31: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-32: Loss: 0.5680 Acc: 50.0000%\n",
      "\ttrain 29-33: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 29-34: Loss: 0.6338 Acc: 25.0000%\n",
      "\ttrain 29-35: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 29-36: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 29-37: Loss: 0.9921 Acc: 50.0000%\n",
      "\ttrain 29-38: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 29-39: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 29-40: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 29-41: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-42: Loss: 0.1818 Acc: 75.0000%\n",
      "\ttrain 29-43: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-44: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 29-45: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-46: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 29-47: Loss: 0.3961 Acc: 75.0000%\n",
      "\ttrain 29-48: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 29-49: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 29-50: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-51: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 29-52: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 29-53: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 29-54: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 29-55: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 29-56: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 29-57: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-58: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 29-59: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 29-60: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 29-61: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-62: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 29-63: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 29-64: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 29-65: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 29-66: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 29-67: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 29-68: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 29-69: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 29-70: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 29-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-72: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 29-73: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 29-74: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 29-75: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-76: Loss: 0.0564 Acc: 100.0000%\n",
      "\ttrain 29-77: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 29-78: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 29-79: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 29-80: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-81: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 29-82: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-83: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-84: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 29-85: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 29-86: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-87: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-88: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 29-89: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 29-90: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 29-91: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-92: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-93: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-94: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 29-95: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-96: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 29-97: Loss: 0.0511 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-99: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 29-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-101: Loss: 0.3666 Acc: 50.0000%\n",
      "\ttrain 29-102: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 29-103: Loss: 0.2391 Acc: 50.0000%\n",
      "\ttrain 29-104: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 29-105: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-106: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-107: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 29-108: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 29-109: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 29-110: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 29-111: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 29-112: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 29-113: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 29-114: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 29-115: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 29-116: Loss: 0.2204 Acc: 75.0000%\n",
      "\ttrain 29-117: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 29-118: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 29-119: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 29-120: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 29-121: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 29-122: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 29-123: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-124: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 29-125: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 29-126: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 29-127: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 29-128: Loss: 0.1703 Acc: 75.0000%\n",
      "\ttrain 29-129: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-130: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 29-131: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 29-132: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 29-133: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 29-134: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 29-135: Loss: 0.4268 Acc: 50.0000%\n",
      "\ttrain 29-136: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-137: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-138: Loss: 0.0875 Acc: 100.0000%\n",
      "\ttrain 29-139: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-140: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 29-141: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 29-142: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 29-143: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-144: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-145: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 29-146: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 29-147: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 29-148: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 29-149: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-150: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 29-151: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-152: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 29-153: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-154: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 29-155: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 29-156: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-157: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 29-158: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-159: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-160: Loss: 0.1566 Acc: 75.0000%\n",
      "\ttrain 29-161: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-162: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-163: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 29-164: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 29-165: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 29-166: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 29-167: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 29-168: Loss: 0.0930 Acc: 100.0000%\n",
      "\ttrain 29-169: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-170: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 29-171: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 29-172: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 29-173: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 29-174: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 29-175: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 29-176: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 29-177: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-178: Loss: 0.2361 Acc: 75.0000%\n",
      "\ttrain 29-179: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 29-180: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 29-181: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 29-182: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-183: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 29-184: Loss: 0.2690 Acc: 75.0000%\n",
      "\ttrain 29-185: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-186: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-187: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-188: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-189: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 29-190: Loss: 0.1740 Acc: 75.0000%\n",
      "\ttrain 29-191: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 29-192: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-193: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-194: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-195: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 29-196: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-197: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 29-198: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 29-199: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-200: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-201: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 29-202: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 29-203: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 29-204: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-205: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-206: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-207: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 29-208: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-209: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-210: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-211: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-212: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-213: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 29-214: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-215: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-216: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-217: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 29-218: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 29-219: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-220: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 29-221: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-222: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 29-223: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-224: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 29-225: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-226: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-227: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 29-228: Loss: 0.1645 Acc: 50.0000%\n",
      "\ttrain 29-229: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-230: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 29-231: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 29-232: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-233: Loss: 0.2213 Acc: 50.0000%\n",
      "\ttrain 29-234: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-235: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 29-236: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-237: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-238: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-239: Loss: 0.0473 Acc: 75.0000%\n",
      "\ttrain 29-240: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 29-241: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 29-242: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-243: Loss: 0.0983 Acc: 75.0000%\n",
      "\ttrain 29-244: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 29-245: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 29-1: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-2: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 29-3: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 29-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-5: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-6: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 29-7: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 29-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-11: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-12: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 29-13: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-14: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 29-15: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 29-16: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-17: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 29-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-19: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 29-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-21: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 29-22: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-23: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 29-24: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 29-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-26: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-27: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-28: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-29: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-30: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 29-31: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-32: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 29-33: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 29-34: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-35: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 29-36: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 29-37: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 29-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-40: Loss: 0.0240 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 29-41: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-43: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 29-44: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-47: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-48: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 29-49: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 29-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-51: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 29-52: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-53: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-54: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-55: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 29-56: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 29-57: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 29-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-59: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 29-60: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 29-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-63: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-66: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-69: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 29-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-71: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 29-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-74: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-75: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 29-76: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 29-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-80: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 29-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-82: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-83: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 29-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-85: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-86: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 29-87: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 29-88: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 29-89: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-90: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 29-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-92: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 29-93: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-94: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-95: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-99: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-101: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-102: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-103: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-105: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0565 Acc: 93.7755%\n",
      "\tvalidation Loss: 0.0035 Acc: 100.0000%\n",
      "Time passed 0h 25m 18s\n",
      "--------------------\n",
      "Epoch [30/40]:\n",
      "\ttrain 30-1: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 30-2: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 30-3: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-4: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 30-5: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 30-6: Loss: 0.5784 Acc: 25.0000%\n",
      "\ttrain 30-7: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 30-8: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-9: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 30-10: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-11: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 30-12: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-13: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 30-14: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 30-15: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 30-16: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-17: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 30-18: Loss: 0.1923 Acc: 75.0000%\n",
      "\ttrain 30-19: Loss: 0.1245 Acc: 75.0000%\n",
      "\ttrain 30-20: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 30-21: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-22: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-23: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 30-24: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 30-25: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 30-26: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 30-27: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-28: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 30-29: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 30-30: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 30-31: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 30-32: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-33: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 30-34: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-35: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 30-36: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 30-37: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 30-38: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-39: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 30-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-41: Loss: 0.7850 Acc: 25.0000%\n",
      "\ttrain 30-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 30-43: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 30-44: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 30-45: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 30-46: Loss: 0.4588 Acc: 25.0000%\n",
      "\ttrain 30-47: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-48: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 30-49: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 30-50: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-51: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 30-52: Loss: 0.1756 Acc: 75.0000%\n",
      "\ttrain 30-53: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-54: Loss: 0.2195 Acc: 75.0000%\n",
      "\ttrain 30-55: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 30-56: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 30-57: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 30-58: Loss: 0.1893 Acc: 75.0000%\n",
      "\ttrain 30-59: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 30-60: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 30-61: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 30-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-63: Loss: 0.4824 Acc: 50.0000%\n",
      "\ttrain 30-64: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 30-65: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-66: Loss: 0.3218 Acc: 75.0000%\n",
      "\ttrain 30-67: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-68: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 30-69: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-70: Loss: 0.1539 Acc: 50.0000%\n",
      "\ttrain 30-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-72: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 30-73: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 30-74: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 30-75: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-76: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-77: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 30-78: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 30-79: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-80: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 30-81: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-82: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 30-83: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 30-84: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 30-85: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 30-86: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 30-87: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 30-88: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-89: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 30-90: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-91: Loss: 0.7858 Acc: 25.0000%\n",
      "\ttrain 30-92: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 30-93: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-94: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 30-95: Loss: 0.3522 Acc: 25.0000%\n",
      "\ttrain 30-96: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 30-97: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-98: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 30-99: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-100: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 30-101: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 30-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-103: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 30-104: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 30-105: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-106: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 30-107: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 30-108: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 30-109: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-110: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 30-111: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 30-112: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 30-113: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 30-114: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-115: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 30-116: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 30-117: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 30-118: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 30-119: Loss: 0.1118 Acc: 50.0000%\n",
      "\ttrain 30-120: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 30-121: Loss: 0.0031 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 30-122: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 30-123: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 30-124: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-125: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 30-126: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 30-127: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 30-128: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 30-129: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-130: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 30-131: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-132: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 30-133: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-134: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 30-135: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-136: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-137: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-138: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 30-139: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-140: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 30-141: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-142: Loss: 0.0459 Acc: 75.0000%\n",
      "\ttrain 30-143: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-144: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-145: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-146: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 30-147: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-148: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 30-149: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 30-150: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-152: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 30-153: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-154: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-155: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 30-156: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 30-157: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 30-158: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 30-159: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 30-160: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-161: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-162: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-163: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 30-164: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 30-165: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 30-166: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-167: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-168: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-169: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 30-170: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 30-171: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 30-172: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-173: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-174: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-175: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 30-176: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 30-177: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-178: Loss: 0.1726 Acc: 75.0000%\n",
      "\ttrain 30-179: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-180: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 30-181: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 30-182: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-183: Loss: 0.0493 Acc: 75.0000%\n",
      "\ttrain 30-184: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 30-185: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-186: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 30-187: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 30-188: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 30-189: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-190: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 30-191: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 30-192: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 30-193: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 30-194: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 30-195: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 30-196: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 30-197: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 30-198: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 30-199: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 30-200: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-201: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-202: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-203: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-204: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 30-205: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-206: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-207: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 30-208: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 30-209: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 30-210: Loss: 0.2076 Acc: 25.0000%\n",
      "\ttrain 30-211: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 30-212: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-213: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-214: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 30-215: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 30-216: Loss: 0.0477 Acc: 75.0000%\n",
      "\ttrain 30-217: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 30-218: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 30-219: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-220: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-221: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-222: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-223: Loss: 0.3071 Acc: 75.0000%\n",
      "\ttrain 30-224: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-225: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 30-226: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-227: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-228: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-229: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 30-230: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-231: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-232: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 30-233: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 30-234: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-235: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 30-236: Loss: 0.3679 Acc: 25.0000%\n",
      "\ttrain 30-237: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 30-238: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-239: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-240: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 30-241: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 30-242: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 30-243: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-244: Loss: 0.0461 Acc: 75.0000%\n",
      "\ttrain 30-245: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-1: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-2: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-3: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-4: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 30-5: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-6: Loss: 0.0635 Acc: 75.0000%\n",
      "\tvalidation 30-7: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-8: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-9: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 30-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-12: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-15: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-16: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-17: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 30-18: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-20: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-21: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 30-22: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-24: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-26: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-27: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-28: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 30-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-30: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-32: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-34: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-35: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 30-36: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-37: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-40: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 30-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-43: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-46: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-47: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-49: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 30-50: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 30-51: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-52: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-53: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-54: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 30-55: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 30-56: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-57: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 30-58: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-59: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-61: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-62: Loss: 0.0010 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 30-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-64: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 30-65: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-67: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 30-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-69: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 30-70: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 30-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-74: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-76: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-77: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 30-78: Loss: 0.1097 Acc: 75.0000%\n",
      "\tvalidation 30-79: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 30-80: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-82: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 30-83: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-88: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 30-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-90: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-94: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-97: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 30-98: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 30-99: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-100: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 30-101: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 30-102: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 30-103: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-105: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0438 Acc: 93.7755%\n",
      "\tvalidation Loss: 0.0033 Acc: 99.5238%\n",
      "Time passed 0h 26m 0s\n",
      "--------------------\n",
      "Epoch [31/40]:\n",
      "\ttrain 31-1: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 31-2: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 31-3: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 31-4: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 31-5: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 31-6: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 31-7: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 31-8: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 31-9: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-10: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-11: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 31-12: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 31-13: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 31-14: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 31-15: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-16: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 31-17: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 31-18: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 31-19: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-20: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-21: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-22: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 31-23: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 31-24: Loss: 0.4963 Acc: 75.0000%\n",
      "\ttrain 31-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-26: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 31-27: Loss: 0.2712 Acc: 75.0000%\n",
      "\ttrain 31-28: Loss: 0.0500 Acc: 75.0000%\n",
      "\ttrain 31-29: Loss: 0.3238 Acc: 50.0000%\n",
      "\ttrain 31-30: Loss: 0.2555 Acc: 75.0000%\n",
      "\ttrain 31-31: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 31-32: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 31-33: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 31-34: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 31-35: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 31-36: Loss: 0.1780 Acc: 75.0000%\n",
      "\ttrain 31-37: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 31-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-39: Loss: 0.2145 Acc: 75.0000%\n",
      "\ttrain 31-40: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 31-41: Loss: 0.1962 Acc: 75.0000%\n",
      "\ttrain 31-42: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 31-43: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 31-44: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 31-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-46: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-47: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 31-48: Loss: 0.2671 Acc: 75.0000%\n",
      "\ttrain 31-49: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-50: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 31-51: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-52: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-53: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 31-54: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 31-55: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 31-56: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 31-57: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 31-58: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 31-59: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 31-60: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 31-61: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 31-62: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-63: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 31-64: Loss: 0.2103 Acc: 50.0000%\n",
      "\ttrain 31-65: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 31-66: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 31-67: Loss: 1.1705 Acc: 25.0000%\n",
      "\ttrain 31-68: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 31-69: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 31-70: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 31-71: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 31-72: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-73: Loss: 0.1596 Acc: 75.0000%\n",
      "\ttrain 31-74: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 31-75: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 31-76: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 31-77: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 31-78: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 31-79: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 31-80: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 31-81: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 31-82: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 31-83: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 31-84: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 31-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-86: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 31-87: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 31-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-89: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 31-90: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 31-91: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-92: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 31-93: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-94: Loss: 0.3303 Acc: 75.0000%\n",
      "\ttrain 31-95: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-96: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 31-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-98: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 31-99: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-100: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 31-101: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-102: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-103: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-104: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 31-105: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 31-106: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 31-107: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 31-108: Loss: 0.1988 Acc: 75.0000%\n",
      "\ttrain 31-109: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-110: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 31-111: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 31-112: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 31-113: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 31-114: Loss: 0.4076 Acc: 50.0000%\n",
      "\ttrain 31-115: Loss: 0.1663 Acc: 75.0000%\n",
      "\ttrain 31-116: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 31-117: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 31-118: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 31-119: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-120: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 31-121: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 31-122: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-123: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 31-124: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 31-125: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 31-126: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-127: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 31-128: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 31-129: Loss: 0.0479 Acc: 75.0000%\n",
      "\ttrain 31-130: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 31-131: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-132: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-133: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 31-134: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-135: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 31-136: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 31-137: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 31-138: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 31-139: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 31-140: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-141: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 31-142: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-143: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 31-144: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-145: Loss: 0.2409 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-146: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 31-147: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 31-148: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 31-149: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-150: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 31-151: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 31-152: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 31-153: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-154: Loss: 0.1439 Acc: 50.0000%\n",
      "\ttrain 31-155: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 31-156: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-157: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 31-158: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-159: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-160: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 31-161: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 31-162: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 31-163: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 31-164: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-165: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-166: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 31-167: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 31-168: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-169: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 31-170: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 31-171: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-172: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-173: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 31-174: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-175: Loss: 0.0629 Acc: 75.0000%\n",
      "\ttrain 31-176: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-177: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-178: Loss: 0.1401 Acc: 75.0000%\n",
      "\ttrain 31-179: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-180: Loss: 0.2788 Acc: 50.0000%\n",
      "\ttrain 31-181: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-182: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 31-183: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-184: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-185: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 31-186: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-187: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 31-188: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 31-189: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-190: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-191: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 31-192: Loss: 0.2704 Acc: 75.0000%\n",
      "\ttrain 31-193: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 31-194: Loss: 0.1081 Acc: 100.0000%\n",
      "\ttrain 31-195: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 31-196: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-197: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 31-198: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 31-199: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 31-200: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-201: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 31-202: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-203: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 31-204: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 31-205: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-206: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 31-207: Loss: 0.1906 Acc: 75.0000%\n",
      "\ttrain 31-208: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 31-209: Loss: 0.8131 Acc: 0.0000%\n",
      "\ttrain 31-210: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 31-211: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-212: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-213: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 31-214: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 31-215: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 31-216: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 31-217: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 31-218: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-219: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 31-220: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 31-221: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 31-222: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 31-223: Loss: 0.3344 Acc: 50.0000%\n",
      "\ttrain 31-224: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 31-225: Loss: 0.0547 Acc: 75.0000%\n",
      "\ttrain 31-226: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 31-227: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-228: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 31-229: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-230: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 31-231: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 31-232: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-233: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 31-234: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 31-235: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 31-236: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 31-237: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-238: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 31-239: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-240: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-241: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 31-242: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 31-243: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 31-244: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-245: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 31-1: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 31-2: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 31-3: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-5: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 31-6: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-7: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-10: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-11: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 31-12: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 31-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-15: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-16: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-17: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-19: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 31-20: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-21: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 31-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-24: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-25: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-26: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 31-27: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-28: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-29: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 31-30: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-32: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-33: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 31-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-35: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 31-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 31-37: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-38: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-39: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-40: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-41: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 31-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-44: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-46: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 31-47: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 31-48: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 31-49: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 31-50: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 31-51: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-52: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 31-53: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-54: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-56: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 31-60: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-61: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 31-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-65: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 31-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-67: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-69: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 31-70: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-71: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-72: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-74: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 31-75: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-76: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 31-77: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 31-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-79: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 31-80: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-81: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-84: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 31-85: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-87: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 31-88: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 31-89: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-90: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 31-91: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 31-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-93: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 31-94: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-96: Loss: 0.0527 Acc: 75.0000%\n",
      "\tvalidation 31-97: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 31-98: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 31-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-100: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-102: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 31-103: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-104: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0516 Acc: 93.1633%\n",
      "\tvalidation Loss: 0.0036 Acc: 99.7619%\n",
      "Time passed 0h 26m 36s\n",
      "--------------------\n",
      "Epoch [32/40]:\n",
      "\ttrain 32-1: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 32-2: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 32-3: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-4: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 32-5: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-6: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 32-7: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 32-8: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 32-9: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-10: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-11: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 32-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-13: Loss: 0.2397 Acc: 50.0000%\n",
      "\ttrain 32-14: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 32-15: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 32-16: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 32-17: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-18: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-19: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-20: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 32-21: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 32-22: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 32-23: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 32-24: Loss: 0.1040 Acc: 75.0000%\n",
      "\ttrain 32-25: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 32-26: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-27: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 32-28: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 32-29: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-30: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 32-31: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 32-32: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 32-33: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-34: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 32-35: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-36: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 32-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-38: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 32-39: Loss: 0.4716 Acc: 75.0000%\n",
      "\ttrain 32-40: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 32-41: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-42: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 32-43: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 32-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-45: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 32-46: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-47: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 32-48: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-49: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 32-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-51: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-52: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 32-53: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-54: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-55: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 32-56: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 32-57: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-58: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 32-59: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-61: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 32-62: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 32-63: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 32-64: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 32-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-66: Loss: 0.2259 Acc: 75.0000%\n",
      "\ttrain 32-67: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 32-68: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 32-69: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 32-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-71: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 32-72: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 32-73: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-74: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 32-75: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 32-76: Loss: 0.2486 Acc: 75.0000%\n",
      "\ttrain 32-77: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 32-78: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-79: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 32-80: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 32-81: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-82: Loss: 0.1161 Acc: 50.0000%\n",
      "\ttrain 32-83: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 32-84: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 32-85: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 32-86: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 32-87: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 32-88: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 32-89: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-90: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 32-91: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 32-92: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-93: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 32-94: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 32-95: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 32-96: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 32-97: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 32-98: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 32-99: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 32-100: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 32-101: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-102: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 32-103: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 32-104: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 32-105: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 32-106: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-107: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 32-108: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-109: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-110: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 32-111: Loss: 0.2483 Acc: 75.0000%\n",
      "\ttrain 32-112: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-113: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 32-114: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 32-115: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-116: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 32-117: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-118: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-119: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-120: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-121: Loss: 0.2570 Acc: 75.0000%\n",
      "\ttrain 32-122: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-123: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 32-124: Loss: 0.2155 Acc: 50.0000%\n",
      "\ttrain 32-125: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-126: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-127: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-128: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 32-129: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 32-130: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 32-131: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-132: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 32-133: Loss: 0.1032 Acc: 50.0000%\n",
      "\ttrain 32-134: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-135: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 32-136: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 32-137: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 32-138: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 32-139: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 32-140: Loss: 0.2188 Acc: 75.0000%\n",
      "\ttrain 32-141: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 32-142: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-143: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 32-144: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-145: Loss: 0.0477 Acc: 75.0000%\n",
      "\ttrain 32-146: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 32-147: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 32-148: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 32-149: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-150: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 32-151: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 32-152: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 32-153: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 32-154: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 32-155: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-156: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-157: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 32-158: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-159: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-160: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-161: Loss: 0.5529 Acc: 75.0000%\n",
      "\ttrain 32-162: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-163: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-164: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-165: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 32-166: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 32-167: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 32-168: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-169: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 32-170: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-171: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 32-172: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-173: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 32-174: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 32-175: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-176: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-177: Loss: 0.0026 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-178: Loss: 0.2470 Acc: 75.0000%\n",
      "\ttrain 32-179: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-180: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-181: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-182: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-183: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-184: Loss: 0.8701 Acc: 0.0000%\n",
      "\ttrain 32-185: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-186: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-187: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 32-188: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-189: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-190: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-191: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 32-192: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-193: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 32-194: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 32-195: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 32-196: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 32-197: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 32-198: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 32-199: Loss: 0.2030 Acc: 50.0000%\n",
      "\ttrain 32-200: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-201: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 32-202: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 32-203: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-204: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-205: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 32-206: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-207: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-208: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 32-209: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-210: Loss: 0.0503 Acc: 75.0000%\n",
      "\ttrain 32-211: Loss: 0.3817 Acc: 75.0000%\n",
      "\ttrain 32-212: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-213: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 32-214: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 32-215: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 32-216: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 32-217: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 32-218: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 32-219: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 32-220: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 32-221: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-222: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-223: Loss: 0.4609 Acc: 50.0000%\n",
      "\ttrain 32-224: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 32-225: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-226: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 32-227: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-228: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 32-229: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 32-230: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 32-231: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 32-232: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 32-233: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 32-234: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-235: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 32-236: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 32-237: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-238: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-239: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-240: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 32-241: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-242: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 32-243: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-244: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 32-245: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-1: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-5: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-7: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 32-8: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-9: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 32-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-12: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 32-13: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 32-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-16: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-18: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 32-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-20: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-23: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-26: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-27: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 32-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-30: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 32-31: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-33: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-34: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-35: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 32-36: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 32-37: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 32-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-43: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-45: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 32-46: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 32-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-49: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-50: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-53: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 32-54: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 32-55: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 32-56: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 32-57: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 32-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-60: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-62: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-66: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 32-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-68: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 32-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 32-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-73: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 32-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-77: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 32-78: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-79: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 32-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-81: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-82: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 32-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-86: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-88: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 32-89: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-90: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-91: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 32-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-96: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-99: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-101: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-103: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-104: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-105: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0398 Acc: 94.4898%\n",
      "\tvalidation Loss: 0.0026 Acc: 100.0000%\n",
      "Time passed 0h 27m 15s\n",
      "--------------------\n",
      "Epoch [33/40]:\n",
      "\ttrain 33-1: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 33-2: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 33-3: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 33-4: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-5: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 33-6: Loss: 0.0046 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-7: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-8: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 33-9: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 33-10: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 33-11: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-12: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-13: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 33-14: Loss: 0.2796 Acc: 75.0000%\n",
      "\ttrain 33-15: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 33-16: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 33-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-18: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 33-19: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 33-20: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-21: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 33-22: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 33-23: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-24: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 33-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-26: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-27: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 33-28: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 33-29: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-30: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-31: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 33-32: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-33: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-34: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 33-35: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-36: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-37: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 33-38: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 33-39: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 33-40: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-41: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-42: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 33-43: Loss: 0.1597 Acc: 75.0000%\n",
      "\ttrain 33-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-45: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 33-46: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-48: Loss: 0.4357 Acc: 50.0000%\n",
      "\ttrain 33-49: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 33-50: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-51: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 33-52: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-53: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 33-54: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-55: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-56: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 33-57: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 33-58: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 33-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-60: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 33-61: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-62: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-63: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 33-64: Loss: 0.6204 Acc: 50.0000%\n",
      "\ttrain 33-65: Loss: 0.5261 Acc: 25.0000%\n",
      "\ttrain 33-66: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 33-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-69: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-70: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 33-71: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 33-72: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 33-73: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 33-74: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 33-75: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 33-76: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 33-77: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 33-78: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-79: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 33-80: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 33-81: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-82: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-83: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 33-84: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 33-85: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 33-86: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-87: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 33-88: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-89: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-91: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 33-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-93: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-94: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-95: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-96: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 33-97: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 33-98: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-99: Loss: 0.0671 Acc: 100.0000%\n",
      "\ttrain 33-100: Loss: 0.1405 Acc: 75.0000%\n",
      "\ttrain 33-101: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 33-102: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 33-103: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 33-104: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-105: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 33-106: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-107: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-108: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-109: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 33-110: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-111: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 33-112: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 33-113: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-114: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 33-115: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 33-116: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 33-117: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 33-118: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-119: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 33-120: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 33-121: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-122: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-123: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 33-124: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-125: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-126: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-127: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 33-128: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-129: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 33-130: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 33-131: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-132: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-133: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 33-134: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 33-135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-136: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 33-137: Loss: 0.6283 Acc: 75.0000%\n",
      "\ttrain 33-138: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-139: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 33-140: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 33-141: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-142: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 33-143: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 33-144: Loss: 0.6299 Acc: 75.0000%\n",
      "\ttrain 33-145: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 33-146: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 33-147: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 33-148: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 33-149: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-150: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-151: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-152: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 33-153: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-154: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-155: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 33-156: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 33-157: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-158: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 33-159: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 33-160: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 33-161: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-162: Loss: 0.1836 Acc: 75.0000%\n",
      "\ttrain 33-163: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 33-164: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 33-165: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 33-166: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-167: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-168: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 33-169: Loss: 0.2035 Acc: 75.0000%\n",
      "\ttrain 33-170: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 33-171: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-172: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 33-173: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-174: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 33-175: Loss: 0.2453 Acc: 75.0000%\n",
      "\ttrain 33-176: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-177: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-178: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-179: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-180: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-181: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-182: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-183: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-184: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 33-185: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 33-186: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 33-187: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 33-188: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 33-189: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-190: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-191: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 33-192: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-193: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-194: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 33-195: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-196: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-197: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 33-198: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 33-199: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-200: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-201: Loss: 0.0778 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-202: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 33-203: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 33-204: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 33-205: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-206: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 33-207: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 33-208: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-209: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-210: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 33-211: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-212: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 33-213: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-214: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-215: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-216: Loss: 0.1482 Acc: 75.0000%\n",
      "\ttrain 33-217: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 33-218: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-219: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 33-220: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-221: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-222: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 33-223: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-224: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-225: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 33-226: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 33-227: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-228: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-229: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 33-230: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-231: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 33-232: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 33-233: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-234: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-235: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 33-236: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-237: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 33-238: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-239: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-241: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-242: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 33-243: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-244: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-245: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 33-1: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-2: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-4: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-6: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-7: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 33-8: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-9: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 33-10: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-11: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-14: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 33-15: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 33-16: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-21: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-30: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-33: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-37: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 33-38: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-41: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-45: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-49: Loss: 0.0411 Acc: 100.0000%\n",
      "\tvalidation 33-50: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 33-51: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-52: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 33-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-55: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-60: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-66: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-67: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-69: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 33-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-71: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-72: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-73: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-75: Loss: 0.1314 Acc: 75.0000%\n",
      "\tvalidation 33-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-79: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-84: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 33-85: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 33-86: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 33-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-94: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 33-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-96: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 33-97: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 33-98: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 33-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-101: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 33-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-105: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0356 Acc: 95.5102%\n",
      "\tvalidation Loss: 0.0039 Acc: 99.5238%\n",
      "Time passed 0h 27m 59s\n",
      "--------------------\n",
      "Epoch [34/40]:\n",
      "\ttrain 34-1: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-3: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 34-4: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 34-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-6: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 34-7: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-8: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-9: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 34-10: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 34-11: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 34-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-13: Loss: 0.2101 Acc: 75.0000%\n",
      "\ttrain 34-14: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-15: Loss: 0.2473 Acc: 50.0000%\n",
      "\ttrain 34-16: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-17: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 34-18: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 34-19: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 34-20: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 34-21: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 34-22: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 34-23: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 34-24: Loss: 0.2035 Acc: 75.0000%\n",
      "\ttrain 34-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-26: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 34-27: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 34-28: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-29: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 34-30: Loss: 0.0017 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-31: Loss: 0.0512 Acc: 75.0000%\n",
      "\ttrain 34-32: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 34-33: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 34-34: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 34-35: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 34-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-37: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 34-38: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 34-39: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 34-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-41: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 34-42: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-43: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-44: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 34-45: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 34-46: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-47: Loss: 0.2360 Acc: 75.0000%\n",
      "\ttrain 34-48: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-50: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 34-51: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 34-52: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 34-53: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-54: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 34-55: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 34-56: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 34-57: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 34-58: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-59: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 34-60: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 34-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-62: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-64: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 34-65: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 34-66: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-67: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 34-68: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 34-69: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 34-70: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 34-71: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-72: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-73: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 34-74: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 34-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-76: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 34-77: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-78: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 34-79: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-80: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 34-81: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-82: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-83: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 34-84: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-85: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 34-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-87: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-88: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-89: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-92: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 34-93: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 34-94: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 34-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-96: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 34-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-98: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 34-99: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 34-100: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-101: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-102: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 34-103: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 34-104: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 34-105: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 34-106: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 34-107: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-108: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-109: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 34-110: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-111: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 34-112: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-113: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-114: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 34-115: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-116: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 34-117: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-118: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 34-119: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 34-120: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 34-121: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 34-122: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 34-123: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-124: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 34-125: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 34-126: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-127: Loss: 0.2568 Acc: 75.0000%\n",
      "\ttrain 34-128: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-129: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 34-130: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-131: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 34-132: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 34-133: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-134: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-135: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-136: Loss: 0.7193 Acc: 25.0000%\n",
      "\ttrain 34-137: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-138: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 34-139: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 34-140: Loss: 0.1001 Acc: 75.0000%\n",
      "\ttrain 34-141: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-142: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 34-143: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 34-144: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 34-145: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-146: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 34-147: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 34-148: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-149: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 34-150: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 34-151: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 34-152: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-153: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-154: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 34-155: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 34-156: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-157: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-158: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 34-159: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 34-160: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 34-161: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-162: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 34-163: Loss: 0.1463 Acc: 50.0000%\n",
      "\ttrain 34-164: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 34-165: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-166: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 34-167: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-168: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 34-169: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 34-170: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 34-171: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-172: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 34-173: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 34-174: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-175: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-176: Loss: 0.1426 Acc: 75.0000%\n",
      "\ttrain 34-177: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 34-178: Loss: 0.0783 Acc: 100.0000%\n",
      "\ttrain 34-179: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 34-180: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-181: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-182: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-183: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-184: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-185: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-186: Loss: 0.1423 Acc: 50.0000%\n",
      "\ttrain 34-187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-188: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-189: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-190: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 34-191: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-192: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 34-193: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-194: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-195: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-196: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 34-197: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-198: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 34-199: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 34-200: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-201: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 34-202: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-203: Loss: 0.2504 Acc: 75.0000%\n",
      "\ttrain 34-204: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 34-205: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-206: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 34-207: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 34-208: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 34-209: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-210: Loss: 0.4195 Acc: 50.0000%\n",
      "\ttrain 34-211: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-212: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 34-213: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-214: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 34-215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-216: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 34-217: Loss: 0.2362 Acc: 50.0000%\n",
      "\ttrain 34-218: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-219: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 34-220: Loss: 0.3379 Acc: 75.0000%\n",
      "\ttrain 34-221: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 34-222: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-223: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 34-224: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-225: Loss: 0.0005 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-226: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 34-227: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 34-228: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-229: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-230: Loss: 0.3835 Acc: 50.0000%\n",
      "\ttrain 34-231: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-232: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 34-233: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 34-234: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 34-235: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 34-236: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 34-237: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 34-238: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 34-239: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 34-240: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 34-241: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-242: Loss: 0.4393 Acc: 75.0000%\n",
      "\ttrain 34-243: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 34-244: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 34-245: Loss: 0.0470 Acc: 100.0000%\n",
      "\tvalidation 34-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-2: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-3: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-6: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-9: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-13: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-15: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-16: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-19: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-21: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-23: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-27: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-31: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-33: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 34-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-35: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-37: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 34-38: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-39: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-43: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 34-44: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 34-45: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 34-46: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 34-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-49: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 34-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-52: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 34-53: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-54: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-55: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-57: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-59: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 34-60: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-61: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 34-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-64: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 34-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-67: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-68: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-71: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-74: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 34-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-76: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 34-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-81: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 34-82: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-83: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-84: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-86: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 34-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-89: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-90: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-91: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-95: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 34-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-101: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-102: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 34-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-104: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 34-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0345 Acc: 95.3061%\n",
      "\tvalidation Loss: 0.0009 Acc: 100.0000%\n",
      "Time passed 0h 28m 42s\n",
      "--------------------\n",
      "Epoch [35/40]:\n",
      "\ttrain 35-1: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-2: Loss: 0.2334 Acc: 75.0000%\n",
      "\ttrain 35-3: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-4: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 35-5: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 35-6: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 35-7: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 35-8: Loss: 1.2443 Acc: 50.0000%\n",
      "\ttrain 35-9: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-10: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-11: Loss: 0.1508 Acc: 50.0000%\n",
      "\ttrain 35-12: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-13: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 35-14: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-15: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 35-16: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-17: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-18: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-20: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-21: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-23: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 35-24: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-25: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-26: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-27: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-28: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 35-29: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 35-30: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 35-31: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 35-32: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 35-33: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 35-34: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 35-35: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 35-36: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-37: Loss: 0.3258 Acc: 75.0000%\n",
      "\ttrain 35-38: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-40: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 35-41: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-42: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 35-43: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-44: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-45: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-46: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 35-47: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-49: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 35-50: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-51: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 35-52: Loss: 0.2162 Acc: 75.0000%\n",
      "\ttrain 35-53: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 35-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-55: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 35-56: Loss: 0.0375 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-58: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-60: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 35-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-62: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-63: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 35-64: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 35-65: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 35-66: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-67: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-68: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 35-69: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-70: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 35-71: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-72: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-73: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 35-74: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-75: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 35-76: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 35-77: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 35-78: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 35-79: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-80: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-81: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 35-82: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 35-83: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 35-84: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-85: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 35-86: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 35-87: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 35-88: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-89: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-90: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 35-91: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-92: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 35-93: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 35-94: Loss: 0.0810 Acc: 75.0000%\n",
      "\ttrain 35-95: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 35-96: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 35-97: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 35-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-99: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 35-100: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 35-101: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-102: Loss: 0.4586 Acc: 75.0000%\n",
      "\ttrain 35-103: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 35-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 35-106: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 35-107: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-108: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-109: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 35-110: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-111: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 35-112: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 35-113: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 35-114: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-115: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 35-116: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-117: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 35-118: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-119: Loss: 0.0465 Acc: 75.0000%\n",
      "\ttrain 35-120: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 35-121: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 35-122: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-123: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-124: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 35-125: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-126: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 35-127: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 35-128: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-129: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-130: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-131: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-132: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 35-133: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 35-134: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-135: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-136: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-137: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-138: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-139: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 35-140: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 35-141: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-142: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-143: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 35-144: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 35-145: Loss: 0.2962 Acc: 75.0000%\n",
      "\ttrain 35-146: Loss: 0.2412 Acc: 50.0000%\n",
      "\ttrain 35-147: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 35-148: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 35-149: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 35-150: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-151: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-152: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 35-153: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-154: Loss: 0.4411 Acc: 50.0000%\n",
      "\ttrain 35-155: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 35-156: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-157: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 35-158: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-159: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-160: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 35-161: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 35-162: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-163: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 35-164: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 35-165: Loss: 0.2963 Acc: 75.0000%\n",
      "\ttrain 35-166: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 35-167: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-168: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-169: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-170: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-171: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-172: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 35-173: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 35-174: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-175: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 35-176: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-177: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-178: Loss: 0.2632 Acc: 75.0000%\n",
      "\ttrain 35-179: Loss: 0.2018 Acc: 75.0000%\n",
      "\ttrain 35-180: Loss: 0.1574 Acc: 50.0000%\n",
      "\ttrain 35-181: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 35-182: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-183: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 35-184: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-185: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 35-186: Loss: 0.2568 Acc: 75.0000%\n",
      "\ttrain 35-187: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-188: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 35-189: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 35-190: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-191: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 35-192: Loss: 0.2661 Acc: 75.0000%\n",
      "\ttrain 35-193: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-194: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 35-195: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 35-196: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 35-197: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-198: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-199: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 35-200: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-201: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 35-202: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 35-203: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-204: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 35-205: Loss: 0.2438 Acc: 75.0000%\n",
      "\ttrain 35-206: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 35-207: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-208: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 35-209: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 35-210: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-211: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-212: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-213: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 35-214: Loss: 0.0567 Acc: 75.0000%\n",
      "\ttrain 35-215: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 35-216: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-217: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-218: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 35-219: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-220: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-221: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-222: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 35-223: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 35-224: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-225: Loss: 0.1017 Acc: 75.0000%\n",
      "\ttrain 35-226: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-227: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-228: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-229: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 35-230: Loss: 0.1976 Acc: 75.0000%\n",
      "\ttrain 35-231: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 35-232: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 35-233: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 35-234: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-235: Loss: 0.3317 Acc: 50.0000%\n",
      "\ttrain 35-236: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 35-237: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-238: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-239: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 35-240: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 35-241: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-242: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-243: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-244: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-245: Loss: 0.1353 Acc: 75.0000%\n",
      "\tvalidation 35-1: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 35-2: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 35-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-4: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 35-5: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 35-6: Loss: 0.0019 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 35-7: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 35-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-9: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 35-10: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 35-11: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 35-12: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 35-13: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 35-14: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 35-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-16: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-17: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-18: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 35-19: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 35-20: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-22: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 35-23: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 35-24: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 35-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-26: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 35-27: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-28: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-29: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 35-30: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-31: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 35-32: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 35-33: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-35: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 35-36: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-37: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 35-38: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 35-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-40: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 35-41: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 35-42: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 35-43: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 35-44: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-45: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 35-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-48: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-50: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-51: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-52: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-54: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-55: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 35-56: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 35-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-59: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 35-60: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 35-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-63: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 35-64: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 35-65: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 35-66: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-68: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-69: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-70: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 35-71: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-72: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 35-73: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 35-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-76: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 35-77: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-78: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-79: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-81: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 35-82: Loss: 0.0228 Acc: 100.0000%\n",
      "\tvalidation 35-83: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 35-84: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 35-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-86: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 35-87: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 35-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-89: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 35-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-92: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 35-93: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-96: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-97: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 35-98: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-101: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-102: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-103: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 35-104: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0407 Acc: 94.7959%\n",
      "\tvalidation Loss: 0.0060 Acc: 100.0000%\n",
      "Time passed 0h 29m 21s\n",
      "--------------------\n",
      "Epoch [36/40]:\n",
      "\ttrain 36-1: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 36-2: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-3: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 36-4: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 36-5: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-6: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-7: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 36-8: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 36-9: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-10: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 36-11: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-12: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 36-13: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 36-14: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 36-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-16: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-18: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-19: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-21: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 36-22: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-23: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-24: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 36-25: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 36-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-27: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 36-28: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 36-29: Loss: 0.1103 Acc: 50.0000%\n",
      "\ttrain 36-30: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 36-31: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-33: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 36-34: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 36-35: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-39: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-40: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 36-41: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-43: Loss: 0.7266 Acc: 25.0000%\n",
      "\ttrain 36-44: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 36-45: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 36-46: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 36-47: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-48: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-49: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 36-50: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 36-51: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 36-52: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 36-53: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 36-54: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-55: Loss: 0.2348 Acc: 50.0000%\n",
      "\ttrain 36-56: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-57: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-58: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 36-59: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 36-60: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 36-61: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-62: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 36-63: Loss: 0.3414 Acc: 50.0000%\n",
      "\ttrain 36-64: Loss: 0.1949 Acc: 50.0000%\n",
      "\ttrain 36-65: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 36-66: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-67: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-68: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-69: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-71: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 36-72: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 36-73: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 36-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-75: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-76: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 36-77: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 36-78: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-79: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-80: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 36-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-82: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 36-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-84: Loss: 0.0272 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-85: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-86: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-87: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-88: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 36-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-90: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-91: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 36-92: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 36-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-95: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-96: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-97: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 36-98: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 36-99: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 36-100: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 36-101: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 36-102: Loss: 0.1775 Acc: 50.0000%\n",
      "\ttrain 36-103: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-104: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-105: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 36-106: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 36-107: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 36-108: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-109: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-110: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-111: Loss: 0.3323 Acc: 75.0000%\n",
      "\ttrain 36-112: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-113: Loss: 0.2014 Acc: 75.0000%\n",
      "\ttrain 36-114: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 36-115: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-116: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 36-117: Loss: 0.3683 Acc: 25.0000%\n",
      "\ttrain 36-118: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-119: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-120: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-121: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 36-122: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 36-123: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-124: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 36-125: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 36-126: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 36-127: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 36-128: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-129: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-130: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 36-131: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-132: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-133: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-134: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 36-135: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-136: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 36-137: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 36-138: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-139: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-140: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 36-141: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-142: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-143: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-144: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 36-145: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 36-146: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-147: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 36-148: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 36-149: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 36-150: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-151: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-152: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-153: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 36-154: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 36-155: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-156: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 36-157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-158: Loss: 0.2805 Acc: 75.0000%\n",
      "\ttrain 36-159: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-160: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 36-161: Loss: 0.2721 Acc: 75.0000%\n",
      "\ttrain 36-162: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 36-163: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-164: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 36-165: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-166: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-167: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-168: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 36-169: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-170: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-171: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 36-172: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-173: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 36-174: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 36-175: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 36-176: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 36-177: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-178: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 36-179: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 36-180: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-181: Loss: 0.2183 Acc: 75.0000%\n",
      "\ttrain 36-182: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-183: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-184: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 36-185: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 36-186: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 36-187: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-188: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-189: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 36-190: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-191: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 36-192: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-193: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-194: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 36-195: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-196: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-197: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 36-198: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 36-199: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-200: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 36-201: Loss: 0.5711 Acc: 75.0000%\n",
      "\ttrain 36-202: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 36-203: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 36-204: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-205: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 36-206: Loss: 0.4434 Acc: 75.0000%\n",
      "\ttrain 36-207: Loss: 0.5313 Acc: 25.0000%\n",
      "\ttrain 36-208: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 36-209: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 36-210: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 36-211: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 36-212: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-213: Loss: 0.9166 Acc: 25.0000%\n",
      "\ttrain 36-214: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-215: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-216: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 36-217: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-218: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 36-219: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 36-220: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 36-221: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-222: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 36-223: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-224: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 36-225: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 36-226: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 36-227: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-228: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 36-229: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 36-230: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 36-231: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 36-232: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 36-233: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 36-234: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-235: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-236: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-237: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-238: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 36-239: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 36-240: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-241: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 36-242: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-243: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 36-244: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 36-245: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 36-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-2: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-6: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-7: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-8: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 36-9: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-10: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 36-11: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 36-12: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-13: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-14: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-15: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-16: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 36-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-18: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-22: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-23: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 36-24: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 36-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-27: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-28: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 36-29: Loss: 0.0013 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 36-30: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-33: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-34: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-35: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 36-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-38: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 36-39: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-40: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 36-41: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-49: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-51: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 36-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-53: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-54: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-56: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 36-57: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-58: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-59: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-61: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 36-62: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-63: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 36-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-65: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-66: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 36-67: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 36-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-69: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-71: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-72: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-74: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 36-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-77: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-79: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-80: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-81: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-83: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-84: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 36-85: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 36-86: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 36-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-90: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 36-93: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-95: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 36-96: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-97: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 36-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-100: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 36-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-103: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 36-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-105: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0411 Acc: 94.8980%\n",
      "\tvalidation Loss: 0.0019 Acc: 100.0000%\n",
      "Time passed 0h 30m 0s\n",
      "--------------------\n",
      "Epoch [37/40]:\n",
      "\ttrain 37-1: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-2: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-3: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-4: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 37-5: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 37-6: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-7: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 37-8: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 37-9: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-10: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-11: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 37-12: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-13: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-14: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 37-15: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 37-16: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 37-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-18: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 37-19: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 37-20: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 37-21: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-23: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 37-24: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-25: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 37-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-27: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-28: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 37-29: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 37-30: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-31: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 37-32: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 37-33: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-34: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 37-35: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 37-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-37: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 37-38: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 37-39: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 37-40: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 37-41: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 37-42: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 37-43: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 37-44: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 37-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-46: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-47: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 37-48: Loss: 0.5758 Acc: 75.0000%\n",
      "\ttrain 37-49: Loss: 0.0543 Acc: 75.0000%\n",
      "\ttrain 37-50: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-51: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-52: Loss: 0.8243 Acc: 50.0000%\n",
      "\ttrain 37-53: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 37-54: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-55: Loss: 0.3617 Acc: 25.0000%\n",
      "\ttrain 37-56: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 37-57: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 37-58: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-59: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-60: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 37-61: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 37-62: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-63: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-64: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-65: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 37-66: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 37-67: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-68: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-69: Loss: 0.2526 Acc: 75.0000%\n",
      "\ttrain 37-70: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 37-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-72: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-73: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 37-74: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 37-75: Loss: 0.0642 Acc: 75.0000%\n",
      "\ttrain 37-76: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 37-77: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 37-78: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 37-79: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-80: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-81: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-82: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-84: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 37-85: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-86: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 37-87: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-88: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-89: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 37-90: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 37-91: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 37-92: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 37-93: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 37-94: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-95: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-96: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 37-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-98: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-99: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-100: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 37-101: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 37-102: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 37-103: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-104: Loss: 0.4541 Acc: 50.0000%\n",
      "\ttrain 37-105: Loss: 0.9210 Acc: 25.0000%\n",
      "\ttrain 37-106: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-107: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-108: Loss: 0.2115 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-109: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 37-110: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 37-111: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 37-112: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 37-113: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 37-114: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 37-115: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 37-116: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 37-117: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-118: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 37-119: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 37-120: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 37-121: Loss: 0.2695 Acc: 50.0000%\n",
      "\ttrain 37-122: Loss: 0.1850 Acc: 75.0000%\n",
      "\ttrain 37-123: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 37-124: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 37-125: Loss: 0.4980 Acc: 50.0000%\n",
      "\ttrain 37-126: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-127: Loss: 0.2769 Acc: 50.0000%\n",
      "\ttrain 37-128: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 37-129: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-130: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-131: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 37-132: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 37-133: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-134: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 37-135: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 37-136: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 37-137: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 37-138: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-139: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 37-140: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-141: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 37-142: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 37-143: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-144: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 37-145: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 37-146: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-147: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 37-148: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 37-149: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 37-150: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 37-151: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 37-152: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 37-153: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-154: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-155: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-156: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-157: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-158: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-159: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 37-160: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-161: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-162: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 37-163: Loss: 0.0746 Acc: 75.0000%\n",
      "\ttrain 37-164: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 37-165: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-166: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 37-167: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 37-168: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 37-169: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 37-170: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 37-171: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-172: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 37-173: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 37-174: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 37-175: Loss: 0.0682 Acc: 75.0000%\n",
      "\ttrain 37-176: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 37-177: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-178: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-179: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-180: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 37-181: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-182: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 37-183: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 37-184: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 37-185: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 37-186: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 37-187: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-188: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-189: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 37-190: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-191: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-192: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 37-193: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-194: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 37-195: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 37-196: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-197: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 37-198: Loss: 0.2404 Acc: 75.0000%\n",
      "\ttrain 37-199: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 37-200: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 37-201: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 37-202: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 37-203: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 37-204: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-205: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 37-206: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-207: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 37-208: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-209: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-210: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 37-211: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 37-212: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-213: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-214: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-215: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 37-216: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 37-217: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-218: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 37-219: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 37-220: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 37-221: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 37-222: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 37-223: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-224: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 37-225: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 37-226: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-227: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 37-228: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 37-229: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-230: Loss: 0.1784 Acc: 75.0000%\n",
      "\ttrain 37-231: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-232: Loss: 0.1958 Acc: 75.0000%\n",
      "\ttrain 37-233: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-234: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 37-235: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 37-236: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 37-237: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 37-238: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 37-239: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-240: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-241: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-242: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-243: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 37-244: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-245: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 37-1: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-2: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-6: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-9: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 37-10: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-11: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-14: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 37-15: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-16: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 37-17: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 37-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-20: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 37-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-23: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-26: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-31: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-33: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 37-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-38: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-40: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-41: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 37-42: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-44: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 37-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-48: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-50: Loss: 0.0005 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 37-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-52: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-55: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-59: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-60: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 37-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-68: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-70: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-71: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 37-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-74: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-75: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-76: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-77: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 37-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-79: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-80: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 37-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-82: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-84: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-86: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-87: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-88: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-92: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-94: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-97: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-99: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-100: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-103: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-104: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 37-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0428 Acc: 94.1837%\n",
      "\tvalidation Loss: 0.0007 Acc: 100.0000%\n",
      "Time passed 0h 30m 40s\n",
      "--------------------\n",
      "Epoch [38/40]:\n",
      "\ttrain 38-1: Loss: 0.9263 Acc: 50.0000%\n",
      "\ttrain 38-2: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-3: Loss: 0.2080 Acc: 50.0000%\n",
      "\ttrain 38-4: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 38-5: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-7: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 38-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-9: Loss: 0.3831 Acc: 75.0000%\n",
      "\ttrain 38-10: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 38-11: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-12: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-13: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 38-14: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 38-15: Loss: 0.2104 Acc: 75.0000%\n",
      "\ttrain 38-16: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-17: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 38-18: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-19: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 38-20: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 38-21: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 38-22: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 38-23: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 38-24: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 38-25: Loss: 0.1076 Acc: 50.0000%\n",
      "\ttrain 38-26: Loss: 0.1416 Acc: 75.0000%\n",
      "\ttrain 38-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-29: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 38-30: Loss: 0.0470 Acc: 75.0000%\n",
      "\ttrain 38-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-33: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 38-34: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-35: Loss: 0.2443 Acc: 50.0000%\n",
      "\ttrain 38-36: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-37: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-38: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 38-39: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 38-40: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-41: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 38-42: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 38-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-44: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 38-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-46: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-47: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 38-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-49: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-50: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-51: Loss: 0.0541 Acc: 75.0000%\n",
      "\ttrain 38-52: Loss: 0.1682 Acc: 75.0000%\n",
      "\ttrain 38-53: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-54: Loss: 0.1604 Acc: 50.0000%\n",
      "\ttrain 38-55: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-56: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 38-57: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 38-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-59: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 38-60: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 38-61: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 38-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-63: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-64: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-65: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 38-66: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-67: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-68: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 38-69: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-70: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 38-71: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 38-72: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 38-73: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-74: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 38-75: Loss: 0.3271 Acc: 75.0000%\n",
      "\ttrain 38-76: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-77: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 38-78: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 38-79: Loss: 0.3075 Acc: 50.0000%\n",
      "\ttrain 38-80: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 38-81: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 38-82: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 38-83: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 38-84: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 38-85: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 38-86: Loss: 0.2249 Acc: 75.0000%\n",
      "\ttrain 38-87: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 38-88: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 38-89: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 38-90: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 38-91: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 38-92: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-93: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 38-94: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 38-95: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 38-96: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-97: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-98: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-99: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-101: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-102: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 38-103: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 38-104: Loss: 0.0816 Acc: 75.0000%\n",
      "\ttrain 38-105: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 38-106: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-107: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 38-108: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 38-109: Loss: 0.0545 Acc: 75.0000%\n",
      "\ttrain 38-110: Loss: 0.1907 Acc: 75.0000%\n",
      "\ttrain 38-111: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 38-112: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 38-113: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-114: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 38-115: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 38-116: Loss: 0.1665 Acc: 75.0000%\n",
      "\ttrain 38-117: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 38-118: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-119: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 38-120: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 38-121: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-122: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-123: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-124: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 38-125: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-126: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 38-127: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-128: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-129: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 38-130: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 38-131: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 38-132: Loss: 0.0297 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 38-133: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-134: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-135: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 38-136: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 38-137: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-138: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-139: Loss: 0.3858 Acc: 25.0000%\n",
      "\ttrain 38-140: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-141: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-142: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-143: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-144: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-145: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 38-146: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 38-147: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-148: Loss: 0.1820 Acc: 50.0000%\n",
      "\ttrain 38-149: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-150: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 38-151: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-152: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-153: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-154: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-155: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 38-156: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-157: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 38-158: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 38-159: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-160: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 38-161: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 38-162: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-163: Loss: 0.1892 Acc: 75.0000%\n",
      "\ttrain 38-164: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 38-165: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-166: Loss: 0.2003 Acc: 75.0000%\n",
      "\ttrain 38-167: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 38-168: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 38-169: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-170: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 38-171: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-172: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-173: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-175: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-176: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-177: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-178: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-179: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 38-180: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 38-181: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-182: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-183: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 38-184: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 38-185: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-186: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 38-187: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 38-188: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 38-189: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 38-190: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-191: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 38-192: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-193: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-194: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-195: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-196: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-197: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 38-198: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-200: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 38-201: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 38-202: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-203: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-204: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 38-205: Loss: 0.7109 Acc: 0.0000%\n",
      "\ttrain 38-206: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 38-207: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-208: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-209: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-210: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-211: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-212: Loss: 0.9657 Acc: 25.0000%\n",
      "\ttrain 38-213: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-214: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-215: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 38-216: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-217: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-218: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-219: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-220: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-221: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-222: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-223: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 38-224: Loss: 0.1627 Acc: 75.0000%\n",
      "\ttrain 38-225: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 38-226: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-227: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-228: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 38-229: Loss: 0.0772 Acc: 100.0000%\n",
      "\ttrain 38-230: Loss: 0.2125 Acc: 75.0000%\n",
      "\ttrain 38-231: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-232: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-233: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 38-234: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 38-235: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-236: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 38-237: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 38-238: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-239: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-240: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-241: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 38-242: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-243: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 38-244: Loss: 0.4774 Acc: 25.0000%\n",
      "\ttrain 38-245: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 38-1: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 38-2: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-4: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-5: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-6: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 38-7: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 38-8: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 38-9: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-10: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 38-11: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-12: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 38-13: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 38-14: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 38-15: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-16: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-17: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-18: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 38-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-20: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-21: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-22: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-23: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-24: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-26: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-27: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 38-28: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 38-29: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 38-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-31: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-32: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 38-33: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 38-34: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-35: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 38-36: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-37: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-38: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-39: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 38-40: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 38-41: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 38-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-43: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-44: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-46: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-47: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-48: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-49: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-50: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-51: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 38-52: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 38-53: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-54: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 38-55: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-56: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 38-57: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-58: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-59: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-60: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 38-61: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 38-62: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 38-63: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 38-64: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 38-65: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-66: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-68: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-69: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 38-70: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 38-71: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-72: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 38-73: Loss: 0.0007 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 38-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-75: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 38-76: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-79: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-81: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-82: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 38-83: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-84: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-85: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 38-86: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-87: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-88: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 38-89: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-90: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-91: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 38-92: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 38-93: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 38-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-95: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 38-96: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 38-97: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-98: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 38-99: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-101: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-102: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 38-104: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 38-105: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0477 Acc: 92.8571%\n",
      "\tvalidation Loss: 0.0045 Acc: 100.0000%\n",
      "Time passed 0h 31m 23s\n",
      "--------------------\n",
      "Epoch [39/40]:\n",
      "\ttrain 39-1: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 39-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-3: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 39-4: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 39-5: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-6: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 39-7: Loss: 0.9526 Acc: 50.0000%\n",
      "\ttrain 39-8: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 39-9: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 39-10: Loss: 0.2106 Acc: 75.0000%\n",
      "\ttrain 39-11: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-12: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 39-13: Loss: 0.0691 Acc: 100.0000%\n",
      "\ttrain 39-14: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-15: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 39-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-17: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-18: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 39-19: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-20: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 39-21: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 39-22: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 39-23: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-24: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 39-25: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 39-26: Loss: 0.2785 Acc: 75.0000%\n",
      "\ttrain 39-27: Loss: 0.0730 Acc: 100.0000%\n",
      "\ttrain 39-28: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-29: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 39-30: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-32: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 39-33: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-34: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 39-35: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-36: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 39-37: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-39: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-40: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 39-41: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 39-42: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-43: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 39-44: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-45: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-46: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-47: Loss: 0.1702 Acc: 50.0000%\n",
      "\ttrain 39-48: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 39-49: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-50: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 39-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-52: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 39-53: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-54: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 39-55: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 39-56: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 39-57: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-58: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 39-59: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-60: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 39-61: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-63: Loss: 0.2235 Acc: 75.0000%\n",
      "\ttrain 39-64: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-65: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-66: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 39-67: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 39-68: Loss: 0.2839 Acc: 75.0000%\n",
      "\ttrain 39-69: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 39-70: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-71: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-72: Loss: 0.4641 Acc: 75.0000%\n",
      "\ttrain 39-73: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 39-74: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 39-75: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 39-76: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 39-77: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-78: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-79: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-80: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 39-81: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-83: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 39-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-85: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 39-86: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-87: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-88: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-89: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 39-90: Loss: 0.2587 Acc: 50.0000%\n",
      "\ttrain 39-91: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-92: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-94: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 39-95: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-97: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 39-98: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 39-99: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 39-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-101: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-102: Loss: 0.1377 Acc: 75.0000%\n",
      "\ttrain 39-103: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 39-104: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 39-105: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 39-106: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 39-107: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-108: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 39-109: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-110: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 39-111: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 39-112: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-113: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 39-114: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 39-115: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-116: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 39-117: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-118: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-119: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 39-120: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 39-121: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-122: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-123: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 39-124: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 39-125: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 39-126: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 39-127: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-128: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 39-129: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-130: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-131: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-132: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 39-133: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-134: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-135: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-136: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 39-137: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-138: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 39-139: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-140: Loss: 0.3250 Acc: 75.0000%\n",
      "\ttrain 39-141: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 39-142: Loss: 0.0676 Acc: 100.0000%\n",
      "\ttrain 39-143: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-144: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 39-145: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 39-146: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-147: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-148: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-149: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-150: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-151: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 39-152: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-153: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 39-154: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 39-155: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-156: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-157: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 39-158: Loss: 0.0414 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-159: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-160: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 39-161: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 39-162: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 39-163: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-164: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-165: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-166: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 39-167: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 39-168: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 39-169: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-170: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 39-171: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 39-172: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-173: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-174: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-175: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 39-176: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-177: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 39-178: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-179: Loss: 0.2733 Acc: 50.0000%\n",
      "\ttrain 39-180: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 39-181: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 39-182: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-183: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 39-184: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 39-185: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 39-186: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 39-187: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 39-188: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 39-189: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-190: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 39-191: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 39-192: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-193: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 39-194: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 39-195: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-196: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-197: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-198: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-199: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 39-200: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-201: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 39-202: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-203: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-204: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-205: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 39-206: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-207: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-208: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-209: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 39-210: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-211: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-212: Loss: 0.3958 Acc: 50.0000%\n",
      "\ttrain 39-213: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 39-214: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-215: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-216: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 39-217: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 39-218: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-219: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-220: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 39-221: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-222: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-223: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-224: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 39-225: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-226: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-227: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-228: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-229: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 39-230: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-231: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-232: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-233: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 39-234: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-235: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 39-236: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-237: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-238: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-240: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-241: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-242: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-243: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-244: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 39-245: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-3: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-9: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-13: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-19: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 39-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-21: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-22: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-25: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-26: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 39-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-34: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 39-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-38: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-41: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-46: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-49: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-54: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-62: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-64: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-75: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-79: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-80: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 39-81: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 39-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-83: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-86: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-89: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-90: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 39-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-97: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-98: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 39-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-100: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-101: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-103: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-104: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 39-105: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0334 Acc: 96.1224%\n",
      "\tvalidation Loss: 0.0005 Acc: 100.0000%\n",
      "Time passed 0h 32m 6s\n",
      "--------------------\n",
      "Epoch [40/40]:\n",
      "\ttrain 40-1: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 40-2: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-4: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-5: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-6: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-8: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 40-9: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-10: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 40-11: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 40-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-13: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-14: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-15: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-16: Loss: 0.1688 Acc: 75.0000%\n",
      "\ttrain 40-17: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-18: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-19: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 40-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-21: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-23: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-26: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-27: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 40-28: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 40-29: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 40-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-31: Loss: 0.0983 Acc: 75.0000%\n",
      "\ttrain 40-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-34: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-35: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 40-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-37: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-38: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-39: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-40: Loss: 0.4860 Acc: 50.0000%\n",
      "\ttrain 40-41: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-42: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-43: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-45: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-46: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 40-47: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-48: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 40-49: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 40-50: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 40-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-53: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 40-54: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 40-55: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-56: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-57: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 40-58: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 40-59: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 40-60: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 40-61: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 40-62: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-64: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 40-65: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 40-66: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-67: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 40-68: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-69: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-70: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-74: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 40-75: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-76: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-77: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 40-78: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-79: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 40-80: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 40-81: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 40-82: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 40-83: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-85: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-86: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-88: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 40-89: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-90: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-91: Loss: 0.3979 Acc: 50.0000%\n",
      "\ttrain 40-92: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-93: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 40-94: Loss: 0.2654 Acc: 75.0000%\n",
      "\ttrain 40-95: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 40-96: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 40-97: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 40-98: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 40-99: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-100: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 40-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-102: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-103: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-104: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 40-105: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 40-106: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-107: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-108: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-109: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-110: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 40-111: Loss: 0.2002 Acc: 50.0000%\n",
      "\ttrain 40-112: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-113: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 40-114: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-115: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-116: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 40-117: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-118: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-119: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 40-120: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 40-121: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-122: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 40-123: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-124: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 40-125: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-126: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-127: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 40-128: Loss: 0.0457 Acc: 75.0000%\n",
      "\ttrain 40-129: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-130: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 40-131: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 40-132: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-133: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 40-134: Loss: 0.0780 Acc: 75.0000%\n",
      "\ttrain 40-135: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-136: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-137: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-138: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 40-139: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 40-140: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 40-141: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-142: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 40-143: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 40-144: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-145: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-146: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 40-147: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 40-148: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 40-149: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-150: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 40-151: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-152: Loss: 0.3005 Acc: 75.0000%\n",
      "\ttrain 40-153: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-154: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-155: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-156: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-157: Loss: 0.2572 Acc: 50.0000%\n",
      "\ttrain 40-158: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 40-159: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 40-160: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-161: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 40-162: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-163: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 40-164: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 40-165: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-166: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-167: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 40-168: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 40-169: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 40-170: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 40-171: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-172: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-173: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-174: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-175: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-176: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-177: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-178: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 40-179: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-180: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 40-181: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-182: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 40-183: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 40-184: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 40-185: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 40-186: Loss: 0.0065 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-187: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 40-188: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 40-189: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 40-190: Loss: 0.4598 Acc: 50.0000%\n",
      "\ttrain 40-191: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-192: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-193: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-194: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 40-195: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 40-196: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-197: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-198: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-199: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 40-200: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-201: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 40-202: Loss: 0.4129 Acc: 50.0000%\n",
      "\ttrain 40-203: Loss: 0.2188 Acc: 75.0000%\n",
      "\ttrain 40-204: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 40-205: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 40-206: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 40-207: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-208: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 40-209: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 40-210: Loss: 0.2387 Acc: 75.0000%\n",
      "\ttrain 40-211: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-212: Loss: 0.1853 Acc: 75.0000%\n",
      "\ttrain 40-213: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 40-214: Loss: 0.2033 Acc: 50.0000%\n",
      "\ttrain 40-215: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 40-216: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 40-217: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 40-218: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-219: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 40-220: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-221: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 40-222: Loss: 0.2703 Acc: 75.0000%\n",
      "\ttrain 40-223: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 40-224: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-225: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 40-226: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-227: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 40-228: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 40-229: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 40-230: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 40-231: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 40-232: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-233: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-234: Loss: 0.2282 Acc: 75.0000%\n",
      "\ttrain 40-235: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 40-236: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-237: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-238: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-239: Loss: 0.0825 Acc: 75.0000%\n",
      "\ttrain 40-240: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 40-241: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-242: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 40-243: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 40-244: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 40-245: Loss: 0.2517 Acc: 75.0000%\n",
      "\tvalidation 40-1: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 40-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-7: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-16: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-17: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 40-18: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-20: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 40-21: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 40-22: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-23: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 40-24: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-26: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 40-27: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 40-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-29: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 40-30: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-31: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 40-32: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-35: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 40-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-38: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 40-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-40: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 40-41: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-42: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 40-43: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 40-44: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 40-45: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 40-46: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-47: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 40-48: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-49: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-50: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-51: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-52: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-54: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 40-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-56: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-58: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 40-59: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-60: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 40-61: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 40-62: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-65: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 40-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-67: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-69: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-70: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-73: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-74: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 40-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-76: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-77: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 40-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-81: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 40-82: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 40-83: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-86: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-87: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-88: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 40-89: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 40-90: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-93: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 40-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-95: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-97: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 40-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-99: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-101: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 40-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-103: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-104: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0388 Acc: 94.4898%\n",
      "\tvalidation Loss: 0.0018 Acc: 100.0000%\n",
      "Time passed 0h 32m 44s\n",
      "--------------------\n",
      "Training complete in 0h 32m 44s\n",
      "Best validation Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "loss_train = []  # 训练集loss\n",
    "acc_train = []  # 训练集正确率\n",
    "loss_val = []  # 验证集loss\n",
    "acc_val = []  # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "\n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            i = 1\n",
    "            j = 1\n",
    "            # exp_lr_scheduler.step()\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            i = 1\n",
    "            j = 2\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            # if use_gpu:\n",
    "            #     inputs = inputs.cuda()\n",
    "            #     labels = labels.cuda()\n",
    "            # else:\n",
    "            #     inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            # '_'就是一个变量，换成a也是可以的，没有特别的意思，不过一般用_表示的变量好像都是没什么用的一个临时变量，大概是\n",
    "            # 一个编程习惯吧。所以这边'_,'没有特殊的含义，'_'就是一个变量，只是为了让preds取到max函数返回值的第二项，\n",
    "            # 即找到的最大值的索引位置（对应到这里就是类别标签）\n",
    "            # （max函数解释见https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max）\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, num_classes):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "\n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, i, loss.item()/4, torch.sum(preds == labels.data).item()/4.0*100))\n",
    "            i = i + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if j == 1:\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and j == 2:\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'validation' and epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"网络参数更新\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/params_resnet50.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "#             print(\"Model's state_dict:\")\n",
    "#             for param_tensor in best_model_wts:\n",
    "#                 print(param_tensor, \"\\t\", best_model_wts[param_tensor].size())\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.6391922061236537, 0.3744046525383482, 0.3094751033855944, 0.2755426866667611, 0.2623668855550338, 0.2318807403043825, 0.22329289073846778, 0.21390683416809356, 0.2020427270051168, 0.15577980594671503, 0.14587588371062765, 0.1381097043047146, 0.1233956486746973, 0.08083296631063734, 0.08315224978996782, 0.07916821699057307, 0.10958076169600292, 0.08690906139660855, 0.06904868843908213, 0.08389012314835373, 0.07372647174158875, 0.06236682509889408, 0.08329961348553093, 0.04358386373033329, 0.04720718136855534, 0.06044517036299316, 0.05897781523514767, 0.050253636374765515, 0.056514696320708914, 0.04384061882690508, 0.05157311654516629, 0.03975570323515912, 0.03560592599061071, 0.034513533723597625, 0.040692951180497, 0.0411090466136835, 0.0428333975678804, 0.04766702934795496, 0.03339526774931927, 0.038825749134530824]\n",
      "loss_val: [1.0873847594573385, 0.323656174327646, 0.13883835765577499, 0.28562708795070646, 0.23622659338372096, 0.13505131808065232, 0.18579890273866198, 0.17749543573175158, 0.05906922916571299, 0.19202903587193715, 0.18551496710805665, 0.1222011495204199, 0.11339954116514751, 0.1251209747223627, 0.009142517333938963, 0.026532288250469025, 0.016749878156752815, 0.006250017242772239, 0.09778594835883095, 0.0028452295632589433, 0.007735016587234678, 0.0015616625547409057, 0.021179984509944915, 0.021981514990329742, 0.0062206030601546876, 0.004570688803990682, 0.0008476440395627703, 0.003510365741593497, 0.003469500087556385, 0.0033373625505538212, 0.0036043111767087663, 0.0026237161386580693, 0.003914639424710047, 0.0008829129593712943, 0.005993883524622236, 0.00186917625722431, 0.0007129392453602382, 0.004466173904282706, 0.0004843842415582566, 0.0017785059554236277]\n",
      "acc_train: [0.3224489795918367, 0.4714285714285714, 0.5755102040816327, 0.5816326530612245, 0.5887755102040816, 0.6326530612244898, 0.6214285714285714, 0.6479591836734694, 0.676530612244898, 0.7489795918367347, 0.7969387755102041, 0.7989795918367347, 0.8224489795918367, 0.8948979591836734, 0.8795918367346939, 0.8795918367346939, 0.8448979591836735, 0.8693877551020408, 0.9071428571428571, 0.8846938775510204, 0.8989795918367347, 0.9142857142857143, 0.8857142857142857, 0.9479591836734694, 0.9408163265306122, 0.9081632653061225, 0.9214285714285714, 0.926530612244898, 0.9377551020408164, 0.9377551020408164, 0.9316326530612244, 0.9448979591836735, 0.9551020408163265, 0.9530612244897959, 0.9479591836734694, 0.9489795918367347, 0.9418367346938775, 0.9285714285714286, 0.9612244897959183, 0.9448979591836735]\n",
      "acc_val: [0.4595238095238095, 0.6761904761904762, 0.7428571428571429, 0.7476190476190476, 0.7476190476190476, 0.7452380952380953, 0.7214285714285714, 0.7523809523809524, 0.9, 0.8, 0.9166666666666666, 0.8976190476190476, 0.8595238095238096, 0.819047619047619, 0.9952380952380953, 0.9642857142857143, 0.9761904761904762, 1.0, 0.85, 1.0, 0.9928571428571429, 1.0, 0.9642857142857143, 0.969047619047619, 0.9928571428571429, 1.0, 1.0, 0.9952380952380953, 1.0, 0.9952380952380953, 0.9976190476190476, 1.0, 0.9952380952380953, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss(ResNet50)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy(ResNet50)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:     75    81    77    79\n",
      "Predicted:     75    81    77    79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('75', '77', '79', '81')\n",
    "\n",
    "dataiter = iter(dataloders['validation'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[z]] for z in range(4)))\n",
    "\n",
    "# test\n",
    "outputs = model(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[z]] for z in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   Predicted\n",
      "\n",
      "\t   75\t77\t79\t81\n",
      "\n",
      "Actual 75  105\t0\t0\t0\t\n",
      "\n",
      "Actual 77  0\t105\t0\t0\t\n",
      "\n",
      "Actual 79  0\t0\t105\t0\t\n",
      "\n",
      "Actual 81  0\t0\t0\t105\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conc = {\n",
    "    '0': '75  ',\n",
    "    '1': '77  ',\n",
    "    '2': '79  ',\n",
    "    '3': '81  '\n",
    "}\n",
    "\n",
    "print(\"\\t   Predicted\\n\")\n",
    "print(\"\\t   75\\t77\\t79\\t81\\n\")\n",
    "for i in range(0, num_classes):\n",
    "    print(\"Actual \", end='')\n",
    "    print(conc[str(i)], end='')\n",
    "    for j in range(0, num_classes):\n",
    "        print(str(best_matrix[i][j]) + '\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
