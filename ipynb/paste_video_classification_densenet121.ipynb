{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个代码每个epoch都跑一遍训练集和验证集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "shuffle = True\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "# 加载densenet121预训练模型\n",
    "model = models.densenet121(pretrained=False)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=10) for x in ['train', 'validation']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]:\n",
      "\ttrain 1-1: Loss: 0.3408 Acc: 0.0000%\n",
      "\ttrain 1-2: Loss: 0.3412 Acc: 0.0000%\n",
      "\ttrain 1-3: Loss: 0.3297 Acc: 0.0000%\n",
      "\ttrain 1-4: Loss: 0.3548 Acc: 25.0000%\n",
      "\ttrain 1-5: Loss: 0.3106 Acc: 25.0000%\n",
      "\ttrain 1-6: Loss: 0.3681 Acc: 25.0000%\n",
      "\ttrain 1-7: Loss: 0.3053 Acc: 50.0000%\n",
      "\ttrain 1-8: Loss: 0.4291 Acc: 0.0000%\n",
      "\ttrain 1-9: Loss: 0.2934 Acc: 75.0000%\n",
      "\ttrain 1-10: Loss: 0.3481 Acc: 25.0000%\n",
      "\ttrain 1-11: Loss: 0.2626 Acc: 50.0000%\n",
      "\ttrain 1-12: Loss: 0.4329 Acc: 25.0000%\n",
      "\ttrain 1-13: Loss: 0.3589 Acc: 25.0000%\n",
      "\ttrain 1-14: Loss: 0.3841 Acc: 50.0000%\n",
      "\ttrain 1-15: Loss: 0.3908 Acc: 25.0000%\n",
      "\ttrain 1-16: Loss: 0.2650 Acc: 75.0000%\n",
      "\ttrain 1-17: Loss: 0.3220 Acc: 50.0000%\n",
      "\ttrain 1-18: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 1-19: Loss: 0.3787 Acc: 25.0000%\n",
      "\ttrain 1-20: Loss: 0.3593 Acc: 25.0000%\n",
      "\ttrain 1-21: Loss: 0.3874 Acc: 0.0000%\n",
      "\ttrain 1-22: Loss: 0.3245 Acc: 25.0000%\n",
      "\ttrain 1-23: Loss: 0.3442 Acc: 50.0000%\n",
      "\ttrain 1-24: Loss: 0.3017 Acc: 25.0000%\n",
      "\ttrain 1-25: Loss: 0.3035 Acc: 50.0000%\n",
      "\ttrain 1-26: Loss: 0.2799 Acc: 50.0000%\n",
      "\ttrain 1-27: Loss: 0.3227 Acc: 50.0000%\n",
      "\ttrain 1-28: Loss: 0.3726 Acc: 25.0000%\n",
      "\ttrain 1-29: Loss: 0.3876 Acc: 0.0000%\n",
      "\ttrain 1-30: Loss: 0.2371 Acc: 75.0000%\n",
      "\ttrain 1-31: Loss: 0.2732 Acc: 75.0000%\n",
      "\ttrain 1-32: Loss: 0.3693 Acc: 25.0000%\n",
      "\ttrain 1-33: Loss: 0.2855 Acc: 25.0000%\n",
      "\ttrain 1-34: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 1-35: Loss: 0.2717 Acc: 25.0000%\n",
      "\ttrain 1-36: Loss: 0.4427 Acc: 25.0000%\n",
      "\ttrain 1-37: Loss: 0.2514 Acc: 25.0000%\n",
      "\ttrain 1-38: Loss: 0.2777 Acc: 50.0000%\n",
      "\ttrain 1-39: Loss: 0.3015 Acc: 50.0000%\n",
      "\ttrain 1-40: Loss: 0.3101 Acc: 25.0000%\n",
      "\ttrain 1-41: Loss: 0.3099 Acc: 50.0000%\n",
      "\ttrain 1-42: Loss: 0.5339 Acc: 0.0000%\n",
      "\ttrain 1-43: Loss: 0.3210 Acc: 75.0000%\n",
      "\ttrain 1-44: Loss: 0.4577 Acc: 25.0000%\n",
      "\ttrain 1-45: Loss: 0.2520 Acc: 50.0000%\n",
      "\ttrain 1-46: Loss: 0.2759 Acc: 50.0000%\n",
      "\ttrain 1-47: Loss: 0.2824 Acc: 50.0000%\n",
      "\ttrain 1-48: Loss: 0.2836 Acc: 50.0000%\n",
      "\ttrain 1-49: Loss: 0.3625 Acc: 25.0000%\n",
      "\ttrain 1-50: Loss: 0.2478 Acc: 75.0000%\n",
      "\ttrain 1-51: Loss: 0.2558 Acc: 75.0000%\n",
      "\ttrain 1-52: Loss: 0.3327 Acc: 50.0000%\n",
      "\ttrain 1-53: Loss: 0.3267 Acc: 50.0000%\n",
      "\ttrain 1-54: Loss: 0.3291 Acc: 25.0000%\n",
      "\ttrain 1-55: Loss: 0.3380 Acc: 25.0000%\n",
      "\ttrain 1-56: Loss: 0.2140 Acc: 75.0000%\n",
      "\ttrain 1-57: Loss: 0.3086 Acc: 25.0000%\n",
      "\ttrain 1-58: Loss: 0.3121 Acc: 25.0000%\n",
      "\ttrain 1-59: Loss: 0.4183 Acc: 25.0000%\n",
      "\ttrain 1-60: Loss: 0.2524 Acc: 50.0000%\n",
      "\ttrain 1-61: Loss: 0.1703 Acc: 100.0000%\n",
      "\ttrain 1-62: Loss: 0.3014 Acc: 50.0000%\n",
      "\ttrain 1-63: Loss: 0.3587 Acc: 25.0000%\n",
      "\ttrain 1-64: Loss: 0.2984 Acc: 25.0000%\n",
      "\ttrain 1-65: Loss: 0.1624 Acc: 100.0000%\n",
      "\ttrain 1-66: Loss: 0.2706 Acc: 50.0000%\n",
      "\ttrain 1-67: Loss: 0.4590 Acc: 0.0000%\n",
      "\ttrain 1-68: Loss: 0.3866 Acc: 25.0000%\n",
      "\ttrain 1-69: Loss: 0.4374 Acc: 0.0000%\n",
      "\ttrain 1-70: Loss: 0.2528 Acc: 50.0000%\n",
      "\ttrain 1-71: Loss: 0.2629 Acc: 25.0000%\n",
      "\ttrain 1-72: Loss: 0.2068 Acc: 75.0000%\n",
      "\ttrain 1-73: Loss: 0.4167 Acc: 0.0000%\n",
      "\ttrain 1-74: Loss: 0.1791 Acc: 75.0000%\n",
      "\ttrain 1-75: Loss: 0.2433 Acc: 75.0000%\n",
      "\ttrain 1-76: Loss: 0.4417 Acc: 25.0000%\n",
      "\ttrain 1-77: Loss: 0.1920 Acc: 100.0000%\n",
      "\ttrain 1-78: Loss: 0.2567 Acc: 25.0000%\n",
      "\ttrain 1-79: Loss: 0.1980 Acc: 100.0000%\n",
      "\ttrain 1-80: Loss: 0.3202 Acc: 25.0000%\n",
      "\ttrain 1-81: Loss: 0.2579 Acc: 75.0000%\n",
      "\ttrain 1-82: Loss: 0.2910 Acc: 50.0000%\n",
      "\ttrain 1-83: Loss: 0.2872 Acc: 25.0000%\n",
      "\ttrain 1-84: Loss: 0.2407 Acc: 75.0000%\n",
      "\ttrain 1-85: Loss: 0.2884 Acc: 25.0000%\n",
      "\ttrain 1-86: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 1-87: Loss: 0.2237 Acc: 75.0000%\n",
      "\ttrain 1-88: Loss: 0.4174 Acc: 0.0000%\n",
      "\ttrain 1-89: Loss: 0.3114 Acc: 25.0000%\n",
      "\ttrain 1-90: Loss: 0.2426 Acc: 50.0000%\n",
      "\ttrain 1-91: Loss: 0.3195 Acc: 50.0000%\n",
      "\ttrain 1-92: Loss: 0.1918 Acc: 75.0000%\n",
      "\ttrain 1-93: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 1-94: Loss: 0.2832 Acc: 25.0000%\n",
      "\ttrain 1-95: Loss: 0.4721 Acc: 25.0000%\n",
      "\ttrain 1-96: Loss: 0.2776 Acc: 50.0000%\n",
      "\ttrain 1-97: Loss: 0.2899 Acc: 50.0000%\n",
      "\ttrain 1-98: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 1-99: Loss: 0.2932 Acc: 50.0000%\n",
      "\ttrain 1-100: Loss: 0.2361 Acc: 25.0000%\n",
      "\ttrain 1-101: Loss: 0.1586 Acc: 50.0000%\n",
      "\ttrain 1-102: Loss: 0.2189 Acc: 100.0000%\n",
      "\ttrain 1-103: Loss: 0.2276 Acc: 75.0000%\n",
      "\ttrain 1-104: Loss: 0.2588 Acc: 50.0000%\n",
      "\ttrain 1-105: Loss: 0.2058 Acc: 50.0000%\n",
      "\ttrain 1-106: Loss: 0.1695 Acc: 100.0000%\n",
      "\ttrain 1-107: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 1-108: Loss: 0.2868 Acc: 25.0000%\n",
      "\ttrain 1-109: Loss: 0.1647 Acc: 75.0000%\n",
      "\ttrain 1-110: Loss: 0.2621 Acc: 50.0000%\n",
      "\ttrain 1-111: Loss: 0.2366 Acc: 50.0000%\n",
      "\ttrain 1-112: Loss: 0.2341 Acc: 25.0000%\n",
      "\ttrain 1-113: Loss: 0.2245 Acc: 50.0000%\n",
      "\ttrain 1-114: Loss: 0.2495 Acc: 75.0000%\n",
      "\ttrain 1-115: Loss: 0.3273 Acc: 50.0000%\n",
      "\ttrain 1-116: Loss: 0.4212 Acc: 25.0000%\n",
      "\ttrain 1-117: Loss: 0.1336 Acc: 100.0000%\n",
      "\ttrain 1-118: Loss: 0.2476 Acc: 50.0000%\n",
      "\ttrain 1-119: Loss: 0.3341 Acc: 50.0000%\n",
      "\ttrain 1-120: Loss: 0.1950 Acc: 75.0000%\n",
      "\ttrain 1-121: Loss: 0.2297 Acc: 25.0000%\n",
      "\ttrain 1-122: Loss: 0.3270 Acc: 25.0000%\n",
      "\ttrain 1-123: Loss: 0.1446 Acc: 100.0000%\n",
      "\ttrain 1-124: Loss: 0.3677 Acc: 25.0000%\n",
      "\ttrain 1-125: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 1-126: Loss: 0.2109 Acc: 75.0000%\n",
      "\ttrain 1-127: Loss: 0.1807 Acc: 100.0000%\n",
      "\ttrain 1-128: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 1-129: Loss: 0.1328 Acc: 100.0000%\n",
      "\ttrain 1-130: Loss: 0.1244 Acc: 100.0000%\n",
      "\ttrain 1-131: Loss: 0.1612 Acc: 100.0000%\n",
      "\ttrain 1-132: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 1-133: Loss: 0.2943 Acc: 50.0000%\n",
      "\ttrain 1-134: Loss: 0.3607 Acc: 25.0000%\n",
      "\ttrain 1-135: Loss: 0.1787 Acc: 75.0000%\n",
      "\ttrain 1-136: Loss: 0.2202 Acc: 75.0000%\n",
      "\ttrain 1-137: Loss: 0.3704 Acc: 50.0000%\n",
      "\ttrain 1-138: Loss: 0.2996 Acc: 25.0000%\n",
      "\ttrain 1-139: Loss: 0.1741 Acc: 75.0000%\n",
      "\ttrain 1-140: Loss: 0.2060 Acc: 100.0000%\n",
      "\ttrain 1-141: Loss: 0.2683 Acc: 50.0000%\n",
      "\ttrain 1-142: Loss: 0.2874 Acc: 25.0000%\n",
      "\ttrain 1-143: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 1-144: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 1-145: Loss: 0.2055 Acc: 50.0000%\n",
      "\ttrain 1-146: Loss: 0.1806 Acc: 50.0000%\n",
      "\ttrain 1-147: Loss: 0.2889 Acc: 75.0000%\n",
      "\ttrain 1-148: Loss: 0.3336 Acc: 50.0000%\n",
      "\ttrain 1-149: Loss: 0.2646 Acc: 25.0000%\n",
      "\ttrain 1-150: Loss: 0.2798 Acc: 50.0000%\n",
      "\ttrain 1-151: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 1-152: Loss: 0.2686 Acc: 75.0000%\n",
      "\ttrain 1-153: Loss: 0.2160 Acc: 50.0000%\n",
      "\ttrain 1-154: Loss: 0.1188 Acc: 100.0000%\n",
      "\ttrain 1-155: Loss: 0.2426 Acc: 50.0000%\n",
      "\ttrain 1-156: Loss: 0.2977 Acc: 50.0000%\n",
      "\ttrain 1-157: Loss: 0.1955 Acc: 75.0000%\n",
      "\ttrain 1-158: Loss: 0.1020 Acc: 100.0000%\n",
      "\ttrain 1-159: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 1-160: Loss: 0.1295 Acc: 100.0000%\n",
      "\ttrain 1-161: Loss: 0.1430 Acc: 100.0000%\n",
      "\ttrain 1-162: Loss: 0.1493 Acc: 100.0000%\n",
      "\ttrain 1-163: Loss: 0.1888 Acc: 50.0000%\n",
      "\ttrain 1-164: Loss: 0.2059 Acc: 25.0000%\n",
      "\ttrain 1-165: Loss: 0.2782 Acc: 25.0000%\n",
      "\ttrain 1-166: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 1-167: Loss: 0.2251 Acc: 50.0000%\n",
      "\ttrain 1-168: Loss: 0.2357 Acc: 50.0000%\n",
      "\ttrain 1-169: Loss: 0.2373 Acc: 25.0000%\n",
      "\ttrain 1-170: Loss: 0.1066 Acc: 100.0000%\n",
      "\ttrain 1-171: Loss: 0.1244 Acc: 100.0000%\n",
      "\ttrain 1-172: Loss: 0.2836 Acc: 50.0000%\n",
      "\ttrain 1-173: Loss: 0.2592 Acc: 25.0000%\n",
      "\ttrain 1-174: Loss: 0.1906 Acc: 75.0000%\n",
      "\ttrain 1-175: Loss: 0.2460 Acc: 50.0000%\n",
      "\ttrain 1-176: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 1-177: Loss: 0.2649 Acc: 50.0000%\n",
      "\ttrain 1-178: Loss: 0.3588 Acc: 50.0000%\n",
      "\ttrain 1-179: Loss: 0.1459 Acc: 100.0000%\n",
      "\ttrain 1-180: Loss: 0.0968 Acc: 100.0000%\n",
      "\ttrain 1-181: Loss: 0.1009 Acc: 100.0000%\n",
      "\ttrain 1-182: Loss: 0.2012 Acc: 50.0000%\n",
      "\ttrain 1-183: Loss: 0.3188 Acc: 25.0000%\n",
      "\ttrain 1-184: Loss: 0.1676 Acc: 50.0000%\n",
      "\ttrain 1-185: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 1-186: Loss: 0.2204 Acc: 75.0000%\n",
      "\ttrain 1-187: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 1-188: Loss: 0.2805 Acc: 50.0000%\n",
      "\ttrain 1-189: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 1-190: Loss: 0.0829 Acc: 100.0000%\n",
      "\ttrain 1-191: Loss: 0.3302 Acc: 50.0000%\n",
      "\ttrain 1-192: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 1-193: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 1-194: Loss: 0.2854 Acc: 25.0000%\n",
      "\ttrain 1-195: Loss: 0.2027 Acc: 50.0000%\n",
      "\ttrain 1-196: Loss: 0.1337 Acc: 100.0000%\n",
      "\ttrain 1-197: Loss: 0.3731 Acc: 25.0000%\n",
      "\ttrain 1-198: Loss: 0.2560 Acc: 50.0000%\n",
      "\ttrain 1-199: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 1-200: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 1-201: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 1-202: Loss: 0.1698 Acc: 75.0000%\n",
      "\ttrain 1-203: Loss: 0.3326 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-204: Loss: 0.2539 Acc: 50.0000%\n",
      "\ttrain 1-205: Loss: 0.4606 Acc: 0.0000%\n",
      "\ttrain 1-206: Loss: 0.2918 Acc: 50.0000%\n",
      "\ttrain 1-207: Loss: 0.1399 Acc: 100.0000%\n",
      "\ttrain 1-208: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 1-209: Loss: 0.1239 Acc: 100.0000%\n",
      "\ttrain 1-210: Loss: 0.2970 Acc: 75.0000%\n",
      "\ttrain 1-211: Loss: 0.1102 Acc: 100.0000%\n",
      "\ttrain 1-212: Loss: 0.2353 Acc: 50.0000%\n",
      "\ttrain 1-213: Loss: 0.2355 Acc: 75.0000%\n",
      "\ttrain 1-214: Loss: 0.1951 Acc: 50.0000%\n",
      "\ttrain 1-215: Loss: 0.3053 Acc: 50.0000%\n",
      "\ttrain 1-216: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 1-217: Loss: 0.1800 Acc: 50.0000%\n",
      "\ttrain 1-218: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 1-219: Loss: 0.2990 Acc: 25.0000%\n",
      "\ttrain 1-220: Loss: 0.1341 Acc: 100.0000%\n",
      "\ttrain 1-221: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 1-222: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 1-223: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 1-224: Loss: 0.2524 Acc: 50.0000%\n",
      "\ttrain 1-225: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 1-226: Loss: 0.2016 Acc: 75.0000%\n",
      "\ttrain 1-227: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 1-228: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain 1-229: Loss: 0.1280 Acc: 100.0000%\n",
      "\ttrain 1-230: Loss: 0.1331 Acc: 100.0000%\n",
      "\ttrain 1-231: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 1-232: Loss: 0.1771 Acc: 50.0000%\n",
      "\ttrain 1-233: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 1-234: Loss: 0.2565 Acc: 25.0000%\n",
      "\ttrain 1-235: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 1-236: Loss: 0.1263 Acc: 100.0000%\n",
      "\ttrain 1-237: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 1-238: Loss: 0.1664 Acc: 75.0000%\n",
      "\ttrain 1-239: Loss: 0.3591 Acc: 50.0000%\n",
      "\ttrain 1-240: Loss: 0.2589 Acc: 50.0000%\n",
      "\ttrain 1-241: Loss: 0.4271 Acc: 50.0000%\n",
      "\ttrain 1-242: Loss: 0.3668 Acc: 50.0000%\n",
      "\ttrain 1-243: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 1-244: Loss: 0.2923 Acc: 50.0000%\n",
      "\ttrain 1-245: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 1-1: Loss: 0.0490 Acc: 100.0000%\n",
      "\tvalidation 1-2: Loss: 0.1518 Acc: 75.0000%\n",
      "\tvalidation 1-3: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 1-4: Loss: 0.0334 Acc: 100.0000%\n",
      "\tvalidation 1-5: Loss: 0.1025 Acc: 100.0000%\n",
      "\tvalidation 1-6: Loss: 0.1009 Acc: 100.0000%\n",
      "\tvalidation 1-7: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 1-8: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 1-9: Loss: 0.0824 Acc: 100.0000%\n",
      "\tvalidation 1-10: Loss: 0.0538 Acc: 100.0000%\n",
      "\tvalidation 1-11: Loss: 0.0566 Acc: 100.0000%\n",
      "\tvalidation 1-12: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 1-13: Loss: 0.1176 Acc: 75.0000%\n",
      "\tvalidation 1-14: Loss: 0.0484 Acc: 100.0000%\n",
      "\tvalidation 1-15: Loss: 0.1193 Acc: 100.0000%\n",
      "\tvalidation 1-16: Loss: 0.0820 Acc: 100.0000%\n",
      "\tvalidation 1-17: Loss: 0.0871 Acc: 100.0000%\n",
      "\tvalidation 1-18: Loss: 0.1769 Acc: 50.0000%\n",
      "\tvalidation 1-19: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 1-20: Loss: 0.1021 Acc: 75.0000%\n",
      "\tvalidation 1-21: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 1-22: Loss: 0.0947 Acc: 100.0000%\n",
      "\tvalidation 1-23: Loss: 0.0811 Acc: 100.0000%\n",
      "\tvalidation 1-24: Loss: 0.0476 Acc: 100.0000%\n",
      "\tvalidation 1-25: Loss: 0.0695 Acc: 100.0000%\n",
      "\tvalidation 1-26: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 1-27: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 1-28: Loss: 0.0746 Acc: 100.0000%\n",
      "\tvalidation 1-29: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 1-30: Loss: 0.1348 Acc: 75.0000%\n",
      "\tvalidation 1-31: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 1-32: Loss: 0.1018 Acc: 100.0000%\n",
      "\tvalidation 1-33: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 1-34: Loss: 0.0802 Acc: 100.0000%\n",
      "\tvalidation 1-35: Loss: 0.0805 Acc: 100.0000%\n",
      "\tvalidation 1-36: Loss: 0.0693 Acc: 100.0000%\n",
      "\tvalidation 1-37: Loss: 0.1071 Acc: 100.0000%\n",
      "\tvalidation 1-38: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 1-39: Loss: 0.0685 Acc: 100.0000%\n",
      "\tvalidation 1-40: Loss: 0.0367 Acc: 100.0000%\n",
      "\tvalidation 1-41: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 1-42: Loss: 0.1128 Acc: 100.0000%\n",
      "\tvalidation 1-43: Loss: 0.0747 Acc: 100.0000%\n",
      "\tvalidation 1-44: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 1-45: Loss: 0.0662 Acc: 100.0000%\n",
      "\tvalidation 1-46: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 1-47: Loss: 0.0758 Acc: 100.0000%\n",
      "\tvalidation 1-48: Loss: 0.1951 Acc: 75.0000%\n",
      "\tvalidation 1-49: Loss: 0.0884 Acc: 100.0000%\n",
      "\tvalidation 1-50: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 1-51: Loss: 0.0935 Acc: 100.0000%\n",
      "\tvalidation 1-52: Loss: 0.0899 Acc: 100.0000%\n",
      "\tvalidation 1-53: Loss: 0.0590 Acc: 100.0000%\n",
      "\tvalidation 1-54: Loss: 0.0574 Acc: 100.0000%\n",
      "\tvalidation 1-55: Loss: 0.0671 Acc: 100.0000%\n",
      "\tvalidation 1-56: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 1-57: Loss: 0.1099 Acc: 100.0000%\n",
      "\tvalidation 1-58: Loss: 0.0757 Acc: 100.0000%\n",
      "\tvalidation 1-59: Loss: 0.0667 Acc: 100.0000%\n",
      "\tvalidation 1-60: Loss: 0.1397 Acc: 75.0000%\n",
      "\tvalidation 1-61: Loss: 0.0663 Acc: 100.0000%\n",
      "\tvalidation 1-62: Loss: 0.0715 Acc: 75.0000%\n",
      "\tvalidation 1-63: Loss: 0.0916 Acc: 100.0000%\n",
      "\tvalidation 1-64: Loss: 0.0470 Acc: 100.0000%\n",
      "\tvalidation 1-65: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 1-66: Loss: 0.1037 Acc: 100.0000%\n",
      "\tvalidation 1-67: Loss: 0.0477 Acc: 100.0000%\n",
      "\tvalidation 1-68: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 1-69: Loss: 0.0930 Acc: 100.0000%\n",
      "\tvalidation 1-70: Loss: 0.0890 Acc: 100.0000%\n",
      "\tvalidation 1-71: Loss: 0.0555 Acc: 100.0000%\n",
      "\tvalidation 1-72: Loss: 0.0784 Acc: 100.0000%\n",
      "\tvalidation 1-73: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 1-74: Loss: 0.1490 Acc: 75.0000%\n",
      "\tvalidation 1-75: Loss: 0.1110 Acc: 100.0000%\n",
      "\tvalidation 1-76: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-77: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 1-78: Loss: 0.0827 Acc: 100.0000%\n",
      "\tvalidation 1-79: Loss: 0.1312 Acc: 100.0000%\n",
      "\tvalidation 1-80: Loss: 0.0999 Acc: 100.0000%\n",
      "\tvalidation 1-81: Loss: 0.0943 Acc: 100.0000%\n",
      "\tvalidation 1-82: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 1-83: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 1-84: Loss: 0.0491 Acc: 100.0000%\n",
      "\tvalidation 1-85: Loss: 0.0720 Acc: 100.0000%\n",
      "\tvalidation 1-86: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 1-87: Loss: 0.0923 Acc: 100.0000%\n",
      "\tvalidation 1-88: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 1-89: Loss: 0.0570 Acc: 100.0000%\n",
      "\tvalidation 1-90: Loss: 0.0612 Acc: 100.0000%\n",
      "\tvalidation 1-91: Loss: 0.1130 Acc: 75.0000%\n",
      "\tvalidation 1-92: Loss: 0.1495 Acc: 100.0000%\n",
      "\tvalidation 1-93: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 1-94: Loss: 0.0456 Acc: 100.0000%\n",
      "\tvalidation 1-95: Loss: 0.0607 Acc: 100.0000%\n",
      "\tvalidation 1-96: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 1-97: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 1-98: Loss: 0.0861 Acc: 100.0000%\n",
      "\tvalidation 1-99: Loss: 0.0687 Acc: 100.0000%\n",
      "\tvalidation 1-100: Loss: 0.1068 Acc: 100.0000%\n",
      "\tvalidation 1-101: Loss: 0.0486 Acc: 100.0000%\n",
      "\tvalidation 1-102: Loss: 0.1613 Acc: 75.0000%\n",
      "\tvalidation 1-103: Loss: 0.1479 Acc: 75.0000%\n",
      "\tvalidation 1-104: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 1-105: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2498 Acc: 55.6122%\n",
      "\tvalidation Loss: 0.0717 Acc: 96.6667%\n",
      "网络参数更新\n",
      "Time passed 0h 0m 33s\n",
      "--------------------\n",
      "Epoch [2/40]:\n",
      "\ttrain 2-1: Loss: 0.2431 Acc: 50.0000%\n",
      "\ttrain 2-2: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 2-3: Loss: 0.0952 Acc: 100.0000%\n",
      "\ttrain 2-4: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 2-5: Loss: 0.0827 Acc: 100.0000%\n",
      "\ttrain 2-6: Loss: 0.1752 Acc: 50.0000%\n",
      "\ttrain 2-7: Loss: 0.1604 Acc: 50.0000%\n",
      "\ttrain 2-8: Loss: 0.1998 Acc: 50.0000%\n",
      "\ttrain 2-9: Loss: 0.3422 Acc: 50.0000%\n",
      "\ttrain 2-10: Loss: 0.2546 Acc: 50.0000%\n",
      "\ttrain 2-11: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 2-12: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 2-13: Loss: 0.1440 Acc: 50.0000%\n",
      "\ttrain 2-14: Loss: 0.3250 Acc: 25.0000%\n",
      "\ttrain 2-15: Loss: 0.1810 Acc: 75.0000%\n",
      "\ttrain 2-16: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 2-17: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain 2-18: Loss: 0.2926 Acc: 25.0000%\n",
      "\ttrain 2-19: Loss: 0.1552 Acc: 75.0000%\n",
      "\ttrain 2-20: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 2-21: Loss: 0.1396 Acc: 75.0000%\n",
      "\ttrain 2-22: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 2-23: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 2-24: Loss: 0.0677 Acc: 100.0000%\n",
      "\ttrain 2-25: Loss: 0.1888 Acc: 50.0000%\n",
      "\ttrain 2-26: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 2-27: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 2-28: Loss: 0.2382 Acc: 50.0000%\n",
      "\ttrain 2-29: Loss: 0.1853 Acc: 75.0000%\n",
      "\ttrain 2-30: Loss: 0.1881 Acc: 75.0000%\n",
      "\ttrain 2-31: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 2-32: Loss: 0.2861 Acc: 50.0000%\n",
      "\ttrain 2-33: Loss: 0.5051 Acc: 25.0000%\n",
      "\ttrain 2-34: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 2-35: Loss: 0.2736 Acc: 50.0000%\n",
      "\ttrain 2-36: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 2-37: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 2-38: Loss: 0.0383 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-39: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 2-40: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 2-41: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 2-42: Loss: 0.1768 Acc: 75.0000%\n",
      "\ttrain 2-43: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 2-44: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 2-45: Loss: 0.1319 Acc: 100.0000%\n",
      "\ttrain 2-46: Loss: 0.2351 Acc: 75.0000%\n",
      "\ttrain 2-47: Loss: 0.1117 Acc: 100.0000%\n",
      "\ttrain 2-48: Loss: 0.3550 Acc: 25.0000%\n",
      "\ttrain 2-49: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 2-50: Loss: 0.1044 Acc: 100.0000%\n",
      "\ttrain 2-51: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 2-52: Loss: 0.0971 Acc: 100.0000%\n",
      "\ttrain 2-53: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 2-54: Loss: 0.2912 Acc: 50.0000%\n",
      "\ttrain 2-55: Loss: 0.1213 Acc: 100.0000%\n",
      "\ttrain 2-56: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 2-57: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 2-58: Loss: 0.1678 Acc: 75.0000%\n",
      "\ttrain 2-59: Loss: 0.1035 Acc: 100.0000%\n",
      "\ttrain 2-60: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 2-61: Loss: 0.2229 Acc: 50.0000%\n",
      "\ttrain 2-62: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 2-63: Loss: 0.1042 Acc: 100.0000%\n",
      "\ttrain 2-64: Loss: 0.2438 Acc: 50.0000%\n",
      "\ttrain 2-65: Loss: 0.1573 Acc: 75.0000%\n",
      "\ttrain 2-66: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 2-67: Loss: 0.0805 Acc: 100.0000%\n",
      "\ttrain 2-68: Loss: 0.5482 Acc: 25.0000%\n",
      "\ttrain 2-69: Loss: 0.1927 Acc: 50.0000%\n",
      "\ttrain 2-70: Loss: 0.2215 Acc: 50.0000%\n",
      "\ttrain 2-71: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 2-72: Loss: 0.3278 Acc: 25.0000%\n",
      "\ttrain 2-73: Loss: 0.1202 Acc: 100.0000%\n",
      "\ttrain 2-74: Loss: 0.1616 Acc: 50.0000%\n",
      "\ttrain 2-75: Loss: 0.1872 Acc: 25.0000%\n",
      "\ttrain 2-76: Loss: 0.1336 Acc: 100.0000%\n",
      "\ttrain 2-77: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 2-78: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 2-79: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 2-80: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 2-81: Loss: 0.2380 Acc: 50.0000%\n",
      "\ttrain 2-82: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 2-83: Loss: 0.1681 Acc: 75.0000%\n",
      "\ttrain 2-84: Loss: 0.5295 Acc: 0.0000%\n",
      "\ttrain 2-85: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 2-86: Loss: 0.1846 Acc: 75.0000%\n",
      "\ttrain 2-87: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 2-88: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 2-89: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 2-90: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 2-91: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 2-92: Loss: 0.1815 Acc: 50.0000%\n",
      "\ttrain 2-93: Loss: 0.2275 Acc: 50.0000%\n",
      "\ttrain 2-94: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 2-95: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 2-96: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 2-97: Loss: 0.1310 Acc: 100.0000%\n",
      "\ttrain 2-98: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 2-99: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 2-100: Loss: 0.1319 Acc: 100.0000%\n",
      "\ttrain 2-101: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 2-102: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 2-103: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 2-104: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 2-105: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 2-106: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 2-107: Loss: 0.1400 Acc: 50.0000%\n",
      "\ttrain 2-108: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 2-109: Loss: 0.1679 Acc: 75.0000%\n",
      "\ttrain 2-110: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 2-111: Loss: 0.1163 Acc: 100.0000%\n",
      "\ttrain 2-112: Loss: 0.1998 Acc: 50.0000%\n",
      "\ttrain 2-113: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 2-114: Loss: 0.2317 Acc: 75.0000%\n",
      "\ttrain 2-115: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 2-116: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 2-117: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 2-118: Loss: 0.0819 Acc: 100.0000%\n",
      "\ttrain 2-119: Loss: 0.2492 Acc: 50.0000%\n",
      "\ttrain 2-120: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 2-121: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 2-122: Loss: 0.4568 Acc: 75.0000%\n",
      "\ttrain 2-123: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 2-124: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 2-125: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 2-126: Loss: 0.1007 Acc: 100.0000%\n",
      "\ttrain 2-127: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 2-128: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 2-129: Loss: 0.1242 Acc: 50.0000%\n",
      "\ttrain 2-130: Loss: 0.1971 Acc: 75.0000%\n",
      "\ttrain 2-131: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 2-132: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 2-133: Loss: 0.1229 Acc: 100.0000%\n",
      "\ttrain 2-134: Loss: 0.2481 Acc: 25.0000%\n",
      "\ttrain 2-135: Loss: 0.1630 Acc: 75.0000%\n",
      "\ttrain 2-136: Loss: 0.3555 Acc: 50.0000%\n",
      "\ttrain 2-137: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 2-138: Loss: 0.3623 Acc: 25.0000%\n",
      "\ttrain 2-139: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 2-140: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 2-141: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 2-142: Loss: 0.3747 Acc: 75.0000%\n",
      "\ttrain 2-143: Loss: 0.2459 Acc: 50.0000%\n",
      "\ttrain 2-144: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 2-145: Loss: 0.0885 Acc: 100.0000%\n",
      "\ttrain 2-146: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 2-147: Loss: 0.3193 Acc: 50.0000%\n",
      "\ttrain 2-148: Loss: 0.5103 Acc: 0.0000%\n",
      "\ttrain 2-149: Loss: 0.2360 Acc: 75.0000%\n",
      "\ttrain 2-150: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 2-151: Loss: 0.1662 Acc: 50.0000%\n",
      "\ttrain 2-152: Loss: 0.2989 Acc: 50.0000%\n",
      "\ttrain 2-153: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 2-154: Loss: 0.1485 Acc: 75.0000%\n",
      "\ttrain 2-155: Loss: 0.3059 Acc: 25.0000%\n",
      "\ttrain 2-156: Loss: 0.5504 Acc: 25.0000%\n",
      "\ttrain 2-157: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 2-158: Loss: 0.2333 Acc: 75.0000%\n",
      "\ttrain 2-159: Loss: 0.0902 Acc: 100.0000%\n",
      "\ttrain 2-160: Loss: 0.1367 Acc: 100.0000%\n",
      "\ttrain 2-161: Loss: 0.1988 Acc: 75.0000%\n",
      "\ttrain 2-162: Loss: 0.3478 Acc: 50.0000%\n",
      "\ttrain 2-163: Loss: 0.2247 Acc: 50.0000%\n",
      "\ttrain 2-164: Loss: 0.7274 Acc: 0.0000%\n",
      "\ttrain 2-165: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 2-166: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 2-167: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 2-168: Loss: 0.3249 Acc: 25.0000%\n",
      "\ttrain 2-169: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 2-170: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 2-171: Loss: 0.2499 Acc: 50.0000%\n",
      "\ttrain 2-172: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 2-173: Loss: 0.0834 Acc: 100.0000%\n",
      "\ttrain 2-174: Loss: 0.2968 Acc: 50.0000%\n",
      "\ttrain 2-175: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 2-176: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 2-177: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 2-178: Loss: 0.1812 Acc: 50.0000%\n",
      "\ttrain 2-179: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 2-180: Loss: 0.2012 Acc: 50.0000%\n",
      "\ttrain 2-181: Loss: 0.2722 Acc: 50.0000%\n",
      "\ttrain 2-182: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 2-183: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 2-184: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 2-185: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 2-186: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 2-187: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 2-188: Loss: 0.0905 Acc: 100.0000%\n",
      "\ttrain 2-189: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 2-190: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 2-191: Loss: 0.0716 Acc: 100.0000%\n",
      "\ttrain 2-192: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 2-193: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 2-194: Loss: 0.2418 Acc: 75.0000%\n",
      "\ttrain 2-195: Loss: 0.1752 Acc: 50.0000%\n",
      "\ttrain 2-196: Loss: 0.1528 Acc: 75.0000%\n",
      "\ttrain 2-197: Loss: 0.1740 Acc: 75.0000%\n",
      "\ttrain 2-198: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 2-199: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 2-200: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 2-201: Loss: 0.2700 Acc: 75.0000%\n",
      "\ttrain 2-202: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 2-203: Loss: 0.1983 Acc: 25.0000%\n",
      "\ttrain 2-204: Loss: 0.1779 Acc: 75.0000%\n",
      "\ttrain 2-205: Loss: 0.0790 Acc: 100.0000%\n",
      "\ttrain 2-206: Loss: 0.0841 Acc: 100.0000%\n",
      "\ttrain 2-207: Loss: 0.1778 Acc: 75.0000%\n",
      "\ttrain 2-208: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 2-209: Loss: 0.0746 Acc: 75.0000%\n",
      "\ttrain 2-210: Loss: 0.1766 Acc: 50.0000%\n",
      "\ttrain 2-211: Loss: 0.0974 Acc: 100.0000%\n",
      "\ttrain 2-212: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 2-213: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 2-214: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 2-215: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 2-216: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 2-217: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 2-218: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 2-219: Loss: 0.2032 Acc: 75.0000%\n",
      "\ttrain 2-220: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 2-221: Loss: 0.2094 Acc: 50.0000%\n",
      "\ttrain 2-222: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 2-223: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 2-224: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 2-225: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 2-226: Loss: 0.0673 Acc: 100.0000%\n",
      "\ttrain 2-227: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 2-228: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 2-229: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 2-230: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 2-231: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 2-232: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 2-233: Loss: 0.0974 Acc: 100.0000%\n",
      "\ttrain 2-234: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 2-235: Loss: 0.1535 Acc: 75.0000%\n",
      "\ttrain 2-236: Loss: 0.0673 Acc: 100.0000%\n",
      "\ttrain 2-237: Loss: 0.1769 Acc: 50.0000%\n",
      "\ttrain 2-238: Loss: 0.5888 Acc: 0.0000%\n",
      "\ttrain 2-239: Loss: 0.1160 Acc: 50.0000%\n",
      "\ttrain 2-240: Loss: 0.0627 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-241: Loss: 0.0816 Acc: 100.0000%\n",
      "\ttrain 2-242: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 2-243: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 2-244: Loss: 0.4029 Acc: 50.0000%\n",
      "\ttrain 2-245: Loss: 0.3761 Acc: 25.0000%\n",
      "\tvalidation 2-1: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 2-2: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 2-3: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 2-4: Loss: 0.1077 Acc: 75.0000%\n",
      "\tvalidation 2-5: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 2-6: Loss: 0.1120 Acc: 75.0000%\n",
      "\tvalidation 2-7: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 2-8: Loss: 0.0334 Acc: 100.0000%\n",
      "\tvalidation 2-9: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 2-10: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 2-11: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 2-12: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 2-13: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 2-14: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 2-15: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 2-16: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 2-17: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 2-18: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 2-19: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 2-20: Loss: 0.0752 Acc: 100.0000%\n",
      "\tvalidation 2-21: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 2-22: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 2-23: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 2-24: Loss: 0.0512 Acc: 100.0000%\n",
      "\tvalidation 2-25: Loss: 0.0570 Acc: 100.0000%\n",
      "\tvalidation 2-26: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 2-27: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 2-28: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-29: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 2-30: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 2-31: Loss: 0.0584 Acc: 100.0000%\n",
      "\tvalidation 2-32: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 2-33: Loss: 0.0474 Acc: 75.0000%\n",
      "\tvalidation 2-34: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-35: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 2-36: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 2-37: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 2-38: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 2-39: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 2-40: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 2-41: Loss: 0.0868 Acc: 75.0000%\n",
      "\tvalidation 2-42: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 2-43: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 2-44: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 2-45: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 2-46: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 2-47: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 2-48: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 2-49: Loss: 0.0578 Acc: 100.0000%\n",
      "\tvalidation 2-50: Loss: 0.0538 Acc: 100.0000%\n",
      "\tvalidation 2-51: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 2-52: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 2-53: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 2-54: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 2-55: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 2-56: Loss: 0.0473 Acc: 100.0000%\n",
      "\tvalidation 2-57: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 2-58: Loss: 0.0727 Acc: 100.0000%\n",
      "\tvalidation 2-59: Loss: 0.0937 Acc: 100.0000%\n",
      "\tvalidation 2-60: Loss: 0.0795 Acc: 100.0000%\n",
      "\tvalidation 2-61: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 2-62: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-63: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 2-64: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 2-65: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 2-66: Loss: 0.0497 Acc: 100.0000%\n",
      "\tvalidation 2-67: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-68: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 2-69: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 2-70: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 2-71: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 2-72: Loss: 0.0568 Acc: 100.0000%\n",
      "\tvalidation 2-73: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 2-74: Loss: 0.0405 Acc: 100.0000%\n",
      "\tvalidation 2-75: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 2-76: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 2-77: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 2-78: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 2-79: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 2-80: Loss: 0.0778 Acc: 100.0000%\n",
      "\tvalidation 2-81: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 2-82: Loss: 0.0500 Acc: 100.0000%\n",
      "\tvalidation 2-83: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 2-84: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 2-85: Loss: 0.0668 Acc: 100.0000%\n",
      "\tvalidation 2-86: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 2-87: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 2-88: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 2-89: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 2-90: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 2-91: Loss: 0.0608 Acc: 100.0000%\n",
      "\tvalidation 2-92: Loss: 0.0462 Acc: 100.0000%\n",
      "\tvalidation 2-93: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 2-94: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 2-95: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 2-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-97: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 2-98: Loss: 0.0686 Acc: 100.0000%\n",
      "\tvalidation 2-99: Loss: 0.0629 Acc: 100.0000%\n",
      "\tvalidation 2-100: Loss: 0.0912 Acc: 75.0000%\n",
      "\tvalidation 2-101: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 2-102: Loss: 0.0717 Acc: 100.0000%\n",
      "\tvalidation 2-103: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 2-104: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 2-105: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1544 Acc: 74.8980%\n",
      "\tvalidation Loss: 0.0308 Acc: 98.8095%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 5s\n",
      "--------------------\n",
      "Epoch [3/40]:\n",
      "\ttrain 3-1: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 3-2: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 3-3: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 3-4: Loss: 0.1627 Acc: 75.0000%\n",
      "\ttrain 3-5: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 3-6: Loss: 0.2466 Acc: 50.0000%\n",
      "\ttrain 3-7: Loss: 0.2344 Acc: 75.0000%\n",
      "\ttrain 3-8: Loss: 0.1098 Acc: 100.0000%\n",
      "\ttrain 3-9: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 3-10: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 3-11: Loss: 0.2650 Acc: 50.0000%\n",
      "\ttrain 3-12: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 3-13: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 3-14: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 3-15: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 3-16: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 3-17: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 3-18: Loss: 0.1923 Acc: 75.0000%\n",
      "\ttrain 3-19: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 3-20: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 3-21: Loss: 0.2003 Acc: 50.0000%\n",
      "\ttrain 3-22: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 3-23: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 3-24: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 3-25: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 3-26: Loss: 0.5044 Acc: 0.0000%\n",
      "\ttrain 3-27: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 3-28: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 3-29: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 3-30: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 3-31: Loss: 0.3942 Acc: 25.0000%\n",
      "\ttrain 3-32: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 3-33: Loss: 0.2119 Acc: 50.0000%\n",
      "\ttrain 3-34: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 3-35: Loss: 0.1033 Acc: 100.0000%\n",
      "\ttrain 3-36: Loss: 0.2955 Acc: 50.0000%\n",
      "\ttrain 3-37: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 3-38: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 3-39: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 3-40: Loss: 0.0709 Acc: 100.0000%\n",
      "\ttrain 3-41: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 3-42: Loss: 0.3470 Acc: 50.0000%\n",
      "\ttrain 3-43: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 3-44: Loss: 0.3745 Acc: 50.0000%\n",
      "\ttrain 3-45: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 3-46: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 3-47: Loss: 0.1069 Acc: 100.0000%\n",
      "\ttrain 3-48: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 3-49: Loss: 0.1350 Acc: 75.0000%\n",
      "\ttrain 3-50: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 3-51: Loss: 0.1967 Acc: 75.0000%\n",
      "\ttrain 3-52: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 3-53: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 3-54: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 3-55: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 3-56: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 3-57: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 3-58: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 3-59: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 3-60: Loss: 0.1579 Acc: 75.0000%\n",
      "\ttrain 3-61: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 3-62: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 3-63: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 3-64: Loss: 0.3710 Acc: 50.0000%\n",
      "\ttrain 3-65: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 3-66: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 3-67: Loss: 0.5320 Acc: 25.0000%\n",
      "\ttrain 3-68: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 3-69: Loss: 0.0932 Acc: 100.0000%\n",
      "\ttrain 3-70: Loss: 0.1578 Acc: 50.0000%\n",
      "\ttrain 3-71: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 3-72: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 3-73: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 3-74: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 3-75: Loss: 0.1092 Acc: 100.0000%\n",
      "\ttrain 3-76: Loss: 0.2225 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-77: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 3-78: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 3-79: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 3-80: Loss: 0.2450 Acc: 50.0000%\n",
      "\ttrain 3-81: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 3-82: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 3-83: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 3-84: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 3-85: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 3-86: Loss: 0.1011 Acc: 100.0000%\n",
      "\ttrain 3-87: Loss: 0.2588 Acc: 50.0000%\n",
      "\ttrain 3-88: Loss: 0.0904 Acc: 100.0000%\n",
      "\ttrain 3-89: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 3-90: Loss: 0.3543 Acc: 25.0000%\n",
      "\ttrain 3-91: Loss: 0.3848 Acc: 0.0000%\n",
      "\ttrain 3-92: Loss: 0.2029 Acc: 75.0000%\n",
      "\ttrain 3-93: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain 3-94: Loss: 0.2527 Acc: 50.0000%\n",
      "\ttrain 3-95: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 3-96: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 3-97: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 3-98: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 3-99: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 3-100: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 3-101: Loss: 0.2362 Acc: 50.0000%\n",
      "\ttrain 3-102: Loss: 0.1351 Acc: 50.0000%\n",
      "\ttrain 3-103: Loss: 0.6543 Acc: 0.0000%\n",
      "\ttrain 3-104: Loss: 0.1434 Acc: 50.0000%\n",
      "\ttrain 3-105: Loss: 0.1941 Acc: 75.0000%\n",
      "\ttrain 3-106: Loss: 0.3083 Acc: 50.0000%\n",
      "\ttrain 3-107: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 3-108: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 3-109: Loss: 0.1029 Acc: 100.0000%\n",
      "\ttrain 3-110: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 3-111: Loss: 0.1085 Acc: 100.0000%\n",
      "\ttrain 3-112: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 3-113: Loss: 0.4216 Acc: 50.0000%\n",
      "\ttrain 3-114: Loss: 0.1512 Acc: 50.0000%\n",
      "\ttrain 3-115: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 3-116: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 3-117: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 3-118: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 3-119: Loss: 0.1661 Acc: 75.0000%\n",
      "\ttrain 3-120: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 3-121: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 3-122: Loss: 0.2190 Acc: 25.0000%\n",
      "\ttrain 3-123: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 3-124: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 3-125: Loss: 0.1822 Acc: 50.0000%\n",
      "\ttrain 3-126: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 3-127: Loss: 0.1899 Acc: 75.0000%\n",
      "\ttrain 3-128: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 3-129: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 3-130: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 3-131: Loss: 0.3741 Acc: 25.0000%\n",
      "\ttrain 3-132: Loss: 0.0994 Acc: 100.0000%\n",
      "\ttrain 3-133: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 3-134: Loss: 0.0699 Acc: 100.0000%\n",
      "\ttrain 3-135: Loss: 0.1977 Acc: 75.0000%\n",
      "\ttrain 3-136: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 3-137: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 3-138: Loss: 0.3312 Acc: 50.0000%\n",
      "\ttrain 3-139: Loss: 0.1331 Acc: 75.0000%\n",
      "\ttrain 3-140: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 3-141: Loss: 0.0889 Acc: 100.0000%\n",
      "\ttrain 3-142: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 3-143: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 3-144: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 3-145: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 3-146: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 3-147: Loss: 0.5035 Acc: 50.0000%\n",
      "\ttrain 3-148: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 3-149: Loss: 0.0579 Acc: 75.0000%\n",
      "\ttrain 3-150: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 3-151: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 3-152: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 3-153: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 3-154: Loss: 0.2295 Acc: 50.0000%\n",
      "\ttrain 3-155: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 3-156: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 3-157: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 3-158: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 3-159: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 3-160: Loss: 0.0761 Acc: 100.0000%\n",
      "\ttrain 3-161: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 3-162: Loss: 0.1626 Acc: 50.0000%\n",
      "\ttrain 3-163: Loss: 0.2170 Acc: 50.0000%\n",
      "\ttrain 3-164: Loss: 0.1536 Acc: 75.0000%\n",
      "\ttrain 3-165: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 3-166: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 3-167: Loss: 0.1186 Acc: 75.0000%\n",
      "\ttrain 3-168: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 3-169: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 3-170: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 3-171: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 3-172: Loss: 0.2658 Acc: 50.0000%\n",
      "\ttrain 3-173: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 3-174: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 3-175: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 3-176: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 3-177: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 3-178: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 3-179: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 3-180: Loss: 0.6001 Acc: 0.0000%\n",
      "\ttrain 3-181: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 3-182: Loss: 0.0912 Acc: 100.0000%\n",
      "\ttrain 3-183: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 3-184: Loss: 0.1934 Acc: 75.0000%\n",
      "\ttrain 3-185: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 3-186: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 3-187: Loss: 0.2246 Acc: 75.0000%\n",
      "\ttrain 3-188: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 3-189: Loss: 0.7026 Acc: 25.0000%\n",
      "\ttrain 3-190: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 3-191: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 3-192: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 3-193: Loss: 0.1845 Acc: 50.0000%\n",
      "\ttrain 3-194: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 3-195: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 3-196: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 3-197: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 3-198: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 3-199: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 3-200: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 3-201: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 3-202: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 3-203: Loss: 0.0613 Acc: 100.0000%\n",
      "\ttrain 3-204: Loss: 0.2099 Acc: 50.0000%\n",
      "\ttrain 3-205: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 3-206: Loss: 0.7160 Acc: 0.0000%\n",
      "\ttrain 3-207: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 3-208: Loss: 0.2558 Acc: 50.0000%\n",
      "\ttrain 3-209: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 3-210: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 3-211: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 3-212: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 3-213: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 3-214: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 3-215: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 3-216: Loss: 0.1718 Acc: 75.0000%\n",
      "\ttrain 3-217: Loss: 0.1952 Acc: 50.0000%\n",
      "\ttrain 3-218: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 3-219: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 3-220: Loss: 0.2188 Acc: 50.0000%\n",
      "\ttrain 3-221: Loss: 0.1913 Acc: 50.0000%\n",
      "\ttrain 3-222: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 3-223: Loss: 0.2099 Acc: 50.0000%\n",
      "\ttrain 3-224: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 3-225: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 3-226: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 3-227: Loss: 0.1550 Acc: 75.0000%\n",
      "\ttrain 3-228: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 3-229: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 3-230: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 3-231: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 3-232: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 3-233: Loss: 0.1690 Acc: 75.0000%\n",
      "\ttrain 3-234: Loss: 0.3407 Acc: 50.0000%\n",
      "\ttrain 3-235: Loss: 0.1059 Acc: 100.0000%\n",
      "\ttrain 3-236: Loss: 0.1926 Acc: 75.0000%\n",
      "\ttrain 3-237: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 3-238: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 3-239: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 3-240: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 3-241: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 3-242: Loss: 0.3727 Acc: 50.0000%\n",
      "\ttrain 3-243: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 3-244: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 3-245: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 3-1: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 3-2: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 3-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 3-4: Loss: 0.0446 Acc: 100.0000%\n",
      "\tvalidation 3-5: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 3-6: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 3-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-8: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 3-9: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 3-10: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 3-11: Loss: 0.0517 Acc: 100.0000%\n",
      "\tvalidation 3-12: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 3-13: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 3-14: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 3-15: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 3-16: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 3-17: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 3-18: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 3-19: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 3-20: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 3-21: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-23: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 3-24: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 3-25: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 3-26: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 3-27: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 3-28: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 3-29: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 3-30: Loss: 0.0011 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-31: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 3-32: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 3-33: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 3-34: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 3-35: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 3-36: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 3-37: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 3-38: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 3-39: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 3-40: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 3-41: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 3-42: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 3-43: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 3-44: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 3-45: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 3-46: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 3-47: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 3-48: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 3-49: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 3-50: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 3-51: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 3-52: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 3-53: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 3-54: Loss: 0.0862 Acc: 75.0000%\n",
      "\tvalidation 3-55: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 3-56: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 3-57: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-58: Loss: 0.0350 Acc: 100.0000%\n",
      "\tvalidation 3-59: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 3-60: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 3-61: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 3-62: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 3-63: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 3-64: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 3-65: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 3-66: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 3-67: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 3-68: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 3-69: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 3-70: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 3-71: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 3-72: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 3-73: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 3-74: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 3-75: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 3-76: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 3-77: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 3-78: Loss: 0.0539 Acc: 75.0000%\n",
      "\tvalidation 3-79: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 3-80: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 3-81: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 3-82: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 3-83: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 3-84: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 3-85: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 3-86: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 3-87: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 3-88: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 3-89: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 3-90: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 3-91: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 3-92: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 3-93: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 3-94: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 3-95: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 3-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-97: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 3-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-99: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 3-100: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 3-101: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 3-102: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 3-103: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 3-104: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 3-105: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1241 Acc: 80.9184%\n",
      "\tvalidation Loss: 0.0106 Acc: 99.5238%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 38s\n",
      "--------------------\n",
      "Epoch [4/40]:\n",
      "\ttrain 4-1: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 4-2: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 4-3: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 4-4: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 4-5: Loss: 0.1739 Acc: 75.0000%\n",
      "\ttrain 4-6: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 4-7: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 4-8: Loss: 0.2582 Acc: 50.0000%\n",
      "\ttrain 4-9: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 4-10: Loss: 0.1234 Acc: 50.0000%\n",
      "\ttrain 4-11: Loss: 0.2675 Acc: 50.0000%\n",
      "\ttrain 4-12: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 4-13: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 4-14: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 4-15: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 4-16: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 4-17: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 4-18: Loss: 0.0789 Acc: 100.0000%\n",
      "\ttrain 4-19: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 4-20: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 4-21: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 4-22: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 4-23: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 4-24: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 4-25: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 4-26: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 4-27: Loss: 0.3295 Acc: 50.0000%\n",
      "\ttrain 4-28: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 4-29: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 4-30: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 4-31: Loss: 0.1809 Acc: 75.0000%\n",
      "\ttrain 4-32: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 4-33: Loss: 0.2228 Acc: 75.0000%\n",
      "\ttrain 4-34: Loss: 0.2409 Acc: 75.0000%\n",
      "\ttrain 4-35: Loss: 0.4890 Acc: 25.0000%\n",
      "\ttrain 4-36: Loss: 0.1367 Acc: 75.0000%\n",
      "\ttrain 4-37: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 4-38: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 4-39: Loss: 0.1198 Acc: 100.0000%\n",
      "\ttrain 4-40: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 4-41: Loss: 0.7358 Acc: 0.0000%\n",
      "\ttrain 4-42: Loss: 0.2086 Acc: 50.0000%\n",
      "\ttrain 4-43: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 4-44: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 4-45: Loss: 0.0983 Acc: 100.0000%\n",
      "\ttrain 4-46: Loss: 0.0826 Acc: 100.0000%\n",
      "\ttrain 4-47: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 4-48: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 4-49: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 4-50: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 4-51: Loss: 0.2373 Acc: 50.0000%\n",
      "\ttrain 4-52: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 4-53: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 4-54: Loss: 0.1191 Acc: 100.0000%\n",
      "\ttrain 4-55: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 4-56: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 4-57: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 4-58: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 4-59: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 4-60: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 4-61: Loss: 0.1472 Acc: 50.0000%\n",
      "\ttrain 4-62: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 4-63: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 4-64: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 4-65: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 4-66: Loss: 0.4047 Acc: 50.0000%\n",
      "\ttrain 4-67: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 4-68: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 4-69: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 4-70: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 4-71: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 4-72: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 4-73: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 4-74: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 4-75: Loss: 0.3080 Acc: 50.0000%\n",
      "\ttrain 4-76: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 4-77: Loss: 0.1647 Acc: 50.0000%\n",
      "\ttrain 4-78: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 4-79: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 4-80: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 4-81: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 4-82: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 4-83: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 4-84: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 4-85: Loss: 0.1664 Acc: 75.0000%\n",
      "\ttrain 4-86: Loss: 0.2666 Acc: 50.0000%\n",
      "\ttrain 4-87: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 4-88: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 4-89: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 4-90: Loss: 0.3337 Acc: 50.0000%\n",
      "\ttrain 4-91: Loss: 0.0663 Acc: 100.0000%\n",
      "\ttrain 4-92: Loss: 0.3222 Acc: 50.0000%\n",
      "\ttrain 4-93: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 4-94: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 4-95: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 4-96: Loss: 0.1644 Acc: 75.0000%\n",
      "\ttrain 4-97: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 4-98: Loss: 0.0603 Acc: 100.0000%\n",
      "\ttrain 4-99: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 4-100: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 4-101: Loss: 0.1777 Acc: 75.0000%\n",
      "\ttrain 4-102: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 4-103: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 4-104: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 4-105: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 4-106: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 4-107: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 4-108: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 4-109: Loss: 0.1036 Acc: 100.0000%\n",
      "\ttrain 4-110: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 4-111: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 4-112: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 4-113: Loss: 0.3531 Acc: 50.0000%\n",
      "\ttrain 4-114: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 4-115: Loss: 0.1125 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-116: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 4-117: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 4-118: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 4-119: Loss: 0.1618 Acc: 75.0000%\n",
      "\ttrain 4-120: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 4-121: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 4-122: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 4-123: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 4-124: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 4-125: Loss: 0.2397 Acc: 50.0000%\n",
      "\ttrain 4-126: Loss: 0.1781 Acc: 75.0000%\n",
      "\ttrain 4-127: Loss: 0.2290 Acc: 50.0000%\n",
      "\ttrain 4-128: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 4-129: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 4-130: Loss: 0.2652 Acc: 50.0000%\n",
      "\ttrain 4-131: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 4-132: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 4-133: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 4-134: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 4-135: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 4-136: Loss: 0.2053 Acc: 50.0000%\n",
      "\ttrain 4-137: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 4-138: Loss: 0.1170 Acc: 50.0000%\n",
      "\ttrain 4-139: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 4-140: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 4-141: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 4-142: Loss: 0.2974 Acc: 50.0000%\n",
      "\ttrain 4-143: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 4-144: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 4-145: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 4-146: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 4-147: Loss: 0.2757 Acc: 75.0000%\n",
      "\ttrain 4-148: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 4-149: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 4-150: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 4-151: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 4-152: Loss: 0.0837 Acc: 100.0000%\n",
      "\ttrain 4-153: Loss: 0.2517 Acc: 25.0000%\n",
      "\ttrain 4-154: Loss: 0.1934 Acc: 75.0000%\n",
      "\ttrain 4-155: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 4-156: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 4-157: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 4-158: Loss: 0.1754 Acc: 75.0000%\n",
      "\ttrain 4-159: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 4-160: Loss: 0.2036 Acc: 50.0000%\n",
      "\ttrain 4-161: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 4-162: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 4-163: Loss: 0.2369 Acc: 50.0000%\n",
      "\ttrain 4-164: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 4-165: Loss: 0.2309 Acc: 75.0000%\n",
      "\ttrain 4-166: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 4-167: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 4-168: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 4-169: Loss: 0.1954 Acc: 75.0000%\n",
      "\ttrain 4-170: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 4-171: Loss: 0.2382 Acc: 50.0000%\n",
      "\ttrain 4-172: Loss: 0.0762 Acc: 100.0000%\n",
      "\ttrain 4-173: Loss: 0.1774 Acc: 50.0000%\n",
      "\ttrain 4-174: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 4-175: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 4-176: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 4-177: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 4-178: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 4-179: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 4-180: Loss: 0.2621 Acc: 75.0000%\n",
      "\ttrain 4-181: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 4-182: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 4-183: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 4-184: Loss: 0.2456 Acc: 75.0000%\n",
      "\ttrain 4-185: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 4-186: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 4-187: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 4-188: Loss: 0.0737 Acc: 100.0000%\n",
      "\ttrain 4-189: Loss: 0.2056 Acc: 75.0000%\n",
      "\ttrain 4-190: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 4-191: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 4-192: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 4-193: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 4-194: Loss: 0.2650 Acc: 50.0000%\n",
      "\ttrain 4-195: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 4-196: Loss: 0.3028 Acc: 50.0000%\n",
      "\ttrain 4-197: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 4-198: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 4-199: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 4-200: Loss: 0.0854 Acc: 100.0000%\n",
      "\ttrain 4-201: Loss: 0.2067 Acc: 75.0000%\n",
      "\ttrain 4-202: Loss: 0.1447 Acc: 50.0000%\n",
      "\ttrain 4-203: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 4-204: Loss: 0.2631 Acc: 50.0000%\n",
      "\ttrain 4-205: Loss: 0.2129 Acc: 50.0000%\n",
      "\ttrain 4-206: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 4-207: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 4-208: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 4-209: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 4-210: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 4-211: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 4-212: Loss: 0.2189 Acc: 75.0000%\n",
      "\ttrain 4-213: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 4-214: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 4-215: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 4-216: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 4-217: Loss: 0.2423 Acc: 75.0000%\n",
      "\ttrain 4-218: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 4-219: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 4-220: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 4-221: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 4-222: Loss: 0.2324 Acc: 50.0000%\n",
      "\ttrain 4-223: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 4-224: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 4-225: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 4-226: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 4-227: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 4-228: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 4-229: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 4-230: Loss: 0.2261 Acc: 75.0000%\n",
      "\ttrain 4-231: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 4-232: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 4-233: Loss: 0.2018 Acc: 75.0000%\n",
      "\ttrain 4-234: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 4-235: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 4-236: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 4-237: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 4-238: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 4-239: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 4-240: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 4-241: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 4-242: Loss: 0.2600 Acc: 50.0000%\n",
      "\ttrain 4-243: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 4-244: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 4-245: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 4-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 4-2: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 4-3: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 4-4: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 4-5: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 4-6: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 4-7: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 4-8: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 4-9: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 4-10: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 4-11: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 4-12: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 4-13: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 4-14: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 4-15: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 4-16: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 4-17: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 4-18: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 4-19: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 4-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 4-21: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 4-22: Loss: 0.0623 Acc: 75.0000%\n",
      "\tvalidation 4-23: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 4-24: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 4-25: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 4-26: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 4-27: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 4-28: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 4-29: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 4-30: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 4-31: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 4-32: Loss: 0.0872 Acc: 75.0000%\n",
      "\tvalidation 4-33: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 4-34: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 4-35: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 4-36: Loss: 0.0241 Acc: 100.0000%\n",
      "\tvalidation 4-37: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 4-38: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 4-39: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 4-40: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 4-41: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 4-42: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 4-43: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 4-44: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 4-45: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 4-46: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 4-47: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 4-48: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 4-49: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 4-50: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 4-51: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 4-52: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 4-53: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 4-54: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 4-55: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 4-56: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 4-57: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 4-58: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 4-59: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 4-60: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 4-61: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 4-62: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 4-63: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 4-64: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 4-65: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 4-66: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 4-67: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 4-68: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 4-69: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 4-70: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 4-71: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 4-72: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 4-73: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 4-74: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 4-75: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 4-76: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 4-77: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 4-78: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 4-79: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 4-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 4-81: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 4-82: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 4-83: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 4-84: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 4-85: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 4-86: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 4-87: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 4-88: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 4-89: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 4-90: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 4-91: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 4-92: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 4-93: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 4-94: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 4-95: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 4-96: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 4-97: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 4-98: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 4-99: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 4-100: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 4-101: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 4-102: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 4-103: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 4-104: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 4-105: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1018 Acc: 85.0000%\n",
      "\tvalidation Loss: 0.0113 Acc: 99.5238%\n",
      "Time passed 0h 2m 10s\n",
      "--------------------\n",
      "Epoch [5/40]:\n",
      "\ttrain 5-1: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 5-2: Loss: 0.3363 Acc: 50.0000%\n",
      "\ttrain 5-3: Loss: 0.0799 Acc: 100.0000%\n",
      "\ttrain 5-4: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 5-5: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 5-6: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 5-7: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 5-8: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 5-9: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 5-10: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 5-11: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 5-12: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 5-13: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 5-14: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 5-15: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 5-16: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 5-17: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 5-18: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 5-19: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 5-20: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 5-21: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 5-22: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 5-23: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 5-24: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 5-25: Loss: 0.1750 Acc: 75.0000%\n",
      "\ttrain 5-26: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 5-27: Loss: 0.1642 Acc: 75.0000%\n",
      "\ttrain 5-28: Loss: 0.3100 Acc: 75.0000%\n",
      "\ttrain 5-29: Loss: 0.3657 Acc: 25.0000%\n",
      "\ttrain 5-30: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 5-31: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 5-32: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 5-33: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 5-34: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 5-35: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 5-36: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 5-37: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 5-38: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 5-39: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 5-40: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 5-41: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 5-42: Loss: 0.0905 Acc: 100.0000%\n",
      "\ttrain 5-43: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 5-44: Loss: 0.3324 Acc: 50.0000%\n",
      "\ttrain 5-45: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 5-46: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 5-47: Loss: 0.2771 Acc: 75.0000%\n",
      "\ttrain 5-48: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 5-49: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 5-50: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 5-51: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 5-52: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 5-53: Loss: 0.1987 Acc: 75.0000%\n",
      "\ttrain 5-54: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 5-55: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 5-56: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 5-57: Loss: 0.1239 Acc: 100.0000%\n",
      "\ttrain 5-58: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 5-59: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 5-60: Loss: 0.1359 Acc: 75.0000%\n",
      "\ttrain 5-61: Loss: 0.1437 Acc: 50.0000%\n",
      "\ttrain 5-62: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 5-63: Loss: 0.2381 Acc: 75.0000%\n",
      "\ttrain 5-64: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 5-65: Loss: 0.1443 Acc: 50.0000%\n",
      "\ttrain 5-66: Loss: 0.4548 Acc: 75.0000%\n",
      "\ttrain 5-67: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 5-68: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 5-69: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 5-70: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 5-71: Loss: 0.3161 Acc: 25.0000%\n",
      "\ttrain 5-72: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 5-73: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 5-74: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 5-75: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 5-76: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 5-77: Loss: 0.4019 Acc: 50.0000%\n",
      "\ttrain 5-78: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 5-79: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 5-80: Loss: 0.2071 Acc: 50.0000%\n",
      "\ttrain 5-81: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 5-82: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 5-83: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 5-84: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 5-85: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 5-86: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 5-87: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 5-88: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 5-89: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 5-90: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 5-91: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 5-92: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 5-93: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 5-94: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 5-95: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 5-96: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 5-97: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 5-98: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 5-99: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 5-100: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 5-101: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 5-102: Loss: 0.1674 Acc: 75.0000%\n",
      "\ttrain 5-103: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 5-104: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 5-105: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 5-106: Loss: 0.4011 Acc: 50.0000%\n",
      "\ttrain 5-107: Loss: 0.0793 Acc: 100.0000%\n",
      "\ttrain 5-108: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 5-109: Loss: 0.1603 Acc: 75.0000%\n",
      "\ttrain 5-110: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 5-111: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 5-112: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 5-113: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 5-114: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 5-115: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 5-116: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 5-117: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 5-118: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 5-119: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 5-120: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 5-121: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 5-122: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 5-123: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 5-124: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 5-125: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 5-126: Loss: 0.1706 Acc: 75.0000%\n",
      "\ttrain 5-127: Loss: 0.2182 Acc: 75.0000%\n",
      "\ttrain 5-128: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 5-129: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 5-130: Loss: 0.0562 Acc: 75.0000%\n",
      "\ttrain 5-131: Loss: 0.2740 Acc: 75.0000%\n",
      "\ttrain 5-132: Loss: 0.1644 Acc: 75.0000%\n",
      "\ttrain 5-133: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 5-134: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 5-135: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 5-136: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 5-137: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 5-138: Loss: 0.2477 Acc: 75.0000%\n",
      "\ttrain 5-139: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 5-140: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 5-141: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 5-142: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 5-143: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 5-144: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 5-145: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 5-146: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 5-147: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 5-148: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 5-149: Loss: 0.0341 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 5-150: Loss: 0.2403 Acc: 50.0000%\n",
      "\ttrain 5-151: Loss: 0.1724 Acc: 75.0000%\n",
      "\ttrain 5-152: Loss: 0.0699 Acc: 75.0000%\n",
      "\ttrain 5-153: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 5-154: Loss: 0.0744 Acc: 100.0000%\n",
      "\ttrain 5-155: Loss: 0.2530 Acc: 75.0000%\n",
      "\ttrain 5-156: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 5-157: Loss: 0.3183 Acc: 75.0000%\n",
      "\ttrain 5-158: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 5-159: Loss: 0.1560 Acc: 75.0000%\n",
      "\ttrain 5-160: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 5-161: Loss: 0.2189 Acc: 50.0000%\n",
      "\ttrain 5-162: Loss: 0.2062 Acc: 75.0000%\n",
      "\ttrain 5-163: Loss: 0.3643 Acc: 25.0000%\n",
      "\ttrain 5-164: Loss: 0.1726 Acc: 75.0000%\n",
      "\ttrain 5-165: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 5-166: Loss: 0.1786 Acc: 50.0000%\n",
      "\ttrain 5-167: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 5-168: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 5-169: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 5-170: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 5-171: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 5-172: Loss: 0.2241 Acc: 50.0000%\n",
      "\ttrain 5-173: Loss: 0.0677 Acc: 75.0000%\n",
      "\ttrain 5-174: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 5-175: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 5-176: Loss: 0.9063 Acc: 0.0000%\n",
      "\ttrain 5-177: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 5-178: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 5-179: Loss: 0.2117 Acc: 25.0000%\n",
      "\ttrain 5-180: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 5-181: Loss: 0.6607 Acc: 25.0000%\n",
      "\ttrain 5-182: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 5-183: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 5-184: Loss: 0.2168 Acc: 50.0000%\n",
      "\ttrain 5-185: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 5-186: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 5-187: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 5-188: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 5-189: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 5-190: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 5-191: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 5-192: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 5-193: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 5-194: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 5-195: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 5-196: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 5-197: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 5-198: Loss: 0.0818 Acc: 100.0000%\n",
      "\ttrain 5-199: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 5-200: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 5-201: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 5-202: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 5-203: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 5-204: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 5-205: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 5-206: Loss: 0.1690 Acc: 75.0000%\n",
      "\ttrain 5-207: Loss: 0.4152 Acc: 25.0000%\n",
      "\ttrain 5-208: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 5-209: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 5-210: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 5-211: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 5-212: Loss: 0.4376 Acc: 25.0000%\n",
      "\ttrain 5-213: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 5-214: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 5-215: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 5-216: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 5-217: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 5-218: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 5-219: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 5-220: Loss: 0.1949 Acc: 75.0000%\n",
      "\ttrain 5-221: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 5-222: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 5-223: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 5-224: Loss: 0.3862 Acc: 25.0000%\n",
      "\ttrain 5-225: Loss: 0.1904 Acc: 50.0000%\n",
      "\ttrain 5-226: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 5-227: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 5-228: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 5-229: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 5-230: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 5-231: Loss: 0.2115 Acc: 75.0000%\n",
      "\ttrain 5-232: Loss: 0.1036 Acc: 100.0000%\n",
      "\ttrain 5-233: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 5-234: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 5-235: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 5-236: Loss: 0.1135 Acc: 100.0000%\n",
      "\ttrain 5-237: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 5-238: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 5-239: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 5-240: Loss: 0.1781 Acc: 75.0000%\n",
      "\ttrain 5-241: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 5-242: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 5-243: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 5-244: Loss: 0.1383 Acc: 75.0000%\n",
      "\ttrain 5-245: Loss: 0.1441 Acc: 75.0000%\n",
      "\tvalidation 5-1: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 5-2: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 5-3: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 5-4: Loss: 0.0863 Acc: 75.0000%\n",
      "\tvalidation 5-5: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 5-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 5-7: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 5-8: Loss: 0.0835 Acc: 75.0000%\n",
      "\tvalidation 5-9: Loss: 0.0662 Acc: 75.0000%\n",
      "\tvalidation 5-10: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 5-11: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 5-12: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 5-13: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 5-14: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 5-15: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 5-16: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 5-17: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 5-18: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 5-19: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 5-20: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 5-21: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 5-22: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 5-23: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 5-24: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 5-25: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 5-26: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 5-27: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 5-28: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 5-29: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 5-30: Loss: 0.0324 Acc: 100.0000%\n",
      "\tvalidation 5-31: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 5-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 5-33: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 5-34: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 5-35: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 5-36: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 5-37: Loss: 0.0514 Acc: 75.0000%\n",
      "\tvalidation 5-38: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 5-39: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 5-40: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 5-41: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 5-42: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 5-43: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 5-44: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 5-45: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 5-46: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 5-47: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 5-48: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 5-49: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 5-50: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 5-51: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 5-52: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 5-53: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 5-54: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 5-55: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 5-56: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 5-57: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 5-58: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 5-59: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 5-60: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 5-61: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 5-62: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 5-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 5-64: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 5-65: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 5-66: Loss: 0.0536 Acc: 100.0000%\n",
      "\tvalidation 5-67: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 5-68: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 5-69: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 5-70: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 5-71: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 5-72: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 5-73: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 5-74: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 5-75: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 5-76: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 5-77: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 5-78: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 5-79: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 5-80: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 5-81: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 5-82: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 5-83: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 5-84: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 5-85: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 5-86: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 5-87: Loss: 0.0479 Acc: 100.0000%\n",
      "\tvalidation 5-88: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 5-89: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 5-90: Loss: 0.0468 Acc: 100.0000%\n",
      "\tvalidation 5-91: Loss: 0.0277 Acc: 100.0000%\n",
      "\tvalidation 5-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 5-93: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 5-94: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 5-95: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 5-96: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 5-97: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 5-98: Loss: 0.0004 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 5-99: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 5-100: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 5-101: Loss: 0.0412 Acc: 100.0000%\n",
      "\tvalidation 5-102: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 5-103: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 5-104: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 5-105: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0913 Acc: 87.0408%\n",
      "\tvalidation Loss: 0.0160 Acc: 98.8095%\n",
      "Time passed 0h 2m 42s\n",
      "--------------------\n",
      "Epoch [6/40]:\n",
      "\ttrain 6-1: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 6-2: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 6-3: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 6-4: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 6-5: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 6-6: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 6-7: Loss: 0.1074 Acc: 100.0000%\n",
      "\ttrain 6-8: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 6-9: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 6-10: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 6-11: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 6-12: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 6-13: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 6-14: Loss: 0.1769 Acc: 75.0000%\n",
      "\ttrain 6-15: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 6-16: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 6-17: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 6-18: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 6-19: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 6-20: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 6-21: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 6-22: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 6-23: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 6-24: Loss: 0.1458 Acc: 50.0000%\n",
      "\ttrain 6-25: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 6-26: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 6-27: Loss: 0.3281 Acc: 75.0000%\n",
      "\ttrain 6-28: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 6-29: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 6-30: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 6-31: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 6-32: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 6-33: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 6-34: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 6-35: Loss: 0.2410 Acc: 50.0000%\n",
      "\ttrain 6-36: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 6-37: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 6-38: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 6-39: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 6-40: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 6-41: Loss: 0.1838 Acc: 75.0000%\n",
      "\ttrain 6-42: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 6-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 6-44: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 6-45: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 6-46: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 6-47: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 6-48: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 6-49: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 6-50: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 6-51: Loss: 0.1845 Acc: 75.0000%\n",
      "\ttrain 6-52: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 6-53: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 6-54: Loss: 0.9074 Acc: 25.0000%\n",
      "\ttrain 6-55: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 6-56: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 6-57: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 6-58: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 6-59: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 6-60: Loss: 0.0942 Acc: 100.0000%\n",
      "\ttrain 6-61: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 6-62: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 6-63: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 6-64: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 6-65: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 6-66: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 6-67: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 6-68: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 6-69: Loss: 0.1747 Acc: 50.0000%\n",
      "\ttrain 6-70: Loss: 0.0988 Acc: 100.0000%\n",
      "\ttrain 6-71: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 6-72: Loss: 0.2471 Acc: 75.0000%\n",
      "\ttrain 6-73: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 6-74: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 6-75: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 6-76: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 6-77: Loss: 0.2315 Acc: 75.0000%\n",
      "\ttrain 6-78: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 6-79: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 6-80: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 6-81: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 6-82: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 6-83: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 6-84: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 6-85: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 6-86: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 6-87: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 6-88: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 6-89: Loss: 0.2783 Acc: 50.0000%\n",
      "\ttrain 6-90: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 6-91: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 6-92: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 6-93: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 6-94: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 6-95: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 6-96: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 6-97: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 6-98: Loss: 0.3946 Acc: 50.0000%\n",
      "\ttrain 6-99: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 6-100: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 6-101: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 6-102: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 6-103: Loss: 0.2069 Acc: 75.0000%\n",
      "\ttrain 6-104: Loss: 0.1171 Acc: 100.0000%\n",
      "\ttrain 6-105: Loss: 0.9128 Acc: 0.0000%\n",
      "\ttrain 6-106: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 6-107: Loss: 0.2015 Acc: 75.0000%\n",
      "\ttrain 6-108: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 6-109: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 6-110: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 6-111: Loss: 0.3609 Acc: 25.0000%\n",
      "\ttrain 6-112: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 6-113: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 6-114: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 6-115: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 6-116: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 6-117: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 6-118: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 6-119: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 6-120: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 6-121: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 6-122: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 6-123: Loss: 0.4411 Acc: 25.0000%\n",
      "\ttrain 6-124: Loss: 0.1527 Acc: 75.0000%\n",
      "\ttrain 6-125: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 6-126: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 6-127: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 6-128: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 6-129: Loss: 0.1771 Acc: 50.0000%\n",
      "\ttrain 6-130: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 6-131: Loss: 0.3957 Acc: 50.0000%\n",
      "\ttrain 6-132: Loss: 0.0458 Acc: 75.0000%\n",
      "\ttrain 6-133: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 6-134: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 6-135: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 6-136: Loss: 0.2016 Acc: 75.0000%\n",
      "\ttrain 6-137: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 6-138: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 6-139: Loss: 0.1538 Acc: 75.0000%\n",
      "\ttrain 6-140: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 6-141: Loss: 0.1766 Acc: 50.0000%\n",
      "\ttrain 6-142: Loss: 0.0706 Acc: 100.0000%\n",
      "\ttrain 6-143: Loss: 0.0928 Acc: 100.0000%\n",
      "\ttrain 6-144: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 6-145: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 6-146: Loss: 0.5027 Acc: 0.0000%\n",
      "\ttrain 6-147: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 6-148: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 6-149: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 6-150: Loss: 0.3916 Acc: 0.0000%\n",
      "\ttrain 6-151: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 6-152: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 6-153: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 6-154: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 6-155: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 6-156: Loss: 0.4015 Acc: 50.0000%\n",
      "\ttrain 6-157: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 6-158: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 6-159: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 6-160: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 6-161: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 6-162: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 6-163: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 6-164: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 6-165: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 6-166: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 6-167: Loss: 0.3161 Acc: 75.0000%\n",
      "\ttrain 6-168: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 6-169: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 6-170: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 6-171: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 6-172: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 6-173: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 6-174: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 6-175: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 6-176: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 6-177: Loss: 0.3689 Acc: 25.0000%\n",
      "\ttrain 6-178: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 6-179: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 6-180: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 6-181: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 6-182: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 6-183: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 6-184: Loss: 0.2512 Acc: 50.0000%\n",
      "\ttrain 6-185: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 6-186: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 6-187: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 6-188: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 6-189: Loss: 0.0138 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-190: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 6-191: Loss: 0.2557 Acc: 50.0000%\n",
      "\ttrain 6-192: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 6-193: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 6-194: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 6-195: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 6-196: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 6-197: Loss: 0.1687 Acc: 75.0000%\n",
      "\ttrain 6-198: Loss: 0.5935 Acc: 25.0000%\n",
      "\ttrain 6-199: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 6-200: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 6-201: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 6-202: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 6-203: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 6-204: Loss: 0.3452 Acc: 50.0000%\n",
      "\ttrain 6-205: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 6-206: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 6-207: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 6-208: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 6-209: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 6-210: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 6-211: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 6-212: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 6-213: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 6-214: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 6-215: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 6-216: Loss: 0.1680 Acc: 75.0000%\n",
      "\ttrain 6-217: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 6-218: Loss: 0.5094 Acc: 25.0000%\n",
      "\ttrain 6-219: Loss: 0.2214 Acc: 50.0000%\n",
      "\ttrain 6-220: Loss: 0.1578 Acc: 50.0000%\n",
      "\ttrain 6-221: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 6-222: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 6-223: Loss: 0.1717 Acc: 75.0000%\n",
      "\ttrain 6-224: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 6-225: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 6-226: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 6-227: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 6-228: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 6-229: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 6-230: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 6-231: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 6-232: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 6-233: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 6-234: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 6-235: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 6-236: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 6-237: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 6-238: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 6-239: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 6-240: Loss: 0.1892 Acc: 75.0000%\n",
      "\ttrain 6-241: Loss: 0.6053 Acc: 25.0000%\n",
      "\ttrain 6-242: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 6-243: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 6-244: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 6-245: Loss: 0.0603 Acc: 100.0000%\n",
      "\tvalidation 6-1: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 6-2: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 6-3: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 6-4: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 6-5: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 6-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 6-7: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 6-8: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 6-9: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 6-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 6-11: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 6-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 6-13: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 6-14: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 6-15: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 6-16: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 6-17: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 6-18: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 6-19: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 6-20: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 6-21: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 6-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 6-23: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 6-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 6-25: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 6-26: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 6-27: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 6-28: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 6-29: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 6-30: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 6-31: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 6-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 6-33: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 6-34: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 6-35: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 6-36: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 6-37: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 6-38: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 6-39: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 6-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 6-41: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 6-42: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 6-43: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 6-44: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 6-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 6-46: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 6-47: Loss: 0.0954 Acc: 75.0000%\n",
      "\tvalidation 6-48: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 6-49: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 6-50: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 6-51: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 6-52: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 6-53: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 6-54: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 6-55: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 6-56: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 6-57: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 6-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 6-59: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 6-60: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 6-61: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 6-62: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 6-63: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 6-64: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 6-65: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 6-66: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 6-67: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 6-68: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 6-69: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 6-70: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 6-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 6-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 6-73: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 6-74: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 6-75: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 6-76: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 6-77: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 6-78: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 6-79: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 6-80: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 6-81: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 6-82: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 6-83: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 6-84: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 6-85: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 6-86: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 6-87: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 6-88: Loss: 0.0645 Acc: 75.0000%\n",
      "\tvalidation 6-89: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 6-90: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 6-91: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 6-92: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 6-93: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 6-94: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 6-95: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 6-96: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 6-97: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 6-98: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 6-99: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 6-100: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 6-101: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 6-102: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 6-103: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 6-104: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 6-105: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0894 Acc: 87.8571%\n",
      "\tvalidation Loss: 0.0075 Acc: 99.5238%\n",
      "Time passed 0h 3m 15s\n",
      "--------------------\n",
      "Epoch [7/40]:\n",
      "\ttrain 7-1: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 7-2: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 7-3: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 7-4: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 7-5: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 7-6: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 7-7: Loss: 0.1579 Acc: 75.0000%\n",
      "\ttrain 7-8: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 7-9: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 7-10: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 7-11: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 7-12: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 7-13: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 7-14: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 7-15: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 7-16: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 7-17: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 7-18: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 7-19: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 7-20: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 7-21: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 7-22: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 7-23: Loss: 0.0061 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-24: Loss: 0.2516 Acc: 75.0000%\n",
      "\ttrain 7-25: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 7-26: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 7-27: Loss: 0.1720 Acc: 50.0000%\n",
      "\ttrain 7-28: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 7-29: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 7-30: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 7-31: Loss: 0.2078 Acc: 75.0000%\n",
      "\ttrain 7-32: Loss: 0.0858 Acc: 100.0000%\n",
      "\ttrain 7-33: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 7-34: Loss: 0.1728 Acc: 50.0000%\n",
      "\ttrain 7-35: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 7-36: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 7-37: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 7-38: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 7-39: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 7-40: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 7-41: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 7-42: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 7-43: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 7-44: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 7-45: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 7-46: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 7-47: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 7-48: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 7-49: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 7-50: Loss: 0.0735 Acc: 100.0000%\n",
      "\ttrain 7-51: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 7-52: Loss: 0.1231 Acc: 50.0000%\n",
      "\ttrain 7-53: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 7-54: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 7-55: Loss: 0.2016 Acc: 50.0000%\n",
      "\ttrain 7-56: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 7-57: Loss: 0.1891 Acc: 50.0000%\n",
      "\ttrain 7-58: Loss: 0.2711 Acc: 75.0000%\n",
      "\ttrain 7-59: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 7-60: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 7-61: Loss: 0.1645 Acc: 75.0000%\n",
      "\ttrain 7-62: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 7-63: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 7-64: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 7-65: Loss: 0.2817 Acc: 75.0000%\n",
      "\ttrain 7-66: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 7-67: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 7-68: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 7-69: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 7-70: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 7-71: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 7-72: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 7-73: Loss: 0.0536 Acc: 75.0000%\n",
      "\ttrain 7-74: Loss: 0.0652 Acc: 75.0000%\n",
      "\ttrain 7-75: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 7-76: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 7-77: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 7-78: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 7-79: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 7-80: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 7-81: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 7-82: Loss: 0.1126 Acc: 100.0000%\n",
      "\ttrain 7-83: Loss: 0.2550 Acc: 50.0000%\n",
      "\ttrain 7-84: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 7-85: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 7-86: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 7-87: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 7-88: Loss: 0.5541 Acc: 75.0000%\n",
      "\ttrain 7-89: Loss: 0.3093 Acc: 50.0000%\n",
      "\ttrain 7-90: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 7-91: Loss: 0.0579 Acc: 100.0000%\n",
      "\ttrain 7-92: Loss: 0.0840 Acc: 100.0000%\n",
      "\ttrain 7-93: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 7-94: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 7-95: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 7-96: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 7-97: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 7-98: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 7-99: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 7-100: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 7-101: Loss: 0.1603 Acc: 75.0000%\n",
      "\ttrain 7-102: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 7-103: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 7-104: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 7-105: Loss: 0.0495 Acc: 75.0000%\n",
      "\ttrain 7-106: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 7-107: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 7-108: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 7-109: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 7-110: Loss: 0.2195 Acc: 75.0000%\n",
      "\ttrain 7-111: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 7-112: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 7-113: Loss: 0.3405 Acc: 75.0000%\n",
      "\ttrain 7-114: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 7-115: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 7-116: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 7-117: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 7-118: Loss: 0.1974 Acc: 75.0000%\n",
      "\ttrain 7-119: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 7-120: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 7-121: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 7-122: Loss: 0.3506 Acc: 75.0000%\n",
      "\ttrain 7-123: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 7-124: Loss: 0.3178 Acc: 50.0000%\n",
      "\ttrain 7-125: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 7-126: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 7-127: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 7-128: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 7-129: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 7-130: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 7-131: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 7-132: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 7-133: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 7-134: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 7-135: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 7-136: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 7-137: Loss: 0.1682 Acc: 75.0000%\n",
      "\ttrain 7-138: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 7-139: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 7-140: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 7-141: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 7-142: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 7-143: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 7-144: Loss: 0.1800 Acc: 50.0000%\n",
      "\ttrain 7-145: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 7-146: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 7-147: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 7-148: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 7-149: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 7-150: Loss: 0.1956 Acc: 50.0000%\n",
      "\ttrain 7-151: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 7-152: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 7-153: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 7-154: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 7-155: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 7-156: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 7-157: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 7-158: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 7-159: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 7-160: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 7-161: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 7-162: Loss: 0.6941 Acc: 25.0000%\n",
      "\ttrain 7-163: Loss: 0.5753 Acc: 25.0000%\n",
      "\ttrain 7-164: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 7-165: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 7-166: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 7-167: Loss: 0.1924 Acc: 75.0000%\n",
      "\ttrain 7-168: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 7-169: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 7-170: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 7-171: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 7-172: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 7-173: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 7-174: Loss: 0.1749 Acc: 50.0000%\n",
      "\ttrain 7-175: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 7-176: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 7-177: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 7-178: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 7-179: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 7-180: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 7-181: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 7-182: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 7-183: Loss: 0.3124 Acc: 50.0000%\n",
      "\ttrain 7-184: Loss: 0.4765 Acc: 50.0000%\n",
      "\ttrain 7-185: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 7-186: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 7-187: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 7-188: Loss: 0.1826 Acc: 50.0000%\n",
      "\ttrain 7-189: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 7-190: Loss: 0.3068 Acc: 75.0000%\n",
      "\ttrain 7-191: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 7-192: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 7-193: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 7-194: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 7-195: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 7-196: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 7-197: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 7-198: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 7-199: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 7-200: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 7-201: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 7-202: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 7-203: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 7-204: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 7-205: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 7-206: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 7-207: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 7-208: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 7-209: Loss: 0.2134 Acc: 75.0000%\n",
      "\ttrain 7-210: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 7-211: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 7-212: Loss: 0.1833 Acc: 50.0000%\n",
      "\ttrain 7-213: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 7-214: Loss: 0.1017 Acc: 75.0000%\n",
      "\ttrain 7-215: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 7-216: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 7-217: Loss: 0.1214 Acc: 100.0000%\n",
      "\ttrain 7-218: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 7-219: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 7-220: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 7-221: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 7-222: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 7-223: Loss: 0.0018 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-224: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 7-225: Loss: 0.1224 Acc: 50.0000%\n",
      "\ttrain 7-226: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 7-227: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 7-228: Loss: 0.2387 Acc: 75.0000%\n",
      "\ttrain 7-229: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 7-230: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 7-231: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 7-232: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 7-233: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 7-234: Loss: 0.3089 Acc: 50.0000%\n",
      "\ttrain 7-235: Loss: 0.1508 Acc: 75.0000%\n",
      "\ttrain 7-236: Loss: 0.1039 Acc: 50.0000%\n",
      "\ttrain 7-237: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 7-238: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 7-239: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 7-240: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 7-241: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 7-242: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 7-243: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 7-244: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 7-245: Loss: 0.2463 Acc: 75.0000%\n",
      "\tvalidation 7-1: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 7-2: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 7-3: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 7-4: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 7-5: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 7-6: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 7-7: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 7-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-9: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 7-10: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 7-11: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 7-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 7-13: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 7-14: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 7-15: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 7-16: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 7-17: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 7-18: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 7-19: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 7-20: Loss: 0.0529 Acc: 100.0000%\n",
      "\tvalidation 7-21: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 7-22: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 7-23: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 7-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 7-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 7-26: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 7-27: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-28: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 7-29: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 7-30: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 7-31: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 7-32: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 7-33: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 7-34: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 7-35: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 7-36: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 7-37: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 7-38: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 7-39: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 7-40: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 7-41: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 7-42: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 7-43: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 7-44: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 7-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 7-46: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 7-47: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 7-48: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 7-49: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 7-50: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 7-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 7-52: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 7-53: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 7-54: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 7-55: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 7-56: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 7-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 7-58: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 7-59: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 7-60: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 7-61: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 7-62: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 7-63: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 7-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 7-65: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 7-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-67: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 7-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 7-69: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 7-70: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 7-71: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 7-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 7-73: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 7-74: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 7-75: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 7-76: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 7-77: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 7-78: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 7-79: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 7-80: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 7-81: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 7-82: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 7-83: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 7-84: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 7-85: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 7-86: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 7-87: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 7-88: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 7-89: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 7-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-91: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 7-92: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 7-93: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 7-94: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 7-95: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 7-96: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 7-97: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 7-98: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 7-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 7-100: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 7-101: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 7-102: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 7-103: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 7-104: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 7-105: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0793 Acc: 89.0816%\n",
      "\tvalidation Loss: 0.0060 Acc: 100.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 3m 48s\n",
      "--------------------\n",
      "Epoch [8/40]:\n",
      "\ttrain 8-1: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 8-2: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 8-3: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 8-4: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 8-5: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 8-6: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 8-7: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 8-8: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 8-9: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 8-10: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 8-11: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 8-12: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 8-13: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 8-14: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 8-15: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 8-16: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 8-17: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 8-18: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 8-19: Loss: 0.5909 Acc: 25.0000%\n",
      "\ttrain 8-20: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 8-21: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 8-22: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 8-23: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 8-24: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 8-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 8-26: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 8-27: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 8-28: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 8-29: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 8-30: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 8-31: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 8-32: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 8-33: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 8-34: Loss: 0.1661 Acc: 75.0000%\n",
      "\ttrain 8-35: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 8-36: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 8-37: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 8-38: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 8-39: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 8-40: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 8-41: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 8-42: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 8-43: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 8-44: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 8-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 8-46: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 8-47: Loss: 0.1950 Acc: 75.0000%\n",
      "\ttrain 8-48: Loss: 0.1401 Acc: 75.0000%\n",
      "\ttrain 8-49: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 8-50: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 8-51: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 8-52: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 8-53: Loss: 0.2143 Acc: 75.0000%\n",
      "\ttrain 8-54: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 8-55: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 8-56: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 8-57: Loss: 0.1646 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 8-58: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 8-59: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 8-60: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 8-61: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 8-62: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 8-63: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 8-64: Loss: 0.2509 Acc: 75.0000%\n",
      "\ttrain 8-65: Loss: 0.1274 Acc: 50.0000%\n",
      "\ttrain 8-66: Loss: 0.1844 Acc: 75.0000%\n",
      "\ttrain 8-67: Loss: 0.2659 Acc: 50.0000%\n",
      "\ttrain 8-68: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 8-69: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 8-70: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 8-71: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 8-72: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 8-73: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 8-74: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 8-75: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 8-76: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 8-77: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 8-78: Loss: 0.2306 Acc: 75.0000%\n",
      "\ttrain 8-79: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 8-80: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 8-81: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 8-82: Loss: 0.1036 Acc: 100.0000%\n",
      "\ttrain 8-83: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 8-84: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 8-85: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 8-86: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 8-87: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 8-88: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 8-89: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 8-90: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 8-91: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 8-92: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 8-93: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 8-94: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 8-95: Loss: 0.0737 Acc: 75.0000%\n",
      "\ttrain 8-96: Loss: 0.5195 Acc: 50.0000%\n",
      "\ttrain 8-97: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 8-98: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 8-99: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 8-100: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 8-101: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 8-102: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 8-103: Loss: 0.1817 Acc: 50.0000%\n",
      "\ttrain 8-104: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 8-105: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 8-106: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 8-107: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 8-108: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 8-109: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 8-110: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 8-111: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 8-112: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 8-113: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 8-114: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 8-115: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 8-116: Loss: 0.1785 Acc: 50.0000%\n",
      "\ttrain 8-117: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 8-118: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 8-119: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 8-120: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 8-121: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 8-122: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 8-123: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 8-124: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 8-125: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 8-126: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 8-127: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 8-128: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 8-129: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 8-130: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 8-131: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 8-132: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 8-133: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 8-134: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 8-135: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 8-136: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 8-137: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 8-138: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 8-139: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 8-140: Loss: 0.0498 Acc: 75.0000%\n",
      "\ttrain 8-141: Loss: 0.0673 Acc: 100.0000%\n",
      "\ttrain 8-142: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 8-143: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 8-144: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 8-145: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 8-146: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 8-147: Loss: 0.3017 Acc: 75.0000%\n",
      "\ttrain 8-148: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 8-149: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 8-150: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 8-151: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 8-152: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 8-153: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 8-154: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 8-155: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 8-156: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 8-157: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 8-158: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 8-159: Loss: 0.0708 Acc: 75.0000%\n",
      "\ttrain 8-160: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 8-161: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 8-162: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 8-163: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 8-164: Loss: 0.0600 Acc: 100.0000%\n",
      "\ttrain 8-165: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 8-166: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 8-167: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 8-168: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 8-169: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 8-170: Loss: 0.6920 Acc: 50.0000%\n",
      "\ttrain 8-171: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 8-172: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 8-173: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 8-174: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 8-175: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 8-176: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 8-177: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 8-178: Loss: 0.4029 Acc: 50.0000%\n",
      "\ttrain 8-179: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 8-180: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 8-181: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 8-182: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 8-183: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 8-184: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 8-185: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 8-186: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 8-187: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 8-188: Loss: 0.2212 Acc: 50.0000%\n",
      "\ttrain 8-189: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 8-190: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 8-191: Loss: 0.2076 Acc: 75.0000%\n",
      "\ttrain 8-192: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 8-193: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 8-194: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 8-195: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 8-196: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 8-197: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 8-198: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 8-199: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 8-200: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 8-201: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 8-202: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 8-203: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 8-204: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 8-205: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 8-206: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 8-207: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 8-208: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 8-209: Loss: 0.0641 Acc: 100.0000%\n",
      "\ttrain 8-210: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 8-211: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 8-212: Loss: 0.5272 Acc: 50.0000%\n",
      "\ttrain 8-213: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 8-214: Loss: 0.2201 Acc: 75.0000%\n",
      "\ttrain 8-215: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 8-216: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 8-217: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 8-218: Loss: 0.1842 Acc: 50.0000%\n",
      "\ttrain 8-219: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 8-220: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 8-221: Loss: 0.2026 Acc: 50.0000%\n",
      "\ttrain 8-222: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 8-223: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 8-224: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 8-225: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 8-226: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 8-227: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 8-228: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 8-229: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 8-230: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 8-231: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 8-232: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 8-233: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 8-234: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 8-235: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 8-236: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 8-237: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 8-238: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 8-239: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 8-240: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 8-241: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 8-242: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 8-243: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 8-244: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 8-245: Loss: 0.1123 Acc: 75.0000%\n",
      "\tvalidation 8-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 8-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 8-3: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 8-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-5: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 8-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-7: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 8-8: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 8-9: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 8-10: Loss: 0.0006 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 8-11: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 8-12: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 8-13: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 8-14: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 8-15: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 8-16: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 8-17: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 8-18: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 8-19: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 8-20: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 8-21: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 8-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 8-23: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 8-24: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 8-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 8-26: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 8-27: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 8-28: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 8-29: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 8-30: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 8-31: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 8-32: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 8-33: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 8-34: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 8-35: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 8-36: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 8-37: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 8-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 8-39: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 8-40: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 8-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-42: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 8-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-44: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 8-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 8-46: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 8-47: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 8-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 8-49: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 8-50: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 8-51: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 8-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-53: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 8-54: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 8-55: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 8-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-57: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 8-58: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 8-59: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 8-60: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 8-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-62: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 8-63: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 8-64: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 8-65: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 8-66: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 8-67: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 8-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 8-69: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 8-70: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 8-71: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 8-72: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 8-73: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 8-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-76: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 8-77: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 8-78: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 8-79: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 8-80: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 8-81: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 8-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 8-83: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 8-84: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 8-85: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 8-86: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 8-87: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 8-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-89: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 8-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-91: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 8-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 8-93: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 8-94: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 8-95: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 8-96: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 8-97: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 8-98: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 8-99: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 8-100: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 8-101: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 8-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 8-103: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 8-104: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 8-105: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0618 Acc: 92.2449%\n",
      "\tvalidation Loss: 0.0027 Acc: 100.0000%\n",
      "Time passed 0h 4m 20s\n",
      "--------------------\n",
      "Epoch [9/40]:\n",
      "\ttrain 9-1: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 9-2: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 9-3: Loss: 0.1701 Acc: 75.0000%\n",
      "\ttrain 9-4: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 9-5: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 9-6: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 9-7: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 9-8: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 9-9: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 9-10: Loss: 0.0534 Acc: 75.0000%\n",
      "\ttrain 9-11: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 9-12: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 9-13: Loss: 0.0587 Acc: 75.0000%\n",
      "\ttrain 9-14: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 9-15: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 9-16: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 9-17: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 9-18: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 9-19: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 9-20: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 9-21: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 9-22: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 9-23: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 9-24: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 9-25: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 9-26: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 9-27: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 9-28: Loss: 0.1920 Acc: 75.0000%\n",
      "\ttrain 9-29: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 9-30: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 9-31: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 9-32: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 9-33: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 9-34: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 9-35: Loss: 0.1901 Acc: 75.0000%\n",
      "\ttrain 9-36: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 9-37: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 9-38: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 9-39: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 9-40: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 9-41: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 9-42: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 9-43: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 9-44: Loss: 0.2292 Acc: 75.0000%\n",
      "\ttrain 9-45: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 9-46: Loss: 0.2767 Acc: 50.0000%\n",
      "\ttrain 9-47: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 9-48: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 9-49: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 9-50: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 9-51: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 9-52: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 9-53: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 9-54: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 9-55: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 9-56: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 9-57: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 9-58: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 9-59: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 9-60: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 9-61: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 9-62: Loss: 0.1332 Acc: 75.0000%\n",
      "\ttrain 9-63: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 9-64: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 9-65: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 9-66: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 9-67: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 9-68: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 9-69: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 9-70: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 9-71: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 9-72: Loss: 0.2664 Acc: 50.0000%\n",
      "\ttrain 9-73: Loss: 0.4038 Acc: 50.0000%\n",
      "\ttrain 9-74: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 9-75: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 9-76: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 9-77: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 9-78: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 9-79: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 9-80: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 9-81: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 9-82: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 9-83: Loss: 0.3142 Acc: 50.0000%\n",
      "\ttrain 9-84: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 9-85: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 9-86: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 9-87: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 9-88: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 9-89: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 9-90: Loss: 0.3615 Acc: 50.0000%\n",
      "\ttrain 9-91: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 9-92: Loss: 0.0547 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 9-93: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 9-94: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 9-95: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 9-96: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 9-97: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 9-98: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 9-99: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 9-100: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 9-101: Loss: 0.6132 Acc: 0.0000%\n",
      "\ttrain 9-102: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 9-103: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 9-104: Loss: 0.0701 Acc: 100.0000%\n",
      "\ttrain 9-105: Loss: 0.2433 Acc: 50.0000%\n",
      "\ttrain 9-106: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 9-107: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 9-108: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 9-109: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 9-110: Loss: 0.1829 Acc: 50.0000%\n",
      "\ttrain 9-111: Loss: 0.1712 Acc: 50.0000%\n",
      "\ttrain 9-112: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 9-113: Loss: 0.1868 Acc: 75.0000%\n",
      "\ttrain 9-114: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 9-115: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 9-116: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 9-117: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 9-118: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 9-119: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 9-120: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 9-121: Loss: 0.4808 Acc: 50.0000%\n",
      "\ttrain 9-122: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 9-123: Loss: 0.2183 Acc: 75.0000%\n",
      "\ttrain 9-124: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 9-125: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 9-126: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 9-127: Loss: 0.2887 Acc: 75.0000%\n",
      "\ttrain 9-128: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 9-129: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 9-130: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 9-131: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 9-132: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 9-133: Loss: 0.1316 Acc: 50.0000%\n",
      "\ttrain 9-134: Loss: 0.2607 Acc: 75.0000%\n",
      "\ttrain 9-135: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 9-136: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 9-137: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 9-138: Loss: 0.0694 Acc: 100.0000%\n",
      "\ttrain 9-139: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 9-140: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 9-141: Loss: 0.5806 Acc: 50.0000%\n",
      "\ttrain 9-142: Loss: 0.3089 Acc: 50.0000%\n",
      "\ttrain 9-143: Loss: 0.2123 Acc: 50.0000%\n",
      "\ttrain 9-144: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 9-145: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 9-146: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 9-147: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 9-148: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 9-149: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 9-150: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 9-151: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 9-152: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 9-153: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 9-154: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 9-155: Loss: 0.1055 Acc: 100.0000%\n",
      "\ttrain 9-156: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 9-157: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 9-158: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 9-159: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 9-160: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 9-161: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 9-162: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 9-163: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 9-164: Loss: 0.2362 Acc: 50.0000%\n",
      "\ttrain 9-165: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 9-166: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 9-167: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 9-168: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 9-169: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 9-170: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 9-171: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 9-172: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 9-173: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 9-174: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 9-175: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 9-176: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 9-177: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 9-178: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 9-179: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 9-180: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 9-181: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 9-182: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 9-183: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 9-184: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 9-185: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 9-186: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 9-187: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 9-188: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 9-189: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 9-190: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 9-191: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 9-192: Loss: 0.2815 Acc: 75.0000%\n",
      "\ttrain 9-193: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 9-194: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 9-195: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 9-196: Loss: 0.3224 Acc: 50.0000%\n",
      "\ttrain 9-197: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 9-198: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 9-199: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 9-200: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 9-201: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 9-202: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 9-203: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 9-204: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 9-205: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 9-206: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 9-207: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 9-208: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 9-209: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 9-210: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 9-211: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 9-212: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 9-213: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 9-214: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 9-215: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 9-216: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 9-217: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 9-218: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 9-219: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 9-220: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 9-221: Loss: 0.1332 Acc: 75.0000%\n",
      "\ttrain 9-222: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 9-223: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 9-224: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 9-225: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 9-226: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 9-227: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 9-228: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 9-229: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 9-230: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 9-231: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 9-232: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 9-233: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 9-234: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 9-235: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 9-236: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 9-237: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 9-238: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 9-239: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 9-240: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 9-241: Loss: 0.0696 Acc: 75.0000%\n",
      "\ttrain 9-242: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 9-243: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 9-244: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 9-245: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 9-1: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 9-2: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 9-3: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-4: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 9-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-6: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 9-7: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 9-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-9: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 9-10: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 9-11: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 9-12: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 9-13: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-15: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 9-16: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 9-17: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-18: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 9-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-22: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 9-24: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-25: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 9-26: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 9-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-28: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 9-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-30: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-32: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 9-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 9-34: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 9-35: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-36: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 9-37: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 9-38: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 9-39: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 9-40: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 9-41: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 9-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 9-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-45: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 9-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-47: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-48: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 9-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-50: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 9-51: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 9-53: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 9-54: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 9-55: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-56: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 9-57: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 9-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-59: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 9-60: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 9-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-62: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 9-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 9-64: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 9-65: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 9-66: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 9-67: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 9-68: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 9-69: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 9-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 9-71: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 9-72: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 9-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-74: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 9-75: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 9-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-77: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-78: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 9-79: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-80: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-81: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 9-82: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 9-83: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 9-84: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 9-85: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 9-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 9-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-88: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 9-89: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-90: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 9-91: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-92: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 9-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 9-95: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 9-96: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 9-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 9-98: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 9-99: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 9-100: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 9-101: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 9-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 9-103: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 9-104: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 9-105: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0674 Acc: 90.6122%\n",
      "\tvalidation Loss: 0.0034 Acc: 100.0000%\n",
      "Time passed 0h 4m 53s\n",
      "--------------------\n",
      "Epoch [10/40]:\n",
      "\ttrain 10-1: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 10-2: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 10-3: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 10-4: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 10-5: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 10-6: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 10-7: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 10-8: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 10-9: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 10-10: Loss: 0.3622 Acc: 75.0000%\n",
      "\ttrain 10-11: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 10-12: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 10-13: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 10-14: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 10-15: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 10-16: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 10-17: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 10-18: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 10-19: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 10-20: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 10-21: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 10-22: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 10-23: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 10-24: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 10-25: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 10-26: Loss: 0.1331 Acc: 75.0000%\n",
      "\ttrain 10-27: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 10-28: Loss: 0.2354 Acc: 50.0000%\n",
      "\ttrain 10-29: Loss: 0.2077 Acc: 75.0000%\n",
      "\ttrain 10-30: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 10-31: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 10-32: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 10-33: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 10-34: Loss: 0.0516 Acc: 75.0000%\n",
      "\ttrain 10-35: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 10-36: Loss: 0.0508 Acc: 75.0000%\n",
      "\ttrain 10-37: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 10-38: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 10-39: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 10-40: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 10-41: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 10-42: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 10-43: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 10-44: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 10-45: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 10-46: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 10-47: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 10-48: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 10-49: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 10-50: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 10-51: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 10-52: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 10-53: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 10-54: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 10-55: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 10-56: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 10-57: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 10-58: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 10-59: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 10-60: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 10-61: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 10-62: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 10-63: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 10-64: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 10-65: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 10-66: Loss: 0.1890 Acc: 50.0000%\n",
      "\ttrain 10-67: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 10-68: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 10-69: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 10-70: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 10-71: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 10-72: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 10-73: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 10-74: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 10-75: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 10-76: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 10-77: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 10-78: Loss: 0.1903 Acc: 50.0000%\n",
      "\ttrain 10-79: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 10-80: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 10-81: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 10-82: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 10-83: Loss: 0.1242 Acc: 50.0000%\n",
      "\ttrain 10-84: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 10-85: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 10-86: Loss: 0.6023 Acc: 50.0000%\n",
      "\ttrain 10-87: Loss: 0.3430 Acc: 75.0000%\n",
      "\ttrain 10-88: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 10-89: Loss: 0.0461 Acc: 75.0000%\n",
      "\ttrain 10-90: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 10-91: Loss: 0.2186 Acc: 75.0000%\n",
      "\ttrain 10-92: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 10-93: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 10-94: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 10-95: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 10-96: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 10-97: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 10-98: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 10-99: Loss: 0.1401 Acc: 50.0000%\n",
      "\ttrain 10-100: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 10-101: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 10-102: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 10-103: Loss: 0.3373 Acc: 50.0000%\n",
      "\ttrain 10-104: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 10-105: Loss: 0.2131 Acc: 75.0000%\n",
      "\ttrain 10-106: Loss: 0.1668 Acc: 50.0000%\n",
      "\ttrain 10-107: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 10-108: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 10-109: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 10-110: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 10-111: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 10-112: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 10-113: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 10-114: Loss: 0.1517 Acc: 75.0000%\n",
      "\ttrain 10-115: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 10-116: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 10-117: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 10-118: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 10-119: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 10-120: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 10-121: Loss: 0.1316 Acc: 75.0000%\n",
      "\ttrain 10-122: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 10-123: Loss: 0.0019 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 10-124: Loss: 0.1317 Acc: 75.0000%\n",
      "\ttrain 10-125: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 10-126: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 10-127: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 10-128: Loss: 0.1563 Acc: 75.0000%\n",
      "\ttrain 10-129: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 10-130: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 10-131: Loss: 0.1820 Acc: 50.0000%\n",
      "\ttrain 10-132: Loss: 0.2227 Acc: 75.0000%\n",
      "\ttrain 10-133: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 10-134: Loss: 0.0603 Acc: 75.0000%\n",
      "\ttrain 10-135: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 10-136: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 10-137: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 10-138: Loss: 0.2412 Acc: 75.0000%\n",
      "\ttrain 10-139: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 10-140: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 10-141: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 10-142: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 10-143: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 10-144: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 10-145: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 10-146: Loss: 0.3057 Acc: 50.0000%\n",
      "\ttrain 10-147: Loss: 0.1557 Acc: 75.0000%\n",
      "\ttrain 10-148: Loss: 0.3418 Acc: 25.0000%\n",
      "\ttrain 10-149: Loss: 0.2323 Acc: 50.0000%\n",
      "\ttrain 10-150: Loss: 0.2312 Acc: 50.0000%\n",
      "\ttrain 10-151: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 10-152: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 10-153: Loss: 0.1847 Acc: 75.0000%\n",
      "\ttrain 10-154: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 10-155: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 10-156: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 10-157: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 10-158: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 10-159: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 10-160: Loss: 0.4817 Acc: 50.0000%\n",
      "\ttrain 10-161: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 10-162: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 10-163: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 10-164: Loss: 0.3878 Acc: 50.0000%\n",
      "\ttrain 10-165: Loss: 0.0940 Acc: 100.0000%\n",
      "\ttrain 10-166: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 10-167: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 10-168: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 10-169: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 10-170: Loss: 0.1820 Acc: 75.0000%\n",
      "\ttrain 10-171: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 10-172: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 10-173: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 10-174: Loss: 0.2326 Acc: 50.0000%\n",
      "\ttrain 10-175: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 10-176: Loss: 0.1692 Acc: 50.0000%\n",
      "\ttrain 10-177: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 10-178: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 10-179: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 10-180: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 10-181: Loss: 0.2369 Acc: 50.0000%\n",
      "\ttrain 10-182: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 10-183: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 10-184: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 10-185: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 10-186: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 10-187: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 10-188: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 10-189: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 10-190: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 10-191: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 10-192: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 10-193: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 10-194: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 10-195: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 10-196: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 10-197: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 10-198: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 10-199: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 10-200: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 10-201: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 10-202: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 10-203: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 10-204: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 10-205: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 10-206: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 10-207: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 10-208: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 10-209: Loss: 0.2290 Acc: 50.0000%\n",
      "\ttrain 10-210: Loss: 0.1396 Acc: 75.0000%\n",
      "\ttrain 10-211: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 10-212: Loss: 0.1996 Acc: 50.0000%\n",
      "\ttrain 10-213: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 10-214: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 10-215: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 10-216: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 10-217: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 10-218: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 10-219: Loss: 0.2212 Acc: 75.0000%\n",
      "\ttrain 10-220: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 10-221: Loss: 0.8053 Acc: 50.0000%\n",
      "\ttrain 10-222: Loss: 0.1603 Acc: 75.0000%\n",
      "\ttrain 10-223: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 10-224: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 10-225: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 10-226: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 10-227: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 10-228: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 10-229: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 10-230: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 10-231: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 10-232: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 10-233: Loss: 0.1799 Acc: 75.0000%\n",
      "\ttrain 10-234: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 10-235: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 10-236: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 10-237: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 10-238: Loss: 0.2308 Acc: 50.0000%\n",
      "\ttrain 10-239: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 10-240: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 10-241: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 10-242: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 10-243: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 10-244: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 10-245: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 10-1: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 10-2: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 10-3: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 10-4: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 10-5: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 10-6: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 10-7: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 10-8: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 10-9: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 10-10: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 10-11: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 10-12: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 10-13: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 10-14: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 10-15: Loss: 0.0761 Acc: 75.0000%\n",
      "\tvalidation 10-16: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 10-17: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 10-18: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 10-19: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 10-20: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 10-21: Loss: 0.1076 Acc: 75.0000%\n",
      "\tvalidation 10-22: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 10-23: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 10-24: Loss: 0.1723 Acc: 75.0000%\n",
      "\tvalidation 10-25: Loss: 0.0809 Acc: 75.0000%\n",
      "\tvalidation 10-26: Loss: 0.0696 Acc: 75.0000%\n",
      "\tvalidation 10-27: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 10-28: Loss: 0.2261 Acc: 75.0000%\n",
      "\tvalidation 10-29: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 10-30: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 10-31: Loss: 0.2287 Acc: 75.0000%\n",
      "\tvalidation 10-32: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 10-33: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 10-34: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 10-35: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 10-36: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 10-37: Loss: 0.0698 Acc: 75.0000%\n",
      "\tvalidation 10-38: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 10-39: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 10-40: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 10-41: Loss: 0.0977 Acc: 75.0000%\n",
      "\tvalidation 10-42: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 10-43: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 10-44: Loss: 0.2763 Acc: 75.0000%\n",
      "\tvalidation 10-45: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 10-46: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 10-47: Loss: 0.0583 Acc: 75.0000%\n",
      "\tvalidation 10-48: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 10-49: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 10-50: Loss: 0.0510 Acc: 75.0000%\n",
      "\tvalidation 10-51: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 10-52: Loss: 0.0822 Acc: 100.0000%\n",
      "\tvalidation 10-53: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 10-54: Loss: 0.0725 Acc: 75.0000%\n",
      "\tvalidation 10-55: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 10-56: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 10-57: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 10-58: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 10-59: Loss: 0.0592 Acc: 100.0000%\n",
      "\tvalidation 10-60: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 10-61: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 10-62: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 10-63: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 10-64: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 10-65: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 10-66: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 10-67: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 10-68: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 10-69: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 10-70: Loss: 0.0028 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 10-71: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 10-72: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 10-73: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 10-74: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 10-75: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 10-76: Loss: 0.2038 Acc: 75.0000%\n",
      "\tvalidation 10-77: Loss: 0.0683 Acc: 75.0000%\n",
      "\tvalidation 10-78: Loss: 0.3005 Acc: 75.0000%\n",
      "\tvalidation 10-79: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 10-80: Loss: 0.0696 Acc: 100.0000%\n",
      "\tvalidation 10-81: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 10-82: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 10-83: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 10-84: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 10-85: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 10-86: Loss: 0.0652 Acc: 75.0000%\n",
      "\tvalidation 10-87: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 10-88: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 10-89: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 10-90: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 10-91: Loss: 0.0756 Acc: 75.0000%\n",
      "\tvalidation 10-92: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 10-93: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 10-94: Loss: 0.0556 Acc: 75.0000%\n",
      "\tvalidation 10-95: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 10-96: Loss: 0.0756 Acc: 75.0000%\n",
      "\tvalidation 10-97: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 10-98: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 10-99: Loss: 0.0405 Acc: 100.0000%\n",
      "\tvalidation 10-100: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 10-101: Loss: 0.2402 Acc: 75.0000%\n",
      "\tvalidation 10-102: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 10-103: Loss: 0.0475 Acc: 75.0000%\n",
      "\tvalidation 10-104: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 10-105: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0726 Acc: 88.5714%\n",
      "\tvalidation Loss: 0.0396 Acc: 94.7619%\n",
      "Time passed 0h 5m 26s\n",
      "--------------------\n",
      "Epoch [11/40]:\n",
      "\ttrain 11-1: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 11-2: Loss: 0.2168 Acc: 50.0000%\n",
      "\ttrain 11-3: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 11-4: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 11-5: Loss: 0.1186 Acc: 75.0000%\n",
      "\ttrain 11-6: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 11-7: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 11-8: Loss: 0.2802 Acc: 50.0000%\n",
      "\ttrain 11-9: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 11-10: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 11-11: Loss: 0.1867 Acc: 50.0000%\n",
      "\ttrain 11-12: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 11-13: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 11-14: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 11-15: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 11-16: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 11-17: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 11-18: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 11-19: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 11-20: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 11-21: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 11-22: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 11-23: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 11-24: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 11-25: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 11-26: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 11-27: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 11-28: Loss: 0.1652 Acc: 75.0000%\n",
      "\ttrain 11-29: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 11-30: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 11-31: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 11-32: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 11-33: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 11-34: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 11-35: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 11-36: Loss: 0.2618 Acc: 75.0000%\n",
      "\ttrain 11-37: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 11-38: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 11-39: Loss: 0.2515 Acc: 50.0000%\n",
      "\ttrain 11-40: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 11-41: Loss: 0.0806 Acc: 75.0000%\n",
      "\ttrain 11-42: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 11-43: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 11-44: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 11-45: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 11-46: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 11-47: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 11-48: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 11-49: Loss: 0.1586 Acc: 75.0000%\n",
      "\ttrain 11-50: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 11-51: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 11-52: Loss: 0.3615 Acc: 50.0000%\n",
      "\ttrain 11-53: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 11-54: Loss: 0.0815 Acc: 75.0000%\n",
      "\ttrain 11-55: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 11-56: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 11-57: Loss: 0.3875 Acc: 50.0000%\n",
      "\ttrain 11-58: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 11-59: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 11-60: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 11-61: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 11-62: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 11-63: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 11-64: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 11-65: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 11-66: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 11-67: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 11-68: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 11-69: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 11-70: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 11-71: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 11-72: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 11-73: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 11-74: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 11-75: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 11-76: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 11-77: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 11-78: Loss: 0.3307 Acc: 50.0000%\n",
      "\ttrain 11-79: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 11-80: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 11-81: Loss: 0.1906 Acc: 75.0000%\n",
      "\ttrain 11-82: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 11-83: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 11-84: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 11-85: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 11-86: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 11-87: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 11-88: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 11-89: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 11-90: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 11-91: Loss: 0.5166 Acc: 25.0000%\n",
      "\ttrain 11-92: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 11-93: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 11-94: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 11-95: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 11-96: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 11-97: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 11-98: Loss: 0.1723 Acc: 75.0000%\n",
      "\ttrain 11-99: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 11-100: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 11-101: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 11-102: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 11-103: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 11-104: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 11-105: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 11-106: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 11-107: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 11-108: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 11-109: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 11-110: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 11-111: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 11-112: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 11-113: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 11-114: Loss: 0.2977 Acc: 50.0000%\n",
      "\ttrain 11-115: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 11-116: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 11-117: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 11-118: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 11-119: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 11-120: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 11-121: Loss: 0.1976 Acc: 75.0000%\n",
      "\ttrain 11-122: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 11-123: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 11-124: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 11-125: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 11-126: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 11-127: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 11-128: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 11-129: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 11-130: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 11-131: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 11-132: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 11-133: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 11-134: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 11-135: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 11-136: Loss: 0.0902 Acc: 100.0000%\n",
      "\ttrain 11-137: Loss: 0.1919 Acc: 75.0000%\n",
      "\ttrain 11-138: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 11-139: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 11-140: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 11-141: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 11-142: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 11-143: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 11-144: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 11-145: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 11-146: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 11-147: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 11-148: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 11-149: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 11-150: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 11-151: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 11-152: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 11-153: Loss: 0.0223 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-154: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 11-155: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 11-156: Loss: 0.0673 Acc: 100.0000%\n",
      "\ttrain 11-157: Loss: 0.0725 Acc: 100.0000%\n",
      "\ttrain 11-158: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 11-159: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 11-160: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 11-161: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 11-162: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 11-163: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 11-164: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 11-165: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 11-166: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 11-167: Loss: 0.6563 Acc: 75.0000%\n",
      "\ttrain 11-168: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 11-169: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 11-170: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 11-171: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 11-172: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 11-173: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 11-174: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 11-175: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 11-176: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 11-177: Loss: 0.9255 Acc: 50.0000%\n",
      "\ttrain 11-178: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 11-179: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 11-180: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 11-181: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 11-182: Loss: 0.1759 Acc: 50.0000%\n",
      "\ttrain 11-183: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 11-184: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 11-185: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 11-186: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 11-187: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 11-188: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 11-189: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 11-190: Loss: 0.2825 Acc: 50.0000%\n",
      "\ttrain 11-191: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 11-192: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 11-193: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 11-194: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 11-195: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 11-196: Loss: 0.3250 Acc: 50.0000%\n",
      "\ttrain 11-197: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 11-198: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 11-199: Loss: 0.7006 Acc: 50.0000%\n",
      "\ttrain 11-200: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 11-201: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 11-202: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 11-203: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 11-204: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 11-205: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 11-206: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 11-207: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 11-208: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 11-209: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 11-210: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 11-211: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 11-212: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 11-213: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 11-214: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 11-215: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 11-216: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 11-217: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 11-218: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 11-219: Loss: 0.2437 Acc: 50.0000%\n",
      "\ttrain 11-220: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 11-221: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 11-222: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 11-223: Loss: 0.0515 Acc: 75.0000%\n",
      "\ttrain 11-224: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 11-225: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 11-226: Loss: 0.2577 Acc: 50.0000%\n",
      "\ttrain 11-227: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 11-228: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 11-229: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 11-230: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 11-231: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 11-232: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 11-233: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 11-234: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 11-235: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 11-236: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 11-237: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 11-238: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 11-239: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 11-240: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 11-241: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 11-242: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 11-243: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 11-244: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 11-245: Loss: 0.1842 Acc: 50.0000%\n",
      "\tvalidation 11-1: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 11-2: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 11-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-4: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 11-5: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 11-6: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 11-7: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 11-8: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 11-9: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 11-10: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 11-11: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 11-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 11-13: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 11-14: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 11-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 11-16: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 11-17: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 11-18: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 11-19: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 11-20: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 11-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 11-22: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 11-23: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 11-24: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 11-25: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 11-26: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 11-27: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 11-28: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 11-29: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 11-30: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 11-31: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 11-32: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 11-33: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 11-34: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 11-35: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 11-36: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 11-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 11-38: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 11-39: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-40: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 11-41: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 11-42: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 11-43: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 11-44: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 11-45: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 11-46: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 11-47: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 11-48: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 11-49: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 11-50: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 11-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 11-52: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 11-53: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 11-54: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 11-55: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 11-56: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 11-57: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 11-58: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 11-59: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 11-60: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 11-61: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 11-62: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 11-63: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 11-64: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 11-65: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 11-66: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 11-67: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 11-68: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 11-69: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 11-70: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 11-71: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 11-72: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 11-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 11-74: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 11-75: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 11-76: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 11-77: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 11-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 11-79: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 11-80: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 11-81: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 11-82: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 11-83: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 11-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 11-85: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 11-86: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 11-87: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 11-88: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 11-89: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 11-90: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 11-91: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 11-92: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 11-93: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 11-94: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 11-95: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 11-96: Loss: 0.0006 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 11-97: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 11-98: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 11-99: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 11-100: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 11-101: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 11-102: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 11-103: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 11-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 11-105: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0649 Acc: 91.4286%\n",
      "\tvalidation Loss: 0.0060 Acc: 100.0000%\n",
      "Time passed 0h 5m 59s\n",
      "--------------------\n",
      "Epoch [12/40]:\n",
      "\ttrain 12-1: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 12-2: Loss: 0.0974 Acc: 100.0000%\n",
      "\ttrain 12-3: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 12-4: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 12-5: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 12-6: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 12-7: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 12-8: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 12-9: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 12-10: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 12-11: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 12-12: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 12-13: Loss: 0.2735 Acc: 25.0000%\n",
      "\ttrain 12-14: Loss: 0.1362 Acc: 75.0000%\n",
      "\ttrain 12-15: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 12-16: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 12-17: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 12-18: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 12-19: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 12-20: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 12-21: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 12-22: Loss: 0.4851 Acc: 50.0000%\n",
      "\ttrain 12-23: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 12-24: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 12-25: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 12-26: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 12-27: Loss: 0.2448 Acc: 75.0000%\n",
      "\ttrain 12-28: Loss: 0.2562 Acc: 75.0000%\n",
      "\ttrain 12-29: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 12-30: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 12-31: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 12-32: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 12-33: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 12-34: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 12-35: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 12-36: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 12-37: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 12-38: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 12-39: Loss: 0.0994 Acc: 100.0000%\n",
      "\ttrain 12-40: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 12-41: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 12-42: Loss: 0.1673 Acc: 75.0000%\n",
      "\ttrain 12-43: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 12-44: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 12-45: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 12-46: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 12-47: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 12-48: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 12-49: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 12-50: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 12-51: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 12-52: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 12-53: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 12-54: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 12-55: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 12-56: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 12-57: Loss: 0.3811 Acc: 25.0000%\n",
      "\ttrain 12-58: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 12-59: Loss: 0.2014 Acc: 75.0000%\n",
      "\ttrain 12-60: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 12-61: Loss: 0.2207 Acc: 50.0000%\n",
      "\ttrain 12-62: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 12-63: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 12-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 12-65: Loss: 0.1795 Acc: 75.0000%\n",
      "\ttrain 12-66: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 12-67: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 12-68: Loss: 0.2639 Acc: 75.0000%\n",
      "\ttrain 12-69: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 12-70: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 12-71: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 12-72: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 12-73: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 12-74: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 12-75: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 12-76: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 12-77: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 12-78: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 12-79: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 12-80: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 12-81: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 12-82: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 12-83: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 12-84: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 12-85: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 12-86: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 12-87: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 12-88: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 12-89: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 12-90: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 12-91: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 12-92: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 12-93: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 12-94: Loss: 0.2281 Acc: 50.0000%\n",
      "\ttrain 12-95: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 12-96: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 12-97: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 12-98: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 12-99: Loss: 0.3003 Acc: 75.0000%\n",
      "\ttrain 12-100: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 12-101: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 12-102: Loss: 0.1378 Acc: 50.0000%\n",
      "\ttrain 12-103: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 12-104: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 12-105: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 12-106: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 12-107: Loss: 0.1896 Acc: 75.0000%\n",
      "\ttrain 12-108: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 12-109: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 12-110: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 12-111: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 12-112: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 12-113: Loss: 0.1320 Acc: 50.0000%\n",
      "\ttrain 12-114: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 12-115: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 12-116: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 12-117: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 12-118: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 12-119: Loss: 1.1031 Acc: 50.0000%\n",
      "\ttrain 12-120: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 12-121: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 12-122: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 12-123: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 12-124: Loss: 0.0497 Acc: 75.0000%\n",
      "\ttrain 12-125: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 12-126: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 12-127: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 12-128: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 12-129: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 12-130: Loss: 0.2557 Acc: 75.0000%\n",
      "\ttrain 12-131: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 12-132: Loss: 0.2524 Acc: 50.0000%\n",
      "\ttrain 12-133: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 12-134: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 12-135: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 12-136: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 12-137: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 12-138: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 12-139: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 12-140: Loss: 0.1425 Acc: 50.0000%\n",
      "\ttrain 12-141: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 12-142: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 12-143: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 12-144: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 12-145: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 12-146: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 12-147: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 12-148: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 12-149: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 12-150: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 12-151: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 12-152: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 12-153: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 12-154: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 12-155: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 12-156: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 12-157: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 12-158: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 12-159: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 12-160: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 12-161: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 12-162: Loss: 0.1643 Acc: 50.0000%\n",
      "\ttrain 12-163: Loss: 0.1707 Acc: 75.0000%\n",
      "\ttrain 12-164: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 12-165: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 12-166: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 12-167: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 12-168: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 12-169: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 12-170: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 12-171: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 12-172: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 12-173: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 12-174: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 12-175: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 12-176: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 12-177: Loss: 0.5782 Acc: 25.0000%\n",
      "\ttrain 12-178: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 12-179: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 12-180: Loss: 0.8476 Acc: 0.0000%\n",
      "\ttrain 12-181: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 12-182: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 12-183: Loss: 0.0048 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-184: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 12-185: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 12-186: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 12-187: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 12-188: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 12-189: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 12-190: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 12-191: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 12-192: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 12-193: Loss: 0.3452 Acc: 50.0000%\n",
      "\ttrain 12-194: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 12-195: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 12-196: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 12-197: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 12-198: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 12-199: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 12-200: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 12-201: Loss: 0.1818 Acc: 75.0000%\n",
      "\ttrain 12-202: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 12-203: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 12-204: Loss: 0.1709 Acc: 75.0000%\n",
      "\ttrain 12-205: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 12-206: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 12-207: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 12-208: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 12-209: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 12-210: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 12-211: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 12-212: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 12-213: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 12-214: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 12-215: Loss: 0.1358 Acc: 75.0000%\n",
      "\ttrain 12-216: Loss: 0.3325 Acc: 75.0000%\n",
      "\ttrain 12-217: Loss: 0.2523 Acc: 50.0000%\n",
      "\ttrain 12-218: Loss: 0.2508 Acc: 75.0000%\n",
      "\ttrain 12-219: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 12-220: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 12-221: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 12-222: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 12-223: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 12-224: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 12-225: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 12-226: Loss: 0.1874 Acc: 75.0000%\n",
      "\ttrain 12-227: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 12-228: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 12-229: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 12-230: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 12-231: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 12-232: Loss: 0.2252 Acc: 75.0000%\n",
      "\ttrain 12-233: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 12-234: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 12-235: Loss: 0.1352 Acc: 50.0000%\n",
      "\ttrain 12-236: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 12-237: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 12-238: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 12-239: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 12-240: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 12-241: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 12-242: Loss: 0.3891 Acc: 75.0000%\n",
      "\ttrain 12-243: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 12-244: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 12-245: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 12-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 12-2: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 12-3: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 12-4: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 12-5: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 12-6: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 12-7: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 12-8: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 12-9: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 12-10: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 12-11: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 12-12: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 12-13: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 12-14: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 12-15: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 12-16: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 12-17: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 12-18: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 12-19: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 12-20: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 12-21: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 12-22: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 12-23: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 12-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 12-25: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 12-26: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 12-27: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 12-28: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 12-29: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 12-30: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 12-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 12-32: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 12-33: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 12-34: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 12-35: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 12-36: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 12-37: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 12-38: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 12-39: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 12-40: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 12-41: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 12-42: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 12-43: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 12-44: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 12-45: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 12-46: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 12-47: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 12-48: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 12-49: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 12-50: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 12-51: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 12-52: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 12-53: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 12-54: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 12-55: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 12-56: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 12-57: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 12-58: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 12-59: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 12-60: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 12-61: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 12-62: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 12-63: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 12-64: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 12-65: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 12-66: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 12-67: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 12-68: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 12-69: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 12-70: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 12-71: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 12-72: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 12-73: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 12-74: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 12-75: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 12-76: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 12-77: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 12-78: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 12-79: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 12-80: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 12-81: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 12-82: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 12-83: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 12-84: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 12-85: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 12-86: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 12-87: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 12-88: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 12-89: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 12-90: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 12-91: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 12-92: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 12-93: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 12-94: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 12-95: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 12-96: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 12-97: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 12-98: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 12-99: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 12-100: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 12-101: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 12-102: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 12-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 12-104: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 12-105: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0687 Acc: 91.1224%\n",
      "\tvalidation Loss: 0.0049 Acc: 100.0000%\n",
      "Time passed 0h 6m 32s\n",
      "--------------------\n",
      "Epoch [13/40]:\n",
      "\ttrain 13-1: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 13-2: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 13-3: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 13-4: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 13-5: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 13-6: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 13-7: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 13-8: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 13-9: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 13-10: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 13-11: Loss: 0.2066 Acc: 75.0000%\n",
      "\ttrain 13-12: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 13-13: Loss: 0.0724 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-14: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 13-15: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 13-16: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 13-17: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 13-18: Loss: 0.2578 Acc: 50.0000%\n",
      "\ttrain 13-19: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 13-20: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 13-21: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 13-22: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 13-23: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 13-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 13-25: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 13-26: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 13-27: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 13-28: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 13-29: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 13-30: Loss: 0.2286 Acc: 50.0000%\n",
      "\ttrain 13-31: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 13-32: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 13-33: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 13-34: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 13-35: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 13-36: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 13-37: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 13-38: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 13-39: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 13-40: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 13-41: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 13-42: Loss: 0.0888 Acc: 100.0000%\n",
      "\ttrain 13-43: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 13-44: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 13-45: Loss: 0.2726 Acc: 75.0000%\n",
      "\ttrain 13-46: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 13-47: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 13-48: Loss: 0.3355 Acc: 75.0000%\n",
      "\ttrain 13-49: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 13-50: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 13-51: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 13-52: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 13-53: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 13-54: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 13-55: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 13-56: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 13-57: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 13-58: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 13-59: Loss: 0.1868 Acc: 50.0000%\n",
      "\ttrain 13-60: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 13-61: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 13-62: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 13-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 13-64: Loss: 0.7649 Acc: 75.0000%\n",
      "\ttrain 13-65: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 13-66: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 13-67: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 13-68: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 13-69: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 13-70: Loss: 0.2676 Acc: 50.0000%\n",
      "\ttrain 13-71: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 13-72: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 13-73: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 13-74: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 13-75: Loss: 0.4494 Acc: 50.0000%\n",
      "\ttrain 13-76: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 13-77: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 13-78: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 13-79: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 13-80: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 13-81: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 13-82: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 13-83: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 13-84: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 13-85: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 13-86: Loss: 0.1699 Acc: 75.0000%\n",
      "\ttrain 13-87: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 13-88: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 13-89: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 13-90: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 13-91: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 13-92: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 13-93: Loss: 0.2005 Acc: 75.0000%\n",
      "\ttrain 13-94: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 13-95: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 13-96: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 13-97: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 13-98: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 13-99: Loss: 0.2803 Acc: 75.0000%\n",
      "\ttrain 13-100: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 13-101: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 13-102: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 13-103: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 13-104: Loss: 0.0776 Acc: 75.0000%\n",
      "\ttrain 13-105: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 13-106: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 13-107: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 13-108: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 13-109: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 13-110: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 13-111: Loss: 0.1077 Acc: 100.0000%\n",
      "\ttrain 13-112: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 13-113: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 13-114: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 13-115: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 13-116: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 13-117: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 13-118: Loss: 0.0942 Acc: 100.0000%\n",
      "\ttrain 13-119: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 13-120: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 13-121: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 13-122: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 13-123: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 13-124: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 13-125: Loss: 0.2185 Acc: 50.0000%\n",
      "\ttrain 13-126: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 13-127: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 13-128: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 13-129: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 13-130: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 13-131: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 13-132: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 13-133: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 13-134: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 13-135: Loss: 0.3026 Acc: 75.0000%\n",
      "\ttrain 13-136: Loss: 0.2470 Acc: 75.0000%\n",
      "\ttrain 13-137: Loss: 0.2995 Acc: 50.0000%\n",
      "\ttrain 13-138: Loss: 0.5300 Acc: 50.0000%\n",
      "\ttrain 13-139: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 13-140: Loss: 0.1756 Acc: 75.0000%\n",
      "\ttrain 13-141: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 13-142: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 13-143: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 13-144: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 13-145: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 13-146: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 13-147: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 13-148: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 13-149: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 13-150: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 13-151: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 13-152: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 13-153: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 13-154: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 13-155: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 13-156: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 13-157: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 13-158: Loss: 0.2641 Acc: 75.0000%\n",
      "\ttrain 13-159: Loss: 0.2030 Acc: 75.0000%\n",
      "\ttrain 13-160: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 13-161: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 13-162: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 13-163: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 13-164: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 13-165: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 13-166: Loss: 0.2428 Acc: 75.0000%\n",
      "\ttrain 13-167: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 13-168: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 13-169: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 13-170: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 13-171: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 13-172: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 13-173: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 13-174: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 13-175: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 13-176: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 13-177: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 13-178: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 13-179: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 13-180: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 13-181: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 13-182: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 13-183: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 13-184: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 13-185: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 13-186: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 13-187: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 13-188: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 13-189: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 13-190: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 13-191: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 13-192: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 13-193: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 13-194: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 13-195: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 13-196: Loss: 0.2091 Acc: 25.0000%\n",
      "\ttrain 13-197: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 13-198: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 13-199: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 13-200: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 13-201: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 13-202: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 13-203: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 13-204: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 13-205: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 13-206: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 13-207: Loss: 0.1030 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-208: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 13-209: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 13-210: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 13-211: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 13-212: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 13-213: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 13-214: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 13-215: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 13-216: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 13-217: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 13-218: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 13-219: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 13-220: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 13-221: Loss: 0.1082 Acc: 75.0000%\n",
      "\ttrain 13-222: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 13-223: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 13-224: Loss: 0.2658 Acc: 75.0000%\n",
      "\ttrain 13-225: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 13-226: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 13-227: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 13-228: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 13-229: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 13-230: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 13-231: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 13-232: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 13-233: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 13-234: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 13-235: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 13-236: Loss: 0.1068 Acc: 100.0000%\n",
      "\ttrain 13-237: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 13-238: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 13-239: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 13-240: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 13-241: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 13-242: Loss: 0.2360 Acc: 75.0000%\n",
      "\ttrain 13-243: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 13-244: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 13-245: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 13-1: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 13-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-3: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 13-4: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 13-5: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 13-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 13-9: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 13-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-11: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 13-12: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 13-13: Loss: 0.0608 Acc: 100.0000%\n",
      "\tvalidation 13-14: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 13-15: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 13-16: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 13-17: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 13-18: Loss: 0.1311 Acc: 75.0000%\n",
      "\tvalidation 13-19: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 13-20: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 13-21: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-22: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 13-23: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 13-24: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 13-25: Loss: 0.1110 Acc: 75.0000%\n",
      "\tvalidation 13-26: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 13-27: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 13-28: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-29: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 13-30: Loss: 0.0761 Acc: 75.0000%\n",
      "\tvalidation 13-31: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 13-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-33: Loss: 0.0536 Acc: 100.0000%\n",
      "\tvalidation 13-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-35: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 13-36: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-37: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 13-38: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 13-39: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 13-40: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 13-41: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 13-42: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 13-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-44: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 13-45: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 13-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 13-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-49: Loss: 0.1904 Acc: 75.0000%\n",
      "\tvalidation 13-50: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 13-51: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 13-52: Loss: 0.0456 Acc: 100.0000%\n",
      "\tvalidation 13-53: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 13-54: Loss: 0.0637 Acc: 100.0000%\n",
      "\tvalidation 13-55: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 13-56: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 13-57: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 13-58: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 13-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 13-60: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 13-61: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-62: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 13-63: Loss: 0.0352 Acc: 100.0000%\n",
      "\tvalidation 13-64: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 13-65: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 13-66: Loss: 0.0510 Acc: 100.0000%\n",
      "\tvalidation 13-67: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 13-68: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 13-69: Loss: 0.1917 Acc: 50.0000%\n",
      "\tvalidation 13-70: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 13-71: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 13-72: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 13-73: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 13-74: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 13-75: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 13-76: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 13-77: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 13-78: Loss: 0.0572 Acc: 75.0000%\n",
      "\tvalidation 13-79: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 13-80: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 13-81: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 13-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 13-83: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-86: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 13-87: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 13-88: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 13-89: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 13-90: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 13-91: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 13-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-93: Loss: 0.0502 Acc: 75.0000%\n",
      "\tvalidation 13-94: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 13-95: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 13-96: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 13-97: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 13-98: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 13-99: Loss: 0.1195 Acc: 75.0000%\n",
      "\tvalidation 13-100: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 13-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-102: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 13-103: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 13-104: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 13-105: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0610 Acc: 91.5306%\n",
      "\tvalidation Loss: 0.0200 Acc: 97.6190%\n",
      "Time passed 0h 7m 6s\n",
      "--------------------\n",
      "Epoch [14/40]:\n",
      "\ttrain 14-1: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 14-2: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 14-3: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 14-4: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 14-5: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 14-6: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 14-7: Loss: 0.2791 Acc: 75.0000%\n",
      "\ttrain 14-8: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 14-9: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 14-10: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 14-11: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 14-12: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 14-13: Loss: 0.3294 Acc: 50.0000%\n",
      "\ttrain 14-14: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 14-15: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 14-16: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 14-17: Loss: 0.0779 Acc: 100.0000%\n",
      "\ttrain 14-18: Loss: 0.1011 Acc: 100.0000%\n",
      "\ttrain 14-19: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 14-20: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 14-21: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 14-22: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 14-23: Loss: 0.0866 Acc: 100.0000%\n",
      "\ttrain 14-24: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 14-25: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 14-26: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 14-27: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 14-28: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 14-29: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 14-30: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 14-31: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 14-32: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 14-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 14-34: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 14-35: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 14-36: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 14-37: Loss: 0.0693 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-38: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 14-39: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 14-40: Loss: 0.2196 Acc: 75.0000%\n",
      "\ttrain 14-41: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 14-42: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 14-43: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 14-44: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 14-45: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 14-46: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 14-47: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 14-48: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 14-49: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 14-50: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 14-51: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 14-52: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 14-53: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 14-54: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 14-55: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 14-56: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 14-57: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 14-58: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 14-59: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 14-60: Loss: 0.1583 Acc: 50.0000%\n",
      "\ttrain 14-61: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 14-62: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 14-63: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 14-64: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 14-65: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 14-66: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 14-67: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 14-68: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 14-69: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 14-70: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 14-71: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 14-72: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 14-73: Loss: 0.8156 Acc: 0.0000%\n",
      "\ttrain 14-74: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 14-75: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 14-76: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 14-77: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 14-78: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 14-79: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 14-80: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 14-81: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 14-82: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 14-83: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 14-84: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 14-85: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 14-86: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 14-87: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 14-88: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 14-89: Loss: 0.2011 Acc: 50.0000%\n",
      "\ttrain 14-90: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 14-91: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 14-92: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 14-93: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 14-94: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 14-95: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 14-96: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 14-97: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 14-98: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 14-99: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 14-100: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 14-101: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 14-102: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 14-103: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 14-104: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 14-105: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 14-106: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 14-107: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 14-108: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 14-109: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 14-110: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 14-111: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 14-112: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 14-113: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 14-114: Loss: 0.7469 Acc: 25.0000%\n",
      "\ttrain 14-115: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 14-116: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 14-117: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 14-118: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 14-119: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 14-120: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 14-121: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 14-122: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 14-123: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 14-124: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 14-125: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 14-126: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 14-127: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 14-128: Loss: 0.1664 Acc: 75.0000%\n",
      "\ttrain 14-129: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 14-130: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 14-131: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 14-132: Loss: 0.7179 Acc: 0.0000%\n",
      "\ttrain 14-133: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 14-134: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 14-135: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 14-136: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 14-137: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 14-138: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 14-139: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 14-140: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 14-141: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 14-142: Loss: 0.3883 Acc: 75.0000%\n",
      "\ttrain 14-143: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 14-144: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 14-145: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 14-146: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 14-147: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 14-148: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 14-149: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 14-150: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 14-151: Loss: 0.3805 Acc: 50.0000%\n",
      "\ttrain 14-152: Loss: 0.5939 Acc: 0.0000%\n",
      "\ttrain 14-153: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 14-154: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 14-155: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 14-156: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 14-157: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 14-158: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 14-159: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 14-160: Loss: 0.2306 Acc: 75.0000%\n",
      "\ttrain 14-161: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 14-162: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 14-163: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 14-164: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 14-165: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 14-166: Loss: 0.1887 Acc: 75.0000%\n",
      "\ttrain 14-167: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 14-168: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 14-169: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 14-170: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 14-171: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 14-172: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 14-173: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 14-174: Loss: 0.2480 Acc: 75.0000%\n",
      "\ttrain 14-175: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 14-176: Loss: 0.1327 Acc: 50.0000%\n",
      "\ttrain 14-177: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 14-178: Loss: 0.2531 Acc: 75.0000%\n",
      "\ttrain 14-179: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 14-180: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 14-181: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 14-182: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 14-183: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 14-184: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 14-185: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 14-186: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 14-187: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 14-188: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 14-189: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 14-190: Loss: 0.3216 Acc: 50.0000%\n",
      "\ttrain 14-191: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 14-192: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 14-193: Loss: 0.3648 Acc: 50.0000%\n",
      "\ttrain 14-194: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 14-195: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 14-196: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 14-197: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 14-198: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 14-199: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 14-200: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 14-201: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 14-202: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 14-203: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 14-204: Loss: 0.3230 Acc: 75.0000%\n",
      "\ttrain 14-205: Loss: 0.3470 Acc: 25.0000%\n",
      "\ttrain 14-206: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 14-207: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 14-208: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 14-209: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 14-210: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 14-211: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 14-212: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 14-213: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 14-214: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 14-215: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 14-216: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 14-217: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 14-218: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 14-219: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 14-220: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 14-221: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 14-222: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 14-223: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 14-224: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 14-225: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 14-226: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 14-227: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 14-228: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 14-229: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 14-230: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 14-231: Loss: 0.0721 Acc: 75.0000%\n",
      "\ttrain 14-232: Loss: 0.0409 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-233: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 14-234: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 14-235: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 14-236: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 14-237: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 14-238: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 14-239: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 14-240: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 14-241: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 14-242: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 14-243: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 14-244: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 14-245: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 14-1: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 14-2: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 14-3: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 14-4: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 14-5: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 14-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 14-7: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 14-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 14-9: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-10: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 14-11: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 14-12: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 14-13: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 14-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-15: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-16: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 14-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 14-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-20: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-21: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 14-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-23: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 14-24: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 14-25: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 14-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 14-27: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 14-28: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 14-29: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 14-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 14-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-33: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 14-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-36: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 14-37: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-38: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-39: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 14-40: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 14-41: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 14-42: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 14-43: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 14-44: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-45: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-46: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 14-47: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 14-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-51: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-52: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-53: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 14-54: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 14-55: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-57: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 14-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 14-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 14-60: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 14-61: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 14-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 14-64: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-66: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 14-67: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-68: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-69: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 14-70: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 14-71: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 14-72: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 14-73: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-75: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 14-76: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 14-77: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 14-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 14-79: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 14-80: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 14-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 14-82: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 14-83: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 14-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 14-85: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 14-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-87: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 14-88: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 14-89: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-90: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 14-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 14-92: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 14-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-94: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 14-95: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 14-96: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 14-97: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 14-98: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 14-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-100: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 14-101: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 14-102: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 14-103: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 14-104: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 14-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0568 Acc: 92.5510%\n",
      "\tvalidation Loss: 0.0027 Acc: 100.0000%\n",
      "Time passed 0h 7m 39s\n",
      "--------------------\n",
      "Epoch [15/40]:\n",
      "\ttrain 15-1: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 15-2: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 15-3: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 15-4: Loss: 0.2547 Acc: 50.0000%\n",
      "\ttrain 15-5: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 15-6: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 15-7: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 15-8: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 15-9: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 15-10: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 15-11: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 15-12: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 15-13: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 15-14: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 15-15: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 15-16: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 15-17: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 15-18: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 15-19: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 15-20: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 15-21: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 15-22: Loss: 0.5407 Acc: 25.0000%\n",
      "\ttrain 15-23: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 15-24: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 15-25: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 15-26: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 15-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 15-28: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 15-29: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 15-30: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 15-31: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 15-32: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 15-33: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 15-34: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 15-35: Loss: 0.3563 Acc: 75.0000%\n",
      "\ttrain 15-36: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 15-37: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 15-38: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 15-39: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 15-40: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 15-41: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 15-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 15-43: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 15-44: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 15-45: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 15-46: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 15-47: Loss: 0.2060 Acc: 50.0000%\n",
      "\ttrain 15-48: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 15-49: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 15-50: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 15-51: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 15-52: Loss: 1.0362 Acc: 50.0000%\n",
      "\ttrain 15-53: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 15-54: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 15-55: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 15-56: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 15-57: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 15-58: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 15-59: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 15-60: Loss: 0.2821 Acc: 75.0000%\n",
      "\ttrain 15-61: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 15-62: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 15-63: Loss: 0.0436 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 15-64: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 15-65: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 15-66: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 15-67: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 15-68: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 15-69: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 15-70: Loss: 0.3374 Acc: 75.0000%\n",
      "\ttrain 15-71: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 15-72: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 15-73: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 15-74: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 15-75: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 15-76: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 15-77: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 15-78: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 15-79: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 15-80: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 15-81: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 15-82: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 15-83: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 15-84: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 15-85: Loss: 0.0902 Acc: 100.0000%\n",
      "\ttrain 15-86: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 15-87: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 15-88: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 15-89: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 15-90: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 15-91: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 15-92: Loss: 0.1787 Acc: 75.0000%\n",
      "\ttrain 15-93: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 15-94: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 15-95: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 15-96: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 15-97: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 15-98: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 15-99: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 15-100: Loss: 0.3469 Acc: 50.0000%\n",
      "\ttrain 15-101: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 15-102: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 15-103: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 15-104: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 15-105: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 15-106: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 15-107: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 15-108: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 15-109: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 15-110: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 15-111: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 15-112: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 15-113: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 15-114: Loss: 0.3766 Acc: 50.0000%\n",
      "\ttrain 15-115: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 15-116: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 15-117: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 15-118: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 15-119: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 15-120: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 15-121: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 15-122: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 15-123: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 15-124: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 15-125: Loss: 0.1844 Acc: 75.0000%\n",
      "\ttrain 15-126: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 15-127: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 15-128: Loss: 0.6282 Acc: 0.0000%\n",
      "\ttrain 15-129: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 15-130: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 15-131: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 15-132: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 15-133: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 15-134: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 15-135: Loss: 0.0719 Acc: 75.0000%\n",
      "\ttrain 15-136: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 15-137: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 15-138: Loss: 0.0591 Acc: 75.0000%\n",
      "\ttrain 15-139: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 15-140: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 15-141: Loss: 0.3421 Acc: 75.0000%\n",
      "\ttrain 15-142: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 15-143: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 15-144: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 15-145: Loss: 0.2680 Acc: 75.0000%\n",
      "\ttrain 15-146: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 15-147: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 15-148: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 15-149: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 15-150: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 15-151: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 15-152: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 15-153: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 15-154: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 15-155: Loss: 0.3471 Acc: 50.0000%\n",
      "\ttrain 15-156: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 15-157: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 15-158: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 15-159: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 15-160: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 15-161: Loss: 0.0983 Acc: 75.0000%\n",
      "\ttrain 15-162: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 15-163: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 15-164: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 15-165: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 15-166: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 15-167: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 15-168: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 15-169: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 15-170: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 15-171: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 15-172: Loss: 0.2702 Acc: 75.0000%\n",
      "\ttrain 15-173: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 15-174: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 15-175: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 15-176: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 15-177: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 15-178: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 15-179: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 15-180: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 15-181: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 15-182: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 15-183: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 15-184: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 15-185: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 15-186: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 15-187: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 15-188: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 15-189: Loss: 0.1693 Acc: 75.0000%\n",
      "\ttrain 15-190: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 15-191: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 15-192: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 15-193: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 15-194: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 15-195: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 15-196: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 15-197: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 15-198: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 15-199: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 15-200: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 15-201: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 15-202: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 15-203: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 15-204: Loss: 0.1833 Acc: 75.0000%\n",
      "\ttrain 15-205: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 15-206: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 15-207: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 15-208: Loss: 0.2624 Acc: 25.0000%\n",
      "\ttrain 15-209: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 15-210: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 15-211: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 15-212: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 15-213: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 15-214: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 15-215: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 15-216: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 15-217: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 15-218: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 15-219: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 15-220: Loss: 0.6163 Acc: 75.0000%\n",
      "\ttrain 15-221: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 15-222: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 15-223: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 15-224: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 15-225: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 15-226: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 15-227: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 15-228: Loss: 0.1581 Acc: 75.0000%\n",
      "\ttrain 15-229: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 15-230: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 15-231: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 15-232: Loss: 0.1656 Acc: 75.0000%\n",
      "\ttrain 15-233: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 15-234: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 15-235: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 15-236: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 15-237: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 15-238: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 15-239: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 15-240: Loss: 0.2679 Acc: 75.0000%\n",
      "\ttrain 15-241: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 15-242: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 15-243: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 15-244: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 15-245: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 15-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-2: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 15-3: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 15-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-8: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 15-9: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 15-10: Loss: 0.0016 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 15-11: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 15-12: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 15-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 15-14: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 15-15: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 15-16: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 15-17: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 15-18: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 15-19: Loss: 0.0803 Acc: 75.0000%\n",
      "\tvalidation 15-20: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 15-21: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 15-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-23: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 15-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 15-25: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 15-26: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 15-27: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 15-28: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-29: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 15-30: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 15-31: Loss: 0.1704 Acc: 75.0000%\n",
      "\tvalidation 15-32: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 15-33: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 15-34: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 15-35: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 15-37: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 15-38: Loss: 0.0635 Acc: 75.0000%\n",
      "\tvalidation 15-39: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 15-40: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 15-41: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 15-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-44: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 15-45: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 15-46: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 15-47: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 15-48: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 15-49: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-50: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 15-51: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 15-52: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 15-53: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 15-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-55: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 15-56: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 15-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-58: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 15-59: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 15-60: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 15-61: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 15-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-63: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 15-64: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 15-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-66: Loss: 0.0658 Acc: 75.0000%\n",
      "\tvalidation 15-67: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 15-68: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 15-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 15-71: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 15-72: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 15-73: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 15-74: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 15-75: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 15-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-77: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 15-78: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-79: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 15-80: Loss: 0.0683 Acc: 75.0000%\n",
      "\tvalidation 15-81: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 15-82: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 15-83: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 15-84: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 15-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-86: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 15-88: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 15-89: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 15-90: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 15-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 15-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 15-93: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 15-94: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 15-95: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 15-96: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 15-97: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 15-98: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 15-99: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 15-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 15-101: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 15-102: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 15-103: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 15-104: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 15-105: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0605 Acc: 92.4490%\n",
      "\tvalidation Loss: 0.0090 Acc: 98.8095%\n",
      "Time passed 0h 8m 13s\n",
      "--------------------\n",
      "Epoch [16/40]:\n",
      "\ttrain 16-1: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 16-2: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 16-3: Loss: 0.2025 Acc: 75.0000%\n",
      "\ttrain 16-4: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 16-5: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 16-6: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 16-7: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 16-8: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 16-9: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 16-10: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 16-11: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 16-12: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 16-13: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 16-14: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 16-15: Loss: 0.0839 Acc: 100.0000%\n",
      "\ttrain 16-16: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 16-17: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 16-18: Loss: 0.4403 Acc: 75.0000%\n",
      "\ttrain 16-19: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 16-20: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 16-21: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 16-22: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 16-23: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 16-24: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 16-25: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 16-26: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 16-27: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 16-28: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 16-29: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 16-30: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 16-31: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 16-32: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 16-33: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 16-34: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 16-35: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 16-36: Loss: 0.0783 Acc: 100.0000%\n",
      "\ttrain 16-37: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 16-38: Loss: 0.2124 Acc: 75.0000%\n",
      "\ttrain 16-39: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 16-40: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 16-41: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 16-42: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 16-43: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 16-44: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 16-45: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 16-46: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 16-47: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 16-48: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 16-49: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 16-50: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 16-51: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 16-52: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 16-53: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 16-54: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 16-55: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 16-56: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 16-57: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 16-58: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 16-59: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 16-60: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 16-61: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 16-62: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 16-63: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 16-64: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 16-65: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 16-66: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 16-67: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 16-68: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 16-69: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 16-70: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 16-71: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 16-72: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 16-73: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 16-74: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 16-75: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 16-76: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 16-77: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 16-78: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 16-79: Loss: 0.1836 Acc: 75.0000%\n",
      "\ttrain 16-80: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 16-81: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 16-82: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 16-83: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 16-84: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 16-85: Loss: 0.1647 Acc: 75.0000%\n",
      "\ttrain 16-86: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 16-87: Loss: 0.0483 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 16-88: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 16-89: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 16-90: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 16-91: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 16-92: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 16-93: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 16-94: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 16-95: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 16-96: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 16-97: Loss: 0.1759 Acc: 50.0000%\n",
      "\ttrain 16-98: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 16-99: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 16-100: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 16-101: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 16-102: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 16-103: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 16-104: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 16-105: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 16-106: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 16-107: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 16-108: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 16-109: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 16-110: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 16-111: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 16-112: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 16-113: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 16-114: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 16-115: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 16-116: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 16-117: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 16-118: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 16-119: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 16-120: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 16-121: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 16-122: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 16-123: Loss: 0.2299 Acc: 50.0000%\n",
      "\ttrain 16-124: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 16-125: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 16-126: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 16-127: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 16-128: Loss: 0.0725 Acc: 100.0000%\n",
      "\ttrain 16-129: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 16-130: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 16-131: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 16-132: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 16-133: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 16-134: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 16-135: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 16-136: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 16-137: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 16-138: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 16-139: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 16-140: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 16-141: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 16-142: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 16-143: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 16-144: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 16-145: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 16-146: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 16-147: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 16-148: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 16-149: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 16-150: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 16-151: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 16-152: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 16-153: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 16-154: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 16-155: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 16-156: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 16-157: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 16-158: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 16-159: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 16-160: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 16-161: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 16-162: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 16-163: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 16-164: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 16-165: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 16-166: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 16-167: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 16-168: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 16-169: Loss: 0.1893 Acc: 75.0000%\n",
      "\ttrain 16-170: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 16-171: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 16-172: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 16-173: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 16-174: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 16-175: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 16-176: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 16-177: Loss: 0.0564 Acc: 100.0000%\n",
      "\ttrain 16-178: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 16-179: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 16-180: Loss: 0.0457 Acc: 75.0000%\n",
      "\ttrain 16-181: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 16-182: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 16-183: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 16-184: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 16-185: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 16-186: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 16-187: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 16-188: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 16-189: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 16-190: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 16-191: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 16-192: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 16-193: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 16-194: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 16-195: Loss: 0.2198 Acc: 75.0000%\n",
      "\ttrain 16-196: Loss: 0.2627 Acc: 75.0000%\n",
      "\ttrain 16-197: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 16-198: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 16-199: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 16-200: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 16-201: Loss: 0.7298 Acc: 25.0000%\n",
      "\ttrain 16-202: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 16-203: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 16-204: Loss: 0.0660 Acc: 100.0000%\n",
      "\ttrain 16-205: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 16-206: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 16-207: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 16-208: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 16-209: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 16-210: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 16-211: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 16-212: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 16-213: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 16-214: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 16-215: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 16-216: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 16-217: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 16-218: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 16-219: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 16-220: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 16-221: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 16-222: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 16-223: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 16-224: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 16-225: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 16-226: Loss: 0.2219 Acc: 75.0000%\n",
      "\ttrain 16-227: Loss: 0.4689 Acc: 50.0000%\n",
      "\ttrain 16-228: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 16-229: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 16-230: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 16-231: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 16-232: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 16-233: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 16-234: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 16-235: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 16-236: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 16-237: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 16-238: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 16-239: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 16-240: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 16-241: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 16-242: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 16-243: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 16-244: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 16-245: Loss: 0.0518 Acc: 75.0000%\n",
      "\tvalidation 16-1: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-2: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 16-3: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-6: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 16-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-9: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 16-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-12: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-14: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-15: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-16: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 16-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-18: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-21: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-22: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-23: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 16-24: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 16-25: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 16-26: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 16-27: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-31: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-32: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 16-33: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-34: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 16-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-37: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 16-38: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 16-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-40: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-41: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 16-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-43: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-46: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-47: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-48: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-49: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 16-50: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-52: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 16-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-54: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-55: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-56: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 16-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 16-60: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 16-61: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-64: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-65: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 16-66: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-67: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 16-68: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-69: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-71: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 16-72: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-75: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-77: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-78: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 16-82: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 16-83: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-84: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 16-85: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 16-86: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-87: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 16-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-89: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-90: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 16-91: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-92: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 16-93: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 16-94: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 16-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-96: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 16-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 16-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-99: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 16-100: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-101: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 16-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 16-105: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0412 Acc: 95.3061%\n",
      "\tvalidation Loss: 0.0011 Acc: 100.0000%\n",
      "Time passed 0h 8m 47s\n",
      "--------------------\n",
      "Epoch [17/40]:\n",
      "\ttrain 17-1: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 17-2: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 17-3: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 17-4: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-5: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 17-6: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 17-7: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 17-8: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 17-9: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 17-10: Loss: 0.9149 Acc: 50.0000%\n",
      "\ttrain 17-11: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 17-12: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 17-13: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 17-14: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 17-15: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 17-16: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 17-17: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 17-18: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 17-19: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 17-20: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 17-21: Loss: 0.3955 Acc: 75.0000%\n",
      "\ttrain 17-22: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 17-23: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-24: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 17-25: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 17-26: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 17-27: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 17-28: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 17-29: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 17-30: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 17-31: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 17-32: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 17-33: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 17-34: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 17-35: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 17-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-37: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 17-38: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-39: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 17-40: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 17-41: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 17-42: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 17-43: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 17-44: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 17-45: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-46: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 17-47: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 17-48: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 17-49: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-50: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 17-51: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 17-52: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 17-53: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 17-54: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 17-55: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 17-56: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 17-57: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 17-58: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 17-59: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 17-60: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 17-61: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 17-62: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 17-63: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 17-64: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 17-65: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 17-66: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 17-67: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 17-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 17-69: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 17-70: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 17-71: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 17-72: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 17-73: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 17-74: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 17-75: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 17-76: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 17-77: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 17-78: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 17-79: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 17-80: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 17-81: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 17-82: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 17-83: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 17-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 17-85: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 17-86: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 17-87: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 17-88: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-90: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 17-91: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 17-92: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 17-93: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 17-94: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 17-95: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 17-96: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 17-97: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 17-98: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 17-99: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 17-100: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 17-101: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 17-102: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 17-103: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 17-104: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 17-105: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 17-106: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 17-107: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 17-108: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 17-109: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 17-110: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 17-111: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 17-112: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 17-113: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 17-114: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 17-115: Loss: 0.2516 Acc: 75.0000%\n",
      "\ttrain 17-116: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 17-117: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 17-118: Loss: 0.0393 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-119: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 17-120: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 17-121: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 17-122: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 17-123: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 17-124: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 17-125: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 17-126: Loss: 0.0516 Acc: 75.0000%\n",
      "\ttrain 17-127: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 17-128: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 17-129: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 17-130: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 17-131: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-132: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 17-133: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 17-134: Loss: 0.3547 Acc: 50.0000%\n",
      "\ttrain 17-135: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 17-136: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 17-137: Loss: 0.0516 Acc: 75.0000%\n",
      "\ttrain 17-138: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 17-139: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 17-140: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 17-141: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 17-142: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 17-143: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 17-144: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 17-145: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 17-146: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 17-147: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 17-148: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 17-149: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 17-150: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 17-151: Loss: 0.2606 Acc: 50.0000%\n",
      "\ttrain 17-152: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 17-153: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 17-154: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 17-155: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 17-156: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 17-157: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-158: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 17-159: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 17-160: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 17-161: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 17-162: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 17-163: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 17-164: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 17-165: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 17-166: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 17-167: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-168: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 17-169: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 17-170: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 17-171: Loss: 0.2331 Acc: 50.0000%\n",
      "\ttrain 17-172: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 17-173: Loss: 0.0860 Acc: 100.0000%\n",
      "\ttrain 17-174: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 17-175: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 17-176: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 17-177: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 17-178: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 17-179: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 17-180: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 17-181: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 17-182: Loss: 0.1910 Acc: 75.0000%\n",
      "\ttrain 17-183: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 17-184: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 17-185: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 17-186: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 17-187: Loss: 0.7537 Acc: 50.0000%\n",
      "\ttrain 17-188: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 17-189: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-190: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 17-191: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 17-192: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 17-193: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 17-194: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 17-195: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 17-196: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 17-197: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 17-198: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 17-199: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 17-200: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 17-201: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 17-202: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 17-203: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 17-204: Loss: 0.2306 Acc: 75.0000%\n",
      "\ttrain 17-205: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 17-206: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 17-207: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 17-208: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 17-209: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 17-210: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 17-211: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 17-212: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 17-213: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 17-214: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 17-215: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 17-216: Loss: 0.5772 Acc: 0.0000%\n",
      "\ttrain 17-217: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 17-218: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 17-219: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 17-220: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-221: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 17-222: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 17-223: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 17-224: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 17-225: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 17-226: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 17-227: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 17-228: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 17-229: Loss: 0.2088 Acc: 75.0000%\n",
      "\ttrain 17-230: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 17-231: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-232: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 17-233: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 17-234: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 17-235: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 17-236: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 17-237: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 17-238: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 17-239: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 17-240: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 17-241: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 17-242: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 17-243: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 17-244: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 17-245: Loss: 0.2123 Acc: 75.0000%\n",
      "\tvalidation 17-1: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 17-2: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-3: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 17-4: Loss: 0.0911 Acc: 75.0000%\n",
      "\tvalidation 17-5: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 17-6: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 17-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-8: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-9: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 17-10: Loss: 0.0556 Acc: 75.0000%\n",
      "\tvalidation 17-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-12: Loss: 0.0342 Acc: 100.0000%\n",
      "\tvalidation 17-13: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-14: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-15: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 17-16: Loss: 0.0518 Acc: 75.0000%\n",
      "\tvalidation 17-17: Loss: 0.0705 Acc: 75.0000%\n",
      "\tvalidation 17-18: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 17-19: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 17-20: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 17-21: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 17-22: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 17-23: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 17-24: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 17-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-26: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-27: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-28: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 17-29: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 17-30: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 17-31: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 17-32: Loss: 0.0584 Acc: 100.0000%\n",
      "\tvalidation 17-33: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-35: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 17-36: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 17-37: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-38: Loss: 0.1368 Acc: 75.0000%\n",
      "\tvalidation 17-39: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-41: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 17-42: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 17-43: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 17-44: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 17-45: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-46: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-47: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 17-48: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 17-49: Loss: 0.0527 Acc: 75.0000%\n",
      "\tvalidation 17-50: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-51: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-53: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 17-54: Loss: 0.0851 Acc: 100.0000%\n",
      "\tvalidation 17-55: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-56: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 17-57: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 17-58: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 17-59: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 17-60: Loss: 0.0402 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 17-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-63: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-67: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 17-68: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 17-69: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 17-70: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 17-71: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-72: Loss: 0.0524 Acc: 75.0000%\n",
      "\tvalidation 17-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 17-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-75: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 17-76: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-77: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-78: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 17-79: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 17-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 17-81: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 17-82: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-83: Loss: 0.1214 Acc: 50.0000%\n",
      "\tvalidation 17-84: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 17-85: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 17-86: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-87: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 17-88: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-89: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-90: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 17-91: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 17-92: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-93: Loss: 0.0712 Acc: 75.0000%\n",
      "\tvalidation 17-94: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 17-95: Loss: 0.1346 Acc: 75.0000%\n",
      "\tvalidation 17-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-98: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 17-99: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 17-100: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 17-101: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-102: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 17-103: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 17-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 17-105: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0408 Acc: 95.3061%\n",
      "\tvalidation Loss: 0.0181 Acc: 96.6667%\n",
      "Time passed 0h 9m 20s\n",
      "--------------------\n",
      "Epoch [18/40]:\n",
      "\ttrain 18-1: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 18-2: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 18-3: Loss: 0.3811 Acc: 75.0000%\n",
      "\ttrain 18-4: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 18-5: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 18-6: Loss: 0.3500 Acc: 50.0000%\n",
      "\ttrain 18-7: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 18-8: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 18-9: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 18-10: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 18-11: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 18-12: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 18-13: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 18-14: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 18-15: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 18-16: Loss: 0.1428 Acc: 75.0000%\n",
      "\ttrain 18-17: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 18-18: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 18-19: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 18-20: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 18-21: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 18-22: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 18-23: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-24: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 18-25: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 18-26: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 18-27: Loss: 0.5523 Acc: 25.0000%\n",
      "\ttrain 18-28: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 18-29: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 18-30: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 18-31: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 18-32: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 18-33: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 18-34: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 18-35: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 18-36: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 18-37: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 18-38: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 18-39: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 18-40: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 18-41: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 18-42: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 18-43: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 18-44: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 18-45: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 18-46: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 18-47: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-48: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 18-49: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 18-50: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 18-51: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 18-52: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 18-53: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 18-54: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 18-55: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 18-56: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 18-57: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 18-58: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 18-59: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 18-60: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 18-61: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 18-62: Loss: 0.4718 Acc: 75.0000%\n",
      "\ttrain 18-63: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 18-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 18-65: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 18-66: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 18-67: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 18-68: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 18-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 18-70: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 18-71: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 18-72: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 18-73: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-74: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 18-75: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 18-76: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 18-77: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 18-78: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 18-79: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 18-80: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 18-81: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 18-82: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 18-83: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 18-84: Loss: 0.3449 Acc: 75.0000%\n",
      "\ttrain 18-85: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 18-86: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 18-87: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 18-88: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 18-89: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 18-90: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 18-91: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 18-92: Loss: 0.1770 Acc: 75.0000%\n",
      "\ttrain 18-93: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 18-94: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 18-95: Loss: 0.0925 Acc: 100.0000%\n",
      "\ttrain 18-96: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 18-97: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 18-98: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 18-99: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 18-100: Loss: 0.8692 Acc: 50.0000%\n",
      "\ttrain 18-101: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 18-102: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 18-103: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 18-104: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 18-105: Loss: 0.0772 Acc: 100.0000%\n",
      "\ttrain 18-106: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 18-107: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 18-108: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 18-109: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-110: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 18-111: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 18-112: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 18-113: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 18-114: Loss: 0.1729 Acc: 75.0000%\n",
      "\ttrain 18-115: Loss: 0.1144 Acc: 50.0000%\n",
      "\ttrain 18-116: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 18-117: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 18-118: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 18-119: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 18-120: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 18-121: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 18-122: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 18-123: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-124: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 18-125: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 18-126: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 18-127: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 18-128: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 18-129: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 18-130: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 18-131: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 18-132: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 18-133: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 18-134: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 18-135: Loss: 0.2826 Acc: 50.0000%\n",
      "\ttrain 18-136: Loss: 0.1969 Acc: 50.0000%\n",
      "\ttrain 18-137: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 18-138: Loss: 0.0794 Acc: 100.0000%\n",
      "\ttrain 18-139: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 18-140: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 18-141: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 18-142: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 18-143: Loss: 0.0630 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-144: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 18-145: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 18-146: Loss: 0.2587 Acc: 50.0000%\n",
      "\ttrain 18-147: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 18-148: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 18-149: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 18-150: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 18-151: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 18-152: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 18-153: Loss: 0.3085 Acc: 75.0000%\n",
      "\ttrain 18-154: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 18-155: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 18-156: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 18-157: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 18-158: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 18-159: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 18-160: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 18-161: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 18-162: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 18-163: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 18-164: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 18-165: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 18-166: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 18-167: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 18-168: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 18-169: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 18-170: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 18-171: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 18-172: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 18-173: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 18-174: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 18-175: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 18-176: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 18-177: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 18-178: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 18-179: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 18-180: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 18-181: Loss: 0.5472 Acc: 50.0000%\n",
      "\ttrain 18-182: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 18-183: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 18-184: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 18-185: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 18-186: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 18-187: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 18-188: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 18-189: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 18-190: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 18-191: Loss: 0.2214 Acc: 50.0000%\n",
      "\ttrain 18-192: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 18-193: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 18-194: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 18-195: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 18-196: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 18-197: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 18-198: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 18-199: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 18-200: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 18-201: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 18-202: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 18-203: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 18-204: Loss: 0.0847 Acc: 100.0000%\n",
      "\ttrain 18-205: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 18-206: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 18-207: Loss: 0.7357 Acc: 25.0000%\n",
      "\ttrain 18-208: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 18-209: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 18-210: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 18-211: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 18-212: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-213: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 18-214: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 18-215: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 18-216: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 18-217: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 18-218: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 18-219: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 18-220: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 18-221: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 18-222: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 18-223: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 18-224: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 18-225: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 18-226: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 18-227: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 18-228: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 18-229: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 18-230: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 18-231: Loss: 0.6516 Acc: 25.0000%\n",
      "\ttrain 18-232: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 18-233: Loss: 0.0543 Acc: 75.0000%\n",
      "\ttrain 18-234: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 18-235: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 18-236: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 18-237: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 18-238: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 18-239: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 18-240: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 18-241: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 18-242: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 18-243: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 18-244: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 18-245: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 18-1: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 18-2: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 18-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-4: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 18-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-8: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-9: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 18-10: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-11: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 18-12: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-14: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 18-15: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 18-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 18-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-18: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 18-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-20: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 18-21: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 18-22: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-23: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 18-24: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 18-25: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-26: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-27: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 18-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 18-29: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-31: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-33: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 18-34: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 18-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-36: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-37: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-38: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-39: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 18-40: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-41: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 18-44: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 18-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-46: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 18-47: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 18-49: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 18-50: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 18-51: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 18-52: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 18-53: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 18-54: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 18-55: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 18-56: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-57: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 18-58: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 18-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-60: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-61: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 18-62: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 18-64: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-65: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-66: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 18-67: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 18-68: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 18-69: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 18-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-71: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-73: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 18-74: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 18-75: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-76: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 18-77: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 18-78: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 18-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-80: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-81: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-83: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 18-84: Loss: 0.0115 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 18-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-86: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 18-87: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 18-88: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 18-89: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 18-90: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-91: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 18-92: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 18-93: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 18-94: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 18-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 18-96: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 18-97: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 18-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 18-99: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 18-100: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-101: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-103: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 18-105: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0533 Acc: 93.8776%\n",
      "\tvalidation Loss: 0.0037 Acc: 100.0000%\n",
      "Time passed 0h 9m 53s\n",
      "--------------------\n",
      "Epoch [19/40]:\n",
      "\ttrain 19-1: Loss: 0.1777 Acc: 75.0000%\n",
      "\ttrain 19-2: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 19-3: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 19-4: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 19-5: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 19-6: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 19-7: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 19-8: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 19-9: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 19-10: Loss: 0.1942 Acc: 50.0000%\n",
      "\ttrain 19-11: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 19-12: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 19-13: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 19-14: Loss: 0.1357 Acc: 75.0000%\n",
      "\ttrain 19-15: Loss: 0.1683 Acc: 75.0000%\n",
      "\ttrain 19-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 19-17: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 19-18: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 19-19: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 19-20: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 19-21: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 19-22: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 19-23: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 19-24: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 19-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-26: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 19-27: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 19-28: Loss: 0.3106 Acc: 75.0000%\n",
      "\ttrain 19-29: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 19-30: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 19-31: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 19-32: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 19-33: Loss: 0.5881 Acc: 25.0000%\n",
      "\ttrain 19-34: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 19-35: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 19-36: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 19-37: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 19-38: Loss: 0.2884 Acc: 75.0000%\n",
      "\ttrain 19-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 19-40: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 19-41: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 19-42: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 19-43: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 19-44: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 19-45: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 19-46: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 19-47: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 19-48: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 19-49: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 19-50: Loss: 0.0746 Acc: 75.0000%\n",
      "\ttrain 19-51: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 19-52: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 19-53: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 19-54: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 19-55: Loss: 0.2852 Acc: 75.0000%\n",
      "\ttrain 19-56: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 19-57: Loss: 0.3158 Acc: 75.0000%\n",
      "\ttrain 19-58: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 19-59: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 19-60: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 19-61: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 19-62: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 19-63: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 19-64: Loss: 0.2624 Acc: 75.0000%\n",
      "\ttrain 19-65: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 19-66: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 19-67: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 19-68: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 19-69: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 19-70: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 19-71: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 19-72: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 19-73: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 19-74: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 19-75: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 19-76: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 19-77: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 19-78: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 19-79: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 19-80: Loss: 0.0742 Acc: 100.0000%\n",
      "\ttrain 19-81: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 19-82: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 19-83: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 19-84: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 19-85: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 19-86: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 19-87: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-88: Loss: 0.1078 Acc: 75.0000%\n",
      "\ttrain 19-89: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 19-90: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 19-91: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 19-92: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 19-93: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 19-94: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 19-95: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 19-96: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 19-97: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 19-98: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 19-99: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 19-100: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 19-101: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 19-102: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 19-103: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-104: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 19-105: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 19-106: Loss: 1.3502 Acc: 25.0000%\n",
      "\ttrain 19-107: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 19-108: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 19-109: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 19-110: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 19-111: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 19-112: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 19-113: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 19-114: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 19-115: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 19-116: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 19-117: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-118: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 19-119: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 19-120: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 19-121: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 19-122: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 19-123: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 19-124: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 19-125: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 19-126: Loss: 0.1450 Acc: 75.0000%\n",
      "\ttrain 19-127: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 19-128: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 19-129: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 19-130: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 19-131: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 19-132: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 19-133: Loss: 0.1878 Acc: 75.0000%\n",
      "\ttrain 19-134: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 19-135: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 19-136: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 19-137: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-138: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 19-139: Loss: 0.7486 Acc: 25.0000%\n",
      "\ttrain 19-140: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 19-141: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 19-142: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 19-143: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 19-144: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 19-145: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 19-146: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 19-147: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 19-148: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 19-149: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 19-150: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 19-151: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 19-152: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 19-153: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 19-154: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 19-155: Loss: 0.1532 Acc: 75.0000%\n",
      "\ttrain 19-156: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 19-157: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 19-158: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 19-159: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 19-160: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 19-161: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 19-162: Loss: 0.4332 Acc: 75.0000%\n",
      "\ttrain 19-163: Loss: 0.0493 Acc: 75.0000%\n",
      "\ttrain 19-164: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 19-165: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 19-166: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 19-167: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 19-168: Loss: 0.0008 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-169: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 19-170: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 19-171: Loss: 0.0682 Acc: 75.0000%\n",
      "\ttrain 19-172: Loss: 0.3899 Acc: 50.0000%\n",
      "\ttrain 19-173: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 19-174: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 19-175: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 19-176: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 19-177: Loss: 0.8648 Acc: 50.0000%\n",
      "\ttrain 19-178: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 19-179: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 19-180: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 19-181: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 19-182: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 19-183: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 19-184: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 19-185: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 19-186: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 19-187: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 19-188: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 19-189: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 19-190: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 19-191: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 19-192: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 19-193: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 19-194: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 19-195: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 19-196: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 19-197: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 19-198: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-199: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 19-200: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 19-201: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 19-202: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 19-203: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 19-204: Loss: 0.4206 Acc: 50.0000%\n",
      "\ttrain 19-205: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 19-206: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 19-207: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 19-208: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 19-209: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 19-210: Loss: 0.1960 Acc: 50.0000%\n",
      "\ttrain 19-211: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 19-212: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 19-213: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 19-214: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 19-215: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 19-216: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 19-217: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 19-218: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 19-219: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 19-220: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 19-221: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 19-222: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 19-223: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 19-224: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 19-225: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 19-226: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 19-227: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 19-228: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 19-229: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 19-230: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 19-231: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 19-232: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 19-233: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 19-234: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 19-235: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 19-236: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 19-237: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 19-238: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 19-239: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 19-240: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 19-241: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 19-242: Loss: 0.4224 Acc: 50.0000%\n",
      "\ttrain 19-243: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 19-244: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 19-245: Loss: 0.0466 Acc: 100.0000%\n",
      "\tvalidation 19-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-3: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-5: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 19-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-8: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 19-9: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-11: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 19-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-13: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 19-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-17: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 19-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-20: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 19-21: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 19-22: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 19-23: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-25: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 19-26: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 19-27: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-29: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-30: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 19-31: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 19-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 19-33: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 19-34: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 19-35: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-37: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 19-38: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-40: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 19-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-43: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 19-44: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 19-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-47: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-49: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-50: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-51: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 19-52: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 19-53: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 19-54: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 19-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-56: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-57: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 19-58: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-59: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 19-60: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 19-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-62: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 19-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-65: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 19-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-67: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 19-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 19-69: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 19-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-72: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-73: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 19-75: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 19-76: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 19-77: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-78: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-79: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 19-80: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 19-81: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 19-82: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 19-83: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-85: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 19-86: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 19-87: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 19-88: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-89: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 19-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-94: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 19-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 19-98: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-99: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-100: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 19-101: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 19-102: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 19-103: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-104: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 19-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0554 Acc: 93.9796%\n",
      "\tvalidation Loss: 0.0018 Acc: 100.0000%\n",
      "Time passed 0h 10m 27s\n",
      "--------------------\n",
      "Epoch [20/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-1: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 20-2: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 20-3: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 20-4: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 20-5: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 20-6: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 20-7: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 20-8: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 20-9: Loss: 0.3529 Acc: 25.0000%\n",
      "\ttrain 20-10: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 20-11: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 20-12: Loss: 0.1956 Acc: 75.0000%\n",
      "\ttrain 20-13: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 20-14: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 20-15: Loss: 0.8612 Acc: 25.0000%\n",
      "\ttrain 20-16: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 20-17: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 20-18: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 20-19: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 20-20: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 20-21: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 20-22: Loss: 0.4427 Acc: 50.0000%\n",
      "\ttrain 20-23: Loss: 0.1043 Acc: 75.0000%\n",
      "\ttrain 20-24: Loss: 0.2528 Acc: 75.0000%\n",
      "\ttrain 20-25: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 20-26: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 20-27: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 20-28: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 20-29: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 20-30: Loss: 0.5421 Acc: 25.0000%\n",
      "\ttrain 20-31: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 20-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 20-33: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 20-34: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 20-35: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 20-36: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 20-37: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 20-38: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 20-39: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 20-40: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 20-41: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 20-42: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 20-43: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 20-44: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 20-45: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 20-46: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 20-47: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 20-48: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 20-49: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 20-50: Loss: 0.2254 Acc: 75.0000%\n",
      "\ttrain 20-51: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 20-52: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 20-53: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 20-54: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 20-55: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 20-56: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-57: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 20-58: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 20-59: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 20-60: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 20-61: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 20-62: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 20-63: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 20-64: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 20-65: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 20-66: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 20-67: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 20-68: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 20-69: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 20-70: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 20-71: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 20-72: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 20-73: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 20-74: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 20-75: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 20-76: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 20-77: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-78: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 20-79: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 20-80: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 20-81: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 20-82: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 20-83: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 20-84: Loss: 0.3171 Acc: 75.0000%\n",
      "\ttrain 20-85: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 20-86: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 20-87: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 20-88: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 20-89: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 20-90: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 20-91: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 20-92: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 20-93: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 20-94: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 20-95: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 20-96: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 20-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 20-98: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 20-99: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 20-100: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 20-101: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 20-102: Loss: 0.2550 Acc: 75.0000%\n",
      "\ttrain 20-103: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 20-104: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 20-105: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 20-106: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 20-107: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 20-108: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 20-109: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 20-110: Loss: 0.2069 Acc: 75.0000%\n",
      "\ttrain 20-111: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 20-112: Loss: 0.0848 Acc: 100.0000%\n",
      "\ttrain 20-113: Loss: 0.1739 Acc: 75.0000%\n",
      "\ttrain 20-114: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 20-115: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 20-116: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 20-117: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 20-118: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 20-119: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 20-120: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 20-121: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 20-122: Loss: 0.3548 Acc: 25.0000%\n",
      "\ttrain 20-123: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 20-124: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 20-125: Loss: 0.1529 Acc: 75.0000%\n",
      "\ttrain 20-126: Loss: 0.3458 Acc: 50.0000%\n",
      "\ttrain 20-127: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 20-128: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 20-129: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 20-130: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 20-131: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 20-132: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 20-133: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 20-134: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 20-135: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 20-136: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 20-137: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 20-138: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 20-139: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 20-140: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 20-141: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 20-142: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 20-143: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 20-144: Loss: 0.5032 Acc: 25.0000%\n",
      "\ttrain 20-145: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 20-146: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 20-147: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-148: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 20-149: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 20-150: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 20-151: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 20-152: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 20-153: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 20-154: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 20-155: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 20-156: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 20-157: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-158: Loss: 0.4600 Acc: 50.0000%\n",
      "\ttrain 20-159: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-160: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 20-161: Loss: 0.1479 Acc: 75.0000%\n",
      "\ttrain 20-162: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 20-163: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 20-164: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 20-165: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 20-166: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 20-167: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 20-168: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 20-169: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 20-170: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-171: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 20-172: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 20-173: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 20-174: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 20-175: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 20-176: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-177: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 20-178: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-179: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 20-180: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 20-181: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 20-182: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 20-183: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 20-184: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 20-185: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-186: Loss: 0.4119 Acc: 25.0000%\n",
      "\ttrain 20-187: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 20-188: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 20-189: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 20-190: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-191: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 20-192: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 20-193: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-194: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 20-195: Loss: 0.0096 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-196: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 20-197: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 20-198: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-199: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 20-200: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 20-201: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 20-202: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 20-203: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 20-204: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 20-205: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 20-206: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 20-207: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 20-208: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-209: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 20-210: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 20-211: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 20-212: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 20-213: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 20-214: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 20-215: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 20-216: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 20-217: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 20-218: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 20-219: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 20-220: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 20-221: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-222: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 20-223: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 20-224: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 20-225: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 20-226: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 20-227: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 20-228: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 20-229: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 20-230: Loss: 0.3544 Acc: 25.0000%\n",
      "\ttrain 20-231: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 20-232: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 20-233: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 20-234: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 20-235: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 20-236: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 20-237: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 20-238: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 20-239: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 20-240: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 20-241: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 20-242: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-243: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 20-244: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-245: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 20-1: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 20-2: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 20-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-4: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 20-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-6: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 20-7: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-9: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 20-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-11: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 20-12: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-14: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 20-15: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-16: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-17: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 20-18: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 20-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-20: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-22: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 20-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 20-26: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-27: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 20-28: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-29: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 20-30: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-31: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 20-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 20-33: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 20-34: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 20-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-36: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-37: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 20-38: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 20-39: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-42: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 20-43: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 20-44: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 20-45: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 20-47: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 20-49: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-50: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-51: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 20-52: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-53: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 20-54: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 20-55: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 20-56: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 20-57: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 20-58: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 20-59: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 20-60: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-62: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 20-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-64: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 20-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-67: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-68: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-69: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 20-70: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 20-71: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 20-72: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-74: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-75: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 20-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-79: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-80: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 20-81: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-83: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 20-84: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-88: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 20-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-90: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 20-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 20-92: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-93: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 20-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 20-95: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-96: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 20-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-98: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-99: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 20-100: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-101: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 20-102: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 20-103: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 20-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-105: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0493 Acc: 93.7755%\n",
      "\tvalidation Loss: 0.0023 Acc: 100.0000%\n",
      "Time passed 0h 11m 0s\n",
      "--------------------\n",
      "Epoch [21/40]:\n",
      "\ttrain 21-1: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 21-2: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 21-3: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 21-4: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 21-5: Loss: 0.2755 Acc: 75.0000%\n",
      "\ttrain 21-6: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 21-7: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 21-8: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 21-9: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 21-10: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 21-11: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-12: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 21-13: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 21-14: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 21-15: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 21-16: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-17: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 21-18: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 21-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 21-20: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 21-21: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 21-22: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 21-23: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 21-24: Loss: 0.0084 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-25: Loss: 0.3760 Acc: 75.0000%\n",
      "\ttrain 21-26: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 21-27: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 21-28: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 21-29: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 21-30: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 21-31: Loss: 0.1370 Acc: 50.0000%\n",
      "\ttrain 21-32: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 21-33: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 21-34: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-35: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 21-36: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-37: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 21-38: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 21-39: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 21-40: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 21-41: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 21-42: Loss: 0.1837 Acc: 75.0000%\n",
      "\ttrain 21-43: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 21-44: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 21-45: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-46: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 21-47: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 21-48: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 21-49: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 21-50: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-51: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 21-52: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 21-53: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 21-54: Loss: 0.0512 Acc: 75.0000%\n",
      "\ttrain 21-55: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 21-56: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 21-57: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 21-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-59: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 21-60: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 21-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 21-62: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 21-63: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 21-64: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 21-65: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 21-66: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 21-67: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 21-68: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 21-69: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 21-70: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 21-71: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 21-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-73: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 21-74: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 21-75: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 21-76: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 21-77: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 21-78: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 21-79: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 21-80: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 21-81: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 21-82: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 21-83: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 21-84: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 21-85: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 21-86: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 21-87: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 21-88: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 21-89: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 21-90: Loss: 0.1764 Acc: 75.0000%\n",
      "\ttrain 21-91: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 21-92: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 21-93: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 21-94: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 21-95: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 21-96: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 21-97: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 21-98: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 21-99: Loss: 0.1618 Acc: 75.0000%\n",
      "\ttrain 21-100: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-101: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 21-102: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 21-103: Loss: 0.0906 Acc: 100.0000%\n",
      "\ttrain 21-104: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 21-105: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 21-106: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 21-107: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 21-108: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 21-109: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 21-110: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-111: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 21-112: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-113: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 21-114: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 21-115: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 21-116: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 21-117: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-118: Loss: 0.1728 Acc: 75.0000%\n",
      "\ttrain 21-119: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 21-120: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 21-121: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 21-122: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 21-123: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 21-124: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 21-125: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 21-126: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 21-127: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 21-128: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 21-129: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 21-130: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 21-131: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-132: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 21-133: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 21-134: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-135: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 21-136: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 21-137: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 21-138: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-139: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 21-140: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 21-141: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 21-142: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 21-143: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 21-144: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 21-145: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 21-146: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 21-147: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 21-148: Loss: 0.0460 Acc: 75.0000%\n",
      "\ttrain 21-149: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 21-150: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 21-151: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-152: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 21-153: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 21-154: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 21-155: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 21-156: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 21-157: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 21-158: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 21-159: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 21-160: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-161: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 21-162: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 21-163: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 21-164: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 21-165: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 21-166: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 21-167: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 21-168: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-169: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 21-170: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 21-171: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 21-172: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 21-173: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 21-174: Loss: 0.4125 Acc: 50.0000%\n",
      "\ttrain 21-175: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 21-176: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 21-177: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-178: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 21-179: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 21-180: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 21-181: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 21-182: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 21-183: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 21-184: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 21-185: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 21-186: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 21-187: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 21-188: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 21-189: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 21-190: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 21-191: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-192: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 21-193: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 21-194: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 21-195: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 21-196: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 21-197: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 21-198: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-199: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 21-200: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 21-201: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 21-202: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 21-203: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 21-204: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 21-205: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 21-206: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 21-207: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 21-208: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 21-209: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-210: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 21-211: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-212: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-213: Loss: 0.2470 Acc: 75.0000%\n",
      "\ttrain 21-214: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 21-215: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 21-216: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 21-217: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 21-218: Loss: 0.0511 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-219: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 21-220: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 21-221: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 21-222: Loss: 0.2185 Acc: 75.0000%\n",
      "\ttrain 21-223: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 21-224: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 21-225: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 21-226: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 21-227: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-228: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 21-229: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 21-230: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 21-231: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-232: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 21-233: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-234: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 21-235: Loss: 0.2844 Acc: 75.0000%\n",
      "\ttrain 21-236: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 21-237: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 21-238: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 21-239: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 21-240: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 21-241: Loss: 0.1805 Acc: 75.0000%\n",
      "\ttrain 21-242: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 21-243: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-244: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 21-245: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 21-1: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-2: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 21-3: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 21-4: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 21-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-6: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-7: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 21-8: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 21-9: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 21-10: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-11: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 21-12: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-13: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 21-14: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-15: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 21-16: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 21-17: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 21-18: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-21: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 21-22: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 21-23: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-24: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 21-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 21-26: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-27: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 21-28: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 21-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-30: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 21-31: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 21-32: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 21-33: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 21-34: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 21-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-36: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-38: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 21-39: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-40: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 21-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-42: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-44: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 21-45: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 21-46: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-47: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 21-48: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 21-49: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 21-50: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 21-51: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 21-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-53: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-54: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 21-55: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 21-56: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-58: Loss: 0.0522 Acc: 75.0000%\n",
      "\tvalidation 21-59: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-60: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 21-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-62: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-63: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 21-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-65: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-66: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-67: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-68: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 21-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-70: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 21-71: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 21-72: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 21-73: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 21-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-76: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 21-77: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 21-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-79: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 21-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-81: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-82: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-84: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-85: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 21-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-87: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 21-88: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-89: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 21-90: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-91: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 21-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 21-97: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 21-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-99: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-100: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 21-101: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-102: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-103: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 21-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 21-105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0310 Acc: 96.2245%\n",
      "\tvalidation Loss: 0.0040 Acc: 99.7619%\n",
      "Time passed 0h 11m 33s\n",
      "--------------------\n",
      "Epoch [22/40]:\n",
      "\ttrain 22-1: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 22-2: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 22-3: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 22-4: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 22-5: Loss: 0.6026 Acc: 50.0000%\n",
      "\ttrain 22-6: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 22-7: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 22-8: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-9: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 22-10: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 22-11: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 22-12: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 22-13: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 22-14: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 22-15: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 22-16: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 22-17: Loss: 0.3636 Acc: 75.0000%\n",
      "\ttrain 22-18: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 22-19: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 22-20: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 22-21: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-22: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-23: Loss: 0.2150 Acc: 50.0000%\n",
      "\ttrain 22-24: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 22-25: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 22-26: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 22-27: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 22-28: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-29: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 22-30: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 22-31: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 22-32: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 22-33: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 22-34: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 22-35: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-36: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-37: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 22-38: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 22-39: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 22-40: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 22-41: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 22-42: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 22-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-44: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 22-45: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 22-46: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 22-47: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 22-48: Loss: 0.0138 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-49: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 22-50: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 22-51: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 22-52: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 22-53: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 22-54: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-55: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 22-56: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-57: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-58: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 22-59: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 22-60: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 22-61: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 22-62: Loss: 0.4914 Acc: 75.0000%\n",
      "\ttrain 22-63: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 22-64: Loss: 0.4891 Acc: 75.0000%\n",
      "\ttrain 22-65: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 22-66: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 22-67: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 22-68: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 22-69: Loss: 0.2440 Acc: 50.0000%\n",
      "\ttrain 22-70: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 22-71: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 22-72: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 22-73: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 22-74: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 22-75: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 22-76: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 22-77: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 22-78: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 22-79: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 22-80: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 22-81: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 22-82: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 22-83: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 22-84: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 22-85: Loss: 0.0630 Acc: 100.0000%\n",
      "\ttrain 22-86: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 22-87: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 22-88: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-89: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 22-90: Loss: 0.4880 Acc: 50.0000%\n",
      "\ttrain 22-91: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 22-92: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 22-93: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 22-94: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 22-95: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 22-96: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 22-97: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 22-98: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 22-99: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 22-100: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 22-101: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 22-102: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 22-103: Loss: 0.1915 Acc: 75.0000%\n",
      "\ttrain 22-104: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 22-105: Loss: 0.4840 Acc: 50.0000%\n",
      "\ttrain 22-106: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-107: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 22-108: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 22-109: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 22-110: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 22-111: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 22-112: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 22-113: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 22-114: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 22-115: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 22-116: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 22-117: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 22-118: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 22-119: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 22-120: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 22-121: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 22-122: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 22-123: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 22-124: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 22-125: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 22-126: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 22-127: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 22-128: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 22-129: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-130: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 22-131: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 22-132: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 22-133: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 22-134: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 22-135: Loss: 0.3745 Acc: 75.0000%\n",
      "\ttrain 22-136: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-137: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 22-138: Loss: 0.1011 Acc: 100.0000%\n",
      "\ttrain 22-139: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 22-140: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 22-141: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 22-142: Loss: 0.5531 Acc: 50.0000%\n",
      "\ttrain 22-143: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 22-144: Loss: 0.1931 Acc: 75.0000%\n",
      "\ttrain 22-145: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 22-146: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 22-147: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 22-148: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 22-149: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 22-150: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 22-151: Loss: 0.2390 Acc: 50.0000%\n",
      "\ttrain 22-152: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 22-153: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 22-154: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 22-155: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 22-156: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 22-157: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 22-158: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 22-159: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 22-160: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 22-161: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 22-162: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 22-163: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 22-164: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-165: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 22-166: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 22-167: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 22-168: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 22-169: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 22-170: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 22-171: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 22-172: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 22-173: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 22-174: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-175: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 22-176: Loss: 0.2266 Acc: 75.0000%\n",
      "\ttrain 22-177: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 22-178: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 22-179: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 22-180: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 22-181: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 22-182: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 22-183: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 22-184: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 22-185: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 22-186: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 22-187: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 22-188: Loss: 0.0463 Acc: 75.0000%\n",
      "\ttrain 22-189: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-190: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 22-191: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 22-192: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 22-193: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 22-194: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 22-195: Loss: 0.2613 Acc: 50.0000%\n",
      "\ttrain 22-196: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-197: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 22-198: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 22-199: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 22-200: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-201: Loss: 1.1862 Acc: 25.0000%\n",
      "\ttrain 22-202: Loss: 0.0534 Acc: 75.0000%\n",
      "\ttrain 22-203: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 22-204: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 22-205: Loss: 0.1647 Acc: 75.0000%\n",
      "\ttrain 22-206: Loss: 0.1921 Acc: 75.0000%\n",
      "\ttrain 22-207: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 22-208: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 22-209: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 22-210: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 22-211: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 22-212: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 22-213: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 22-214: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 22-215: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 22-216: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 22-217: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 22-218: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 22-219: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 22-220: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 22-221: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 22-222: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 22-223: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 22-224: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 22-225: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 22-226: Loss: 0.4312 Acc: 75.0000%\n",
      "\ttrain 22-227: Loss: 0.7335 Acc: 0.0000%\n",
      "\ttrain 22-228: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 22-229: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 22-230: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 22-231: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 22-232: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 22-233: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 22-234: Loss: 0.2280 Acc: 75.0000%\n",
      "\ttrain 22-235: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 22-236: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 22-237: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 22-238: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 22-239: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 22-240: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 22-241: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 22-242: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 22-243: Loss: 0.0113 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-244: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 22-245: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 22-1: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 22-2: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 22-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-4: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 22-5: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 22-6: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 22-7: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-8: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 22-9: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 22-10: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 22-11: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 22-12: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-13: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 22-14: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 22-15: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 22-16: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 22-17: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 22-18: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-19: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 22-20: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 22-21: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 22-22: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-23: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 22-24: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 22-25: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-26: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 22-27: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-28: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-29: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 22-30: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 22-31: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 22-32: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 22-33: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 22-34: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 22-35: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-37: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 22-38: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 22-39: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-40: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-41: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 22-42: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 22-43: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 22-44: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 22-45: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 22-46: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 22-47: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 22-48: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 22-49: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 22-50: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 22-53: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 22-54: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 22-55: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 22-56: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 22-57: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 22-58: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-59: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 22-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-62: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-63: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-64: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 22-65: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 22-66: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 22-67: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 22-68: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 22-69: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-70: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 22-71: Loss: 0.0416 Acc: 100.0000%\n",
      "\tvalidation 22-72: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 22-73: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 22-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-75: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-76: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 22-77: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 22-78: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 22-79: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-80: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 22-81: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 22-82: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-83: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 22-84: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 22-85: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 22-86: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 22-87: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 22-88: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 22-89: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 22-90: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-91: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-92: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 22-93: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 22-94: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 22-95: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-96: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 22-97: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 22-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-99: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 22-100: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 22-101: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 22-102: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 22-103: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 22-104: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 22-105: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0611 Acc: 93.4694%\n",
      "\tvalidation Loss: 0.0043 Acc: 100.0000%\n",
      "Time passed 0h 12m 7s\n",
      "--------------------\n",
      "Epoch [23/40]:\n",
      "\ttrain 23-1: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-2: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 23-3: Loss: 0.9287 Acc: 0.0000%\n",
      "\ttrain 23-4: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 23-5: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 23-6: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 23-7: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 23-8: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 23-9: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 23-10: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 23-11: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 23-12: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 23-13: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 23-14: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-15: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 23-16: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 23-17: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 23-18: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 23-19: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 23-20: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 23-21: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 23-22: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 23-23: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 23-24: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 23-25: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 23-26: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 23-27: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 23-28: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 23-29: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 23-30: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 23-31: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 23-32: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 23-33: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-34: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 23-35: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 23-36: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 23-37: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 23-38: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-39: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 23-40: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 23-41: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 23-42: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 23-43: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 23-44: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 23-45: Loss: 0.1987 Acc: 75.0000%\n",
      "\ttrain 23-46: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 23-47: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 23-48: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 23-49: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 23-50: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 23-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 23-52: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 23-53: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-54: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 23-55: Loss: 0.2517 Acc: 75.0000%\n",
      "\ttrain 23-56: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 23-57: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 23-58: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 23-59: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 23-60: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 23-61: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 23-62: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 23-63: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 23-64: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 23-65: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 23-66: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 23-67: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 23-68: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 23-69: Loss: 0.3930 Acc: 50.0000%\n",
      "\ttrain 23-70: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 23-71: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 23-72: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 23-73: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 23-74: Loss: 0.1436 Acc: 75.0000%\n",
      "\ttrain 23-75: Loss: 0.0253 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 23-76: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 23-77: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 23-78: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 23-79: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-80: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 23-81: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 23-82: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 23-83: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 23-84: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 23-85: Loss: 0.8008 Acc: 0.0000%\n",
      "\ttrain 23-86: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-87: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 23-88: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-89: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 23-90: Loss: 0.3091 Acc: 50.0000%\n",
      "\ttrain 23-91: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 23-92: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-93: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 23-94: Loss: 0.3646 Acc: 50.0000%\n",
      "\ttrain 23-95: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 23-96: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 23-97: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 23-98: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 23-99: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 23-100: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 23-101: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 23-102: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 23-103: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 23-104: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 23-105: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 23-106: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 23-107: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 23-108: Loss: 0.2047 Acc: 75.0000%\n",
      "\ttrain 23-109: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 23-110: Loss: 0.1742 Acc: 50.0000%\n",
      "\ttrain 23-111: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 23-112: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 23-113: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 23-114: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-115: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 23-116: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 23-117: Loss: 0.2417 Acc: 50.0000%\n",
      "\ttrain 23-118: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 23-119: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-120: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 23-121: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-122: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 23-123: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 23-124: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 23-125: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-126: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 23-127: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 23-128: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 23-129: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 23-130: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 23-131: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 23-132: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 23-133: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-134: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 23-135: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 23-136: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 23-137: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 23-138: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 23-139: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-140: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 23-141: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 23-142: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-143: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-144: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 23-145: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 23-146: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 23-147: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 23-148: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 23-149: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 23-150: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 23-151: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 23-152: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 23-153: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 23-154: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 23-155: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 23-156: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 23-157: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 23-158: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 23-159: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-160: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 23-161: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 23-162: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-163: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 23-164: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 23-165: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 23-166: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-167: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 23-168: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 23-169: Loss: 0.0603 Acc: 100.0000%\n",
      "\ttrain 23-170: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 23-171: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 23-172: Loss: 0.2963 Acc: 75.0000%\n",
      "\ttrain 23-173: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 23-174: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 23-175: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 23-176: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 23-177: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 23-178: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 23-179: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 23-180: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 23-181: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-182: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-183: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 23-184: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 23-185: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 23-186: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 23-187: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 23-188: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 23-189: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 23-190: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 23-191: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 23-192: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 23-193: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 23-194: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 23-195: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 23-196: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 23-197: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 23-198: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 23-199: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 23-200: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 23-201: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 23-202: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 23-203: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 23-204: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 23-205: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 23-206: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-207: Loss: 0.7692 Acc: 50.0000%\n",
      "\ttrain 23-208: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 23-209: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 23-210: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 23-211: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 23-212: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 23-213: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 23-214: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 23-215: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 23-216: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 23-217: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 23-218: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 23-219: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 23-220: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 23-221: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 23-222: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 23-223: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 23-224: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-225: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 23-226: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 23-227: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 23-228: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 23-229: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 23-230: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 23-231: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 23-232: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 23-233: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 23-234: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 23-235: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 23-236: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 23-237: Loss: 0.0501 Acc: 75.0000%\n",
      "\ttrain 23-238: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 23-239: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-240: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 23-241: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 23-242: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 23-243: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 23-244: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 23-245: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 23-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-2: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 23-3: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-4: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 23-5: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-6: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 23-7: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-8: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 23-9: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-10: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 23-11: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 23-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 23-14: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-15: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 23-16: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-19: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-20: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 23-21: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 23-22: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-23: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-24: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-25: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-26: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-27: Loss: 0.0007 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 23-28: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 23-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-30: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-31: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 23-32: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-33: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-34: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 23-35: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 23-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-37: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-38: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-39: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-41: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-43: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-46: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 23-47: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 23-48: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 23-49: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-50: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-52: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-53: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-55: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-56: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-59: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 23-60: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-62: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-64: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-66: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-67: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 23-68: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 23-69: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 23-70: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-72: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-73: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-74: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-75: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 23-76: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 23-77: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 23-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-81: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 23-82: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-83: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-85: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 23-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-88: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 23-89: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-92: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 23-93: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 23-94: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 23-95: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 23-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-98: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 23-99: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-100: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-101: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 23-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0449 Acc: 94.5918%\n",
      "\tvalidation Loss: 0.0014 Acc: 100.0000%\n",
      "Time passed 0h 12m 40s\n",
      "--------------------\n",
      "Epoch [24/40]:\n",
      "\ttrain 24-1: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 24-2: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-3: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 24-4: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 24-5: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-6: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 24-7: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 24-8: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-9: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 24-10: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 24-11: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 24-12: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 24-13: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 24-14: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-15: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-16: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-17: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 24-18: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-19: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 24-20: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-21: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 24-22: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 24-23: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-24: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-25: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 24-26: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 24-27: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 24-28: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 24-29: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 24-30: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-31: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-32: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 24-33: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 24-34: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 24-35: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 24-36: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 24-37: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 24-38: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 24-39: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 24-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-41: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 24-42: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-43: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 24-44: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-45: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 24-46: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-47: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 24-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-49: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 24-50: Loss: 0.2076 Acc: 75.0000%\n",
      "\ttrain 24-51: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 24-52: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-53: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-54: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 24-55: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 24-56: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 24-57: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-58: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 24-59: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 24-60: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 24-61: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 24-62: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-63: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 24-64: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 24-65: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 24-66: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 24-67: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 24-68: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-69: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-70: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 24-71: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 24-72: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 24-73: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 24-74: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 24-75: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 24-76: Loss: 0.1574 Acc: 75.0000%\n",
      "\ttrain 24-77: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-78: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-79: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-80: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 24-81: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-82: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-83: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-84: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-86: Loss: 0.2241 Acc: 50.0000%\n",
      "\ttrain 24-87: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 24-88: Loss: 0.0652 Acc: 75.0000%\n",
      "\ttrain 24-89: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-90: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-91: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-92: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 24-93: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 24-94: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 24-95: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 24-96: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 24-97: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 24-98: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 24-99: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 24-100: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 24-101: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 24-102: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 24-103: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-104: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 24-105: Loss: 0.0062 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-106: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 24-107: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 24-108: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-109: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 24-110: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 24-111: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 24-112: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 24-113: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-114: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 24-115: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 24-116: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 24-117: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 24-118: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 24-119: Loss: 0.4967 Acc: 50.0000%\n",
      "\ttrain 24-120: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-121: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-122: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 24-123: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 24-124: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 24-125: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-126: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-127: Loss: 0.2271 Acc: 75.0000%\n",
      "\ttrain 24-128: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 24-129: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 24-130: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 24-131: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 24-132: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-133: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 24-134: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 24-135: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-136: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 24-137: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 24-138: Loss: 0.0570 Acc: 75.0000%\n",
      "\ttrain 24-139: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 24-140: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 24-141: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 24-142: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 24-143: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 24-144: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 24-145: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 24-146: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-147: Loss: 0.7764 Acc: 50.0000%\n",
      "\ttrain 24-148: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 24-149: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 24-150: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 24-151: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 24-152: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-153: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 24-154: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-155: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 24-156: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 24-157: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 24-158: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-159: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 24-160: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 24-161: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 24-162: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 24-163: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 24-164: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 24-165: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 24-166: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 24-167: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 24-168: Loss: 0.0761 Acc: 75.0000%\n",
      "\ttrain 24-169: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 24-170: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 24-171: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 24-172: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 24-173: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-174: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 24-175: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 24-176: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 24-177: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 24-178: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 24-179: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 24-180: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 24-181: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-182: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 24-183: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-184: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-185: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 24-186: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 24-187: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-188: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 24-189: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 24-190: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 24-191: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 24-192: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 24-193: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 24-194: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 24-195: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 24-196: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 24-197: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-198: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 24-199: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-200: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-201: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 24-202: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-203: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-204: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 24-205: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 24-206: Loss: 0.7671 Acc: 25.0000%\n",
      "\ttrain 24-207: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-208: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-209: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-210: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 24-211: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 24-212: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 24-213: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 24-214: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 24-215: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 24-216: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 24-217: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-218: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 24-219: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 24-220: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 24-221: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-222: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 24-223: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-224: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 24-225: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-226: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-227: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-228: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 24-229: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 24-230: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 24-231: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 24-232: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 24-233: Loss: 0.6335 Acc: 75.0000%\n",
      "\ttrain 24-234: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-235: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 24-236: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 24-237: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 24-238: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-239: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 24-240: Loss: 0.7705 Acc: 50.0000%\n",
      "\ttrain 24-241: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 24-242: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 24-243: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 24-244: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 24-245: Loss: 0.1013 Acc: 75.0000%\n",
      "\tvalidation 24-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-2: Loss: 0.0315 Acc: 100.0000%\n",
      "\tvalidation 24-3: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-4: Loss: 0.0908 Acc: 75.0000%\n",
      "\tvalidation 24-5: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 24-6: Loss: 0.0370 Acc: 100.0000%\n",
      "\tvalidation 24-7: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-8: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 24-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-10: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-11: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 24-12: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 24-13: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 24-14: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-15: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-16: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 24-17: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 24-18: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 24-19: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 24-20: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 24-21: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 24-22: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-23: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 24-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-26: Loss: 0.0748 Acc: 75.0000%\n",
      "\tvalidation 24-27: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-29: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-30: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 24-31: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 24-32: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-33: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 24-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-35: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 24-36: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 24-37: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 24-38: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 24-39: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 24-40: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 24-41: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 24-42: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 24-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-44: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 24-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-46: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 24-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-49: Loss: 0.0012 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 24-50: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-51: Loss: 0.0973 Acc: 75.0000%\n",
      "\tvalidation 24-52: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 24-53: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 24-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-55: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 24-56: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 24-57: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 24-58: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 24-59: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 24-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-61: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 24-62: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 24-63: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 24-64: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 24-65: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 24-66: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 24-67: Loss: 0.1108 Acc: 75.0000%\n",
      "\tvalidation 24-68: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-69: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 24-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-71: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 24-72: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 24-73: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 24-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-75: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-76: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 24-77: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 24-78: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 24-79: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 24-80: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 24-81: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-82: Loss: 0.0579 Acc: 100.0000%\n",
      "\tvalidation 24-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-84: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 24-85: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 24-86: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 24-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-88: Loss: 0.0446 Acc: 100.0000%\n",
      "\tvalidation 24-89: Loss: 0.0589 Acc: 75.0000%\n",
      "\tvalidation 24-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-91: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 24-92: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 24-93: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 24-94: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 24-95: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 24-96: Loss: 0.0562 Acc: 75.0000%\n",
      "\tvalidation 24-97: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-98: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 24-99: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 24-100: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 24-101: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 24-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-103: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 24-104: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 24-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0365 Acc: 96.1224%\n",
      "\tvalidation Loss: 0.0116 Acc: 98.5714%\n",
      "Time passed 0h 13m 13s\n",
      "--------------------\n",
      "Epoch [25/40]:\n",
      "\ttrain 25-1: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-2: Loss: 0.1480 Acc: 50.0000%\n",
      "\ttrain 25-3: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 25-4: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 25-5: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 25-6: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-7: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-8: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 25-9: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 25-10: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 25-11: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 25-12: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 25-13: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 25-14: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 25-15: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 25-16: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 25-17: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 25-18: Loss: 0.2479 Acc: 75.0000%\n",
      "\ttrain 25-19: Loss: 0.2692 Acc: 50.0000%\n",
      "\ttrain 25-20: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 25-21: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-22: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 25-23: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 25-24: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-25: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 25-26: Loss: 0.1700 Acc: 50.0000%\n",
      "\ttrain 25-27: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 25-28: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 25-29: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 25-30: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 25-31: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 25-32: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 25-33: Loss: 0.1670 Acc: 50.0000%\n",
      "\ttrain 25-34: Loss: 0.1637 Acc: 75.0000%\n",
      "\ttrain 25-35: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-36: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 25-37: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-38: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 25-39: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 25-40: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 25-41: Loss: 0.1628 Acc: 75.0000%\n",
      "\ttrain 25-42: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 25-43: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 25-44: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 25-45: Loss: 0.2597 Acc: 75.0000%\n",
      "\ttrain 25-46: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 25-47: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-48: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 25-49: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 25-50: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-51: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 25-52: Loss: 0.4736 Acc: 25.0000%\n",
      "\ttrain 25-53: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-54: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 25-55: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 25-56: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 25-57: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 25-58: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 25-59: Loss: 0.1605 Acc: 75.0000%\n",
      "\ttrain 25-60: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-61: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 25-62: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 25-63: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 25-64: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 25-65: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 25-66: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 25-67: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-68: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 25-69: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-70: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 25-71: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 25-72: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 25-73: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-74: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-75: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 25-76: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 25-77: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 25-78: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 25-79: Loss: 0.2168 Acc: 50.0000%\n",
      "\ttrain 25-80: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 25-81: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 25-82: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 25-83: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 25-84: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 25-85: Loss: 0.9211 Acc: 25.0000%\n",
      "\ttrain 25-86: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 25-87: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 25-88: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-89: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 25-90: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 25-91: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 25-92: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 25-93: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 25-94: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 25-95: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 25-96: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 25-97: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 25-98: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 25-99: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 25-100: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 25-101: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 25-102: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 25-103: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-104: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-105: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-106: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 25-107: Loss: 0.4255 Acc: 75.0000%\n",
      "\ttrain 25-108: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-109: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 25-110: Loss: 0.2372 Acc: 25.0000%\n",
      "\ttrain 25-111: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 25-112: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 25-113: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 25-114: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 25-115: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 25-116: Loss: 0.4196 Acc: 25.0000%\n",
      "\ttrain 25-117: Loss: 0.1748 Acc: 50.0000%\n",
      "\ttrain 25-118: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 25-119: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 25-120: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-121: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-122: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-123: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 25-124: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 25-125: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 25-126: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 25-127: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-128: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 25-129: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 25-130: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 25-131: Loss: 0.0051 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-132: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 25-133: Loss: 0.2882 Acc: 75.0000%\n",
      "\ttrain 25-134: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 25-135: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 25-136: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 25-137: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 25-138: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 25-139: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 25-140: Loss: 0.3667 Acc: 75.0000%\n",
      "\ttrain 25-141: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 25-142: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 25-143: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-144: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-145: Loss: 0.7642 Acc: 25.0000%\n",
      "\ttrain 25-146: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 25-147: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 25-148: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 25-149: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 25-150: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 25-151: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 25-152: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-153: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 25-154: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-155: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 25-156: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 25-157: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 25-158: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 25-159: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-160: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 25-161: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-162: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-163: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 25-164: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 25-165: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 25-166: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 25-167: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 25-168: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 25-169: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 25-170: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 25-171: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 25-172: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 25-173: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 25-174: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 25-175: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 25-176: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 25-177: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 25-178: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 25-179: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-180: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-181: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 25-182: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 25-183: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 25-184: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-185: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-186: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-187: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-188: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 25-189: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 25-190: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 25-191: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-192: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 25-193: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 25-194: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 25-195: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 25-196: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 25-197: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 25-198: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-199: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 25-200: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 25-201: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 25-202: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-203: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-204: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-205: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 25-206: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 25-207: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 25-208: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 25-209: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 25-210: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 25-211: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 25-212: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 25-213: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-214: Loss: 0.3782 Acc: 50.0000%\n",
      "\ttrain 25-215: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 25-216: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 25-217: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-218: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 25-219: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 25-220: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 25-221: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-222: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 25-223: Loss: 0.0898 Acc: 100.0000%\n",
      "\ttrain 25-224: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 25-225: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 25-226: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-227: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 25-228: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 25-229: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 25-230: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 25-231: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 25-232: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-233: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 25-234: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 25-235: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 25-236: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-237: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 25-238: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 25-239: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 25-240: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 25-241: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 25-242: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 25-243: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 25-244: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 25-245: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 25-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-2: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 25-3: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-4: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-5: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 25-6: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-7: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-8: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 25-9: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 25-10: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 25-11: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-13: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-14: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-15: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-17: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-18: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-20: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-26: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-27: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-28: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-29: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-30: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 25-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-32: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-34: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-38: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-39: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-40: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 25-41: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-44: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 25-45: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 25-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-47: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-49: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-50: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-52: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-55: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 25-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-62: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-65: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 25-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-67: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-72: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 25-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-74: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 25-75: Loss: 0.0035 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 25-76: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 25-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-78: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 25-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-83: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 25-84: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-87: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 25-88: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-89: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-93: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-94: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 25-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-96: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-100: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 25-103: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 25-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-105: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0446 Acc: 94.3878%\n",
      "\tvalidation Loss: 0.0014 Acc: 100.0000%\n",
      "Time passed 0h 13m 47s\n",
      "--------------------\n",
      "Epoch [26/40]:\n",
      "\ttrain 26-1: Loss: 0.3645 Acc: 50.0000%\n",
      "\ttrain 26-2: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 26-3: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 26-4: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 26-5: Loss: 0.5201 Acc: 25.0000%\n",
      "\ttrain 26-6: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-7: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 26-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 26-9: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 26-10: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-11: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 26-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-13: Loss: 0.0527 Acc: 75.0000%\n",
      "\ttrain 26-14: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 26-15: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 26-16: Loss: 0.0626 Acc: 75.0000%\n",
      "\ttrain 26-17: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 26-18: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 26-19: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 26-20: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-21: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 26-22: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 26-23: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-24: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 26-25: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 26-26: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 26-27: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 26-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-29: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 26-30: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 26-31: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 26-32: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 26-33: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-34: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 26-35: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 26-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 26-37: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 26-38: Loss: 0.5216 Acc: 50.0000%\n",
      "\ttrain 26-39: Loss: 0.4675 Acc: 75.0000%\n",
      "\ttrain 26-40: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 26-41: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-42: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 26-43: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 26-44: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-45: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 26-46: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 26-47: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-48: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 26-49: Loss: 0.0575 Acc: 75.0000%\n",
      "\ttrain 26-50: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 26-51: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 26-52: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 26-53: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 26-54: Loss: 0.5938 Acc: 0.0000%\n",
      "\ttrain 26-55: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 26-56: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-57: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-58: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 26-59: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-60: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 26-61: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 26-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 26-63: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 26-64: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 26-65: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-66: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 26-67: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 26-68: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 26-69: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 26-70: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-71: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 26-72: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 26-73: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 26-74: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 26-75: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 26-76: Loss: 0.1022 Acc: 100.0000%\n",
      "\ttrain 26-77: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-78: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 26-79: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 26-80: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 26-81: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 26-82: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 26-83: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 26-84: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 26-85: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 26-86: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 26-87: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 26-88: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 26-89: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 26-90: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 26-91: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 26-92: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 26-93: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 26-94: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 26-95: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 26-96: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 26-97: Loss: 0.4211 Acc: 50.0000%\n",
      "\ttrain 26-98: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-99: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 26-100: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-101: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 26-102: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 26-103: Loss: 0.1437 Acc: 75.0000%\n",
      "\ttrain 26-104: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 26-105: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 26-106: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-107: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-108: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-109: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 26-110: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 26-111: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-112: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-113: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 26-114: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-115: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-116: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 26-117: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 26-118: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-119: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 26-120: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 26-121: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-122: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 26-123: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-124: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 26-125: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 26-126: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 26-127: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-128: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 26-129: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 26-130: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-131: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 26-132: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 26-133: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 26-134: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 26-135: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 26-136: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 26-137: Loss: 0.1646 Acc: 75.0000%\n",
      "\ttrain 26-138: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 26-139: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 26-140: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-141: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 26-142: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-143: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-144: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 26-145: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 26-146: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-147: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-148: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 26-149: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 26-150: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 26-151: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 26-152: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 26-153: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 26-154: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 26-155: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 26-156: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 26-157: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 26-158: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 26-159: Loss: 0.0051 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-160: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-161: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 26-162: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 26-163: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-164: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 26-165: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 26-166: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 26-167: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 26-168: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 26-169: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 26-170: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 26-171: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 26-172: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 26-173: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 26-174: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 26-175: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-176: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-177: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 26-178: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 26-179: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 26-180: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 26-181: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 26-182: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 26-183: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 26-184: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-185: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-186: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 26-187: Loss: 0.4975 Acc: 25.0000%\n",
      "\ttrain 26-188: Loss: 0.3033 Acc: 50.0000%\n",
      "\ttrain 26-189: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 26-190: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 26-191: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 26-192: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 26-193: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 26-194: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 26-195: Loss: 0.2838 Acc: 50.0000%\n",
      "\ttrain 26-196: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 26-197: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 26-198: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 26-199: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 26-200: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-201: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 26-202: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 26-203: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 26-204: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-205: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 26-206: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 26-207: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 26-208: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 26-209: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 26-210: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 26-211: Loss: 0.1604 Acc: 75.0000%\n",
      "\ttrain 26-212: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 26-213: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 26-214: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 26-215: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 26-216: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 26-217: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 26-218: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 26-219: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 26-220: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 26-221: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 26-222: Loss: 0.1357 Acc: 75.0000%\n",
      "\ttrain 26-223: Loss: 0.1359 Acc: 50.0000%\n",
      "\ttrain 26-224: Loss: 0.2075 Acc: 75.0000%\n",
      "\ttrain 26-225: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 26-226: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-227: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 26-228: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 26-229: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 26-230: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 26-231: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 26-232: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 26-233: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 26-234: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 26-235: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 26-236: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 26-237: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 26-238: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 26-239: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 26-240: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 26-241: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 26-242: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-243: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-244: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-245: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 26-1: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 26-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-3: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-5: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 26-6: Loss: 0.0230 Acc: 100.0000%\n",
      "\tvalidation 26-7: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-8: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 26-9: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 26-10: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-11: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-12: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-13: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 26-14: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 26-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-16: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 26-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-18: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-19: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 26-20: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 26-21: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 26-22: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 26-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-24: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 26-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-26: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-27: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 26-28: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 26-29: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 26-30: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 26-31: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 26-32: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 26-33: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 26-34: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 26-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-36: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-37: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-38: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 26-39: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 26-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-41: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-43: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 26-44: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 26-45: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 26-46: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-47: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-48: Loss: 0.0469 Acc: 75.0000%\n",
      "\tvalidation 26-49: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-50: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 26-51: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 26-52: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-53: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 26-54: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 26-55: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 26-56: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 26-57: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 26-58: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 26-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-60: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 26-61: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-64: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 26-65: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 26-66: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-71: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-75: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-76: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 26-77: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-79: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 26-80: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-81: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 26-82: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 26-83: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-84: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-85: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 26-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-87: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-88: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-89: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-90: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-92: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-93: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-94: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 26-97: Loss: 0.0059 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 26-98: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 26-99: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 26-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-101: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-102: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 26-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-105: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0452 Acc: 93.6735%\n",
      "\tvalidation Loss: 0.0037 Acc: 99.7619%\n",
      "Time passed 0h 14m 21s\n",
      "--------------------\n",
      "Epoch [27/40]:\n",
      "\ttrain 27-1: Loss: 0.3469 Acc: 50.0000%\n",
      "\ttrain 27-2: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 27-3: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 27-4: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 27-5: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-6: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 27-7: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 27-8: Loss: 0.5697 Acc: 25.0000%\n",
      "\ttrain 27-9: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 27-10: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 27-11: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 27-12: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 27-13: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 27-14: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-15: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 27-16: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 27-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 27-18: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-19: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 27-20: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 27-21: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-22: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 27-23: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 27-24: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 27-25: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 27-26: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 27-27: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 27-28: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 27-29: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 27-30: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 27-31: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 27-32: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 27-33: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 27-34: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 27-35: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 27-36: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-37: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 27-38: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-39: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 27-40: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 27-41: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 27-42: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-43: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-44: Loss: 0.1186 Acc: 75.0000%\n",
      "\ttrain 27-45: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-46: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 27-47: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 27-48: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 27-49: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 27-50: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 27-51: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 27-52: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 27-53: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 27-54: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 27-55: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 27-56: Loss: 0.7132 Acc: 50.0000%\n",
      "\ttrain 27-57: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 27-58: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 27-59: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 27-60: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 27-61: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 27-62: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 27-63: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-64: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 27-65: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 27-66: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 27-67: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 27-68: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 27-69: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 27-70: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 27-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-72: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 27-73: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 27-74: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-75: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 27-76: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 27-77: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 27-78: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 27-79: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 27-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 27-81: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 27-82: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 27-83: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 27-84: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 27-85: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 27-86: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-87: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-88: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 27-89: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 27-90: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 27-91: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 27-93: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-94: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 27-95: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-96: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 27-97: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 27-98: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 27-99: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 27-100: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 27-101: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 27-102: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 27-103: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 27-104: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 27-105: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 27-106: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-107: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 27-108: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 27-109: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 27-110: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 27-111: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 27-112: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 27-113: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 27-114: Loss: 0.1604 Acc: 50.0000%\n",
      "\ttrain 27-115: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 27-116: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 27-117: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 27-118: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-119: Loss: 0.6898 Acc: 50.0000%\n",
      "\ttrain 27-120: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-121: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 27-122: Loss: 0.5953 Acc: 75.0000%\n",
      "\ttrain 27-123: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-124: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 27-125: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 27-126: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 27-127: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 27-128: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 27-129: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-130: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 27-131: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 27-132: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 27-133: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 27-134: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-135: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-136: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 27-137: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 27-138: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 27-139: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 27-140: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 27-141: Loss: 0.2143 Acc: 75.0000%\n",
      "\ttrain 27-142: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 27-143: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 27-144: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 27-145: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-146: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 27-147: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 27-148: Loss: 0.3648 Acc: 75.0000%\n",
      "\ttrain 27-149: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 27-150: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 27-151: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-152: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-153: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 27-154: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 27-155: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 27-156: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 27-157: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 27-158: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 27-159: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 27-160: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 27-161: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-162: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 27-163: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 27-164: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 27-165: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 27-166: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 27-167: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 27-168: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 27-169: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 27-170: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 27-171: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 27-172: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 27-173: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 27-174: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-175: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 27-176: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-177: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 27-178: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 27-179: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 27-180: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 27-181: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 27-182: Loss: 0.0332 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-183: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 27-184: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-185: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 27-186: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 27-187: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 27-188: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 27-189: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 27-190: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 27-191: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 27-192: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 27-193: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-194: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 27-195: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 27-196: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 27-197: Loss: 0.8783 Acc: 25.0000%\n",
      "\ttrain 27-198: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-199: Loss: 0.1937 Acc: 50.0000%\n",
      "\ttrain 27-200: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-201: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 27-202: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 27-203: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-204: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 27-205: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-206: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 27-207: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 27-208: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 27-209: Loss: 0.2660 Acc: 75.0000%\n",
      "\ttrain 27-210: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 27-211: Loss: 0.1762 Acc: 75.0000%\n",
      "\ttrain 27-212: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 27-213: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 27-214: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 27-215: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 27-216: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-217: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 27-218: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-219: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 27-220: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 27-221: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 27-222: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 27-223: Loss: 0.0725 Acc: 100.0000%\n",
      "\ttrain 27-224: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 27-225: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 27-226: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-227: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 27-228: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 27-229: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-230: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 27-231: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-232: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 27-233: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 27-234: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 27-235: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 27-236: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 27-237: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 27-238: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 27-239: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 27-240: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-241: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 27-242: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-243: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 27-244: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 27-245: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 27-1: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 27-4: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 27-5: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-7: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-10: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 27-11: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-12: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-14: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 27-15: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-16: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 27-17: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-19: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-20: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-21: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 27-22: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-23: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-25: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-26: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-27: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-29: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-30: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-32: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-33: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 27-34: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-35: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 27-36: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 27-37: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-38: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 27-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-41: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-42: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 27-43: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-45: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-47: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-48: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-50: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 27-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-52: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 27-53: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-55: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-56: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-57: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-58: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 27-59: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-60: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 27-61: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-62: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-63: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-66: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 27-67: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-72: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-73: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-74: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-75: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-76: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-77: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 27-78: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-79: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-80: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-82: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 27-83: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-84: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 27-85: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-86: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-87: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-88: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-89: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-90: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 27-91: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-92: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-95: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-96: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 27-102: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 27-103: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-104: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-105: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0422 Acc: 95.1020%\n",
      "\tvalidation Loss: 0.0012 Acc: 100.0000%\n",
      "Time passed 0h 14m 54s\n",
      "--------------------\n",
      "Epoch [28/40]:\n",
      "\ttrain 28-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 28-2: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 28-3: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 28-4: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 28-5: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 28-6: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-7: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 28-8: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 28-9: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 28-10: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 28-11: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 28-12: Loss: 0.0042 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-13: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 28-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-15: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-16: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 28-17: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-18: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 28-19: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-20: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-21: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 28-22: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-23: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 28-24: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 28-25: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-26: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 28-27: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 28-28: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 28-29: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 28-30: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 28-31: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 28-32: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-33: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 28-34: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 28-35: Loss: 0.2047 Acc: 75.0000%\n",
      "\ttrain 28-36: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 28-37: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 28-38: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 28-39: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 28-40: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 28-41: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-42: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-43: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 28-44: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-45: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 28-46: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 28-47: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 28-48: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 28-49: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 28-50: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 28-51: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 28-52: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 28-53: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 28-54: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 28-55: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-56: Loss: 0.4498 Acc: 25.0000%\n",
      "\ttrain 28-57: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 28-58: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 28-59: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 28-60: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 28-61: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 28-62: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 28-63: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 28-64: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 28-65: Loss: 0.2147 Acc: 75.0000%\n",
      "\ttrain 28-66: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 28-67: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-68: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 28-69: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 28-70: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 28-71: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 28-72: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-73: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-74: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 28-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-76: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 28-77: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 28-78: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 28-79: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-80: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 28-81: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 28-82: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 28-83: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-84: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-85: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 28-86: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 28-87: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 28-88: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 28-89: Loss: 0.5064 Acc: 50.0000%\n",
      "\ttrain 28-90: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 28-91: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 28-92: Loss: 0.2086 Acc: 75.0000%\n",
      "\ttrain 28-93: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 28-94: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-95: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 28-96: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 28-97: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-98: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-99: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 28-100: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 28-101: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 28-102: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-103: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 28-104: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 28-105: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 28-106: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-107: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 28-108: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 28-109: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 28-110: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-111: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-112: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 28-113: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 28-114: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 28-115: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 28-116: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 28-117: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 28-118: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 28-119: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-120: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 28-121: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-122: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-123: Loss: 0.4633 Acc: 50.0000%\n",
      "\ttrain 28-124: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 28-125: Loss: 0.2324 Acc: 75.0000%\n",
      "\ttrain 28-126: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 28-127: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-128: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 28-129: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 28-130: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-131: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 28-132: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 28-133: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 28-134: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-135: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 28-136: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 28-137: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 28-138: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 28-139: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 28-140: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 28-141: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 28-142: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 28-143: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 28-144: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 28-145: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 28-146: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 28-147: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 28-148: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 28-149: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 28-150: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 28-151: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-152: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 28-153: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 28-154: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-155: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-156: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 28-157: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 28-158: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 28-159: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 28-160: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-161: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 28-162: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 28-163: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 28-164: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-165: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 28-166: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 28-167: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-168: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-169: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-170: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-171: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-172: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-173: Loss: 0.6634 Acc: 25.0000%\n",
      "\ttrain 28-174: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-175: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 28-176: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 28-177: Loss: 1.0848 Acc: 25.0000%\n",
      "\ttrain 28-178: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-179: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 28-180: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 28-181: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 28-182: Loss: 0.0467 Acc: 75.0000%\n",
      "\ttrain 28-183: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 28-184: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 28-185: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 28-186: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-187: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 28-188: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 28-189: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 28-190: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-191: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 28-192: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-193: Loss: 0.4907 Acc: 50.0000%\n",
      "\ttrain 28-194: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 28-195: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 28-196: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 28-197: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 28-198: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 28-199: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 28-200: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 28-201: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-202: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 28-203: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 28-204: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 28-205: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 28-206: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 28-207: Loss: 0.0021 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-208: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-209: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 28-210: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-211: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 28-212: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 28-213: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-214: Loss: 0.1552 Acc: 50.0000%\n",
      "\ttrain 28-215: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-216: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 28-217: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 28-218: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 28-219: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 28-220: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-221: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 28-222: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 28-223: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 28-224: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 28-225: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-226: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-227: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 28-228: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 28-229: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-230: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-231: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 28-232: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 28-233: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 28-234: Loss: 0.2605 Acc: 75.0000%\n",
      "\ttrain 28-235: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 28-236: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 28-237: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 28-238: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-239: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 28-240: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 28-241: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 28-242: Loss: 0.0473 Acc: 75.0000%\n",
      "\ttrain 28-243: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-244: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 28-245: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 28-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-2: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-5: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 28-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-8: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-9: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 28-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-11: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 28-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-14: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 28-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-16: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 28-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-19: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 28-20: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 28-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-22: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 28-23: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 28-24: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-26: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 28-27: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 28-28: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-30: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-32: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-33: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 28-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-38: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-40: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 28-41: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-43: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 28-44: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-46: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 28-47: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-49: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 28-50: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 28-51: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-52: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 28-53: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 28-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-55: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 28-56: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-57: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-58: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 28-59: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-60: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-62: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 28-63: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 28-64: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 28-65: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 28-66: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-68: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 28-69: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 28-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-72: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-73: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-75: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 28-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-77: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 28-78: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-81: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-82: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-83: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 28-85: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-88: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 28-89: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 28-90: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-91: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 28-92: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-93: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 28-94: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 28-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 28-97: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 28-98: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 28-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-100: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-101: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-102: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-103: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 28-104: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 28-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0388 Acc: 95.3061%\n",
      "\tvalidation Loss: 0.0031 Acc: 100.0000%\n",
      "Time passed 0h 15m 27s\n",
      "--------------------\n",
      "Epoch [29/40]:\n",
      "\ttrain 29-1: Loss: 0.1453 Acc: 75.0000%\n",
      "\ttrain 29-2: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 29-3: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 29-4: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 29-5: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-6: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 29-7: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 29-8: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 29-9: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 29-10: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 29-11: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 29-12: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 29-13: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 29-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-15: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 29-16: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 29-17: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 29-18: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-19: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 29-20: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-21: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 29-22: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 29-23: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 29-24: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 29-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-27: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 29-28: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 29-29: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 29-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-31: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 29-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 29-33: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-35: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 29-36: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 29-37: Loss: 0.0079 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-38: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-39: Loss: 0.0556 Acc: 75.0000%\n",
      "\ttrain 29-40: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 29-41: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 29-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-43: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 29-44: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 29-45: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 29-46: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 29-47: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 29-48: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-49: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-50: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 29-51: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 29-52: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 29-53: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 29-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-55: Loss: 1.0632 Acc: 50.0000%\n",
      "\ttrain 29-56: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-57: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-58: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-59: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 29-60: Loss: 0.3025 Acc: 75.0000%\n",
      "\ttrain 29-61: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-62: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 29-63: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 29-64: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 29-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-66: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-67: Loss: 0.3977 Acc: 50.0000%\n",
      "\ttrain 29-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-69: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 29-70: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 29-71: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 29-72: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 29-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-74: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 29-75: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 29-76: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-77: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-78: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 29-79: Loss: 0.2971 Acc: 75.0000%\n",
      "\ttrain 29-80: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 29-81: Loss: 0.4052 Acc: 75.0000%\n",
      "\ttrain 29-82: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 29-83: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 29-84: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 29-85: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 29-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-87: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 29-88: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-89: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-90: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-91: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 29-92: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 29-93: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 29-94: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-95: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-96: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 29-97: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-98: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 29-99: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 29-100: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-101: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 29-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-103: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-104: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 29-105: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 29-106: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 29-107: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-108: Loss: 0.1656 Acc: 75.0000%\n",
      "\ttrain 29-109: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 29-110: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 29-111: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 29-112: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 29-113: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 29-114: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 29-115: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 29-116: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 29-117: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-118: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-119: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 29-120: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 29-121: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-122: Loss: 0.0526 Acc: 75.0000%\n",
      "\ttrain 29-123: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-124: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 29-125: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 29-126: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 29-127: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 29-128: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 29-129: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 29-130: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 29-131: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-132: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 29-133: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 29-134: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 29-135: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 29-136: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-137: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 29-138: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-139: Loss: 0.2818 Acc: 50.0000%\n",
      "\ttrain 29-140: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 29-141: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-142: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 29-143: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 29-144: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-145: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 29-146: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 29-147: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-148: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-149: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 29-150: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 29-151: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-152: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-153: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 29-154: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 29-155: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 29-156: Loss: 0.1678 Acc: 75.0000%\n",
      "\ttrain 29-157: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-158: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-159: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 29-160: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-161: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 29-162: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-163: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-164: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 29-165: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-166: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 29-167: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 29-168: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-169: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-170: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-171: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 29-172: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 29-173: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-174: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 29-175: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-176: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 29-177: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 29-178: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-179: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 29-180: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 29-181: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 29-182: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 29-183: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 29-184: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-185: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-186: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-187: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 29-188: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 29-189: Loss: 0.0802 Acc: 100.0000%\n",
      "\ttrain 29-190: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-191: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 29-192: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-193: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-194: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-195: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-196: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 29-197: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-198: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 29-199: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 29-200: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 29-201: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-202: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-203: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-204: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-205: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-206: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-207: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-208: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 29-209: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-210: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-211: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-212: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 29-213: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 29-214: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 29-215: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 29-216: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 29-217: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 29-218: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 29-219: Loss: 0.0879 Acc: 100.0000%\n",
      "\ttrain 29-220: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 29-221: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 29-222: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-223: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 29-224: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-225: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-226: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-227: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 29-228: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-229: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 29-230: Loss: 0.0039 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-231: Loss: 0.2751 Acc: 75.0000%\n",
      "\ttrain 29-232: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-233: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 29-234: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-235: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 29-236: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-237: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-238: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 29-239: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 29-240: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-241: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 29-242: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-243: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 29-244: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 29-245: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-3: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-4: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 29-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-6: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-13: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-16: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-18: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-19: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 29-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-21: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-25: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 29-26: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 29-27: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-28: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-31: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-33: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-35: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-36: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-37: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-38: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 29-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-40: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-45: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-46: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-48: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-50: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-51: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-52: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-53: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-54: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-55: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-56: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-58: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 29-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-62: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-63: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-65: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-66: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-69: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-72: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-73: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-74: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 29-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-77: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-81: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-87: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-89: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-92: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 29-93: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-95: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-96: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-99: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-101: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-104: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0315 Acc: 96.9388%\n",
      "\tvalidation Loss: 0.0008 Acc: 100.0000%\n",
      "Time passed 0h 16m 1s\n",
      "--------------------\n",
      "Epoch [30/40]:\n",
      "\ttrain 30-1: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-2: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 30-3: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-4: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 30-5: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 30-6: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 30-7: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-8: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-9: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-10: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-11: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 30-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-13: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-14: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 30-15: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-16: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 30-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-18: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 30-19: Loss: 0.9293 Acc: 50.0000%\n",
      "\ttrain 30-20: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-21: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-22: Loss: 0.8113 Acc: 25.0000%\n",
      "\ttrain 30-23: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 30-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-25: Loss: 0.1825 Acc: 75.0000%\n",
      "\ttrain 30-26: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 30-27: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 30-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-29: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-30: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-31: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-32: Loss: 0.3330 Acc: 25.0000%\n",
      "\ttrain 30-33: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 30-34: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 30-35: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 30-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 30-37: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-38: Loss: 0.6397 Acc: 50.0000%\n",
      "\ttrain 30-39: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-40: Loss: 0.1414 Acc: 75.0000%\n",
      "\ttrain 30-41: Loss: 0.1101 Acc: 50.0000%\n",
      "\ttrain 30-42: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 30-43: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 30-44: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 30-45: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 30-46: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-47: Loss: 0.1040 Acc: 100.0000%\n",
      "\ttrain 30-48: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 30-49: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 30-50: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-51: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 30-52: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 30-53: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 30-54: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 30-55: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 30-56: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-57: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 30-58: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-59: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 30-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-61: Loss: 0.0018 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 30-62: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-63: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-64: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 30-65: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-67: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 30-68: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-69: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 30-70: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 30-71: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-72: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 30-73: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 30-74: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 30-75: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 30-76: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-77: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-78: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 30-79: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-80: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-81: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-82: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 30-83: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-84: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-85: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 30-86: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-87: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 30-88: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 30-89: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 30-90: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-91: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-92: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 30-93: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 30-94: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-95: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-97: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 30-98: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-99: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 30-100: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-101: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-102: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 30-103: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-104: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 30-105: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 30-106: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-107: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 30-108: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-109: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 30-110: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-111: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 30-112: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 30-113: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-114: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 30-115: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 30-116: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-117: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 30-118: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-119: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 30-120: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 30-121: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-122: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-123: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-124: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 30-125: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 30-126: Loss: 0.2170 Acc: 75.0000%\n",
      "\ttrain 30-127: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 30-128: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 30-129: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-130: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-131: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-132: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-133: Loss: 0.2510 Acc: 50.0000%\n",
      "\ttrain 30-134: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-135: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 30-136: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 30-137: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-138: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 30-139: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-140: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 30-141: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 30-142: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 30-143: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-144: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 30-145: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 30-146: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 30-147: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 30-148: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-149: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 30-150: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-151: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 30-152: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 30-153: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 30-154: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-155: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-156: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 30-157: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-158: Loss: 0.2945 Acc: 75.0000%\n",
      "\ttrain 30-159: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-160: Loss: 0.2516 Acc: 75.0000%\n",
      "\ttrain 30-161: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-162: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-163: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 30-164: Loss: 0.2250 Acc: 75.0000%\n",
      "\ttrain 30-165: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 30-166: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-167: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 30-168: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 30-169: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 30-170: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 30-171: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 30-172: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-173: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-174: Loss: 0.1919 Acc: 75.0000%\n",
      "\ttrain 30-175: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-176: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-177: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-178: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 30-179: Loss: 0.2760 Acc: 75.0000%\n",
      "\ttrain 30-180: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 30-181: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-182: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 30-183: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 30-184: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-185: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 30-186: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 30-187: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-188: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 30-189: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-190: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 30-191: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 30-192: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-193: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-194: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 30-195: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 30-196: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 30-197: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 30-198: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-199: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-200: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 30-201: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 30-202: Loss: 0.1959 Acc: 50.0000%\n",
      "\ttrain 30-203: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-204: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 30-205: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 30-206: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 30-207: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 30-208: Loss: 0.3390 Acc: 75.0000%\n",
      "\ttrain 30-209: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 30-210: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-211: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 30-212: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-213: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 30-214: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-215: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-216: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 30-217: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-218: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 30-219: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-220: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 30-221: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 30-222: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 30-223: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-224: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 30-225: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 30-226: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-227: Loss: 0.8337 Acc: 50.0000%\n",
      "\ttrain 30-228: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 30-229: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 30-230: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-231: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-232: Loss: 0.7955 Acc: 25.0000%\n",
      "\ttrain 30-233: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-234: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-235: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 30-236: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-237: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 30-238: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 30-239: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 30-240: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-241: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 30-242: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 30-243: Loss: 0.1415 Acc: 75.0000%\n",
      "\ttrain 30-244: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-245: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 30-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-3: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 30-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-6: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-7: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 30-8: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-9: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-10: Loss: 0.0008 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 30-11: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 30-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-13: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-16: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-18: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-19: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 30-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-21: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 30-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-24: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-27: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-28: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 30-29: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-30: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 30-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-34: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-36: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 30-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-39: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 30-40: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-45: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 30-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 30-47: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-49: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 30-50: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-51: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 30-52: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-53: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-55: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-56: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-58: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-59: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-60: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-62: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 30-63: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 30-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-65: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-66: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-67: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-68: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-69: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-71: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-72: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-73: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-74: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-75: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 30-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-77: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-81: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-83: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-85: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-89: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 30-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-91: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-93: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-95: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 30-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-98: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-102: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 30-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-104: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0428 Acc: 95.6122%\n",
      "\tvalidation Loss: 0.0012 Acc: 100.0000%\n",
      "Time passed 0h 16m 34s\n",
      "--------------------\n",
      "Epoch [31/40]:\n",
      "\ttrain 31-1: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 31-2: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 31-3: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 31-4: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 31-5: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 31-6: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-7: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 31-8: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 31-9: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 31-10: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-11: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 31-12: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 31-13: Loss: 0.0847 Acc: 75.0000%\n",
      "\ttrain 31-14: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 31-15: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-16: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 31-17: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 31-18: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 31-19: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-20: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 31-21: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-22: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 31-23: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 31-24: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 31-25: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 31-26: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 31-27: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-28: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-29: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 31-30: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-31: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 31-32: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 31-33: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-34: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 31-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-36: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 31-37: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 31-38: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 31-39: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-40: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-41: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-42: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 31-43: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-44: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-45: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 31-46: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 31-47: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 31-48: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 31-49: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 31-50: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-51: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 31-52: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-53: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 31-54: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-55: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 31-56: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 31-57: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 31-58: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-61: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-62: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 31-63: Loss: 0.5245 Acc: 50.0000%\n",
      "\ttrain 31-64: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 31-65: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-66: Loss: 0.0618 Acc: 100.0000%\n",
      "\ttrain 31-67: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-68: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 31-69: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 31-70: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-71: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-72: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 31-73: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-74: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-75: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 31-76: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-77: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 31-78: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-79: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 31-80: Loss: 0.9320 Acc: 75.0000%\n",
      "\ttrain 31-81: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-82: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 31-83: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 31-84: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-85: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-86: Loss: 0.0130 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-87: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 31-88: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 31-89: Loss: 0.0519 Acc: 75.0000%\n",
      "\ttrain 31-90: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-91: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-92: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 31-93: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 31-94: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 31-95: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 31-96: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 31-97: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-98: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-99: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 31-100: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 31-101: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 31-102: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-103: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 31-104: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 31-105: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 31-106: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 31-107: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 31-108: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-109: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 31-110: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 31-111: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-112: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 31-113: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 31-114: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 31-115: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 31-116: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-117: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 31-118: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-119: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-120: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 31-121: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 31-122: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-123: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 31-124: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 31-125: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-126: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 31-127: Loss: 0.1375 Acc: 75.0000%\n",
      "\ttrain 31-128: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-129: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 31-130: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-131: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 31-132: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-133: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-134: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-135: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 31-136: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-137: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-138: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 31-139: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 31-140: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-141: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 31-142: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-143: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 31-144: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-145: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-146: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 31-147: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 31-148: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 31-149: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-150: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 31-151: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-152: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 31-153: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-154: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-155: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-156: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 31-157: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 31-158: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 31-159: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 31-160: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-161: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 31-162: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 31-163: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-164: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 31-165: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 31-166: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-167: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 31-168: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 31-169: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 31-170: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 31-171: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-172: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-173: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-174: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 31-175: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-176: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 31-177: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-178: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 31-179: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 31-180: Loss: 0.2155 Acc: 75.0000%\n",
      "\ttrain 31-181: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 31-182: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 31-183: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-184: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 31-185: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 31-186: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-187: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 31-188: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-189: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-190: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-191: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 31-192: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 31-193: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 31-194: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 31-195: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 31-196: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-197: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 31-198: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 31-199: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-200: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-201: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-202: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 31-203: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 31-204: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-205: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 31-206: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 31-207: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 31-208: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-209: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 31-210: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 31-211: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 31-212: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-213: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-214: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 31-215: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 31-216: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-217: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-218: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 31-219: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 31-220: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 31-221: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-222: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 31-223: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 31-224: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 31-225: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-226: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-227: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 31-228: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-229: Loss: 0.0693 Acc: 75.0000%\n",
      "\ttrain 31-230: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-231: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-232: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 31-233: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-234: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-235: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 31-236: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 31-237: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 31-238: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 31-239: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 31-240: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 31-241: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-242: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-243: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 31-244: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 31-245: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 31-1: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-2: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 31-3: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 31-4: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-7: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 31-8: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 31-9: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 31-10: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-11: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-12: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-13: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-15: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-16: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-17: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-20: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-21: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-23: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-25: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-27: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 31-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-29: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 31-30: Loss: 0.0005 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 31-31: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 31-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-33: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 31-34: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 31-35: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 31-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-37: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-38: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-39: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-40: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-41: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-42: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 31-43: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-44: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-46: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 31-47: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-49: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 31-50: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 31-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-52: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 31-53: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 31-54: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 31-55: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 31-56: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 31-57: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-59: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 31-60: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-65: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-66: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 31-67: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 31-68: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-69: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 31-70: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-75: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-77: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-79: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-80: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 31-81: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-83: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-84: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-86: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-87: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-88: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-89: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 31-90: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-92: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-93: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-94: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-95: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 31-96: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 31-97: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-101: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-103: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-104: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0254 Acc: 97.2449%\n",
      "\tvalidation Loss: 0.0020 Acc: 100.0000%\n",
      "Time passed 0h 17m 7s\n",
      "--------------------\n",
      "Epoch [32/40]:\n",
      "\ttrain 32-1: Loss: 1.0417 Acc: 50.0000%\n",
      "\ttrain 32-2: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 32-3: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 32-4: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-5: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-6: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-7: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 32-8: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 32-9: Loss: 0.3640 Acc: 75.0000%\n",
      "\ttrain 32-10: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-11: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 32-12: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 32-13: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-14: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 32-15: Loss: 0.2505 Acc: 75.0000%\n",
      "\ttrain 32-16: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 32-17: Loss: 0.2935 Acc: 75.0000%\n",
      "\ttrain 32-18: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 32-19: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 32-20: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 32-21: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 32-22: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 32-23: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 32-24: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 32-25: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 32-26: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 32-27: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-28: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 32-29: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 32-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-31: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 32-32: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 32-33: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 32-34: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 32-35: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 32-36: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 32-37: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 32-38: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-39: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 32-40: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 32-41: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 32-42: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 32-43: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-44: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 32-45: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-46: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 32-47: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 32-48: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 32-49: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 32-50: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 32-51: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-52: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-53: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 32-54: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 32-55: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-56: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 32-57: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-58: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-59: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 32-60: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-61: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-62: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-63: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-64: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 32-65: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 32-66: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 32-67: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-68: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-69: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 32-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-71: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-72: Loss: 0.7987 Acc: 25.0000%\n",
      "\ttrain 32-73: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 32-74: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-75: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 32-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-77: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-79: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 32-80: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-81: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-82: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 32-83: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 32-84: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 32-85: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 32-86: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 32-87: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 32-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-89: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-91: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-93: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-94: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 32-95: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-96: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 32-97: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 32-98: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 32-99: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-100: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 32-101: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 32-102: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 32-103: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 32-104: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 32-105: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-106: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 32-107: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-108: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-109: Loss: 0.0046 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-110: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-111: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-112: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 32-113: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 32-114: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 32-115: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 32-116: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 32-117: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 32-118: Loss: 0.0609 Acc: 75.0000%\n",
      "\ttrain 32-119: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 32-120: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-121: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-122: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-123: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 32-124: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 32-125: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-126: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 32-127: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-128: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 32-129: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 32-130: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 32-131: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 32-132: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-133: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-134: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 32-135: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 32-136: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 32-137: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 32-138: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 32-139: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-140: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 32-141: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-142: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 32-143: Loss: 0.1302 Acc: 75.0000%\n",
      "\ttrain 32-144: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 32-145: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-146: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 32-147: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 32-148: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 32-149: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 32-150: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 32-151: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 32-152: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 32-153: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 32-154: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-155: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-156: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-157: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-158: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-159: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 32-160: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 32-161: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 32-162: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-163: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 32-164: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 32-165: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-166: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 32-167: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 32-168: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 32-169: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 32-170: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 32-171: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 32-172: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 32-173: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 32-174: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 32-175: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 32-176: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 32-177: Loss: 0.0541 Acc: 75.0000%\n",
      "\ttrain 32-178: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 32-179: Loss: 0.0751 Acc: 100.0000%\n",
      "\ttrain 32-180: Loss: 0.2270 Acc: 50.0000%\n",
      "\ttrain 32-181: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-182: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 32-183: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-184: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 32-185: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-186: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 32-187: Loss: 0.3491 Acc: 50.0000%\n",
      "\ttrain 32-188: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-189: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 32-190: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 32-191: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 32-192: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 32-193: Loss: 0.3445 Acc: 50.0000%\n",
      "\ttrain 32-194: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 32-195: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 32-196: Loss: 0.2745 Acc: 50.0000%\n",
      "\ttrain 32-197: Loss: 0.0708 Acc: 75.0000%\n",
      "\ttrain 32-198: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 32-199: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 32-200: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 32-201: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 32-202: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-203: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 32-204: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 32-205: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 32-206: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 32-207: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-208: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 32-209: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 32-210: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-211: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 32-212: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 32-213: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 32-214: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-215: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 32-216: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-217: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-218: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 32-219: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-220: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-221: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 32-222: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 32-223: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 32-224: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 32-225: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-226: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 32-227: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 32-228: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 32-229: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 32-230: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 32-231: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-232: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 32-233: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 32-234: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 32-235: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 32-236: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-237: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-238: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-239: Loss: 0.8730 Acc: 50.0000%\n",
      "\ttrain 32-240: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 32-241: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 32-242: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-243: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-244: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 32-245: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-2: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-3: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-6: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 32-7: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 32-8: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-9: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 32-10: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-11: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-12: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 32-13: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-14: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 32-15: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-16: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-17: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 32-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-19: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-22: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-23: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-24: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-28: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 32-29: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-31: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-33: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 32-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-37: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-39: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 32-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-41: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 32-42: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 32-43: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-44: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-45: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-46: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 32-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-48: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 32-49: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 32-50: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-51: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 32-52: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-53: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-54: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-55: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-56: Loss: 0.0005 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 32-57: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-59: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-60: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-61: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 32-62: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-64: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 32-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-66: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-67: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 32-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-69: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-71: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-72: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-74: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-75: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-76: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-80: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-81: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-82: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-83: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 32-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-85: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 32-86: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-87: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-88: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-89: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-91: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 32-92: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 32-93: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-94: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 32-95: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-97: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-99: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 32-100: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-101: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-102: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 32-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0389 Acc: 95.8163%\n",
      "\tvalidation Loss: 0.0015 Acc: 100.0000%\n",
      "Time passed 0h 17m 41s\n",
      "--------------------\n",
      "Epoch [33/40]:\n",
      "\ttrain 33-1: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 33-2: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-3: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 33-4: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 33-5: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-6: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 33-7: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 33-8: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 33-9: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 33-10: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 33-11: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 33-12: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-13: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-14: Loss: 0.1289 Acc: 50.0000%\n",
      "\ttrain 33-15: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-16: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 33-17: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 33-18: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 33-19: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 33-20: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-21: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 33-22: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-23: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-24: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-25: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 33-26: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 33-27: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-28: Loss: 0.0446 Acc: 75.0000%\n",
      "\ttrain 33-29: Loss: 0.0482 Acc: 75.0000%\n",
      "\ttrain 33-30: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 33-31: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 33-32: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 33-33: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-34: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 33-35: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-36: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-37: Loss: 0.0501 Acc: 75.0000%\n",
      "\ttrain 33-38: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 33-39: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-40: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 33-41: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-42: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-43: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 33-44: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-45: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 33-46: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-47: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 33-48: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 33-49: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-50: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 33-51: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 33-52: Loss: 0.5775 Acc: 50.0000%\n",
      "\ttrain 33-53: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-54: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-55: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-56: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 33-57: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 33-58: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 33-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-60: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-61: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 33-62: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 33-63: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 33-64: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 33-65: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 33-66: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-67: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 33-68: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-69: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 33-70: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-71: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 33-72: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 33-73: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-74: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-75: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-76: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 33-77: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-78: Loss: 0.9887 Acc: 25.0000%\n",
      "\ttrain 33-79: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-80: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 33-81: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 33-82: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-83: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 33-84: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 33-85: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 33-86: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-87: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-88: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 33-89: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 33-90: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 33-91: Loss: 0.0464 Acc: 75.0000%\n",
      "\ttrain 33-92: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-93: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 33-94: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 33-95: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 33-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-97: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-98: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 33-99: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 33-100: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 33-101: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 33-102: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 33-103: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-104: Loss: 0.6008 Acc: 25.0000%\n",
      "\ttrain 33-105: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 33-106: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 33-107: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-108: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-109: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-110: Loss: 0.3550 Acc: 75.0000%\n",
      "\ttrain 33-111: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-112: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-113: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-114: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-115: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 33-116: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-117: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-118: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-119: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-120: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-121: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 33-122: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 33-123: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-124: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-125: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 33-126: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-127: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 33-128: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-129: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-130: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 33-131: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 33-132: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-133: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-134: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-135: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 33-136: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 33-137: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-138: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 33-139: Loss: 0.0047 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-140: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 33-141: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 33-142: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 33-143: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 33-144: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 33-145: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-146: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 33-147: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-148: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 33-149: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-150: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-151: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 33-152: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 33-153: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-154: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-155: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 33-156: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 33-157: Loss: 0.3251 Acc: 75.0000%\n",
      "\ttrain 33-158: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 33-159: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 33-160: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 33-161: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-162: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 33-163: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 33-164: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 33-165: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-166: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 33-167: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 33-168: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-169: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 33-170: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 33-171: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 33-172: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-173: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 33-174: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 33-175: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 33-176: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-177: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 33-178: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-179: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-180: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-181: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 33-182: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 33-183: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 33-184: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 33-185: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-186: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-187: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-188: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 33-189: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 33-190: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-191: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 33-192: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-193: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-194: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 33-195: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 33-196: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 33-197: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-198: Loss: 0.5658 Acc: 25.0000%\n",
      "\ttrain 33-199: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 33-200: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 33-201: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 33-202: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 33-203: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-204: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-205: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 33-206: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 33-207: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 33-208: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 33-209: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 33-210: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 33-211: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 33-212: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-213: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 33-214: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 33-215: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-216: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 33-217: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-218: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-219: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-220: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 33-221: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 33-222: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 33-223: Loss: 0.2074 Acc: 75.0000%\n",
      "\ttrain 33-224: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 33-225: Loss: 0.4551 Acc: 25.0000%\n",
      "\ttrain 33-226: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 33-227: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 33-228: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-229: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-230: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 33-231: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 33-232: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 33-233: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-234: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-235: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 33-236: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 33-237: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 33-238: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 33-239: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-240: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-241: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-242: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-243: Loss: 1.2135 Acc: 25.0000%\n",
      "\ttrain 33-244: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 33-245: Loss: 0.0566 Acc: 100.0000%\n",
      "\tvalidation 33-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-2: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-4: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 33-5: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 33-6: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-7: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-9: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-10: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 33-11: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-12: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-13: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-14: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-15: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-19: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-20: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-21: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 33-22: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-23: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-25: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 33-26: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-28: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-30: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-34: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 33-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-37: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-38: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-40: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-44: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-46: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-48: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-50: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 33-51: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-53: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-55: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 33-56: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-57: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 33-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-63: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 33-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-67: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 33-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-72: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-73: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 33-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-76: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-77: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-78: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-79: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 33-80: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 33-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-82: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 33-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-84: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-85: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-86: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-87: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-88: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-89: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-90: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 33-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-92: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 33-93: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 33-94: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 33-95: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 33-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-98: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-99: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-100: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-101: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-102: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 33-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-104: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0399 Acc: 95.2041%\n",
      "\tvalidation Loss: 0.0009 Acc: 100.0000%\n",
      "Time passed 0h 18m 15s\n",
      "--------------------\n",
      "Epoch [34/40]:\n",
      "\ttrain 34-1: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-2: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 34-3: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 34-4: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 34-5: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 34-6: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 34-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-8: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-9: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 34-10: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-11: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-12: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 34-13: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 34-14: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 34-15: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 34-16: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 34-17: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-18: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 34-19: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 34-20: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-21: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-23: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 34-24: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 34-25: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 34-26: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 34-27: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 34-28: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 34-29: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 34-30: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-31: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 34-32: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 34-33: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 34-34: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 34-35: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 34-36: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 34-37: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 34-38: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 34-39: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 34-40: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 34-41: Loss: 0.0537 Acc: 75.0000%\n",
      "\ttrain 34-42: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 34-43: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 34-44: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-45: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 34-46: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-47: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 34-48: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 34-49: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 34-50: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 34-51: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-53: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-54: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-55: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 34-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-57: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 34-58: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-59: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-60: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-61: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-62: Loss: 0.8295 Acc: 0.0000%\n",
      "\ttrain 34-63: Loss: 0.2862 Acc: 75.0000%\n",
      "\ttrain 34-64: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-65: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 34-66: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-67: Loss: 0.2993 Acc: 75.0000%\n",
      "\ttrain 34-68: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 34-69: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-70: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 34-71: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 34-72: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-73: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 34-74: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 34-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-76: Loss: 0.0623 Acc: 75.0000%\n",
      "\ttrain 34-77: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 34-78: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-79: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 34-80: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-81: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 34-82: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 34-83: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 34-84: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 34-85: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 34-86: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 34-87: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 34-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-89: Loss: 0.2530 Acc: 50.0000%\n",
      "\ttrain 34-90: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 34-91: Loss: 0.2323 Acc: 50.0000%\n",
      "\ttrain 34-92: Loss: 0.2194 Acc: 50.0000%\n",
      "\ttrain 34-93: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 34-94: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 34-95: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-96: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 34-97: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-98: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-99: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 34-100: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 34-101: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 34-102: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 34-103: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-104: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 34-105: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 34-106: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 34-107: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 34-108: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-109: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 34-110: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 34-111: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-112: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 34-113: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 34-114: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 34-115: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 34-116: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 34-117: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 34-118: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 34-119: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-120: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 34-121: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 34-122: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 34-123: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 34-124: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 34-125: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-126: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-127: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 34-128: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-129: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 34-130: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 34-131: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-132: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-133: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-134: Loss: 0.2035 Acc: 75.0000%\n",
      "\ttrain 34-135: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 34-136: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 34-137: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 34-138: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 34-139: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 34-140: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 34-141: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 34-142: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-143: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 34-144: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-145: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 34-146: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 34-147: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-148: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 34-149: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-150: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 34-151: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-152: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 34-153: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-154: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 34-155: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-156: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-157: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 34-158: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 34-159: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-160: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 34-161: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 34-162: Loss: 0.3681 Acc: 25.0000%\n",
      "\ttrain 34-163: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-164: Loss: 0.0041 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-165: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 34-166: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 34-167: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-168: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-169: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-170: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 34-171: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 34-172: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-173: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-174: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 34-175: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 34-176: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 34-177: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-178: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 34-179: Loss: 0.4186 Acc: 50.0000%\n",
      "\ttrain 34-180: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 34-181: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 34-182: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-183: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-184: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 34-185: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-186: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-187: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 34-188: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 34-189: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-190: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-191: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-192: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 34-193: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 34-194: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 34-195: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-196: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-197: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-198: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 34-199: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 34-200: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 34-201: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 34-202: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 34-203: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 34-204: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 34-205: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 34-206: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-207: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 34-208: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-209: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-210: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 34-211: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-212: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 34-213: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 34-214: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 34-215: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 34-216: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 34-217: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-218: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-219: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 34-220: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-221: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 34-222: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 34-223: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-224: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-225: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 34-226: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 34-227: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-228: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-229: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 34-230: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 34-231: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-232: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-233: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-234: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-235: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-236: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 34-237: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-238: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 34-239: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-240: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 34-241: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 34-242: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-243: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 34-244: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 34-245: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 34-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-2: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 34-3: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-6: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 34-7: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-8: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-9: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-10: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-11: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 34-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-14: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-16: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-23: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-25: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-26: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-27: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-31: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-33: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-35: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-36: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-47: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-50: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-53: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-54: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-55: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-58: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-60: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 34-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-62: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-63: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 34-64: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-65: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-67: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 34-68: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-69: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 34-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-72: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-76: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-79: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-80: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 34-81: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-83: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-84: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 34-85: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 34-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-95: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-96: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-97: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 34-98: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 34-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0282 Acc: 96.1224%\n",
      "\tvalidation Loss: 0.0007 Acc: 100.0000%\n",
      "Time passed 0h 18m 48s\n",
      "--------------------\n",
      "Epoch [35/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-1: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-2: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 35-3: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 35-4: Loss: 0.3598 Acc: 50.0000%\n",
      "\ttrain 35-5: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-6: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 35-7: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 35-8: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 35-9: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 35-10: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-11: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-12: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 35-13: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 35-14: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 35-15: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-16: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 35-17: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 35-18: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 35-19: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 35-20: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 35-21: Loss: 0.1799 Acc: 75.0000%\n",
      "\ttrain 35-22: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 35-23: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 35-24: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-25: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 35-26: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-27: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-28: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 35-29: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 35-30: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-31: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-33: Loss: 0.6220 Acc: 25.0000%\n",
      "\ttrain 35-34: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-35: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-36: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 35-37: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-38: Loss: 0.0488 Acc: 75.0000%\n",
      "\ttrain 35-39: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 35-40: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 35-41: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 35-42: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 35-43: Loss: 0.2498 Acc: 75.0000%\n",
      "\ttrain 35-44: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 35-45: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-46: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-47: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-48: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-49: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 35-50: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 35-51: Loss: 0.2689 Acc: 50.0000%\n",
      "\ttrain 35-52: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 35-53: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 35-54: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-55: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 35-56: Loss: 0.5332 Acc: 50.0000%\n",
      "\ttrain 35-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-58: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 35-59: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-60: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-61: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-62: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 35-63: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 35-64: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 35-65: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-66: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 35-67: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 35-68: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-69: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 35-70: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 35-71: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 35-72: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 35-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-74: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 35-75: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 35-76: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-77: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 35-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-79: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 35-80: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-81: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 35-82: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 35-83: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-84: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 35-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-86: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 35-87: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-88: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-89: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 35-90: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-91: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 35-92: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 35-93: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 35-94: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 35-95: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 35-96: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 35-97: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-98: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-99: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 35-100: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 35-101: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 35-102: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 35-103: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 35-104: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 35-105: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-106: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-107: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 35-108: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-109: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 35-110: Loss: 0.9945 Acc: 0.0000%\n",
      "\ttrain 35-111: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-112: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-113: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 35-114: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-115: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-116: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 35-117: Loss: 0.2140 Acc: 75.0000%\n",
      "\ttrain 35-118: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 35-119: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 35-120: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 35-121: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 35-122: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 35-123: Loss: 0.3779 Acc: 75.0000%\n",
      "\ttrain 35-124: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 35-125: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-126: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 35-127: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 35-128: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-129: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-130: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 35-131: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-132: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-133: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 35-134: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-135: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-136: Loss: 0.2166 Acc: 75.0000%\n",
      "\ttrain 35-137: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 35-138: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-139: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 35-140: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 35-141: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-142: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 35-143: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 35-144: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 35-145: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 35-146: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 35-147: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 35-148: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 35-149: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 35-150: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-151: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 35-152: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-153: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 35-154: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-155: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 35-156: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-157: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 35-158: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-159: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-160: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 35-161: Loss: 0.1586 Acc: 75.0000%\n",
      "\ttrain 35-162: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 35-163: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-164: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-165: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-166: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-167: Loss: 1.1251 Acc: 50.0000%\n",
      "\ttrain 35-168: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-169: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-170: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-171: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-172: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 35-173: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-174: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 35-175: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-176: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 35-177: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 35-178: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-179: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-180: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-181: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 35-182: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 35-183: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 35-184: Loss: 0.3814 Acc: 75.0000%\n",
      "\ttrain 35-185: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 35-186: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 35-187: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 35-188: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 35-189: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 35-190: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 35-191: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-192: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 35-193: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 35-194: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-195: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-196: Loss: 0.0012 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-197: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 35-198: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-199: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 35-200: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 35-201: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 35-202: Loss: 0.2270 Acc: 50.0000%\n",
      "\ttrain 35-203: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 35-204: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-205: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 35-206: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-207: Loss: 0.0844 Acc: 75.0000%\n",
      "\ttrain 35-208: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 35-209: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 35-210: Loss: 0.1530 Acc: 75.0000%\n",
      "\ttrain 35-211: Loss: 0.2175 Acc: 75.0000%\n",
      "\ttrain 35-212: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 35-213: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 35-214: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-215: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 35-216: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 35-217: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 35-218: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 35-219: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 35-220: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 35-221: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-222: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 35-223: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 35-224: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 35-225: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 35-226: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-227: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 35-228: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 35-229: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-230: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-231: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 35-232: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-233: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 35-234: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-235: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 35-236: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 35-237: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-238: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 35-239: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 35-240: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 35-241: Loss: 0.3351 Acc: 75.0000%\n",
      "\ttrain 35-242: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 35-243: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-244: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 35-245: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 35-1: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 35-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-8: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-10: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-16: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-17: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-19: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-21: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 35-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-23: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-26: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-28: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-31: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-32: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-33: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 35-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-35: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-36: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-38: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-40: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-41: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-45: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 35-46: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-48: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-49: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-51: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-54: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 35-55: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-58: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 35-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-61: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 35-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-64: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-68: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-69: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-73: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-76: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-78: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-79: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-80: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-84: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-91: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-92: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 35-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-94: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-97: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 35-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-100: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-102: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-104: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-105: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0458 Acc: 94.6939%\n",
      "\tvalidation Loss: 0.0010 Acc: 100.0000%\n",
      "Time passed 0h 19m 21s\n",
      "--------------------\n",
      "Epoch [36/40]:\n",
      "\ttrain 36-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-2: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-3: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 36-4: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 36-5: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 36-6: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 36-7: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 36-8: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 36-9: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 36-10: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 36-11: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 36-12: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-13: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 36-14: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 36-15: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-16: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 36-17: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 36-18: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 36-19: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 36-20: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-21: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-22: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-23: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-24: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-25: Loss: 0.0086 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-26: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 36-27: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-28: Loss: 0.6659 Acc: 25.0000%\n",
      "\ttrain 36-29: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 36-30: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-31: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-32: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 36-33: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 36-34: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 36-35: Loss: 0.1885 Acc: 75.0000%\n",
      "\ttrain 36-36: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 36-37: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 36-38: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 36-39: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 36-40: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 36-41: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 36-42: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 36-43: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 36-44: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-45: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-46: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-47: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-48: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 36-49: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 36-50: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-51: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-52: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-53: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 36-54: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 36-55: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 36-56: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-57: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-58: Loss: 0.1904 Acc: 75.0000%\n",
      "\ttrain 36-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-60: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-61: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-62: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-64: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 36-65: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 36-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-67: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 36-68: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 36-69: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 36-70: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 36-71: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 36-72: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 36-73: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 36-74: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 36-75: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-76: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 36-77: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 36-78: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 36-79: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-80: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-81: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-82: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-83: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 36-84: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 36-85: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-86: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-87: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-88: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 36-89: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-90: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 36-91: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 36-92: Loss: 0.1737 Acc: 75.0000%\n",
      "\ttrain 36-93: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 36-94: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-95: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 36-96: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 36-97: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-98: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 36-99: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 36-100: Loss: 0.2237 Acc: 50.0000%\n",
      "\ttrain 36-101: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-102: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 36-103: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 36-104: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 36-105: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 36-106: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 36-107: Loss: 0.5759 Acc: 0.0000%\n",
      "\ttrain 36-108: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-109: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 36-110: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-111: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-112: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-113: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 36-114: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-115: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 36-116: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 36-117: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-118: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 36-119: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-120: Loss: 0.0761 Acc: 75.0000%\n",
      "\ttrain 36-121: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-122: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 36-123: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 36-124: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 36-125: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 36-126: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 36-127: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-128: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 36-129: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-130: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-131: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 36-132: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 36-133: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-134: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 36-135: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 36-136: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-137: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 36-138: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-139: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 36-140: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 36-141: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 36-142: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 36-143: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 36-144: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-145: Loss: 0.1479 Acc: 75.0000%\n",
      "\ttrain 36-146: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 36-147: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 36-148: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-149: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 36-150: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-151: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-152: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 36-153: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-154: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 36-155: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-156: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-157: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 36-158: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 36-159: Loss: 0.2784 Acc: 75.0000%\n",
      "\ttrain 36-160: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-161: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 36-162: Loss: 0.1244 Acc: 50.0000%\n",
      "\ttrain 36-163: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-164: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 36-165: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-166: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 36-167: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-168: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-169: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 36-170: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-171: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 36-172: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 36-173: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-174: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 36-175: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 36-176: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 36-177: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-178: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 36-179: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-180: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-181: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-182: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-183: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-184: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 36-185: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 36-186: Loss: 0.1723 Acc: 50.0000%\n",
      "\ttrain 36-187: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-188: Loss: 0.2497 Acc: 50.0000%\n",
      "\ttrain 36-189: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 36-190: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-191: Loss: 0.0729 Acc: 75.0000%\n",
      "\ttrain 36-192: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 36-193: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-194: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 36-195: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-196: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-197: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 36-198: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 36-199: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-200: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-201: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 36-202: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 36-203: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-204: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 36-205: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 36-206: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-207: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 36-208: Loss: 0.3181 Acc: 50.0000%\n",
      "\ttrain 36-209: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-210: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-211: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-212: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 36-213: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-214: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-215: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-216: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 36-217: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 36-218: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 36-219: Loss: 0.0089 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-220: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 36-221: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-222: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 36-223: Loss: 0.0990 Acc: 50.0000%\n",
      "\ttrain 36-224: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 36-225: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-226: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-227: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 36-228: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 36-229: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-230: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 36-231: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-232: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-233: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-234: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-235: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 36-236: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-237: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 36-238: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-239: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 36-240: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-241: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 36-242: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 36-243: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-244: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 36-245: Loss: 0.1205 Acc: 75.0000%\n",
      "\tvalidation 36-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-2: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-6: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 36-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-8: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-9: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 36-10: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 36-11: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 36-12: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-13: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-14: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-17: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-19: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-20: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-21: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-23: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 36-24: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-29: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 36-30: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 36-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-33: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 36-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-36: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 36-37: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 36-38: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 36-39: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-41: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-44: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 36-45: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-46: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-47: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 36-48: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-49: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-51: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-53: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-54: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-58: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-59: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-61: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 36-62: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-64: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-65: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-66: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-67: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 36-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 36-69: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 36-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-71: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-72: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-74: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-76: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-79: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-80: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 36-81: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 36-82: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-86: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-89: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 36-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-92: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-99: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-100: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 36-101: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 36-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-105: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0321 Acc: 95.3061%\n",
      "\tvalidation Loss: 0.0011 Acc: 100.0000%\n",
      "Time passed 0h 19m 55s\n",
      "--------------------\n",
      "Epoch [37/40]:\n",
      "\ttrain 37-1: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 37-2: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-3: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 37-4: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 37-5: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 37-6: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-7: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 37-8: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 37-9: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 37-10: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 37-11: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-12: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 37-13: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-14: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-15: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 37-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-17: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-18: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 37-19: Loss: 0.2399 Acc: 75.0000%\n",
      "\ttrain 37-20: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-21: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-22: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 37-23: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-24: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-25: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 37-26: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 37-27: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-28: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 37-29: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 37-30: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 37-31: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 37-32: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-33: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 37-34: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-36: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 37-37: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 37-38: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 37-39: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-40: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-41: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 37-42: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 37-43: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-44: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 37-45: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 37-46: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 37-47: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-48: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 37-49: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 37-50: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-51: Loss: 0.0036 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-52: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-53: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 37-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-55: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-56: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-58: Loss: 0.5809 Acc: 25.0000%\n",
      "\ttrain 37-59: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 37-60: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 37-61: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 37-62: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-64: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 37-65: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-66: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 37-67: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 37-68: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 37-69: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-70: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-71: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-72: Loss: 0.0466 Acc: 75.0000%\n",
      "\ttrain 37-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-74: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-75: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 37-76: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-77: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 37-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-79: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 37-80: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 37-81: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 37-82: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 37-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-84: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-85: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 37-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-87: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-90: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-91: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-92: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 37-93: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 37-94: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 37-95: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 37-96: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 37-97: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 37-98: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 37-99: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-100: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-101: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-102: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 37-103: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-104: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 37-105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-106: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-107: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-108: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 37-109: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-110: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-111: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 37-112: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-113: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-114: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 37-115: Loss: 0.0881 Acc: 100.0000%\n",
      "\ttrain 37-116: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-117: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-118: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 37-119: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-120: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-121: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-122: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 37-123: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 37-124: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 37-125: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-126: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-127: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-128: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-129: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 37-130: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 37-131: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 37-132: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 37-133: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-134: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-135: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-136: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-137: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 37-138: Loss: 0.1808 Acc: 75.0000%\n",
      "\ttrain 37-139: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-140: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 37-141: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-142: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 37-143: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-144: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 37-145: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-146: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 37-147: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 37-148: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 37-149: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-150: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 37-151: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-152: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-153: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 37-154: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 37-155: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 37-156: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 37-157: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-158: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-159: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 37-160: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 37-161: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 37-162: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 37-163: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 37-164: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-165: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 37-166: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 37-167: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 37-168: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-169: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 37-170: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 37-171: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-172: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 37-173: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-174: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-175: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-176: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-177: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 37-178: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 37-179: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-180: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 37-181: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 37-182: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-183: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-184: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-185: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-186: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-187: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 37-188: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-189: Loss: 0.7573 Acc: 50.0000%\n",
      "\ttrain 37-190: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 37-191: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-192: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 37-193: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-194: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-195: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 37-196: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-197: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 37-198: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-199: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-200: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-201: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 37-202: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-203: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-204: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 37-205: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 37-206: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-207: Loss: 0.7727 Acc: 25.0000%\n",
      "\ttrain 37-208: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 37-209: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-210: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 37-211: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 37-212: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 37-213: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-214: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-215: Loss: 0.8113 Acc: 0.0000%\n",
      "\ttrain 37-216: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 37-217: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 37-218: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-219: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-220: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-221: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-222: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-223: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-224: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-225: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-226: Loss: 0.2067 Acc: 75.0000%\n",
      "\ttrain 37-227: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 37-228: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 37-229: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 37-230: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-231: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 37-232: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 37-233: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 37-234: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 37-235: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 37-236: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 37-237: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 37-238: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-239: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 37-240: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-241: Loss: 0.0861 Acc: 100.0000%\n",
      "\ttrain 37-242: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-243: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-244: Loss: 0.0916 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-245: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 37-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-2: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 37-3: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-4: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-5: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 37-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-8: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-10: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-11: Loss: 0.0790 Acc: 75.0000%\n",
      "\tvalidation 37-12: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 37-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-15: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-16: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-17: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-19: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-22: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 37-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-26: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 37-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-28: Loss: 0.2331 Acc: 75.0000%\n",
      "\tvalidation 37-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-30: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-35: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 37-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-37: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-39: Loss: 0.0745 Acc: 75.0000%\n",
      "\tvalidation 37-40: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-44: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 37-45: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 37-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-49: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-50: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-53: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-54: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 37-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-56: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-59: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 37-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-62: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-64: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 37-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-67: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 37-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-71: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-73: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 37-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-75: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-77: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-78: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-79: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-80: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-82: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 37-83: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-85: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-86: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-88: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 37-89: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 37-90: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 37-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-95: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 37-96: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-99: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-100: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-101: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 37-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-103: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-105: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0292 Acc: 96.9388%\n",
      "\tvalidation Loss: 0.0048 Acc: 99.2857%\n",
      "Time passed 0h 20m 28s\n",
      "--------------------\n",
      "Epoch [38/40]:\n",
      "\ttrain 38-1: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 38-2: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 38-3: Loss: 0.2011 Acc: 50.0000%\n",
      "\ttrain 38-4: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 38-5: Loss: 0.0534 Acc: 75.0000%\n",
      "\ttrain 38-6: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 38-7: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-8: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 38-9: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-10: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 38-11: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-12: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-13: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 38-14: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-15: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-16: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-18: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 38-19: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-20: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 38-21: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 38-22: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 38-23: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-24: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-25: Loss: 0.5058 Acc: 50.0000%\n",
      "\ttrain 38-26: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 38-27: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 38-28: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 38-29: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 38-30: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 38-31: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-32: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 38-33: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-34: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-35: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-36: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-37: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 38-38: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 38-39: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-40: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 38-41: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-42: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 38-43: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 38-44: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-45: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 38-46: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-47: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 38-48: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 38-49: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 38-50: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-51: Loss: 0.2869 Acc: 50.0000%\n",
      "\ttrain 38-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-53: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 38-54: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 38-55: Loss: 0.6338 Acc: 25.0000%\n",
      "\ttrain 38-56: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-57: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-58: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-59: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-60: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-61: Loss: 0.1998 Acc: 75.0000%\n",
      "\ttrain 38-62: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-63: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-64: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-66: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-67: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-68: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-69: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 38-70: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 38-71: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 38-72: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 38-73: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-74: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 38-75: Loss: 0.1185 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 38-76: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 38-77: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 38-78: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-79: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 38-80: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 38-81: Loss: 0.6615 Acc: 25.0000%\n",
      "\ttrain 38-82: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-83: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-84: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-85: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 38-86: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-87: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 38-88: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 38-89: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 38-90: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 38-91: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-92: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-93: Loss: 0.3780 Acc: 50.0000%\n",
      "\ttrain 38-94: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 38-95: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-96: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 38-97: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 38-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-99: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 38-100: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-101: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 38-102: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 38-103: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 38-104: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-105: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 38-106: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-107: Loss: 0.2690 Acc: 50.0000%\n",
      "\ttrain 38-108: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 38-109: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 38-110: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 38-111: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-112: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 38-113: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-114: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-115: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 38-116: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 38-117: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 38-118: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 38-119: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 38-120: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-121: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 38-122: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-123: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 38-124: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-125: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-126: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-127: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-128: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 38-129: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 38-130: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-131: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 38-132: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 38-133: Loss: 0.0463 Acc: 75.0000%\n",
      "\ttrain 38-134: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 38-135: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-136: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-137: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 38-138: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-139: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 38-140: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-141: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 38-142: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 38-143: Loss: 0.0467 Acc: 75.0000%\n",
      "\ttrain 38-144: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 38-145: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-146: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-147: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-148: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-149: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-150: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-151: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-152: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-153: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 38-154: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-155: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-156: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-157: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 38-158: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-159: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-160: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 38-161: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-162: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 38-163: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-164: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 38-165: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-166: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-167: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-168: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-169: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 38-170: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-171: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 38-172: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-173: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-174: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-175: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-176: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-177: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-178: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 38-179: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 38-180: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-181: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-182: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 38-183: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-184: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 38-185: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-186: Loss: 0.8639 Acc: 50.0000%\n",
      "\ttrain 38-187: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-188: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-189: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-190: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-191: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-192: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-193: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 38-194: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 38-195: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-196: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-197: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-198: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 38-199: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 38-200: Loss: 0.3850 Acc: 25.0000%\n",
      "\ttrain 38-201: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 38-202: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-203: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-204: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 38-205: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-206: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-207: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 38-208: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 38-209: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 38-210: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 38-211: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 38-212: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-213: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 38-214: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-215: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-216: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 38-217: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 38-218: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-219: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 38-220: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-221: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-222: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 38-223: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-224: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 38-225: Loss: 0.1678 Acc: 75.0000%\n",
      "\ttrain 38-226: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 38-227: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-228: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 38-229: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-230: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 38-231: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 38-232: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-233: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 38-234: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 38-235: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 38-236: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 38-237: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 38-238: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-239: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-240: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-241: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 38-242: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 38-243: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-244: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 38-245: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 38-1: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 38-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-4: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-6: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 38-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-8: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-9: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-10: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 38-11: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-12: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-13: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 38-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-16: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-17: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 38-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-20: Loss: 0.0009 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 38-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-22: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-23: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-26: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 38-27: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-28: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 38-29: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-31: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 38-32: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-33: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-34: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-35: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-37: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-38: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-41: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-46: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-49: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-50: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-54: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-55: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-56: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-57: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 38-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-59: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 38-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-63: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 38-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-65: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-69: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 38-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-71: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 38-72: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-74: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-75: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-76: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-78: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 38-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-83: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-84: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-88: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 38-89: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-90: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-91: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-92: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-93: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-94: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-95: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-96: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-97: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-100: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-101: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 38-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-104: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0320 Acc: 96.0204%\n",
      "\tvalidation Loss: 0.0011 Acc: 100.0000%\n",
      "Time passed 0h 21m 1s\n",
      "--------------------\n",
      "Epoch [39/40]:\n",
      "\ttrain 39-1: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-2: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-3: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-4: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 39-5: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 39-6: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 39-7: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 39-8: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 39-9: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-10: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-11: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 39-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-14: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 39-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-16: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 39-17: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 39-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-19: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 39-20: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-21: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-23: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-24: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-25: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-26: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-27: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 39-28: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-29: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 39-30: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 39-31: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-32: Loss: 0.7173 Acc: 25.0000%\n",
      "\ttrain 39-33: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 39-34: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 39-35: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-36: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-37: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 39-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-39: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-40: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 39-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-43: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-44: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-45: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 39-46: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-47: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 39-48: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 39-49: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 39-50: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 39-51: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 39-52: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 39-53: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-54: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-55: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 39-56: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-57: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-59: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-60: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-61: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 39-62: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-63: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 39-64: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-65: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 39-66: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-67: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 39-68: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 39-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-71: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-72: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-73: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 39-74: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-75: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 39-76: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-77: Loss: 0.4973 Acc: 0.0000%\n",
      "\ttrain 39-78: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-79: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 39-80: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-81: Loss: 0.3809 Acc: 75.0000%\n",
      "\ttrain 39-82: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 39-83: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 39-84: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 39-85: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-86: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 39-87: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 39-88: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 39-89: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-90: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 39-91: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-92: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-93: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-94: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-95: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-96: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 39-97: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 39-98: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 39-99: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 39-100: Loss: 0.0013 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-101: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 39-102: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 39-103: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-105: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-106: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 39-107: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 39-108: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-109: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-110: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-111: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-112: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 39-113: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-114: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 39-115: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 39-116: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-117: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-118: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 39-119: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-120: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-121: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 39-122: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 39-123: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 39-124: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-125: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 39-126: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-127: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-128: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 39-129: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-130: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-131: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-132: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-133: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-134: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 39-135: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 39-136: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-137: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-138: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-139: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-140: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-141: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-142: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 39-143: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-144: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 39-145: Loss: 0.0463 Acc: 75.0000%\n",
      "\ttrain 39-146: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-147: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-148: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 39-149: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-150: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-151: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-152: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 39-153: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 39-154: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 39-155: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-156: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-157: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 39-158: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-159: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 39-160: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-161: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 39-162: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 39-163: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 39-164: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-165: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-166: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-167: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 39-168: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 39-169: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 39-170: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-171: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 39-172: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-173: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 39-174: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-175: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-176: Loss: 0.6459 Acc: 50.0000%\n",
      "\ttrain 39-177: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 39-178: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-179: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-180: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 39-181: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-182: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-183: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-184: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 39-185: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 39-186: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 39-187: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 39-188: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 39-189: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-190: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-191: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-192: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 39-193: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 39-194: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 39-195: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 39-196: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 39-197: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-198: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-199: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 39-200: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 39-201: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-202: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 39-203: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 39-204: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-205: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 39-206: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-207: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 39-208: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-209: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-210: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 39-211: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-212: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-213: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 39-214: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-215: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-216: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-217: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-218: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 39-219: Loss: 0.3870 Acc: 25.0000%\n",
      "\ttrain 39-220: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-221: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 39-222: Loss: 0.6388 Acc: 75.0000%\n",
      "\ttrain 39-223: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 39-224: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 39-225: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-226: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 39-227: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 39-228: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 39-229: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-230: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-231: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-232: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 39-233: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-234: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 39-235: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 39-236: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 39-237: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-238: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 39-239: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 39-240: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 39-241: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-242: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-243: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-244: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-245: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 39-1: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-2: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 39-3: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 39-4: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 39-5: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-7: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-9: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-11: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 39-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-15: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-16: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-18: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-19: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-20: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 39-21: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-22: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 39-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-24: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-26: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-27: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-28: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-30: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-31: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 39-32: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-33: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-34: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 39-35: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-37: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 39-38: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 39-39: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-40: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-41: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-44: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 39-45: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-46: Loss: 0.0026 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 39-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-48: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 39-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-50: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-51: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 39-52: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-53: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-55: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 39-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-57: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-58: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-59: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 39-60: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-61: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 39-62: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 39-63: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-66: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-67: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-68: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-70: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 39-71: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-75: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-78: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 39-79: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 39-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-81: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-82: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-83: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-84: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 39-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-86: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 39-87: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-89: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 39-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-91: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-92: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 39-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-94: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 39-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-97: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 39-98: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-101: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0257 Acc: 96.9388%\n",
      "\tvalidation Loss: 0.0024 Acc: 99.7619%\n",
      "Time passed 0h 21m 35s\n",
      "--------------------\n",
      "Epoch [40/40]:\n",
      "\ttrain 40-1: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-4: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-5: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-6: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-7: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 40-8: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-9: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-10: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 40-11: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-12: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-13: Loss: 0.0607 Acc: 75.0000%\n",
      "\ttrain 40-14: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-15: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-16: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-17: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 40-18: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-19: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-20: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 40-21: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-22: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 40-23: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 40-24: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-25: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 40-26: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 40-27: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-29: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 40-30: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-31: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-32: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 40-33: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 40-34: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 40-35: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 40-36: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 40-37: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-38: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-39: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 40-40: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-41: Loss: 0.6585 Acc: 25.0000%\n",
      "\ttrain 40-42: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-43: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 40-44: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 40-45: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-46: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 40-47: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-48: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 40-49: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 40-50: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-51: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-52: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 40-53: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 40-54: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 40-55: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-56: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 40-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-58: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-59: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 40-60: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 40-61: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-62: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 40-63: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-64: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 40-65: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 40-66: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 40-67: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-68: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 40-69: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-70: Loss: 0.1218 Acc: 50.0000%\n",
      "\ttrain 40-71: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-72: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 40-73: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 40-74: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-75: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 40-76: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-77: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-78: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 40-79: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 40-80: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-81: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 40-82: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-83: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-84: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 40-85: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-86: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 40-87: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 40-88: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-89: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-90: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 40-91: Loss: 0.3836 Acc: 50.0000%\n",
      "\ttrain 40-92: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 40-93: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-94: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-95: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 40-96: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 40-97: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 40-98: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-99: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 40-100: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-101: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-102: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 40-103: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-104: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-105: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 40-106: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-107: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-108: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-109: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 40-110: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 40-111: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 40-112: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 40-113: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-114: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-115: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-116: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-117: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-118: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 40-119: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 40-120: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 40-121: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 40-122: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 40-123: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 40-124: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-125: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 40-126: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-127: Loss: 0.0012 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-128: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 40-129: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 40-130: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 40-131: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-132: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 40-133: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 40-134: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 40-135: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 40-136: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-137: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 40-138: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 40-139: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-140: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 40-141: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-142: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-143: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-144: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 40-145: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 40-146: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-147: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 40-148: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 40-149: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 40-150: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 40-151: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 40-152: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 40-153: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-154: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-155: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-156: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 40-157: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 40-158: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-159: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 40-160: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-161: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-162: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-163: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 40-164: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-165: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 40-166: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-167: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-168: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 40-169: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-170: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-171: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-172: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-173: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 40-174: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-175: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 40-176: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 40-177: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-178: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-179: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-180: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 40-181: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-182: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-183: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-184: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 40-185: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 40-186: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-187: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-188: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-189: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-190: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 40-191: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-192: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-193: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-194: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-195: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 40-196: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-197: Loss: 0.3589 Acc: 50.0000%\n",
      "\ttrain 40-198: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 40-199: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-200: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 40-201: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 40-202: Loss: 0.3403 Acc: 75.0000%\n",
      "\ttrain 40-203: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-204: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-205: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 40-206: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 40-207: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-208: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-209: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-210: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-211: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-212: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-213: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-214: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-215: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-216: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-217: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-218: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-219: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-220: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 40-221: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-222: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 40-223: Loss: 0.1979 Acc: 75.0000%\n",
      "\ttrain 40-224: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-225: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 40-226: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-227: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 40-228: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 40-229: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 40-230: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-231: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-232: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 40-233: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-234: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 40-235: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 40-236: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 40-237: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-238: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-239: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-240: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 40-241: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-242: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-243: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 40-244: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-245: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-1: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-3: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 40-4: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-8: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-9: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-12: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-13: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 40-14: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-15: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-18: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-19: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-20: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-21: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-23: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-26: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-28: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 40-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-30: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-32: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-33: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 40-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-36: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-37: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-40: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-41: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 40-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-45: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-46: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 40-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-50: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 40-51: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-52: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-54: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-55: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-57: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 40-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-60: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 40-61: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 40-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-64: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 40-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-67: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-68: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 40-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-70: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 40-71: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-74: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-76: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-77: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-79: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-80: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-84: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 40-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-86: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 40-87: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 40-88: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-89: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-90: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-91: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-92: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 40-93: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-97: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-101: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 40-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-103: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0204 Acc: 97.5510%\n",
      "\tvalidation Loss: 0.0009 Acc: 100.0000%\n",
      "Time passed 0h 22m 8s\n",
      "--------------------\n",
      "Training complete in 0h 22m 8s\n",
      "Best validation Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "loss_train = []  # 训练集loss\n",
    "acc_train = []  # 训练集正确率\n",
    "loss_val = []  # 验证集loss\n",
    "acc_val = []  # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "\n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            i = 1\n",
    "            j = 1\n",
    "            # exp_lr_scheduler.step()\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            i = 1\n",
    "            j = 2\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            # if use_gpu:\n",
    "            #     inputs = inputs.cuda()\n",
    "            #     labels = labels.cuda()\n",
    "            # else:\n",
    "            #     inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            # '_'就是一个变量，换成a也是可以的，没有特别的意思，不过一般用_表示的变量好像都是没什么用的一个临时变量，大概是\n",
    "            # 一个编程习惯吧。所以这边'_,'没有特殊的含义，'_'就是一个变量，只是为了让preds取到max函数返回值的第二项，\n",
    "            # 即找到的最大值的索引位置（对应到这里就是类别标签）\n",
    "            # （max函数解释见https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max）\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, num_classes):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "\n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, i, loss.item()/4, torch.sum(preds == labels.data).item()/4.0*100))\n",
    "            i = i + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if j == 1:\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and j == 2:\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'validation' and epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"网络参数更新\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/params_densenet121.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "#             print(\"Model's state_dict:\")\n",
    "#             for param_tensor in best_model_wts:\n",
    "#                 print(param_tensor, \"\\t\", best_model_wts[param_tensor].size())\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.24983441145444402, 0.15444736092978595, 0.12407928068114786, 0.10179118305748823, 0.09132121842430563, 0.0894153284327108, 0.07929935587608085, 0.061838656739920984, 0.06743510018806068, 0.0726036638477627, 0.06487070502979415, 0.06867234156448014, 0.06102027733411108, 0.05683154863666515, 0.06047236189550283, 0.041193851691727734, 0.04080889082076598, 0.05328456747288607, 0.05536183836508771, 0.04932753466525856, 0.03098507712081987, 0.06106710408111008, 0.04489583988883057, 0.03654367805135493, 0.044583418478771134, 0.04521776877191602, 0.04221165101138913, 0.03883421865044808, 0.031465615636231944, 0.04282943781237213, 0.025438622826216173, 0.03894902446440288, 0.039934642035133985, 0.0281818545290402, 0.04576240229059239, 0.03210924320987293, 0.029186830137457168, 0.031976722560975016, 0.025674087995169115, 0.02038042679124949]\n",
      "loss_val: [0.07172253880472411, 0.030783196219376155, 0.01062375654776891, 0.011275496653148106, 0.016005135575930276, 0.007485100768861316, 0.005977461735407512, 0.0027058436757042294, 0.0033698976039886475, 0.039641568667831875, 0.005979868060066586, 0.0049091686805089315, 0.020025405003910972, 0.0026867829617999847, 0.00903053709438869, 0.0010786963360650199, 0.01813735252334958, 0.0037066706589290073, 0.0017843233687537057, 0.00230958206312997, 0.004032233073597863, 0.004281683904784066, 0.0013968721741721745, 0.011600518439497267, 0.0013640132688340686, 0.003656192762511117, 0.0011686716760907854, 0.00314628609589168, 0.0008203371649696714, 0.0011791403804506575, 0.0019917974869410196, 0.0015424075580778576, 0.0009285722460065569, 0.0006925940513610839, 0.0010439240506717137, 0.0010961946986970447, 0.004807971063114348, 0.001135281721750895, 0.002444846289498465, 0.0009165707088652111]\n",
      "acc_train: [0.5561224489795918, 0.7489795918367347, 0.8091836734693878, 0.85, 0.8704081632653061, 0.8785714285714286, 0.8908163265306123, 0.9224489795918367, 0.9061224489795918, 0.8857142857142857, 0.9142857142857143, 0.9112244897959184, 0.9153061224489796, 0.9255102040816326, 0.9244897959183673, 0.9530612244897959, 0.9530612244897959, 0.9387755102040817, 0.939795918367347, 0.9377551020408164, 0.9622448979591837, 0.9346938775510204, 0.9459183673469388, 0.9612244897959183, 0.9438775510204082, 0.936734693877551, 0.9510204081632653, 0.9530612244897959, 0.9693877551020408, 0.9561224489795919, 0.9724489795918367, 0.9581632653061225, 0.9520408163265306, 0.9612244897959183, 0.9469387755102041, 0.9530612244897959, 0.9693877551020408, 0.960204081632653, 0.9693877551020408, 0.9755102040816327]\n",
      "acc_val: [0.9666666666666667, 0.9880952380952381, 0.9952380952380953, 0.9952380952380953, 0.9880952380952381, 0.9952380952380953, 1.0, 1.0, 1.0, 0.9476190476190476, 1.0, 1.0, 0.9761904761904762, 1.0, 0.9880952380952381, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9976190476190476, 1.0, 1.0, 0.9857142857142858, 1.0, 0.9976190476190476, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9928571428571429, 1.0, 0.9976190476190476, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss(DenseNet121)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(2, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy(DenseNet121)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(2, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "GroundTruth:     77    79    77    79\n",
      "Predicted:     77    79    77    79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('75', '77', '79', '81')\n",
    "\n",
    "dataiter = iter(dataloders['validation'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[z]] for z in range(4)))\n",
    "\n",
    "# test\n",
    "outputs = model(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[z]] for z in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   Predicted\n",
      "\n",
      "\t   75\t77\t79\t81\n",
      "\n",
      "Actual 75  105\t0\t0\t0\t\n",
      "\n",
      "Actual 77  0\t105\t0\t0\t\n",
      "\n",
      "Actual 79  0\t0\t105\t0\t\n",
      "\n",
      "Actual 81  0\t0\t0\t105\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conc = {\n",
    "    '0': '75  ',\n",
    "    '1': '77  ',\n",
    "    '2': '79  ',\n",
    "    '3': '81  '\n",
    "}\n",
    "\n",
    "print(\"\\t   Predicted\\n\")\n",
    "print(\"\\t   75\\t77\\t79\\t81\\n\")\n",
    "for i in range(0, num_classes):\n",
    "    print(\"Actual \", end='')\n",
    "    print(conc[str(i)], end='')\n",
    "    for j in range(0, num_classes):\n",
    "        print(str(best_matrix[i][j]) + '\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
