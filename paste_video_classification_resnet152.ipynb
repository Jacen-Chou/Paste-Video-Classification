{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个代码每个epoch都跑一遍训练集和验证集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "shuffle = True\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载vgg16预训练模型\n",
    "model = models.resnet152(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=10) for x in ['train', 'validation']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]:\n",
      "\ttrain 1-1: Loss: 0.3679 Acc: 25.0000%\n",
      "\ttrain 1-2: Loss: 0.2822 Acc: 75.0000%\n",
      "\ttrain 1-3: Loss: 0.3324 Acc: 25.0000%\n",
      "\ttrain 1-4: Loss: 0.5216 Acc: 0.0000%\n",
      "\ttrain 1-5: Loss: 0.3600 Acc: 25.0000%\n",
      "\ttrain 1-6: Loss: 0.6665 Acc: 25.0000%\n",
      "\ttrain 1-7: Loss: 0.5134 Acc: 25.0000%\n",
      "\ttrain 1-8: Loss: 0.4635 Acc: 25.0000%\n",
      "\ttrain 1-9: Loss: 0.6235 Acc: 0.0000%\n",
      "\ttrain 1-10: Loss: 0.8342 Acc: 25.0000%\n",
      "\ttrain 1-11: Loss: 0.7088 Acc: 25.0000%\n",
      "\ttrain 1-12: Loss: 0.3517 Acc: 50.0000%\n",
      "\ttrain 1-13: Loss: 0.3744 Acc: 25.0000%\n",
      "\ttrain 1-14: Loss: 0.3257 Acc: 25.0000%\n",
      "\ttrain 1-15: Loss: 0.9289 Acc: 25.0000%\n",
      "\ttrain 1-16: Loss: 0.6264 Acc: 25.0000%\n",
      "\ttrain 1-17: Loss: 0.5299 Acc: 50.0000%\n",
      "\ttrain 1-18: Loss: 0.7428 Acc: 0.0000%\n",
      "\ttrain 1-19: Loss: 0.4768 Acc: 25.0000%\n",
      "\ttrain 1-20: Loss: 0.3384 Acc: 75.0000%\n",
      "\ttrain 1-21: Loss: 0.3439 Acc: 50.0000%\n",
      "\ttrain 1-22: Loss: 0.9156 Acc: 25.0000%\n",
      "\ttrain 1-23: Loss: 0.6788 Acc: 25.0000%\n",
      "\ttrain 1-24: Loss: 0.4388 Acc: 75.0000%\n",
      "\ttrain 1-25: Loss: 0.4197 Acc: 50.0000%\n",
      "\ttrain 1-26: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 1-27: Loss: 0.6515 Acc: 25.0000%\n",
      "\ttrain 1-28: Loss: 0.8500 Acc: 0.0000%\n",
      "\ttrain 1-29: Loss: 0.3795 Acc: 25.0000%\n",
      "\ttrain 1-30: Loss: 0.6597 Acc: 25.0000%\n",
      "\ttrain 1-31: Loss: 0.5761 Acc: 25.0000%\n",
      "\ttrain 1-32: Loss: 0.7713 Acc: 25.0000%\n",
      "\ttrain 1-33: Loss: 0.3817 Acc: 0.0000%\n",
      "\ttrain 1-34: Loss: 0.3786 Acc: 25.0000%\n",
      "\ttrain 1-35: Loss: 2.3172 Acc: 0.0000%\n",
      "\ttrain 1-36: Loss: 0.3893 Acc: 25.0000%\n",
      "\ttrain 1-37: Loss: 0.2262 Acc: 50.0000%\n",
      "\ttrain 1-38: Loss: 0.4895 Acc: 0.0000%\n",
      "\ttrain 1-39: Loss: 1.0902 Acc: 25.0000%\n",
      "\ttrain 1-40: Loss: 0.3159 Acc: 25.0000%\n",
      "\ttrain 1-41: Loss: 0.2973 Acc: 50.0000%\n",
      "\ttrain 1-42: Loss: 0.5949 Acc: 25.0000%\n",
      "\ttrain 1-43: Loss: 0.6143 Acc: 0.0000%\n",
      "\ttrain 1-44: Loss: 0.7164 Acc: 0.0000%\n",
      "\ttrain 1-45: Loss: 1.0027 Acc: 0.0000%\n",
      "\ttrain 1-46: Loss: 0.2818 Acc: 25.0000%\n",
      "\ttrain 1-47: Loss: 0.2838 Acc: 50.0000%\n",
      "\ttrain 1-48: Loss: 0.5431 Acc: 25.0000%\n",
      "\ttrain 1-49: Loss: 0.6636 Acc: 25.0000%\n",
      "\ttrain 1-50: Loss: 0.2976 Acc: 50.0000%\n",
      "\ttrain 1-51: Loss: 0.2878 Acc: 50.0000%\n",
      "\ttrain 1-52: Loss: 0.4998 Acc: 0.0000%\n",
      "\ttrain 1-53: Loss: 0.4784 Acc: 0.0000%\n",
      "\ttrain 1-54: Loss: 0.7487 Acc: 0.0000%\n",
      "\ttrain 1-55: Loss: 0.2627 Acc: 25.0000%\n",
      "\ttrain 1-56: Loss: 0.3369 Acc: 25.0000%\n",
      "\ttrain 1-57: Loss: 0.4022 Acc: 25.0000%\n",
      "\ttrain 1-58: Loss: 0.3572 Acc: 0.0000%\n",
      "\ttrain 1-59: Loss: 0.3300 Acc: 50.0000%\n",
      "\ttrain 1-60: Loss: 0.4123 Acc: 50.0000%\n",
      "\ttrain 1-61: Loss: 0.3455 Acc: 25.0000%\n",
      "\ttrain 1-62: Loss: 0.3429 Acc: 0.0000%\n",
      "\ttrain 1-63: Loss: 0.4346 Acc: 25.0000%\n",
      "\ttrain 1-64: Loss: 0.3282 Acc: 25.0000%\n",
      "\ttrain 1-65: Loss: 0.6385 Acc: 0.0000%\n",
      "\ttrain 1-66: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 1-67: Loss: 0.4569 Acc: 25.0000%\n",
      "\ttrain 1-68: Loss: 0.4169 Acc: 25.0000%\n",
      "\ttrain 1-69: Loss: 0.4379 Acc: 25.0000%\n",
      "\ttrain 1-70: Loss: 0.3348 Acc: 50.0000%\n",
      "\ttrain 1-71: Loss: 0.4860 Acc: 0.0000%\n",
      "\ttrain 1-72: Loss: 0.7143 Acc: 0.0000%\n",
      "\ttrain 1-73: Loss: 0.4822 Acc: 0.0000%\n",
      "\ttrain 1-74: Loss: 0.3414 Acc: 75.0000%\n",
      "\ttrain 1-75: Loss: 0.6659 Acc: 0.0000%\n",
      "\ttrain 1-76: Loss: 0.5277 Acc: 25.0000%\n",
      "\ttrain 1-77: Loss: 0.1536 Acc: 100.0000%\n",
      "\ttrain 1-78: Loss: 0.6858 Acc: 0.0000%\n",
      "\ttrain 1-79: Loss: 0.7811 Acc: 0.0000%\n",
      "\ttrain 1-80: Loss: 0.4393 Acc: 50.0000%\n",
      "\ttrain 1-81: Loss: 0.6045 Acc: 0.0000%\n",
      "\ttrain 1-82: Loss: 0.6160 Acc: 25.0000%\n",
      "\ttrain 1-83: Loss: 0.4934 Acc: 0.0000%\n",
      "\ttrain 1-84: Loss: 0.5580 Acc: 25.0000%\n",
      "\ttrain 1-85: Loss: 0.9900 Acc: 0.0000%\n",
      "\ttrain 1-86: Loss: 0.3610 Acc: 0.0000%\n",
      "\ttrain 1-87: Loss: 0.6143 Acc: 25.0000%\n",
      "\ttrain 1-88: Loss: 0.6393 Acc: 0.0000%\n",
      "\ttrain 1-89: Loss: 0.5222 Acc: 0.0000%\n",
      "\ttrain 1-90: Loss: 0.4470 Acc: 0.0000%\n",
      "\ttrain 1-91: Loss: 0.4115 Acc: 50.0000%\n",
      "\ttrain 1-92: Loss: 0.3888 Acc: 25.0000%\n",
      "\ttrain 1-93: Loss: 0.4206 Acc: 25.0000%\n",
      "\ttrain 1-94: Loss: 0.2154 Acc: 75.0000%\n",
      "\ttrain 1-95: Loss: 1.1173 Acc: 0.0000%\n",
      "\ttrain 1-96: Loss: 0.7309 Acc: 25.0000%\n",
      "\ttrain 1-97: Loss: 0.5021 Acc: 50.0000%\n",
      "\ttrain 1-98: Loss: 0.7765 Acc: 25.0000%\n",
      "\ttrain 1-99: Loss: 0.4940 Acc: 0.0000%\n",
      "\ttrain 1-100: Loss: 0.3874 Acc: 25.0000%\n",
      "\ttrain 1-101: Loss: 0.2788 Acc: 50.0000%\n",
      "\ttrain 1-102: Loss: 1.3347 Acc: 0.0000%\n",
      "\ttrain 1-103: Loss: 0.8609 Acc: 25.0000%\n",
      "\ttrain 1-104: Loss: 0.6061 Acc: 25.0000%\n",
      "\ttrain 1-105: Loss: 0.3493 Acc: 50.0000%\n",
      "\ttrain 1-106: Loss: 1.4418 Acc: 0.0000%\n",
      "\ttrain 1-107: Loss: 0.6167 Acc: 25.0000%\n",
      "\ttrain 1-108: Loss: 0.8450 Acc: 0.0000%\n",
      "\ttrain 1-109: Loss: 0.3718 Acc: 25.0000%\n",
      "\ttrain 1-110: Loss: 0.3436 Acc: 25.0000%\n",
      "\ttrain 1-111: Loss: 0.4734 Acc: 25.0000%\n",
      "\ttrain 1-112: Loss: 0.2729 Acc: 50.0000%\n",
      "\ttrain 1-113: Loss: 0.7560 Acc: 50.0000%\n",
      "\ttrain 1-114: Loss: 0.7128 Acc: 0.0000%\n",
      "\ttrain 1-115: Loss: 0.6754 Acc: 25.0000%\n",
      "\ttrain 1-116: Loss: 0.7110 Acc: 0.0000%\n",
      "\ttrain 1-117: Loss: 1.2039 Acc: 25.0000%\n",
      "\ttrain 1-118: Loss: 0.5386 Acc: 25.0000%\n",
      "\ttrain 1-119: Loss: 1.4220 Acc: 0.0000%\n",
      "\ttrain 1-120: Loss: 0.4390 Acc: 50.0000%\n",
      "\ttrain 1-121: Loss: 1.2610 Acc: 0.0000%\n",
      "\ttrain 1-122: Loss: 0.9618 Acc: 25.0000%\n",
      "\ttrain 1-123: Loss: 0.6280 Acc: 25.0000%\n",
      "\ttrain 1-124: Loss: 0.5406 Acc: 50.0000%\n",
      "\ttrain 1-125: Loss: 0.5309 Acc: 0.0000%\n",
      "\ttrain 1-126: Loss: 0.5881 Acc: 75.0000%\n",
      "\ttrain 1-127: Loss: 2.0771 Acc: 0.0000%\n",
      "\ttrain 1-128: Loss: 2.2078 Acc: 0.0000%\n",
      "\ttrain 1-129: Loss: 0.7475 Acc: 25.0000%\n",
      "\ttrain 1-130: Loss: 0.5275 Acc: 0.0000%\n",
      "\ttrain 1-131: Loss: 0.2566 Acc: 75.0000%\n",
      "\ttrain 1-132: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 1-133: Loss: 0.3929 Acc: 50.0000%\n",
      "\ttrain 1-134: Loss: 0.9945 Acc: 25.0000%\n",
      "\ttrain 1-135: Loss: 1.1006 Acc: 0.0000%\n",
      "\ttrain 1-136: Loss: 0.7241 Acc: 50.0000%\n",
      "\ttrain 1-137: Loss: 0.4750 Acc: 50.0000%\n",
      "\ttrain 1-138: Loss: 0.8230 Acc: 25.0000%\n",
      "\ttrain 1-139: Loss: 0.7116 Acc: 0.0000%\n",
      "\ttrain 1-140: Loss: 0.7652 Acc: 50.0000%\n",
      "\ttrain 1-141: Loss: 0.8786 Acc: 0.0000%\n",
      "\ttrain 1-142: Loss: 0.4275 Acc: 25.0000%\n",
      "\ttrain 1-143: Loss: 0.3429 Acc: 25.0000%\n",
      "\ttrain 1-144: Loss: 0.3471 Acc: 25.0000%\n",
      "\ttrain 1-145: Loss: 0.6866 Acc: 25.0000%\n",
      "\ttrain 1-146: Loss: 0.2359 Acc: 75.0000%\n",
      "\ttrain 1-147: Loss: 1.5854 Acc: 0.0000%\n",
      "\ttrain 1-148: Loss: 0.2520 Acc: 50.0000%\n",
      "\ttrain 1-149: Loss: 1.2946 Acc: 0.0000%\n",
      "\ttrain 1-150: Loss: 0.4171 Acc: 25.0000%\n",
      "\ttrain 1-151: Loss: 0.6237 Acc: 0.0000%\n",
      "\ttrain 1-152: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 1-153: Loss: 0.3421 Acc: 75.0000%\n",
      "\ttrain 1-154: Loss: 0.5286 Acc: 25.0000%\n",
      "\ttrain 1-155: Loss: 0.9403 Acc: 50.0000%\n",
      "\ttrain 1-156: Loss: 1.0147 Acc: 25.0000%\n",
      "\ttrain 1-157: Loss: 0.7935 Acc: 25.0000%\n",
      "\ttrain 1-158: Loss: 0.4303 Acc: 25.0000%\n",
      "\ttrain 1-159: Loss: 0.6124 Acc: 25.0000%\n",
      "\ttrain 1-160: Loss: 0.4377 Acc: 25.0000%\n",
      "\ttrain 1-161: Loss: 0.3362 Acc: 50.0000%\n",
      "\ttrain 1-162: Loss: 0.2993 Acc: 50.0000%\n",
      "\ttrain 1-163: Loss: 0.2800 Acc: 25.0000%\n",
      "\ttrain 1-164: Loss: 0.5773 Acc: 50.0000%\n",
      "\ttrain 1-165: Loss: 0.6609 Acc: 0.0000%\n",
      "\ttrain 1-166: Loss: 1.4907 Acc: 0.0000%\n",
      "\ttrain 1-167: Loss: 0.1764 Acc: 100.0000%\n",
      "\ttrain 1-168: Loss: 0.7382 Acc: 25.0000%\n",
      "\ttrain 1-169: Loss: 1.3410 Acc: 0.0000%\n",
      "\ttrain 1-170: Loss: 0.6824 Acc: 0.0000%\n",
      "\ttrain 1-171: Loss: 0.5563 Acc: 0.0000%\n",
      "\ttrain 1-172: Loss: 0.3095 Acc: 50.0000%\n",
      "\ttrain 1-173: Loss: 0.3220 Acc: 25.0000%\n",
      "\ttrain 1-174: Loss: 0.2730 Acc: 50.0000%\n",
      "\ttrain 1-175: Loss: 1.1748 Acc: 0.0000%\n",
      "\ttrain 1-176: Loss: 0.5465 Acc: 25.0000%\n",
      "\ttrain 1-177: Loss: 0.5554 Acc: 25.0000%\n",
      "\ttrain 1-178: Loss: 2.1098 Acc: 0.0000%\n",
      "\ttrain 1-179: Loss: 0.0976 Acc: 100.0000%\n",
      "\ttrain 1-180: Loss: 1.5522 Acc: 0.0000%\n",
      "\ttrain 1-181: Loss: 1.2179 Acc: 25.0000%\n",
      "\ttrain 1-182: Loss: 0.6639 Acc: 25.0000%\n",
      "\ttrain 1-183: Loss: 0.5330 Acc: 0.0000%\n",
      "\ttrain 1-184: Loss: 0.3960 Acc: 50.0000%\n",
      "\ttrain 1-185: Loss: 0.8226 Acc: 25.0000%\n",
      "\ttrain 1-186: Loss: 0.6175 Acc: 25.0000%\n",
      "\ttrain 1-187: Loss: 0.7493 Acc: 0.0000%\n",
      "\ttrain 1-188: Loss: 1.2703 Acc: 0.0000%\n",
      "\ttrain 1-189: Loss: 0.4779 Acc: 25.0000%\n",
      "\ttrain 1-190: Loss: 0.5269 Acc: 50.0000%\n",
      "\ttrain 1-191: Loss: 0.9917 Acc: 25.0000%\n",
      "\ttrain 1-192: Loss: 1.2185 Acc: 50.0000%\n",
      "\ttrain 1-193: Loss: 1.1494 Acc: 25.0000%\n",
      "\ttrain 1-194: Loss: 1.2849 Acc: 0.0000%\n",
      "\ttrain 1-195: Loss: 1.0011 Acc: 50.0000%\n",
      "\ttrain 1-196: Loss: 0.1419 Acc: 100.0000%\n",
      "\ttrain 1-197: Loss: 0.9572 Acc: 25.0000%\n",
      "\ttrain 1-198: Loss: 0.8166 Acc: 0.0000%\n",
      "\ttrain 1-199: Loss: 0.2032 Acc: 75.0000%\n",
      "\ttrain 1-200: Loss: 0.3751 Acc: 25.0000%\n",
      "\ttrain 1-201: Loss: 1.0202 Acc: 0.0000%\n",
      "\ttrain 1-202: Loss: 1.0427 Acc: 25.0000%\n",
      "\ttrain 1-203: Loss: 0.3309 Acc: 25.0000%\n",
      "\ttrain 1-204: Loss: 0.2057 Acc: 50.0000%\n",
      "\ttrain 1-205: Loss: 0.5703 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-206: Loss: 0.3532 Acc: 25.0000%\n",
      "\ttrain 1-207: Loss: 0.4553 Acc: 50.0000%\n",
      "\ttrain 1-208: Loss: 0.5322 Acc: 0.0000%\n",
      "\ttrain 1-209: Loss: 0.3372 Acc: 0.0000%\n",
      "\ttrain 1-210: Loss: 0.1852 Acc: 100.0000%\n",
      "\ttrain 1-211: Loss: 0.2937 Acc: 75.0000%\n",
      "\ttrain 1-212: Loss: 0.6005 Acc: 50.0000%\n",
      "\ttrain 1-213: Loss: 0.3347 Acc: 50.0000%\n",
      "\ttrain 1-214: Loss: 0.7509 Acc: 0.0000%\n",
      "\ttrain 1-215: Loss: 0.3088 Acc: 0.0000%\n",
      "\ttrain 1-216: Loss: 0.4356 Acc: 25.0000%\n",
      "\ttrain 1-217: Loss: 0.2595 Acc: 50.0000%\n",
      "\ttrain 1-218: Loss: 0.1876 Acc: 100.0000%\n",
      "\ttrain 1-219: Loss: 0.2181 Acc: 50.0000%\n",
      "\ttrain 1-220: Loss: 0.8476 Acc: 0.0000%\n",
      "\ttrain 1-221: Loss: 0.7103 Acc: 25.0000%\n",
      "\ttrain 1-222: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 1-223: Loss: 0.3753 Acc: 25.0000%\n",
      "\ttrain 1-224: Loss: 0.4047 Acc: 25.0000%\n",
      "\ttrain 1-225: Loss: 0.3187 Acc: 50.0000%\n",
      "\ttrain 1-226: Loss: 0.4786 Acc: 25.0000%\n",
      "\ttrain 1-227: Loss: 0.5431 Acc: 25.0000%\n",
      "\ttrain 1-228: Loss: 0.9159 Acc: 0.0000%\n",
      "\ttrain 1-229: Loss: 0.1951 Acc: 50.0000%\n",
      "\ttrain 1-230: Loss: 0.3709 Acc: 50.0000%\n",
      "\ttrain 1-231: Loss: 0.3295 Acc: 25.0000%\n",
      "\ttrain 1-232: Loss: 0.2179 Acc: 50.0000%\n",
      "\ttrain 1-233: Loss: 0.3060 Acc: 50.0000%\n",
      "\ttrain 1-234: Loss: 0.3613 Acc: 50.0000%\n",
      "\ttrain 1-235: Loss: 0.4624 Acc: 0.0000%\n",
      "\ttrain 1-236: Loss: 0.2910 Acc: 50.0000%\n",
      "\ttrain 1-237: Loss: 1.2792 Acc: 0.0000%\n",
      "\ttrain 1-238: Loss: 0.3757 Acc: 75.0000%\n",
      "\ttrain 1-239: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 1-240: Loss: 0.2814 Acc: 50.0000%\n",
      "\ttrain 1-241: Loss: 0.7866 Acc: 50.0000%\n",
      "\ttrain 1-242: Loss: 0.5488 Acc: 25.0000%\n",
      "\ttrain 1-243: Loss: 0.3445 Acc: 50.0000%\n",
      "\ttrain 1-244: Loss: 0.8537 Acc: 25.0000%\n",
      "\ttrain 1-245: Loss: 0.5579 Acc: 0.0000%\n",
      "\tvalidation 1-1: Loss: 0.1792 Acc: 100.0000%\n",
      "\tvalidation 1-2: Loss: 0.2208 Acc: 100.0000%\n",
      "\tvalidation 1-3: Loss: 0.6092 Acc: 25.0000%\n",
      "\tvalidation 1-4: Loss: 0.6739 Acc: 50.0000%\n",
      "\tvalidation 1-5: Loss: 0.2547 Acc: 75.0000%\n",
      "\tvalidation 1-6: Loss: 0.1580 Acc: 100.0000%\n",
      "\tvalidation 1-7: Loss: 0.1113 Acc: 100.0000%\n",
      "\tvalidation 1-8: Loss: 0.3063 Acc: 75.0000%\n",
      "\tvalidation 1-9: Loss: 0.1806 Acc: 75.0000%\n",
      "\tvalidation 1-10: Loss: 0.1599 Acc: 75.0000%\n",
      "\tvalidation 1-11: Loss: 0.5329 Acc: 50.0000%\n",
      "\tvalidation 1-12: Loss: 0.4091 Acc: 25.0000%\n",
      "\tvalidation 1-13: Loss: 0.2352 Acc: 50.0000%\n",
      "\tvalidation 1-14: Loss: 0.2370 Acc: 75.0000%\n",
      "\tvalidation 1-15: Loss: 0.2398 Acc: 25.0000%\n",
      "\tvalidation 1-16: Loss: 0.2354 Acc: 75.0000%\n",
      "\tvalidation 1-17: Loss: 0.2327 Acc: 75.0000%\n",
      "\tvalidation 1-18: Loss: 0.1621 Acc: 75.0000%\n",
      "\tvalidation 1-19: Loss: 0.3017 Acc: 50.0000%\n",
      "\tvalidation 1-20: Loss: 0.4405 Acc: 50.0000%\n",
      "\tvalidation 1-21: Loss: 0.2966 Acc: 50.0000%\n",
      "\tvalidation 1-22: Loss: 0.2588 Acc: 75.0000%\n",
      "\tvalidation 1-23: Loss: 0.2073 Acc: 50.0000%\n",
      "\tvalidation 1-24: Loss: 0.1803 Acc: 75.0000%\n",
      "\tvalidation 1-25: Loss: 0.1857 Acc: 75.0000%\n",
      "\tvalidation 1-26: Loss: 0.2113 Acc: 100.0000%\n",
      "\tvalidation 1-27: Loss: 0.1368 Acc: 100.0000%\n",
      "\tvalidation 1-28: Loss: 1.0673 Acc: 50.0000%\n",
      "\tvalidation 1-29: Loss: 0.1463 Acc: 100.0000%\n",
      "\tvalidation 1-30: Loss: 0.1282 Acc: 75.0000%\n",
      "\tvalidation 1-31: Loss: 0.1306 Acc: 100.0000%\n",
      "\tvalidation 1-32: Loss: 0.1585 Acc: 75.0000%\n",
      "\tvalidation 1-33: Loss: 0.2033 Acc: 50.0000%\n",
      "\tvalidation 1-34: Loss: 0.2445 Acc: 25.0000%\n",
      "\tvalidation 1-35: Loss: 0.2030 Acc: 100.0000%\n",
      "\tvalidation 1-36: Loss: 0.4991 Acc: 50.0000%\n",
      "\tvalidation 1-37: Loss: 0.0756 Acc: 100.0000%\n",
      "\tvalidation 1-38: Loss: 0.2638 Acc: 75.0000%\n",
      "\tvalidation 1-39: Loss: 3.3788 Acc: 50.0000%\n",
      "\tvalidation 1-40: Loss: 0.3725 Acc: 50.0000%\n",
      "\tvalidation 1-41: Loss: 0.1896 Acc: 75.0000%\n",
      "\tvalidation 1-42: Loss: 0.5164 Acc: 50.0000%\n",
      "\tvalidation 1-43: Loss: 0.3662 Acc: 75.0000%\n",
      "\tvalidation 1-44: Loss: 0.1556 Acc: 100.0000%\n",
      "\tvalidation 1-45: Loss: 0.6867 Acc: 50.0000%\n",
      "\tvalidation 1-46: Loss: 0.1970 Acc: 75.0000%\n",
      "\tvalidation 1-47: Loss: 0.3182 Acc: 50.0000%\n",
      "\tvalidation 1-48: Loss: 0.2810 Acc: 25.0000%\n",
      "\tvalidation 1-49: Loss: 0.2549 Acc: 50.0000%\n",
      "\tvalidation 1-50: Loss: 0.1919 Acc: 75.0000%\n",
      "\tvalidation 1-51: Loss: 0.2396 Acc: 50.0000%\n",
      "\tvalidation 1-52: Loss: 1.0003 Acc: 50.0000%\n",
      "\tvalidation 1-53: Loss: 1.7693 Acc: 50.0000%\n",
      "\tvalidation 1-54: Loss: 0.2160 Acc: 50.0000%\n",
      "\tvalidation 1-55: Loss: 0.2614 Acc: 75.0000%\n",
      "\tvalidation 1-56: Loss: 0.2338 Acc: 50.0000%\n",
      "\tvalidation 1-57: Loss: 0.2542 Acc: 25.0000%\n",
      "\tvalidation 1-58: Loss: 0.2049 Acc: 75.0000%\n",
      "\tvalidation 1-59: Loss: 0.2546 Acc: 50.0000%\n",
      "\tvalidation 1-60: Loss: 0.2314 Acc: 50.0000%\n",
      "\tvalidation 1-61: Loss: 0.1632 Acc: 75.0000%\n",
      "\tvalidation 1-62: Loss: 0.2049 Acc: 100.0000%\n",
      "\tvalidation 1-63: Loss: 0.7781 Acc: 75.0000%\n",
      "\tvalidation 1-64: Loss: 0.2519 Acc: 50.0000%\n",
      "\tvalidation 1-65: Loss: 0.2116 Acc: 75.0000%\n",
      "\tvalidation 1-66: Loss: 0.2327 Acc: 75.0000%\n",
      "\tvalidation 1-67: Loss: 1.5952 Acc: 25.0000%\n",
      "\tvalidation 1-68: Loss: 0.3629 Acc: 50.0000%\n",
      "\tvalidation 1-69: Loss: 0.2734 Acc: 75.0000%\n",
      "\tvalidation 1-70: Loss: 0.1789 Acc: 100.0000%\n",
      "\tvalidation 1-71: Loss: 0.1189 Acc: 75.0000%\n",
      "\tvalidation 1-72: Loss: 0.1861 Acc: 75.0000%\n",
      "\tvalidation 1-73: Loss: 0.1374 Acc: 75.0000%\n",
      "\tvalidation 1-74: Loss: 0.1846 Acc: 75.0000%\n",
      "\tvalidation 1-75: Loss: 0.3493 Acc: 50.0000%\n",
      "\tvalidation 1-76: Loss: 0.1441 Acc: 75.0000%\n",
      "\tvalidation 1-77: Loss: 0.5066 Acc: 25.0000%\n",
      "\tvalidation 1-78: Loss: 0.1113 Acc: 100.0000%\n",
      "\tvalidation 1-79: Loss: 0.6656 Acc: 50.0000%\n",
      "\tvalidation 1-80: Loss: 1.0944 Acc: 75.0000%\n",
      "\tvalidation 1-81: Loss: 0.2126 Acc: 75.0000%\n",
      "\tvalidation 1-82: Loss: 0.2156 Acc: 100.0000%\n",
      "\tvalidation 1-83: Loss: 0.1839 Acc: 50.0000%\n",
      "\tvalidation 1-84: Loss: 1.1567 Acc: 75.0000%\n",
      "\tvalidation 1-85: Loss: 0.2185 Acc: 75.0000%\n",
      "\tvalidation 1-86: Loss: 0.8396 Acc: 25.0000%\n",
      "\tvalidation 1-87: Loss: 0.2052 Acc: 75.0000%\n",
      "\tvalidation 1-88: Loss: 0.7882 Acc: 75.0000%\n",
      "\tvalidation 1-89: Loss: 0.2290 Acc: 75.0000%\n",
      "\tvalidation 1-90: Loss: 0.1438 Acc: 100.0000%\n",
      "\tvalidation 1-91: Loss: 0.0661 Acc: 100.0000%\n",
      "\tvalidation 1-92: Loss: 0.2755 Acc: 50.0000%\n",
      "\tvalidation 1-93: Loss: 0.7552 Acc: 75.0000%\n",
      "\tvalidation 1-94: Loss: 0.4974 Acc: 25.0000%\n",
      "\tvalidation 1-95: Loss: 0.1865 Acc: 100.0000%\n",
      "\tvalidation 1-96: Loss: 0.2331 Acc: 75.0000%\n",
      "\tvalidation 1-97: Loss: 0.1870 Acc: 75.0000%\n",
      "\tvalidation 1-98: Loss: 0.1103 Acc: 100.0000%\n",
      "\tvalidation 1-99: Loss: 0.4863 Acc: 75.0000%\n",
      "\tvalidation 1-100: Loss: 0.1467 Acc: 100.0000%\n",
      "\tvalidation 1-101: Loss: 0.2299 Acc: 100.0000%\n",
      "\tvalidation 1-102: Loss: 1.6824 Acc: 50.0000%\n",
      "\tvalidation 1-103: Loss: 0.7269 Acc: 75.0000%\n",
      "\tvalidation 1-104: Loss: 0.7351 Acc: 50.0000%\n",
      "\tvalidation 1-105: Loss: 2.0818 Acc: 75.0000%\n",
      "\ttrain Loss: 0.5972 Acc: 28.4694%\n",
      "\tvalidation Loss: 0.4038 Acc: 67.8571%\n",
      "网络参数更新\n",
      "Time passed 0h 0m 40s\n",
      "--------------------\n",
      "Epoch [2/40]:\n",
      "\ttrain 2-1: Loss: 0.3083 Acc: 25.0000%\n",
      "\ttrain 2-2: Loss: 0.4047 Acc: 50.0000%\n",
      "\ttrain 2-3: Loss: 0.6819 Acc: 0.0000%\n",
      "\ttrain 2-4: Loss: 0.7586 Acc: 25.0000%\n",
      "\ttrain 2-5: Loss: 0.2781 Acc: 50.0000%\n",
      "\ttrain 2-6: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 2-7: Loss: 0.4339 Acc: 50.0000%\n",
      "\ttrain 2-8: Loss: 0.2445 Acc: 50.0000%\n",
      "\ttrain 2-9: Loss: 0.3546 Acc: 25.0000%\n",
      "\ttrain 2-10: Loss: 0.2671 Acc: 75.0000%\n",
      "\ttrain 2-11: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 2-12: Loss: 0.2678 Acc: 50.0000%\n",
      "\ttrain 2-13: Loss: 0.1935 Acc: 75.0000%\n",
      "\ttrain 2-14: Loss: 0.3790 Acc: 50.0000%\n",
      "\ttrain 2-15: Loss: 0.4713 Acc: 50.0000%\n",
      "\ttrain 2-16: Loss: 0.4835 Acc: 50.0000%\n",
      "\ttrain 2-17: Loss: 0.3870 Acc: 25.0000%\n",
      "\ttrain 2-18: Loss: 0.1406 Acc: 75.0000%\n",
      "\ttrain 2-19: Loss: 0.3491 Acc: 50.0000%\n",
      "\ttrain 2-20: Loss: 0.2351 Acc: 75.0000%\n",
      "\ttrain 2-21: Loss: 0.6420 Acc: 25.0000%\n",
      "\ttrain 2-22: Loss: 0.1869 Acc: 75.0000%\n",
      "\ttrain 2-23: Loss: 0.2647 Acc: 25.0000%\n",
      "\ttrain 2-24: Loss: 0.3444 Acc: 50.0000%\n",
      "\ttrain 2-25: Loss: 0.3174 Acc: 75.0000%\n",
      "\ttrain 2-26: Loss: 0.2634 Acc: 50.0000%\n",
      "\ttrain 2-27: Loss: 0.5313 Acc: 0.0000%\n",
      "\ttrain 2-28: Loss: 0.6679 Acc: 0.0000%\n",
      "\ttrain 2-29: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 2-30: Loss: 0.5080 Acc: 0.0000%\n",
      "\ttrain 2-31: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 2-32: Loss: 0.2926 Acc: 50.0000%\n",
      "\ttrain 2-33: Loss: 0.1657 Acc: 75.0000%\n",
      "\ttrain 2-34: Loss: 0.3739 Acc: 50.0000%\n",
      "\ttrain 2-35: Loss: 0.6393 Acc: 50.0000%\n",
      "\ttrain 2-36: Loss: 0.6518 Acc: 25.0000%\n",
      "\ttrain 2-37: Loss: 0.2083 Acc: 50.0000%\n",
      "\ttrain 2-38: Loss: 0.3117 Acc: 50.0000%\n",
      "\ttrain 2-39: Loss: 0.2093 Acc: 50.0000%\n",
      "\ttrain 2-40: Loss: 0.3328 Acc: 50.0000%\n",
      "\ttrain 2-41: Loss: 0.6412 Acc: 25.0000%\n",
      "\ttrain 2-42: Loss: 0.3121 Acc: 75.0000%\n",
      "\ttrain 2-43: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 2-44: Loss: 0.0834 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-45: Loss: 0.7875 Acc: 25.0000%\n",
      "\ttrain 2-46: Loss: 0.6786 Acc: 25.0000%\n",
      "\ttrain 2-47: Loss: 0.6498 Acc: 25.0000%\n",
      "\ttrain 2-48: Loss: 0.6389 Acc: 0.0000%\n",
      "\ttrain 2-49: Loss: 0.1578 Acc: 75.0000%\n",
      "\ttrain 2-50: Loss: 0.5564 Acc: 25.0000%\n",
      "\ttrain 2-51: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 2-52: Loss: 0.6010 Acc: 50.0000%\n",
      "\ttrain 2-53: Loss: 0.3790 Acc: 25.0000%\n",
      "\ttrain 2-54: Loss: 0.5451 Acc: 25.0000%\n",
      "\ttrain 2-55: Loss: 0.3204 Acc: 50.0000%\n",
      "\ttrain 2-56: Loss: 0.2475 Acc: 50.0000%\n",
      "\ttrain 2-57: Loss: 0.2907 Acc: 50.0000%\n",
      "\ttrain 2-58: Loss: 0.5756 Acc: 0.0000%\n",
      "\ttrain 2-59: Loss: 0.7504 Acc: 0.0000%\n",
      "\ttrain 2-60: Loss: 0.5515 Acc: 25.0000%\n",
      "\ttrain 2-61: Loss: 0.1825 Acc: 50.0000%\n",
      "\ttrain 2-62: Loss: 0.2954 Acc: 25.0000%\n",
      "\ttrain 2-63: Loss: 0.2609 Acc: 25.0000%\n",
      "\ttrain 2-64: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 2-65: Loss: 0.2150 Acc: 75.0000%\n",
      "\ttrain 2-66: Loss: 1.0349 Acc: 25.0000%\n",
      "\ttrain 2-67: Loss: 0.4397 Acc: 25.0000%\n",
      "\ttrain 2-68: Loss: 0.3986 Acc: 25.0000%\n",
      "\ttrain 2-69: Loss: 0.2447 Acc: 50.0000%\n",
      "\ttrain 2-70: Loss: 0.3223 Acc: 25.0000%\n",
      "\ttrain 2-71: Loss: 0.2380 Acc: 25.0000%\n",
      "\ttrain 2-72: Loss: 0.4386 Acc: 25.0000%\n",
      "\ttrain 2-73: Loss: 0.3387 Acc: 25.0000%\n",
      "\ttrain 2-74: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 2-75: Loss: 0.3563 Acc: 50.0000%\n",
      "\ttrain 2-76: Loss: 0.3945 Acc: 25.0000%\n",
      "\ttrain 2-77: Loss: 0.3642 Acc: 0.0000%\n",
      "\ttrain 2-78: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 2-79: Loss: 0.4473 Acc: 25.0000%\n",
      "\ttrain 2-80: Loss: 0.2890 Acc: 75.0000%\n",
      "\ttrain 2-81: Loss: 0.3414 Acc: 75.0000%\n",
      "\ttrain 2-82: Loss: 0.4015 Acc: 25.0000%\n",
      "\ttrain 2-83: Loss: 0.1483 Acc: 100.0000%\n",
      "\ttrain 2-84: Loss: 0.4140 Acc: 50.0000%\n",
      "\ttrain 2-85: Loss: 0.4734 Acc: 50.0000%\n",
      "\ttrain 2-86: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 2-87: Loss: 0.1717 Acc: 75.0000%\n",
      "\ttrain 2-88: Loss: 0.6421 Acc: 25.0000%\n",
      "\ttrain 2-89: Loss: 0.5795 Acc: 25.0000%\n",
      "\ttrain 2-90: Loss: 0.3752 Acc: 25.0000%\n",
      "\ttrain 2-91: Loss: 0.3314 Acc: 50.0000%\n",
      "\ttrain 2-92: Loss: 0.5876 Acc: 25.0000%\n",
      "\ttrain 2-93: Loss: 0.5285 Acc: 50.0000%\n",
      "\ttrain 2-94: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 2-95: Loss: 0.3397 Acc: 50.0000%\n",
      "\ttrain 2-96: Loss: 0.4339 Acc: 0.0000%\n",
      "\ttrain 2-97: Loss: 0.3640 Acc: 50.0000%\n",
      "\ttrain 2-98: Loss: 0.5171 Acc: 50.0000%\n",
      "\ttrain 2-99: Loss: 0.5046 Acc: 0.0000%\n",
      "\ttrain 2-100: Loss: 0.6422 Acc: 0.0000%\n",
      "\ttrain 2-101: Loss: 0.2663 Acc: 25.0000%\n",
      "\ttrain 2-102: Loss: 0.2438 Acc: 50.0000%\n",
      "\ttrain 2-103: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 2-104: Loss: 0.6230 Acc: 25.0000%\n",
      "\ttrain 2-105: Loss: 1.4136 Acc: 0.0000%\n",
      "\ttrain 2-106: Loss: 0.4729 Acc: 25.0000%\n",
      "\ttrain 2-107: Loss: 0.5361 Acc: 25.0000%\n",
      "\ttrain 2-108: Loss: 0.2262 Acc: 50.0000%\n",
      "\ttrain 2-109: Loss: 0.8501 Acc: 0.0000%\n",
      "\ttrain 2-110: Loss: 0.3362 Acc: 50.0000%\n",
      "\ttrain 2-111: Loss: 0.3682 Acc: 50.0000%\n",
      "\ttrain 2-112: Loss: 0.2406 Acc: 75.0000%\n",
      "\ttrain 2-113: Loss: 0.4176 Acc: 25.0000%\n",
      "\ttrain 2-114: Loss: 0.2577 Acc: 75.0000%\n",
      "\ttrain 2-115: Loss: 0.3880 Acc: 50.0000%\n",
      "\ttrain 2-116: Loss: 0.2552 Acc: 50.0000%\n",
      "\ttrain 2-117: Loss: 0.3104 Acc: 75.0000%\n",
      "\ttrain 2-118: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 2-119: Loss: 0.6776 Acc: 25.0000%\n",
      "\ttrain 2-120: Loss: 0.5336 Acc: 25.0000%\n",
      "\ttrain 2-121: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 2-122: Loss: 0.2631 Acc: 50.0000%\n",
      "\ttrain 2-123: Loss: 0.3579 Acc: 50.0000%\n",
      "\ttrain 2-124: Loss: 0.2623 Acc: 50.0000%\n",
      "\ttrain 2-125: Loss: 0.2581 Acc: 50.0000%\n",
      "\ttrain 2-126: Loss: 0.5832 Acc: 25.0000%\n",
      "\ttrain 2-127: Loss: 0.1042 Acc: 100.0000%\n",
      "\ttrain 2-128: Loss: 0.2497 Acc: 50.0000%\n",
      "\ttrain 2-129: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 2-130: Loss: 0.6226 Acc: 25.0000%\n",
      "\ttrain 2-131: Loss: 0.4879 Acc: 50.0000%\n",
      "\ttrain 2-132: Loss: 0.3689 Acc: 50.0000%\n",
      "\ttrain 2-133: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 2-134: Loss: 0.2159 Acc: 75.0000%\n",
      "\ttrain 2-135: Loss: 0.3046 Acc: 75.0000%\n",
      "\ttrain 2-136: Loss: 0.2635 Acc: 75.0000%\n",
      "\ttrain 2-137: Loss: 0.2282 Acc: 50.0000%\n",
      "\ttrain 2-138: Loss: 0.3851 Acc: 50.0000%\n",
      "\ttrain 2-139: Loss: 0.3419 Acc: 25.0000%\n",
      "\ttrain 2-140: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 2-141: Loss: 0.1844 Acc: 50.0000%\n",
      "\ttrain 2-142: Loss: 0.4666 Acc: 0.0000%\n",
      "\ttrain 2-143: Loss: 0.2058 Acc: 75.0000%\n",
      "\ttrain 2-144: Loss: 0.4978 Acc: 25.0000%\n",
      "\ttrain 2-145: Loss: 0.5464 Acc: 25.0000%\n",
      "\ttrain 2-146: Loss: 0.4226 Acc: 75.0000%\n",
      "\ttrain 2-147: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 2-148: Loss: 0.4596 Acc: 25.0000%\n",
      "\ttrain 2-149: Loss: 0.3124 Acc: 25.0000%\n",
      "\ttrain 2-150: Loss: 0.0992 Acc: 100.0000%\n",
      "\ttrain 2-151: Loss: 0.5698 Acc: 0.0000%\n",
      "\ttrain 2-152: Loss: 0.1781 Acc: 75.0000%\n",
      "\ttrain 2-153: Loss: 0.6192 Acc: 0.0000%\n",
      "\ttrain 2-154: Loss: 0.2826 Acc: 50.0000%\n",
      "\ttrain 2-155: Loss: 0.6349 Acc: 25.0000%\n",
      "\ttrain 2-156: Loss: 0.2524 Acc: 50.0000%\n",
      "\ttrain 2-157: Loss: 0.0958 Acc: 100.0000%\n",
      "\ttrain 2-158: Loss: 0.2600 Acc: 25.0000%\n",
      "\ttrain 2-159: Loss: 0.4021 Acc: 25.0000%\n",
      "\ttrain 2-160: Loss: 0.2124 Acc: 50.0000%\n",
      "\ttrain 2-161: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 2-162: Loss: 0.2671 Acc: 25.0000%\n",
      "\ttrain 2-163: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 2-164: Loss: 0.1897 Acc: 50.0000%\n",
      "\ttrain 2-165: Loss: 0.0989 Acc: 100.0000%\n",
      "\ttrain 2-166: Loss: 0.3537 Acc: 50.0000%\n",
      "\ttrain 2-167: Loss: 0.4266 Acc: 25.0000%\n",
      "\ttrain 2-168: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 2-169: Loss: 0.3208 Acc: 25.0000%\n",
      "\ttrain 2-170: Loss: 0.7334 Acc: 25.0000%\n",
      "\ttrain 2-171: Loss: 0.3115 Acc: 25.0000%\n",
      "\ttrain 2-172: Loss: 0.3213 Acc: 75.0000%\n",
      "\ttrain 2-173: Loss: 0.3892 Acc: 75.0000%\n",
      "\ttrain 2-174: Loss: 0.4210 Acc: 50.0000%\n",
      "\ttrain 2-175: Loss: 0.3320 Acc: 75.0000%\n",
      "\ttrain 2-176: Loss: 0.2363 Acc: 75.0000%\n",
      "\ttrain 2-177: Loss: 0.2075 Acc: 50.0000%\n",
      "\ttrain 2-178: Loss: 0.4084 Acc: 75.0000%\n",
      "\ttrain 2-179: Loss: 0.1994 Acc: 75.0000%\n",
      "\ttrain 2-180: Loss: 0.5154 Acc: 25.0000%\n",
      "\ttrain 2-181: Loss: 0.3595 Acc: 0.0000%\n",
      "\ttrain 2-182: Loss: 0.2156 Acc: 50.0000%\n",
      "\ttrain 2-183: Loss: 0.5438 Acc: 25.0000%\n",
      "\ttrain 2-184: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 2-185: Loss: 0.2784 Acc: 50.0000%\n",
      "\ttrain 2-186: Loss: 1.2156 Acc: 0.0000%\n",
      "\ttrain 2-187: Loss: 0.6601 Acc: 50.0000%\n",
      "\ttrain 2-188: Loss: 0.4827 Acc: 25.0000%\n",
      "\ttrain 2-189: Loss: 0.2216 Acc: 50.0000%\n",
      "\ttrain 2-190: Loss: 1.1317 Acc: 0.0000%\n",
      "\ttrain 2-191: Loss: 0.3425 Acc: 50.0000%\n",
      "\ttrain 2-192: Loss: 0.6572 Acc: 25.0000%\n",
      "\ttrain 2-193: Loss: 0.3487 Acc: 50.0000%\n",
      "\ttrain 2-194: Loss: 0.4343 Acc: 50.0000%\n",
      "\ttrain 2-195: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 2-196: Loss: 0.1937 Acc: 50.0000%\n",
      "\ttrain 2-197: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 2-198: Loss: 0.4792 Acc: 25.0000%\n",
      "\ttrain 2-199: Loss: 0.3051 Acc: 50.0000%\n",
      "\ttrain 2-200: Loss: 1.0020 Acc: 50.0000%\n",
      "\ttrain 2-201: Loss: 0.6351 Acc: 0.0000%\n",
      "\ttrain 2-202: Loss: 0.3529 Acc: 25.0000%\n",
      "\ttrain 2-203: Loss: 0.2199 Acc: 25.0000%\n",
      "\ttrain 2-204: Loss: 0.4441 Acc: 25.0000%\n",
      "\ttrain 2-205: Loss: 0.6018 Acc: 25.0000%\n",
      "\ttrain 2-206: Loss: 0.3265 Acc: 25.0000%\n",
      "\ttrain 2-207: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 2-208: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 2-209: Loss: 0.0830 Acc: 100.0000%\n",
      "\ttrain 2-210: Loss: 0.2583 Acc: 75.0000%\n",
      "\ttrain 2-211: Loss: 0.5901 Acc: 0.0000%\n",
      "\ttrain 2-212: Loss: 0.4158 Acc: 50.0000%\n",
      "\ttrain 2-213: Loss: 0.4585 Acc: 0.0000%\n",
      "\ttrain 2-214: Loss: 0.3155 Acc: 50.0000%\n",
      "\ttrain 2-215: Loss: 0.2229 Acc: 50.0000%\n",
      "\ttrain 2-216: Loss: 0.2877 Acc: 50.0000%\n",
      "\ttrain 2-217: Loss: 0.1579 Acc: 75.0000%\n",
      "\ttrain 2-218: Loss: 0.1955 Acc: 50.0000%\n",
      "\ttrain 2-219: Loss: 0.2778 Acc: 50.0000%\n",
      "\ttrain 2-220: Loss: 0.6305 Acc: 50.0000%\n",
      "\ttrain 2-221: Loss: 0.2514 Acc: 75.0000%\n",
      "\ttrain 2-222: Loss: 0.7079 Acc: 25.0000%\n",
      "\ttrain 2-223: Loss: 0.3410 Acc: 75.0000%\n",
      "\ttrain 2-224: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 2-225: Loss: 0.5052 Acc: 50.0000%\n",
      "\ttrain 2-226: Loss: 0.2113 Acc: 50.0000%\n",
      "\ttrain 2-227: Loss: 0.5327 Acc: 25.0000%\n",
      "\ttrain 2-228: Loss: 0.6647 Acc: 25.0000%\n",
      "\ttrain 2-229: Loss: 0.5827 Acc: 25.0000%\n",
      "\ttrain 2-230: Loss: 0.2183 Acc: 50.0000%\n",
      "\ttrain 2-231: Loss: 0.2348 Acc: 75.0000%\n",
      "\ttrain 2-232: Loss: 0.2748 Acc: 50.0000%\n",
      "\ttrain 2-233: Loss: 0.4011 Acc: 25.0000%\n",
      "\ttrain 2-234: Loss: 0.1665 Acc: 75.0000%\n",
      "\ttrain 2-235: Loss: 0.4120 Acc: 25.0000%\n",
      "\ttrain 2-236: Loss: 0.2091 Acc: 75.0000%\n",
      "\ttrain 2-237: Loss: 0.4263 Acc: 50.0000%\n",
      "\ttrain 2-238: Loss: 0.1734 Acc: 75.0000%\n",
      "\ttrain 2-239: Loss: 0.2317 Acc: 50.0000%\n",
      "\ttrain 2-240: Loss: 0.2369 Acc: 50.0000%\n",
      "\ttrain 2-241: Loss: 0.1049 Acc: 100.0000%\n",
      "\ttrain 2-242: Loss: 0.2834 Acc: 75.0000%\n",
      "\ttrain 2-243: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 2-244: Loss: 0.4160 Acc: 25.0000%\n",
      "\ttrain 2-245: Loss: 0.0633 Acc: 100.0000%\n",
      "\tvalidation 2-1: Loss: 0.2482 Acc: 75.0000%\n",
      "\tvalidation 2-2: Loss: 0.2785 Acc: 75.0000%\n",
      "\tvalidation 2-3: Loss: 0.0503 Acc: 100.0000%\n",
      "\tvalidation 2-4: Loss: 0.2351 Acc: 75.0000%\n",
      "\tvalidation 2-5: Loss: 0.1822 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-6: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 2-7: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 2-8: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 2-9: Loss: 0.2536 Acc: 75.0000%\n",
      "\tvalidation 2-10: Loss: 1.2421 Acc: 25.0000%\n",
      "\tvalidation 2-11: Loss: 0.2024 Acc: 75.0000%\n",
      "\tvalidation 2-12: Loss: 1.1162 Acc: 25.0000%\n",
      "\tvalidation 2-13: Loss: 0.3287 Acc: 75.0000%\n",
      "\tvalidation 2-14: Loss: 0.7176 Acc: 25.0000%\n",
      "\tvalidation 2-15: Loss: 0.7927 Acc: 50.0000%\n",
      "\tvalidation 2-16: Loss: 0.2787 Acc: 75.0000%\n",
      "\tvalidation 2-17: Loss: 0.1665 Acc: 75.0000%\n",
      "\tvalidation 2-18: Loss: 0.4566 Acc: 50.0000%\n",
      "\tvalidation 2-19: Loss: 1.5848 Acc: 50.0000%\n",
      "\tvalidation 2-20: Loss: 1.4561 Acc: 50.0000%\n",
      "\tvalidation 2-21: Loss: 0.2052 Acc: 75.0000%\n",
      "\tvalidation 2-22: Loss: 0.5005 Acc: 25.0000%\n",
      "\tvalidation 2-23: Loss: 0.4312 Acc: 50.0000%\n",
      "\tvalidation 2-24: Loss: 0.1561 Acc: 75.0000%\n",
      "\tvalidation 2-25: Loss: 0.1950 Acc: 75.0000%\n",
      "\tvalidation 2-26: Loss: 0.7367 Acc: 50.0000%\n",
      "\tvalidation 2-27: Loss: 0.2262 Acc: 75.0000%\n",
      "\tvalidation 2-28: Loss: 0.2259 Acc: 75.0000%\n",
      "\tvalidation 2-29: Loss: 0.5906 Acc: 25.0000%\n",
      "\tvalidation 2-30: Loss: 0.4277 Acc: 50.0000%\n",
      "\tvalidation 2-31: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 2-32: Loss: 0.4383 Acc: 50.0000%\n",
      "\tvalidation 2-33: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 2-34: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 2-35: Loss: 0.3965 Acc: 50.0000%\n",
      "\tvalidation 2-36: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 2-37: Loss: 0.7407 Acc: 50.0000%\n",
      "\tvalidation 2-38: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 2-39: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 2-40: Loss: 0.3875 Acc: 50.0000%\n",
      "\tvalidation 2-41: Loss: 0.3893 Acc: 50.0000%\n",
      "\tvalidation 2-42: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 2-43: Loss: 0.1771 Acc: 75.0000%\n",
      "\tvalidation 2-44: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 2-45: Loss: 0.6538 Acc: 50.0000%\n",
      "\tvalidation 2-46: Loss: 0.4776 Acc: 75.0000%\n",
      "\tvalidation 2-47: Loss: 0.7937 Acc: 25.0000%\n",
      "\tvalidation 2-48: Loss: 0.1112 Acc: 75.0000%\n",
      "\tvalidation 2-49: Loss: 0.3492 Acc: 50.0000%\n",
      "\tvalidation 2-50: Loss: 0.4156 Acc: 50.0000%\n",
      "\tvalidation 2-51: Loss: 0.2312 Acc: 75.0000%\n",
      "\tvalidation 2-52: Loss: 0.5050 Acc: 75.0000%\n",
      "\tvalidation 2-53: Loss: 0.0520 Acc: 100.0000%\n",
      "\tvalidation 2-54: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 2-55: Loss: 0.1015 Acc: 75.0000%\n",
      "\tvalidation 2-56: Loss: 0.1927 Acc: 75.0000%\n",
      "\tvalidation 2-57: Loss: 0.0432 Acc: 100.0000%\n",
      "\tvalidation 2-58: Loss: 0.9851 Acc: 50.0000%\n",
      "\tvalidation 2-59: Loss: 1.1062 Acc: 25.0000%\n",
      "\tvalidation 2-60: Loss: 0.2753 Acc: 75.0000%\n",
      "\tvalidation 2-61: Loss: 0.1700 Acc: 75.0000%\n",
      "\tvalidation 2-62: Loss: 0.2114 Acc: 75.0000%\n",
      "\tvalidation 2-63: Loss: 0.0561 Acc: 100.0000%\n",
      "\tvalidation 2-64: Loss: 0.1822 Acc: 75.0000%\n",
      "\tvalidation 2-65: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 2-66: Loss: 0.2185 Acc: 75.0000%\n",
      "\tvalidation 2-67: Loss: 0.0886 Acc: 75.0000%\n",
      "\tvalidation 2-68: Loss: 0.3019 Acc: 75.0000%\n",
      "\tvalidation 2-69: Loss: 2.3447 Acc: 75.0000%\n",
      "\tvalidation 2-70: Loss: 0.7012 Acc: 50.0000%\n",
      "\tvalidation 2-71: Loss: 0.3270 Acc: 50.0000%\n",
      "\tvalidation 2-72: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 2-73: Loss: 0.9728 Acc: 25.0000%\n",
      "\tvalidation 2-74: Loss: 0.9898 Acc: 75.0000%\n",
      "\tvalidation 2-75: Loss: 0.3591 Acc: 50.0000%\n",
      "\tvalidation 2-76: Loss: 0.1766 Acc: 75.0000%\n",
      "\tvalidation 2-77: Loss: 0.0819 Acc: 100.0000%\n",
      "\tvalidation 2-78: Loss: 0.3238 Acc: 75.0000%\n",
      "\tvalidation 2-79: Loss: 0.2358 Acc: 75.0000%\n",
      "\tvalidation 2-80: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 2-81: Loss: 0.2084 Acc: 75.0000%\n",
      "\tvalidation 2-82: Loss: 0.1960 Acc: 75.0000%\n",
      "\tvalidation 2-83: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 2-84: Loss: 0.1922 Acc: 75.0000%\n",
      "\tvalidation 2-85: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 2-86: Loss: 0.7288 Acc: 25.0000%\n",
      "\tvalidation 2-87: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 2-88: Loss: 0.4225 Acc: 50.0000%\n",
      "\tvalidation 2-89: Loss: 0.7049 Acc: 25.0000%\n",
      "\tvalidation 2-90: Loss: 0.3655 Acc: 50.0000%\n",
      "\tvalidation 2-91: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 2-92: Loss: 0.0584 Acc: 100.0000%\n",
      "\tvalidation 2-93: Loss: 0.3936 Acc: 50.0000%\n",
      "\tvalidation 2-94: Loss: 0.2357 Acc: 75.0000%\n",
      "\tvalidation 2-95: Loss: 0.1700 Acc: 75.0000%\n",
      "\tvalidation 2-96: Loss: 0.2828 Acc: 75.0000%\n",
      "\tvalidation 2-97: Loss: 0.2824 Acc: 50.0000%\n",
      "\tvalidation 2-98: Loss: 0.1717 Acc: 75.0000%\n",
      "\tvalidation 2-99: Loss: 0.4457 Acc: 50.0000%\n",
      "\tvalidation 2-100: Loss: 0.7997 Acc: 50.0000%\n",
      "\tvalidation 2-101: Loss: 0.6737 Acc: 50.0000%\n",
      "\tvalidation 2-102: Loss: 0.1561 Acc: 75.0000%\n",
      "\tvalidation 2-103: Loss: 0.2311 Acc: 75.0000%\n",
      "\tvalidation 2-104: Loss: 0.1661 Acc: 75.0000%\n",
      "\tvalidation 2-105: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain Loss: 0.3660 Acc: 46.6327%\n",
      "\tvalidation Loss: 0.3545 Acc: 70.2381%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 21s\n",
      "--------------------\n",
      "Epoch [3/40]:\n",
      "\ttrain 3-1: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 3-2: Loss: 0.4235 Acc: 25.0000%\n",
      "\ttrain 3-3: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 3-4: Loss: 0.8897 Acc: 25.0000%\n",
      "\ttrain 3-5: Loss: 1.1039 Acc: 0.0000%\n",
      "\ttrain 3-6: Loss: 0.7681 Acc: 25.0000%\n",
      "\ttrain 3-7: Loss: 0.2917 Acc: 50.0000%\n",
      "\ttrain 3-8: Loss: 0.4666 Acc: 25.0000%\n",
      "\ttrain 3-9: Loss: 0.1416 Acc: 75.0000%\n",
      "\ttrain 3-10: Loss: 0.0891 Acc: 100.0000%\n",
      "\ttrain 3-11: Loss: 0.5382 Acc: 25.0000%\n",
      "\ttrain 3-12: Loss: 0.4528 Acc: 50.0000%\n",
      "\ttrain 3-13: Loss: 0.9495 Acc: 0.0000%\n",
      "\ttrain 3-14: Loss: 0.6715 Acc: 25.0000%\n",
      "\ttrain 3-15: Loss: 0.9822 Acc: 0.0000%\n",
      "\ttrain 3-16: Loss: 0.4649 Acc: 25.0000%\n",
      "\ttrain 3-17: Loss: 0.3170 Acc: 50.0000%\n",
      "\ttrain 3-18: Loss: 0.3542 Acc: 50.0000%\n",
      "\ttrain 3-19: Loss: 0.1408 Acc: 100.0000%\n",
      "\ttrain 3-20: Loss: 0.3615 Acc: 25.0000%\n",
      "\ttrain 3-21: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 3-22: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 3-23: Loss: 0.1468 Acc: 75.0000%\n",
      "\ttrain 3-24: Loss: 0.2818 Acc: 25.0000%\n",
      "\ttrain 3-25: Loss: 0.5040 Acc: 25.0000%\n",
      "\ttrain 3-26: Loss: 0.7016 Acc: 25.0000%\n",
      "\ttrain 3-27: Loss: 0.4704 Acc: 25.0000%\n",
      "\ttrain 3-28: Loss: 0.2193 Acc: 50.0000%\n",
      "\ttrain 3-29: Loss: 0.3903 Acc: 75.0000%\n",
      "\ttrain 3-30: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 3-31: Loss: 0.3908 Acc: 25.0000%\n",
      "\ttrain 3-32: Loss: 0.4624 Acc: 0.0000%\n",
      "\ttrain 3-33: Loss: 0.2940 Acc: 50.0000%\n",
      "\ttrain 3-34: Loss: 0.3349 Acc: 75.0000%\n",
      "\ttrain 3-35: Loss: 0.2939 Acc: 25.0000%\n",
      "\ttrain 3-36: Loss: 0.2667 Acc: 50.0000%\n",
      "\ttrain 3-37: Loss: 0.1576 Acc: 50.0000%\n",
      "\ttrain 3-38: Loss: 0.2548 Acc: 50.0000%\n",
      "\ttrain 3-39: Loss: 0.1204 Acc: 100.0000%\n",
      "\ttrain 3-40: Loss: 0.2862 Acc: 25.0000%\n",
      "\ttrain 3-41: Loss: 0.3397 Acc: 50.0000%\n",
      "\ttrain 3-42: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 3-43: Loss: 0.3220 Acc: 50.0000%\n",
      "\ttrain 3-44: Loss: 0.5892 Acc: 0.0000%\n",
      "\ttrain 3-45: Loss: 0.2752 Acc: 50.0000%\n",
      "\ttrain 3-46: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 3-47: Loss: 0.5175 Acc: 25.0000%\n",
      "\ttrain 3-48: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 3-49: Loss: 0.5611 Acc: 25.0000%\n",
      "\ttrain 3-50: Loss: 0.3465 Acc: 50.0000%\n",
      "\ttrain 3-51: Loss: 0.2922 Acc: 50.0000%\n",
      "\ttrain 3-52: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 3-53: Loss: 0.1336 Acc: 100.0000%\n",
      "\ttrain 3-54: Loss: 0.4178 Acc: 50.0000%\n",
      "\ttrain 3-55: Loss: 0.3911 Acc: 25.0000%\n",
      "\ttrain 3-56: Loss: 0.1880 Acc: 75.0000%\n",
      "\ttrain 3-57: Loss: 0.2294 Acc: 25.0000%\n",
      "\ttrain 3-58: Loss: 0.3442 Acc: 75.0000%\n",
      "\ttrain 3-59: Loss: 0.2799 Acc: 50.0000%\n",
      "\ttrain 3-60: Loss: 0.2625 Acc: 75.0000%\n",
      "\ttrain 3-61: Loss: 0.2145 Acc: 75.0000%\n",
      "\ttrain 3-62: Loss: 0.5292 Acc: 50.0000%\n",
      "\ttrain 3-63: Loss: 0.2039 Acc: 50.0000%\n",
      "\ttrain 3-64: Loss: 0.0861 Acc: 100.0000%\n",
      "\ttrain 3-65: Loss: 0.3419 Acc: 50.0000%\n",
      "\ttrain 3-66: Loss: 0.3871 Acc: 75.0000%\n",
      "\ttrain 3-67: Loss: 0.6327 Acc: 25.0000%\n",
      "\ttrain 3-68: Loss: 0.6018 Acc: 25.0000%\n",
      "\ttrain 3-69: Loss: 0.2840 Acc: 75.0000%\n",
      "\ttrain 3-70: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 3-71: Loss: 0.7632 Acc: 25.0000%\n",
      "\ttrain 3-72: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 3-73: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 3-74: Loss: 0.3146 Acc: 50.0000%\n",
      "\ttrain 3-75: Loss: 0.3402 Acc: 25.0000%\n",
      "\ttrain 3-76: Loss: 0.2061 Acc: 50.0000%\n",
      "\ttrain 3-77: Loss: 0.8919 Acc: 0.0000%\n",
      "\ttrain 3-78: Loss: 0.6219 Acc: 50.0000%\n",
      "\ttrain 3-79: Loss: 0.5675 Acc: 75.0000%\n",
      "\ttrain 3-80: Loss: 0.3920 Acc: 50.0000%\n",
      "\ttrain 3-81: Loss: 0.3593 Acc: 50.0000%\n",
      "\ttrain 3-82: Loss: 0.5259 Acc: 75.0000%\n",
      "\ttrain 3-83: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 3-84: Loss: 0.6668 Acc: 25.0000%\n",
      "\ttrain 3-85: Loss: 0.5205 Acc: 75.0000%\n",
      "\ttrain 3-86: Loss: 0.4289 Acc: 25.0000%\n",
      "\ttrain 3-87: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 3-88: Loss: 0.3764 Acc: 75.0000%\n",
      "\ttrain 3-89: Loss: 0.6094 Acc: 50.0000%\n",
      "\ttrain 3-90: Loss: 0.6189 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-91: Loss: 0.5951 Acc: 25.0000%\n",
      "\ttrain 3-92: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 3-93: Loss: 0.4149 Acc: 50.0000%\n",
      "\ttrain 3-94: Loss: 0.2245 Acc: 25.0000%\n",
      "\ttrain 3-95: Loss: 0.4190 Acc: 0.0000%\n",
      "\ttrain 3-96: Loss: 0.8494 Acc: 0.0000%\n",
      "\ttrain 3-97: Loss: 0.7906 Acc: 0.0000%\n",
      "\ttrain 3-98: Loss: 0.5255 Acc: 75.0000%\n",
      "\ttrain 3-99: Loss: 0.6161 Acc: 25.0000%\n",
      "\ttrain 3-100: Loss: 1.0651 Acc: 0.0000%\n",
      "\ttrain 3-101: Loss: 0.1528 Acc: 75.0000%\n",
      "\ttrain 3-102: Loss: 0.1879 Acc: 50.0000%\n",
      "\ttrain 3-103: Loss: 0.4965 Acc: 25.0000%\n",
      "\ttrain 3-104: Loss: 0.4154 Acc: 50.0000%\n",
      "\ttrain 3-105: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 3-106: Loss: 0.4067 Acc: 50.0000%\n",
      "\ttrain 3-107: Loss: 0.9547 Acc: 25.0000%\n",
      "\ttrain 3-108: Loss: 0.5278 Acc: 50.0000%\n",
      "\ttrain 3-109: Loss: 0.4259 Acc: 25.0000%\n",
      "\ttrain 3-110: Loss: 0.1732 Acc: 75.0000%\n",
      "\ttrain 3-111: Loss: 0.2343 Acc: 50.0000%\n",
      "\ttrain 3-112: Loss: 0.4951 Acc: 25.0000%\n",
      "\ttrain 3-113: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 3-114: Loss: 0.5060 Acc: 0.0000%\n",
      "\ttrain 3-115: Loss: 0.5882 Acc: 25.0000%\n",
      "\ttrain 3-116: Loss: 0.1826 Acc: 25.0000%\n",
      "\ttrain 3-117: Loss: 0.4002 Acc: 75.0000%\n",
      "\ttrain 3-118: Loss: 0.3311 Acc: 50.0000%\n",
      "\ttrain 3-119: Loss: 0.3199 Acc: 50.0000%\n",
      "\ttrain 3-120: Loss: 0.5683 Acc: 25.0000%\n",
      "\ttrain 3-121: Loss: 0.1552 Acc: 75.0000%\n",
      "\ttrain 3-122: Loss: 0.3594 Acc: 25.0000%\n",
      "\ttrain 3-123: Loss: 0.2757 Acc: 50.0000%\n",
      "\ttrain 3-124: Loss: 0.3353 Acc: 25.0000%\n",
      "\ttrain 3-125: Loss: 0.1514 Acc: 75.0000%\n",
      "\ttrain 3-126: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 3-127: Loss: 0.2391 Acc: 25.0000%\n",
      "\ttrain 3-128: Loss: 0.2786 Acc: 50.0000%\n",
      "\ttrain 3-129: Loss: 0.1797 Acc: 50.0000%\n",
      "\ttrain 3-130: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 3-131: Loss: 0.2968 Acc: 25.0000%\n",
      "\ttrain 3-132: Loss: 0.1776 Acc: 50.0000%\n",
      "\ttrain 3-133: Loss: 0.6361 Acc: 25.0000%\n",
      "\ttrain 3-134: Loss: 0.2498 Acc: 75.0000%\n",
      "\ttrain 3-135: Loss: 0.1895 Acc: 50.0000%\n",
      "\ttrain 3-136: Loss: 0.1459 Acc: 75.0000%\n",
      "\ttrain 3-137: Loss: 0.2525 Acc: 50.0000%\n",
      "\ttrain 3-138: Loss: 0.5742 Acc: 25.0000%\n",
      "\ttrain 3-139: Loss: 0.5322 Acc: 25.0000%\n",
      "\ttrain 3-140: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 3-141: Loss: 0.2795 Acc: 50.0000%\n",
      "\ttrain 3-142: Loss: 0.2914 Acc: 25.0000%\n",
      "\ttrain 3-143: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 3-144: Loss: 0.2938 Acc: 50.0000%\n",
      "\ttrain 3-145: Loss: 0.2959 Acc: 75.0000%\n",
      "\ttrain 3-146: Loss: 0.3303 Acc: 50.0000%\n",
      "\ttrain 3-147: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 3-148: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 3-149: Loss: 0.4326 Acc: 50.0000%\n",
      "\ttrain 3-150: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 3-151: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 3-152: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 3-153: Loss: 0.3222 Acc: 25.0000%\n",
      "\ttrain 3-154: Loss: 0.2941 Acc: 25.0000%\n",
      "\ttrain 3-155: Loss: 0.3400 Acc: 50.0000%\n",
      "\ttrain 3-156: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 3-157: Loss: 0.6739 Acc: 0.0000%\n",
      "\ttrain 3-158: Loss: 0.3905 Acc: 75.0000%\n",
      "\ttrain 3-159: Loss: 0.1834 Acc: 75.0000%\n",
      "\ttrain 3-160: Loss: 0.1030 Acc: 100.0000%\n",
      "\ttrain 3-161: Loss: 0.2362 Acc: 50.0000%\n",
      "\ttrain 3-162: Loss: 0.2766 Acc: 50.0000%\n",
      "\ttrain 3-163: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 3-164: Loss: 0.3117 Acc: 50.0000%\n",
      "\ttrain 3-165: Loss: 0.4878 Acc: 0.0000%\n",
      "\ttrain 3-166: Loss: 0.2532 Acc: 50.0000%\n",
      "\ttrain 3-167: Loss: 0.1396 Acc: 50.0000%\n",
      "\ttrain 3-168: Loss: 0.5095 Acc: 0.0000%\n",
      "\ttrain 3-169: Loss: 0.3873 Acc: 25.0000%\n",
      "\ttrain 3-170: Loss: 0.2161 Acc: 50.0000%\n",
      "\ttrain 3-171: Loss: 0.3524 Acc: 50.0000%\n",
      "\ttrain 3-172: Loss: 0.3620 Acc: 25.0000%\n",
      "\ttrain 3-173: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 3-174: Loss: 0.5845 Acc: 25.0000%\n",
      "\ttrain 3-175: Loss: 0.1358 Acc: 75.0000%\n",
      "\ttrain 3-176: Loss: 0.3447 Acc: 75.0000%\n",
      "\ttrain 3-177: Loss: 0.3441 Acc: 50.0000%\n",
      "\ttrain 3-178: Loss: 0.5319 Acc: 25.0000%\n",
      "\ttrain 3-179: Loss: 0.5696 Acc: 25.0000%\n",
      "\ttrain 3-180: Loss: 0.2545 Acc: 50.0000%\n",
      "\ttrain 3-181: Loss: 0.4899 Acc: 25.0000%\n",
      "\ttrain 3-182: Loss: 0.1921 Acc: 75.0000%\n",
      "\ttrain 3-183: Loss: 0.1019 Acc: 100.0000%\n",
      "\ttrain 3-184: Loss: 0.2748 Acc: 25.0000%\n",
      "\ttrain 3-185: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 3-186: Loss: 0.4012 Acc: 75.0000%\n",
      "\ttrain 3-187: Loss: 0.5735 Acc: 0.0000%\n",
      "\ttrain 3-188: Loss: 1.2351 Acc: 0.0000%\n",
      "\ttrain 3-189: Loss: 0.2481 Acc: 50.0000%\n",
      "\ttrain 3-190: Loss: 0.5365 Acc: 50.0000%\n",
      "\ttrain 3-191: Loss: 0.1981 Acc: 50.0000%\n",
      "\ttrain 3-192: Loss: 0.4167 Acc: 50.0000%\n",
      "\ttrain 3-193: Loss: 0.8127 Acc: 25.0000%\n",
      "\ttrain 3-194: Loss: 0.0766 Acc: 100.0000%\n",
      "\ttrain 3-195: Loss: 0.2788 Acc: 50.0000%\n",
      "\ttrain 3-196: Loss: 0.3981 Acc: 50.0000%\n",
      "\ttrain 3-197: Loss: 0.4134 Acc: 50.0000%\n",
      "\ttrain 3-198: Loss: 0.2550 Acc: 50.0000%\n",
      "\ttrain 3-199: Loss: 0.7122 Acc: 25.0000%\n",
      "\ttrain 3-200: Loss: 0.3337 Acc: 75.0000%\n",
      "\ttrain 3-201: Loss: 0.5540 Acc: 25.0000%\n",
      "\ttrain 3-202: Loss: 0.0818 Acc: 100.0000%\n",
      "\ttrain 3-203: Loss: 0.1247 Acc: 100.0000%\n",
      "\ttrain 3-204: Loss: 0.1194 Acc: 100.0000%\n",
      "\ttrain 3-205: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 3-206: Loss: 0.7499 Acc: 25.0000%\n",
      "\ttrain 3-207: Loss: 0.6963 Acc: 25.0000%\n",
      "\ttrain 3-208: Loss: 0.5607 Acc: 25.0000%\n",
      "\ttrain 3-209: Loss: 0.4675 Acc: 50.0000%\n",
      "\ttrain 3-210: Loss: 0.5105 Acc: 25.0000%\n",
      "\ttrain 3-211: Loss: 0.3141 Acc: 25.0000%\n",
      "\ttrain 3-212: Loss: 0.2093 Acc: 75.0000%\n",
      "\ttrain 3-213: Loss: 0.1987 Acc: 50.0000%\n",
      "\ttrain 3-214: Loss: 0.5896 Acc: 50.0000%\n",
      "\ttrain 3-215: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 3-216: Loss: 0.7611 Acc: 50.0000%\n",
      "\ttrain 3-217: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 3-218: Loss: 0.2333 Acc: 75.0000%\n",
      "\ttrain 3-219: Loss: 0.9134 Acc: 25.0000%\n",
      "\ttrain 3-220: Loss: 0.2082 Acc: 50.0000%\n",
      "\ttrain 3-221: Loss: 0.0858 Acc: 100.0000%\n",
      "\ttrain 3-222: Loss: 0.6110 Acc: 75.0000%\n",
      "\ttrain 3-223: Loss: 0.8960 Acc: 50.0000%\n",
      "\ttrain 3-224: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 3-225: Loss: 0.2558 Acc: 75.0000%\n",
      "\ttrain 3-226: Loss: 0.4263 Acc: 75.0000%\n",
      "\ttrain 3-227: Loss: 0.3447 Acc: 50.0000%\n",
      "\ttrain 3-228: Loss: 0.3655 Acc: 50.0000%\n",
      "\ttrain 3-229: Loss: 0.4417 Acc: 25.0000%\n",
      "\ttrain 3-230: Loss: 0.2060 Acc: 50.0000%\n",
      "\ttrain 3-231: Loss: 0.1787 Acc: 50.0000%\n",
      "\ttrain 3-232: Loss: 0.2248 Acc: 50.0000%\n",
      "\ttrain 3-233: Loss: 0.2694 Acc: 25.0000%\n",
      "\ttrain 3-234: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 3-235: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 3-236: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 3-237: Loss: 0.2280 Acc: 75.0000%\n",
      "\ttrain 3-238: Loss: 0.3478 Acc: 0.0000%\n",
      "\ttrain 3-239: Loss: 0.4428 Acc: 0.0000%\n",
      "\ttrain 3-240: Loss: 0.3535 Acc: 25.0000%\n",
      "\ttrain 3-241: Loss: 0.2142 Acc: 50.0000%\n",
      "\ttrain 3-242: Loss: 0.1679 Acc: 50.0000%\n",
      "\ttrain 3-243: Loss: 0.1066 Acc: 100.0000%\n",
      "\ttrain 3-244: Loss: 0.5007 Acc: 25.0000%\n",
      "\ttrain 3-245: Loss: 0.6415 Acc: 25.0000%\n",
      "\tvalidation 3-1: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 3-2: Loss: 0.3025 Acc: 75.0000%\n",
      "\tvalidation 3-3: Loss: 0.1771 Acc: 50.0000%\n",
      "\tvalidation 3-4: Loss: 0.0896 Acc: 75.0000%\n",
      "\tvalidation 3-5: Loss: 0.2454 Acc: 75.0000%\n",
      "\tvalidation 3-6: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 3-7: Loss: 0.0886 Acc: 100.0000%\n",
      "\tvalidation 3-8: Loss: 0.1456 Acc: 50.0000%\n",
      "\tvalidation 3-9: Loss: 0.1488 Acc: 50.0000%\n",
      "\tvalidation 3-10: Loss: 0.4930 Acc: 25.0000%\n",
      "\tvalidation 3-11: Loss: 0.0767 Acc: 100.0000%\n",
      "\tvalidation 3-12: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 3-13: Loss: 0.0611 Acc: 100.0000%\n",
      "\tvalidation 3-14: Loss: 0.6289 Acc: 50.0000%\n",
      "\tvalidation 3-15: Loss: 0.1008 Acc: 100.0000%\n",
      "\tvalidation 3-16: Loss: 0.0985 Acc: 75.0000%\n",
      "\tvalidation 3-17: Loss: 0.1262 Acc: 75.0000%\n",
      "\tvalidation 3-18: Loss: 0.0968 Acc: 75.0000%\n",
      "\tvalidation 3-19: Loss: 0.0777 Acc: 75.0000%\n",
      "\tvalidation 3-20: Loss: 0.1854 Acc: 75.0000%\n",
      "\tvalidation 3-21: Loss: 0.3168 Acc: 75.0000%\n",
      "\tvalidation 3-22: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 3-23: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 3-24: Loss: 0.1013 Acc: 75.0000%\n",
      "\tvalidation 3-25: Loss: 0.1433 Acc: 50.0000%\n",
      "\tvalidation 3-26: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 3-27: Loss: 0.0781 Acc: 100.0000%\n",
      "\tvalidation 3-28: Loss: 0.0794 Acc: 75.0000%\n",
      "\tvalidation 3-29: Loss: 0.6177 Acc: 50.0000%\n",
      "\tvalidation 3-30: Loss: 0.1665 Acc: 75.0000%\n",
      "\tvalidation 3-31: Loss: 0.1593 Acc: 75.0000%\n",
      "\tvalidation 3-32: Loss: 0.1349 Acc: 50.0000%\n",
      "\tvalidation 3-33: Loss: 0.2121 Acc: 50.0000%\n",
      "\tvalidation 3-34: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 3-35: Loss: 0.0985 Acc: 75.0000%\n",
      "\tvalidation 3-36: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 3-37: Loss: 0.0809 Acc: 75.0000%\n",
      "\tvalidation 3-38: Loss: 0.0245 Acc: 100.0000%\n",
      "\tvalidation 3-39: Loss: 0.1908 Acc: 50.0000%\n",
      "\tvalidation 3-40: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 3-41: Loss: 0.2190 Acc: 50.0000%\n",
      "\tvalidation 3-42: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 3-43: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 3-44: Loss: 0.1565 Acc: 75.0000%\n",
      "\tvalidation 3-45: Loss: 0.0942 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-46: Loss: 0.2307 Acc: 25.0000%\n",
      "\tvalidation 3-47: Loss: 1.5142 Acc: 75.0000%\n",
      "\tvalidation 3-48: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 3-49: Loss: 0.6882 Acc: 75.0000%\n",
      "\tvalidation 3-50: Loss: 0.1004 Acc: 75.0000%\n",
      "\tvalidation 3-51: Loss: 0.0976 Acc: 75.0000%\n",
      "\tvalidation 3-52: Loss: 0.8577 Acc: 50.0000%\n",
      "\tvalidation 3-53: Loss: 0.0806 Acc: 100.0000%\n",
      "\tvalidation 3-54: Loss: 0.1118 Acc: 100.0000%\n",
      "\tvalidation 3-55: Loss: 0.1779 Acc: 75.0000%\n",
      "\tvalidation 3-56: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 3-57: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 3-58: Loss: 0.1783 Acc: 75.0000%\n",
      "\tvalidation 3-59: Loss: 0.1527 Acc: 50.0000%\n",
      "\tvalidation 3-60: Loss: 0.0654 Acc: 100.0000%\n",
      "\tvalidation 3-61: Loss: 0.0376 Acc: 100.0000%\n",
      "\tvalidation 3-62: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 3-63: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 3-64: Loss: 0.0542 Acc: 100.0000%\n",
      "\tvalidation 3-65: Loss: 0.1850 Acc: 50.0000%\n",
      "\tvalidation 3-66: Loss: 0.4478 Acc: 75.0000%\n",
      "\tvalidation 3-67: Loss: 0.0752 Acc: 75.0000%\n",
      "\tvalidation 3-68: Loss: 0.1554 Acc: 50.0000%\n",
      "\tvalidation 3-69: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 3-70: Loss: 0.1408 Acc: 50.0000%\n",
      "\tvalidation 3-71: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 3-72: Loss: 0.1503 Acc: 50.0000%\n",
      "\tvalidation 3-73: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 3-74: Loss: 0.6634 Acc: 75.0000%\n",
      "\tvalidation 3-75: Loss: 0.3129 Acc: 75.0000%\n",
      "\tvalidation 3-76: Loss: 0.0736 Acc: 75.0000%\n",
      "\tvalidation 3-77: Loss: 0.0822 Acc: 100.0000%\n",
      "\tvalidation 3-78: Loss: 0.1325 Acc: 75.0000%\n",
      "\tvalidation 3-79: Loss: 0.0855 Acc: 75.0000%\n",
      "\tvalidation 3-80: Loss: 0.0575 Acc: 100.0000%\n",
      "\tvalidation 3-81: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 3-82: Loss: 0.1285 Acc: 50.0000%\n",
      "\tvalidation 3-83: Loss: 0.0867 Acc: 75.0000%\n",
      "\tvalidation 3-84: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 3-85: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 3-86: Loss: 0.1967 Acc: 25.0000%\n",
      "\tvalidation 3-87: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 3-88: Loss: 0.0771 Acc: 75.0000%\n",
      "\tvalidation 3-89: Loss: 0.0854 Acc: 75.0000%\n",
      "\tvalidation 3-90: Loss: 0.1638 Acc: 50.0000%\n",
      "\tvalidation 3-91: Loss: 0.1838 Acc: 75.0000%\n",
      "\tvalidation 3-92: Loss: 0.1793 Acc: 50.0000%\n",
      "\tvalidation 3-93: Loss: 0.1053 Acc: 75.0000%\n",
      "\tvalidation 3-94: Loss: 0.3119 Acc: 75.0000%\n",
      "\tvalidation 3-95: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 3-96: Loss: 0.1590 Acc: 50.0000%\n",
      "\tvalidation 3-97: Loss: 0.0562 Acc: 100.0000%\n",
      "\tvalidation 3-98: Loss: 0.1365 Acc: 50.0000%\n",
      "\tvalidation 3-99: Loss: 0.1556 Acc: 50.0000%\n",
      "\tvalidation 3-100: Loss: 0.0652 Acc: 75.0000%\n",
      "\tvalidation 3-101: Loss: 0.0708 Acc: 75.0000%\n",
      "\tvalidation 3-102: Loss: 0.1306 Acc: 50.0000%\n",
      "\tvalidation 3-103: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 3-104: Loss: 0.1258 Acc: 75.0000%\n",
      "\tvalidation 3-105: Loss: 0.3219 Acc: 25.0000%\n",
      "\ttrain Loss: 0.3561 Acc: 50.1020%\n",
      "\tvalidation Loss: 0.1580 Acc: 75.4762%\n",
      "网络参数更新\n",
      "Time passed 0h 2m 1s\n",
      "--------------------\n",
      "Epoch [4/40]:\n",
      "\ttrain 4-1: Loss: 0.3595 Acc: 25.0000%\n",
      "\ttrain 4-2: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 4-3: Loss: 0.2409 Acc: 75.0000%\n",
      "\ttrain 4-4: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 4-5: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 4-6: Loss: 0.2088 Acc: 25.0000%\n",
      "\ttrain 4-7: Loss: 0.2532 Acc: 75.0000%\n",
      "\ttrain 4-8: Loss: 0.2428 Acc: 75.0000%\n",
      "\ttrain 4-9: Loss: 0.2413 Acc: 75.0000%\n",
      "\ttrain 4-10: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 4-11: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 4-12: Loss: 0.8725 Acc: 25.0000%\n",
      "\ttrain 4-13: Loss: 0.3133 Acc: 50.0000%\n",
      "\ttrain 4-14: Loss: 0.2634 Acc: 50.0000%\n",
      "\ttrain 4-15: Loss: 0.1137 Acc: 75.0000%\n",
      "\ttrain 4-16: Loss: 0.0831 Acc: 100.0000%\n",
      "\ttrain 4-17: Loss: 0.2033 Acc: 50.0000%\n",
      "\ttrain 4-18: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 4-19: Loss: 0.1217 Acc: 100.0000%\n",
      "\ttrain 4-20: Loss: 0.3040 Acc: 75.0000%\n",
      "\ttrain 4-21: Loss: 0.4403 Acc: 25.0000%\n",
      "\ttrain 4-22: Loss: 0.3567 Acc: 25.0000%\n",
      "\ttrain 4-23: Loss: 0.1953 Acc: 50.0000%\n",
      "\ttrain 4-24: Loss: 0.1607 Acc: 50.0000%\n",
      "\ttrain 4-25: Loss: 0.4901 Acc: 25.0000%\n",
      "\ttrain 4-26: Loss: 0.3778 Acc: 25.0000%\n",
      "\ttrain 4-27: Loss: 0.1652 Acc: 50.0000%\n",
      "\ttrain 4-28: Loss: 0.5343 Acc: 50.0000%\n",
      "\ttrain 4-29: Loss: 0.2364 Acc: 50.0000%\n",
      "\ttrain 4-30: Loss: 0.1220 Acc: 100.0000%\n",
      "\ttrain 4-31: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 4-32: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 4-33: Loss: 0.2272 Acc: 50.0000%\n",
      "\ttrain 4-34: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 4-35: Loss: 0.2297 Acc: 75.0000%\n",
      "\ttrain 4-36: Loss: 0.3768 Acc: 25.0000%\n",
      "\ttrain 4-37: Loss: 0.0748 Acc: 100.0000%\n",
      "\ttrain 4-38: Loss: 0.1814 Acc: 75.0000%\n",
      "\ttrain 4-39: Loss: 0.1967 Acc: 75.0000%\n",
      "\ttrain 4-40: Loss: 0.1727 Acc: 50.0000%\n",
      "\ttrain 4-41: Loss: 0.3862 Acc: 25.0000%\n",
      "\ttrain 4-42: Loss: 0.3455 Acc: 50.0000%\n",
      "\ttrain 4-43: Loss: 0.4326 Acc: 25.0000%\n",
      "\ttrain 4-44: Loss: 0.0923 Acc: 100.0000%\n",
      "\ttrain 4-45: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 4-46: Loss: 0.4934 Acc: 50.0000%\n",
      "\ttrain 4-47: Loss: 0.4340 Acc: 50.0000%\n",
      "\ttrain 4-48: Loss: 1.0440 Acc: 25.0000%\n",
      "\ttrain 4-49: Loss: 0.5548 Acc: 25.0000%\n",
      "\ttrain 4-50: Loss: 0.4752 Acc: 25.0000%\n",
      "\ttrain 4-51: Loss: 0.3617 Acc: 25.0000%\n",
      "\ttrain 4-52: Loss: 0.2186 Acc: 75.0000%\n",
      "\ttrain 4-53: Loss: 0.3753 Acc: 25.0000%\n",
      "\ttrain 4-54: Loss: 0.6310 Acc: 25.0000%\n",
      "\ttrain 4-55: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 4-56: Loss: 0.0840 Acc: 100.0000%\n",
      "\ttrain 4-57: Loss: 0.0814 Acc: 100.0000%\n",
      "\ttrain 4-58: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 4-59: Loss: 0.5414 Acc: 25.0000%\n",
      "\ttrain 4-60: Loss: 0.4658 Acc: 50.0000%\n",
      "\ttrain 4-61: Loss: 0.4547 Acc: 50.0000%\n",
      "\ttrain 4-62: Loss: 0.1651 Acc: 50.0000%\n",
      "\ttrain 4-63: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 4-64: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 4-65: Loss: 0.5515 Acc: 50.0000%\n",
      "\ttrain 4-66: Loss: 0.4780 Acc: 25.0000%\n",
      "\ttrain 4-67: Loss: 0.1803 Acc: 75.0000%\n",
      "\ttrain 4-68: Loss: 0.2280 Acc: 75.0000%\n",
      "\ttrain 4-69: Loss: 0.2828 Acc: 25.0000%\n",
      "\ttrain 4-70: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 4-71: Loss: 0.3481 Acc: 50.0000%\n",
      "\ttrain 4-72: Loss: 0.3265 Acc: 50.0000%\n",
      "\ttrain 4-73: Loss: 0.2237 Acc: 25.0000%\n",
      "\ttrain 4-74: Loss: 0.3812 Acc: 25.0000%\n",
      "\ttrain 4-75: Loss: 0.4286 Acc: 75.0000%\n",
      "\ttrain 4-76: Loss: 0.1005 Acc: 50.0000%\n",
      "\ttrain 4-77: Loss: 0.2862 Acc: 25.0000%\n",
      "\ttrain 4-78: Loss: 0.2143 Acc: 75.0000%\n",
      "\ttrain 4-79: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 4-80: Loss: 0.5799 Acc: 25.0000%\n",
      "\ttrain 4-81: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 4-82: Loss: 0.5379 Acc: 0.0000%\n",
      "\ttrain 4-83: Loss: 0.1207 Acc: 50.0000%\n",
      "\ttrain 4-84: Loss: 0.1621 Acc: 50.0000%\n",
      "\ttrain 4-85: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 4-86: Loss: 0.3365 Acc: 50.0000%\n",
      "\ttrain 4-87: Loss: 0.3771 Acc: 50.0000%\n",
      "\ttrain 4-88: Loss: 0.3387 Acc: 25.0000%\n",
      "\ttrain 4-89: Loss: 0.3784 Acc: 75.0000%\n",
      "\ttrain 4-90: Loss: 0.8396 Acc: 50.0000%\n",
      "\ttrain 4-91: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 4-92: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 4-93: Loss: 0.3450 Acc: 75.0000%\n",
      "\ttrain 4-94: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 4-95: Loss: 0.3323 Acc: 50.0000%\n",
      "\ttrain 4-96: Loss: 0.1939 Acc: 75.0000%\n",
      "\ttrain 4-97: Loss: 0.2113 Acc: 50.0000%\n",
      "\ttrain 4-98: Loss: 0.4533 Acc: 25.0000%\n",
      "\ttrain 4-99: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 4-100: Loss: 0.1291 Acc: 100.0000%\n",
      "\ttrain 4-101: Loss: 0.2503 Acc: 50.0000%\n",
      "\ttrain 4-102: Loss: 0.1684 Acc: 50.0000%\n",
      "\ttrain 4-103: Loss: 0.1225 Acc: 75.0000%\n",
      "\ttrain 4-104: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 4-105: Loss: 0.1961 Acc: 75.0000%\n",
      "\ttrain 4-106: Loss: 0.1223 Acc: 100.0000%\n",
      "\ttrain 4-107: Loss: 0.2478 Acc: 75.0000%\n",
      "\ttrain 4-108: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 4-109: Loss: 0.4585 Acc: 25.0000%\n",
      "\ttrain 4-110: Loss: 0.4450 Acc: 25.0000%\n",
      "\ttrain 4-111: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 4-112: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 4-113: Loss: 0.3745 Acc: 25.0000%\n",
      "\ttrain 4-114: Loss: 0.2354 Acc: 75.0000%\n",
      "\ttrain 4-115: Loss: 0.3296 Acc: 25.0000%\n",
      "\ttrain 4-116: Loss: 0.3064 Acc: 50.0000%\n",
      "\ttrain 4-117: Loss: 0.3332 Acc: 25.0000%\n",
      "\ttrain 4-118: Loss: 0.2734 Acc: 25.0000%\n",
      "\ttrain 4-119: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 4-120: Loss: 0.2034 Acc: 50.0000%\n",
      "\ttrain 4-121: Loss: 0.3240 Acc: 50.0000%\n",
      "\ttrain 4-122: Loss: 0.3450 Acc: 50.0000%\n",
      "\ttrain 4-123: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 4-124: Loss: 0.1145 Acc: 100.0000%\n",
      "\ttrain 4-125: Loss: 0.2410 Acc: 50.0000%\n",
      "\ttrain 4-126: Loss: 0.2618 Acc: 75.0000%\n",
      "\ttrain 4-127: Loss: 0.2541 Acc: 50.0000%\n",
      "\ttrain 4-128: Loss: 0.1945 Acc: 50.0000%\n",
      "\ttrain 4-129: Loss: 0.1450 Acc: 50.0000%\n",
      "\ttrain 4-130: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 4-131: Loss: 0.3855 Acc: 50.0000%\n",
      "\ttrain 4-132: Loss: 0.2121 Acc: 50.0000%\n",
      "\ttrain 4-133: Loss: 0.2813 Acc: 50.0000%\n",
      "\ttrain 4-134: Loss: 0.1365 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-135: Loss: 0.5940 Acc: 0.0000%\n",
      "\ttrain 4-136: Loss: 0.3885 Acc: 50.0000%\n",
      "\ttrain 4-137: Loss: 0.2027 Acc: 75.0000%\n",
      "\ttrain 4-138: Loss: 0.3207 Acc: 50.0000%\n",
      "\ttrain 4-139: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 4-140: Loss: 0.3875 Acc: 50.0000%\n",
      "\ttrain 4-141: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 4-142: Loss: 0.3414 Acc: 50.0000%\n",
      "\ttrain 4-143: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 4-144: Loss: 0.2273 Acc: 75.0000%\n",
      "\ttrain 4-145: Loss: 0.2950 Acc: 50.0000%\n",
      "\ttrain 4-146: Loss: 0.4572 Acc: 25.0000%\n",
      "\ttrain 4-147: Loss: 0.1856 Acc: 75.0000%\n",
      "\ttrain 4-148: Loss: 0.2593 Acc: 50.0000%\n",
      "\ttrain 4-149: Loss: 0.1825 Acc: 50.0000%\n",
      "\ttrain 4-150: Loss: 0.4937 Acc: 0.0000%\n",
      "\ttrain 4-151: Loss: 0.2011 Acc: 75.0000%\n",
      "\ttrain 4-152: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 4-153: Loss: 0.1908 Acc: 25.0000%\n",
      "\ttrain 4-154: Loss: 0.3573 Acc: 50.0000%\n",
      "\ttrain 4-155: Loss: 0.6129 Acc: 50.0000%\n",
      "\ttrain 4-156: Loss: 0.1915 Acc: 50.0000%\n",
      "\ttrain 4-157: Loss: 0.3197 Acc: 25.0000%\n",
      "\ttrain 4-158: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 4-159: Loss: 0.2066 Acc: 50.0000%\n",
      "\ttrain 4-160: Loss: 0.1596 Acc: 75.0000%\n",
      "\ttrain 4-161: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 4-162: Loss: 0.1642 Acc: 50.0000%\n",
      "\ttrain 4-163: Loss: 0.2402 Acc: 75.0000%\n",
      "\ttrain 4-164: Loss: 0.2996 Acc: 25.0000%\n",
      "\ttrain 4-165: Loss: 0.2195 Acc: 50.0000%\n",
      "\ttrain 4-166: Loss: 0.2706 Acc: 25.0000%\n",
      "\ttrain 4-167: Loss: 0.3063 Acc: 50.0000%\n",
      "\ttrain 4-168: Loss: 0.1749 Acc: 50.0000%\n",
      "\ttrain 4-169: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 4-170: Loss: 0.7137 Acc: 25.0000%\n",
      "\ttrain 4-171: Loss: 0.3066 Acc: 50.0000%\n",
      "\ttrain 4-172: Loss: 0.1938 Acc: 75.0000%\n",
      "\ttrain 4-173: Loss: 0.3581 Acc: 50.0000%\n",
      "\ttrain 4-174: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 4-175: Loss: 0.4127 Acc: 25.0000%\n",
      "\ttrain 4-176: Loss: 0.2015 Acc: 75.0000%\n",
      "\ttrain 4-177: Loss: 0.1480 Acc: 75.0000%\n",
      "\ttrain 4-178: Loss: 0.5194 Acc: 25.0000%\n",
      "\ttrain 4-179: Loss: 0.2566 Acc: 50.0000%\n",
      "\ttrain 4-180: Loss: 0.2517 Acc: 50.0000%\n",
      "\ttrain 4-181: Loss: 0.1256 Acc: 100.0000%\n",
      "\ttrain 4-182: Loss: 0.2652 Acc: 25.0000%\n",
      "\ttrain 4-183: Loss: 0.2859 Acc: 50.0000%\n",
      "\ttrain 4-184: Loss: 0.1759 Acc: 50.0000%\n",
      "\ttrain 4-185: Loss: 0.1780 Acc: 25.0000%\n",
      "\ttrain 4-186: Loss: 0.2361 Acc: 50.0000%\n",
      "\ttrain 4-187: Loss: 0.2746 Acc: 25.0000%\n",
      "\ttrain 4-188: Loss: 0.2958 Acc: 25.0000%\n",
      "\ttrain 4-189: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 4-190: Loss: 0.2432 Acc: 50.0000%\n",
      "\ttrain 4-191: Loss: 0.2117 Acc: 50.0000%\n",
      "\ttrain 4-192: Loss: 0.3299 Acc: 25.0000%\n",
      "\ttrain 4-193: Loss: 0.4875 Acc: 50.0000%\n",
      "\ttrain 4-194: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 4-195: Loss: 0.5509 Acc: 25.0000%\n",
      "\ttrain 4-196: Loss: 0.2762 Acc: 50.0000%\n",
      "\ttrain 4-197: Loss: 0.3302 Acc: 25.0000%\n",
      "\ttrain 4-198: Loss: 0.2631 Acc: 50.0000%\n",
      "\ttrain 4-199: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 4-200: Loss: 0.1984 Acc: 50.0000%\n",
      "\ttrain 4-201: Loss: 0.2869 Acc: 25.0000%\n",
      "\ttrain 4-202: Loss: 0.1651 Acc: 50.0000%\n",
      "\ttrain 4-203: Loss: 0.2708 Acc: 50.0000%\n",
      "\ttrain 4-204: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 4-205: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 4-206: Loss: 0.2818 Acc: 25.0000%\n",
      "\ttrain 4-207: Loss: 0.0879 Acc: 100.0000%\n",
      "\ttrain 4-208: Loss: 0.0839 Acc: 100.0000%\n",
      "\ttrain 4-209: Loss: 0.2893 Acc: 50.0000%\n",
      "\ttrain 4-210: Loss: 0.4241 Acc: 0.0000%\n",
      "\ttrain 4-211: Loss: 0.5245 Acc: 25.0000%\n",
      "\ttrain 4-212: Loss: 0.5063 Acc: 25.0000%\n",
      "\ttrain 4-213: Loss: 0.2968 Acc: 50.0000%\n",
      "\ttrain 4-214: Loss: 0.3456 Acc: 50.0000%\n",
      "\ttrain 4-215: Loss: 0.2700 Acc: 75.0000%\n",
      "\ttrain 4-216: Loss: 0.1538 Acc: 50.0000%\n",
      "\ttrain 4-217: Loss: 0.1559 Acc: 50.0000%\n",
      "\ttrain 4-218: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 4-219: Loss: 0.1895 Acc: 50.0000%\n",
      "\ttrain 4-220: Loss: 0.5084 Acc: 25.0000%\n",
      "\ttrain 4-221: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 4-222: Loss: 0.2194 Acc: 50.0000%\n",
      "\ttrain 4-223: Loss: 0.3509 Acc: 25.0000%\n",
      "\ttrain 4-224: Loss: 0.2632 Acc: 25.0000%\n",
      "\ttrain 4-225: Loss: 0.3602 Acc: 25.0000%\n",
      "\ttrain 4-226: Loss: 0.2648 Acc: 25.0000%\n",
      "\ttrain 4-227: Loss: 0.3641 Acc: 50.0000%\n",
      "\ttrain 4-228: Loss: 0.4991 Acc: 25.0000%\n",
      "\ttrain 4-229: Loss: 0.2070 Acc: 50.0000%\n",
      "\ttrain 4-230: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 4-231: Loss: 0.1214 Acc: 100.0000%\n",
      "\ttrain 4-232: Loss: 0.1638 Acc: 50.0000%\n",
      "\ttrain 4-233: Loss: 0.3370 Acc: 25.0000%\n",
      "\ttrain 4-234: Loss: 0.2812 Acc: 75.0000%\n",
      "\ttrain 4-235: Loss: 0.3621 Acc: 25.0000%\n",
      "\ttrain 4-236: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 4-237: Loss: 0.6491 Acc: 0.0000%\n",
      "\ttrain 4-238: Loss: 0.2821 Acc: 50.0000%\n",
      "\ttrain 4-239: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 4-240: Loss: 0.1330 Acc: 100.0000%\n",
      "\ttrain 4-241: Loss: 0.1440 Acc: 50.0000%\n",
      "\ttrain 4-242: Loss: 0.4172 Acc: 50.0000%\n",
      "\ttrain 4-243: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 4-244: Loss: 0.2065 Acc: 50.0000%\n",
      "\ttrain 4-245: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 4-1: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 4-2: Loss: 0.1887 Acc: 50.0000%\n",
      "\tvalidation 4-3: Loss: 0.9737 Acc: 50.0000%\n",
      "\tvalidation 4-4: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 4-5: Loss: 0.4389 Acc: 50.0000%\n",
      "\tvalidation 4-6: Loss: 0.0787 Acc: 75.0000%\n",
      "\tvalidation 4-7: Loss: 0.0526 Acc: 100.0000%\n",
      "\tvalidation 4-8: Loss: 0.0691 Acc: 100.0000%\n",
      "\tvalidation 4-9: Loss: 0.0732 Acc: 100.0000%\n",
      "\tvalidation 4-10: Loss: 0.1853 Acc: 75.0000%\n",
      "\tvalidation 4-11: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 4-12: Loss: 0.1344 Acc: 75.0000%\n",
      "\tvalidation 4-13: Loss: 0.0857 Acc: 100.0000%\n",
      "\tvalidation 4-14: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 4-15: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 4-16: Loss: 0.5482 Acc: 50.0000%\n",
      "\tvalidation 4-17: Loss: 0.1430 Acc: 50.0000%\n",
      "\tvalidation 4-18: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 4-19: Loss: 0.1581 Acc: 75.0000%\n",
      "\tvalidation 4-20: Loss: 0.0979 Acc: 75.0000%\n",
      "\tvalidation 4-21: Loss: 0.1759 Acc: 50.0000%\n",
      "\tvalidation 4-22: Loss: 0.0550 Acc: 100.0000%\n",
      "\tvalidation 4-23: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 4-24: Loss: 0.2096 Acc: 75.0000%\n",
      "\tvalidation 4-25: Loss: 0.1310 Acc: 75.0000%\n",
      "\tvalidation 4-26: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 4-27: Loss: 0.1650 Acc: 50.0000%\n",
      "\tvalidation 4-28: Loss: 0.5943 Acc: 75.0000%\n",
      "\tvalidation 4-29: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 4-30: Loss: 0.9107 Acc: 75.0000%\n",
      "\tvalidation 4-31: Loss: 0.0803 Acc: 75.0000%\n",
      "\tvalidation 4-32: Loss: 0.0874 Acc: 75.0000%\n",
      "\tvalidation 4-33: Loss: 0.1345 Acc: 75.0000%\n",
      "\tvalidation 4-34: Loss: 0.2561 Acc: 25.0000%\n",
      "\tvalidation 4-35: Loss: 0.5259 Acc: 50.0000%\n",
      "\tvalidation 4-36: Loss: 0.0851 Acc: 75.0000%\n",
      "\tvalidation 4-37: Loss: 0.1486 Acc: 75.0000%\n",
      "\tvalidation 4-38: Loss: 0.1039 Acc: 75.0000%\n",
      "\tvalidation 4-39: Loss: 0.0885 Acc: 75.0000%\n",
      "\tvalidation 4-40: Loss: 0.4292 Acc: 25.0000%\n",
      "\tvalidation 4-41: Loss: 0.8038 Acc: 0.0000%\n",
      "\tvalidation 4-42: Loss: 0.2046 Acc: 50.0000%\n",
      "\tvalidation 4-43: Loss: 0.2219 Acc: 50.0000%\n",
      "\tvalidation 4-44: Loss: 0.1882 Acc: 75.0000%\n",
      "\tvalidation 4-45: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 4-46: Loss: 0.1116 Acc: 75.0000%\n",
      "\tvalidation 4-47: Loss: 0.2337 Acc: 25.0000%\n",
      "\tvalidation 4-48: Loss: 0.8995 Acc: 50.0000%\n",
      "\tvalidation 4-49: Loss: 0.0673 Acc: 100.0000%\n",
      "\tvalidation 4-50: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 4-51: Loss: 0.1097 Acc: 75.0000%\n",
      "\tvalidation 4-52: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 4-53: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 4-54: Loss: 0.1044 Acc: 75.0000%\n",
      "\tvalidation 4-55: Loss: 0.1866 Acc: 50.0000%\n",
      "\tvalidation 4-56: Loss: 0.1157 Acc: 75.0000%\n",
      "\tvalidation 4-57: Loss: 0.0468 Acc: 100.0000%\n",
      "\tvalidation 4-58: Loss: 0.3908 Acc: 75.0000%\n",
      "\tvalidation 4-59: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 4-60: Loss: 0.0645 Acc: 100.0000%\n",
      "\tvalidation 4-61: Loss: 0.1854 Acc: 50.0000%\n",
      "\tvalidation 4-62: Loss: 0.1492 Acc: 75.0000%\n",
      "\tvalidation 4-63: Loss: 0.5718 Acc: 25.0000%\n",
      "\tvalidation 4-64: Loss: 0.3450 Acc: 50.0000%\n",
      "\tvalidation 4-65: Loss: 0.0523 Acc: 100.0000%\n",
      "\tvalidation 4-66: Loss: 0.1727 Acc: 75.0000%\n",
      "\tvalidation 4-67: Loss: 0.1363 Acc: 75.0000%\n",
      "\tvalidation 4-68: Loss: 0.3073 Acc: 50.0000%\n",
      "\tvalidation 4-69: Loss: 0.1028 Acc: 75.0000%\n",
      "\tvalidation 4-70: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 4-71: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 4-72: Loss: 0.1004 Acc: 75.0000%\n",
      "\tvalidation 4-73: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 4-74: Loss: 0.0733 Acc: 75.0000%\n",
      "\tvalidation 4-75: Loss: 0.1221 Acc: 75.0000%\n",
      "\tvalidation 4-76: Loss: 0.2107 Acc: 75.0000%\n",
      "\tvalidation 4-77: Loss: 0.7518 Acc: 50.0000%\n",
      "\tvalidation 4-78: Loss: 0.5093 Acc: 50.0000%\n",
      "\tvalidation 4-79: Loss: 0.2301 Acc: 50.0000%\n",
      "\tvalidation 4-80: Loss: 0.1109 Acc: 75.0000%\n",
      "\tvalidation 4-81: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 4-82: Loss: 0.1503 Acc: 75.0000%\n",
      "\tvalidation 4-83: Loss: 0.0902 Acc: 75.0000%\n",
      "\tvalidation 4-84: Loss: 0.0925 Acc: 75.0000%\n",
      "\tvalidation 4-85: Loss: 0.1246 Acc: 75.0000%\n",
      "\tvalidation 4-86: Loss: 0.1112 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 4-87: Loss: 0.0827 Acc: 75.0000%\n",
      "\tvalidation 4-88: Loss: 0.1050 Acc: 75.0000%\n",
      "\tvalidation 4-89: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 4-90: Loss: 0.1853 Acc: 75.0000%\n",
      "\tvalidation 4-91: Loss: 0.0885 Acc: 75.0000%\n",
      "\tvalidation 4-92: Loss: 0.1420 Acc: 75.0000%\n",
      "\tvalidation 4-93: Loss: 0.1687 Acc: 75.0000%\n",
      "\tvalidation 4-94: Loss: 0.1119 Acc: 75.0000%\n",
      "\tvalidation 4-95: Loss: 0.0460 Acc: 100.0000%\n",
      "\tvalidation 4-96: Loss: 0.1421 Acc: 50.0000%\n",
      "\tvalidation 4-97: Loss: 0.0393 Acc: 100.0000%\n",
      "\tvalidation 4-98: Loss: 0.1471 Acc: 75.0000%\n",
      "\tvalidation 4-99: Loss: 0.0691 Acc: 100.0000%\n",
      "\tvalidation 4-100: Loss: 0.0515 Acc: 100.0000%\n",
      "\tvalidation 4-101: Loss: 1.7437 Acc: 50.0000%\n",
      "\tvalidation 4-102: Loss: 0.1975 Acc: 50.0000%\n",
      "\tvalidation 4-103: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 4-104: Loss: 0.0805 Acc: 75.0000%\n",
      "\tvalidation 4-105: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2669 Acc: 55.0000%\n",
      "\tvalidation Loss: 0.1927 Acc: 74.7619%\n",
      "Time passed 0h 2m 40s\n",
      "--------------------\n",
      "Epoch [5/40]:\n",
      "\ttrain 5-1: Loss: 0.3262 Acc: 50.0000%\n",
      "\ttrain 5-2: Loss: 0.0825 Acc: 100.0000%\n",
      "\ttrain 5-3: Loss: 0.2224 Acc: 50.0000%\n",
      "\ttrain 5-4: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 5-5: Loss: 0.2395 Acc: 50.0000%\n",
      "\ttrain 5-6: Loss: 0.3667 Acc: 50.0000%\n",
      "\ttrain 5-7: Loss: 0.0893 Acc: 100.0000%\n",
      "\ttrain 5-8: Loss: 0.2374 Acc: 75.0000%\n",
      "\ttrain 5-9: Loss: 0.1759 Acc: 75.0000%\n",
      "\ttrain 5-10: Loss: 0.1742 Acc: 75.0000%\n",
      "\ttrain 5-11: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 5-12: Loss: 0.1086 Acc: 100.0000%\n",
      "\ttrain 5-13: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 5-14: Loss: 0.2186 Acc: 75.0000%\n",
      "\ttrain 5-15: Loss: 0.6654 Acc: 25.0000%\n",
      "\ttrain 5-16: Loss: 0.7780 Acc: 25.0000%\n",
      "\ttrain 5-17: Loss: 0.2861 Acc: 25.0000%\n",
      "\ttrain 5-18: Loss: 0.9840 Acc: 25.0000%\n",
      "\ttrain 5-19: Loss: 0.3937 Acc: 75.0000%\n",
      "\ttrain 5-20: Loss: 0.5202 Acc: 25.0000%\n",
      "\ttrain 5-21: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 5-22: Loss: 0.2956 Acc: 50.0000%\n",
      "\ttrain 5-23: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 5-24: Loss: 0.3933 Acc: 25.0000%\n",
      "\ttrain 5-25: Loss: 0.2054 Acc: 75.0000%\n",
      "\ttrain 5-26: Loss: 0.3216 Acc: 50.0000%\n",
      "\ttrain 5-27: Loss: 0.6904 Acc: 50.0000%\n",
      "\ttrain 5-28: Loss: 0.4660 Acc: 50.0000%\n",
      "\ttrain 5-29: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 5-30: Loss: 0.5302 Acc: 50.0000%\n",
      "\ttrain 5-31: Loss: 0.3019 Acc: 50.0000%\n",
      "\ttrain 5-32: Loss: 0.2629 Acc: 75.0000%\n",
      "\ttrain 5-33: Loss: 0.0845 Acc: 100.0000%\n",
      "\ttrain 5-34: Loss: 0.3617 Acc: 25.0000%\n",
      "\ttrain 5-35: Loss: 0.2063 Acc: 50.0000%\n",
      "\ttrain 5-36: Loss: 0.1898 Acc: 50.0000%\n",
      "\ttrain 5-37: Loss: 0.3500 Acc: 25.0000%\n",
      "\ttrain 5-38: Loss: 0.3770 Acc: 25.0000%\n",
      "\ttrain 5-39: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 5-40: Loss: 0.2712 Acc: 75.0000%\n",
      "\ttrain 5-41: Loss: 0.2944 Acc: 50.0000%\n",
      "\ttrain 5-42: Loss: 0.2257 Acc: 50.0000%\n",
      "\ttrain 5-43: Loss: 0.2603 Acc: 50.0000%\n",
      "\ttrain 5-44: Loss: 0.4147 Acc: 25.0000%\n",
      "\ttrain 5-45: Loss: 0.2075 Acc: 75.0000%\n",
      "\ttrain 5-46: Loss: 0.2648 Acc: 75.0000%\n",
      "\ttrain 5-47: Loss: 0.1664 Acc: 75.0000%\n",
      "\ttrain 5-48: Loss: 0.1557 Acc: 100.0000%\n",
      "\ttrain 5-49: Loss: 0.3148 Acc: 50.0000%\n",
      "\ttrain 5-50: Loss: 0.3306 Acc: 50.0000%\n",
      "\ttrain 5-51: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 5-52: Loss: 0.3982 Acc: 50.0000%\n",
      "\ttrain 5-53: Loss: 0.3398 Acc: 50.0000%\n",
      "\ttrain 5-54: Loss: 0.3240 Acc: 50.0000%\n",
      "\ttrain 5-55: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 5-56: Loss: 0.2950 Acc: 25.0000%\n",
      "\ttrain 5-57: Loss: 0.1967 Acc: 50.0000%\n",
      "\ttrain 5-58: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 5-59: Loss: 0.3603 Acc: 75.0000%\n",
      "\ttrain 5-60: Loss: 0.4570 Acc: 0.0000%\n",
      "\ttrain 5-61: Loss: 0.3581 Acc: 25.0000%\n",
      "\ttrain 5-62: Loss: 0.1897 Acc: 50.0000%\n",
      "\ttrain 5-63: Loss: 0.1741 Acc: 50.0000%\n",
      "\ttrain 5-64: Loss: 0.3929 Acc: 25.0000%\n",
      "\ttrain 5-65: Loss: 0.4224 Acc: 50.0000%\n",
      "\ttrain 5-66: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 5-67: Loss: 0.1724 Acc: 75.0000%\n",
      "\ttrain 5-68: Loss: 0.2306 Acc: 50.0000%\n",
      "\ttrain 5-69: Loss: 0.2574 Acc: 50.0000%\n",
      "\ttrain 5-70: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 5-71: Loss: 0.2668 Acc: 50.0000%\n",
      "\ttrain 5-72: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 5-73: Loss: 0.3952 Acc: 25.0000%\n",
      "\ttrain 5-74: Loss: 0.2306 Acc: 50.0000%\n",
      "\ttrain 5-75: Loss: 0.2122 Acc: 50.0000%\n",
      "\ttrain 5-76: Loss: 0.2037 Acc: 50.0000%\n",
      "\ttrain 5-77: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 5-78: Loss: 0.4871 Acc: 25.0000%\n",
      "\ttrain 5-79: Loss: 0.4014 Acc: 25.0000%\n",
      "\ttrain 5-80: Loss: 0.2914 Acc: 75.0000%\n",
      "\ttrain 5-81: Loss: 0.3159 Acc: 50.0000%\n",
      "\ttrain 5-82: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 5-83: Loss: 0.2153 Acc: 50.0000%\n",
      "\ttrain 5-84: Loss: 0.2938 Acc: 50.0000%\n",
      "\ttrain 5-85: Loss: 0.5323 Acc: 25.0000%\n",
      "\ttrain 5-86: Loss: 0.2331 Acc: 50.0000%\n",
      "\ttrain 5-87: Loss: 0.3073 Acc: 75.0000%\n",
      "\ttrain 5-88: Loss: 0.3290 Acc: 50.0000%\n",
      "\ttrain 5-89: Loss: 0.6225 Acc: 25.0000%\n",
      "\ttrain 5-90: Loss: 0.9251 Acc: 25.0000%\n",
      "\ttrain 5-91: Loss: 0.3877 Acc: 25.0000%\n",
      "\ttrain 5-92: Loss: 0.2640 Acc: 50.0000%\n",
      "\ttrain 5-93: Loss: 0.3496 Acc: 25.0000%\n",
      "\ttrain 5-94: Loss: 0.3124 Acc: 50.0000%\n",
      "\ttrain 5-95: Loss: 0.2911 Acc: 50.0000%\n",
      "\ttrain 5-96: Loss: 0.2045 Acc: 50.0000%\n",
      "\ttrain 5-97: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 5-98: Loss: 0.2732 Acc: 50.0000%\n",
      "\ttrain 5-99: Loss: 0.0594 Acc: 75.0000%\n",
      "\ttrain 5-100: Loss: 0.1972 Acc: 50.0000%\n",
      "\ttrain 5-101: Loss: 0.3783 Acc: 25.0000%\n",
      "\ttrain 5-102: Loss: 0.3089 Acc: 25.0000%\n",
      "\ttrain 5-103: Loss: 0.2384 Acc: 75.0000%\n",
      "\ttrain 5-104: Loss: 0.3140 Acc: 50.0000%\n",
      "\ttrain 5-105: Loss: 0.2460 Acc: 50.0000%\n",
      "\ttrain 5-106: Loss: 0.3081 Acc: 75.0000%\n",
      "\ttrain 5-107: Loss: 0.3291 Acc: 50.0000%\n",
      "\ttrain 5-108: Loss: 0.5519 Acc: 25.0000%\n",
      "\ttrain 5-109: Loss: 0.0713 Acc: 100.0000%\n",
      "\ttrain 5-110: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 5-111: Loss: 0.4849 Acc: 25.0000%\n",
      "\ttrain 5-112: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 5-113: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 5-114: Loss: 0.3580 Acc: 25.0000%\n",
      "\ttrain 5-115: Loss: 0.2944 Acc: 50.0000%\n",
      "\ttrain 5-116: Loss: 0.3023 Acc: 0.0000%\n",
      "\ttrain 5-117: Loss: 0.4208 Acc: 25.0000%\n",
      "\ttrain 5-118: Loss: 0.2439 Acc: 50.0000%\n",
      "\ttrain 5-119: Loss: 0.2302 Acc: 50.0000%\n",
      "\ttrain 5-120: Loss: 0.5787 Acc: 50.0000%\n",
      "\ttrain 5-121: Loss: 0.1971 Acc: 50.0000%\n",
      "\ttrain 5-122: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 5-123: Loss: 0.2461 Acc: 75.0000%\n",
      "\ttrain 5-124: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 5-125: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 5-126: Loss: 0.0919 Acc: 100.0000%\n",
      "\ttrain 5-127: Loss: 0.1820 Acc: 50.0000%\n",
      "\ttrain 5-128: Loss: 0.3105 Acc: 25.0000%\n",
      "\ttrain 5-129: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 5-130: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 5-131: Loss: 0.2352 Acc: 50.0000%\n",
      "\ttrain 5-132: Loss: 0.5127 Acc: 25.0000%\n",
      "\ttrain 5-133: Loss: 0.2401 Acc: 50.0000%\n",
      "\ttrain 5-134: Loss: 0.3269 Acc: 25.0000%\n",
      "\ttrain 5-135: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 5-136: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 5-137: Loss: 0.2962 Acc: 50.0000%\n",
      "\ttrain 5-138: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 5-139: Loss: 0.1532 Acc: 50.0000%\n",
      "\ttrain 5-140: Loss: 0.1868 Acc: 75.0000%\n",
      "\ttrain 5-141: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 5-142: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 5-143: Loss: 0.1530 Acc: 50.0000%\n",
      "\ttrain 5-144: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 5-145: Loss: 0.2137 Acc: 50.0000%\n",
      "\ttrain 5-146: Loss: 0.1896 Acc: 75.0000%\n",
      "\ttrain 5-147: Loss: 0.1500 Acc: 50.0000%\n",
      "\ttrain 5-148: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 5-149: Loss: 0.2442 Acc: 50.0000%\n",
      "\ttrain 5-150: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 5-151: Loss: 0.3997 Acc: 50.0000%\n",
      "\ttrain 5-152: Loss: 0.1566 Acc: 75.0000%\n",
      "\ttrain 5-153: Loss: 0.3136 Acc: 50.0000%\n",
      "\ttrain 5-154: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 5-155: Loss: 0.2824 Acc: 50.0000%\n",
      "\ttrain 5-156: Loss: 0.3599 Acc: 50.0000%\n",
      "\ttrain 5-157: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 5-158: Loss: 0.2862 Acc: 25.0000%\n",
      "\ttrain 5-159: Loss: 0.1243 Acc: 100.0000%\n",
      "\ttrain 5-160: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 5-161: Loss: 0.2873 Acc: 75.0000%\n",
      "\ttrain 5-162: Loss: 0.1604 Acc: 75.0000%\n",
      "\ttrain 5-163: Loss: 0.4485 Acc: 25.0000%\n",
      "\ttrain 5-164: Loss: 0.2072 Acc: 50.0000%\n",
      "\ttrain 5-165: Loss: 0.3798 Acc: 75.0000%\n",
      "\ttrain 5-166: Loss: 0.1850 Acc: 75.0000%\n",
      "\ttrain 5-167: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 5-168: Loss: 0.2401 Acc: 50.0000%\n",
      "\ttrain 5-169: Loss: 0.4361 Acc: 50.0000%\n",
      "\ttrain 5-170: Loss: 0.1757 Acc: 50.0000%\n",
      "\ttrain 5-171: Loss: 0.3394 Acc: 50.0000%\n",
      "\ttrain 5-172: Loss: 0.5205 Acc: 25.0000%\n",
      "\ttrain 5-173: Loss: 0.1690 Acc: 75.0000%\n",
      "\ttrain 5-174: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 5-175: Loss: 0.2263 Acc: 50.0000%\n",
      "\ttrain 5-176: Loss: 0.1975 Acc: 50.0000%\n",
      "\ttrain 5-177: Loss: 0.1957 Acc: 75.0000%\n",
      "\ttrain 5-178: Loss: 0.2272 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 5-179: Loss: 0.1093 Acc: 100.0000%\n",
      "\ttrain 5-180: Loss: 0.2721 Acc: 50.0000%\n",
      "\ttrain 5-181: Loss: 0.2999 Acc: 50.0000%\n",
      "\ttrain 5-182: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 5-183: Loss: 0.2723 Acc: 25.0000%\n",
      "\ttrain 5-184: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 5-185: Loss: 0.2557 Acc: 75.0000%\n",
      "\ttrain 5-186: Loss: 0.2379 Acc: 75.0000%\n",
      "\ttrain 5-187: Loss: 0.2374 Acc: 50.0000%\n",
      "\ttrain 5-188: Loss: 0.1712 Acc: 75.0000%\n",
      "\ttrain 5-189: Loss: 0.4217 Acc: 50.0000%\n",
      "\ttrain 5-190: Loss: 0.3837 Acc: 25.0000%\n",
      "\ttrain 5-191: Loss: 0.2309 Acc: 50.0000%\n",
      "\ttrain 5-192: Loss: 0.3787 Acc: 25.0000%\n",
      "\ttrain 5-193: Loss: 0.3159 Acc: 0.0000%\n",
      "\ttrain 5-194: Loss: 0.3635 Acc: 50.0000%\n",
      "\ttrain 5-195: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 5-196: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 5-197: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 5-198: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 5-199: Loss: 0.3941 Acc: 50.0000%\n",
      "\ttrain 5-200: Loss: 0.1606 Acc: 100.0000%\n",
      "\ttrain 5-201: Loss: 0.1116 Acc: 100.0000%\n",
      "\ttrain 5-202: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 5-203: Loss: 0.2264 Acc: 50.0000%\n",
      "\ttrain 5-204: Loss: 0.5158 Acc: 0.0000%\n",
      "\ttrain 5-205: Loss: 0.2469 Acc: 25.0000%\n",
      "\ttrain 5-206: Loss: 0.4296 Acc: 25.0000%\n",
      "\ttrain 5-207: Loss: 0.2277 Acc: 75.0000%\n",
      "\ttrain 5-208: Loss: 0.3028 Acc: 50.0000%\n",
      "\ttrain 5-209: Loss: 0.1079 Acc: 100.0000%\n",
      "\ttrain 5-210: Loss: 0.1752 Acc: 75.0000%\n",
      "\ttrain 5-211: Loss: 0.2236 Acc: 50.0000%\n",
      "\ttrain 5-212: Loss: 0.5146 Acc: 25.0000%\n",
      "\ttrain 5-213: Loss: 0.2384 Acc: 50.0000%\n",
      "\ttrain 5-214: Loss: 0.2848 Acc: 25.0000%\n",
      "\ttrain 5-215: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 5-216: Loss: 0.5328 Acc: 25.0000%\n",
      "\ttrain 5-217: Loss: 0.3103 Acc: 50.0000%\n",
      "\ttrain 5-218: Loss: 0.4899 Acc: 25.0000%\n",
      "\ttrain 5-219: Loss: 0.4014 Acc: 50.0000%\n",
      "\ttrain 5-220: Loss: 0.2609 Acc: 75.0000%\n",
      "\ttrain 5-221: Loss: 0.2867 Acc: 50.0000%\n",
      "\ttrain 5-222: Loss: 0.8271 Acc: 25.0000%\n",
      "\ttrain 5-223: Loss: 0.4435 Acc: 25.0000%\n",
      "\ttrain 5-224: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 5-225: Loss: 0.3159 Acc: 75.0000%\n",
      "\ttrain 5-226: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 5-227: Loss: 0.1957 Acc: 75.0000%\n",
      "\ttrain 5-228: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 5-229: Loss: 0.7394 Acc: 50.0000%\n",
      "\ttrain 5-230: Loss: 1.0894 Acc: 0.0000%\n",
      "\ttrain 5-231: Loss: 0.2741 Acc: 75.0000%\n",
      "\ttrain 5-232: Loss: 0.2384 Acc: 50.0000%\n",
      "\ttrain 5-233: Loss: 0.2650 Acc: 50.0000%\n",
      "\ttrain 5-234: Loss: 0.2252 Acc: 50.0000%\n",
      "\ttrain 5-235: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 5-236: Loss: 0.3486 Acc: 50.0000%\n",
      "\ttrain 5-237: Loss: 0.2676 Acc: 50.0000%\n",
      "\ttrain 5-238: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 5-239: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 5-240: Loss: 0.3862 Acc: 50.0000%\n",
      "\ttrain 5-241: Loss: 0.2178 Acc: 50.0000%\n",
      "\ttrain 5-242: Loss: 0.1845 Acc: 75.0000%\n",
      "\ttrain 5-243: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 5-244: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 5-245: Loss: 0.2110 Acc: 50.0000%\n",
      "\tvalidation 5-1: Loss: 0.0701 Acc: 75.0000%\n",
      "\tvalidation 5-2: Loss: 0.0663 Acc: 75.0000%\n",
      "\tvalidation 5-3: Loss: 0.1641 Acc: 50.0000%\n",
      "\tvalidation 5-4: Loss: 0.4154 Acc: 50.0000%\n",
      "\tvalidation 5-5: Loss: 0.1356 Acc: 75.0000%\n",
      "\tvalidation 5-6: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 5-7: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 5-8: Loss: 0.2155 Acc: 25.0000%\n",
      "\tvalidation 5-9: Loss: 0.3954 Acc: 75.0000%\n",
      "\tvalidation 5-10: Loss: 0.0751 Acc: 100.0000%\n",
      "\tvalidation 5-11: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 5-12: Loss: 0.0993 Acc: 75.0000%\n",
      "\tvalidation 5-13: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 5-14: Loss: 0.0804 Acc: 75.0000%\n",
      "\tvalidation 5-15: Loss: 0.1302 Acc: 75.0000%\n",
      "\tvalidation 5-16: Loss: 0.0686 Acc: 100.0000%\n",
      "\tvalidation 5-17: Loss: 0.1691 Acc: 50.0000%\n",
      "\tvalidation 5-18: Loss: 0.8357 Acc: 50.0000%\n",
      "\tvalidation 5-19: Loss: 0.2203 Acc: 25.0000%\n",
      "\tvalidation 5-20: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 5-21: Loss: 0.1355 Acc: 50.0000%\n",
      "\tvalidation 5-22: Loss: 0.5876 Acc: 25.0000%\n",
      "\tvalidation 5-23: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 5-24: Loss: 0.1388 Acc: 50.0000%\n",
      "\tvalidation 5-25: Loss: 0.0773 Acc: 75.0000%\n",
      "\tvalidation 5-26: Loss: 0.0904 Acc: 75.0000%\n",
      "\tvalidation 5-27: Loss: 0.3060 Acc: 25.0000%\n",
      "\tvalidation 5-28: Loss: 0.0949 Acc: 75.0000%\n",
      "\tvalidation 5-29: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 5-30: Loss: 0.3358 Acc: 50.0000%\n",
      "\tvalidation 5-31: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 5-32: Loss: 0.2963 Acc: 50.0000%\n",
      "\tvalidation 5-33: Loss: 0.0444 Acc: 100.0000%\n",
      "\tvalidation 5-34: Loss: 0.5934 Acc: 50.0000%\n",
      "\tvalidation 5-35: Loss: 0.0861 Acc: 75.0000%\n",
      "\tvalidation 5-36: Loss: 0.1193 Acc: 75.0000%\n",
      "\tvalidation 5-37: Loss: 0.0544 Acc: 100.0000%\n",
      "\tvalidation 5-38: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 5-39: Loss: 0.0961 Acc: 75.0000%\n",
      "\tvalidation 5-40: Loss: 0.1500 Acc: 75.0000%\n",
      "\tvalidation 5-41: Loss: 0.1264 Acc: 75.0000%\n",
      "\tvalidation 5-42: Loss: 0.0466 Acc: 100.0000%\n",
      "\tvalidation 5-43: Loss: 0.0845 Acc: 100.0000%\n",
      "\tvalidation 5-44: Loss: 1.6918 Acc: 25.0000%\n",
      "\tvalidation 5-45: Loss: 0.2971 Acc: 25.0000%\n",
      "\tvalidation 5-46: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 5-47: Loss: 0.2125 Acc: 25.0000%\n",
      "\tvalidation 5-48: Loss: 0.0883 Acc: 75.0000%\n",
      "\tvalidation 5-49: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 5-50: Loss: 1.6830 Acc: 75.0000%\n",
      "\tvalidation 5-51: Loss: 0.0948 Acc: 75.0000%\n",
      "\tvalidation 5-52: Loss: 0.3186 Acc: 25.0000%\n",
      "\tvalidation 5-53: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 5-54: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 5-55: Loss: 0.0778 Acc: 75.0000%\n",
      "\tvalidation 5-56: Loss: 0.0882 Acc: 75.0000%\n",
      "\tvalidation 5-57: Loss: 0.0860 Acc: 100.0000%\n",
      "\tvalidation 5-58: Loss: 0.0679 Acc: 100.0000%\n",
      "\tvalidation 5-59: Loss: 0.0857 Acc: 75.0000%\n",
      "\tvalidation 5-60: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 5-61: Loss: 0.1463 Acc: 50.0000%\n",
      "\tvalidation 5-62: Loss: 0.1785 Acc: 50.0000%\n",
      "\tvalidation 5-63: Loss: 0.0403 Acc: 100.0000%\n",
      "\tvalidation 5-64: Loss: 0.1784 Acc: 50.0000%\n",
      "\tvalidation 5-65: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 5-66: Loss: 0.1063 Acc: 75.0000%\n",
      "\tvalidation 5-67: Loss: 0.1688 Acc: 50.0000%\n",
      "\tvalidation 5-68: Loss: 0.1645 Acc: 50.0000%\n",
      "\tvalidation 5-69: Loss: 0.6427 Acc: 25.0000%\n",
      "\tvalidation 5-70: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 5-71: Loss: 0.1242 Acc: 75.0000%\n",
      "\tvalidation 5-72: Loss: 0.6142 Acc: 75.0000%\n",
      "\tvalidation 5-73: Loss: 0.1086 Acc: 75.0000%\n",
      "\tvalidation 5-74: Loss: 0.1216 Acc: 75.0000%\n",
      "\tvalidation 5-75: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 5-76: Loss: 0.1317 Acc: 75.0000%\n",
      "\tvalidation 5-77: Loss: 0.1582 Acc: 50.0000%\n",
      "\tvalidation 5-78: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 5-79: Loss: 0.2221 Acc: 50.0000%\n",
      "\tvalidation 5-80: Loss: 0.2019 Acc: 50.0000%\n",
      "\tvalidation 5-81: Loss: 0.1999 Acc: 50.0000%\n",
      "\tvalidation 5-82: Loss: 0.0837 Acc: 75.0000%\n",
      "\tvalidation 5-83: Loss: 0.0701 Acc: 100.0000%\n",
      "\tvalidation 5-84: Loss: 0.0636 Acc: 100.0000%\n",
      "\tvalidation 5-85: Loss: 0.1111 Acc: 75.0000%\n",
      "\tvalidation 5-86: Loss: 0.1470 Acc: 75.0000%\n",
      "\tvalidation 5-87: Loss: 0.0562 Acc: 75.0000%\n",
      "\tvalidation 5-88: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 5-89: Loss: 0.0821 Acc: 75.0000%\n",
      "\tvalidation 5-90: Loss: 0.0783 Acc: 75.0000%\n",
      "\tvalidation 5-91: Loss: 0.1128 Acc: 50.0000%\n",
      "\tvalidation 5-92: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 5-93: Loss: 0.0974 Acc: 75.0000%\n",
      "\tvalidation 5-94: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 5-95: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 5-96: Loss: 0.1356 Acc: 75.0000%\n",
      "\tvalidation 5-97: Loss: 0.5536 Acc: 75.0000%\n",
      "\tvalidation 5-98: Loss: 0.1215 Acc: 75.0000%\n",
      "\tvalidation 5-99: Loss: 0.1126 Acc: 75.0000%\n",
      "\tvalidation 5-100: Loss: 1.9975 Acc: 75.0000%\n",
      "\tvalidation 5-101: Loss: 0.9489 Acc: 50.0000%\n",
      "\tvalidation 5-102: Loss: 0.0717 Acc: 75.0000%\n",
      "\tvalidation 5-103: Loss: 0.0962 Acc: 75.0000%\n",
      "\tvalidation 5-104: Loss: 0.1692 Acc: 50.0000%\n",
      "\tvalidation 5-105: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain Loss: 0.2683 Acc: 57.2449%\n",
      "\tvalidation Loss: 0.1984 Acc: 72.8571%\n",
      "Time passed 0h 3m 20s\n",
      "--------------------\n",
      "Epoch [6/40]:\n",
      "\ttrain 6-1: Loss: 0.1448 Acc: 50.0000%\n",
      "\ttrain 6-2: Loss: 0.7552 Acc: 50.0000%\n",
      "\ttrain 6-3: Loss: 0.2359 Acc: 50.0000%\n",
      "\ttrain 6-4: Loss: 0.3215 Acc: 50.0000%\n",
      "\ttrain 6-5: Loss: 0.2614 Acc: 25.0000%\n",
      "\ttrain 6-6: Loss: 0.1780 Acc: 75.0000%\n",
      "\ttrain 6-7: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 6-8: Loss: 0.4759 Acc: 0.0000%\n",
      "\ttrain 6-9: Loss: 0.1505 Acc: 50.0000%\n",
      "\ttrain 6-10: Loss: 0.1918 Acc: 50.0000%\n",
      "\ttrain 6-11: Loss: 0.1818 Acc: 75.0000%\n",
      "\ttrain 6-12: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 6-13: Loss: 0.1627 Acc: 75.0000%\n",
      "\ttrain 6-14: Loss: 0.2690 Acc: 25.0000%\n",
      "\ttrain 6-15: Loss: 0.2413 Acc: 75.0000%\n",
      "\ttrain 6-16: Loss: 0.2280 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-17: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 6-18: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 6-19: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 6-20: Loss: 0.3837 Acc: 25.0000%\n",
      "\ttrain 6-21: Loss: 0.1834 Acc: 50.0000%\n",
      "\ttrain 6-22: Loss: 0.4634 Acc: 25.0000%\n",
      "\ttrain 6-23: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 6-24: Loss: 0.4439 Acc: 25.0000%\n",
      "\ttrain 6-25: Loss: 0.2661 Acc: 75.0000%\n",
      "\ttrain 6-26: Loss: 0.1649 Acc: 75.0000%\n",
      "\ttrain 6-27: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 6-28: Loss: 0.4068 Acc: 75.0000%\n",
      "\ttrain 6-29: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 6-30: Loss: 0.3415 Acc: 50.0000%\n",
      "\ttrain 6-31: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 6-32: Loss: 0.4815 Acc: 25.0000%\n",
      "\ttrain 6-33: Loss: 0.2680 Acc: 50.0000%\n",
      "\ttrain 6-34: Loss: 0.1981 Acc: 50.0000%\n",
      "\ttrain 6-35: Loss: 0.2078 Acc: 75.0000%\n",
      "\ttrain 6-36: Loss: 0.6767 Acc: 25.0000%\n",
      "\ttrain 6-37: Loss: 0.2954 Acc: 50.0000%\n",
      "\ttrain 6-38: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 6-39: Loss: 0.3650 Acc: 25.0000%\n",
      "\ttrain 6-40: Loss: 0.3638 Acc: 25.0000%\n",
      "\ttrain 6-41: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 6-42: Loss: 0.3378 Acc: 75.0000%\n",
      "\ttrain 6-43: Loss: 0.3806 Acc: 75.0000%\n",
      "\ttrain 6-44: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 6-45: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 6-46: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 6-47: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 6-48: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 6-49: Loss: 0.1907 Acc: 75.0000%\n",
      "\ttrain 6-50: Loss: 0.2552 Acc: 50.0000%\n",
      "\ttrain 6-51: Loss: 0.4569 Acc: 50.0000%\n",
      "\ttrain 6-52: Loss: 0.0938 Acc: 100.0000%\n",
      "\ttrain 6-53: Loss: 0.2844 Acc: 50.0000%\n",
      "\ttrain 6-54: Loss: 0.1538 Acc: 50.0000%\n",
      "\ttrain 6-55: Loss: 0.1072 Acc: 50.0000%\n",
      "\ttrain 6-56: Loss: 0.2005 Acc: 100.0000%\n",
      "\ttrain 6-57: Loss: 0.2017 Acc: 50.0000%\n",
      "\ttrain 6-58: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 6-59: Loss: 0.2444 Acc: 25.0000%\n",
      "\ttrain 6-60: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 6-61: Loss: 0.2032 Acc: 50.0000%\n",
      "\ttrain 6-62: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 6-63: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 6-64: Loss: 0.4296 Acc: 25.0000%\n",
      "\ttrain 6-65: Loss: 0.1517 Acc: 100.0000%\n",
      "\ttrain 6-66: Loss: 0.3760 Acc: 50.0000%\n",
      "\ttrain 6-67: Loss: 0.2038 Acc: 50.0000%\n",
      "\ttrain 6-68: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 6-69: Loss: 0.2566 Acc: 50.0000%\n",
      "\ttrain 6-70: Loss: 0.6303 Acc: 25.0000%\n",
      "\ttrain 6-71: Loss: 0.4490 Acc: 25.0000%\n",
      "\ttrain 6-72: Loss: 0.3829 Acc: 25.0000%\n",
      "\ttrain 6-73: Loss: 0.1762 Acc: 50.0000%\n",
      "\ttrain 6-74: Loss: 0.2629 Acc: 50.0000%\n",
      "\ttrain 6-75: Loss: 0.2437 Acc: 75.0000%\n",
      "\ttrain 6-76: Loss: 0.1604 Acc: 50.0000%\n",
      "\ttrain 6-77: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 6-78: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 6-79: Loss: 0.2097 Acc: 75.0000%\n",
      "\ttrain 6-80: Loss: 0.2666 Acc: 75.0000%\n",
      "\ttrain 6-81: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 6-82: Loss: 0.1527 Acc: 75.0000%\n",
      "\ttrain 6-83: Loss: 0.2850 Acc: 75.0000%\n",
      "\ttrain 6-84: Loss: 0.5341 Acc: 0.0000%\n",
      "\ttrain 6-85: Loss: 0.3966 Acc: 25.0000%\n",
      "\ttrain 6-86: Loss: 0.1812 Acc: 50.0000%\n",
      "\ttrain 6-87: Loss: 0.4139 Acc: 0.0000%\n",
      "\ttrain 6-88: Loss: 0.4645 Acc: 25.0000%\n",
      "\ttrain 6-89: Loss: 0.1249 Acc: 50.0000%\n",
      "\ttrain 6-90: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 6-91: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 6-92: Loss: 0.3401 Acc: 25.0000%\n",
      "\ttrain 6-93: Loss: 0.3793 Acc: 50.0000%\n",
      "\ttrain 6-94: Loss: 0.1880 Acc: 75.0000%\n",
      "\ttrain 6-95: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 6-96: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 6-97: Loss: 0.1332 Acc: 50.0000%\n",
      "\ttrain 6-98: Loss: 0.1781 Acc: 75.0000%\n",
      "\ttrain 6-99: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 6-100: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 6-101: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 6-102: Loss: 0.4209 Acc: 25.0000%\n",
      "\ttrain 6-103: Loss: 0.7011 Acc: 25.0000%\n",
      "\ttrain 6-104: Loss: 0.1953 Acc: 50.0000%\n",
      "\ttrain 6-105: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 6-106: Loss: 0.1820 Acc: 50.0000%\n",
      "\ttrain 6-107: Loss: 0.1906 Acc: 75.0000%\n",
      "\ttrain 6-108: Loss: 0.3228 Acc: 25.0000%\n",
      "\ttrain 6-109: Loss: 0.4531 Acc: 25.0000%\n",
      "\ttrain 6-110: Loss: 0.1914 Acc: 75.0000%\n",
      "\ttrain 6-111: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 6-112: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 6-113: Loss: 0.2360 Acc: 50.0000%\n",
      "\ttrain 6-114: Loss: 0.2629 Acc: 50.0000%\n",
      "\ttrain 6-115: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 6-116: Loss: 0.2462 Acc: 50.0000%\n",
      "\ttrain 6-117: Loss: 0.2519 Acc: 50.0000%\n",
      "\ttrain 6-118: Loss: 0.1017 Acc: 100.0000%\n",
      "\ttrain 6-119: Loss: 0.2959 Acc: 50.0000%\n",
      "\ttrain 6-120: Loss: 0.6350 Acc: 25.0000%\n",
      "\ttrain 6-121: Loss: 0.3820 Acc: 50.0000%\n",
      "\ttrain 6-122: Loss: 0.2990 Acc: 50.0000%\n",
      "\ttrain 6-123: Loss: 0.2417 Acc: 25.0000%\n",
      "\ttrain 6-124: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 6-125: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 6-126: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 6-127: Loss: 0.3469 Acc: 25.0000%\n",
      "\ttrain 6-128: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 6-129: Loss: 0.2788 Acc: 25.0000%\n",
      "\ttrain 6-130: Loss: 0.1482 Acc: 75.0000%\n",
      "\ttrain 6-131: Loss: 0.1930 Acc: 75.0000%\n",
      "\ttrain 6-132: Loss: 0.2410 Acc: 50.0000%\n",
      "\ttrain 6-133: Loss: 0.2058 Acc: 75.0000%\n",
      "\ttrain 6-134: Loss: 0.1462 Acc: 50.0000%\n",
      "\ttrain 6-135: Loss: 0.1699 Acc: 75.0000%\n",
      "\ttrain 6-136: Loss: 0.1938 Acc: 50.0000%\n",
      "\ttrain 6-137: Loss: 0.7857 Acc: 25.0000%\n",
      "\ttrain 6-138: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 6-139: Loss: 0.3236 Acc: 75.0000%\n",
      "\ttrain 6-140: Loss: 0.1974 Acc: 50.0000%\n",
      "\ttrain 6-141: Loss: 0.1122 Acc: 100.0000%\n",
      "\ttrain 6-142: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 6-143: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 6-144: Loss: 0.3976 Acc: 50.0000%\n",
      "\ttrain 6-145: Loss: 0.4842 Acc: 25.0000%\n",
      "\ttrain 6-146: Loss: 0.1581 Acc: 75.0000%\n",
      "\ttrain 6-147: Loss: 0.2758 Acc: 25.0000%\n",
      "\ttrain 6-148: Loss: 0.2197 Acc: 50.0000%\n",
      "\ttrain 6-149: Loss: 0.0671 Acc: 100.0000%\n",
      "\ttrain 6-150: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 6-151: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 6-152: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 6-153: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 6-154: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 6-155: Loss: 0.1287 Acc: 50.0000%\n",
      "\ttrain 6-156: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 6-157: Loss: 0.3040 Acc: 25.0000%\n",
      "\ttrain 6-158: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 6-159: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 6-160: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 6-161: Loss: 0.2603 Acc: 75.0000%\n",
      "\ttrain 6-162: Loss: 0.1365 Acc: 50.0000%\n",
      "\ttrain 6-163: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 6-164: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 6-165: Loss: 0.1772 Acc: 50.0000%\n",
      "\ttrain 6-166: Loss: 0.0907 Acc: 100.0000%\n",
      "\ttrain 6-167: Loss: 0.1788 Acc: 50.0000%\n",
      "\ttrain 6-168: Loss: 0.2705 Acc: 50.0000%\n",
      "\ttrain 6-169: Loss: 0.1608 Acc: 50.0000%\n",
      "\ttrain 6-170: Loss: 0.2189 Acc: 50.0000%\n",
      "\ttrain 6-171: Loss: 0.2119 Acc: 75.0000%\n",
      "\ttrain 6-172: Loss: 0.2037 Acc: 50.0000%\n",
      "\ttrain 6-173: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 6-174: Loss: 0.4513 Acc: 25.0000%\n",
      "\ttrain 6-175: Loss: 0.0794 Acc: 100.0000%\n",
      "\ttrain 6-176: Loss: 0.1855 Acc: 75.0000%\n",
      "\ttrain 6-177: Loss: 0.5292 Acc: 25.0000%\n",
      "\ttrain 6-178: Loss: 0.0933 Acc: 100.0000%\n",
      "\ttrain 6-179: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 6-180: Loss: 0.1002 Acc: 100.0000%\n",
      "\ttrain 6-181: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 6-182: Loss: 0.1725 Acc: 75.0000%\n",
      "\ttrain 6-183: Loss: 0.2848 Acc: 75.0000%\n",
      "\ttrain 6-184: Loss: 0.4338 Acc: 25.0000%\n",
      "\ttrain 6-185: Loss: 0.5299 Acc: 25.0000%\n",
      "\ttrain 6-186: Loss: 0.1990 Acc: 75.0000%\n",
      "\ttrain 6-187: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 6-188: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 6-189: Loss: 0.5164 Acc: 50.0000%\n",
      "\ttrain 6-190: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 6-191: Loss: 0.3039 Acc: 25.0000%\n",
      "\ttrain 6-192: Loss: 0.2209 Acc: 75.0000%\n",
      "\ttrain 6-193: Loss: 0.4329 Acc: 25.0000%\n",
      "\ttrain 6-194: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 6-195: Loss: 0.5970 Acc: 50.0000%\n",
      "\ttrain 6-196: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 6-197: Loss: 0.2233 Acc: 50.0000%\n",
      "\ttrain 6-198: Loss: 0.2899 Acc: 75.0000%\n",
      "\ttrain 6-199: Loss: 0.2504 Acc: 75.0000%\n",
      "\ttrain 6-200: Loss: 0.2146 Acc: 25.0000%\n",
      "\ttrain 6-201: Loss: 0.1272 Acc: 50.0000%\n",
      "\ttrain 6-202: Loss: 0.3375 Acc: 75.0000%\n",
      "\ttrain 6-203: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 6-204: Loss: 0.2714 Acc: 50.0000%\n",
      "\ttrain 6-205: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 6-206: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 6-207: Loss: 0.2570 Acc: 50.0000%\n",
      "\ttrain 6-208: Loss: 0.3557 Acc: 25.0000%\n",
      "\ttrain 6-209: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 6-210: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 6-211: Loss: 0.9602 Acc: 25.0000%\n",
      "\ttrain 6-212: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 6-213: Loss: 0.1865 Acc: 50.0000%\n",
      "\ttrain 6-214: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 6-215: Loss: 0.5354 Acc: 0.0000%\n",
      "\ttrain 6-216: Loss: 0.2571 Acc: 50.0000%\n",
      "\ttrain 6-217: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 6-218: Loss: 0.1096 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-219: Loss: 0.5305 Acc: 0.0000%\n",
      "\ttrain 6-220: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 6-221: Loss: 0.2482 Acc: 25.0000%\n",
      "\ttrain 6-222: Loss: 0.4418 Acc: 0.0000%\n",
      "\ttrain 6-223: Loss: 0.4010 Acc: 25.0000%\n",
      "\ttrain 6-224: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 6-225: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 6-226: Loss: 0.1290 Acc: 75.0000%\n",
      "\ttrain 6-227: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 6-228: Loss: 0.4455 Acc: 50.0000%\n",
      "\ttrain 6-229: Loss: 0.6727 Acc: 50.0000%\n",
      "\ttrain 6-230: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 6-231: Loss: 0.2314 Acc: 50.0000%\n",
      "\ttrain 6-232: Loss: 0.2290 Acc: 25.0000%\n",
      "\ttrain 6-233: Loss: 0.4455 Acc: 50.0000%\n",
      "\ttrain 6-234: Loss: 0.7307 Acc: 25.0000%\n",
      "\ttrain 6-235: Loss: 0.1767 Acc: 75.0000%\n",
      "\ttrain 6-236: Loss: 0.5224 Acc: 0.0000%\n",
      "\ttrain 6-237: Loss: 0.1939 Acc: 75.0000%\n",
      "\ttrain 6-238: Loss: 0.2063 Acc: 50.0000%\n",
      "\ttrain 6-239: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 6-240: Loss: 0.4366 Acc: 0.0000%\n",
      "\ttrain 6-241: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 6-242: Loss: 0.3543 Acc: 25.0000%\n",
      "\ttrain 6-243: Loss: 0.3979 Acc: 25.0000%\n",
      "\ttrain 6-244: Loss: 0.2585 Acc: 50.0000%\n",
      "\ttrain 6-245: Loss: 0.0982 Acc: 75.0000%\n",
      "\tvalidation 6-1: Loss: 0.0440 Acc: 100.0000%\n",
      "\tvalidation 6-2: Loss: 0.2047 Acc: 50.0000%\n",
      "\tvalidation 6-3: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 6-4: Loss: 1.0517 Acc: 50.0000%\n",
      "\tvalidation 6-5: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 6-6: Loss: 0.3520 Acc: 50.0000%\n",
      "\tvalidation 6-7: Loss: 0.1220 Acc: 50.0000%\n",
      "\tvalidation 6-8: Loss: 0.0775 Acc: 100.0000%\n",
      "\tvalidation 6-9: Loss: 0.0364 Acc: 100.0000%\n",
      "\tvalidation 6-10: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 6-11: Loss: 0.1031 Acc: 75.0000%\n",
      "\tvalidation 6-12: Loss: 0.1218 Acc: 75.0000%\n",
      "\tvalidation 6-13: Loss: 0.0818 Acc: 75.0000%\n",
      "\tvalidation 6-14: Loss: 0.0997 Acc: 75.0000%\n",
      "\tvalidation 6-15: Loss: 0.3625 Acc: 75.0000%\n",
      "\tvalidation 6-16: Loss: 0.1789 Acc: 75.0000%\n",
      "\tvalidation 6-17: Loss: 0.1756 Acc: 50.0000%\n",
      "\tvalidation 6-18: Loss: 0.0595 Acc: 75.0000%\n",
      "\tvalidation 6-19: Loss: 0.1748 Acc: 50.0000%\n",
      "\tvalidation 6-20: Loss: 0.3067 Acc: 50.0000%\n",
      "\tvalidation 6-21: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 6-22: Loss: 0.1638 Acc: 75.0000%\n",
      "\tvalidation 6-23: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 6-24: Loss: 0.0806 Acc: 100.0000%\n",
      "\tvalidation 6-25: Loss: 0.2111 Acc: 50.0000%\n",
      "\tvalidation 6-26: Loss: 0.2007 Acc: 50.0000%\n",
      "\tvalidation 6-27: Loss: 0.1835 Acc: 50.0000%\n",
      "\tvalidation 6-28: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 6-29: Loss: 0.0689 Acc: 100.0000%\n",
      "\tvalidation 6-30: Loss: 0.1026 Acc: 75.0000%\n",
      "\tvalidation 6-31: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 6-32: Loss: 0.0802 Acc: 75.0000%\n",
      "\tvalidation 6-33: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 6-34: Loss: 0.1941 Acc: 50.0000%\n",
      "\tvalidation 6-35: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 6-36: Loss: 0.1703 Acc: 75.0000%\n",
      "\tvalidation 6-37: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 6-38: Loss: 0.1142 Acc: 75.0000%\n",
      "\tvalidation 6-39: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 6-40: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 6-41: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 6-42: Loss: 0.1012 Acc: 75.0000%\n",
      "\tvalidation 6-43: Loss: 0.1012 Acc: 75.0000%\n",
      "\tvalidation 6-44: Loss: 0.1431 Acc: 75.0000%\n",
      "\tvalidation 6-45: Loss: 0.1703 Acc: 50.0000%\n",
      "\tvalidation 6-46: Loss: 0.2059 Acc: 50.0000%\n",
      "\tvalidation 6-47: Loss: 0.2196 Acc: 25.0000%\n",
      "\tvalidation 6-48: Loss: 0.2863 Acc: 25.0000%\n",
      "\tvalidation 6-49: Loss: 0.3713 Acc: 25.0000%\n",
      "\tvalidation 6-50: Loss: 0.0878 Acc: 75.0000%\n",
      "\tvalidation 6-51: Loss: 0.0854 Acc: 100.0000%\n",
      "\tvalidation 6-52: Loss: 0.1868 Acc: 50.0000%\n",
      "\tvalidation 6-53: Loss: 0.1087 Acc: 100.0000%\n",
      "\tvalidation 6-54: Loss: 2.2554 Acc: 25.0000%\n",
      "\tvalidation 6-55: Loss: 0.0827 Acc: 100.0000%\n",
      "\tvalidation 6-56: Loss: 0.2639 Acc: 25.0000%\n",
      "\tvalidation 6-57: Loss: 0.1168 Acc: 75.0000%\n",
      "\tvalidation 6-58: Loss: 0.1193 Acc: 75.0000%\n",
      "\tvalidation 6-59: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 6-60: Loss: 0.1094 Acc: 75.0000%\n",
      "\tvalidation 6-61: Loss: 2.4409 Acc: 0.0000%\n",
      "\tvalidation 6-62: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 6-63: Loss: 0.7882 Acc: 50.0000%\n",
      "\tvalidation 6-64: Loss: 0.9551 Acc: 25.0000%\n",
      "\tvalidation 6-65: Loss: 0.1115 Acc: 75.0000%\n",
      "\tvalidation 6-66: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 6-67: Loss: 0.0687 Acc: 75.0000%\n",
      "\tvalidation 6-68: Loss: 0.0522 Acc: 100.0000%\n",
      "\tvalidation 6-69: Loss: 0.4491 Acc: 25.0000%\n",
      "\tvalidation 6-70: Loss: 0.1446 Acc: 75.0000%\n",
      "\tvalidation 6-71: Loss: 0.1091 Acc: 75.0000%\n",
      "\tvalidation 6-72: Loss: 0.3993 Acc: 50.0000%\n",
      "\tvalidation 6-73: Loss: 0.1150 Acc: 75.0000%\n",
      "\tvalidation 6-74: Loss: 0.0772 Acc: 75.0000%\n",
      "\tvalidation 6-75: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 6-76: Loss: 0.0909 Acc: 100.0000%\n",
      "\tvalidation 6-77: Loss: 0.0737 Acc: 100.0000%\n",
      "\tvalidation 6-78: Loss: 0.1479 Acc: 75.0000%\n",
      "\tvalidation 6-79: Loss: 0.6725 Acc: 50.0000%\n",
      "\tvalidation 6-80: Loss: 0.1751 Acc: 50.0000%\n",
      "\tvalidation 6-81: Loss: 0.1983 Acc: 50.0000%\n",
      "\tvalidation 6-82: Loss: 0.4998 Acc: 75.0000%\n",
      "\tvalidation 6-83: Loss: 0.1393 Acc: 50.0000%\n",
      "\tvalidation 6-84: Loss: 0.1845 Acc: 50.0000%\n",
      "\tvalidation 6-85: Loss: 0.0698 Acc: 100.0000%\n",
      "\tvalidation 6-86: Loss: 0.1741 Acc: 50.0000%\n",
      "\tvalidation 6-87: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 6-88: Loss: 0.0410 Acc: 100.0000%\n",
      "\tvalidation 6-89: Loss: 0.1538 Acc: 50.0000%\n",
      "\tvalidation 6-90: Loss: 0.1770 Acc: 50.0000%\n",
      "\tvalidation 6-91: Loss: 0.1797 Acc: 50.0000%\n",
      "\tvalidation 6-92: Loss: 0.1710 Acc: 50.0000%\n",
      "\tvalidation 6-93: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 6-94: Loss: 1.6593 Acc: 75.0000%\n",
      "\tvalidation 6-95: Loss: 0.4194 Acc: 50.0000%\n",
      "\tvalidation 6-96: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 6-97: Loss: 0.1292 Acc: 75.0000%\n",
      "\tvalidation 6-98: Loss: 0.2126 Acc: 75.0000%\n",
      "\tvalidation 6-99: Loss: 0.2155 Acc: 50.0000%\n",
      "\tvalidation 6-100: Loss: 0.1752 Acc: 50.0000%\n",
      "\tvalidation 6-101: Loss: 0.0835 Acc: 75.0000%\n",
      "\tvalidation 6-102: Loss: 0.1789 Acc: 50.0000%\n",
      "\tvalidation 6-103: Loss: 0.0930 Acc: 100.0000%\n",
      "\tvalidation 6-104: Loss: 0.1331 Acc: 75.0000%\n",
      "\tvalidation 6-105: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2374 Acc: 60.2041%\n",
      "\tvalidation Loss: 0.2219 Acc: 70.4762%\n",
      "Time passed 0h 3m 59s\n",
      "--------------------\n",
      "Epoch [7/40]:\n",
      "\ttrain 7-1: Loss: 0.5007 Acc: 0.0000%\n",
      "\ttrain 7-2: Loss: 0.1756 Acc: 50.0000%\n",
      "\ttrain 7-3: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 7-4: Loss: 0.1796 Acc: 50.0000%\n",
      "\ttrain 7-5: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 7-6: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 7-7: Loss: 0.2815 Acc: 25.0000%\n",
      "\ttrain 7-8: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 7-9: Loss: 0.3831 Acc: 25.0000%\n",
      "\ttrain 7-10: Loss: 0.3060 Acc: 50.0000%\n",
      "\ttrain 7-11: Loss: 0.1255 Acc: 100.0000%\n",
      "\ttrain 7-12: Loss: 0.1145 Acc: 50.0000%\n",
      "\ttrain 7-13: Loss: 0.2267 Acc: 75.0000%\n",
      "\ttrain 7-14: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 7-15: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 7-16: Loss: 0.3462 Acc: 50.0000%\n",
      "\ttrain 7-17: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 7-18: Loss: 0.1379 Acc: 100.0000%\n",
      "\ttrain 7-19: Loss: 0.1838 Acc: 50.0000%\n",
      "\ttrain 7-20: Loss: 0.3128 Acc: 25.0000%\n",
      "\ttrain 7-21: Loss: 0.2065 Acc: 25.0000%\n",
      "\ttrain 7-22: Loss: 0.5775 Acc: 25.0000%\n",
      "\ttrain 7-23: Loss: 0.2273 Acc: 75.0000%\n",
      "\ttrain 7-24: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 7-25: Loss: 0.3305 Acc: 25.0000%\n",
      "\ttrain 7-26: Loss: 0.1729 Acc: 75.0000%\n",
      "\ttrain 7-27: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 7-28: Loss: 0.1822 Acc: 75.0000%\n",
      "\ttrain 7-29: Loss: 0.1961 Acc: 50.0000%\n",
      "\ttrain 7-30: Loss: 0.3160 Acc: 75.0000%\n",
      "\ttrain 7-31: Loss: 0.4454 Acc: 25.0000%\n",
      "\ttrain 7-32: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 7-33: Loss: 0.5201 Acc: 25.0000%\n",
      "\ttrain 7-34: Loss: 0.3737 Acc: 25.0000%\n",
      "\ttrain 7-35: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 7-36: Loss: 0.3167 Acc: 25.0000%\n",
      "\ttrain 7-37: Loss: 0.2364 Acc: 75.0000%\n",
      "\ttrain 7-38: Loss: 0.2329 Acc: 75.0000%\n",
      "\ttrain 7-39: Loss: 0.3886 Acc: 50.0000%\n",
      "\ttrain 7-40: Loss: 0.3140 Acc: 50.0000%\n",
      "\ttrain 7-41: Loss: 0.3709 Acc: 50.0000%\n",
      "\ttrain 7-42: Loss: 0.2728 Acc: 75.0000%\n",
      "\ttrain 7-43: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 7-44: Loss: 0.2437 Acc: 50.0000%\n",
      "\ttrain 7-45: Loss: 0.2700 Acc: 50.0000%\n",
      "\ttrain 7-46: Loss: 0.1849 Acc: 75.0000%\n",
      "\ttrain 7-47: Loss: 0.7283 Acc: 25.0000%\n",
      "\ttrain 7-48: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 7-49: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 7-50: Loss: 0.5350 Acc: 0.0000%\n",
      "\ttrain 7-51: Loss: 0.1855 Acc: 75.0000%\n",
      "\ttrain 7-52: Loss: 0.2446 Acc: 50.0000%\n",
      "\ttrain 7-53: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 7-54: Loss: 0.0961 Acc: 100.0000%\n",
      "\ttrain 7-55: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 7-56: Loss: 0.2126 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-57: Loss: 0.2214 Acc: 25.0000%\n",
      "\ttrain 7-58: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 7-59: Loss: 0.4312 Acc: 25.0000%\n",
      "\ttrain 7-60: Loss: 0.8557 Acc: 25.0000%\n",
      "\ttrain 7-61: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 7-62: Loss: 0.4434 Acc: 50.0000%\n",
      "\ttrain 7-63: Loss: 0.4015 Acc: 50.0000%\n",
      "\ttrain 7-64: Loss: 0.2660 Acc: 50.0000%\n",
      "\ttrain 7-65: Loss: 0.2096 Acc: 75.0000%\n",
      "\ttrain 7-66: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 7-67: Loss: 0.3829 Acc: 50.0000%\n",
      "\ttrain 7-68: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 7-69: Loss: 0.0966 Acc: 75.0000%\n",
      "\ttrain 7-70: Loss: 0.3757 Acc: 25.0000%\n",
      "\ttrain 7-71: Loss: 0.3213 Acc: 50.0000%\n",
      "\ttrain 7-72: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 7-73: Loss: 0.5409 Acc: 25.0000%\n",
      "\ttrain 7-74: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 7-75: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 7-76: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 7-77: Loss: 0.5702 Acc: 50.0000%\n",
      "\ttrain 7-78: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 7-79: Loss: 0.2260 Acc: 25.0000%\n",
      "\ttrain 7-80: Loss: 0.2320 Acc: 50.0000%\n",
      "\ttrain 7-81: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 7-82: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 7-83: Loss: 0.2368 Acc: 75.0000%\n",
      "\ttrain 7-84: Loss: 0.1553 Acc: 50.0000%\n",
      "\ttrain 7-85: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 7-86: Loss: 0.3119 Acc: 0.0000%\n",
      "\ttrain 7-87: Loss: 0.1790 Acc: 50.0000%\n",
      "\ttrain 7-88: Loss: 0.1620 Acc: 50.0000%\n",
      "\ttrain 7-89: Loss: 0.2958 Acc: 25.0000%\n",
      "\ttrain 7-90: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 7-91: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 7-92: Loss: 0.1077 Acc: 100.0000%\n",
      "\ttrain 7-93: Loss: 0.1689 Acc: 25.0000%\n",
      "\ttrain 7-94: Loss: 0.2124 Acc: 25.0000%\n",
      "\ttrain 7-95: Loss: 0.3849 Acc: 75.0000%\n",
      "\ttrain 7-96: Loss: 0.2209 Acc: 50.0000%\n",
      "\ttrain 7-97: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 7-98: Loss: 0.5406 Acc: 25.0000%\n",
      "\ttrain 7-99: Loss: 0.3108 Acc: 50.0000%\n",
      "\ttrain 7-100: Loss: 0.2102 Acc: 50.0000%\n",
      "\ttrain 7-101: Loss: 0.2470 Acc: 50.0000%\n",
      "\ttrain 7-102: Loss: 0.2045 Acc: 25.0000%\n",
      "\ttrain 7-103: Loss: 0.2118 Acc: 50.0000%\n",
      "\ttrain 7-104: Loss: 0.1373 Acc: 50.0000%\n",
      "\ttrain 7-105: Loss: 0.5166 Acc: 50.0000%\n",
      "\ttrain 7-106: Loss: 0.2340 Acc: 25.0000%\n",
      "\ttrain 7-107: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 7-108: Loss: 0.0956 Acc: 100.0000%\n",
      "\ttrain 7-109: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 7-110: Loss: 0.1527 Acc: 100.0000%\n",
      "\ttrain 7-111: Loss: 0.1898 Acc: 50.0000%\n",
      "\ttrain 7-112: Loss: 0.2164 Acc: 50.0000%\n",
      "\ttrain 7-113: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 7-114: Loss: 0.3652 Acc: 0.0000%\n",
      "\ttrain 7-115: Loss: 0.2561 Acc: 75.0000%\n",
      "\ttrain 7-116: Loss: 0.2588 Acc: 75.0000%\n",
      "\ttrain 7-117: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 7-118: Loss: 0.2301 Acc: 50.0000%\n",
      "\ttrain 7-119: Loss: 0.1316 Acc: 100.0000%\n",
      "\ttrain 7-120: Loss: 0.0729 Acc: 100.0000%\n",
      "\ttrain 7-121: Loss: 0.1846 Acc: 75.0000%\n",
      "\ttrain 7-122: Loss: 0.3859 Acc: 25.0000%\n",
      "\ttrain 7-123: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 7-124: Loss: 0.3977 Acc: 50.0000%\n",
      "\ttrain 7-125: Loss: 0.2742 Acc: 25.0000%\n",
      "\ttrain 7-126: Loss: 0.1655 Acc: 75.0000%\n",
      "\ttrain 7-127: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 7-128: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 7-129: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 7-130: Loss: 0.2131 Acc: 75.0000%\n",
      "\ttrain 7-131: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 7-132: Loss: 0.3167 Acc: 50.0000%\n",
      "\ttrain 7-133: Loss: 0.1683 Acc: 75.0000%\n",
      "\ttrain 7-134: Loss: 0.1764 Acc: 75.0000%\n",
      "\ttrain 7-135: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 7-136: Loss: 0.2238 Acc: 50.0000%\n",
      "\ttrain 7-137: Loss: 0.2257 Acc: 50.0000%\n",
      "\ttrain 7-138: Loss: 0.2617 Acc: 50.0000%\n",
      "\ttrain 7-139: Loss: 0.1401 Acc: 75.0000%\n",
      "\ttrain 7-140: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 7-141: Loss: 0.1819 Acc: 75.0000%\n",
      "\ttrain 7-142: Loss: 0.1013 Acc: 100.0000%\n",
      "\ttrain 7-143: Loss: 0.2794 Acc: 50.0000%\n",
      "\ttrain 7-144: Loss: 0.1968 Acc: 25.0000%\n",
      "\ttrain 7-145: Loss: 0.2133 Acc: 50.0000%\n",
      "\ttrain 7-146: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 7-147: Loss: 0.1110 Acc: 100.0000%\n",
      "\ttrain 7-148: Loss: 0.3053 Acc: 75.0000%\n",
      "\ttrain 7-149: Loss: 0.1732 Acc: 50.0000%\n",
      "\ttrain 7-150: Loss: 0.1037 Acc: 50.0000%\n",
      "\ttrain 7-151: Loss: 0.1094 Acc: 100.0000%\n",
      "\ttrain 7-152: Loss: 0.2318 Acc: 50.0000%\n",
      "\ttrain 7-153: Loss: 0.2931 Acc: 50.0000%\n",
      "\ttrain 7-154: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 7-155: Loss: 0.2501 Acc: 25.0000%\n",
      "\ttrain 7-156: Loss: 0.2528 Acc: 25.0000%\n",
      "\ttrain 7-157: Loss: 0.5008 Acc: 0.0000%\n",
      "\ttrain 7-158: Loss: 0.5527 Acc: 25.0000%\n",
      "\ttrain 7-159: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 7-160: Loss: 0.1080 Acc: 50.0000%\n",
      "\ttrain 7-161: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 7-162: Loss: 0.1833 Acc: 75.0000%\n",
      "\ttrain 7-163: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 7-164: Loss: 0.3460 Acc: 75.0000%\n",
      "\ttrain 7-165: Loss: 0.5961 Acc: 50.0000%\n",
      "\ttrain 7-166: Loss: 0.2313 Acc: 50.0000%\n",
      "\ttrain 7-167: Loss: 0.4970 Acc: 25.0000%\n",
      "\ttrain 7-168: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 7-169: Loss: 0.3075 Acc: 50.0000%\n",
      "\ttrain 7-170: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 7-171: Loss: 0.2744 Acc: 50.0000%\n",
      "\ttrain 7-172: Loss: 0.3321 Acc: 50.0000%\n",
      "\ttrain 7-173: Loss: 0.4836 Acc: 50.0000%\n",
      "\ttrain 7-174: Loss: 0.2548 Acc: 75.0000%\n",
      "\ttrain 7-175: Loss: 0.1950 Acc: 75.0000%\n",
      "\ttrain 7-176: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 7-177: Loss: 0.2002 Acc: 50.0000%\n",
      "\ttrain 7-178: Loss: 0.2973 Acc: 50.0000%\n",
      "\ttrain 7-179: Loss: 0.4631 Acc: 25.0000%\n",
      "\ttrain 7-180: Loss: 0.1453 Acc: 50.0000%\n",
      "\ttrain 7-181: Loss: 0.2796 Acc: 25.0000%\n",
      "\ttrain 7-182: Loss: 0.4340 Acc: 25.0000%\n",
      "\ttrain 7-183: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 7-184: Loss: 0.2346 Acc: 75.0000%\n",
      "\ttrain 7-185: Loss: 0.3013 Acc: 50.0000%\n",
      "\ttrain 7-186: Loss: 0.3998 Acc: 25.0000%\n",
      "\ttrain 7-187: Loss: 0.2157 Acc: 25.0000%\n",
      "\ttrain 7-188: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 7-189: Loss: 0.1017 Acc: 75.0000%\n",
      "\ttrain 7-190: Loss: 0.2052 Acc: 25.0000%\n",
      "\ttrain 7-191: Loss: 0.1339 Acc: 100.0000%\n",
      "\ttrain 7-192: Loss: 0.1921 Acc: 75.0000%\n",
      "\ttrain 7-193: Loss: 0.2757 Acc: 50.0000%\n",
      "\ttrain 7-194: Loss: 0.1621 Acc: 50.0000%\n",
      "\ttrain 7-195: Loss: 0.1129 Acc: 100.0000%\n",
      "\ttrain 7-196: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 7-197: Loss: 0.1709 Acc: 50.0000%\n",
      "\ttrain 7-198: Loss: 0.1962 Acc: 50.0000%\n",
      "\ttrain 7-199: Loss: 0.4350 Acc: 75.0000%\n",
      "\ttrain 7-200: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 7-201: Loss: 0.1505 Acc: 75.0000%\n",
      "\ttrain 7-202: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 7-203: Loss: 0.1535 Acc: 75.0000%\n",
      "\ttrain 7-204: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 7-205: Loss: 0.1807 Acc: 75.0000%\n",
      "\ttrain 7-206: Loss: 0.2524 Acc: 50.0000%\n",
      "\ttrain 7-207: Loss: 0.1428 Acc: 75.0000%\n",
      "\ttrain 7-208: Loss: 0.2438 Acc: 50.0000%\n",
      "\ttrain 7-209: Loss: 0.3607 Acc: 75.0000%\n",
      "\ttrain 7-210: Loss: 0.2514 Acc: 75.0000%\n",
      "\ttrain 7-211: Loss: 0.4017 Acc: 25.0000%\n",
      "\ttrain 7-212: Loss: 0.2446 Acc: 75.0000%\n",
      "\ttrain 7-213: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 7-214: Loss: 0.1617 Acc: 50.0000%\n",
      "\ttrain 7-215: Loss: 0.1582 Acc: 50.0000%\n",
      "\ttrain 7-216: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 7-217: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 7-218: Loss: 0.3496 Acc: 50.0000%\n",
      "\ttrain 7-219: Loss: 0.1793 Acc: 50.0000%\n",
      "\ttrain 7-220: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 7-221: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 7-222: Loss: 0.1537 Acc: 50.0000%\n",
      "\ttrain 7-223: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 7-224: Loss: 0.1791 Acc: 25.0000%\n",
      "\ttrain 7-225: Loss: 0.4293 Acc: 25.0000%\n",
      "\ttrain 7-226: Loss: 0.5767 Acc: 25.0000%\n",
      "\ttrain 7-227: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 7-228: Loss: 0.5989 Acc: 25.0000%\n",
      "\ttrain 7-229: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 7-230: Loss: 0.2597 Acc: 25.0000%\n",
      "\ttrain 7-231: Loss: 0.2405 Acc: 75.0000%\n",
      "\ttrain 7-232: Loss: 0.1431 Acc: 75.0000%\n",
      "\ttrain 7-233: Loss: 0.2583 Acc: 50.0000%\n",
      "\ttrain 7-234: Loss: 0.2374 Acc: 50.0000%\n",
      "\ttrain 7-235: Loss: 0.0724 Acc: 100.0000%\n",
      "\ttrain 7-236: Loss: 0.1764 Acc: 50.0000%\n",
      "\ttrain 7-237: Loss: 0.2523 Acc: 50.0000%\n",
      "\ttrain 7-238: Loss: 0.2116 Acc: 75.0000%\n",
      "\ttrain 7-239: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 7-240: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 7-241: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 7-242: Loss: 0.2690 Acc: 25.0000%\n",
      "\ttrain 7-243: Loss: 0.3721 Acc: 25.0000%\n",
      "\ttrain 7-244: Loss: 0.1331 Acc: 50.0000%\n",
      "\ttrain 7-245: Loss: 0.2650 Acc: 50.0000%\n",
      "\tvalidation 7-1: Loss: 0.0595 Acc: 100.0000%\n",
      "\tvalidation 7-2: Loss: 0.1635 Acc: 75.0000%\n",
      "\tvalidation 7-3: Loss: 0.0687 Acc: 75.0000%\n",
      "\tvalidation 7-4: Loss: 0.6175 Acc: 75.0000%\n",
      "\tvalidation 7-5: Loss: 3.2618 Acc: 75.0000%\n",
      "\tvalidation 7-6: Loss: 0.0753 Acc: 100.0000%\n",
      "\tvalidation 7-7: Loss: 0.0877 Acc: 100.0000%\n",
      "\tvalidation 7-8: Loss: 0.0905 Acc: 75.0000%\n",
      "\tvalidation 7-9: Loss: 1.3492 Acc: 75.0000%\n",
      "\tvalidation 7-10: Loss: 0.0722 Acc: 100.0000%\n",
      "\tvalidation 7-11: Loss: 0.0557 Acc: 100.0000%\n",
      "\tvalidation 7-12: Loss: 1.1197 Acc: 50.0000%\n",
      "\tvalidation 7-13: Loss: 0.0616 Acc: 75.0000%\n",
      "\tvalidation 7-14: Loss: 0.2595 Acc: 25.0000%\n",
      "\tvalidation 7-15: Loss: 0.1936 Acc: 50.0000%\n",
      "\tvalidation 7-16: Loss: 0.0642 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 7-17: Loss: 0.1609 Acc: 50.0000%\n",
      "\tvalidation 7-18: Loss: 0.7661 Acc: 75.0000%\n",
      "\tvalidation 7-19: Loss: 0.3108 Acc: 50.0000%\n",
      "\tvalidation 7-20: Loss: 1.0109 Acc: 75.0000%\n",
      "\tvalidation 7-21: Loss: 0.0968 Acc: 75.0000%\n",
      "\tvalidation 7-22: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 7-23: Loss: 0.0425 Acc: 100.0000%\n",
      "\tvalidation 7-24: Loss: 0.0721 Acc: 100.0000%\n",
      "\tvalidation 7-25: Loss: 2.0515 Acc: 50.0000%\n",
      "\tvalidation 7-26: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 7-27: Loss: 0.3621 Acc: 75.0000%\n",
      "\tvalidation 7-28: Loss: 0.3893 Acc: 75.0000%\n",
      "\tvalidation 7-29: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 7-30: Loss: 0.2318 Acc: 50.0000%\n",
      "\tvalidation 7-31: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 7-32: Loss: 0.1205 Acc: 50.0000%\n",
      "\tvalidation 7-33: Loss: 0.0541 Acc: 75.0000%\n",
      "\tvalidation 7-34: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 7-35: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 7-36: Loss: 0.3262 Acc: 50.0000%\n",
      "\tvalidation 7-37: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 7-38: Loss: 0.6528 Acc: 75.0000%\n",
      "\tvalidation 7-39: Loss: 0.1630 Acc: 50.0000%\n",
      "\tvalidation 7-40: Loss: 0.1130 Acc: 75.0000%\n",
      "\tvalidation 7-41: Loss: 0.1100 Acc: 100.0000%\n",
      "\tvalidation 7-42: Loss: 0.0828 Acc: 100.0000%\n",
      "\tvalidation 7-43: Loss: 0.4889 Acc: 75.0000%\n",
      "\tvalidation 7-44: Loss: 0.2787 Acc: 50.0000%\n",
      "\tvalidation 7-45: Loss: 0.1796 Acc: 50.0000%\n",
      "\tvalidation 7-46: Loss: 1.0044 Acc: 50.0000%\n",
      "\tvalidation 7-47: Loss: 0.1213 Acc: 50.0000%\n",
      "\tvalidation 7-48: Loss: 0.2871 Acc: 75.0000%\n",
      "\tvalidation 7-49: Loss: 0.1020 Acc: 75.0000%\n",
      "\tvalidation 7-50: Loss: 0.2090 Acc: 75.0000%\n",
      "\tvalidation 7-51: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 7-52: Loss: 0.5173 Acc: 75.0000%\n",
      "\tvalidation 7-53: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 7-54: Loss: 0.2708 Acc: 75.0000%\n",
      "\tvalidation 7-55: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 7-56: Loss: 0.1796 Acc: 50.0000%\n",
      "\tvalidation 7-57: Loss: 0.1054 Acc: 50.0000%\n",
      "\tvalidation 7-58: Loss: 0.0758 Acc: 75.0000%\n",
      "\tvalidation 7-59: Loss: 0.2358 Acc: 75.0000%\n",
      "\tvalidation 7-60: Loss: 0.1394 Acc: 50.0000%\n",
      "\tvalidation 7-61: Loss: 3.3322 Acc: 50.0000%\n",
      "\tvalidation 7-62: Loss: 0.1451 Acc: 50.0000%\n",
      "\tvalidation 7-63: Loss: 0.1767 Acc: 75.0000%\n",
      "\tvalidation 7-64: Loss: 0.7549 Acc: 50.0000%\n",
      "\tvalidation 7-65: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 7-66: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 7-67: Loss: 0.0907 Acc: 75.0000%\n",
      "\tvalidation 7-68: Loss: 0.0681 Acc: 75.0000%\n",
      "\tvalidation 7-69: Loss: 0.0587 Acc: 75.0000%\n",
      "\tvalidation 7-70: Loss: 0.0797 Acc: 75.0000%\n",
      "\tvalidation 7-71: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 7-72: Loss: 0.1182 Acc: 75.0000%\n",
      "\tvalidation 7-73: Loss: 0.1669 Acc: 25.0000%\n",
      "\tvalidation 7-74: Loss: 0.0975 Acc: 100.0000%\n",
      "\tvalidation 7-75: Loss: 0.1431 Acc: 75.0000%\n",
      "\tvalidation 7-76: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 7-77: Loss: 1.3100 Acc: 75.0000%\n",
      "\tvalidation 7-78: Loss: 0.0940 Acc: 75.0000%\n",
      "\tvalidation 7-79: Loss: 0.0906 Acc: 75.0000%\n",
      "\tvalidation 7-80: Loss: 0.0895 Acc: 75.0000%\n",
      "\tvalidation 7-81: Loss: 0.1134 Acc: 100.0000%\n",
      "\tvalidation 7-82: Loss: 0.1811 Acc: 25.0000%\n",
      "\tvalidation 7-83: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 7-84: Loss: 0.1101 Acc: 50.0000%\n",
      "\tvalidation 7-85: Loss: 0.0671 Acc: 100.0000%\n",
      "\tvalidation 7-86: Loss: 0.1673 Acc: 75.0000%\n",
      "\tvalidation 7-87: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 7-88: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 7-89: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 7-90: Loss: 0.0573 Acc: 100.0000%\n",
      "\tvalidation 7-91: Loss: 0.0634 Acc: 100.0000%\n",
      "\tvalidation 7-92: Loss: 0.0571 Acc: 75.0000%\n",
      "\tvalidation 7-93: Loss: 0.0571 Acc: 75.0000%\n",
      "\tvalidation 7-94: Loss: 0.0697 Acc: 75.0000%\n",
      "\tvalidation 7-95: Loss: 0.1492 Acc: 50.0000%\n",
      "\tvalidation 7-96: Loss: 0.1402 Acc: 50.0000%\n",
      "\tvalidation 7-97: Loss: 0.0607 Acc: 75.0000%\n",
      "\tvalidation 7-98: Loss: 0.3520 Acc: 75.0000%\n",
      "\tvalidation 7-99: Loss: 4.0625 Acc: 75.0000%\n",
      "\tvalidation 7-100: Loss: 0.1300 Acc: 50.0000%\n",
      "\tvalidation 7-101: Loss: 0.1232 Acc: 75.0000%\n",
      "\tvalidation 7-102: Loss: 0.1587 Acc: 50.0000%\n",
      "\tvalidation 7-103: Loss: 0.1432 Acc: 75.0000%\n",
      "\tvalidation 7-104: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 7-105: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2292 Acc: 59.5918%\n",
      "\tvalidation Loss: 0.3129 Acc: 75.0000%\n",
      "Time passed 0h 4m 39s\n",
      "--------------------\n",
      "Epoch [8/40]:\n",
      "\ttrain 8-1: Loss: 0.2058 Acc: 75.0000%\n",
      "\ttrain 8-2: Loss: 0.4283 Acc: 0.0000%\n",
      "\ttrain 8-3: Loss: 0.4940 Acc: 25.0000%\n",
      "\ttrain 8-4: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 8-5: Loss: 0.4388 Acc: 50.0000%\n",
      "\ttrain 8-6: Loss: 0.2618 Acc: 50.0000%\n",
      "\ttrain 8-7: Loss: 0.4511 Acc: 0.0000%\n",
      "\ttrain 8-8: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 8-9: Loss: 0.5075 Acc: 25.0000%\n",
      "\ttrain 8-10: Loss: 0.2412 Acc: 25.0000%\n",
      "\ttrain 8-11: Loss: 0.4372 Acc: 0.0000%\n",
      "\ttrain 8-12: Loss: 0.0813 Acc: 100.0000%\n",
      "\ttrain 8-13: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 8-14: Loss: 0.2499 Acc: 50.0000%\n",
      "\ttrain 8-15: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 8-16: Loss: 0.2183 Acc: 75.0000%\n",
      "\ttrain 8-17: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 8-18: Loss: 0.2025 Acc: 25.0000%\n",
      "\ttrain 8-19: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 8-20: Loss: 0.3152 Acc: 25.0000%\n",
      "\ttrain 8-21: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 8-22: Loss: 0.1936 Acc: 75.0000%\n",
      "\ttrain 8-23: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 8-24: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 8-25: Loss: 0.1013 Acc: 100.0000%\n",
      "\ttrain 8-26: Loss: 0.2623 Acc: 50.0000%\n",
      "\ttrain 8-27: Loss: 0.3378 Acc: 25.0000%\n",
      "\ttrain 8-28: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 8-29: Loss: 0.1658 Acc: 50.0000%\n",
      "\ttrain 8-30: Loss: 0.6291 Acc: 25.0000%\n",
      "\ttrain 8-31: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 8-32: Loss: 0.2743 Acc: 75.0000%\n",
      "\ttrain 8-33: Loss: 0.1524 Acc: 75.0000%\n",
      "\ttrain 8-34: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 8-35: Loss: 0.1074 Acc: 100.0000%\n",
      "\ttrain 8-36: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 8-37: Loss: 0.2646 Acc: 25.0000%\n",
      "\ttrain 8-38: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 8-39: Loss: 0.1967 Acc: 25.0000%\n",
      "\ttrain 8-40: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 8-41: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 8-42: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 8-43: Loss: 0.2363 Acc: 50.0000%\n",
      "\ttrain 8-44: Loss: 0.1640 Acc: 75.0000%\n",
      "\ttrain 8-45: Loss: 0.1193 Acc: 100.0000%\n",
      "\ttrain 8-46: Loss: 0.2759 Acc: 25.0000%\n",
      "\ttrain 8-47: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 8-48: Loss: 0.3396 Acc: 25.0000%\n",
      "\ttrain 8-49: Loss: 0.9243 Acc: 0.0000%\n",
      "\ttrain 8-50: Loss: 0.6881 Acc: 25.0000%\n",
      "\ttrain 8-51: Loss: 0.1182 Acc: 50.0000%\n",
      "\ttrain 8-52: Loss: 0.2347 Acc: 75.0000%\n",
      "\ttrain 8-53: Loss: 0.2870 Acc: 75.0000%\n",
      "\ttrain 8-54: Loss: 0.2310 Acc: 75.0000%\n",
      "\ttrain 8-55: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 8-56: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 8-57: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 8-58: Loss: 0.0920 Acc: 100.0000%\n",
      "\ttrain 8-59: Loss: 0.6382 Acc: 25.0000%\n",
      "\ttrain 8-60: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 8-61: Loss: 0.3726 Acc: 50.0000%\n",
      "\ttrain 8-62: Loss: 0.1808 Acc: 50.0000%\n",
      "\ttrain 8-63: Loss: 0.3359 Acc: 75.0000%\n",
      "\ttrain 8-64: Loss: 0.3087 Acc: 25.0000%\n",
      "\ttrain 8-65: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 8-66: Loss: 0.2724 Acc: 75.0000%\n",
      "\ttrain 8-67: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 8-68: Loss: 1.0773 Acc: 0.0000%\n",
      "\ttrain 8-69: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 8-70: Loss: 0.3981 Acc: 50.0000%\n",
      "\ttrain 8-71: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 8-72: Loss: 0.5394 Acc: 25.0000%\n",
      "\ttrain 8-73: Loss: 0.4765 Acc: 50.0000%\n",
      "\ttrain 8-74: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 8-75: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 8-76: Loss: 0.3304 Acc: 50.0000%\n",
      "\ttrain 8-77: Loss: 0.1940 Acc: 50.0000%\n",
      "\ttrain 8-78: Loss: 0.2510 Acc: 50.0000%\n",
      "\ttrain 8-79: Loss: 0.1831 Acc: 75.0000%\n",
      "\ttrain 8-80: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 8-81: Loss: 0.1776 Acc: 75.0000%\n",
      "\ttrain 8-82: Loss: 0.2791 Acc: 50.0000%\n",
      "\ttrain 8-83: Loss: 0.2200 Acc: 75.0000%\n",
      "\ttrain 8-84: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 8-85: Loss: 0.8588 Acc: 0.0000%\n",
      "\ttrain 8-86: Loss: 0.3474 Acc: 25.0000%\n",
      "\ttrain 8-87: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 8-88: Loss: 0.2398 Acc: 25.0000%\n",
      "\ttrain 8-89: Loss: 0.1510 Acc: 50.0000%\n",
      "\ttrain 8-90: Loss: 0.2163 Acc: 25.0000%\n",
      "\ttrain 8-91: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 8-92: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 8-93: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 8-94: Loss: 0.3365 Acc: 50.0000%\n",
      "\ttrain 8-95: Loss: 0.2121 Acc: 50.0000%\n",
      "\ttrain 8-96: Loss: 0.1300 Acc: 100.0000%\n",
      "\ttrain 8-97: Loss: 0.3108 Acc: 0.0000%\n",
      "\ttrain 8-98: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 8-99: Loss: 0.2999 Acc: 50.0000%\n",
      "\ttrain 8-100: Loss: 0.8499 Acc: 50.0000%\n",
      "\ttrain 8-101: Loss: 0.0829 Acc: 100.0000%\n",
      "\ttrain 8-102: Loss: 0.1295 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 8-103: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 8-104: Loss: 0.3646 Acc: 25.0000%\n",
      "\ttrain 8-105: Loss: 0.2319 Acc: 75.0000%\n",
      "\ttrain 8-106: Loss: 0.1952 Acc: 50.0000%\n",
      "\ttrain 8-107: Loss: 0.2207 Acc: 50.0000%\n",
      "\ttrain 8-108: Loss: 0.2527 Acc: 25.0000%\n",
      "\ttrain 8-109: Loss: 0.1647 Acc: 75.0000%\n",
      "\ttrain 8-110: Loss: 0.0601 Acc: 75.0000%\n",
      "\ttrain 8-111: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 8-112: Loss: 0.3488 Acc: 25.0000%\n",
      "\ttrain 8-113: Loss: 0.3084 Acc: 25.0000%\n",
      "\ttrain 8-114: Loss: 0.2323 Acc: 50.0000%\n",
      "\ttrain 8-115: Loss: 0.2351 Acc: 25.0000%\n",
      "\ttrain 8-116: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 8-117: Loss: 0.4206 Acc: 50.0000%\n",
      "\ttrain 8-118: Loss: 0.3698 Acc: 50.0000%\n",
      "\ttrain 8-119: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 8-120: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 8-121: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 8-122: Loss: 0.1799 Acc: 75.0000%\n",
      "\ttrain 8-123: Loss: 0.3790 Acc: 50.0000%\n",
      "\ttrain 8-124: Loss: 0.3267 Acc: 25.0000%\n",
      "\ttrain 8-125: Loss: 0.2252 Acc: 75.0000%\n",
      "\ttrain 8-126: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 8-127: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 8-128: Loss: 0.1344 Acc: 50.0000%\n",
      "\ttrain 8-129: Loss: 0.5705 Acc: 0.0000%\n",
      "\ttrain 8-130: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 8-131: Loss: 0.2394 Acc: 50.0000%\n",
      "\ttrain 8-132: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 8-133: Loss: 0.2141 Acc: 75.0000%\n",
      "\ttrain 8-134: Loss: 0.2180 Acc: 75.0000%\n",
      "\ttrain 8-135: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 8-136: Loss: 0.2047 Acc: 50.0000%\n",
      "\ttrain 8-137: Loss: 0.2665 Acc: 25.0000%\n",
      "\ttrain 8-138: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 8-139: Loss: 0.3547 Acc: 50.0000%\n",
      "\ttrain 8-140: Loss: 0.1534 Acc: 75.0000%\n",
      "\ttrain 8-141: Loss: 0.2747 Acc: 50.0000%\n",
      "\ttrain 8-142: Loss: 0.3541 Acc: 50.0000%\n",
      "\ttrain 8-143: Loss: 0.2385 Acc: 50.0000%\n",
      "\ttrain 8-144: Loss: 0.2593 Acc: 50.0000%\n",
      "\ttrain 8-145: Loss: 0.2779 Acc: 25.0000%\n",
      "\ttrain 8-146: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 8-147: Loss: 0.2310 Acc: 50.0000%\n",
      "\ttrain 8-148: Loss: 0.2090 Acc: 75.0000%\n",
      "\ttrain 8-149: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 8-150: Loss: 0.2233 Acc: 75.0000%\n",
      "\ttrain 8-151: Loss: 0.2642 Acc: 50.0000%\n",
      "\ttrain 8-152: Loss: 0.3196 Acc: 0.0000%\n",
      "\ttrain 8-153: Loss: 0.4151 Acc: 50.0000%\n",
      "\ttrain 8-154: Loss: 0.3132 Acc: 25.0000%\n",
      "\ttrain 8-155: Loss: 0.4671 Acc: 50.0000%\n",
      "\ttrain 8-156: Loss: 0.2915 Acc: 25.0000%\n",
      "\ttrain 8-157: Loss: 0.1726 Acc: 50.0000%\n",
      "\ttrain 8-158: Loss: 0.1786 Acc: 50.0000%\n",
      "\ttrain 8-159: Loss: 0.5191 Acc: 50.0000%\n",
      "\ttrain 8-160: Loss: 0.1269 Acc: 50.0000%\n",
      "\ttrain 8-161: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 8-162: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 8-163: Loss: 0.5511 Acc: 50.0000%\n",
      "\ttrain 8-164: Loss: 0.2174 Acc: 75.0000%\n",
      "\ttrain 8-165: Loss: 0.3630 Acc: 50.0000%\n",
      "\ttrain 8-166: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 8-167: Loss: 0.1543 Acc: 75.0000%\n",
      "\ttrain 8-168: Loss: 0.1239 Acc: 75.0000%\n",
      "\ttrain 8-169: Loss: 0.2168 Acc: 25.0000%\n",
      "\ttrain 8-170: Loss: 0.3816 Acc: 25.0000%\n",
      "\ttrain 8-171: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 8-172: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 8-173: Loss: 0.3163 Acc: 50.0000%\n",
      "\ttrain 8-174: Loss: 0.2783 Acc: 50.0000%\n",
      "\ttrain 8-175: Loss: 0.3792 Acc: 50.0000%\n",
      "\ttrain 8-176: Loss: 0.3160 Acc: 75.0000%\n",
      "\ttrain 8-177: Loss: 0.4292 Acc: 25.0000%\n",
      "\ttrain 8-178: Loss: 0.3433 Acc: 75.0000%\n",
      "\ttrain 8-179: Loss: 0.3545 Acc: 25.0000%\n",
      "\ttrain 8-180: Loss: 0.4666 Acc: 0.0000%\n",
      "\ttrain 8-181: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 8-182: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 8-183: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 8-184: Loss: 0.6684 Acc: 0.0000%\n",
      "\ttrain 8-185: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 8-186: Loss: 0.5230 Acc: 25.0000%\n",
      "\ttrain 8-187: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 8-188: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 8-189: Loss: 0.6845 Acc: 50.0000%\n",
      "\ttrain 8-190: Loss: 0.2673 Acc: 75.0000%\n",
      "\ttrain 8-191: Loss: 0.4486 Acc: 25.0000%\n",
      "\ttrain 8-192: Loss: 0.5081 Acc: 50.0000%\n",
      "\ttrain 8-193: Loss: 0.2041 Acc: 50.0000%\n",
      "\ttrain 8-194: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 8-195: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 8-196: Loss: 0.3346 Acc: 25.0000%\n",
      "\ttrain 8-197: Loss: 0.3166 Acc: 50.0000%\n",
      "\ttrain 8-198: Loss: 0.1743 Acc: 75.0000%\n",
      "\ttrain 8-199: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 8-200: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 8-201: Loss: 1.0315 Acc: 25.0000%\n",
      "\ttrain 8-202: Loss: 0.2820 Acc: 75.0000%\n",
      "\ttrain 8-203: Loss: 0.2339 Acc: 75.0000%\n",
      "\ttrain 8-204: Loss: 0.3522 Acc: 50.0000%\n",
      "\ttrain 8-205: Loss: 0.2471 Acc: 50.0000%\n",
      "\ttrain 8-206: Loss: 0.2442 Acc: 50.0000%\n",
      "\ttrain 8-207: Loss: 0.1827 Acc: 50.0000%\n",
      "\ttrain 8-208: Loss: 0.2663 Acc: 50.0000%\n",
      "\ttrain 8-209: Loss: 0.3337 Acc: 50.0000%\n",
      "\ttrain 8-210: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 8-211: Loss: 0.3933 Acc: 25.0000%\n",
      "\ttrain 8-212: Loss: 0.4115 Acc: 25.0000%\n",
      "\ttrain 8-213: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 8-214: Loss: 0.1872 Acc: 75.0000%\n",
      "\ttrain 8-215: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 8-216: Loss: 0.4663 Acc: 25.0000%\n",
      "\ttrain 8-217: Loss: 0.3549 Acc: 25.0000%\n",
      "\ttrain 8-218: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 8-219: Loss: 0.1830 Acc: 50.0000%\n",
      "\ttrain 8-220: Loss: 0.1680 Acc: 50.0000%\n",
      "\ttrain 8-221: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 8-222: Loss: 0.1482 Acc: 50.0000%\n",
      "\ttrain 8-223: Loss: 0.1946 Acc: 50.0000%\n",
      "\ttrain 8-224: Loss: 0.2319 Acc: 25.0000%\n",
      "\ttrain 8-225: Loss: 0.2987 Acc: 75.0000%\n",
      "\ttrain 8-226: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 8-227: Loss: 0.3569 Acc: 0.0000%\n",
      "\ttrain 8-228: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 8-229: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 8-230: Loss: 0.0780 Acc: 100.0000%\n",
      "\ttrain 8-231: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 8-232: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 8-233: Loss: 0.1682 Acc: 75.0000%\n",
      "\ttrain 8-234: Loss: 0.5085 Acc: 0.0000%\n",
      "\ttrain 8-235: Loss: 0.1420 Acc: 50.0000%\n",
      "\ttrain 8-236: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 8-237: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 8-238: Loss: 0.2704 Acc: 25.0000%\n",
      "\ttrain 8-239: Loss: 0.3120 Acc: 25.0000%\n",
      "\ttrain 8-240: Loss: 0.2003 Acc: 75.0000%\n",
      "\ttrain 8-241: Loss: 0.1528 Acc: 75.0000%\n",
      "\ttrain 8-242: Loss: 0.3990 Acc: 50.0000%\n",
      "\ttrain 8-243: Loss: 0.2772 Acc: 50.0000%\n",
      "\ttrain 8-244: Loss: 0.1757 Acc: 50.0000%\n",
      "\ttrain 8-245: Loss: 0.1284 Acc: 75.0000%\n",
      "\tvalidation 8-1: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 8-2: Loss: 0.1511 Acc: 50.0000%\n",
      "\tvalidation 8-3: Loss: 0.0759 Acc: 75.0000%\n",
      "\tvalidation 8-4: Loss: 0.0681 Acc: 75.0000%\n",
      "\tvalidation 8-5: Loss: 0.0548 Acc: 100.0000%\n",
      "\tvalidation 8-6: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 8-7: Loss: 0.0925 Acc: 75.0000%\n",
      "\tvalidation 8-8: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 8-9: Loss: 0.0734 Acc: 75.0000%\n",
      "\tvalidation 8-10: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 8-11: Loss: 0.1291 Acc: 75.0000%\n",
      "\tvalidation 8-12: Loss: 0.0951 Acc: 75.0000%\n",
      "\tvalidation 8-13: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 8-14: Loss: 0.1377 Acc: 75.0000%\n",
      "\tvalidation 8-15: Loss: 0.1690 Acc: 75.0000%\n",
      "\tvalidation 8-16: Loss: 0.1190 Acc: 75.0000%\n",
      "\tvalidation 8-17: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 8-18: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 8-19: Loss: 0.1659 Acc: 50.0000%\n",
      "\tvalidation 8-20: Loss: 0.1163 Acc: 75.0000%\n",
      "\tvalidation 8-21: Loss: 0.0779 Acc: 100.0000%\n",
      "\tvalidation 8-22: Loss: 0.1168 Acc: 75.0000%\n",
      "\tvalidation 8-23: Loss: 0.1597 Acc: 50.0000%\n",
      "\tvalidation 8-24: Loss: 0.0629 Acc: 75.0000%\n",
      "\tvalidation 8-25: Loss: 0.1461 Acc: 50.0000%\n",
      "\tvalidation 8-26: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 8-27: Loss: 0.7164 Acc: 75.0000%\n",
      "\tvalidation 8-28: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 8-29: Loss: 2.9468 Acc: 50.0000%\n",
      "\tvalidation 8-30: Loss: 0.1574 Acc: 50.0000%\n",
      "\tvalidation 8-31: Loss: 0.0989 Acc: 75.0000%\n",
      "\tvalidation 8-32: Loss: 0.3230 Acc: 0.0000%\n",
      "\tvalidation 8-33: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 8-34: Loss: 0.1045 Acc: 75.0000%\n",
      "\tvalidation 8-35: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 8-36: Loss: 0.0864 Acc: 75.0000%\n",
      "\tvalidation 8-37: Loss: 0.0725 Acc: 100.0000%\n",
      "\tvalidation 8-38: Loss: 0.1775 Acc: 50.0000%\n",
      "\tvalidation 8-39: Loss: 0.1810 Acc: 75.0000%\n",
      "\tvalidation 8-40: Loss: 0.1108 Acc: 75.0000%\n",
      "\tvalidation 8-41: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 8-42: Loss: 0.0815 Acc: 100.0000%\n",
      "\tvalidation 8-43: Loss: 0.3189 Acc: 50.0000%\n",
      "\tvalidation 8-44: Loss: 0.3753 Acc: 50.0000%\n",
      "\tvalidation 8-45: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 8-46: Loss: 0.0715 Acc: 75.0000%\n",
      "\tvalidation 8-47: Loss: 2.5469 Acc: 50.0000%\n",
      "\tvalidation 8-48: Loss: 0.8094 Acc: 75.0000%\n",
      "\tvalidation 8-49: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 8-50: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 8-51: Loss: 0.0784 Acc: 75.0000%\n",
      "\tvalidation 8-52: Loss: 0.1596 Acc: 50.0000%\n",
      "\tvalidation 8-53: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 8-54: Loss: 0.0896 Acc: 75.0000%\n",
      "\tvalidation 8-55: Loss: 0.1380 Acc: 50.0000%\n",
      "\tvalidation 8-56: Loss: 0.1289 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 8-57: Loss: 1.9800 Acc: 50.0000%\n",
      "\tvalidation 8-58: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 8-59: Loss: 0.0712 Acc: 75.0000%\n",
      "\tvalidation 8-60: Loss: 0.2766 Acc: 50.0000%\n",
      "\tvalidation 8-61: Loss: 0.1039 Acc: 75.0000%\n",
      "\tvalidation 8-62: Loss: 0.1689 Acc: 50.0000%\n",
      "\tvalidation 8-63: Loss: 0.2297 Acc: 25.0000%\n",
      "\tvalidation 8-64: Loss: 0.1301 Acc: 75.0000%\n",
      "\tvalidation 8-65: Loss: 0.1199 Acc: 75.0000%\n",
      "\tvalidation 8-66: Loss: 0.0984 Acc: 75.0000%\n",
      "\tvalidation 8-67: Loss: 0.2220 Acc: 25.0000%\n",
      "\tvalidation 8-68: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 8-69: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 8-70: Loss: 0.1127 Acc: 75.0000%\n",
      "\tvalidation 8-71: Loss: 0.1063 Acc: 75.0000%\n",
      "\tvalidation 8-72: Loss: 0.0929 Acc: 75.0000%\n",
      "\tvalidation 8-73: Loss: 0.1493 Acc: 75.0000%\n",
      "\tvalidation 8-74: Loss: 0.5719 Acc: 75.0000%\n",
      "\tvalidation 8-75: Loss: 0.4454 Acc: 50.0000%\n",
      "\tvalidation 8-76: Loss: 0.0572 Acc: 100.0000%\n",
      "\tvalidation 8-77: Loss: 0.1482 Acc: 50.0000%\n",
      "\tvalidation 8-78: Loss: 0.2084 Acc: 50.0000%\n",
      "\tvalidation 8-79: Loss: 0.1003 Acc: 75.0000%\n",
      "\tvalidation 8-80: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 8-81: Loss: 0.0739 Acc: 100.0000%\n",
      "\tvalidation 8-82: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 8-83: Loss: 0.2597 Acc: 50.0000%\n",
      "\tvalidation 8-84: Loss: 0.2035 Acc: 50.0000%\n",
      "\tvalidation 8-85: Loss: 0.0908 Acc: 100.0000%\n",
      "\tvalidation 8-86: Loss: 0.0804 Acc: 75.0000%\n",
      "\tvalidation 8-87: Loss: 0.1286 Acc: 50.0000%\n",
      "\tvalidation 8-88: Loss: 0.3309 Acc: 25.0000%\n",
      "\tvalidation 8-89: Loss: 0.4687 Acc: 75.0000%\n",
      "\tvalidation 8-90: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 8-91: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 8-92: Loss: 0.1283 Acc: 75.0000%\n",
      "\tvalidation 8-93: Loss: 0.1246 Acc: 75.0000%\n",
      "\tvalidation 8-94: Loss: 0.0838 Acc: 75.0000%\n",
      "\tvalidation 8-95: Loss: 0.1675 Acc: 50.0000%\n",
      "\tvalidation 8-96: Loss: 0.1754 Acc: 50.0000%\n",
      "\tvalidation 8-97: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-98: Loss: 0.0815 Acc: 75.0000%\n",
      "\tvalidation 8-99: Loss: 0.3613 Acc: 50.0000%\n",
      "\tvalidation 8-100: Loss: 0.1686 Acc: 50.0000%\n",
      "\tvalidation 8-101: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 8-102: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 8-103: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 8-104: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 8-105: Loss: 2.3875 Acc: 50.0000%\n",
      "\ttrain Loss: 0.2404 Acc: 59.1837%\n",
      "\tvalidation Loss: 0.2209 Acc: 74.7619%\n",
      "Time passed 0h 5m 18s\n",
      "--------------------\n",
      "Epoch [9/40]:\n",
      "\ttrain 9-1: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 9-2: Loss: 0.2964 Acc: 25.0000%\n",
      "\ttrain 9-3: Loss: 0.3937 Acc: 25.0000%\n",
      "\ttrain 9-4: Loss: 0.2766 Acc: 50.0000%\n",
      "\ttrain 9-5: Loss: 0.1009 Acc: 50.0000%\n",
      "\ttrain 9-6: Loss: 0.2711 Acc: 50.0000%\n",
      "\ttrain 9-7: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 9-8: Loss: 0.2243 Acc: 75.0000%\n",
      "\ttrain 9-9: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 9-10: Loss: 0.3942 Acc: 50.0000%\n",
      "\ttrain 9-11: Loss: 0.3434 Acc: 50.0000%\n",
      "\ttrain 9-12: Loss: 0.4605 Acc: 50.0000%\n",
      "\ttrain 9-13: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 9-14: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 9-15: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 9-16: Loss: 0.3374 Acc: 25.0000%\n",
      "\ttrain 9-17: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 9-18: Loss: 0.1924 Acc: 75.0000%\n",
      "\ttrain 9-19: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 9-20: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 9-21: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 9-22: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 9-23: Loss: 0.3298 Acc: 50.0000%\n",
      "\ttrain 9-24: Loss: 0.1446 Acc: 50.0000%\n",
      "\ttrain 9-25: Loss: 0.2821 Acc: 25.0000%\n",
      "\ttrain 9-26: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 9-27: Loss: 0.2274 Acc: 50.0000%\n",
      "\ttrain 9-28: Loss: 0.2042 Acc: 50.0000%\n",
      "\ttrain 9-29: Loss: 0.2985 Acc: 50.0000%\n",
      "\ttrain 9-30: Loss: 0.3455 Acc: 25.0000%\n",
      "\ttrain 9-31: Loss: 0.3923 Acc: 25.0000%\n",
      "\ttrain 9-32: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 9-33: Loss: 0.1765 Acc: 75.0000%\n",
      "\ttrain 9-34: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 9-35: Loss: 0.2770 Acc: 50.0000%\n",
      "\ttrain 9-36: Loss: 0.4034 Acc: 50.0000%\n",
      "\ttrain 9-37: Loss: 0.3753 Acc: 50.0000%\n",
      "\ttrain 9-38: Loss: 0.1570 Acc: 75.0000%\n",
      "\ttrain 9-39: Loss: 0.2482 Acc: 50.0000%\n",
      "\ttrain 9-40: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 9-41: Loss: 0.2628 Acc: 75.0000%\n",
      "\ttrain 9-42: Loss: 0.4401 Acc: 25.0000%\n",
      "\ttrain 9-43: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 9-44: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 9-45: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 9-46: Loss: 0.2162 Acc: 50.0000%\n",
      "\ttrain 9-47: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 9-48: Loss: 0.2072 Acc: 50.0000%\n",
      "\ttrain 9-49: Loss: 0.4259 Acc: 50.0000%\n",
      "\ttrain 9-50: Loss: 0.1889 Acc: 75.0000%\n",
      "\ttrain 9-51: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 9-52: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 9-53: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 9-54: Loss: 0.1923 Acc: 25.0000%\n",
      "\ttrain 9-55: Loss: 0.1644 Acc: 50.0000%\n",
      "\ttrain 9-56: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 9-57: Loss: 0.3427 Acc: 25.0000%\n",
      "\ttrain 9-58: Loss: 0.3284 Acc: 50.0000%\n",
      "\ttrain 9-59: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 9-60: Loss: 0.4997 Acc: 25.0000%\n",
      "\ttrain 9-61: Loss: 0.2179 Acc: 50.0000%\n",
      "\ttrain 9-62: Loss: 0.4196 Acc: 25.0000%\n",
      "\ttrain 9-63: Loss: 0.1314 Acc: 100.0000%\n",
      "\ttrain 9-64: Loss: 0.4706 Acc: 25.0000%\n",
      "\ttrain 9-65: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 9-66: Loss: 0.1948 Acc: 50.0000%\n",
      "\ttrain 9-67: Loss: 0.2280 Acc: 50.0000%\n",
      "\ttrain 9-68: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 9-69: Loss: 0.4402 Acc: 25.0000%\n",
      "\ttrain 9-70: Loss: 0.1722 Acc: 50.0000%\n",
      "\ttrain 9-71: Loss: 0.4615 Acc: 0.0000%\n",
      "\ttrain 9-72: Loss: 0.1862 Acc: 50.0000%\n",
      "\ttrain 9-73: Loss: 0.1790 Acc: 75.0000%\n",
      "\ttrain 9-74: Loss: 0.1766 Acc: 50.0000%\n",
      "\ttrain 9-75: Loss: 0.3349 Acc: 50.0000%\n",
      "\ttrain 9-76: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 9-77: Loss: 0.1379 Acc: 50.0000%\n",
      "\ttrain 9-78: Loss: 0.1262 Acc: 50.0000%\n",
      "\ttrain 9-79: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 9-80: Loss: 0.1371 Acc: 75.0000%\n",
      "\ttrain 9-81: Loss: 0.1871 Acc: 75.0000%\n",
      "\ttrain 9-82: Loss: 0.0913 Acc: 100.0000%\n",
      "\ttrain 9-83: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 9-84: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 9-85: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 9-86: Loss: 0.3133 Acc: 25.0000%\n",
      "\ttrain 9-87: Loss: 0.1275 Acc: 100.0000%\n",
      "\ttrain 9-88: Loss: 0.3007 Acc: 25.0000%\n",
      "\ttrain 9-89: Loss: 0.2682 Acc: 75.0000%\n",
      "\ttrain 9-90: Loss: 0.1981 Acc: 75.0000%\n",
      "\ttrain 9-91: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 9-92: Loss: 0.2349 Acc: 50.0000%\n",
      "\ttrain 9-93: Loss: 0.1980 Acc: 50.0000%\n",
      "\ttrain 9-94: Loss: 0.3794 Acc: 0.0000%\n",
      "\ttrain 9-95: Loss: 0.5393 Acc: 25.0000%\n",
      "\ttrain 9-96: Loss: 0.2208 Acc: 50.0000%\n",
      "\ttrain 9-97: Loss: 0.1342 Acc: 50.0000%\n",
      "\ttrain 9-98: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 9-99: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 9-100: Loss: 0.3523 Acc: 25.0000%\n",
      "\ttrain 9-101: Loss: 0.1506 Acc: 75.0000%\n",
      "\ttrain 9-102: Loss: 0.1927 Acc: 50.0000%\n",
      "\ttrain 9-103: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 9-104: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 9-105: Loss: 0.3668 Acc: 0.0000%\n",
      "\ttrain 9-106: Loss: 0.1918 Acc: 50.0000%\n",
      "\ttrain 9-107: Loss: 0.0951 Acc: 100.0000%\n",
      "\ttrain 9-108: Loss: 0.4274 Acc: 50.0000%\n",
      "\ttrain 9-109: Loss: 0.4313 Acc: 75.0000%\n",
      "\ttrain 9-110: Loss: 0.4523 Acc: 25.0000%\n",
      "\ttrain 9-111: Loss: 0.5033 Acc: 0.0000%\n",
      "\ttrain 9-112: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 9-113: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 9-114: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 9-115: Loss: 0.1004 Acc: 100.0000%\n",
      "\ttrain 9-116: Loss: 0.2128 Acc: 75.0000%\n",
      "\ttrain 9-117: Loss: 0.0882 Acc: 100.0000%\n",
      "\ttrain 9-118: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 9-119: Loss: 0.2766 Acc: 25.0000%\n",
      "\ttrain 9-120: Loss: 0.4214 Acc: 50.0000%\n",
      "\ttrain 9-121: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 9-122: Loss: 0.2213 Acc: 75.0000%\n",
      "\ttrain 9-123: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 9-124: Loss: 0.2043 Acc: 25.0000%\n",
      "\ttrain 9-125: Loss: 0.1844 Acc: 75.0000%\n",
      "\ttrain 9-126: Loss: 0.4120 Acc: 75.0000%\n",
      "\ttrain 9-127: Loss: 0.3113 Acc: 25.0000%\n",
      "\ttrain 9-128: Loss: 0.3420 Acc: 50.0000%\n",
      "\ttrain 9-129: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 9-130: Loss: 0.1729 Acc: 50.0000%\n",
      "\ttrain 9-131: Loss: 0.2248 Acc: 50.0000%\n",
      "\ttrain 9-132: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 9-133: Loss: 0.2252 Acc: 50.0000%\n",
      "\ttrain 9-134: Loss: 0.1502 Acc: 75.0000%\n",
      "\ttrain 9-135: Loss: 0.3980 Acc: 50.0000%\n",
      "\ttrain 9-136: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 9-137: Loss: 0.3156 Acc: 25.0000%\n",
      "\ttrain 9-138: Loss: 0.2043 Acc: 50.0000%\n",
      "\ttrain 9-139: Loss: 0.2517 Acc: 75.0000%\n",
      "\ttrain 9-140: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 9-141: Loss: 0.1137 Acc: 75.0000%\n",
      "\ttrain 9-142: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 9-143: Loss: 0.4588 Acc: 50.0000%\n",
      "\ttrain 9-144: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 9-145: Loss: 0.4229 Acc: 25.0000%\n",
      "\ttrain 9-146: Loss: 0.1296 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 9-147: Loss: 0.3313 Acc: 25.0000%\n",
      "\ttrain 9-148: Loss: 0.1441 Acc: 75.0000%\n",
      "\ttrain 9-149: Loss: 0.1235 Acc: 75.0000%\n",
      "\ttrain 9-150: Loss: 0.2057 Acc: 50.0000%\n",
      "\ttrain 9-151: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 9-152: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 9-153: Loss: 0.2396 Acc: 50.0000%\n",
      "\ttrain 9-154: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 9-155: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 9-156: Loss: 0.2727 Acc: 25.0000%\n",
      "\ttrain 9-157: Loss: 0.4210 Acc: 25.0000%\n",
      "\ttrain 9-158: Loss: 0.0957 Acc: 100.0000%\n",
      "\ttrain 9-159: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 9-160: Loss: 0.3079 Acc: 50.0000%\n",
      "\ttrain 9-161: Loss: 0.5538 Acc: 50.0000%\n",
      "\ttrain 9-162: Loss: 0.1305 Acc: 100.0000%\n",
      "\ttrain 9-163: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 9-164: Loss: 0.2233 Acc: 50.0000%\n",
      "\ttrain 9-165: Loss: 0.1593 Acc: 50.0000%\n",
      "\ttrain 9-166: Loss: 0.1526 Acc: 50.0000%\n",
      "\ttrain 9-167: Loss: 0.2676 Acc: 50.0000%\n",
      "\ttrain 9-168: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 9-169: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 9-170: Loss: 0.4394 Acc: 25.0000%\n",
      "\ttrain 9-171: Loss: 0.6664 Acc: 25.0000%\n",
      "\ttrain 9-172: Loss: 0.1559 Acc: 50.0000%\n",
      "\ttrain 9-173: Loss: 0.1859 Acc: 75.0000%\n",
      "\ttrain 9-174: Loss: 0.3430 Acc: 25.0000%\n",
      "\ttrain 9-175: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 9-176: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 9-177: Loss: 0.0994 Acc: 100.0000%\n",
      "\ttrain 9-178: Loss: 0.2688 Acc: 50.0000%\n",
      "\ttrain 9-179: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 9-180: Loss: 0.1129 Acc: 100.0000%\n",
      "\ttrain 9-181: Loss: 0.0815 Acc: 100.0000%\n",
      "\ttrain 9-182: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 9-183: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 9-184: Loss: 0.2671 Acc: 50.0000%\n",
      "\ttrain 9-185: Loss: 0.2513 Acc: 50.0000%\n",
      "\ttrain 9-186: Loss: 0.2092 Acc: 75.0000%\n",
      "\ttrain 9-187: Loss: 0.2079 Acc: 50.0000%\n",
      "\ttrain 9-188: Loss: 0.1883 Acc: 75.0000%\n",
      "\ttrain 9-189: Loss: 0.1171 Acc: 50.0000%\n",
      "\ttrain 9-190: Loss: 0.4448 Acc: 50.0000%\n",
      "\ttrain 9-191: Loss: 0.2490 Acc: 50.0000%\n",
      "\ttrain 9-192: Loss: 0.2887 Acc: 50.0000%\n",
      "\ttrain 9-193: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 9-194: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 9-195: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 9-196: Loss: 0.0909 Acc: 100.0000%\n",
      "\ttrain 9-197: Loss: 0.2172 Acc: 50.0000%\n",
      "\ttrain 9-198: Loss: 0.4124 Acc: 0.0000%\n",
      "\ttrain 9-199: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 9-200: Loss: 0.6861 Acc: 50.0000%\n",
      "\ttrain 9-201: Loss: 0.5604 Acc: 0.0000%\n",
      "\ttrain 9-202: Loss: 0.4262 Acc: 50.0000%\n",
      "\ttrain 9-203: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 9-204: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 9-205: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 9-206: Loss: 0.2629 Acc: 75.0000%\n",
      "\ttrain 9-207: Loss: 0.3470 Acc: 75.0000%\n",
      "\ttrain 9-208: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 9-209: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 9-210: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 9-211: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 9-212: Loss: 0.2135 Acc: 25.0000%\n",
      "\ttrain 9-213: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 9-214: Loss: 0.4202 Acc: 50.0000%\n",
      "\ttrain 9-215: Loss: 0.3168 Acc: 25.0000%\n",
      "\ttrain 9-216: Loss: 0.1845 Acc: 25.0000%\n",
      "\ttrain 9-217: Loss: 0.2873 Acc: 25.0000%\n",
      "\ttrain 9-218: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 9-219: Loss: 0.2385 Acc: 50.0000%\n",
      "\ttrain 9-220: Loss: 0.1638 Acc: 75.0000%\n",
      "\ttrain 9-221: Loss: 0.2527 Acc: 50.0000%\n",
      "\ttrain 9-222: Loss: 0.3207 Acc: 25.0000%\n",
      "\ttrain 9-223: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 9-224: Loss: 0.2793 Acc: 50.0000%\n",
      "\ttrain 9-225: Loss: 0.1350 Acc: 75.0000%\n",
      "\ttrain 9-226: Loss: 0.5646 Acc: 75.0000%\n",
      "\ttrain 9-227: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 9-228: Loss: 0.2691 Acc: 50.0000%\n",
      "\ttrain 9-229: Loss: 0.2666 Acc: 50.0000%\n",
      "\ttrain 9-230: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 9-231: Loss: 0.1100 Acc: 100.0000%\n",
      "\ttrain 9-232: Loss: 0.5052 Acc: 50.0000%\n",
      "\ttrain 9-233: Loss: 0.1474 Acc: 50.0000%\n",
      "\ttrain 9-234: Loss: 0.0730 Acc: 100.0000%\n",
      "\ttrain 9-235: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 9-236: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 9-237: Loss: 0.3977 Acc: 25.0000%\n",
      "\ttrain 9-238: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 9-239: Loss: 0.3220 Acc: 50.0000%\n",
      "\ttrain 9-240: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 9-241: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 9-242: Loss: 0.2501 Acc: 50.0000%\n",
      "\ttrain 9-243: Loss: 0.2421 Acc: 50.0000%\n",
      "\ttrain 9-244: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 9-245: Loss: 0.2670 Acc: 50.0000%\n",
      "\tvalidation 9-1: Loss: 0.0342 Acc: 100.0000%\n",
      "\tvalidation 9-2: Loss: 6.1500 Acc: 50.0000%\n",
      "\tvalidation 9-3: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 9-4: Loss: 0.9168 Acc: 75.0000%\n",
      "\tvalidation 9-5: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 9-6: Loss: 0.1489 Acc: 75.0000%\n",
      "\tvalidation 9-7: Loss: 0.1377 Acc: 75.0000%\n",
      "\tvalidation 9-8: Loss: 0.1126 Acc: 50.0000%\n",
      "\tvalidation 9-9: Loss: 0.0658 Acc: 75.0000%\n",
      "\tvalidation 9-10: Loss: 0.6718 Acc: 25.0000%\n",
      "\tvalidation 9-11: Loss: 0.2318 Acc: 75.0000%\n",
      "\tvalidation 9-12: Loss: 0.7255 Acc: 50.0000%\n",
      "\tvalidation 9-13: Loss: 0.1672 Acc: 50.0000%\n",
      "\tvalidation 9-14: Loss: 0.3713 Acc: 50.0000%\n",
      "\tvalidation 9-15: Loss: 1.5232 Acc: 50.0000%\n",
      "\tvalidation 9-16: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 9-17: Loss: 0.0858 Acc: 75.0000%\n",
      "\tvalidation 9-18: Loss: 0.4023 Acc: 75.0000%\n",
      "\tvalidation 9-19: Loss: 1.0205 Acc: 50.0000%\n",
      "\tvalidation 9-20: Loss: 0.1349 Acc: 50.0000%\n",
      "\tvalidation 9-21: Loss: 0.1174 Acc: 50.0000%\n",
      "\tvalidation 9-22: Loss: 1.5770 Acc: 50.0000%\n",
      "\tvalidation 9-23: Loss: 0.0482 Acc: 75.0000%\n",
      "\tvalidation 9-24: Loss: 1.0551 Acc: 50.0000%\n",
      "\tvalidation 9-25: Loss: 0.0609 Acc: 75.0000%\n",
      "\tvalidation 9-26: Loss: 0.9209 Acc: 25.0000%\n",
      "\tvalidation 9-27: Loss: 0.1234 Acc: 75.0000%\n",
      "\tvalidation 9-28: Loss: 1.3982 Acc: 50.0000%\n",
      "\tvalidation 9-29: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 9-30: Loss: 1.2230 Acc: 75.0000%\n",
      "\tvalidation 9-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-32: Loss: 0.3839 Acc: 50.0000%\n",
      "\tvalidation 9-33: Loss: 0.1484 Acc: 50.0000%\n",
      "\tvalidation 9-34: Loss: 0.0641 Acc: 100.0000%\n",
      "\tvalidation 9-35: Loss: 1.5334 Acc: 50.0000%\n",
      "\tvalidation 9-36: Loss: 0.0644 Acc: 75.0000%\n",
      "\tvalidation 9-37: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 9-38: Loss: 0.9348 Acc: 75.0000%\n",
      "\tvalidation 9-39: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 9-40: Loss: 1.6523 Acc: 50.0000%\n",
      "\tvalidation 9-41: Loss: 0.8650 Acc: 75.0000%\n",
      "\tvalidation 9-42: Loss: 0.8875 Acc: 75.0000%\n",
      "\tvalidation 9-43: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 9-44: Loss: 0.1654 Acc: 50.0000%\n",
      "\tvalidation 9-45: Loss: 0.1442 Acc: 50.0000%\n",
      "\tvalidation 9-46: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 9-47: Loss: 0.3301 Acc: 75.0000%\n",
      "\tvalidation 9-48: Loss: 0.1333 Acc: 75.0000%\n",
      "\tvalidation 9-49: Loss: 0.5245 Acc: 75.0000%\n",
      "\tvalidation 9-50: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 9-51: Loss: 0.2312 Acc: 25.0000%\n",
      "\tvalidation 9-52: Loss: 0.3059 Acc: 50.0000%\n",
      "\tvalidation 9-53: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 9-54: Loss: 0.0392 Acc: 100.0000%\n",
      "\tvalidation 9-55: Loss: 0.3749 Acc: 75.0000%\n",
      "\tvalidation 9-56: Loss: 0.1068 Acc: 75.0000%\n",
      "\tvalidation 9-57: Loss: 0.0655 Acc: 75.0000%\n",
      "\tvalidation 9-58: Loss: 0.4615 Acc: 75.0000%\n",
      "\tvalidation 9-59: Loss: 0.2415 Acc: 50.0000%\n",
      "\tvalidation 9-60: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 9-61: Loss: 4.3620 Acc: 50.0000%\n",
      "\tvalidation 9-62: Loss: 0.1292 Acc: 50.0000%\n",
      "\tvalidation 9-63: Loss: 2.0745 Acc: 50.0000%\n",
      "\tvalidation 9-64: Loss: 4.4065 Acc: 50.0000%\n",
      "\tvalidation 9-65: Loss: 0.0553 Acc: 100.0000%\n",
      "\tvalidation 9-66: Loss: 0.0730 Acc: 75.0000%\n",
      "\tvalidation 9-67: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 9-68: Loss: 0.0698 Acc: 75.0000%\n",
      "\tvalidation 9-69: Loss: 0.9261 Acc: 25.0000%\n",
      "\tvalidation 9-70: Loss: 0.4059 Acc: 50.0000%\n",
      "\tvalidation 9-71: Loss: 0.1671 Acc: 50.0000%\n",
      "\tvalidation 9-72: Loss: 1.7758 Acc: 25.0000%\n",
      "\tvalidation 9-73: Loss: 0.1187 Acc: 75.0000%\n",
      "\tvalidation 9-74: Loss: 0.6319 Acc: 50.0000%\n",
      "\tvalidation 9-75: Loss: 0.0465 Acc: 100.0000%\n",
      "\tvalidation 9-76: Loss: 0.9625 Acc: 75.0000%\n",
      "\tvalidation 9-77: Loss: 0.0701 Acc: 100.0000%\n",
      "\tvalidation 9-78: Loss: 3.4837 Acc: 75.0000%\n",
      "\tvalidation 9-79: Loss: 0.1693 Acc: 50.0000%\n",
      "\tvalidation 9-80: Loss: 0.1419 Acc: 75.0000%\n",
      "\tvalidation 9-81: Loss: 0.3644 Acc: 50.0000%\n",
      "\tvalidation 9-82: Loss: 0.3244 Acc: 75.0000%\n",
      "\tvalidation 9-83: Loss: 2.0620 Acc: 75.0000%\n",
      "\tvalidation 9-84: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 9-85: Loss: 0.1231 Acc: 75.0000%\n",
      "\tvalidation 9-86: Loss: 0.0511 Acc: 75.0000%\n",
      "\tvalidation 9-87: Loss: 0.1395 Acc: 75.0000%\n",
      "\tvalidation 9-88: Loss: 0.2803 Acc: 75.0000%\n",
      "\tvalidation 9-89: Loss: 1.9977 Acc: 25.0000%\n",
      "\tvalidation 9-90: Loss: 0.0489 Acc: 100.0000%\n",
      "\tvalidation 9-91: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 9-92: Loss: 0.0740 Acc: 75.0000%\n",
      "\tvalidation 9-93: Loss: 0.0668 Acc: 100.0000%\n",
      "\tvalidation 9-94: Loss: 0.3871 Acc: 50.0000%\n",
      "\tvalidation 9-95: Loss: 1.0005 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 9-96: Loss: 1.0372 Acc: 25.0000%\n",
      "\tvalidation 9-97: Loss: 0.1799 Acc: 75.0000%\n",
      "\tvalidation 9-98: Loss: 6.0105 Acc: 50.0000%\n",
      "\tvalidation 9-99: Loss: 2.6000 Acc: 25.0000%\n",
      "\tvalidation 9-100: Loss: 0.6607 Acc: 50.0000%\n",
      "\tvalidation 9-101: Loss: 0.8316 Acc: 75.0000%\n",
      "\tvalidation 9-102: Loss: 0.1174 Acc: 50.0000%\n",
      "\tvalidation 9-103: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 9-104: Loss: 0.0657 Acc: 75.0000%\n",
      "\tvalidation 9-105: Loss: 0.5462 Acc: 50.0000%\n",
      "\ttrain Loss: 0.2170 Acc: 61.0204%\n",
      "\tvalidation Loss: 0.6545 Acc: 68.3333%\n",
      "Time passed 0h 5m 58s\n",
      "--------------------\n",
      "Epoch [10/40]:\n",
      "\ttrain 10-1: Loss: 0.1617 Acc: 75.0000%\n",
      "\ttrain 10-2: Loss: 0.1468 Acc: 50.0000%\n",
      "\ttrain 10-3: Loss: 0.1359 Acc: 75.0000%\n",
      "\ttrain 10-4: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 10-5: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 10-6: Loss: 0.6585 Acc: 25.0000%\n",
      "\ttrain 10-7: Loss: 0.2070 Acc: 50.0000%\n",
      "\ttrain 10-8: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 10-9: Loss: 0.0683 Acc: 100.0000%\n",
      "\ttrain 10-10: Loss: 0.1446 Acc: 75.0000%\n",
      "\ttrain 10-11: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 10-12: Loss: 0.3425 Acc: 25.0000%\n",
      "\ttrain 10-13: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 10-14: Loss: 0.4975 Acc: 25.0000%\n",
      "\ttrain 10-15: Loss: 0.1004 Acc: 50.0000%\n",
      "\ttrain 10-16: Loss: 0.2141 Acc: 50.0000%\n",
      "\ttrain 10-17: Loss: 0.2112 Acc: 25.0000%\n",
      "\ttrain 10-18: Loss: 0.1947 Acc: 25.0000%\n",
      "\ttrain 10-19: Loss: 0.3531 Acc: 0.0000%\n",
      "\ttrain 10-20: Loss: 0.0801 Acc: 100.0000%\n",
      "\ttrain 10-21: Loss: 0.1214 Acc: 50.0000%\n",
      "\ttrain 10-22: Loss: 0.1595 Acc: 75.0000%\n",
      "\ttrain 10-23: Loss: 0.2427 Acc: 75.0000%\n",
      "\ttrain 10-24: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 10-25: Loss: 0.5190 Acc: 25.0000%\n",
      "\ttrain 10-26: Loss: 0.7507 Acc: 25.0000%\n",
      "\ttrain 10-27: Loss: 0.2503 Acc: 50.0000%\n",
      "\ttrain 10-28: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 10-29: Loss: 0.2468 Acc: 50.0000%\n",
      "\ttrain 10-30: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 10-31: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 10-32: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 10-33: Loss: 0.2162 Acc: 50.0000%\n",
      "\ttrain 10-34: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 10-35: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 10-36: Loss: 0.3019 Acc: 50.0000%\n",
      "\ttrain 10-37: Loss: 0.1625 Acc: 75.0000%\n",
      "\ttrain 10-38: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 10-39: Loss: 0.2018 Acc: 75.0000%\n",
      "\ttrain 10-40: Loss: 0.1994 Acc: 75.0000%\n",
      "\ttrain 10-41: Loss: 0.5405 Acc: 50.0000%\n",
      "\ttrain 10-42: Loss: 0.2379 Acc: 50.0000%\n",
      "\ttrain 10-43: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 10-44: Loss: 0.7548 Acc: 25.0000%\n",
      "\ttrain 10-45: Loss: 0.2951 Acc: 75.0000%\n",
      "\ttrain 10-46: Loss: 0.2532 Acc: 75.0000%\n",
      "\ttrain 10-47: Loss: 0.2403 Acc: 50.0000%\n",
      "\ttrain 10-48: Loss: 0.3583 Acc: 0.0000%\n",
      "\ttrain 10-49: Loss: 0.1725 Acc: 50.0000%\n",
      "\ttrain 10-50: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 10-51: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 10-52: Loss: 0.4756 Acc: 25.0000%\n",
      "\ttrain 10-53: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 10-54: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 10-55: Loss: 0.1644 Acc: 75.0000%\n",
      "\ttrain 10-56: Loss: 0.4377 Acc: 50.0000%\n",
      "\ttrain 10-57: Loss: 0.3464 Acc: 50.0000%\n",
      "\ttrain 10-58: Loss: 0.3990 Acc: 50.0000%\n",
      "\ttrain 10-59: Loss: 0.2126 Acc: 50.0000%\n",
      "\ttrain 10-60: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 10-61: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 10-62: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 10-63: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 10-64: Loss: 0.3276 Acc: 50.0000%\n",
      "\ttrain 10-65: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 10-66: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 10-67: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 10-68: Loss: 0.3508 Acc: 50.0000%\n",
      "\ttrain 10-69: Loss: 0.3552 Acc: 75.0000%\n",
      "\ttrain 10-70: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 10-71: Loss: 0.5105 Acc: 25.0000%\n",
      "\ttrain 10-72: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 10-73: Loss: 0.1485 Acc: 75.0000%\n",
      "\ttrain 10-74: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 10-75: Loss: 0.4400 Acc: 50.0000%\n",
      "\ttrain 10-76: Loss: 0.3326 Acc: 50.0000%\n",
      "\ttrain 10-77: Loss: 0.3002 Acc: 25.0000%\n",
      "\ttrain 10-78: Loss: 0.2899 Acc: 75.0000%\n",
      "\ttrain 10-79: Loss: 0.5600 Acc: 25.0000%\n",
      "\ttrain 10-80: Loss: 0.1248 Acc: 100.0000%\n",
      "\ttrain 10-81: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 10-82: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 10-83: Loss: 0.1580 Acc: 50.0000%\n",
      "\ttrain 10-84: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 10-85: Loss: 0.1813 Acc: 75.0000%\n",
      "\ttrain 10-86: Loss: 0.1889 Acc: 50.0000%\n",
      "\ttrain 10-87: Loss: 0.0599 Acc: 100.0000%\n",
      "\ttrain 10-88: Loss: 0.1199 Acc: 50.0000%\n",
      "\ttrain 10-89: Loss: 0.2401 Acc: 50.0000%\n",
      "\ttrain 10-90: Loss: 0.3247 Acc: 50.0000%\n",
      "\ttrain 10-91: Loss: 0.1570 Acc: 100.0000%\n",
      "\ttrain 10-92: Loss: 0.1233 Acc: 100.0000%\n",
      "\ttrain 10-93: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 10-94: Loss: 0.1879 Acc: 50.0000%\n",
      "\ttrain 10-95: Loss: 0.1974 Acc: 50.0000%\n",
      "\ttrain 10-96: Loss: 0.2585 Acc: 50.0000%\n",
      "\ttrain 10-97: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 10-98: Loss: 0.3677 Acc: 50.0000%\n",
      "\ttrain 10-99: Loss: 0.2703 Acc: 50.0000%\n",
      "\ttrain 10-100: Loss: 0.3134 Acc: 50.0000%\n",
      "\ttrain 10-101: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 10-102: Loss: 0.1082 Acc: 75.0000%\n",
      "\ttrain 10-103: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 10-104: Loss: 0.2221 Acc: 50.0000%\n",
      "\ttrain 10-105: Loss: 0.1977 Acc: 75.0000%\n",
      "\ttrain 10-106: Loss: 0.4341 Acc: 0.0000%\n",
      "\ttrain 10-107: Loss: 0.3957 Acc: 25.0000%\n",
      "\ttrain 10-108: Loss: 0.1761 Acc: 75.0000%\n",
      "\ttrain 10-109: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 10-110: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 10-111: Loss: 0.4854 Acc: 50.0000%\n",
      "\ttrain 10-112: Loss: 0.1268 Acc: 75.0000%\n",
      "\ttrain 10-113: Loss: 0.3094 Acc: 75.0000%\n",
      "\ttrain 10-114: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 10-115: Loss: 0.3961 Acc: 50.0000%\n",
      "\ttrain 10-116: Loss: 0.4161 Acc: 50.0000%\n",
      "\ttrain 10-117: Loss: 0.2794 Acc: 75.0000%\n",
      "\ttrain 10-118: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 10-119: Loss: 0.2132 Acc: 50.0000%\n",
      "\ttrain 10-120: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 10-121: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 10-122: Loss: 0.3335 Acc: 50.0000%\n",
      "\ttrain 10-123: Loss: 0.3601 Acc: 50.0000%\n",
      "\ttrain 10-124: Loss: 0.4454 Acc: 50.0000%\n",
      "\ttrain 10-125: Loss: 0.3377 Acc: 50.0000%\n",
      "\ttrain 10-126: Loss: 0.2238 Acc: 50.0000%\n",
      "\ttrain 10-127: Loss: 0.1455 Acc: 75.0000%\n",
      "\ttrain 10-128: Loss: 0.2424 Acc: 50.0000%\n",
      "\ttrain 10-129: Loss: 0.2352 Acc: 25.0000%\n",
      "\ttrain 10-130: Loss: 0.7367 Acc: 25.0000%\n",
      "\ttrain 10-131: Loss: 0.2780 Acc: 25.0000%\n",
      "\ttrain 10-132: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 10-133: Loss: 0.2236 Acc: 25.0000%\n",
      "\ttrain 10-134: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 10-135: Loss: 0.0960 Acc: 100.0000%\n",
      "\ttrain 10-136: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 10-137: Loss: 0.7587 Acc: 50.0000%\n",
      "\ttrain 10-138: Loss: 0.2133 Acc: 50.0000%\n",
      "\ttrain 10-139: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 10-140: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 10-141: Loss: 0.4793 Acc: 25.0000%\n",
      "\ttrain 10-142: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 10-143: Loss: 0.2028 Acc: 50.0000%\n",
      "\ttrain 10-144: Loss: 0.2804 Acc: 50.0000%\n",
      "\ttrain 10-145: Loss: 0.2402 Acc: 25.0000%\n",
      "\ttrain 10-146: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 10-147: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 10-148: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 10-149: Loss: 0.2571 Acc: 25.0000%\n",
      "\ttrain 10-150: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 10-151: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 10-152: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 10-153: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 10-154: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 10-155: Loss: 0.1555 Acc: 75.0000%\n",
      "\ttrain 10-156: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 10-157: Loss: 0.2036 Acc: 50.0000%\n",
      "\ttrain 10-158: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 10-159: Loss: 0.2700 Acc: 50.0000%\n",
      "\ttrain 10-160: Loss: 0.2891 Acc: 75.0000%\n",
      "\ttrain 10-161: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 10-162: Loss: 0.0671 Acc: 100.0000%\n",
      "\ttrain 10-163: Loss: 0.2116 Acc: 50.0000%\n",
      "\ttrain 10-164: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 10-165: Loss: 0.2652 Acc: 50.0000%\n",
      "\ttrain 10-166: Loss: 0.1894 Acc: 75.0000%\n",
      "\ttrain 10-167: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 10-168: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 10-169: Loss: 0.1798 Acc: 50.0000%\n",
      "\ttrain 10-170: Loss: 0.1928 Acc: 50.0000%\n",
      "\ttrain 10-171: Loss: 0.0869 Acc: 100.0000%\n",
      "\ttrain 10-172: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 10-173: Loss: 0.3531 Acc: 75.0000%\n",
      "\ttrain 10-174: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 10-175: Loss: 0.1348 Acc: 100.0000%\n",
      "\ttrain 10-176: Loss: 0.1445 Acc: 75.0000%\n",
      "\ttrain 10-177: Loss: 0.4671 Acc: 0.0000%\n",
      "\ttrain 10-178: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 10-179: Loss: 0.2218 Acc: 75.0000%\n",
      "\ttrain 10-180: Loss: 0.1401 Acc: 75.0000%\n",
      "\ttrain 10-181: Loss: 0.1726 Acc: 75.0000%\n",
      "\ttrain 10-182: Loss: 0.3193 Acc: 25.0000%\n",
      "\ttrain 10-183: Loss: 0.4871 Acc: 0.0000%\n",
      "\ttrain 10-184: Loss: 0.0723 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 10-185: Loss: 0.1188 Acc: 75.0000%\n",
      "\ttrain 10-186: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 10-187: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 10-188: Loss: 0.3831 Acc: 50.0000%\n",
      "\ttrain 10-189: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 10-190: Loss: 0.2520 Acc: 50.0000%\n",
      "\ttrain 10-191: Loss: 0.5477 Acc: 25.0000%\n",
      "\ttrain 10-192: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 10-193: Loss: 0.4745 Acc: 25.0000%\n",
      "\ttrain 10-194: Loss: 0.4791 Acc: 25.0000%\n",
      "\ttrain 10-195: Loss: 0.7606 Acc: 25.0000%\n",
      "\ttrain 10-196: Loss: 0.1335 Acc: 75.0000%\n",
      "\ttrain 10-197: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 10-198: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 10-199: Loss: 0.4590 Acc: 25.0000%\n",
      "\ttrain 10-200: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 10-201: Loss: 0.2275 Acc: 75.0000%\n",
      "\ttrain 10-202: Loss: 0.5280 Acc: 0.0000%\n",
      "\ttrain 10-203: Loss: 0.2654 Acc: 50.0000%\n",
      "\ttrain 10-204: Loss: 0.3695 Acc: 25.0000%\n",
      "\ttrain 10-205: Loss: 0.2754 Acc: 50.0000%\n",
      "\ttrain 10-206: Loss: 0.3238 Acc: 50.0000%\n",
      "\ttrain 10-207: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 10-208: Loss: 0.2532 Acc: 50.0000%\n",
      "\ttrain 10-209: Loss: 0.7151 Acc: 0.0000%\n",
      "\ttrain 10-210: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 10-211: Loss: 0.1657 Acc: 50.0000%\n",
      "\ttrain 10-212: Loss: 0.5505 Acc: 50.0000%\n",
      "\ttrain 10-213: Loss: 0.3685 Acc: 75.0000%\n",
      "\ttrain 10-214: Loss: 0.7129 Acc: 50.0000%\n",
      "\ttrain 10-215: Loss: 0.4199 Acc: 75.0000%\n",
      "\ttrain 10-216: Loss: 0.3573 Acc: 75.0000%\n",
      "\ttrain 10-217: Loss: 0.3839 Acc: 50.0000%\n",
      "\ttrain 10-218: Loss: 0.1453 Acc: 75.0000%\n",
      "\ttrain 10-219: Loss: 0.3521 Acc: 25.0000%\n",
      "\ttrain 10-220: Loss: 0.0908 Acc: 100.0000%\n",
      "\ttrain 10-221: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 10-222: Loss: 0.5372 Acc: 50.0000%\n",
      "\ttrain 10-223: Loss: 0.3001 Acc: 50.0000%\n",
      "\ttrain 10-224: Loss: 0.3895 Acc: 75.0000%\n",
      "\ttrain 10-225: Loss: 0.5802 Acc: 25.0000%\n",
      "\ttrain 10-226: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 10-227: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 10-228: Loss: 0.4542 Acc: 50.0000%\n",
      "\ttrain 10-229: Loss: 0.5071 Acc: 25.0000%\n",
      "\ttrain 10-230: Loss: 0.1759 Acc: 75.0000%\n",
      "\ttrain 10-231: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 10-232: Loss: 0.1516 Acc: 75.0000%\n",
      "\ttrain 10-233: Loss: 0.2324 Acc: 75.0000%\n",
      "\ttrain 10-234: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 10-235: Loss: 0.2947 Acc: 25.0000%\n",
      "\ttrain 10-236: Loss: 0.1630 Acc: 75.0000%\n",
      "\ttrain 10-237: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 10-238: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 10-239: Loss: 0.2463 Acc: 75.0000%\n",
      "\ttrain 10-240: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 10-241: Loss: 0.0787 Acc: 100.0000%\n",
      "\ttrain 10-242: Loss: 0.3153 Acc: 25.0000%\n",
      "\ttrain 10-243: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 10-244: Loss: 0.4620 Acc: 50.0000%\n",
      "\ttrain 10-245: Loss: 0.1134 Acc: 75.0000%\n",
      "\tvalidation 10-1: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 10-2: Loss: 0.0802 Acc: 100.0000%\n",
      "\tvalidation 10-3: Loss: 0.0419 Acc: 100.0000%\n",
      "\tvalidation 10-4: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 10-5: Loss: 0.1390 Acc: 75.0000%\n",
      "\tvalidation 10-6: Loss: 0.1351 Acc: 75.0000%\n",
      "\tvalidation 10-7: Loss: 0.0783 Acc: 75.0000%\n",
      "\tvalidation 10-8: Loss: 0.0998 Acc: 75.0000%\n",
      "\tvalidation 10-9: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 10-10: Loss: 0.0654 Acc: 100.0000%\n",
      "\tvalidation 10-11: Loss: 0.1178 Acc: 75.0000%\n",
      "\tvalidation 10-12: Loss: 0.0749 Acc: 100.0000%\n",
      "\tvalidation 10-13: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 10-14: Loss: 0.0815 Acc: 75.0000%\n",
      "\tvalidation 10-15: Loss: 0.0619 Acc: 75.0000%\n",
      "\tvalidation 10-16: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 10-17: Loss: 0.1186 Acc: 50.0000%\n",
      "\tvalidation 10-18: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 10-19: Loss: 0.3428 Acc: 25.0000%\n",
      "\tvalidation 10-20: Loss: 0.0658 Acc: 75.0000%\n",
      "\tvalidation 10-21: Loss: 0.1080 Acc: 50.0000%\n",
      "\tvalidation 10-22: Loss: 0.1261 Acc: 50.0000%\n",
      "\tvalidation 10-23: Loss: 0.0534 Acc: 75.0000%\n",
      "\tvalidation 10-24: Loss: 0.6864 Acc: 50.0000%\n",
      "\tvalidation 10-25: Loss: 0.5113 Acc: 75.0000%\n",
      "\tvalidation 10-26: Loss: 0.0617 Acc: 75.0000%\n",
      "\tvalidation 10-27: Loss: 0.1097 Acc: 75.0000%\n",
      "\tvalidation 10-28: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 10-29: Loss: 0.0381 Acc: 100.0000%\n",
      "\tvalidation 10-30: Loss: 0.2648 Acc: 75.0000%\n",
      "\tvalidation 10-31: Loss: 0.0667 Acc: 100.0000%\n",
      "\tvalidation 10-32: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 10-33: Loss: 0.1398 Acc: 50.0000%\n",
      "\tvalidation 10-34: Loss: 0.1590 Acc: 50.0000%\n",
      "\tvalidation 10-35: Loss: 0.1019 Acc: 75.0000%\n",
      "\tvalidation 10-36: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 10-37: Loss: 0.0551 Acc: 75.0000%\n",
      "\tvalidation 10-38: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 10-39: Loss: 0.1041 Acc: 75.0000%\n",
      "\tvalidation 10-40: Loss: 0.0949 Acc: 75.0000%\n",
      "\tvalidation 10-41: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 10-42: Loss: 0.1199 Acc: 75.0000%\n",
      "\tvalidation 10-43: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 10-44: Loss: 0.5032 Acc: 50.0000%\n",
      "\tvalidation 10-45: Loss: 0.1323 Acc: 50.0000%\n",
      "\tvalidation 10-46: Loss: 0.0971 Acc: 100.0000%\n",
      "\tvalidation 10-47: Loss: 0.1673 Acc: 50.0000%\n",
      "\tvalidation 10-48: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 10-49: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 10-50: Loss: 0.1058 Acc: 75.0000%\n",
      "\tvalidation 10-51: Loss: 0.1136 Acc: 50.0000%\n",
      "\tvalidation 10-52: Loss: 0.0488 Acc: 75.0000%\n",
      "\tvalidation 10-53: Loss: 0.0977 Acc: 100.0000%\n",
      "\tvalidation 10-54: Loss: 0.0455 Acc: 100.0000%\n",
      "\tvalidation 10-55: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 10-56: Loss: 0.0622 Acc: 75.0000%\n",
      "\tvalidation 10-57: Loss: 0.4972 Acc: 50.0000%\n",
      "\tvalidation 10-58: Loss: 0.0455 Acc: 100.0000%\n",
      "\tvalidation 10-59: Loss: 0.1534 Acc: 50.0000%\n",
      "\tvalidation 10-60: Loss: 0.1197 Acc: 50.0000%\n",
      "\tvalidation 10-61: Loss: 0.1969 Acc: 50.0000%\n",
      "\tvalidation 10-62: Loss: 0.0826 Acc: 75.0000%\n",
      "\tvalidation 10-63: Loss: 0.1235 Acc: 50.0000%\n",
      "\tvalidation 10-64: Loss: 0.0880 Acc: 75.0000%\n",
      "\tvalidation 10-65: Loss: 0.1613 Acc: 50.0000%\n",
      "\tvalidation 10-66: Loss: 0.0700 Acc: 75.0000%\n",
      "\tvalidation 10-67: Loss: 0.1887 Acc: 25.0000%\n",
      "\tvalidation 10-68: Loss: 0.1158 Acc: 100.0000%\n",
      "\tvalidation 10-69: Loss: 1.7879 Acc: 50.0000%\n",
      "\tvalidation 10-70: Loss: 0.0517 Acc: 75.0000%\n",
      "\tvalidation 10-71: Loss: 0.0670 Acc: 100.0000%\n",
      "\tvalidation 10-72: Loss: 0.0532 Acc: 75.0000%\n",
      "\tvalidation 10-73: Loss: 0.2572 Acc: 75.0000%\n",
      "\tvalidation 10-74: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 10-75: Loss: 0.0780 Acc: 100.0000%\n",
      "\tvalidation 10-76: Loss: 0.1266 Acc: 75.0000%\n",
      "\tvalidation 10-77: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 10-78: Loss: 0.1185 Acc: 50.0000%\n",
      "\tvalidation 10-79: Loss: 0.0523 Acc: 75.0000%\n",
      "\tvalidation 10-80: Loss: 0.0643 Acc: 100.0000%\n",
      "\tvalidation 10-81: Loss: 0.7925 Acc: 75.0000%\n",
      "\tvalidation 10-82: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 10-83: Loss: 0.0621 Acc: 75.0000%\n",
      "\tvalidation 10-84: Loss: 0.1165 Acc: 100.0000%\n",
      "\tvalidation 10-85: Loss: 0.1517 Acc: 50.0000%\n",
      "\tvalidation 10-86: Loss: 0.1735 Acc: 25.0000%\n",
      "\tvalidation 10-87: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 10-88: Loss: 0.6990 Acc: 25.0000%\n",
      "\tvalidation 10-89: Loss: 0.1331 Acc: 75.0000%\n",
      "\tvalidation 10-90: Loss: 0.1150 Acc: 75.0000%\n",
      "\tvalidation 10-91: Loss: 0.0500 Acc: 100.0000%\n",
      "\tvalidation 10-92: Loss: 0.0825 Acc: 100.0000%\n",
      "\tvalidation 10-93: Loss: 0.0627 Acc: 75.0000%\n",
      "\tvalidation 10-94: Loss: 0.0524 Acc: 75.0000%\n",
      "\tvalidation 10-95: Loss: 0.0966 Acc: 75.0000%\n",
      "\tvalidation 10-96: Loss: 0.0480 Acc: 75.0000%\n",
      "\tvalidation 10-97: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 10-98: Loss: 0.1118 Acc: 50.0000%\n",
      "\tvalidation 10-99: Loss: 0.1732 Acc: 50.0000%\n",
      "\tvalidation 10-100: Loss: 0.1059 Acc: 50.0000%\n",
      "\tvalidation 10-101: Loss: 0.0636 Acc: 75.0000%\n",
      "\tvalidation 10-102: Loss: 0.0875 Acc: 75.0000%\n",
      "\tvalidation 10-103: Loss: 0.0930 Acc: 75.0000%\n",
      "\tvalidation 10-104: Loss: 0.0806 Acc: 100.0000%\n",
      "\tvalidation 10-105: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain Loss: 0.2298 Acc: 63.6735%\n",
      "\tvalidation Loss: 0.1359 Acc: 76.6667%\n",
      "网络参数更新\n",
      "Time passed 0h 6m 38s\n",
      "--------------------\n",
      "Epoch [11/40]:\n",
      "\ttrain 11-1: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 11-2: Loss: 0.3209 Acc: 50.0000%\n",
      "\ttrain 11-3: Loss: 0.2445 Acc: 50.0000%\n",
      "\ttrain 11-4: Loss: 0.3103 Acc: 75.0000%\n",
      "\ttrain 11-5: Loss: 0.3290 Acc: 25.0000%\n",
      "\ttrain 11-6: Loss: 0.1054 Acc: 100.0000%\n",
      "\ttrain 11-7: Loss: 0.3013 Acc: 50.0000%\n",
      "\ttrain 11-8: Loss: 0.1348 Acc: 50.0000%\n",
      "\ttrain 11-9: Loss: 0.1137 Acc: 100.0000%\n",
      "\ttrain 11-10: Loss: 0.1835 Acc: 50.0000%\n",
      "\ttrain 11-11: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 11-12: Loss: 0.3898 Acc: 25.0000%\n",
      "\ttrain 11-13: Loss: 0.1497 Acc: 75.0000%\n",
      "\ttrain 11-14: Loss: 0.2086 Acc: 50.0000%\n",
      "\ttrain 11-15: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 11-16: Loss: 0.1502 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-17: Loss: 0.4056 Acc: 25.0000%\n",
      "\ttrain 11-18: Loss: 0.2012 Acc: 50.0000%\n",
      "\ttrain 11-19: Loss: 0.2140 Acc: 50.0000%\n",
      "\ttrain 11-20: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 11-21: Loss: 0.2412 Acc: 50.0000%\n",
      "\ttrain 11-22: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 11-23: Loss: 0.1920 Acc: 50.0000%\n",
      "\ttrain 11-24: Loss: 0.3455 Acc: 25.0000%\n",
      "\ttrain 11-25: Loss: 0.1013 Acc: 100.0000%\n",
      "\ttrain 11-26: Loss: 0.1541 Acc: 50.0000%\n",
      "\ttrain 11-27: Loss: 0.2055 Acc: 25.0000%\n",
      "\ttrain 11-28: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 11-29: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 11-30: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 11-31: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 11-32: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 11-33: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 11-34: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 11-35: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 11-36: Loss: 0.3311 Acc: 50.0000%\n",
      "\ttrain 11-37: Loss: 0.0930 Acc: 100.0000%\n",
      "\ttrain 11-38: Loss: 0.2152 Acc: 50.0000%\n",
      "\ttrain 11-39: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 11-40: Loss: 0.1830 Acc: 50.0000%\n",
      "\ttrain 11-41: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 11-42: Loss: 0.3535 Acc: 25.0000%\n",
      "\ttrain 11-43: Loss: 0.1717 Acc: 25.0000%\n",
      "\ttrain 11-44: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 11-45: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 11-46: Loss: 0.2204 Acc: 50.0000%\n",
      "\ttrain 11-47: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 11-48: Loss: 0.1375 Acc: 50.0000%\n",
      "\ttrain 11-49: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 11-50: Loss: 0.2723 Acc: 50.0000%\n",
      "\ttrain 11-51: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 11-52: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 11-53: Loss: 0.2131 Acc: 50.0000%\n",
      "\ttrain 11-54: Loss: 0.1364 Acc: 50.0000%\n",
      "\ttrain 11-55: Loss: 0.1506 Acc: 100.0000%\n",
      "\ttrain 11-56: Loss: 0.2385 Acc: 75.0000%\n",
      "\ttrain 11-57: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 11-58: Loss: 0.2444 Acc: 50.0000%\n",
      "\ttrain 11-59: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 11-60: Loss: 0.0772 Acc: 100.0000%\n",
      "\ttrain 11-61: Loss: 0.1186 Acc: 100.0000%\n",
      "\ttrain 11-62: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 11-63: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 11-64: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 11-65: Loss: 0.2645 Acc: 50.0000%\n",
      "\ttrain 11-66: Loss: 0.4635 Acc: 25.0000%\n",
      "\ttrain 11-67: Loss: 0.3088 Acc: 50.0000%\n",
      "\ttrain 11-68: Loss: 0.3324 Acc: 25.0000%\n",
      "\ttrain 11-69: Loss: 0.3903 Acc: 50.0000%\n",
      "\ttrain 11-70: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 11-71: Loss: 0.1055 Acc: 100.0000%\n",
      "\ttrain 11-72: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 11-73: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 11-74: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 11-75: Loss: 0.1698 Acc: 50.0000%\n",
      "\ttrain 11-76: Loss: 0.3164 Acc: 50.0000%\n",
      "\ttrain 11-77: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 11-78: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 11-79: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 11-80: Loss: 0.1975 Acc: 50.0000%\n",
      "\ttrain 11-81: Loss: 0.2792 Acc: 50.0000%\n",
      "\ttrain 11-82: Loss: 0.2611 Acc: 50.0000%\n",
      "\ttrain 11-83: Loss: 0.1188 Acc: 75.0000%\n",
      "\ttrain 11-84: Loss: 0.3417 Acc: 50.0000%\n",
      "\ttrain 11-85: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 11-86: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 11-87: Loss: 0.3174 Acc: 25.0000%\n",
      "\ttrain 11-88: Loss: 0.4168 Acc: 75.0000%\n",
      "\ttrain 11-89: Loss: 0.4812 Acc: 25.0000%\n",
      "\ttrain 11-90: Loss: 0.3060 Acc: 75.0000%\n",
      "\ttrain 11-91: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 11-92: Loss: 0.0729 Acc: 100.0000%\n",
      "\ttrain 11-93: Loss: 0.0761 Acc: 100.0000%\n",
      "\ttrain 11-94: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 11-95: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 11-96: Loss: 0.3117 Acc: 50.0000%\n",
      "\ttrain 11-97: Loss: 0.3276 Acc: 25.0000%\n",
      "\ttrain 11-98: Loss: 0.2488 Acc: 75.0000%\n",
      "\ttrain 11-99: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 11-100: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 11-101: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 11-102: Loss: 0.3019 Acc: 75.0000%\n",
      "\ttrain 11-103: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 11-104: Loss: 0.2041 Acc: 75.0000%\n",
      "\ttrain 11-105: Loss: 0.9197 Acc: 0.0000%\n",
      "\ttrain 11-106: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 11-107: Loss: 0.0828 Acc: 100.0000%\n",
      "\ttrain 11-108: Loss: 0.3251 Acc: 25.0000%\n",
      "\ttrain 11-109: Loss: 0.1990 Acc: 75.0000%\n",
      "\ttrain 11-110: Loss: 0.2597 Acc: 25.0000%\n",
      "\ttrain 11-111: Loss: 0.3264 Acc: 25.0000%\n",
      "\ttrain 11-112: Loss: 0.1375 Acc: 50.0000%\n",
      "\ttrain 11-113: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 11-114: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 11-115: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 11-116: Loss: 0.1627 Acc: 50.0000%\n",
      "\ttrain 11-117: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 11-118: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 11-119: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 11-120: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 11-121: Loss: 0.1139 Acc: 50.0000%\n",
      "\ttrain 11-122: Loss: 0.1456 Acc: 50.0000%\n",
      "\ttrain 11-123: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 11-124: Loss: 0.2648 Acc: 25.0000%\n",
      "\ttrain 11-125: Loss: 0.4513 Acc: 50.0000%\n",
      "\ttrain 11-126: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 11-127: Loss: 0.0744 Acc: 100.0000%\n",
      "\ttrain 11-128: Loss: 0.3158 Acc: 25.0000%\n",
      "\ttrain 11-129: Loss: 0.1978 Acc: 50.0000%\n",
      "\ttrain 11-130: Loss: 0.2122 Acc: 50.0000%\n",
      "\ttrain 11-131: Loss: 0.2341 Acc: 75.0000%\n",
      "\ttrain 11-132: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 11-133: Loss: 0.4390 Acc: 50.0000%\n",
      "\ttrain 11-134: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 11-135: Loss: 0.0483 Acc: 75.0000%\n",
      "\ttrain 11-136: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 11-137: Loss: 0.1710 Acc: 75.0000%\n",
      "\ttrain 11-138: Loss: 0.3686 Acc: 50.0000%\n",
      "\ttrain 11-139: Loss: 0.1388 Acc: 50.0000%\n",
      "\ttrain 11-140: Loss: 0.1475 Acc: 50.0000%\n",
      "\ttrain 11-141: Loss: 0.1416 Acc: 50.0000%\n",
      "\ttrain 11-142: Loss: 0.3617 Acc: 50.0000%\n",
      "\ttrain 11-143: Loss: 0.2744 Acc: 75.0000%\n",
      "\ttrain 11-144: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 11-145: Loss: 0.6173 Acc: 25.0000%\n",
      "\ttrain 11-146: Loss: 0.1840 Acc: 50.0000%\n",
      "\ttrain 11-147: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 11-148: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 11-149: Loss: 0.1713 Acc: 50.0000%\n",
      "\ttrain 11-150: Loss: 0.4141 Acc: 0.0000%\n",
      "\ttrain 11-151: Loss: 0.1690 Acc: 75.0000%\n",
      "\ttrain 11-152: Loss: 0.1687 Acc: 25.0000%\n",
      "\ttrain 11-153: Loss: 0.1646 Acc: 50.0000%\n",
      "\ttrain 11-154: Loss: 0.0781 Acc: 100.0000%\n",
      "\ttrain 11-155: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 11-156: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 11-157: Loss: 0.3629 Acc: 50.0000%\n",
      "\ttrain 11-158: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 11-159: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 11-160: Loss: 0.2911 Acc: 50.0000%\n",
      "\ttrain 11-161: Loss: 0.3999 Acc: 50.0000%\n",
      "\ttrain 11-162: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 11-163: Loss: 0.2303 Acc: 25.0000%\n",
      "\ttrain 11-164: Loss: 0.1238 Acc: 100.0000%\n",
      "\ttrain 11-165: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 11-166: Loss: 0.1757 Acc: 50.0000%\n",
      "\ttrain 11-167: Loss: 0.1622 Acc: 50.0000%\n",
      "\ttrain 11-168: Loss: 0.4198 Acc: 25.0000%\n",
      "\ttrain 11-169: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 11-170: Loss: 0.0886 Acc: 100.0000%\n",
      "\ttrain 11-171: Loss: 0.3333 Acc: 25.0000%\n",
      "\ttrain 11-172: Loss: 0.1862 Acc: 50.0000%\n",
      "\ttrain 11-173: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 11-174: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 11-175: Loss: 0.3812 Acc: 25.0000%\n",
      "\ttrain 11-176: Loss: 0.2719 Acc: 25.0000%\n",
      "\ttrain 11-177: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 11-178: Loss: 0.7971 Acc: 25.0000%\n",
      "\ttrain 11-179: Loss: 0.1956 Acc: 50.0000%\n",
      "\ttrain 11-180: Loss: 0.1539 Acc: 50.0000%\n",
      "\ttrain 11-181: Loss: 0.1405 Acc: 50.0000%\n",
      "\ttrain 11-182: Loss: 0.2101 Acc: 50.0000%\n",
      "\ttrain 11-183: Loss: 0.2509 Acc: 75.0000%\n",
      "\ttrain 11-184: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 11-185: Loss: 0.2837 Acc: 75.0000%\n",
      "\ttrain 11-186: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 11-187: Loss: 0.2866 Acc: 50.0000%\n",
      "\ttrain 11-188: Loss: 0.2908 Acc: 25.0000%\n",
      "\ttrain 11-189: Loss: 0.2358 Acc: 50.0000%\n",
      "\ttrain 11-190: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 11-191: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 11-192: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 11-193: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 11-194: Loss: 0.3064 Acc: 50.0000%\n",
      "\ttrain 11-195: Loss: 0.3851 Acc: 50.0000%\n",
      "\ttrain 11-196: Loss: 0.2473 Acc: 75.0000%\n",
      "\ttrain 11-197: Loss: 0.1328 Acc: 50.0000%\n",
      "\ttrain 11-198: Loss: 0.2354 Acc: 50.0000%\n",
      "\ttrain 11-199: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 11-200: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 11-201: Loss: 0.2101 Acc: 50.0000%\n",
      "\ttrain 11-202: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 11-203: Loss: 0.1338 Acc: 50.0000%\n",
      "\ttrain 11-204: Loss: 0.1746 Acc: 50.0000%\n",
      "\ttrain 11-205: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 11-206: Loss: 0.1278 Acc: 100.0000%\n",
      "\ttrain 11-207: Loss: 0.1868 Acc: 50.0000%\n",
      "\ttrain 11-208: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 11-209: Loss: 0.4216 Acc: 25.0000%\n",
      "\ttrain 11-210: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 11-211: Loss: 0.1903 Acc: 50.0000%\n",
      "\ttrain 11-212: Loss: 0.2317 Acc: 25.0000%\n",
      "\ttrain 11-213: Loss: 0.1110 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-214: Loss: 0.3812 Acc: 50.0000%\n",
      "\ttrain 11-215: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 11-216: Loss: 0.1203 Acc: 50.0000%\n",
      "\ttrain 11-217: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 11-218: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 11-219: Loss: 0.2241 Acc: 75.0000%\n",
      "\ttrain 11-220: Loss: 0.1983 Acc: 50.0000%\n",
      "\ttrain 11-221: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 11-222: Loss: 0.1383 Acc: 50.0000%\n",
      "\ttrain 11-223: Loss: 0.3406 Acc: 25.0000%\n",
      "\ttrain 11-224: Loss: 0.0985 Acc: 100.0000%\n",
      "\ttrain 11-225: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 11-226: Loss: 0.1714 Acc: 50.0000%\n",
      "\ttrain 11-227: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 11-228: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 11-229: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 11-230: Loss: 0.5262 Acc: 25.0000%\n",
      "\ttrain 11-231: Loss: 0.0789 Acc: 100.0000%\n",
      "\ttrain 11-232: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 11-233: Loss: 0.3653 Acc: 25.0000%\n",
      "\ttrain 11-234: Loss: 0.1838 Acc: 75.0000%\n",
      "\ttrain 11-235: Loss: 0.4471 Acc: 50.0000%\n",
      "\ttrain 11-236: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 11-237: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 11-238: Loss: 0.1839 Acc: 50.0000%\n",
      "\ttrain 11-239: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 11-240: Loss: 0.5260 Acc: 50.0000%\n",
      "\ttrain 11-241: Loss: 0.3895 Acc: 25.0000%\n",
      "\ttrain 11-242: Loss: 0.5150 Acc: 0.0000%\n",
      "\ttrain 11-243: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 11-244: Loss: 0.1841 Acc: 25.0000%\n",
      "\ttrain 11-245: Loss: 0.1311 Acc: 75.0000%\n",
      "\tvalidation 11-1: Loss: 1.8412 Acc: 75.0000%\n",
      "\tvalidation 11-2: Loss: 0.0865 Acc: 75.0000%\n",
      "\tvalidation 11-3: Loss: 0.0695 Acc: 75.0000%\n",
      "\tvalidation 11-4: Loss: 0.0592 Acc: 75.0000%\n",
      "\tvalidation 11-5: Loss: 0.1593 Acc: 50.0000%\n",
      "\tvalidation 11-6: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 11-7: Loss: 0.1506 Acc: 50.0000%\n",
      "\tvalidation 11-8: Loss: 0.2190 Acc: 75.0000%\n",
      "\tvalidation 11-9: Loss: 0.9782 Acc: 50.0000%\n",
      "\tvalidation 11-10: Loss: 0.3477 Acc: 75.0000%\n",
      "\tvalidation 11-11: Loss: 0.0613 Acc: 75.0000%\n",
      "\tvalidation 11-12: Loss: 0.0549 Acc: 75.0000%\n",
      "\tvalidation 11-13: Loss: 0.0926 Acc: 75.0000%\n",
      "\tvalidation 11-14: Loss: 1.3668 Acc: 75.0000%\n",
      "\tvalidation 11-15: Loss: 0.1907 Acc: 75.0000%\n",
      "\tvalidation 11-16: Loss: 0.1480 Acc: 50.0000%\n",
      "\tvalidation 11-17: Loss: 0.0871 Acc: 75.0000%\n",
      "\tvalidation 11-18: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 11-19: Loss: 0.0573 Acc: 75.0000%\n",
      "\tvalidation 11-20: Loss: 0.0573 Acc: 100.0000%\n",
      "\tvalidation 11-21: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 11-22: Loss: 0.0657 Acc: 100.0000%\n",
      "\tvalidation 11-23: Loss: 0.1336 Acc: 75.0000%\n",
      "\tvalidation 11-24: Loss: 0.5636 Acc: 75.0000%\n",
      "\tvalidation 11-25: Loss: 0.1171 Acc: 50.0000%\n",
      "\tvalidation 11-26: Loss: 0.0479 Acc: 75.0000%\n",
      "\tvalidation 11-27: Loss: 0.1037 Acc: 75.0000%\n",
      "\tvalidation 11-28: Loss: 0.0555 Acc: 100.0000%\n",
      "\tvalidation 11-29: Loss: 0.1018 Acc: 75.0000%\n",
      "\tvalidation 11-30: Loss: 0.0959 Acc: 75.0000%\n",
      "\tvalidation 11-31: Loss: 0.2188 Acc: 50.0000%\n",
      "\tvalidation 11-32: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 11-33: Loss: 0.0444 Acc: 100.0000%\n",
      "\tvalidation 11-34: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 11-35: Loss: 0.1608 Acc: 50.0000%\n",
      "\tvalidation 11-36: Loss: 0.2392 Acc: 50.0000%\n",
      "\tvalidation 11-37: Loss: 7.3586 Acc: 75.0000%\n",
      "\tvalidation 11-38: Loss: 1.6393 Acc: 75.0000%\n",
      "\tvalidation 11-39: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 11-40: Loss: 0.2004 Acc: 75.0000%\n",
      "\tvalidation 11-41: Loss: 0.6029 Acc: 75.0000%\n",
      "\tvalidation 11-42: Loss: 0.4537 Acc: 75.0000%\n",
      "\tvalidation 11-43: Loss: 0.0881 Acc: 75.0000%\n",
      "\tvalidation 11-44: Loss: 5.1327 Acc: 50.0000%\n",
      "\tvalidation 11-45: Loss: 5.7734 Acc: 50.0000%\n",
      "\tvalidation 11-46: Loss: 0.1574 Acc: 50.0000%\n",
      "\tvalidation 11-47: Loss: 0.1866 Acc: 50.0000%\n",
      "\tvalidation 11-48: Loss: 0.0696 Acc: 75.0000%\n",
      "\tvalidation 11-49: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 11-50: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 11-51: Loss: 0.0869 Acc: 75.0000%\n",
      "\tvalidation 11-52: Loss: 0.1283 Acc: 50.0000%\n",
      "\tvalidation 11-53: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 11-54: Loss: 0.2807 Acc: 50.0000%\n",
      "\tvalidation 11-55: Loss: 0.0886 Acc: 100.0000%\n",
      "\tvalidation 11-56: Loss: 0.7932 Acc: 50.0000%\n",
      "\tvalidation 11-57: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 11-58: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 11-59: Loss: 0.1479 Acc: 75.0000%\n",
      "\tvalidation 11-60: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 11-61: Loss: 0.0836 Acc: 75.0000%\n",
      "\tvalidation 11-62: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 11-63: Loss: 0.6940 Acc: 50.0000%\n",
      "\tvalidation 11-64: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 11-65: Loss: 0.0669 Acc: 75.0000%\n",
      "\tvalidation 11-66: Loss: 0.2685 Acc: 75.0000%\n",
      "\tvalidation 11-67: Loss: 0.0867 Acc: 100.0000%\n",
      "\tvalidation 11-68: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 11-69: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 11-70: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 11-71: Loss: 0.0716 Acc: 75.0000%\n",
      "\tvalidation 11-72: Loss: 0.0584 Acc: 75.0000%\n",
      "\tvalidation 11-73: Loss: 0.1835 Acc: 50.0000%\n",
      "\tvalidation 11-74: Loss: 0.0654 Acc: 100.0000%\n",
      "\tvalidation 11-75: Loss: 0.0825 Acc: 75.0000%\n",
      "\tvalidation 11-76: Loss: 0.0694 Acc: 100.0000%\n",
      "\tvalidation 11-77: Loss: 0.1602 Acc: 50.0000%\n",
      "\tvalidation 11-78: Loss: 0.0678 Acc: 100.0000%\n",
      "\tvalidation 11-79: Loss: 0.0583 Acc: 100.0000%\n",
      "\tvalidation 11-80: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 11-81: Loss: 0.0352 Acc: 100.0000%\n",
      "\tvalidation 11-82: Loss: 0.0868 Acc: 100.0000%\n",
      "\tvalidation 11-83: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 11-84: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 11-85: Loss: 0.9417 Acc: 50.0000%\n",
      "\tvalidation 11-86: Loss: 0.1290 Acc: 50.0000%\n",
      "\tvalidation 11-87: Loss: 0.1028 Acc: 75.0000%\n",
      "\tvalidation 11-88: Loss: 0.0453 Acc: 100.0000%\n",
      "\tvalidation 11-89: Loss: 0.0914 Acc: 50.0000%\n",
      "\tvalidation 11-90: Loss: 0.5209 Acc: 50.0000%\n",
      "\tvalidation 11-91: Loss: 0.1229 Acc: 75.0000%\n",
      "\tvalidation 11-92: Loss: 3.2326 Acc: 50.0000%\n",
      "\tvalidation 11-93: Loss: 0.2485 Acc: 75.0000%\n",
      "\tvalidation 11-94: Loss: 0.0896 Acc: 75.0000%\n",
      "\tvalidation 11-95: Loss: 0.0722 Acc: 75.0000%\n",
      "\tvalidation 11-96: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 11-97: Loss: 0.0548 Acc: 100.0000%\n",
      "\tvalidation 11-98: Loss: 2.5489 Acc: 50.0000%\n",
      "\tvalidation 11-99: Loss: 1.2473 Acc: 75.0000%\n",
      "\tvalidation 11-100: Loss: 0.0532 Acc: 75.0000%\n",
      "\tvalidation 11-101: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 11-102: Loss: 0.9318 Acc: 75.0000%\n",
      "\tvalidation 11-103: Loss: 0.0849 Acc: 100.0000%\n",
      "\tvalidation 11-104: Loss: 0.1507 Acc: 50.0000%\n",
      "\tvalidation 11-105: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1897 Acc: 64.5918%\n",
      "\tvalidation Loss: 0.4293 Acc: 76.6667%\n",
      "Time passed 0h 7m 17s\n",
      "--------------------\n",
      "Epoch [12/40]:\n",
      "\ttrain 12-1: Loss: 0.3559 Acc: 50.0000%\n",
      "\ttrain 12-2: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 12-3: Loss: 0.2109 Acc: 50.0000%\n",
      "\ttrain 12-4: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain 12-5: Loss: 0.2529 Acc: 50.0000%\n",
      "\ttrain 12-6: Loss: 0.2214 Acc: 75.0000%\n",
      "\ttrain 12-7: Loss: 0.2094 Acc: 50.0000%\n",
      "\ttrain 12-8: Loss: 0.1726 Acc: 75.0000%\n",
      "\ttrain 12-9: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 12-10: Loss: 0.2674 Acc: 75.0000%\n",
      "\ttrain 12-11: Loss: 0.5993 Acc: 25.0000%\n",
      "\ttrain 12-12: Loss: 0.0825 Acc: 75.0000%\n",
      "\ttrain 12-13: Loss: 0.3101 Acc: 50.0000%\n",
      "\ttrain 12-14: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 12-15: Loss: 0.5997 Acc: 25.0000%\n",
      "\ttrain 12-16: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 12-17: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 12-18: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 12-19: Loss: 0.1574 Acc: 100.0000%\n",
      "\ttrain 12-20: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 12-21: Loss: 0.2198 Acc: 75.0000%\n",
      "\ttrain 12-22: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 12-23: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 12-24: Loss: 0.1251 Acc: 100.0000%\n",
      "\ttrain 12-25: Loss: 0.2774 Acc: 50.0000%\n",
      "\ttrain 12-26: Loss: 0.2917 Acc: 50.0000%\n",
      "\ttrain 12-27: Loss: 0.2241 Acc: 50.0000%\n",
      "\ttrain 12-28: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 12-29: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 12-30: Loss: 0.3062 Acc: 75.0000%\n",
      "\ttrain 12-31: Loss: 0.2561 Acc: 75.0000%\n",
      "\ttrain 12-32: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 12-33: Loss: 0.0560 Acc: 75.0000%\n",
      "\ttrain 12-34: Loss: 0.2557 Acc: 75.0000%\n",
      "\ttrain 12-35: Loss: 0.1726 Acc: 75.0000%\n",
      "\ttrain 12-36: Loss: 0.3547 Acc: 25.0000%\n",
      "\ttrain 12-37: Loss: 0.1277 Acc: 75.0000%\n",
      "\ttrain 12-38: Loss: 0.2684 Acc: 75.0000%\n",
      "\ttrain 12-39: Loss: 0.2558 Acc: 25.0000%\n",
      "\ttrain 12-40: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 12-41: Loss: 0.3361 Acc: 75.0000%\n",
      "\ttrain 12-42: Loss: 0.1279 Acc: 50.0000%\n",
      "\ttrain 12-43: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 12-44: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 12-45: Loss: 0.0780 Acc: 100.0000%\n",
      "\ttrain 12-46: Loss: 0.2094 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-47: Loss: 0.2823 Acc: 75.0000%\n",
      "\ttrain 12-48: Loss: 0.5275 Acc: 25.0000%\n",
      "\ttrain 12-49: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 12-50: Loss: 0.1110 Acc: 50.0000%\n",
      "\ttrain 12-51: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 12-52: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 12-53: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 12-54: Loss: 0.1791 Acc: 75.0000%\n",
      "\ttrain 12-55: Loss: 0.2648 Acc: 50.0000%\n",
      "\ttrain 12-56: Loss: 0.1533 Acc: 50.0000%\n",
      "\ttrain 12-57: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 12-58: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 12-59: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 12-60: Loss: 0.1073 Acc: 100.0000%\n",
      "\ttrain 12-61: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 12-62: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 12-63: Loss: 0.4646 Acc: 25.0000%\n",
      "\ttrain 12-64: Loss: 0.1918 Acc: 50.0000%\n",
      "\ttrain 12-65: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 12-66: Loss: 0.5098 Acc: 0.0000%\n",
      "\ttrain 12-67: Loss: 0.3618 Acc: 50.0000%\n",
      "\ttrain 12-68: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 12-69: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 12-70: Loss: 0.5481 Acc: 0.0000%\n",
      "\ttrain 12-71: Loss: 0.2027 Acc: 50.0000%\n",
      "\ttrain 12-72: Loss: 0.1672 Acc: 50.0000%\n",
      "\ttrain 12-73: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 12-74: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 12-75: Loss: 0.2852 Acc: 25.0000%\n",
      "\ttrain 12-76: Loss: 0.3633 Acc: 25.0000%\n",
      "\ttrain 12-77: Loss: 0.2130 Acc: 75.0000%\n",
      "\ttrain 12-78: Loss: 0.1445 Acc: 75.0000%\n",
      "\ttrain 12-79: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 12-80: Loss: 0.1853 Acc: 50.0000%\n",
      "\ttrain 12-81: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 12-82: Loss: 0.0786 Acc: 100.0000%\n",
      "\ttrain 12-83: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 12-84: Loss: 0.0909 Acc: 100.0000%\n",
      "\ttrain 12-85: Loss: 0.3360 Acc: 25.0000%\n",
      "\ttrain 12-86: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 12-87: Loss: 0.2367 Acc: 50.0000%\n",
      "\ttrain 12-88: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 12-89: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 12-90: Loss: 0.2916 Acc: 50.0000%\n",
      "\ttrain 12-91: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 12-92: Loss: 0.5322 Acc: 50.0000%\n",
      "\ttrain 12-93: Loss: 0.0787 Acc: 100.0000%\n",
      "\ttrain 12-94: Loss: 0.1243 Acc: 50.0000%\n",
      "\ttrain 12-95: Loss: 0.3863 Acc: 50.0000%\n",
      "\ttrain 12-96: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 12-97: Loss: 0.2165 Acc: 25.0000%\n",
      "\ttrain 12-98: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 12-99: Loss: 0.3273 Acc: 25.0000%\n",
      "\ttrain 12-100: Loss: 0.1780 Acc: 75.0000%\n",
      "\ttrain 12-101: Loss: 0.1044 Acc: 100.0000%\n",
      "\ttrain 12-102: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 12-103: Loss: 0.2110 Acc: 50.0000%\n",
      "\ttrain 12-104: Loss: 0.2953 Acc: 25.0000%\n",
      "\ttrain 12-105: Loss: 0.2052 Acc: 50.0000%\n",
      "\ttrain 12-106: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 12-107: Loss: 0.2887 Acc: 50.0000%\n",
      "\ttrain 12-108: Loss: 0.1110 Acc: 100.0000%\n",
      "\ttrain 12-109: Loss: 0.1910 Acc: 50.0000%\n",
      "\ttrain 12-110: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 12-111: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 12-112: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 12-113: Loss: 0.1952 Acc: 50.0000%\n",
      "\ttrain 12-114: Loss: 0.1659 Acc: 50.0000%\n",
      "\ttrain 12-115: Loss: 0.0834 Acc: 100.0000%\n",
      "\ttrain 12-116: Loss: 0.1145 Acc: 100.0000%\n",
      "\ttrain 12-117: Loss: 0.1222 Acc: 50.0000%\n",
      "\ttrain 12-118: Loss: 0.0671 Acc: 100.0000%\n",
      "\ttrain 12-119: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 12-120: Loss: 0.3101 Acc: 50.0000%\n",
      "\ttrain 12-121: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 12-122: Loss: 0.2232 Acc: 50.0000%\n",
      "\ttrain 12-123: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 12-124: Loss: 0.1483 Acc: 50.0000%\n",
      "\ttrain 12-125: Loss: 0.3265 Acc: 50.0000%\n",
      "\ttrain 12-126: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 12-127: Loss: 0.4100 Acc: 0.0000%\n",
      "\ttrain 12-128: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 12-129: Loss: 0.2279 Acc: 75.0000%\n",
      "\ttrain 12-130: Loss: 0.2248 Acc: 75.0000%\n",
      "\ttrain 12-131: Loss: 0.1887 Acc: 50.0000%\n",
      "\ttrain 12-132: Loss: 0.2013 Acc: 75.0000%\n",
      "\ttrain 12-133: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 12-134: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 12-135: Loss: 0.4105 Acc: 50.0000%\n",
      "\ttrain 12-136: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 12-137: Loss: 0.0931 Acc: 100.0000%\n",
      "\ttrain 12-138: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 12-139: Loss: 0.3760 Acc: 75.0000%\n",
      "\ttrain 12-140: Loss: 0.2875 Acc: 75.0000%\n",
      "\ttrain 12-141: Loss: 0.2416 Acc: 75.0000%\n",
      "\ttrain 12-142: Loss: 0.2090 Acc: 50.0000%\n",
      "\ttrain 12-143: Loss: 0.3605 Acc: 75.0000%\n",
      "\ttrain 12-144: Loss: 0.4677 Acc: 50.0000%\n",
      "\ttrain 12-145: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 12-146: Loss: 0.2974 Acc: 25.0000%\n",
      "\ttrain 12-147: Loss: 0.1879 Acc: 75.0000%\n",
      "\ttrain 12-148: Loss: 0.1868 Acc: 75.0000%\n",
      "\ttrain 12-149: Loss: 0.1897 Acc: 50.0000%\n",
      "\ttrain 12-150: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 12-151: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 12-152: Loss: 0.2528 Acc: 50.0000%\n",
      "\ttrain 12-153: Loss: 0.3884 Acc: 25.0000%\n",
      "\ttrain 12-154: Loss: 0.5134 Acc: 50.0000%\n",
      "\ttrain 12-155: Loss: 0.2669 Acc: 25.0000%\n",
      "\ttrain 12-156: Loss: 0.1904 Acc: 50.0000%\n",
      "\ttrain 12-157: Loss: 0.2069 Acc: 75.0000%\n",
      "\ttrain 12-158: Loss: 0.2284 Acc: 50.0000%\n",
      "\ttrain 12-159: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 12-160: Loss: 0.1556 Acc: 50.0000%\n",
      "\ttrain 12-161: Loss: 0.1698 Acc: 75.0000%\n",
      "\ttrain 12-162: Loss: 0.1618 Acc: 75.0000%\n",
      "\ttrain 12-163: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 12-164: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 12-165: Loss: 0.1408 Acc: 75.0000%\n",
      "\ttrain 12-166: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 12-167: Loss: 0.4466 Acc: 50.0000%\n",
      "\ttrain 12-168: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 12-169: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 12-170: Loss: 0.3275 Acc: 50.0000%\n",
      "\ttrain 12-171: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 12-172: Loss: 0.3169 Acc: 75.0000%\n",
      "\ttrain 12-173: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 12-174: Loss: 0.1609 Acc: 50.0000%\n",
      "\ttrain 12-175: Loss: 0.0555 Acc: 100.0000%\n",
      "\ttrain 12-176: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 12-177: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 12-178: Loss: 0.1914 Acc: 50.0000%\n",
      "\ttrain 12-179: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 12-180: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 12-181: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 12-182: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 12-183: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 12-184: Loss: 0.1672 Acc: 50.0000%\n",
      "\ttrain 12-185: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 12-186: Loss: 0.1551 Acc: 50.0000%\n",
      "\ttrain 12-187: Loss: 0.1874 Acc: 50.0000%\n",
      "\ttrain 12-188: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 12-189: Loss: 0.1241 Acc: 50.0000%\n",
      "\ttrain 12-190: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 12-191: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 12-192: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 12-193: Loss: 0.2287 Acc: 50.0000%\n",
      "\ttrain 12-194: Loss: 0.3148 Acc: 50.0000%\n",
      "\ttrain 12-195: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 12-196: Loss: 0.4972 Acc: 75.0000%\n",
      "\ttrain 12-197: Loss: 0.0959 Acc: 100.0000%\n",
      "\ttrain 12-198: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 12-199: Loss: 0.1986 Acc: 50.0000%\n",
      "\ttrain 12-200: Loss: 0.2091 Acc: 25.0000%\n",
      "\ttrain 12-201: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 12-202: Loss: 0.2332 Acc: 50.0000%\n",
      "\ttrain 12-203: Loss: 0.1408 Acc: 75.0000%\n",
      "\ttrain 12-204: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 12-205: Loss: 0.6094 Acc: 0.0000%\n",
      "\ttrain 12-206: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 12-207: Loss: 0.1690 Acc: 75.0000%\n",
      "\ttrain 12-208: Loss: 0.1188 Acc: 75.0000%\n",
      "\ttrain 12-209: Loss: 0.0861 Acc: 100.0000%\n",
      "\ttrain 12-210: Loss: 0.1306 Acc: 75.0000%\n",
      "\ttrain 12-211: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 12-212: Loss: 0.1139 Acc: 100.0000%\n",
      "\ttrain 12-213: Loss: 0.3245 Acc: 25.0000%\n",
      "\ttrain 12-214: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 12-215: Loss: 0.9358 Acc: 0.0000%\n",
      "\ttrain 12-216: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 12-217: Loss: 0.9787 Acc: 0.0000%\n",
      "\ttrain 12-218: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 12-219: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 12-220: Loss: 0.1732 Acc: 50.0000%\n",
      "\ttrain 12-221: Loss: 0.2832 Acc: 50.0000%\n",
      "\ttrain 12-222: Loss: 0.1035 Acc: 50.0000%\n",
      "\ttrain 12-223: Loss: 0.0820 Acc: 100.0000%\n",
      "\ttrain 12-224: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 12-225: Loss: 0.4092 Acc: 50.0000%\n",
      "\ttrain 12-226: Loss: 0.4771 Acc: 25.0000%\n",
      "\ttrain 12-227: Loss: 0.4057 Acc: 25.0000%\n",
      "\ttrain 12-228: Loss: 0.5050 Acc: 0.0000%\n",
      "\ttrain 12-229: Loss: 0.2380 Acc: 50.0000%\n",
      "\ttrain 12-230: Loss: 0.2033 Acc: 75.0000%\n",
      "\ttrain 12-231: Loss: 0.2434 Acc: 50.0000%\n",
      "\ttrain 12-232: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 12-233: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 12-234: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 12-235: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 12-236: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 12-237: Loss: 0.1207 Acc: 100.0000%\n",
      "\ttrain 12-238: Loss: 0.1637 Acc: 50.0000%\n",
      "\ttrain 12-239: Loss: 0.0674 Acc: 100.0000%\n",
      "\ttrain 12-240: Loss: 0.1142 Acc: 100.0000%\n",
      "\ttrain 12-241: Loss: 0.2562 Acc: 50.0000%\n",
      "\ttrain 12-242: Loss: 0.2612 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-243: Loss: 0.1005 Acc: 50.0000%\n",
      "\ttrain 12-244: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 12-245: Loss: 0.1255 Acc: 100.0000%\n",
      "\tvalidation 12-1: Loss: 0.0578 Acc: 75.0000%\n",
      "\tvalidation 12-2: Loss: 0.0826 Acc: 100.0000%\n",
      "\tvalidation 12-3: Loss: 0.0693 Acc: 100.0000%\n",
      "\tvalidation 12-4: Loss: 0.4114 Acc: 75.0000%\n",
      "\tvalidation 12-5: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 12-6: Loss: 0.0898 Acc: 100.0000%\n",
      "\tvalidation 12-7: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 12-8: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 12-9: Loss: 1.5282 Acc: 75.0000%\n",
      "\tvalidation 12-10: Loss: 0.0876 Acc: 75.0000%\n",
      "\tvalidation 12-11: Loss: 0.0425 Acc: 100.0000%\n",
      "\tvalidation 12-12: Loss: 0.0799 Acc: 100.0000%\n",
      "\tvalidation 12-13: Loss: 0.4709 Acc: 75.0000%\n",
      "\tvalidation 12-14: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 12-15: Loss: 0.1300 Acc: 75.0000%\n",
      "\tvalidation 12-16: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 12-17: Loss: 0.0803 Acc: 75.0000%\n",
      "\tvalidation 12-18: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 12-19: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 12-20: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 12-21: Loss: 0.0775 Acc: 75.0000%\n",
      "\tvalidation 12-22: Loss: 0.2777 Acc: 25.0000%\n",
      "\tvalidation 12-23: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 12-24: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 12-25: Loss: 0.9788 Acc: 75.0000%\n",
      "\tvalidation 12-26: Loss: 0.1160 Acc: 100.0000%\n",
      "\tvalidation 12-27: Loss: 0.1207 Acc: 100.0000%\n",
      "\tvalidation 12-28: Loss: 0.0931 Acc: 100.0000%\n",
      "\tvalidation 12-29: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 12-30: Loss: 0.0830 Acc: 75.0000%\n",
      "\tvalidation 12-31: Loss: 0.1479 Acc: 75.0000%\n",
      "\tvalidation 12-32: Loss: 0.8828 Acc: 75.0000%\n",
      "\tvalidation 12-33: Loss: 0.0551 Acc: 100.0000%\n",
      "\tvalidation 12-34: Loss: 0.0835 Acc: 100.0000%\n",
      "\tvalidation 12-35: Loss: 0.0830 Acc: 100.0000%\n",
      "\tvalidation 12-36: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 12-37: Loss: 3.2023 Acc: 50.0000%\n",
      "\tvalidation 12-38: Loss: 0.1151 Acc: 75.0000%\n",
      "\tvalidation 12-39: Loss: 3.5153 Acc: 50.0000%\n",
      "\tvalidation 12-40: Loss: 0.0884 Acc: 100.0000%\n",
      "\tvalidation 12-41: Loss: 0.1535 Acc: 100.0000%\n",
      "\tvalidation 12-42: Loss: 0.1594 Acc: 25.0000%\n",
      "\tvalidation 12-43: Loss: 0.0649 Acc: 100.0000%\n",
      "\tvalidation 12-44: Loss: 0.0582 Acc: 75.0000%\n",
      "\tvalidation 12-45: Loss: 0.0844 Acc: 100.0000%\n",
      "\tvalidation 12-46: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 12-47: Loss: 0.2227 Acc: 75.0000%\n",
      "\tvalidation 12-48: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 12-49: Loss: 0.4198 Acc: 75.0000%\n",
      "\tvalidation 12-50: Loss: 0.1293 Acc: 100.0000%\n",
      "\tvalidation 12-51: Loss: 0.0834 Acc: 75.0000%\n",
      "\tvalidation 12-52: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 12-53: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 12-54: Loss: 3.8257 Acc: 50.0000%\n",
      "\tvalidation 12-55: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 12-56: Loss: 0.0890 Acc: 100.0000%\n",
      "\tvalidation 12-57: Loss: 0.1068 Acc: 100.0000%\n",
      "\tvalidation 12-58: Loss: 0.1105 Acc: 50.0000%\n",
      "\tvalidation 12-59: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 12-60: Loss: 0.0355 Acc: 100.0000%\n",
      "\tvalidation 12-61: Loss: 0.0453 Acc: 75.0000%\n",
      "\tvalidation 12-62: Loss: 0.8084 Acc: 75.0000%\n",
      "\tvalidation 12-63: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 12-64: Loss: 0.0817 Acc: 75.0000%\n",
      "\tvalidation 12-65: Loss: 0.1175 Acc: 75.0000%\n",
      "\tvalidation 12-66: Loss: 0.1065 Acc: 100.0000%\n",
      "\tvalidation 12-67: Loss: 0.0742 Acc: 100.0000%\n",
      "\tvalidation 12-68: Loss: 0.0801 Acc: 100.0000%\n",
      "\tvalidation 12-69: Loss: 0.1274 Acc: 50.0000%\n",
      "\tvalidation 12-70: Loss: 0.0625 Acc: 100.0000%\n",
      "\tvalidation 12-71: Loss: 0.0452 Acc: 75.0000%\n",
      "\tvalidation 12-72: Loss: 0.1214 Acc: 100.0000%\n",
      "\tvalidation 12-73: Loss: 0.0813 Acc: 75.0000%\n",
      "\tvalidation 12-74: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 12-75: Loss: 0.0760 Acc: 100.0000%\n",
      "\tvalidation 12-76: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 12-77: Loss: 0.0453 Acc: 100.0000%\n",
      "\tvalidation 12-78: Loss: 0.0659 Acc: 100.0000%\n",
      "\tvalidation 12-79: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 12-80: Loss: 0.2095 Acc: 75.0000%\n",
      "\tvalidation 12-81: Loss: 0.0778 Acc: 100.0000%\n",
      "\tvalidation 12-82: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 12-83: Loss: 0.0939 Acc: 100.0000%\n",
      "\tvalidation 12-84: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 12-85: Loss: 0.1106 Acc: 50.0000%\n",
      "\tvalidation 12-86: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 12-87: Loss: 0.0635 Acc: 100.0000%\n",
      "\tvalidation 12-88: Loss: 0.0431 Acc: 100.0000%\n",
      "\tvalidation 12-89: Loss: 0.1243 Acc: 75.0000%\n",
      "\tvalidation 12-90: Loss: 0.5640 Acc: 25.0000%\n",
      "\tvalidation 12-91: Loss: 0.1263 Acc: 75.0000%\n",
      "\tvalidation 12-92: Loss: 0.0537 Acc: 100.0000%\n",
      "\tvalidation 12-93: Loss: 0.1893 Acc: 75.0000%\n",
      "\tvalidation 12-94: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 12-95: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 12-96: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 12-97: Loss: 0.0718 Acc: 100.0000%\n",
      "\tvalidation 12-98: Loss: 0.0990 Acc: 100.0000%\n",
      "\tvalidation 12-99: Loss: 0.1316 Acc: 75.0000%\n",
      "\tvalidation 12-100: Loss: 0.2191 Acc: 50.0000%\n",
      "\tvalidation 12-101: Loss: 0.2019 Acc: 50.0000%\n",
      "\tvalidation 12-102: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 12-103: Loss: 1.4983 Acc: 25.0000%\n",
      "\tvalidation 12-104: Loss: 0.1639 Acc: 75.0000%\n",
      "\tvalidation 12-105: Loss: 0.3361 Acc: 50.0000%\n",
      "\ttrain Loss: 0.1920 Acc: 67.1429%\n",
      "\tvalidation Loss: 0.2486 Acc: 84.5238%\n",
      "网络参数更新\n",
      "Time passed 0h 7m 58s\n",
      "--------------------\n",
      "Epoch [13/40]:\n",
      "\ttrain 13-1: Loss: 0.3155 Acc: 50.0000%\n",
      "\ttrain 13-2: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 13-3: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 13-4: Loss: 0.1578 Acc: 75.0000%\n",
      "\ttrain 13-5: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 13-6: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 13-7: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 13-8: Loss: 0.2945 Acc: 25.0000%\n",
      "\ttrain 13-9: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 13-10: Loss: 0.2467 Acc: 25.0000%\n",
      "\ttrain 13-11: Loss: 0.1767 Acc: 75.0000%\n",
      "\ttrain 13-12: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 13-13: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 13-14: Loss: 0.2545 Acc: 50.0000%\n",
      "\ttrain 13-15: Loss: 0.1123 Acc: 50.0000%\n",
      "\ttrain 13-16: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 13-17: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 13-18: Loss: 0.1728 Acc: 50.0000%\n",
      "\ttrain 13-19: Loss: 0.1418 Acc: 75.0000%\n",
      "\ttrain 13-20: Loss: 0.0734 Acc: 100.0000%\n",
      "\ttrain 13-21: Loss: 0.2014 Acc: 50.0000%\n",
      "\ttrain 13-22: Loss: 0.2940 Acc: 50.0000%\n",
      "\ttrain 13-23: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 13-24: Loss: 0.3275 Acc: 50.0000%\n",
      "\ttrain 13-25: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 13-26: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 13-27: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 13-28: Loss: 0.2973 Acc: 50.0000%\n",
      "\ttrain 13-29: Loss: 0.2297 Acc: 75.0000%\n",
      "\ttrain 13-30: Loss: 0.2142 Acc: 50.0000%\n",
      "\ttrain 13-31: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 13-32: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 13-33: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 13-34: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 13-35: Loss: 0.1523 Acc: 75.0000%\n",
      "\ttrain 13-36: Loss: 0.1643 Acc: 50.0000%\n",
      "\ttrain 13-37: Loss: 0.4823 Acc: 50.0000%\n",
      "\ttrain 13-38: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 13-39: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 13-40: Loss: 0.2846 Acc: 75.0000%\n",
      "\ttrain 13-41: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 13-42: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 13-43: Loss: 0.4376 Acc: 25.0000%\n",
      "\ttrain 13-44: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 13-45: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 13-46: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 13-47: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 13-48: Loss: 0.2206 Acc: 75.0000%\n",
      "\ttrain 13-49: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 13-50: Loss: 0.5024 Acc: 25.0000%\n",
      "\ttrain 13-51: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 13-52: Loss: 0.1329 Acc: 75.0000%\n",
      "\ttrain 13-53: Loss: 0.2882 Acc: 25.0000%\n",
      "\ttrain 13-54: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 13-55: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 13-56: Loss: 0.1466 Acc: 50.0000%\n",
      "\ttrain 13-57: Loss: 0.3349 Acc: 0.0000%\n",
      "\ttrain 13-58: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 13-59: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 13-60: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 13-61: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 13-62: Loss: 0.4770 Acc: 50.0000%\n",
      "\ttrain 13-63: Loss: 0.2164 Acc: 50.0000%\n",
      "\ttrain 13-64: Loss: 0.1223 Acc: 50.0000%\n",
      "\ttrain 13-65: Loss: 0.1110 Acc: 75.0000%\n",
      "\ttrain 13-66: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 13-67: Loss: 0.1268 Acc: 75.0000%\n",
      "\ttrain 13-68: Loss: 0.1432 Acc: 75.0000%\n",
      "\ttrain 13-69: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 13-70: Loss: 0.1811 Acc: 50.0000%\n",
      "\ttrain 13-71: Loss: 0.1581 Acc: 75.0000%\n",
      "\ttrain 13-72: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 13-73: Loss: 0.2416 Acc: 50.0000%\n",
      "\ttrain 13-74: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 13-75: Loss: 0.2091 Acc: 50.0000%\n",
      "\ttrain 13-76: Loss: 0.2974 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-77: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 13-78: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 13-79: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 13-80: Loss: 0.2157 Acc: 50.0000%\n",
      "\ttrain 13-81: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 13-82: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 13-83: Loss: 0.2368 Acc: 50.0000%\n",
      "\ttrain 13-84: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 13-85: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 13-86: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 13-87: Loss: 0.2654 Acc: 50.0000%\n",
      "\ttrain 13-88: Loss: 0.2409 Acc: 75.0000%\n",
      "\ttrain 13-89: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 13-90: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 13-91: Loss: 0.4545 Acc: 25.0000%\n",
      "\ttrain 13-92: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 13-93: Loss: 0.1304 Acc: 100.0000%\n",
      "\ttrain 13-94: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 13-95: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 13-96: Loss: 0.2784 Acc: 25.0000%\n",
      "\ttrain 13-97: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 13-98: Loss: 0.2533 Acc: 50.0000%\n",
      "\ttrain 13-99: Loss: 0.2588 Acc: 50.0000%\n",
      "\ttrain 13-100: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 13-101: Loss: 0.1010 Acc: 100.0000%\n",
      "\ttrain 13-102: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 13-103: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 13-104: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 13-105: Loss: 0.2761 Acc: 25.0000%\n",
      "\ttrain 13-106: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 13-107: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 13-108: Loss: 0.4329 Acc: 50.0000%\n",
      "\ttrain 13-109: Loss: 0.2205 Acc: 50.0000%\n",
      "\ttrain 13-110: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 13-111: Loss: 0.0878 Acc: 100.0000%\n",
      "\ttrain 13-112: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 13-113: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 13-114: Loss: 0.2484 Acc: 25.0000%\n",
      "\ttrain 13-115: Loss: 0.3607 Acc: 50.0000%\n",
      "\ttrain 13-116: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 13-117: Loss: 0.1979 Acc: 50.0000%\n",
      "\ttrain 13-118: Loss: 0.0671 Acc: 75.0000%\n",
      "\ttrain 13-119: Loss: 0.1235 Acc: 75.0000%\n",
      "\ttrain 13-120: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 13-121: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 13-122: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 13-123: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 13-124: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 13-125: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 13-126: Loss: 0.3401 Acc: 75.0000%\n",
      "\ttrain 13-127: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 13-128: Loss: 0.2218 Acc: 25.0000%\n",
      "\ttrain 13-129: Loss: 0.1285 Acc: 100.0000%\n",
      "\ttrain 13-130: Loss: 0.2189 Acc: 25.0000%\n",
      "\ttrain 13-131: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 13-132: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 13-133: Loss: 0.0859 Acc: 100.0000%\n",
      "\ttrain 13-134: Loss: 0.4183 Acc: 50.0000%\n",
      "\ttrain 13-135: Loss: 0.3712 Acc: 25.0000%\n",
      "\ttrain 13-136: Loss: 0.4521 Acc: 50.0000%\n",
      "\ttrain 13-137: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 13-138: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 13-139: Loss: 0.1488 Acc: 75.0000%\n",
      "\ttrain 13-140: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 13-141: Loss: 0.1536 Acc: 75.0000%\n",
      "\ttrain 13-142: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 13-143: Loss: 0.1355 Acc: 75.0000%\n",
      "\ttrain 13-144: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 13-145: Loss: 0.3670 Acc: 0.0000%\n",
      "\ttrain 13-146: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 13-147: Loss: 0.1350 Acc: 75.0000%\n",
      "\ttrain 13-148: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 13-149: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 13-150: Loss: 0.2155 Acc: 75.0000%\n",
      "\ttrain 13-151: Loss: 0.2213 Acc: 50.0000%\n",
      "\ttrain 13-152: Loss: 0.1627 Acc: 75.0000%\n",
      "\ttrain 13-153: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 13-154: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 13-155: Loss: 0.3045 Acc: 50.0000%\n",
      "\ttrain 13-156: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 13-157: Loss: 0.3820 Acc: 25.0000%\n",
      "\ttrain 13-158: Loss: 0.2168 Acc: 75.0000%\n",
      "\ttrain 13-159: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 13-160: Loss: 0.2069 Acc: 25.0000%\n",
      "\ttrain 13-161: Loss: 0.3694 Acc: 50.0000%\n",
      "\ttrain 13-162: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 13-163: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 13-164: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 13-165: Loss: 0.1625 Acc: 50.0000%\n",
      "\ttrain 13-166: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 13-167: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 13-168: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 13-169: Loss: 0.2473 Acc: 25.0000%\n",
      "\ttrain 13-170: Loss: 0.4838 Acc: 50.0000%\n",
      "\ttrain 13-171: Loss: 0.2010 Acc: 75.0000%\n",
      "\ttrain 13-172: Loss: 0.1031 Acc: 100.0000%\n",
      "\ttrain 13-173: Loss: 0.0863 Acc: 100.0000%\n",
      "\ttrain 13-174: Loss: 0.2362 Acc: 50.0000%\n",
      "\ttrain 13-175: Loss: 0.2154 Acc: 50.0000%\n",
      "\ttrain 13-176: Loss: 0.1679 Acc: 50.0000%\n",
      "\ttrain 13-177: Loss: 0.1632 Acc: 50.0000%\n",
      "\ttrain 13-178: Loss: 0.1056 Acc: 100.0000%\n",
      "\ttrain 13-179: Loss: 0.2115 Acc: 50.0000%\n",
      "\ttrain 13-180: Loss: 0.2910 Acc: 50.0000%\n",
      "\ttrain 13-181: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 13-182: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 13-183: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 13-184: Loss: 0.3492 Acc: 25.0000%\n",
      "\ttrain 13-185: Loss: 0.0952 Acc: 100.0000%\n",
      "\ttrain 13-186: Loss: 0.1742 Acc: 75.0000%\n",
      "\ttrain 13-187: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 13-188: Loss: 0.2842 Acc: 75.0000%\n",
      "\ttrain 13-189: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 13-190: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 13-191: Loss: 0.2527 Acc: 50.0000%\n",
      "\ttrain 13-192: Loss: 0.2135 Acc: 50.0000%\n",
      "\ttrain 13-193: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 13-194: Loss: 0.1792 Acc: 75.0000%\n",
      "\ttrain 13-195: Loss: 0.1357 Acc: 75.0000%\n",
      "\ttrain 13-196: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 13-197: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 13-198: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 13-199: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 13-200: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 13-201: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 13-202: Loss: 0.3852 Acc: 25.0000%\n",
      "\ttrain 13-203: Loss: 0.1834 Acc: 50.0000%\n",
      "\ttrain 13-204: Loss: 0.2486 Acc: 75.0000%\n",
      "\ttrain 13-205: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 13-206: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 13-207: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 13-208: Loss: 0.2744 Acc: 50.0000%\n",
      "\ttrain 13-209: Loss: 0.3054 Acc: 0.0000%\n",
      "\ttrain 13-210: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 13-211: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 13-212: Loss: 0.1123 Acc: 100.0000%\n",
      "\ttrain 13-213: Loss: 0.2934 Acc: 50.0000%\n",
      "\ttrain 13-214: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 13-215: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 13-216: Loss: 0.0769 Acc: 100.0000%\n",
      "\ttrain 13-217: Loss: 0.2848 Acc: 50.0000%\n",
      "\ttrain 13-218: Loss: 0.1199 Acc: 50.0000%\n",
      "\ttrain 13-219: Loss: 0.2133 Acc: 50.0000%\n",
      "\ttrain 13-220: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 13-221: Loss: 0.2303 Acc: 25.0000%\n",
      "\ttrain 13-222: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 13-223: Loss: 0.1765 Acc: 25.0000%\n",
      "\ttrain 13-224: Loss: 0.4868 Acc: 25.0000%\n",
      "\ttrain 13-225: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 13-226: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 13-227: Loss: 0.1845 Acc: 75.0000%\n",
      "\ttrain 13-228: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 13-229: Loss: 0.2083 Acc: 50.0000%\n",
      "\ttrain 13-230: Loss: 0.1164 Acc: 50.0000%\n",
      "\ttrain 13-231: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 13-232: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 13-233: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 13-234: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 13-235: Loss: 0.3452 Acc: 50.0000%\n",
      "\ttrain 13-236: Loss: 0.1119 Acc: 75.0000%\n",
      "\ttrain 13-237: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 13-238: Loss: 0.1410 Acc: 50.0000%\n",
      "\ttrain 13-239: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 13-240: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 13-241: Loss: 0.2351 Acc: 50.0000%\n",
      "\ttrain 13-242: Loss: 0.1426 Acc: 75.0000%\n",
      "\ttrain 13-243: Loss: 0.1912 Acc: 75.0000%\n",
      "\ttrain 13-244: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 13-245: Loss: 0.1622 Acc: 75.0000%\n",
      "\tvalidation 13-1: Loss: 0.9195 Acc: 75.0000%\n",
      "\tvalidation 13-2: Loss: 0.1416 Acc: 50.0000%\n",
      "\tvalidation 13-3: Loss: 0.2481 Acc: 50.0000%\n",
      "\tvalidation 13-4: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 13-5: Loss: 0.0973 Acc: 75.0000%\n",
      "\tvalidation 13-6: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 13-7: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 13-8: Loss: 0.7835 Acc: 50.0000%\n",
      "\tvalidation 13-9: Loss: 0.1180 Acc: 75.0000%\n",
      "\tvalidation 13-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-11: Loss: 0.2520 Acc: 50.0000%\n",
      "\tvalidation 13-12: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 13-13: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 13-14: Loss: 2.6219 Acc: 75.0000%\n",
      "\tvalidation 13-15: Loss: 0.0582 Acc: 75.0000%\n",
      "\tvalidation 13-16: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 13-17: Loss: 0.2196 Acc: 50.0000%\n",
      "\tvalidation 13-18: Loss: 0.0763 Acc: 75.0000%\n",
      "\tvalidation 13-19: Loss: 0.0678 Acc: 75.0000%\n",
      "\tvalidation 13-20: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 13-21: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 13-22: Loss: 0.1292 Acc: 50.0000%\n",
      "\tvalidation 13-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-24: Loss: 0.1528 Acc: 50.0000%\n",
      "\tvalidation 13-25: Loss: 0.0557 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 13-26: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-27: Loss: 0.3758 Acc: 25.0000%\n",
      "\tvalidation 13-28: Loss: 0.0529 Acc: 100.0000%\n",
      "\tvalidation 13-29: Loss: 0.2780 Acc: 50.0000%\n",
      "\tvalidation 13-30: Loss: 0.1119 Acc: 75.0000%\n",
      "\tvalidation 13-31: Loss: 0.1280 Acc: 75.0000%\n",
      "\tvalidation 13-32: Loss: 0.0384 Acc: 100.0000%\n",
      "\tvalidation 13-33: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 13-34: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 13-35: Loss: 0.0618 Acc: 100.0000%\n",
      "\tvalidation 13-36: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 13-37: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 13-38: Loss: 0.0678 Acc: 75.0000%\n",
      "\tvalidation 13-39: Loss: 0.4372 Acc: 50.0000%\n",
      "\tvalidation 13-40: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 13-41: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 13-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 13-43: Loss: 0.1166 Acc: 75.0000%\n",
      "\tvalidation 13-44: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 13-45: Loss: 0.5342 Acc: 50.0000%\n",
      "\tvalidation 13-46: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 13-47: Loss: 0.1545 Acc: 75.0000%\n",
      "\tvalidation 13-48: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 13-49: Loss: 0.1417 Acc: 75.0000%\n",
      "\tvalidation 13-50: Loss: 0.1676 Acc: 75.0000%\n",
      "\tvalidation 13-51: Loss: 0.0938 Acc: 75.0000%\n",
      "\tvalidation 13-52: Loss: 1.1724 Acc: 75.0000%\n",
      "\tvalidation 13-53: Loss: 0.1166 Acc: 75.0000%\n",
      "\tvalidation 13-54: Loss: 0.2701 Acc: 75.0000%\n",
      "\tvalidation 13-55: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 13-56: Loss: 0.1546 Acc: 50.0000%\n",
      "\tvalidation 13-57: Loss: 0.0487 Acc: 100.0000%\n",
      "\tvalidation 13-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-59: Loss: 0.0977 Acc: 75.0000%\n",
      "\tvalidation 13-60: Loss: 0.2372 Acc: 50.0000%\n",
      "\tvalidation 13-61: Loss: 0.3019 Acc: 75.0000%\n",
      "\tvalidation 13-62: Loss: 0.4316 Acc: 75.0000%\n",
      "\tvalidation 13-63: Loss: 0.7953 Acc: 50.0000%\n",
      "\tvalidation 13-64: Loss: 0.1362 Acc: 75.0000%\n",
      "\tvalidation 13-65: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 13-66: Loss: 0.8386 Acc: 50.0000%\n",
      "\tvalidation 13-67: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 13-68: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 13-69: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 13-70: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 13-71: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 13-72: Loss: 0.0578 Acc: 75.0000%\n",
      "\tvalidation 13-73: Loss: 0.1279 Acc: 75.0000%\n",
      "\tvalidation 13-74: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 13-75: Loss: 0.1153 Acc: 75.0000%\n",
      "\tvalidation 13-76: Loss: 0.2456 Acc: 25.0000%\n",
      "\tvalidation 13-77: Loss: 0.1333 Acc: 50.0000%\n",
      "\tvalidation 13-78: Loss: 0.1221 Acc: 50.0000%\n",
      "\tvalidation 13-79: Loss: 0.2189 Acc: 50.0000%\n",
      "\tvalidation 13-80: Loss: 0.3145 Acc: 50.0000%\n",
      "\tvalidation 13-81: Loss: 0.0355 Acc: 100.0000%\n",
      "\tvalidation 13-82: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 13-83: Loss: 0.1294 Acc: 75.0000%\n",
      "\tvalidation 13-84: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-85: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 13-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 13-87: Loss: 0.0649 Acc: 75.0000%\n",
      "\tvalidation 13-88: Loss: 0.1782 Acc: 50.0000%\n",
      "\tvalidation 13-89: Loss: 2.2624 Acc: 75.0000%\n",
      "\tvalidation 13-90: Loss: 0.1073 Acc: 75.0000%\n",
      "\tvalidation 13-91: Loss: 0.0832 Acc: 75.0000%\n",
      "\tvalidation 13-92: Loss: 0.8065 Acc: 75.0000%\n",
      "\tvalidation 13-93: Loss: 3.1068 Acc: 75.0000%\n",
      "\tvalidation 13-94: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 13-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 13-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 13-97: Loss: 0.4656 Acc: 50.0000%\n",
      "\tvalidation 13-98: Loss: 0.1002 Acc: 50.0000%\n",
      "\tvalidation 13-99: Loss: 0.1587 Acc: 50.0000%\n",
      "\tvalidation 13-100: Loss: 0.2881 Acc: 75.0000%\n",
      "\tvalidation 13-101: Loss: 0.1258 Acc: 75.0000%\n",
      "\tvalidation 13-102: Loss: 0.0725 Acc: 75.0000%\n",
      "\tvalidation 13-103: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 13-104: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 13-105: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1626 Acc: 70.0000%\n",
      "\tvalidation Loss: 0.2230 Acc: 78.8095%\n",
      "Time passed 0h 8m 37s\n",
      "--------------------\n",
      "Epoch [14/40]:\n",
      "\ttrain 14-1: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 14-2: Loss: 0.3936 Acc: 50.0000%\n",
      "\ttrain 14-3: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 14-4: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 14-5: Loss: 0.1803 Acc: 75.0000%\n",
      "\ttrain 14-6: Loss: 0.2752 Acc: 50.0000%\n",
      "\ttrain 14-7: Loss: 0.2644 Acc: 50.0000%\n",
      "\ttrain 14-8: Loss: 0.3691 Acc: 0.0000%\n",
      "\ttrain 14-9: Loss: 0.4158 Acc: 50.0000%\n",
      "\ttrain 14-10: Loss: 0.2194 Acc: 75.0000%\n",
      "\ttrain 14-11: Loss: 0.3149 Acc: 25.0000%\n",
      "\ttrain 14-12: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 14-13: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 14-14: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 14-15: Loss: 0.2855 Acc: 50.0000%\n",
      "\ttrain 14-16: Loss: 0.1893 Acc: 75.0000%\n",
      "\ttrain 14-17: Loss: 0.5393 Acc: 25.0000%\n",
      "\ttrain 14-18: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 14-19: Loss: 0.2633 Acc: 75.0000%\n",
      "\ttrain 14-20: Loss: 0.1873 Acc: 50.0000%\n",
      "\ttrain 14-21: Loss: 0.3135 Acc: 25.0000%\n",
      "\ttrain 14-22: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 14-23: Loss: 0.3698 Acc: 25.0000%\n",
      "\ttrain 14-24: Loss: 0.1200 Acc: 100.0000%\n",
      "\ttrain 14-25: Loss: 0.2223 Acc: 50.0000%\n",
      "\ttrain 14-26: Loss: 0.5555 Acc: 25.0000%\n",
      "\ttrain 14-27: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 14-28: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 14-29: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 14-30: Loss: 0.2352 Acc: 75.0000%\n",
      "\ttrain 14-31: Loss: 0.3958 Acc: 50.0000%\n",
      "\ttrain 14-32: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 14-33: Loss: 0.3597 Acc: 50.0000%\n",
      "\ttrain 14-34: Loss: 0.3099 Acc: 75.0000%\n",
      "\ttrain 14-35: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 14-36: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 14-37: Loss: 0.1722 Acc: 50.0000%\n",
      "\ttrain 14-38: Loss: 0.1837 Acc: 75.0000%\n",
      "\ttrain 14-39: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 14-40: Loss: 0.4229 Acc: 25.0000%\n",
      "\ttrain 14-41: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 14-42: Loss: 0.2479 Acc: 50.0000%\n",
      "\ttrain 14-43: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 14-44: Loss: 0.2245 Acc: 75.0000%\n",
      "\ttrain 14-45: Loss: 0.2010 Acc: 50.0000%\n",
      "\ttrain 14-46: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 14-47: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 14-48: Loss: 0.3779 Acc: 25.0000%\n",
      "\ttrain 14-49: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 14-50: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 14-51: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 14-52: Loss: 0.3289 Acc: 50.0000%\n",
      "\ttrain 14-53: Loss: 0.3551 Acc: 25.0000%\n",
      "\ttrain 14-54: Loss: 0.2685 Acc: 50.0000%\n",
      "\ttrain 14-55: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 14-56: Loss: 0.1101 Acc: 75.0000%\n",
      "\ttrain 14-57: Loss: 0.1798 Acc: 50.0000%\n",
      "\ttrain 14-58: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 14-59: Loss: 0.1029 Acc: 100.0000%\n",
      "\ttrain 14-60: Loss: 0.3149 Acc: 50.0000%\n",
      "\ttrain 14-61: Loss: 0.5270 Acc: 0.0000%\n",
      "\ttrain 14-62: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 14-63: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 14-64: Loss: 0.2289 Acc: 50.0000%\n",
      "\ttrain 14-65: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 14-66: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 14-67: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 14-68: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 14-69: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 14-70: Loss: 0.0967 Acc: 100.0000%\n",
      "\ttrain 14-71: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 14-72: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 14-73: Loss: 0.1042 Acc: 100.0000%\n",
      "\ttrain 14-74: Loss: 0.2000 Acc: 50.0000%\n",
      "\ttrain 14-75: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 14-76: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 14-77: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 14-78: Loss: 0.0831 Acc: 100.0000%\n",
      "\ttrain 14-79: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 14-80: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 14-81: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 14-82: Loss: 0.1332 Acc: 75.0000%\n",
      "\ttrain 14-83: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 14-84: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 14-85: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 14-86: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 14-87: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 14-88: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 14-89: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 14-90: Loss: 0.0759 Acc: 100.0000%\n",
      "\ttrain 14-91: Loss: 0.1225 Acc: 75.0000%\n",
      "\ttrain 14-92: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 14-93: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 14-94: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 14-95: Loss: 0.2447 Acc: 25.0000%\n",
      "\ttrain 14-96: Loss: 0.1861 Acc: 75.0000%\n",
      "\ttrain 14-97: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 14-98: Loss: 0.3069 Acc: 50.0000%\n",
      "\ttrain 14-99: Loss: 0.1009 Acc: 100.0000%\n",
      "\ttrain 14-100: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 14-101: Loss: 0.3310 Acc: 50.0000%\n",
      "\ttrain 14-102: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 14-103: Loss: 0.1743 Acc: 75.0000%\n",
      "\ttrain 14-104: Loss: 0.2725 Acc: 50.0000%\n",
      "\ttrain 14-105: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 14-106: Loss: 0.0997 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-107: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 14-108: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 14-109: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 14-110: Loss: 0.1706 Acc: 75.0000%\n",
      "\ttrain 14-111: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 14-112: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 14-113: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 14-114: Loss: 0.2969 Acc: 25.0000%\n",
      "\ttrain 14-115: Loss: 0.2512 Acc: 50.0000%\n",
      "\ttrain 14-116: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 14-117: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 14-118: Loss: 0.4671 Acc: 25.0000%\n",
      "\ttrain 14-119: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 14-120: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 14-121: Loss: 0.3889 Acc: 50.0000%\n",
      "\ttrain 14-122: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 14-123: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 14-124: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 14-125: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 14-126: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 14-127: Loss: 0.1794 Acc: 50.0000%\n",
      "\ttrain 14-128: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 14-129: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 14-130: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 14-131: Loss: 0.4536 Acc: 25.0000%\n",
      "\ttrain 14-132: Loss: 0.2500 Acc: 50.0000%\n",
      "\ttrain 14-133: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 14-134: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 14-135: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 14-136: Loss: 0.1620 Acc: 75.0000%\n",
      "\ttrain 14-137: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 14-138: Loss: 0.1113 Acc: 100.0000%\n",
      "\ttrain 14-139: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 14-140: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 14-141: Loss: 0.1473 Acc: 75.0000%\n",
      "\ttrain 14-142: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 14-143: Loss: 0.1105 Acc: 75.0000%\n",
      "\ttrain 14-144: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 14-145: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 14-146: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 14-147: Loss: 0.2170 Acc: 75.0000%\n",
      "\ttrain 14-148: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 14-149: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 14-150: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 14-151: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 14-152: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 14-153: Loss: 0.1999 Acc: 50.0000%\n",
      "\ttrain 14-154: Loss: 0.2274 Acc: 25.0000%\n",
      "\ttrain 14-155: Loss: 0.3055 Acc: 25.0000%\n",
      "\ttrain 14-156: Loss: 0.1959 Acc: 50.0000%\n",
      "\ttrain 14-157: Loss: 0.0600 Acc: 100.0000%\n",
      "\ttrain 14-158: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 14-159: Loss: 0.2719 Acc: 50.0000%\n",
      "\ttrain 14-160: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 14-161: Loss: 0.1397 Acc: 50.0000%\n",
      "\ttrain 14-162: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 14-163: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 14-164: Loss: 0.2637 Acc: 50.0000%\n",
      "\ttrain 14-165: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 14-166: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 14-167: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 14-168: Loss: 0.2063 Acc: 75.0000%\n",
      "\ttrain 14-169: Loss: 0.3683 Acc: 50.0000%\n",
      "\ttrain 14-170: Loss: 0.2187 Acc: 25.0000%\n",
      "\ttrain 14-171: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 14-172: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 14-173: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 14-174: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 14-175: Loss: 0.3188 Acc: 50.0000%\n",
      "\ttrain 14-176: Loss: 0.2171 Acc: 50.0000%\n",
      "\ttrain 14-177: Loss: 0.2414 Acc: 75.0000%\n",
      "\ttrain 14-178: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 14-179: Loss: 0.1928 Acc: 75.0000%\n",
      "\ttrain 14-180: Loss: 0.1460 Acc: 50.0000%\n",
      "\ttrain 14-181: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 14-182: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 14-183: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 14-184: Loss: 0.2036 Acc: 75.0000%\n",
      "\ttrain 14-185: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 14-186: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 14-187: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 14-188: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 14-189: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 14-190: Loss: 0.1809 Acc: 50.0000%\n",
      "\ttrain 14-191: Loss: 0.1785 Acc: 75.0000%\n",
      "\ttrain 14-192: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 14-193: Loss: 0.2339 Acc: 25.0000%\n",
      "\ttrain 14-194: Loss: 0.2186 Acc: 75.0000%\n",
      "\ttrain 14-195: Loss: 0.5170 Acc: 25.0000%\n",
      "\ttrain 14-196: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 14-197: Loss: 0.1365 Acc: 50.0000%\n",
      "\ttrain 14-198: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 14-199: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 14-200: Loss: 0.2530 Acc: 25.0000%\n",
      "\ttrain 14-201: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 14-202: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 14-203: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 14-204: Loss: 0.1591 Acc: 75.0000%\n",
      "\ttrain 14-205: Loss: 0.3899 Acc: 25.0000%\n",
      "\ttrain 14-206: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 14-207: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 14-208: Loss: 0.1972 Acc: 75.0000%\n",
      "\ttrain 14-209: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 14-210: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 14-211: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 14-212: Loss: 0.2164 Acc: 75.0000%\n",
      "\ttrain 14-213: Loss: 0.2383 Acc: 25.0000%\n",
      "\ttrain 14-214: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 14-215: Loss: 0.1562 Acc: 75.0000%\n",
      "\ttrain 14-216: Loss: 0.3061 Acc: 50.0000%\n",
      "\ttrain 14-217: Loss: 0.2275 Acc: 50.0000%\n",
      "\ttrain 14-218: Loss: 0.1604 Acc: 75.0000%\n",
      "\ttrain 14-219: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 14-220: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 14-221: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 14-222: Loss: 0.0671 Acc: 75.0000%\n",
      "\ttrain 14-223: Loss: 0.1405 Acc: 50.0000%\n",
      "\ttrain 14-224: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 14-225: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 14-226: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 14-227: Loss: 0.1642 Acc: 50.0000%\n",
      "\ttrain 14-228: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 14-229: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 14-230: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 14-231: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 14-232: Loss: 0.5619 Acc: 50.0000%\n",
      "\ttrain 14-233: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 14-234: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 14-235: Loss: 0.1738 Acc: 50.0000%\n",
      "\ttrain 14-236: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 14-237: Loss: 0.5798 Acc: 0.0000%\n",
      "\ttrain 14-238: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 14-239: Loss: 0.5386 Acc: 25.0000%\n",
      "\ttrain 14-240: Loss: 0.2544 Acc: 50.0000%\n",
      "\ttrain 14-241: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 14-242: Loss: 0.2532 Acc: 50.0000%\n",
      "\ttrain 14-243: Loss: 0.3704 Acc: 75.0000%\n",
      "\ttrain 14-244: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 14-245: Loss: 0.1958 Acc: 50.0000%\n",
      "\tvalidation 14-1: Loss: 0.1652 Acc: 75.0000%\n",
      "\tvalidation 14-2: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-3: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 14-4: Loss: 0.1297 Acc: 75.0000%\n",
      "\tvalidation 14-5: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 14-6: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 14-7: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 14-8: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 14-9: Loss: 0.6677 Acc: 50.0000%\n",
      "\tvalidation 14-10: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 14-11: Loss: 0.0681 Acc: 75.0000%\n",
      "\tvalidation 14-12: Loss: 0.0432 Acc: 100.0000%\n",
      "\tvalidation 14-13: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 14-14: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 14-15: Loss: 0.2666 Acc: 50.0000%\n",
      "\tvalidation 14-16: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 14-17: Loss: 0.1811 Acc: 50.0000%\n",
      "\tvalidation 14-18: Loss: 0.0851 Acc: 75.0000%\n",
      "\tvalidation 14-19: Loss: 0.0686 Acc: 100.0000%\n",
      "\tvalidation 14-20: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 14-21: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 14-22: Loss: 0.0465 Acc: 75.0000%\n",
      "\tvalidation 14-23: Loss: 0.2075 Acc: 75.0000%\n",
      "\tvalidation 14-24: Loss: 0.1768 Acc: 75.0000%\n",
      "\tvalidation 14-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 14-26: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 14-27: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 14-28: Loss: 0.1923 Acc: 75.0000%\n",
      "\tvalidation 14-29: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 14-30: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 14-31: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 14-32: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 14-33: Loss: 0.1265 Acc: 75.0000%\n",
      "\tvalidation 14-34: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 14-35: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 14-36: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 14-37: Loss: 0.2469 Acc: 75.0000%\n",
      "\tvalidation 14-38: Loss: 0.1859 Acc: 75.0000%\n",
      "\tvalidation 14-39: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 14-40: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 14-41: Loss: 0.0772 Acc: 75.0000%\n",
      "\tvalidation 14-42: Loss: 0.0777 Acc: 75.0000%\n",
      "\tvalidation 14-43: Loss: 0.0507 Acc: 100.0000%\n",
      "\tvalidation 14-44: Loss: 0.1129 Acc: 75.0000%\n",
      "\tvalidation 14-45: Loss: 0.2848 Acc: 50.0000%\n",
      "\tvalidation 14-46: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 14-47: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 14-48: Loss: 0.0654 Acc: 75.0000%\n",
      "\tvalidation 14-49: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 14-50: Loss: 0.1928 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 14-51: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 14-53: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 14-54: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 14-55: Loss: 0.0659 Acc: 75.0000%\n",
      "\tvalidation 14-56: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 14-57: Loss: 0.2256 Acc: 50.0000%\n",
      "\tvalidation 14-58: Loss: 0.6616 Acc: 50.0000%\n",
      "\tvalidation 14-59: Loss: 0.2825 Acc: 50.0000%\n",
      "\tvalidation 14-60: Loss: 0.2051 Acc: 75.0000%\n",
      "\tvalidation 14-61: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-62: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 14-63: Loss: 0.0892 Acc: 100.0000%\n",
      "\tvalidation 14-64: Loss: 0.1182 Acc: 50.0000%\n",
      "\tvalidation 14-65: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 14-66: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 14-67: Loss: 0.0317 Acc: 100.0000%\n",
      "\tvalidation 14-68: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 14-69: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 14-70: Loss: 0.0773 Acc: 75.0000%\n",
      "\tvalidation 14-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 14-72: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 14-73: Loss: 0.0706 Acc: 75.0000%\n",
      "\tvalidation 14-74: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 14-75: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 14-76: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 14-77: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 14-78: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 14-79: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 14-80: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 14-81: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 14-82: Loss: 0.1145 Acc: 75.0000%\n",
      "\tvalidation 14-83: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 14-84: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 14-85: Loss: 0.0688 Acc: 100.0000%\n",
      "\tvalidation 14-86: Loss: 0.3557 Acc: 50.0000%\n",
      "\tvalidation 14-87: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 14-88: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 14-89: Loss: 0.1051 Acc: 75.0000%\n",
      "\tvalidation 14-90: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 14-91: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 14-92: Loss: 0.0513 Acc: 100.0000%\n",
      "\tvalidation 14-93: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 14-94: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 14-95: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 14-96: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 14-97: Loss: 0.1613 Acc: 50.0000%\n",
      "\tvalidation 14-98: Loss: 0.0849 Acc: 75.0000%\n",
      "\tvalidation 14-99: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 14-100: Loss: 0.1242 Acc: 75.0000%\n",
      "\tvalidation 14-101: Loss: 0.0741 Acc: 75.0000%\n",
      "\tvalidation 14-102: Loss: 0.1882 Acc: 75.0000%\n",
      "\tvalidation 14-103: Loss: 0.1011 Acc: 75.0000%\n",
      "\tvalidation 14-104: Loss: 0.2329 Acc: 50.0000%\n",
      "\tvalidation 14-105: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1551 Acc: 73.0612%\n",
      "\tvalidation Loss: 0.0771 Acc: 87.8571%\n",
      "网络参数更新\n",
      "Time passed 0h 9m 19s\n",
      "--------------------\n",
      "Epoch [15/40]:\n",
      "\ttrain 15-1: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 15-2: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 15-3: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 15-4: Loss: 0.3819 Acc: 25.0000%\n",
      "\ttrain 15-5: Loss: 0.2237 Acc: 25.0000%\n",
      "\ttrain 15-6: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 15-7: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 15-8: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 15-9: Loss: 0.1606 Acc: 50.0000%\n",
      "\ttrain 15-10: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 15-11: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 15-12: Loss: 0.1679 Acc: 75.0000%\n",
      "\ttrain 15-13: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 15-14: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 15-15: Loss: 0.1406 Acc: 75.0000%\n",
      "\ttrain 15-16: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 15-17: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 15-18: Loss: 0.3316 Acc: 25.0000%\n",
      "\ttrain 15-19: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 15-20: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 15-21: Loss: 0.3464 Acc: 50.0000%\n",
      "\ttrain 15-22: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 15-23: Loss: 0.2307 Acc: 75.0000%\n",
      "\ttrain 15-24: Loss: 0.5296 Acc: 50.0000%\n",
      "\ttrain 15-25: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 15-26: Loss: 0.0527 Acc: 75.0000%\n",
      "\ttrain 15-27: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 15-28: Loss: 0.3540 Acc: 75.0000%\n",
      "\ttrain 15-29: Loss: 0.1075 Acc: 100.0000%\n",
      "\ttrain 15-30: Loss: 0.2780 Acc: 75.0000%\n",
      "\ttrain 15-31: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 15-32: Loss: 0.4279 Acc: 50.0000%\n",
      "\ttrain 15-33: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 15-34: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 15-35: Loss: 0.3748 Acc: 75.0000%\n",
      "\ttrain 15-36: Loss: 0.2069 Acc: 75.0000%\n",
      "\ttrain 15-37: Loss: 0.2265 Acc: 75.0000%\n",
      "\ttrain 15-38: Loss: 0.3121 Acc: 50.0000%\n",
      "\ttrain 15-39: Loss: 0.2550 Acc: 25.0000%\n",
      "\ttrain 15-40: Loss: 0.1788 Acc: 75.0000%\n",
      "\ttrain 15-41: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 15-42: Loss: 0.4977 Acc: 25.0000%\n",
      "\ttrain 15-43: Loss: 0.0960 Acc: 100.0000%\n",
      "\ttrain 15-44: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 15-45: Loss: 0.1437 Acc: 75.0000%\n",
      "\ttrain 15-46: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 15-47: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 15-48: Loss: 0.0774 Acc: 100.0000%\n",
      "\ttrain 15-49: Loss: 0.1470 Acc: 75.0000%\n",
      "\ttrain 15-50: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 15-51: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 15-52: Loss: 0.2330 Acc: 50.0000%\n",
      "\ttrain 15-53: Loss: 0.1864 Acc: 100.0000%\n",
      "\ttrain 15-54: Loss: 0.0801 Acc: 100.0000%\n",
      "\ttrain 15-55: Loss: 0.2787 Acc: 50.0000%\n",
      "\ttrain 15-56: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 15-57: Loss: 0.1649 Acc: 75.0000%\n",
      "\ttrain 15-58: Loss: 0.4395 Acc: 50.0000%\n",
      "\ttrain 15-59: Loss: 0.2049 Acc: 25.0000%\n",
      "\ttrain 15-60: Loss: 0.1347 Acc: 75.0000%\n",
      "\ttrain 15-61: Loss: 0.2186 Acc: 50.0000%\n",
      "\ttrain 15-62: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 15-63: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 15-64: Loss: 0.2992 Acc: 25.0000%\n",
      "\ttrain 15-65: Loss: 0.1782 Acc: 50.0000%\n",
      "\ttrain 15-66: Loss: 0.2153 Acc: 50.0000%\n",
      "\ttrain 15-67: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 15-68: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 15-69: Loss: 0.1925 Acc: 75.0000%\n",
      "\ttrain 15-70: Loss: 0.2077 Acc: 75.0000%\n",
      "\ttrain 15-71: Loss: 0.1953 Acc: 50.0000%\n",
      "\ttrain 15-72: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 15-73: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 15-74: Loss: 0.2722 Acc: 75.0000%\n",
      "\ttrain 15-75: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 15-76: Loss: 0.4954 Acc: 25.0000%\n",
      "\ttrain 15-77: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 15-78: Loss: 0.0734 Acc: 100.0000%\n",
      "\ttrain 15-79: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 15-80: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 15-81: Loss: 0.0809 Acc: 100.0000%\n",
      "\ttrain 15-82: Loss: 0.1920 Acc: 25.0000%\n",
      "\ttrain 15-83: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 15-84: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 15-85: Loss: 0.1011 Acc: 100.0000%\n",
      "\ttrain 15-86: Loss: 0.1068 Acc: 50.0000%\n",
      "\ttrain 15-87: Loss: 0.1611 Acc: 50.0000%\n",
      "\ttrain 15-88: Loss: 0.2142 Acc: 25.0000%\n",
      "\ttrain 15-89: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 15-90: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 15-91: Loss: 0.3656 Acc: 50.0000%\n",
      "\ttrain 15-92: Loss: 0.3128 Acc: 50.0000%\n",
      "\ttrain 15-93: Loss: 0.2279 Acc: 25.0000%\n",
      "\ttrain 15-94: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 15-95: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 15-96: Loss: 0.1499 Acc: 75.0000%\n",
      "\ttrain 15-97: Loss: 0.3040 Acc: 75.0000%\n",
      "\ttrain 15-98: Loss: 0.0898 Acc: 100.0000%\n",
      "\ttrain 15-99: Loss: 0.2202 Acc: 50.0000%\n",
      "\ttrain 15-100: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 15-101: Loss: 0.2071 Acc: 25.0000%\n",
      "\ttrain 15-102: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 15-103: Loss: 0.1594 Acc: 50.0000%\n",
      "\ttrain 15-104: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 15-105: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 15-106: Loss: 0.4363 Acc: 25.0000%\n",
      "\ttrain 15-107: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 15-108: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 15-109: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 15-110: Loss: 0.2609 Acc: 50.0000%\n",
      "\ttrain 15-111: Loss: 0.2727 Acc: 75.0000%\n",
      "\ttrain 15-112: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 15-113: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 15-114: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 15-115: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 15-116: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 15-117: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 15-118: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 15-119: Loss: 0.1396 Acc: 75.0000%\n",
      "\ttrain 15-120: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 15-121: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 15-122: Loss: 0.6290 Acc: 25.0000%\n",
      "\ttrain 15-123: Loss: 0.1580 Acc: 50.0000%\n",
      "\ttrain 15-124: Loss: 0.3670 Acc: 50.0000%\n",
      "\ttrain 15-125: Loss: 0.6617 Acc: 50.0000%\n",
      "\ttrain 15-126: Loss: 0.5790 Acc: 0.0000%\n",
      "\ttrain 15-127: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 15-128: Loss: 0.9830 Acc: 50.0000%\n",
      "\ttrain 15-129: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 15-130: Loss: 0.2617 Acc: 75.0000%\n",
      "\ttrain 15-131: Loss: 0.9658 Acc: 25.0000%\n",
      "\ttrain 15-132: Loss: 0.6801 Acc: 25.0000%\n",
      "\ttrain 15-133: Loss: 0.1744 Acc: 50.0000%\n",
      "\ttrain 15-134: Loss: 0.0835 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 15-135: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 15-136: Loss: 0.2616 Acc: 50.0000%\n",
      "\ttrain 15-137: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 15-138: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 15-139: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 15-140: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 15-141: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 15-142: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 15-143: Loss: 0.1768 Acc: 50.0000%\n",
      "\ttrain 15-144: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 15-145: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 15-146: Loss: 0.4018 Acc: 25.0000%\n",
      "\ttrain 15-147: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 15-148: Loss: 0.3586 Acc: 50.0000%\n",
      "\ttrain 15-149: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 15-150: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 15-151: Loss: 0.1718 Acc: 75.0000%\n",
      "\ttrain 15-152: Loss: 0.2262 Acc: 50.0000%\n",
      "\ttrain 15-153: Loss: 0.3935 Acc: 50.0000%\n",
      "\ttrain 15-154: Loss: 0.1292 Acc: 75.0000%\n",
      "\ttrain 15-155: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 15-156: Loss: 0.1131 Acc: 100.0000%\n",
      "\ttrain 15-157: Loss: 0.1882 Acc: 75.0000%\n",
      "\ttrain 15-158: Loss: 0.1930 Acc: 50.0000%\n",
      "\ttrain 15-159: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 15-160: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 15-161: Loss: 0.0579 Acc: 75.0000%\n",
      "\ttrain 15-162: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 15-163: Loss: 0.4229 Acc: 50.0000%\n",
      "\ttrain 15-164: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 15-165: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 15-166: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 15-167: Loss: 0.3054 Acc: 25.0000%\n",
      "\ttrain 15-168: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 15-169: Loss: 0.4776 Acc: 50.0000%\n",
      "\ttrain 15-170: Loss: 0.4190 Acc: 50.0000%\n",
      "\ttrain 15-171: Loss: 0.3516 Acc: 50.0000%\n",
      "\ttrain 15-172: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 15-173: Loss: 0.6246 Acc: 0.0000%\n",
      "\ttrain 15-174: Loss: 0.1775 Acc: 50.0000%\n",
      "\ttrain 15-175: Loss: 0.4273 Acc: 50.0000%\n",
      "\ttrain 15-176: Loss: 0.1375 Acc: 75.0000%\n",
      "\ttrain 15-177: Loss: 0.1984 Acc: 50.0000%\n",
      "\ttrain 15-178: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 15-179: Loss: 0.1121 Acc: 100.0000%\n",
      "\ttrain 15-180: Loss: 0.4635 Acc: 50.0000%\n",
      "\ttrain 15-181: Loss: 0.6048 Acc: 0.0000%\n",
      "\ttrain 15-182: Loss: 0.5426 Acc: 0.0000%\n",
      "\ttrain 15-183: Loss: 0.0780 Acc: 75.0000%\n",
      "\ttrain 15-184: Loss: 0.3107 Acc: 50.0000%\n",
      "\ttrain 15-185: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 15-186: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 15-187: Loss: 0.2310 Acc: 75.0000%\n",
      "\ttrain 15-188: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 15-189: Loss: 0.3977 Acc: 25.0000%\n",
      "\ttrain 15-190: Loss: 0.3485 Acc: 50.0000%\n",
      "\ttrain 15-191: Loss: 0.1566 Acc: 75.0000%\n",
      "\ttrain 15-192: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 15-193: Loss: 0.2513 Acc: 50.0000%\n",
      "\ttrain 15-194: Loss: 0.1526 Acc: 50.0000%\n",
      "\ttrain 15-195: Loss: 0.1822 Acc: 50.0000%\n",
      "\ttrain 15-196: Loss: 0.2818 Acc: 50.0000%\n",
      "\ttrain 15-197: Loss: 0.0899 Acc: 100.0000%\n",
      "\ttrain 15-198: Loss: 0.3672 Acc: 50.0000%\n",
      "\ttrain 15-199: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 15-200: Loss: 0.2062 Acc: 75.0000%\n",
      "\ttrain 15-201: Loss: 0.1727 Acc: 50.0000%\n",
      "\ttrain 15-202: Loss: 0.2654 Acc: 50.0000%\n",
      "\ttrain 15-203: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 15-204: Loss: 0.0761 Acc: 100.0000%\n",
      "\ttrain 15-205: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 15-206: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 15-207: Loss: 0.3016 Acc: 75.0000%\n",
      "\ttrain 15-208: Loss: 0.2016 Acc: 75.0000%\n",
      "\ttrain 15-209: Loss: 0.2690 Acc: 75.0000%\n",
      "\ttrain 15-210: Loss: 0.2508 Acc: 50.0000%\n",
      "\ttrain 15-211: Loss: 0.1645 Acc: 75.0000%\n",
      "\ttrain 15-212: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 15-213: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 15-214: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 15-215: Loss: 0.1636 Acc: 50.0000%\n",
      "\ttrain 15-216: Loss: 0.3963 Acc: 25.0000%\n",
      "\ttrain 15-217: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 15-218: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 15-219: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 15-220: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 15-221: Loss: 0.2592 Acc: 50.0000%\n",
      "\ttrain 15-222: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 15-223: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 15-224: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 15-225: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 15-226: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 15-227: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 15-228: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 15-229: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 15-230: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 15-231: Loss: 0.3412 Acc: 25.0000%\n",
      "\ttrain 15-232: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 15-233: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 15-234: Loss: 0.0889 Acc: 100.0000%\n",
      "\ttrain 15-235: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 15-236: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 15-237: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 15-238: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 15-239: Loss: 0.2854 Acc: 75.0000%\n",
      "\ttrain 15-240: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 15-241: Loss: 0.1890 Acc: 50.0000%\n",
      "\ttrain 15-242: Loss: 0.2852 Acc: 50.0000%\n",
      "\ttrain 15-243: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 15-244: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 15-245: Loss: 0.1563 Acc: 75.0000%\n",
      "\tvalidation 15-1: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 15-2: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 15-3: Loss: 0.0761 Acc: 75.0000%\n",
      "\tvalidation 15-4: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 15-5: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 15-6: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 15-7: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 15-8: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 15-9: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 15-10: Loss: 0.0703 Acc: 100.0000%\n",
      "\tvalidation 15-11: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 15-12: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 15-13: Loss: 0.0460 Acc: 100.0000%\n",
      "\tvalidation 15-14: Loss: 0.0398 Acc: 100.0000%\n",
      "\tvalidation 15-15: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 15-16: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 15-17: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 15-18: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 15-19: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 15-20: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 15-21: Loss: 0.0407 Acc: 100.0000%\n",
      "\tvalidation 15-22: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 15-23: Loss: 0.0633 Acc: 75.0000%\n",
      "\tvalidation 15-24: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 15-25: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 15-26: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 15-27: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 15-28: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 15-29: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 15-30: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 15-31: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 15-32: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 15-33: Loss: 0.1076 Acc: 75.0000%\n",
      "\tvalidation 15-34: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 15-35: Loss: 0.0549 Acc: 100.0000%\n",
      "\tvalidation 15-36: Loss: 0.0987 Acc: 75.0000%\n",
      "\tvalidation 15-37: Loss: 0.1805 Acc: 75.0000%\n",
      "\tvalidation 15-38: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 15-39: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 15-40: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 15-41: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 15-42: Loss: 0.0495 Acc: 100.0000%\n",
      "\tvalidation 15-43: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 15-44: Loss: 0.0560 Acc: 100.0000%\n",
      "\tvalidation 15-45: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 15-46: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 15-47: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 15-48: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 15-49: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 15-50: Loss: 0.0659 Acc: 75.0000%\n",
      "\tvalidation 15-51: Loss: 0.1256 Acc: 75.0000%\n",
      "\tvalidation 15-52: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 15-53: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 15-54: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 15-55: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 15-56: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 15-57: Loss: 0.2590 Acc: 75.0000%\n",
      "\tvalidation 15-58: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 15-59: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 15-60: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 15-61: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 15-62: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 15-63: Loss: 0.1818 Acc: 75.0000%\n",
      "\tvalidation 15-64: Loss: 0.0714 Acc: 75.0000%\n",
      "\tvalidation 15-65: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 15-66: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 15-67: Loss: 0.1204 Acc: 75.0000%\n",
      "\tvalidation 15-68: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 15-69: Loss: 0.0488 Acc: 100.0000%\n",
      "\tvalidation 15-70: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 15-71: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 15-72: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 15-73: Loss: 0.0477 Acc: 75.0000%\n",
      "\tvalidation 15-74: Loss: 0.0696 Acc: 75.0000%\n",
      "\tvalidation 15-75: Loss: 0.0369 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 15-76: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 15-77: Loss: 0.0436 Acc: 100.0000%\n",
      "\tvalidation 15-78: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 15-79: Loss: 0.1056 Acc: 50.0000%\n",
      "\tvalidation 15-80: Loss: 0.0843 Acc: 75.0000%\n",
      "\tvalidation 15-81: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 15-82: Loss: 0.0995 Acc: 75.0000%\n",
      "\tvalidation 15-83: Loss: 0.0527 Acc: 75.0000%\n",
      "\tvalidation 15-84: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 15-85: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 15-86: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 15-87: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 15-88: Loss: 0.0866 Acc: 75.0000%\n",
      "\tvalidation 15-89: Loss: 0.2908 Acc: 75.0000%\n",
      "\tvalidation 15-90: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 15-91: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 15-92: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 15-93: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 15-94: Loss: 0.0759 Acc: 75.0000%\n",
      "\tvalidation 15-95: Loss: 0.1128 Acc: 75.0000%\n",
      "\tvalidation 15-96: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 15-97: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 15-98: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 15-99: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 15-100: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 15-101: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 15-102: Loss: 0.0878 Acc: 75.0000%\n",
      "\tvalidation 15-103: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 15-104: Loss: 0.1198 Acc: 75.0000%\n",
      "\tvalidation 15-105: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1770 Acc: 72.3469%\n",
      "\tvalidation Loss: 0.0410 Acc: 93.5714%\n",
      "网络参数更新\n",
      "Time passed 0h 9m 59s\n",
      "--------------------\n",
      "Epoch [16/40]:\n",
      "\ttrain 16-1: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 16-2: Loss: 0.1977 Acc: 75.0000%\n",
      "\ttrain 16-3: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 16-4: Loss: 0.2360 Acc: 75.0000%\n",
      "\ttrain 16-5: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 16-6: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 16-7: Loss: 0.1983 Acc: 50.0000%\n",
      "\ttrain 16-8: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 16-9: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 16-10: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 16-11: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 16-12: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 16-13: Loss: 0.4153 Acc: 0.0000%\n",
      "\ttrain 16-14: Loss: 0.2233 Acc: 75.0000%\n",
      "\ttrain 16-15: Loss: 0.7826 Acc: 0.0000%\n",
      "\ttrain 16-16: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 16-17: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 16-18: Loss: 0.1015 Acc: 100.0000%\n",
      "\ttrain 16-19: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 16-20: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 16-21: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 16-22: Loss: 0.2349 Acc: 75.0000%\n",
      "\ttrain 16-23: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 16-24: Loss: 0.3662 Acc: 25.0000%\n",
      "\ttrain 16-25: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 16-26: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 16-27: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 16-28: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 16-29: Loss: 0.2189 Acc: 50.0000%\n",
      "\ttrain 16-30: Loss: 0.2278 Acc: 75.0000%\n",
      "\ttrain 16-31: Loss: 0.2922 Acc: 25.0000%\n",
      "\ttrain 16-32: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 16-33: Loss: 0.1653 Acc: 50.0000%\n",
      "\ttrain 16-34: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 16-35: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 16-36: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 16-37: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 16-38: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 16-39: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 16-40: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 16-41: Loss: 0.5758 Acc: 50.0000%\n",
      "\ttrain 16-42: Loss: 0.1386 Acc: 75.0000%\n",
      "\ttrain 16-43: Loss: 0.3703 Acc: 50.0000%\n",
      "\ttrain 16-44: Loss: 0.3662 Acc: 50.0000%\n",
      "\ttrain 16-45: Loss: 0.1349 Acc: 75.0000%\n",
      "\ttrain 16-46: Loss: 0.3134 Acc: 50.0000%\n",
      "\ttrain 16-47: Loss: 0.0700 Acc: 100.0000%\n",
      "\ttrain 16-48: Loss: 0.0793 Acc: 100.0000%\n",
      "\ttrain 16-49: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 16-50: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 16-51: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 16-52: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 16-53: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 16-54: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 16-55: Loss: 0.3359 Acc: 75.0000%\n",
      "\ttrain 16-56: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 16-57: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 16-58: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 16-59: Loss: 0.1591 Acc: 75.0000%\n",
      "\ttrain 16-60: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 16-61: Loss: 0.5034 Acc: 0.0000%\n",
      "\ttrain 16-62: Loss: 0.2445 Acc: 75.0000%\n",
      "\ttrain 16-63: Loss: 0.5849 Acc: 25.0000%\n",
      "\ttrain 16-64: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 16-65: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 16-66: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 16-67: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 16-68: Loss: 0.2064 Acc: 50.0000%\n",
      "\ttrain 16-69: Loss: 0.1513 Acc: 75.0000%\n",
      "\ttrain 16-70: Loss: 0.3555 Acc: 50.0000%\n",
      "\ttrain 16-71: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 16-72: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 16-73: Loss: 0.2939 Acc: 50.0000%\n",
      "\ttrain 16-74: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 16-75: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 16-76: Loss: 0.5626 Acc: 50.0000%\n",
      "\ttrain 16-77: Loss: 0.2065 Acc: 75.0000%\n",
      "\ttrain 16-78: Loss: 0.1593 Acc: 75.0000%\n",
      "\ttrain 16-79: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 16-80: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 16-81: Loss: 0.4069 Acc: 50.0000%\n",
      "\ttrain 16-82: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 16-83: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 16-84: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 16-85: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 16-86: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 16-87: Loss: 0.4171 Acc: 25.0000%\n",
      "\ttrain 16-88: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 16-89: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 16-90: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 16-91: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 16-92: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 16-93: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 16-94: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 16-95: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 16-96: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 16-97: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 16-98: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 16-99: Loss: 0.2639 Acc: 50.0000%\n",
      "\ttrain 16-100: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 16-101: Loss: 0.2772 Acc: 75.0000%\n",
      "\ttrain 16-102: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 16-103: Loss: 0.0939 Acc: 75.0000%\n",
      "\ttrain 16-104: Loss: 0.3426 Acc: 50.0000%\n",
      "\ttrain 16-105: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 16-106: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 16-107: Loss: 0.1638 Acc: 75.0000%\n",
      "\ttrain 16-108: Loss: 0.2384 Acc: 50.0000%\n",
      "\ttrain 16-109: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 16-110: Loss: 0.1960 Acc: 50.0000%\n",
      "\ttrain 16-111: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 16-112: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 16-113: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 16-114: Loss: 0.2790 Acc: 50.0000%\n",
      "\ttrain 16-115: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 16-116: Loss: 0.3318 Acc: 25.0000%\n",
      "\ttrain 16-117: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 16-118: Loss: 0.0846 Acc: 100.0000%\n",
      "\ttrain 16-119: Loss: 0.1512 Acc: 75.0000%\n",
      "\ttrain 16-120: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 16-121: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 16-122: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 16-123: Loss: 0.4909 Acc: 25.0000%\n",
      "\ttrain 16-124: Loss: 0.2245 Acc: 50.0000%\n",
      "\ttrain 16-125: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 16-126: Loss: 0.0950 Acc: 100.0000%\n",
      "\ttrain 16-127: Loss: 0.1415 Acc: 75.0000%\n",
      "\ttrain 16-128: Loss: 0.3306 Acc: 50.0000%\n",
      "\ttrain 16-129: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 16-130: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 16-131: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 16-132: Loss: 0.2038 Acc: 75.0000%\n",
      "\ttrain 16-133: Loss: 0.1341 Acc: 50.0000%\n",
      "\ttrain 16-134: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 16-135: Loss: 0.3079 Acc: 50.0000%\n",
      "\ttrain 16-136: Loss: 0.2253 Acc: 50.0000%\n",
      "\ttrain 16-137: Loss: 0.3711 Acc: 75.0000%\n",
      "\ttrain 16-138: Loss: 0.3376 Acc: 75.0000%\n",
      "\ttrain 16-139: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 16-140: Loss: 0.1191 Acc: 100.0000%\n",
      "\ttrain 16-141: Loss: 0.1966 Acc: 75.0000%\n",
      "\ttrain 16-142: Loss: 0.0540 Acc: 75.0000%\n",
      "\ttrain 16-143: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 16-144: Loss: 0.3883 Acc: 50.0000%\n",
      "\ttrain 16-145: Loss: 0.2443 Acc: 50.0000%\n",
      "\ttrain 16-146: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 16-147: Loss: 0.1779 Acc: 50.0000%\n",
      "\ttrain 16-148: Loss: 0.2178 Acc: 75.0000%\n",
      "\ttrain 16-149: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 16-150: Loss: 0.1708 Acc: 50.0000%\n",
      "\ttrain 16-151: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 16-152: Loss: 0.2035 Acc: 75.0000%\n",
      "\ttrain 16-153: Loss: 0.1531 Acc: 75.0000%\n",
      "\ttrain 16-154: Loss: 0.1440 Acc: 50.0000%\n",
      "\ttrain 16-155: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 16-156: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 16-157: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 16-158: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 16-159: Loss: 0.4339 Acc: 25.0000%\n",
      "\ttrain 16-160: Loss: 0.2701 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 16-161: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 16-162: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 16-163: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 16-164: Loss: 0.0514 Acc: 100.0000%\n",
      "\ttrain 16-165: Loss: 0.1796 Acc: 75.0000%\n",
      "\ttrain 16-166: Loss: 0.2689 Acc: 25.0000%\n",
      "\ttrain 16-167: Loss: 0.2682 Acc: 75.0000%\n",
      "\ttrain 16-168: Loss: 0.2171 Acc: 50.0000%\n",
      "\ttrain 16-169: Loss: 0.1972 Acc: 50.0000%\n",
      "\ttrain 16-170: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 16-171: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 16-172: Loss: 0.2066 Acc: 75.0000%\n",
      "\ttrain 16-173: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 16-174: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 16-175: Loss: 0.4178 Acc: 50.0000%\n",
      "\ttrain 16-176: Loss: 0.2595 Acc: 75.0000%\n",
      "\ttrain 16-177: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 16-178: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 16-179: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 16-180: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 16-181: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 16-182: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 16-183: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 16-184: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 16-185: Loss: 0.2116 Acc: 50.0000%\n",
      "\ttrain 16-186: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 16-187: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 16-188: Loss: 0.2639 Acc: 75.0000%\n",
      "\ttrain 16-189: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 16-190: Loss: 0.5952 Acc: 50.0000%\n",
      "\ttrain 16-191: Loss: 0.2152 Acc: 50.0000%\n",
      "\ttrain 16-192: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 16-193: Loss: 0.1896 Acc: 75.0000%\n",
      "\ttrain 16-194: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 16-195: Loss: 0.2152 Acc: 75.0000%\n",
      "\ttrain 16-196: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 16-197: Loss: 0.2259 Acc: 75.0000%\n",
      "\ttrain 16-198: Loss: 0.1529 Acc: 50.0000%\n",
      "\ttrain 16-199: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 16-200: Loss: 0.1893 Acc: 75.0000%\n",
      "\ttrain 16-201: Loss: 0.5215 Acc: 25.0000%\n",
      "\ttrain 16-202: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 16-203: Loss: 0.2450 Acc: 50.0000%\n",
      "\ttrain 16-204: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 16-205: Loss: 0.2804 Acc: 25.0000%\n",
      "\ttrain 16-206: Loss: 0.2301 Acc: 50.0000%\n",
      "\ttrain 16-207: Loss: 0.1369 Acc: 50.0000%\n",
      "\ttrain 16-208: Loss: 0.2723 Acc: 50.0000%\n",
      "\ttrain 16-209: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 16-210: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 16-211: Loss: 0.0954 Acc: 100.0000%\n",
      "\ttrain 16-212: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 16-213: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 16-214: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 16-215: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 16-216: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 16-217: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 16-218: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 16-219: Loss: 0.2659 Acc: 25.0000%\n",
      "\ttrain 16-220: Loss: 0.1736 Acc: 75.0000%\n",
      "\ttrain 16-221: Loss: 0.1505 Acc: 75.0000%\n",
      "\ttrain 16-222: Loss: 0.2931 Acc: 50.0000%\n",
      "\ttrain 16-223: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 16-224: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 16-225: Loss: 0.1821 Acc: 75.0000%\n",
      "\ttrain 16-226: Loss: 0.1080 Acc: 100.0000%\n",
      "\ttrain 16-227: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 16-228: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 16-229: Loss: 0.2417 Acc: 75.0000%\n",
      "\ttrain 16-230: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 16-231: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 16-232: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 16-233: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 16-234: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 16-235: Loss: 0.1185 Acc: 50.0000%\n",
      "\ttrain 16-236: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 16-237: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 16-238: Loss: 0.4929 Acc: 25.0000%\n",
      "\ttrain 16-239: Loss: 0.1972 Acc: 75.0000%\n",
      "\ttrain 16-240: Loss: 0.0694 Acc: 75.0000%\n",
      "\ttrain 16-241: Loss: 0.6157 Acc: 0.0000%\n",
      "\ttrain 16-242: Loss: 0.2064 Acc: 75.0000%\n",
      "\ttrain 16-243: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 16-244: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 16-245: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 16-1: Loss: 0.0585 Acc: 75.0000%\n",
      "\tvalidation 16-2: Loss: 0.1107 Acc: 50.0000%\n",
      "\tvalidation 16-3: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 16-4: Loss: 0.1203 Acc: 75.0000%\n",
      "\tvalidation 16-5: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 16-6: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 16-7: Loss: 0.1728 Acc: 75.0000%\n",
      "\tvalidation 16-8: Loss: 0.2374 Acc: 50.0000%\n",
      "\tvalidation 16-9: Loss: 0.0877 Acc: 75.0000%\n",
      "\tvalidation 16-10: Loss: 0.0823 Acc: 75.0000%\n",
      "\tvalidation 16-11: Loss: 0.3002 Acc: 75.0000%\n",
      "\tvalidation 16-12: Loss: 0.0576 Acc: 75.0000%\n",
      "\tvalidation 16-13: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 16-14: Loss: 0.2184 Acc: 25.0000%\n",
      "\tvalidation 16-15: Loss: 0.0674 Acc: 100.0000%\n",
      "\tvalidation 16-16: Loss: 0.1636 Acc: 75.0000%\n",
      "\tvalidation 16-17: Loss: 0.1088 Acc: 75.0000%\n",
      "\tvalidation 16-18: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 16-19: Loss: 0.1390 Acc: 75.0000%\n",
      "\tvalidation 16-20: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 16-21: Loss: 0.4166 Acc: 75.0000%\n",
      "\tvalidation 16-22: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 16-23: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 16-24: Loss: 0.1864 Acc: 75.0000%\n",
      "\tvalidation 16-25: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 16-26: Loss: 0.1603 Acc: 75.0000%\n",
      "\tvalidation 16-27: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 16-28: Loss: 0.1676 Acc: 75.0000%\n",
      "\tvalidation 16-29: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 16-30: Loss: 0.1415 Acc: 75.0000%\n",
      "\tvalidation 16-31: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 16-32: Loss: 0.0342 Acc: 100.0000%\n",
      "\tvalidation 16-33: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 16-34: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 16-35: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 16-36: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 16-37: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-38: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 16-39: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 16-40: Loss: 0.0535 Acc: 75.0000%\n",
      "\tvalidation 16-41: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 16-42: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 16-43: Loss: 0.0529 Acc: 75.0000%\n",
      "\tvalidation 16-44: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 16-45: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 16-46: Loss: 0.1356 Acc: 75.0000%\n",
      "\tvalidation 16-47: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 16-48: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 16-49: Loss: 0.1190 Acc: 75.0000%\n",
      "\tvalidation 16-50: Loss: 0.0446 Acc: 100.0000%\n",
      "\tvalidation 16-51: Loss: 0.0546 Acc: 100.0000%\n",
      "\tvalidation 16-52: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 16-53: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 16-54: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 16-55: Loss: 0.0609 Acc: 100.0000%\n",
      "\tvalidation 16-56: Loss: 0.0857 Acc: 75.0000%\n",
      "\tvalidation 16-57: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 16-58: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 16-59: Loss: 0.1714 Acc: 75.0000%\n",
      "\tvalidation 16-60: Loss: 0.1423 Acc: 75.0000%\n",
      "\tvalidation 16-61: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 16-62: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 16-63: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 16-64: Loss: 0.0975 Acc: 75.0000%\n",
      "\tvalidation 16-65: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 16-66: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 16-67: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 16-68: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 16-69: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 16-70: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-71: Loss: 0.1514 Acc: 75.0000%\n",
      "\tvalidation 16-72: Loss: 0.0711 Acc: 75.0000%\n",
      "\tvalidation 16-73: Loss: 0.1098 Acc: 75.0000%\n",
      "\tvalidation 16-74: Loss: 0.0995 Acc: 100.0000%\n",
      "\tvalidation 16-75: Loss: 0.1018 Acc: 75.0000%\n",
      "\tvalidation 16-76: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 16-77: Loss: 0.2597 Acc: 75.0000%\n",
      "\tvalidation 16-78: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 16-79: Loss: 0.4348 Acc: 75.0000%\n",
      "\tvalidation 16-80: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 16-81: Loss: 0.4010 Acc: 50.0000%\n",
      "\tvalidation 16-82: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 16-83: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 16-84: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 16-85: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 16-86: Loss: 0.0780 Acc: 75.0000%\n",
      "\tvalidation 16-87: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 16-88: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 16-89: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 16-90: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 16-91: Loss: 0.3953 Acc: 25.0000%\n",
      "\tvalidation 16-92: Loss: 0.1490 Acc: 75.0000%\n",
      "\tvalidation 16-93: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 16-94: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 16-95: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 16-96: Loss: 0.2078 Acc: 75.0000%\n",
      "\tvalidation 16-97: Loss: 0.0802 Acc: 100.0000%\n",
      "\tvalidation 16-98: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 16-99: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 16-100: Loss: 0.1185 Acc: 75.0000%\n",
      "\tvalidation 16-101: Loss: 0.2030 Acc: 75.0000%\n",
      "\tvalidation 16-102: Loss: 0.3949 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 16-103: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 16-104: Loss: 0.1401 Acc: 75.0000%\n",
      "\tvalidation 16-105: Loss: 0.1936 Acc: 50.0000%\n",
      "\ttrain Loss: 0.1569 Acc: 74.2857%\n",
      "\tvalidation Loss: 0.0817 Acc: 87.3810%\n",
      "Time passed 0h 10m 38s\n",
      "--------------------\n",
      "Epoch [17/40]:\n",
      "\ttrain 17-1: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 17-2: Loss: 0.1245 Acc: 75.0000%\n",
      "\ttrain 17-3: Loss: 0.1139 Acc: 50.0000%\n",
      "\ttrain 17-4: Loss: 0.2254 Acc: 50.0000%\n",
      "\ttrain 17-5: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 17-6: Loss: 0.3076 Acc: 50.0000%\n",
      "\ttrain 17-7: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 17-8: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 17-9: Loss: 0.3642 Acc: 75.0000%\n",
      "\ttrain 17-10: Loss: 0.1769 Acc: 50.0000%\n",
      "\ttrain 17-11: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 17-12: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 17-13: Loss: 0.1725 Acc: 50.0000%\n",
      "\ttrain 17-14: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 17-15: Loss: 0.1614 Acc: 50.0000%\n",
      "\ttrain 17-16: Loss: 0.0818 Acc: 100.0000%\n",
      "\ttrain 17-17: Loss: 0.0787 Acc: 100.0000%\n",
      "\ttrain 17-18: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 17-19: Loss: 0.1760 Acc: 75.0000%\n",
      "\ttrain 17-20: Loss: 0.3441 Acc: 50.0000%\n",
      "\ttrain 17-21: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 17-22: Loss: 0.2382 Acc: 50.0000%\n",
      "\ttrain 17-23: Loss: 0.1137 Acc: 100.0000%\n",
      "\ttrain 17-24: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 17-25: Loss: 0.2775 Acc: 50.0000%\n",
      "\ttrain 17-26: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 17-27: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 17-28: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 17-29: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 17-30: Loss: 0.3143 Acc: 75.0000%\n",
      "\ttrain 17-31: Loss: 0.1464 Acc: 75.0000%\n",
      "\ttrain 17-32: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 17-33: Loss: 0.3384 Acc: 50.0000%\n",
      "\ttrain 17-34: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 17-35: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 17-36: Loss: 0.3960 Acc: 75.0000%\n",
      "\ttrain 17-37: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 17-38: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 17-39: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 17-40: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 17-41: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 17-42: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 17-43: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 17-44: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 17-45: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 17-46: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 17-47: Loss: 0.1719 Acc: 50.0000%\n",
      "\ttrain 17-48: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 17-49: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 17-50: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 17-51: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 17-52: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 17-53: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 17-54: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 17-55: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 17-56: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 17-57: Loss: 0.2312 Acc: 50.0000%\n",
      "\ttrain 17-58: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 17-59: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 17-60: Loss: 0.4921 Acc: 50.0000%\n",
      "\ttrain 17-61: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 17-62: Loss: 0.1161 Acc: 50.0000%\n",
      "\ttrain 17-63: Loss: 0.1356 Acc: 50.0000%\n",
      "\ttrain 17-64: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 17-65: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 17-66: Loss: 0.2696 Acc: 50.0000%\n",
      "\ttrain 17-67: Loss: 0.1721 Acc: 75.0000%\n",
      "\ttrain 17-68: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 17-69: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 17-70: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 17-71: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 17-72: Loss: 0.1268 Acc: 50.0000%\n",
      "\ttrain 17-73: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 17-74: Loss: 0.3014 Acc: 50.0000%\n",
      "\ttrain 17-75: Loss: 0.2475 Acc: 50.0000%\n",
      "\ttrain 17-76: Loss: 0.2250 Acc: 50.0000%\n",
      "\ttrain 17-77: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 17-78: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 17-79: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 17-80: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 17-81: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 17-82: Loss: 0.1726 Acc: 75.0000%\n",
      "\ttrain 17-83: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 17-84: Loss: 0.1668 Acc: 75.0000%\n",
      "\ttrain 17-85: Loss: 0.5071 Acc: 50.0000%\n",
      "\ttrain 17-86: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 17-87: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 17-88: Loss: 0.2811 Acc: 50.0000%\n",
      "\ttrain 17-89: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 17-90: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 17-91: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 17-92: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 17-93: Loss: 0.1860 Acc: 50.0000%\n",
      "\ttrain 17-94: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 17-95: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 17-96: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 17-97: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 17-98: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 17-99: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 17-100: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 17-101: Loss: 0.0868 Acc: 100.0000%\n",
      "\ttrain 17-102: Loss: 0.1398 Acc: 50.0000%\n",
      "\ttrain 17-103: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 17-104: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 17-105: Loss: 0.3223 Acc: 50.0000%\n",
      "\ttrain 17-106: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 17-107: Loss: 0.2115 Acc: 50.0000%\n",
      "\ttrain 17-108: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 17-109: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 17-110: Loss: 0.1837 Acc: 50.0000%\n",
      "\ttrain 17-111: Loss: 0.3137 Acc: 50.0000%\n",
      "\ttrain 17-112: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 17-113: Loss: 0.0659 Acc: 100.0000%\n",
      "\ttrain 17-114: Loss: 0.1532 Acc: 75.0000%\n",
      "\ttrain 17-115: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 17-116: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 17-117: Loss: 0.2267 Acc: 50.0000%\n",
      "\ttrain 17-118: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 17-119: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 17-120: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 17-121: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 17-122: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 17-123: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 17-124: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 17-125: Loss: 0.1059 Acc: 100.0000%\n",
      "\ttrain 17-126: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 17-127: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 17-128: Loss: 0.3701 Acc: 25.0000%\n",
      "\ttrain 17-129: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 17-130: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 17-131: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 17-132: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 17-133: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 17-134: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 17-135: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 17-136: Loss: 0.5356 Acc: 25.0000%\n",
      "\ttrain 17-137: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 17-138: Loss: 0.5812 Acc: 25.0000%\n",
      "\ttrain 17-139: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 17-140: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 17-141: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 17-142: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 17-143: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 17-144: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 17-145: Loss: 0.0719 Acc: 75.0000%\n",
      "\ttrain 17-146: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 17-147: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 17-148: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 17-149: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 17-150: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 17-151: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 17-152: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 17-153: Loss: 0.4539 Acc: 75.0000%\n",
      "\ttrain 17-154: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 17-155: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 17-156: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 17-157: Loss: 0.1803 Acc: 75.0000%\n",
      "\ttrain 17-158: Loss: 0.1954 Acc: 50.0000%\n",
      "\ttrain 17-159: Loss: 0.3847 Acc: 50.0000%\n",
      "\ttrain 17-160: Loss: 0.2904 Acc: 25.0000%\n",
      "\ttrain 17-161: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 17-162: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 17-163: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 17-164: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 17-165: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 17-166: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 17-167: Loss: 0.1994 Acc: 50.0000%\n",
      "\ttrain 17-168: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 17-169: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 17-170: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 17-171: Loss: 0.4977 Acc: 50.0000%\n",
      "\ttrain 17-172: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 17-173: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 17-174: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 17-175: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 17-176: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 17-177: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 17-178: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 17-179: Loss: 0.2629 Acc: 50.0000%\n",
      "\ttrain 17-180: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 17-181: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 17-182: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 17-183: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 17-184: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 17-185: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 17-186: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 17-187: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 17-188: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 17-189: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 17-190: Loss: 0.3014 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-191: Loss: 0.2527 Acc: 50.0000%\n",
      "\ttrain 17-192: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 17-193: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 17-194: Loss: 0.3095 Acc: 75.0000%\n",
      "\ttrain 17-195: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 17-196: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 17-197: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 17-198: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 17-199: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 17-200: Loss: 0.3425 Acc: 50.0000%\n",
      "\ttrain 17-201: Loss: 0.1793 Acc: 75.0000%\n",
      "\ttrain 17-202: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 17-203: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 17-204: Loss: 0.2103 Acc: 75.0000%\n",
      "\ttrain 17-205: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 17-206: Loss: 0.3489 Acc: 75.0000%\n",
      "\ttrain 17-207: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 17-208: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 17-209: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 17-210: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 17-211: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 17-212: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 17-213: Loss: 0.1553 Acc: 75.0000%\n",
      "\ttrain 17-214: Loss: 0.1191 Acc: 50.0000%\n",
      "\ttrain 17-215: Loss: 0.3047 Acc: 25.0000%\n",
      "\ttrain 17-216: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 17-217: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 17-218: Loss: 0.1390 Acc: 50.0000%\n",
      "\ttrain 17-219: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 17-220: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 17-221: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 17-222: Loss: 0.1755 Acc: 50.0000%\n",
      "\ttrain 17-223: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 17-224: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 17-225: Loss: 0.6747 Acc: 50.0000%\n",
      "\ttrain 17-226: Loss: 0.2389 Acc: 75.0000%\n",
      "\ttrain 17-227: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 17-228: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 17-229: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 17-230: Loss: 0.0517 Acc: 75.0000%\n",
      "\ttrain 17-231: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 17-232: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 17-233: Loss: 0.2886 Acc: 50.0000%\n",
      "\ttrain 17-234: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 17-235: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 17-236: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 17-237: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 17-238: Loss: 0.1859 Acc: 75.0000%\n",
      "\ttrain 17-239: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 17-240: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 17-241: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 17-242: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 17-243: Loss: 0.2845 Acc: 75.0000%\n",
      "\ttrain 17-244: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 17-245: Loss: 0.1216 Acc: 75.0000%\n",
      "\tvalidation 17-1: Loss: 0.1970 Acc: 75.0000%\n",
      "\tvalidation 17-2: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 17-3: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 17-4: Loss: 0.0609 Acc: 75.0000%\n",
      "\tvalidation 17-5: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 17-6: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 17-7: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 17-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 17-9: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 17-10: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 17-11: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 17-12: Loss: 0.6300 Acc: 50.0000%\n",
      "\tvalidation 17-13: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 17-14: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 17-15: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 17-16: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 17-17: Loss: 1.7673 Acc: 75.0000%\n",
      "\tvalidation 17-18: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 17-19: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-20: Loss: 0.0465 Acc: 100.0000%\n",
      "\tvalidation 17-21: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 17-22: Loss: 0.0714 Acc: 100.0000%\n",
      "\tvalidation 17-23: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 17-24: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 17-25: Loss: 0.0476 Acc: 100.0000%\n",
      "\tvalidation 17-26: Loss: 0.3256 Acc: 75.0000%\n",
      "\tvalidation 17-27: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 17-28: Loss: 0.0401 Acc: 100.0000%\n",
      "\tvalidation 17-29: Loss: 0.0948 Acc: 75.0000%\n",
      "\tvalidation 17-30: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 17-31: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 17-32: Loss: 0.0693 Acc: 75.0000%\n",
      "\tvalidation 17-33: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 17-34: Loss: 0.0254 Acc: 100.0000%\n",
      "\tvalidation 17-35: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 17-36: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 17-37: Loss: 0.3575 Acc: 75.0000%\n",
      "\tvalidation 17-38: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 17-39: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 17-40: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 17-41: Loss: 0.0730 Acc: 75.0000%\n",
      "\tvalidation 17-42: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 17-43: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 17-44: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 17-45: Loss: 0.0599 Acc: 75.0000%\n",
      "\tvalidation 17-46: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 17-47: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 17-48: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 17-49: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 17-50: Loss: 0.1015 Acc: 75.0000%\n",
      "\tvalidation 17-51: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 17-52: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 17-53: Loss: 0.2316 Acc: 75.0000%\n",
      "\tvalidation 17-54: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 17-55: Loss: 0.0624 Acc: 75.0000%\n",
      "\tvalidation 17-56: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 17-57: Loss: 0.0485 Acc: 100.0000%\n",
      "\tvalidation 17-58: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 17-59: Loss: 0.4121 Acc: 75.0000%\n",
      "\tvalidation 17-60: Loss: 0.0750 Acc: 75.0000%\n",
      "\tvalidation 17-61: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 17-62: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 17-63: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 17-64: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 17-65: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 17-66: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 17-67: Loss: 5.0744 Acc: 50.0000%\n",
      "\tvalidation 17-68: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 17-69: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 17-70: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 17-71: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 17-72: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 17-73: Loss: 0.0889 Acc: 75.0000%\n",
      "\tvalidation 17-74: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 17-75: Loss: 0.0529 Acc: 100.0000%\n",
      "\tvalidation 17-76: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 17-77: Loss: 0.5853 Acc: 50.0000%\n",
      "\tvalidation 17-78: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 17-79: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 17-80: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 17-81: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 17-82: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 17-83: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 17-84: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 17-85: Loss: 0.0784 Acc: 75.0000%\n",
      "\tvalidation 17-86: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 17-87: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 17-88: Loss: 1.8569 Acc: 75.0000%\n",
      "\tvalidation 17-89: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 17-90: Loss: 0.1423 Acc: 75.0000%\n",
      "\tvalidation 17-91: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 17-92: Loss: 0.0526 Acc: 100.0000%\n",
      "\tvalidation 17-93: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 17-94: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 17-95: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-96: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 17-97: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 17-98: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 17-99: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 17-100: Loss: 0.0658 Acc: 75.0000%\n",
      "\tvalidation 17-101: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 17-102: Loss: 0.1044 Acc: 75.0000%\n",
      "\tvalidation 17-103: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 17-104: Loss: 0.3459 Acc: 75.0000%\n",
      "\tvalidation 17-105: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1233 Acc: 80.0000%\n",
      "\tvalidation Loss: 0.1370 Acc: 93.3333%\n",
      "Time passed 0h 11m 17s\n",
      "--------------------\n",
      "Epoch [18/40]:\n",
      "\ttrain 18-1: Loss: 0.0858 Acc: 100.0000%\n",
      "\ttrain 18-2: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 18-3: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 18-4: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 18-5: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 18-6: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 18-7: Loss: 0.1527 Acc: 75.0000%\n",
      "\ttrain 18-8: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 18-9: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 18-10: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 18-11: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 18-12: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 18-13: Loss: 0.0863 Acc: 100.0000%\n",
      "\ttrain 18-14: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 18-15: Loss: 0.1537 Acc: 75.0000%\n",
      "\ttrain 18-16: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 18-17: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 18-18: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 18-19: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 18-20: Loss: 0.0531 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-21: Loss: 0.2860 Acc: 50.0000%\n",
      "\ttrain 18-22: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 18-23: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 18-24: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 18-25: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 18-26: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 18-27: Loss: 0.2019 Acc: 75.0000%\n",
      "\ttrain 18-28: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 18-29: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 18-30: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 18-31: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 18-32: Loss: 0.1512 Acc: 75.0000%\n",
      "\ttrain 18-33: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 18-34: Loss: 0.3291 Acc: 50.0000%\n",
      "\ttrain 18-35: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 18-36: Loss: 0.0588 Acc: 75.0000%\n",
      "\ttrain 18-37: Loss: 0.1242 Acc: 50.0000%\n",
      "\ttrain 18-38: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 18-39: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 18-40: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 18-41: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 18-42: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 18-43: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 18-44: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 18-45: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 18-46: Loss: 0.2935 Acc: 50.0000%\n",
      "\ttrain 18-47: Loss: 0.3699 Acc: 25.0000%\n",
      "\ttrain 18-48: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 18-49: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 18-50: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 18-51: Loss: 0.1579 Acc: 75.0000%\n",
      "\ttrain 18-52: Loss: 0.3221 Acc: 75.0000%\n",
      "\ttrain 18-53: Loss: 0.4258 Acc: 25.0000%\n",
      "\ttrain 18-54: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 18-55: Loss: 0.1415 Acc: 50.0000%\n",
      "\ttrain 18-56: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 18-57: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 18-58: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 18-59: Loss: 0.2622 Acc: 50.0000%\n",
      "\ttrain 18-60: Loss: 0.2352 Acc: 50.0000%\n",
      "\ttrain 18-61: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 18-62: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 18-63: Loss: 0.1613 Acc: 50.0000%\n",
      "\ttrain 18-64: Loss: 0.2896 Acc: 50.0000%\n",
      "\ttrain 18-65: Loss: 0.0771 Acc: 75.0000%\n",
      "\ttrain 18-66: Loss: 0.5070 Acc: 75.0000%\n",
      "\ttrain 18-67: Loss: 0.0988 Acc: 75.0000%\n",
      "\ttrain 18-68: Loss: 0.3259 Acc: 75.0000%\n",
      "\ttrain 18-69: Loss: 0.4483 Acc: 50.0000%\n",
      "\ttrain 18-70: Loss: 0.3328 Acc: 50.0000%\n",
      "\ttrain 18-71: Loss: 0.3092 Acc: 50.0000%\n",
      "\ttrain 18-72: Loss: 0.4416 Acc: 50.0000%\n",
      "\ttrain 18-73: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 18-74: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 18-75: Loss: 0.2725 Acc: 50.0000%\n",
      "\ttrain 18-76: Loss: 0.4527 Acc: 50.0000%\n",
      "\ttrain 18-77: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 18-78: Loss: 0.2380 Acc: 75.0000%\n",
      "\ttrain 18-79: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 18-80: Loss: 0.4033 Acc: 25.0000%\n",
      "\ttrain 18-81: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 18-82: Loss: 0.0797 Acc: 75.0000%\n",
      "\ttrain 18-83: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 18-84: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 18-85: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 18-86: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 18-87: Loss: 0.2601 Acc: 50.0000%\n",
      "\ttrain 18-88: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 18-89: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 18-90: Loss: 0.2181 Acc: 75.0000%\n",
      "\ttrain 18-91: Loss: 0.1792 Acc: 75.0000%\n",
      "\ttrain 18-92: Loss: 0.2663 Acc: 25.0000%\n",
      "\ttrain 18-93: Loss: 0.1749 Acc: 50.0000%\n",
      "\ttrain 18-94: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 18-95: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 18-96: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 18-97: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 18-98: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 18-99: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 18-100: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 18-101: Loss: 0.1963 Acc: 75.0000%\n",
      "\ttrain 18-102: Loss: 0.3505 Acc: 75.0000%\n",
      "\ttrain 18-103: Loss: 0.1350 Acc: 50.0000%\n",
      "\ttrain 18-104: Loss: 0.1113 Acc: 50.0000%\n",
      "\ttrain 18-105: Loss: 0.2786 Acc: 50.0000%\n",
      "\ttrain 18-106: Loss: 0.4712 Acc: 25.0000%\n",
      "\ttrain 18-107: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 18-108: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 18-109: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 18-110: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 18-111: Loss: 0.1421 Acc: 50.0000%\n",
      "\ttrain 18-112: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 18-113: Loss: 0.3782 Acc: 50.0000%\n",
      "\ttrain 18-114: Loss: 0.1756 Acc: 75.0000%\n",
      "\ttrain 18-115: Loss: 0.4620 Acc: 25.0000%\n",
      "\ttrain 18-116: Loss: 0.1370 Acc: 50.0000%\n",
      "\ttrain 18-117: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 18-118: Loss: 0.2583 Acc: 50.0000%\n",
      "\ttrain 18-119: Loss: 0.4017 Acc: 50.0000%\n",
      "\ttrain 18-120: Loss: 0.3709 Acc: 50.0000%\n",
      "\ttrain 18-121: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 18-122: Loss: 0.4383 Acc: 25.0000%\n",
      "\ttrain 18-123: Loss: 0.2391 Acc: 50.0000%\n",
      "\ttrain 18-124: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 18-125: Loss: 0.0931 Acc: 100.0000%\n",
      "\ttrain 18-126: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 18-127: Loss: 0.0827 Acc: 100.0000%\n",
      "\ttrain 18-128: Loss: 0.0764 Acc: 100.0000%\n",
      "\ttrain 18-129: Loss: 0.2330 Acc: 75.0000%\n",
      "\ttrain 18-130: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 18-131: Loss: 0.1523 Acc: 75.0000%\n",
      "\ttrain 18-132: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 18-133: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 18-134: Loss: 0.0979 Acc: 100.0000%\n",
      "\ttrain 18-135: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 18-136: Loss: 0.2792 Acc: 50.0000%\n",
      "\ttrain 18-137: Loss: 0.3939 Acc: 75.0000%\n",
      "\ttrain 18-138: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 18-139: Loss: 0.1188 Acc: 100.0000%\n",
      "\ttrain 18-140: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 18-141: Loss: 0.2317 Acc: 75.0000%\n",
      "\ttrain 18-142: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 18-143: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 18-144: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 18-145: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 18-146: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 18-147: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 18-148: Loss: 0.2801 Acc: 75.0000%\n",
      "\ttrain 18-149: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 18-150: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 18-151: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 18-152: Loss: 0.1755 Acc: 75.0000%\n",
      "\ttrain 18-153: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 18-154: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 18-155: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 18-156: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 18-157: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 18-158: Loss: 0.2719 Acc: 75.0000%\n",
      "\ttrain 18-159: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 18-160: Loss: 0.1181 Acc: 75.0000%\n",
      "\ttrain 18-161: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 18-162: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 18-163: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 18-164: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 18-165: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 18-166: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 18-167: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 18-168: Loss: 0.2815 Acc: 50.0000%\n",
      "\ttrain 18-169: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 18-170: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 18-171: Loss: 0.1236 Acc: 100.0000%\n",
      "\ttrain 18-172: Loss: 0.2979 Acc: 75.0000%\n",
      "\ttrain 18-173: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 18-174: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 18-175: Loss: 0.1393 Acc: 50.0000%\n",
      "\ttrain 18-176: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 18-177: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 18-178: Loss: 0.3774 Acc: 50.0000%\n",
      "\ttrain 18-179: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 18-180: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 18-181: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 18-182: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 18-183: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 18-184: Loss: 0.4131 Acc: 25.0000%\n",
      "\ttrain 18-185: Loss: 0.5315 Acc: 75.0000%\n",
      "\ttrain 18-186: Loss: 0.3953 Acc: 50.0000%\n",
      "\ttrain 18-187: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 18-188: Loss: 0.2596 Acc: 50.0000%\n",
      "\ttrain 18-189: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 18-190: Loss: 0.2584 Acc: 75.0000%\n",
      "\ttrain 18-191: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 18-192: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 18-193: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 18-194: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 18-195: Loss: 0.1805 Acc: 75.0000%\n",
      "\ttrain 18-196: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 18-197: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 18-198: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 18-199: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 18-200: Loss: 0.2497 Acc: 50.0000%\n",
      "\ttrain 18-201: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 18-202: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 18-203: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 18-204: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 18-205: Loss: 0.1283 Acc: 100.0000%\n",
      "\ttrain 18-206: Loss: 0.0643 Acc: 100.0000%\n",
      "\ttrain 18-207: Loss: 0.0815 Acc: 75.0000%\n",
      "\ttrain 18-208: Loss: 0.1930 Acc: 50.0000%\n",
      "\ttrain 18-209: Loss: 0.1401 Acc: 50.0000%\n",
      "\ttrain 18-210: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 18-211: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 18-212: Loss: 0.1824 Acc: 50.0000%\n",
      "\ttrain 18-213: Loss: 0.2343 Acc: 50.0000%\n",
      "\ttrain 18-214: Loss: 0.2329 Acc: 75.0000%\n",
      "\ttrain 18-215: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 18-216: Loss: 0.0085 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-217: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 18-218: Loss: 0.3186 Acc: 75.0000%\n",
      "\ttrain 18-219: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 18-220: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 18-221: Loss: 0.2943 Acc: 75.0000%\n",
      "\ttrain 18-222: Loss: 0.3137 Acc: 75.0000%\n",
      "\ttrain 18-223: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 18-224: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 18-225: Loss: 0.2671 Acc: 75.0000%\n",
      "\ttrain 18-226: Loss: 0.1641 Acc: 75.0000%\n",
      "\ttrain 18-227: Loss: 0.3075 Acc: 25.0000%\n",
      "\ttrain 18-228: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 18-229: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 18-230: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 18-231: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 18-232: Loss: 0.4280 Acc: 50.0000%\n",
      "\ttrain 18-233: Loss: 0.2950 Acc: 50.0000%\n",
      "\ttrain 18-234: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 18-235: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 18-236: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 18-237: Loss: 0.0780 Acc: 100.0000%\n",
      "\ttrain 18-238: Loss: 0.0902 Acc: 100.0000%\n",
      "\ttrain 18-239: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 18-240: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 18-241: Loss: 0.3284 Acc: 75.0000%\n",
      "\ttrain 18-242: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 18-243: Loss: 0.5354 Acc: 50.0000%\n",
      "\ttrain 18-244: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 18-245: Loss: 0.1142 Acc: 75.0000%\n",
      "\tvalidation 18-1: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 18-2: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 18-3: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 18-4: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 18-5: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-6: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 18-7: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 18-8: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 18-9: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 18-10: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 18-11: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 18-12: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 18-13: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 18-14: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 18-15: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 18-16: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 18-17: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 18-18: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 18-19: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 18-20: Loss: 0.1041 Acc: 75.0000%\n",
      "\tvalidation 18-21: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 18-22: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 18-23: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 18-24: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 18-25: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 18-26: Loss: 1.4511 Acc: 50.0000%\n",
      "\tvalidation 18-27: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 18-28: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 18-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-30: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 18-31: Loss: 0.0324 Acc: 100.0000%\n",
      "\tvalidation 18-32: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 18-33: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 18-34: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 18-35: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 18-36: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 18-37: Loss: 0.0762 Acc: 75.0000%\n",
      "\tvalidation 18-38: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 18-39: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 18-40: Loss: 0.0351 Acc: 100.0000%\n",
      "\tvalidation 18-41: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 18-42: Loss: 0.1158 Acc: 75.0000%\n",
      "\tvalidation 18-43: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 18-44: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 18-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-46: Loss: 0.0550 Acc: 75.0000%\n",
      "\tvalidation 18-47: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 18-48: Loss: 0.2435 Acc: 75.0000%\n",
      "\tvalidation 18-49: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 18-50: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 18-51: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 18-52: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 18-53: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 18-54: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 18-55: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 18-56: Loss: 0.0748 Acc: 75.0000%\n",
      "\tvalidation 18-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 18-58: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 18-59: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 18-60: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 18-61: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 18-62: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 18-63: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 18-64: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-65: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 18-66: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 18-67: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 18-68: Loss: 0.0472 Acc: 100.0000%\n",
      "\tvalidation 18-69: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 18-70: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 18-71: Loss: 0.7346 Acc: 75.0000%\n",
      "\tvalidation 18-72: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 18-73: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 18-74: Loss: 0.0806 Acc: 75.0000%\n",
      "\tvalidation 18-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 18-76: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 18-77: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 18-78: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 18-79: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 18-80: Loss: 0.0407 Acc: 100.0000%\n",
      "\tvalidation 18-81: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 18-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-83: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 18-84: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 18-85: Loss: 0.0586 Acc: 75.0000%\n",
      "\tvalidation 18-86: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-87: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 18-88: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 18-89: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 18-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 18-91: Loss: 0.8481 Acc: 75.0000%\n",
      "\tvalidation 18-92: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-93: Loss: 0.0450 Acc: 100.0000%\n",
      "\tvalidation 18-94: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 18-95: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 18-96: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 18-97: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 18-98: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 18-99: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 18-100: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 18-101: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 18-102: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 18-103: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 18-104: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 18-105: Loss: 0.0881 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1428 Acc: 78.0612%\n",
      "\tvalidation Loss: 0.0505 Acc: 96.9048%\n",
      "网络参数更新\n",
      "Time passed 0h 11m 58s\n",
      "--------------------\n",
      "Epoch [19/40]:\n",
      "\ttrain 19-1: Loss: 0.4959 Acc: 50.0000%\n",
      "\ttrain 19-2: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 19-3: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 19-4: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 19-5: Loss: 0.2366 Acc: 50.0000%\n",
      "\ttrain 19-6: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 19-7: Loss: 0.2760 Acc: 75.0000%\n",
      "\ttrain 19-8: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 19-9: Loss: 0.1463 Acc: 50.0000%\n",
      "\ttrain 19-10: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 19-11: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 19-12: Loss: 0.1362 Acc: 75.0000%\n",
      "\ttrain 19-13: Loss: 0.2349 Acc: 75.0000%\n",
      "\ttrain 19-14: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 19-15: Loss: 0.2176 Acc: 50.0000%\n",
      "\ttrain 19-16: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 19-17: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 19-18: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 19-19: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 19-20: Loss: 0.1554 Acc: 100.0000%\n",
      "\ttrain 19-21: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 19-22: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 19-23: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 19-24: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 19-25: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 19-26: Loss: 0.1367 Acc: 75.0000%\n",
      "\ttrain 19-27: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 19-28: Loss: 0.0831 Acc: 100.0000%\n",
      "\ttrain 19-29: Loss: 0.1053 Acc: 75.0000%\n",
      "\ttrain 19-30: Loss: 0.3294 Acc: 25.0000%\n",
      "\ttrain 19-31: Loss: 0.2438 Acc: 50.0000%\n",
      "\ttrain 19-32: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 19-33: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 19-34: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 19-35: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 19-36: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 19-37: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 19-38: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 19-39: Loss: 0.0802 Acc: 100.0000%\n",
      "\ttrain 19-40: Loss: 0.0836 Acc: 100.0000%\n",
      "\ttrain 19-41: Loss: 0.3046 Acc: 50.0000%\n",
      "\ttrain 19-42: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 19-43: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 19-44: Loss: 0.2252 Acc: 25.0000%\n",
      "\ttrain 19-45: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 19-46: Loss: 0.0861 Acc: 100.0000%\n",
      "\ttrain 19-47: Loss: 0.2377 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-48: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 19-49: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 19-50: Loss: 0.2835 Acc: 0.0000%\n",
      "\ttrain 19-51: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 19-52: Loss: 0.0752 Acc: 100.0000%\n",
      "\ttrain 19-53: Loss: 0.0912 Acc: 75.0000%\n",
      "\ttrain 19-54: Loss: 0.2214 Acc: 50.0000%\n",
      "\ttrain 19-55: Loss: 0.3612 Acc: 50.0000%\n",
      "\ttrain 19-56: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 19-57: Loss: 0.1855 Acc: 75.0000%\n",
      "\ttrain 19-58: Loss: 0.3034 Acc: 50.0000%\n",
      "\ttrain 19-59: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 19-60: Loss: 0.1629 Acc: 50.0000%\n",
      "\ttrain 19-61: Loss: 0.2951 Acc: 75.0000%\n",
      "\ttrain 19-62: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 19-63: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 19-64: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 19-65: Loss: 0.1634 Acc: 50.0000%\n",
      "\ttrain 19-66: Loss: 0.2025 Acc: 50.0000%\n",
      "\ttrain 19-67: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 19-68: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 19-69: Loss: 0.3885 Acc: 25.0000%\n",
      "\ttrain 19-70: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 19-71: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 19-72: Loss: 0.2619 Acc: 50.0000%\n",
      "\ttrain 19-73: Loss: 0.1055 Acc: 100.0000%\n",
      "\ttrain 19-74: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 19-75: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 19-76: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 19-77: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 19-78: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 19-79: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 19-80: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 19-81: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 19-82: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 19-83: Loss: 0.5158 Acc: 50.0000%\n",
      "\ttrain 19-84: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 19-85: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 19-86: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 19-87: Loss: 0.1066 Acc: 100.0000%\n",
      "\ttrain 19-88: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 19-89: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 19-90: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 19-91: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 19-92: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 19-93: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 19-94: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 19-95: Loss: 0.5596 Acc: 25.0000%\n",
      "\ttrain 19-96: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 19-97: Loss: 0.2574 Acc: 75.0000%\n",
      "\ttrain 19-98: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 19-99: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 19-100: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 19-101: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 19-102: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 19-103: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 19-104: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 19-105: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 19-106: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 19-107: Loss: 0.1998 Acc: 75.0000%\n",
      "\ttrain 19-108: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 19-109: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 19-110: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 19-111: Loss: 0.2948 Acc: 75.0000%\n",
      "\ttrain 19-112: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 19-113: Loss: 0.1370 Acc: 75.0000%\n",
      "\ttrain 19-114: Loss: 0.1940 Acc: 50.0000%\n",
      "\ttrain 19-115: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 19-116: Loss: 0.3413 Acc: 25.0000%\n",
      "\ttrain 19-117: Loss: 0.3062 Acc: 50.0000%\n",
      "\ttrain 19-118: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 19-119: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 19-120: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 19-121: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 19-122: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 19-123: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 19-124: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 19-125: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 19-126: Loss: 0.2402 Acc: 50.0000%\n",
      "\ttrain 19-127: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 19-128: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 19-129: Loss: 0.0819 Acc: 100.0000%\n",
      "\ttrain 19-130: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 19-131: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 19-132: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 19-133: Loss: 0.4254 Acc: 75.0000%\n",
      "\ttrain 19-134: Loss: 0.2818 Acc: 50.0000%\n",
      "\ttrain 19-135: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 19-136: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 19-137: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 19-138: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 19-139: Loss: 0.1301 Acc: 50.0000%\n",
      "\ttrain 19-140: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 19-141: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 19-142: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 19-143: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 19-144: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 19-145: Loss: 0.8635 Acc: 0.0000%\n",
      "\ttrain 19-146: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 19-147: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 19-148: Loss: 0.2643 Acc: 50.0000%\n",
      "\ttrain 19-149: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 19-150: Loss: 0.4385 Acc: 50.0000%\n",
      "\ttrain 19-151: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 19-152: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 19-153: Loss: 0.1406 Acc: 75.0000%\n",
      "\ttrain 19-154: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 19-155: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 19-156: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 19-157: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 19-158: Loss: 0.1856 Acc: 75.0000%\n",
      "\ttrain 19-159: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 19-160: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 19-161: Loss: 1.1257 Acc: 25.0000%\n",
      "\ttrain 19-162: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 19-163: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 19-164: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 19-165: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 19-166: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 19-167: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 19-168: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 19-169: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 19-170: Loss: 0.0793 Acc: 100.0000%\n",
      "\ttrain 19-171: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 19-172: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 19-173: Loss: 0.2791 Acc: 50.0000%\n",
      "\ttrain 19-174: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 19-175: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 19-176: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 19-177: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 19-178: Loss: 0.2252 Acc: 75.0000%\n",
      "\ttrain 19-179: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 19-180: Loss: 0.1958 Acc: 75.0000%\n",
      "\ttrain 19-181: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 19-182: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 19-183: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 19-184: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 19-185: Loss: 0.1858 Acc: 75.0000%\n",
      "\ttrain 19-186: Loss: 0.1662 Acc: 50.0000%\n",
      "\ttrain 19-187: Loss: 0.2147 Acc: 75.0000%\n",
      "\ttrain 19-188: Loss: 0.3051 Acc: 75.0000%\n",
      "\ttrain 19-189: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 19-190: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 19-191: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 19-192: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 19-193: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 19-194: Loss: 0.2080 Acc: 75.0000%\n",
      "\ttrain 19-195: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 19-196: Loss: 0.0676 Acc: 100.0000%\n",
      "\ttrain 19-197: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 19-198: Loss: 0.0741 Acc: 75.0000%\n",
      "\ttrain 19-199: Loss: 0.3842 Acc: 0.0000%\n",
      "\ttrain 19-200: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 19-201: Loss: 0.3004 Acc: 25.0000%\n",
      "\ttrain 19-202: Loss: 0.2063 Acc: 50.0000%\n",
      "\ttrain 19-203: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 19-204: Loss: 0.2172 Acc: 75.0000%\n",
      "\ttrain 19-205: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 19-206: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 19-207: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 19-208: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 19-209: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 19-210: Loss: 0.0867 Acc: 100.0000%\n",
      "\ttrain 19-211: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 19-212: Loss: 0.8416 Acc: 0.0000%\n",
      "\ttrain 19-213: Loss: 0.2122 Acc: 75.0000%\n",
      "\ttrain 19-214: Loss: 0.1642 Acc: 75.0000%\n",
      "\ttrain 19-215: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 19-216: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 19-217: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 19-218: Loss: 0.1776 Acc: 75.0000%\n",
      "\ttrain 19-219: Loss: 0.1834 Acc: 75.0000%\n",
      "\ttrain 19-220: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 19-221: Loss: 0.3508 Acc: 50.0000%\n",
      "\ttrain 19-222: Loss: 0.6422 Acc: 50.0000%\n",
      "\ttrain 19-223: Loss: 0.7510 Acc: 0.0000%\n",
      "\ttrain 19-224: Loss: 0.7235 Acc: 50.0000%\n",
      "\ttrain 19-225: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 19-226: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 19-227: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 19-228: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 19-229: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 19-230: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 19-231: Loss: 0.3453 Acc: 50.0000%\n",
      "\ttrain 19-232: Loss: 0.4615 Acc: 50.0000%\n",
      "\ttrain 19-233: Loss: 0.1066 Acc: 100.0000%\n",
      "\ttrain 19-234: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 19-235: Loss: 0.1626 Acc: 75.0000%\n",
      "\ttrain 19-236: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 19-237: Loss: 0.4836 Acc: 25.0000%\n",
      "\ttrain 19-238: Loss: 0.2723 Acc: 50.0000%\n",
      "\ttrain 19-239: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 19-240: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 19-241: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 19-242: Loss: 0.1964 Acc: 75.0000%\n",
      "\ttrain 19-243: Loss: 0.0173 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-244: Loss: 0.4233 Acc: 25.0000%\n",
      "\ttrain 19-245: Loss: 0.1499 Acc: 75.0000%\n",
      "\tvalidation 19-1: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 19-2: Loss: 0.3439 Acc: 75.0000%\n",
      "\tvalidation 19-3: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 19-4: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 19-5: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 19-6: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 19-7: Loss: 0.0524 Acc: 100.0000%\n",
      "\tvalidation 19-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 19-9: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 19-10: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 19-11: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 19-12: Loss: 0.1470 Acc: 75.0000%\n",
      "\tvalidation 19-13: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 19-14: Loss: 0.0398 Acc: 100.0000%\n",
      "\tvalidation 19-15: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 19-16: Loss: 0.0866 Acc: 75.0000%\n",
      "\tvalidation 19-17: Loss: 0.5949 Acc: 50.0000%\n",
      "\tvalidation 19-18: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 19-19: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 19-20: Loss: 0.0635 Acc: 75.0000%\n",
      "\tvalidation 19-21: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 19-22: Loss: 0.1377 Acc: 75.0000%\n",
      "\tvalidation 19-23: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 19-24: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 19-25: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 19-26: Loss: 0.1065 Acc: 75.0000%\n",
      "\tvalidation 19-27: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 19-28: Loss: 0.9111 Acc: 50.0000%\n",
      "\tvalidation 19-29: Loss: 0.1695 Acc: 75.0000%\n",
      "\tvalidation 19-30: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 19-31: Loss: 1.1825 Acc: 75.0000%\n",
      "\tvalidation 19-32: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 19-33: Loss: 0.0632 Acc: 100.0000%\n",
      "\tvalidation 19-34: Loss: 0.1668 Acc: 75.0000%\n",
      "\tvalidation 19-35: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 19-36: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 19-37: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 19-38: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 19-39: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 19-40: Loss: 0.1291 Acc: 75.0000%\n",
      "\tvalidation 19-41: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 19-42: Loss: 0.0676 Acc: 100.0000%\n",
      "\tvalidation 19-43: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 19-44: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 19-45: Loss: 0.3172 Acc: 75.0000%\n",
      "\tvalidation 19-46: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 19-47: Loss: 0.1459 Acc: 75.0000%\n",
      "\tvalidation 19-48: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 19-49: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 19-50: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 19-51: Loss: 0.4585 Acc: 50.0000%\n",
      "\tvalidation 19-52: Loss: 0.0407 Acc: 100.0000%\n",
      "\tvalidation 19-53: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 19-54: Loss: 0.0504 Acc: 100.0000%\n",
      "\tvalidation 19-55: Loss: 0.0640 Acc: 100.0000%\n",
      "\tvalidation 19-56: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 19-57: Loss: 1.1016 Acc: 75.0000%\n",
      "\tvalidation 19-58: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 19-59: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 19-60: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 19-61: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 19-62: Loss: 0.0612 Acc: 75.0000%\n",
      "\tvalidation 19-63: Loss: 1.9926 Acc: 75.0000%\n",
      "\tvalidation 19-64: Loss: 0.9058 Acc: 75.0000%\n",
      "\tvalidation 19-65: Loss: 0.0266 Acc: 100.0000%\n",
      "\tvalidation 19-66: Loss: 5.4114 Acc: 75.0000%\n",
      "\tvalidation 19-67: Loss: 0.1947 Acc: 75.0000%\n",
      "\tvalidation 19-68: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 19-69: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 19-70: Loss: 0.0454 Acc: 100.0000%\n",
      "\tvalidation 19-71: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 19-72: Loss: 3.5777 Acc: 75.0000%\n",
      "\tvalidation 19-73: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 19-74: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 19-75: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 19-76: Loss: 0.5218 Acc: 75.0000%\n",
      "\tvalidation 19-77: Loss: 0.0605 Acc: 100.0000%\n",
      "\tvalidation 19-78: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-79: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 19-80: Loss: 0.1175 Acc: 75.0000%\n",
      "\tvalidation 19-81: Loss: 0.2986 Acc: 75.0000%\n",
      "\tvalidation 19-82: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 19-83: Loss: 0.4236 Acc: 75.0000%\n",
      "\tvalidation 19-84: Loss: 0.4035 Acc: 75.0000%\n",
      "\tvalidation 19-85: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 19-86: Loss: 1.9187 Acc: 75.0000%\n",
      "\tvalidation 19-87: Loss: 0.6774 Acc: 75.0000%\n",
      "\tvalidation 19-88: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 19-89: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-90: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 19-91: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 19-92: Loss: 0.5095 Acc: 75.0000%\n",
      "\tvalidation 19-93: Loss: 0.1201 Acc: 75.0000%\n",
      "\tvalidation 19-94: Loss: 1.4937 Acc: 75.0000%\n",
      "\tvalidation 19-95: Loss: 0.0581 Acc: 100.0000%\n",
      "\tvalidation 19-96: Loss: 0.0290 Acc: 100.0000%\n",
      "\tvalidation 19-97: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-98: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 19-99: Loss: 0.5101 Acc: 50.0000%\n",
      "\tvalidation 19-100: Loss: 0.0914 Acc: 75.0000%\n",
      "\tvalidation 19-101: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 19-102: Loss: 0.1585 Acc: 75.0000%\n",
      "\tvalidation 19-103: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 19-104: Loss: 3.7309 Acc: 75.0000%\n",
      "\tvalidation 19-105: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1405 Acc: 79.2857%\n",
      "\tvalidation Loss: 0.2958 Acc: 90.0000%\n",
      "Time passed 0h 12m 38s\n",
      "--------------------\n",
      "Epoch [20/40]:\n",
      "\ttrain 20-1: Loss: 0.1307 Acc: 50.0000%\n",
      "\ttrain 20-2: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 20-3: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 20-4: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 20-5: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 20-6: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 20-7: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 20-8: Loss: 0.2252 Acc: 50.0000%\n",
      "\ttrain 20-9: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 20-10: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 20-11: Loss: 0.1733 Acc: 75.0000%\n",
      "\ttrain 20-12: Loss: 0.1137 Acc: 100.0000%\n",
      "\ttrain 20-13: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 20-14: Loss: 0.1539 Acc: 50.0000%\n",
      "\ttrain 20-15: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 20-16: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 20-17: Loss: 0.2628 Acc: 25.0000%\n",
      "\ttrain 20-18: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 20-19: Loss: 0.2563 Acc: 75.0000%\n",
      "\ttrain 20-20: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 20-21: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 20-22: Loss: 0.3581 Acc: 75.0000%\n",
      "\ttrain 20-23: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 20-24: Loss: 0.2984 Acc: 50.0000%\n",
      "\ttrain 20-25: Loss: 0.1431 Acc: 50.0000%\n",
      "\ttrain 20-26: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 20-27: Loss: 0.0693 Acc: 100.0000%\n",
      "\ttrain 20-28: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 20-29: Loss: 0.1311 Acc: 50.0000%\n",
      "\ttrain 20-30: Loss: 0.7209 Acc: 0.0000%\n",
      "\ttrain 20-31: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 20-32: Loss: 0.1291 Acc: 50.0000%\n",
      "\ttrain 20-33: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 20-34: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 20-35: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 20-36: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 20-37: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 20-38: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 20-39: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 20-40: Loss: 0.4622 Acc: 25.0000%\n",
      "\ttrain 20-41: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 20-42: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 20-43: Loss: 0.0686 Acc: 100.0000%\n",
      "\ttrain 20-44: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 20-45: Loss: 0.1582 Acc: 50.0000%\n",
      "\ttrain 20-46: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 20-47: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 20-48: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 20-49: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 20-50: Loss: 0.0799 Acc: 100.0000%\n",
      "\ttrain 20-51: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 20-52: Loss: 0.1085 Acc: 100.0000%\n",
      "\ttrain 20-53: Loss: 0.1878 Acc: 50.0000%\n",
      "\ttrain 20-54: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 20-55: Loss: 0.2424 Acc: 50.0000%\n",
      "\ttrain 20-56: Loss: 0.2580 Acc: 25.0000%\n",
      "\ttrain 20-57: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 20-58: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 20-59: Loss: 0.1574 Acc: 75.0000%\n",
      "\ttrain 20-60: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 20-61: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 20-62: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 20-63: Loss: 0.0912 Acc: 100.0000%\n",
      "\ttrain 20-64: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 20-65: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 20-66: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 20-67: Loss: 0.0799 Acc: 100.0000%\n",
      "\ttrain 20-68: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 20-69: Loss: 0.2198 Acc: 75.0000%\n",
      "\ttrain 20-70: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 20-71: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 20-72: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 20-73: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 20-74: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 20-75: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 20-76: Loss: 0.1048 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-77: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 20-78: Loss: 0.2892 Acc: 50.0000%\n",
      "\ttrain 20-79: Loss: 0.2182 Acc: 75.0000%\n",
      "\ttrain 20-80: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 20-81: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 20-82: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 20-83: Loss: 0.0505 Acc: 75.0000%\n",
      "\ttrain 20-84: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 20-85: Loss: 0.0847 Acc: 75.0000%\n",
      "\ttrain 20-86: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 20-87: Loss: 0.4581 Acc: 50.0000%\n",
      "\ttrain 20-88: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 20-89: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 20-90: Loss: 0.3332 Acc: 25.0000%\n",
      "\ttrain 20-91: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 20-92: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 20-93: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 20-94: Loss: 0.3663 Acc: 50.0000%\n",
      "\ttrain 20-95: Loss: 0.2497 Acc: 25.0000%\n",
      "\ttrain 20-96: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 20-97: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 20-98: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 20-99: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 20-100: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 20-101: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 20-102: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 20-103: Loss: 0.1784 Acc: 50.0000%\n",
      "\ttrain 20-104: Loss: 0.2025 Acc: 50.0000%\n",
      "\ttrain 20-105: Loss: 0.2259 Acc: 50.0000%\n",
      "\ttrain 20-106: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 20-107: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 20-108: Loss: 0.2131 Acc: 75.0000%\n",
      "\ttrain 20-109: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 20-110: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 20-111: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 20-112: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 20-113: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 20-114: Loss: 0.2104 Acc: 75.0000%\n",
      "\ttrain 20-115: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 20-116: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 20-117: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 20-118: Loss: 0.2353 Acc: 75.0000%\n",
      "\ttrain 20-119: Loss: 0.0803 Acc: 100.0000%\n",
      "\ttrain 20-120: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 20-121: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 20-122: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 20-123: Loss: 0.1145 Acc: 75.0000%\n",
      "\ttrain 20-124: Loss: 0.2370 Acc: 75.0000%\n",
      "\ttrain 20-125: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 20-126: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 20-127: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 20-128: Loss: 0.3082 Acc: 75.0000%\n",
      "\ttrain 20-129: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 20-130: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 20-131: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 20-132: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 20-133: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 20-134: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 20-135: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 20-136: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 20-137: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 20-138: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 20-139: Loss: 0.2803 Acc: 75.0000%\n",
      "\ttrain 20-140: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 20-141: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 20-142: Loss: 0.9019 Acc: 0.0000%\n",
      "\ttrain 20-143: Loss: 1.0795 Acc: 25.0000%\n",
      "\ttrain 20-144: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 20-145: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 20-146: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 20-147: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 20-148: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 20-149: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 20-150: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 20-151: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 20-152: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 20-153: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 20-154: Loss: 0.3000 Acc: 25.0000%\n",
      "\ttrain 20-155: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 20-156: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 20-157: Loss: 0.1683 Acc: 75.0000%\n",
      "\ttrain 20-158: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 20-159: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 20-160: Loss: 0.1937 Acc: 50.0000%\n",
      "\ttrain 20-161: Loss: 0.0802 Acc: 75.0000%\n",
      "\ttrain 20-162: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 20-163: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 20-164: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 20-165: Loss: 0.1368 Acc: 75.0000%\n",
      "\ttrain 20-166: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 20-167: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 20-168: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 20-169: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-170: Loss: 0.2554 Acc: 50.0000%\n",
      "\ttrain 20-171: Loss: 0.4950 Acc: 50.0000%\n",
      "\ttrain 20-172: Loss: 0.2061 Acc: 75.0000%\n",
      "\ttrain 20-173: Loss: 0.1012 Acc: 100.0000%\n",
      "\ttrain 20-174: Loss: 0.1326 Acc: 50.0000%\n",
      "\ttrain 20-175: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 20-176: Loss: 0.4822 Acc: 50.0000%\n",
      "\ttrain 20-177: Loss: 0.3347 Acc: 25.0000%\n",
      "\ttrain 20-178: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 20-179: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 20-180: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 20-181: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 20-182: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 20-183: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 20-184: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 20-185: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 20-186: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 20-187: Loss: 0.1612 Acc: 75.0000%\n",
      "\ttrain 20-188: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 20-189: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 20-190: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 20-191: Loss: 0.1683 Acc: 75.0000%\n",
      "\ttrain 20-192: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 20-193: Loss: 0.5414 Acc: 25.0000%\n",
      "\ttrain 20-194: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 20-195: Loss: 0.1557 Acc: 75.0000%\n",
      "\ttrain 20-196: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 20-197: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 20-198: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 20-199: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 20-200: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 20-201: Loss: 0.1376 Acc: 75.0000%\n",
      "\ttrain 20-202: Loss: 0.2806 Acc: 50.0000%\n",
      "\ttrain 20-203: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 20-204: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 20-205: Loss: 0.1771 Acc: 75.0000%\n",
      "\ttrain 20-206: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 20-207: Loss: 0.0660 Acc: 100.0000%\n",
      "\ttrain 20-208: Loss: 0.1235 Acc: 75.0000%\n",
      "\ttrain 20-209: Loss: 0.2857 Acc: 75.0000%\n",
      "\ttrain 20-210: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 20-211: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 20-212: Loss: 0.3265 Acc: 50.0000%\n",
      "\ttrain 20-213: Loss: 0.2034 Acc: 75.0000%\n",
      "\ttrain 20-214: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 20-215: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 20-216: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 20-217: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 20-218: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 20-219: Loss: 0.3411 Acc: 25.0000%\n",
      "\ttrain 20-220: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 20-221: Loss: 0.2163 Acc: 50.0000%\n",
      "\ttrain 20-222: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 20-223: Loss: 0.1767 Acc: 25.0000%\n",
      "\ttrain 20-224: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 20-225: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 20-226: Loss: 0.3688 Acc: 75.0000%\n",
      "\ttrain 20-227: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 20-228: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 20-229: Loss: 0.2563 Acc: 75.0000%\n",
      "\ttrain 20-230: Loss: 0.3461 Acc: 50.0000%\n",
      "\ttrain 20-231: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 20-232: Loss: 0.0663 Acc: 75.0000%\n",
      "\ttrain 20-233: Loss: 0.4384 Acc: 50.0000%\n",
      "\ttrain 20-234: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 20-235: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 20-236: Loss: 0.1463 Acc: 50.0000%\n",
      "\ttrain 20-237: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 20-238: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 20-239: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 20-240: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 20-241: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 20-242: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 20-243: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 20-244: Loss: 0.1159 Acc: 50.0000%\n",
      "\ttrain 20-245: Loss: 0.2374 Acc: 50.0000%\n",
      "\tvalidation 20-1: Loss: 0.3245 Acc: 75.0000%\n",
      "\tvalidation 20-2: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-3: Loss: 0.4585 Acc: 75.0000%\n",
      "\tvalidation 20-4: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-5: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 20-6: Loss: 0.0460 Acc: 100.0000%\n",
      "\tvalidation 20-7: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 20-8: Loss: 0.0479 Acc: 75.0000%\n",
      "\tvalidation 20-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 20-10: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 20-11: Loss: 0.7598 Acc: 75.0000%\n",
      "\tvalidation 20-12: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 20-13: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 20-14: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 20-15: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 20-16: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 20-17: Loss: 0.4837 Acc: 75.0000%\n",
      "\tvalidation 20-18: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-19: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 20-20: Loss: 0.3612 Acc: 75.0000%\n",
      "\tvalidation 20-21: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 20-22: Loss: 0.3118 Acc: 75.0000%\n",
      "\tvalidation 20-23: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 20-24: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 20-25: Loss: 0.0475 Acc: 100.0000%\n",
      "\tvalidation 20-26: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-27: Loss: 0.0028 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 20-28: Loss: 0.2257 Acc: 75.0000%\n",
      "\tvalidation 20-29: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 20-30: Loss: 1.1659 Acc: 75.0000%\n",
      "\tvalidation 20-31: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 20-32: Loss: 0.1370 Acc: 75.0000%\n",
      "\tvalidation 20-33: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 20-34: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 20-35: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 20-36: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 20-37: Loss: 0.1071 Acc: 75.0000%\n",
      "\tvalidation 20-38: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 20-39: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 20-40: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 20-41: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 20-42: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 20-43: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 20-44: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 20-45: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 20-46: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 20-47: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 20-48: Loss: 0.6571 Acc: 75.0000%\n",
      "\tvalidation 20-49: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 20-50: Loss: 0.7629 Acc: 75.0000%\n",
      "\tvalidation 20-51: Loss: 1.5655 Acc: 75.0000%\n",
      "\tvalidation 20-52: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 20-53: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 20-54: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 20-55: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 20-56: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 20-57: Loss: 0.0573 Acc: 75.0000%\n",
      "\tvalidation 20-58: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-59: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 20-60: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 20-61: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 20-62: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 20-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 20-64: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 20-65: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 20-66: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 20-67: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 20-68: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 20-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-70: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 20-71: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 20-72: Loss: 0.0602 Acc: 75.0000%\n",
      "\tvalidation 20-73: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 20-74: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 20-75: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 20-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-77: Loss: 0.0565 Acc: 100.0000%\n",
      "\tvalidation 20-78: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 20-79: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 20-80: Loss: 0.7954 Acc: 50.0000%\n",
      "\tvalidation 20-81: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 20-82: Loss: 0.6091 Acc: 50.0000%\n",
      "\tvalidation 20-83: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 20-84: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 20-85: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 20-86: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 20-87: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 20-88: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 20-89: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 20-90: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 20-91: Loss: 0.6654 Acc: 75.0000%\n",
      "\tvalidation 20-92: Loss: 0.0681 Acc: 100.0000%\n",
      "\tvalidation 20-93: Loss: 0.0380 Acc: 100.0000%\n",
      "\tvalidation 20-94: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 20-95: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 20-96: Loss: 0.0730 Acc: 75.0000%\n",
      "\tvalidation 20-97: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 20-98: Loss: 0.1358 Acc: 75.0000%\n",
      "\tvalidation 20-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 20-100: Loss: 0.1100 Acc: 75.0000%\n",
      "\tvalidation 20-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 20-102: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 20-103: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 20-104: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 20-105: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1212 Acc: 80.7143%\n",
      "\tvalidation Loss: 0.1036 Acc: 94.2857%\n",
      "Time passed 0h 13m 18s\n",
      "--------------------\n",
      "Epoch [21/40]:\n",
      "\ttrain 21-1: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 21-2: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 21-3: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 21-4: Loss: 0.1355 Acc: 50.0000%\n",
      "\ttrain 21-5: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 21-6: Loss: 0.1375 Acc: 75.0000%\n",
      "\ttrain 21-7: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 21-8: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 21-9: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 21-10: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 21-11: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 21-12: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 21-13: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 21-14: Loss: 0.2829 Acc: 50.0000%\n",
      "\ttrain 21-15: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 21-16: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 21-17: Loss: 0.2977 Acc: 50.0000%\n",
      "\ttrain 21-18: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 21-19: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 21-20: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 21-21: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 21-22: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 21-23: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 21-24: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 21-25: Loss: 0.2377 Acc: 50.0000%\n",
      "\ttrain 21-26: Loss: 0.1317 Acc: 75.0000%\n",
      "\ttrain 21-27: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 21-28: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 21-29: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 21-30: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 21-31: Loss: 0.4086 Acc: 50.0000%\n",
      "\ttrain 21-32: Loss: 0.0772 Acc: 75.0000%\n",
      "\ttrain 21-33: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 21-34: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 21-35: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 21-36: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 21-37: Loss: 0.2233 Acc: 75.0000%\n",
      "\ttrain 21-38: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 21-39: Loss: 0.3136 Acc: 25.0000%\n",
      "\ttrain 21-40: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 21-41: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 21-42: Loss: 0.4786 Acc: 50.0000%\n",
      "\ttrain 21-43: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 21-44: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-45: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 21-46: Loss: 0.1760 Acc: 75.0000%\n",
      "\ttrain 21-47: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 21-48: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 21-49: Loss: 0.1205 Acc: 50.0000%\n",
      "\ttrain 21-50: Loss: 0.0868 Acc: 100.0000%\n",
      "\ttrain 21-51: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 21-52: Loss: 0.2860 Acc: 50.0000%\n",
      "\ttrain 21-53: Loss: 0.1619 Acc: 75.0000%\n",
      "\ttrain 21-54: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 21-55: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 21-56: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 21-57: Loss: 0.1573 Acc: 75.0000%\n",
      "\ttrain 21-58: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 21-59: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 21-60: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 21-61: Loss: 0.1498 Acc: 50.0000%\n",
      "\ttrain 21-62: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 21-63: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 21-64: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 21-65: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 21-66: Loss: 0.4913 Acc: 25.0000%\n",
      "\ttrain 21-67: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 21-68: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 21-69: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 21-70: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 21-71: Loss: 0.4047 Acc: 0.0000%\n",
      "\ttrain 21-72: Loss: 0.1876 Acc: 75.0000%\n",
      "\ttrain 21-73: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 21-74: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 21-75: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 21-76: Loss: 0.3079 Acc: 50.0000%\n",
      "\ttrain 21-77: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 21-78: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 21-79: Loss: 0.4864 Acc: 25.0000%\n",
      "\ttrain 21-80: Loss: 0.1306 Acc: 75.0000%\n",
      "\ttrain 21-81: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-82: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 21-83: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 21-84: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 21-85: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 21-86: Loss: 0.2469 Acc: 50.0000%\n",
      "\ttrain 21-87: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 21-88: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 21-89: Loss: 0.3303 Acc: 50.0000%\n",
      "\ttrain 21-90: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 21-91: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 21-92: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 21-93: Loss: 0.3075 Acc: 75.0000%\n",
      "\ttrain 21-94: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 21-95: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 21-96: Loss: 0.1731 Acc: 50.0000%\n",
      "\ttrain 21-97: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 21-98: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 21-99: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 21-100: Loss: 0.6376 Acc: 50.0000%\n",
      "\ttrain 21-101: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 21-102: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 21-103: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 21-104: Loss: 0.1039 Acc: 100.0000%\n",
      "\ttrain 21-105: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 21-106: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 21-107: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 21-108: Loss: 0.0126 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-109: Loss: 0.0741 Acc: 75.0000%\n",
      "\ttrain 21-110: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 21-111: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 21-112: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 21-113: Loss: 0.3605 Acc: 50.0000%\n",
      "\ttrain 21-114: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 21-115: Loss: 0.2463 Acc: 50.0000%\n",
      "\ttrain 21-116: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 21-117: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 21-118: Loss: 0.1650 Acc: 50.0000%\n",
      "\ttrain 21-119: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 21-120: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 21-121: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 21-122: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 21-123: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 21-124: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 21-125: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 21-126: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 21-127: Loss: 0.1934 Acc: 75.0000%\n",
      "\ttrain 21-128: Loss: 0.1522 Acc: 50.0000%\n",
      "\ttrain 21-129: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 21-130: Loss: 0.2129 Acc: 50.0000%\n",
      "\ttrain 21-131: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 21-132: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 21-133: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 21-134: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 21-135: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 21-136: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 21-137: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 21-138: Loss: 0.1588 Acc: 50.0000%\n",
      "\ttrain 21-139: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 21-140: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 21-141: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 21-142: Loss: 0.8789 Acc: 25.0000%\n",
      "\ttrain 21-143: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 21-144: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 21-145: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 21-146: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 21-147: Loss: 0.2614 Acc: 50.0000%\n",
      "\ttrain 21-148: Loss: 0.2184 Acc: 50.0000%\n",
      "\ttrain 21-149: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 21-150: Loss: 0.1908 Acc: 50.0000%\n",
      "\ttrain 21-151: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 21-152: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 21-153: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 21-154: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 21-155: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 21-156: Loss: 0.0895 Acc: 100.0000%\n",
      "\ttrain 21-157: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 21-158: Loss: 0.0822 Acc: 100.0000%\n",
      "\ttrain 21-159: Loss: 0.2037 Acc: 75.0000%\n",
      "\ttrain 21-160: Loss: 0.1743 Acc: 75.0000%\n",
      "\ttrain 21-161: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 21-162: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 21-163: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 21-164: Loss: 0.2237 Acc: 50.0000%\n",
      "\ttrain 21-165: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 21-166: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 21-167: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 21-168: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 21-169: Loss: 0.0702 Acc: 100.0000%\n",
      "\ttrain 21-170: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 21-171: Loss: 0.3131 Acc: 50.0000%\n",
      "\ttrain 21-172: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 21-173: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 21-174: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 21-175: Loss: 0.1552 Acc: 75.0000%\n",
      "\ttrain 21-176: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 21-177: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 21-178: Loss: 0.0812 Acc: 100.0000%\n",
      "\ttrain 21-179: Loss: 0.1284 Acc: 100.0000%\n",
      "\ttrain 21-180: Loss: 0.1779 Acc: 50.0000%\n",
      "\ttrain 21-181: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 21-182: Loss: 0.7081 Acc: 0.0000%\n",
      "\ttrain 21-183: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 21-184: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 21-185: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 21-186: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 21-187: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 21-188: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 21-189: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 21-190: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 21-191: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 21-192: Loss: 0.0893 Acc: 100.0000%\n",
      "\ttrain 21-193: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 21-194: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 21-195: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 21-196: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 21-197: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 21-198: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 21-199: Loss: 0.2475 Acc: 75.0000%\n",
      "\ttrain 21-200: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 21-201: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 21-202: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 21-203: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-204: Loss: 0.1408 Acc: 50.0000%\n",
      "\ttrain 21-205: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-206: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 21-207: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 21-208: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 21-209: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 21-210: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 21-211: Loss: 0.3184 Acc: 75.0000%\n",
      "\ttrain 21-212: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-213: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 21-214: Loss: 0.2374 Acc: 75.0000%\n",
      "\ttrain 21-215: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 21-216: Loss: 0.0954 Acc: 100.0000%\n",
      "\ttrain 21-217: Loss: 0.1979 Acc: 75.0000%\n",
      "\ttrain 21-218: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 21-219: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 21-220: Loss: 0.2075 Acc: 75.0000%\n",
      "\ttrain 21-221: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 21-222: Loss: 0.0773 Acc: 100.0000%\n",
      "\ttrain 21-223: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 21-224: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 21-225: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 21-226: Loss: 0.1098 Acc: 75.0000%\n",
      "\ttrain 21-227: Loss: 0.5379 Acc: 50.0000%\n",
      "\ttrain 21-228: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 21-229: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 21-230: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-231: Loss: 0.2821 Acc: 50.0000%\n",
      "\ttrain 21-232: Loss: 0.5921 Acc: 50.0000%\n",
      "\ttrain 21-233: Loss: 0.3105 Acc: 75.0000%\n",
      "\ttrain 21-234: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 21-235: Loss: 0.2547 Acc: 75.0000%\n",
      "\ttrain 21-236: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 21-237: Loss: 0.0978 Acc: 100.0000%\n",
      "\ttrain 21-238: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 21-239: Loss: 0.1826 Acc: 75.0000%\n",
      "\ttrain 21-240: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 21-241: Loss: 0.1114 Acc: 100.0000%\n",
      "\ttrain 21-242: Loss: 0.2919 Acc: 75.0000%\n",
      "\ttrain 21-243: Loss: 0.4697 Acc: 25.0000%\n",
      "\ttrain 21-244: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 21-245: Loss: 0.0818 Acc: 100.0000%\n",
      "\tvalidation 21-1: Loss: 0.6107 Acc: 75.0000%\n",
      "\tvalidation 21-2: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 21-3: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 21-4: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 21-5: Loss: 0.1172 Acc: 75.0000%\n",
      "\tvalidation 21-6: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 21-7: Loss: 0.0454 Acc: 100.0000%\n",
      "\tvalidation 21-8: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 21-9: Loss: 0.8254 Acc: 75.0000%\n",
      "\tvalidation 21-10: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 21-11: Loss: 2.3762 Acc: 75.0000%\n",
      "\tvalidation 21-12: Loss: 0.0714 Acc: 100.0000%\n",
      "\tvalidation 21-13: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 21-14: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 21-15: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 21-16: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 21-17: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 21-18: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 21-19: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 21-20: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 21-21: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 21-22: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 21-23: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 21-24: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 21-25: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 21-26: Loss: 0.8265 Acc: 75.0000%\n",
      "\tvalidation 21-27: Loss: 1.1643 Acc: 50.0000%\n",
      "\tvalidation 21-28: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 21-29: Loss: 1.4342 Acc: 75.0000%\n",
      "\tvalidation 21-30: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 21-31: Loss: 0.0843 Acc: 75.0000%\n",
      "\tvalidation 21-32: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 21-33: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 21-34: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 21-35: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 21-36: Loss: 0.1337 Acc: 75.0000%\n",
      "\tvalidation 21-37: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 21-38: Loss: 0.4837 Acc: 75.0000%\n",
      "\tvalidation 21-39: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 21-40: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 21-41: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 21-42: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 21-43: Loss: 0.0839 Acc: 75.0000%\n",
      "\tvalidation 21-44: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 21-45: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 21-46: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 21-47: Loss: 0.5901 Acc: 75.0000%\n",
      "\tvalidation 21-48: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 21-49: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 21-50: Loss: 0.5403 Acc: 75.0000%\n",
      "\tvalidation 21-51: Loss: 0.0616 Acc: 75.0000%\n",
      "\tvalidation 21-52: Loss: 0.1138 Acc: 75.0000%\n",
      "\tvalidation 21-53: Loss: 0.4103 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 21-54: Loss: 3.8484 Acc: 75.0000%\n",
      "\tvalidation 21-55: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 21-56: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 21-57: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 21-58: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 21-59: Loss: 0.2183 Acc: 75.0000%\n",
      "\tvalidation 21-60: Loss: 3.2916 Acc: 75.0000%\n",
      "\tvalidation 21-61: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 21-62: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 21-63: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 21-64: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-65: Loss: 5.3100 Acc: 75.0000%\n",
      "\tvalidation 21-66: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 21-67: Loss: 0.0513 Acc: 75.0000%\n",
      "\tvalidation 21-68: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 21-69: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 21-70: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 21-71: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 21-72: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 21-73: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 21-74: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 21-75: Loss: 1.3368 Acc: 75.0000%\n",
      "\tvalidation 21-76: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 21-77: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 21-78: Loss: 0.0835 Acc: 75.0000%\n",
      "\tvalidation 21-79: Loss: 0.0195 Acc: 100.0000%\n",
      "\tvalidation 21-80: Loss: 1.0995 Acc: 50.0000%\n",
      "\tvalidation 21-81: Loss: 0.2124 Acc: 75.0000%\n",
      "\tvalidation 21-82: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 21-83: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 21-84: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 21-85: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 21-86: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 21-87: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 21-88: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 21-89: Loss: 1.8372 Acc: 75.0000%\n",
      "\tvalidation 21-90: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 21-91: Loss: 0.2203 Acc: 75.0000%\n",
      "\tvalidation 21-92: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 21-93: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 21-94: Loss: 0.1548 Acc: 75.0000%\n",
      "\tvalidation 21-95: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 21-96: Loss: 0.1849 Acc: 75.0000%\n",
      "\tvalidation 21-97: Loss: 0.3736 Acc: 75.0000%\n",
      "\tvalidation 21-98: Loss: 0.2068 Acc: 75.0000%\n",
      "\tvalidation 21-99: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 21-100: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 21-101: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 21-102: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 21-103: Loss: 0.3713 Acc: 75.0000%\n",
      "\tvalidation 21-104: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 21-105: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1114 Acc: 83.2653%\n",
      "\tvalidation Loss: 0.2840 Acc: 91.6667%\n",
      "Time passed 0h 13m 58s\n",
      "--------------------\n",
      "Epoch [22/40]:\n",
      "\ttrain 22-1: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 22-2: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 22-3: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 22-4: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 22-5: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 22-6: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 22-7: Loss: 0.1711 Acc: 50.0000%\n",
      "\ttrain 22-8: Loss: 0.0643 Acc: 100.0000%\n",
      "\ttrain 22-9: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 22-10: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 22-11: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 22-12: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 22-13: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 22-14: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 22-15: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 22-16: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 22-17: Loss: 0.1735 Acc: 50.0000%\n",
      "\ttrain 22-18: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 22-19: Loss: 0.1594 Acc: 50.0000%\n",
      "\ttrain 22-20: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 22-21: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 22-22: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 22-23: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 22-24: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 22-25: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 22-26: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 22-27: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 22-28: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 22-29: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 22-30: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 22-31: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 22-32: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 22-33: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 22-34: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 22-35: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 22-36: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 22-37: Loss: 0.1735 Acc: 75.0000%\n",
      "\ttrain 22-38: Loss: 0.3516 Acc: 50.0000%\n",
      "\ttrain 22-39: Loss: 0.2301 Acc: 75.0000%\n",
      "\ttrain 22-40: Loss: 0.3535 Acc: 25.0000%\n",
      "\ttrain 22-41: Loss: 0.1512 Acc: 50.0000%\n",
      "\ttrain 22-42: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 22-43: Loss: 0.3553 Acc: 50.0000%\n",
      "\ttrain 22-44: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 22-45: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 22-46: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 22-47: Loss: 0.1803 Acc: 75.0000%\n",
      "\ttrain 22-48: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 22-49: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 22-50: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 22-51: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 22-52: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 22-53: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 22-54: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 22-55: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 22-56: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 22-57: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 22-58: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 22-59: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 22-60: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 22-61: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 22-62: Loss: 0.2655 Acc: 50.0000%\n",
      "\ttrain 22-63: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 22-64: Loss: 0.3231 Acc: 50.0000%\n",
      "\ttrain 22-65: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 22-66: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 22-67: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 22-68: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 22-69: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 22-70: Loss: 0.1833 Acc: 75.0000%\n",
      "\ttrain 22-71: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 22-72: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 22-73: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 22-74: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 22-75: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 22-76: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 22-77: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 22-78: Loss: 0.1082 Acc: 75.0000%\n",
      "\ttrain 22-79: Loss: 0.3442 Acc: 25.0000%\n",
      "\ttrain 22-80: Loss: 0.1556 Acc: 50.0000%\n",
      "\ttrain 22-81: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 22-82: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 22-83: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 22-84: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 22-85: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 22-86: Loss: 0.3488 Acc: 75.0000%\n",
      "\ttrain 22-87: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 22-88: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 22-89: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 22-90: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 22-91: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-92: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 22-93: Loss: 0.1759 Acc: 75.0000%\n",
      "\ttrain 22-94: Loss: 0.3453 Acc: 50.0000%\n",
      "\ttrain 22-95: Loss: 0.1628 Acc: 75.0000%\n",
      "\ttrain 22-96: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 22-97: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 22-98: Loss: 0.1805 Acc: 75.0000%\n",
      "\ttrain 22-99: Loss: 0.1233 Acc: 50.0000%\n",
      "\ttrain 22-100: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 22-101: Loss: 0.3147 Acc: 75.0000%\n",
      "\ttrain 22-102: Loss: 0.4010 Acc: 75.0000%\n",
      "\ttrain 22-103: Loss: 0.1260 Acc: 75.0000%\n",
      "\ttrain 22-104: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 22-105: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 22-106: Loss: 0.1400 Acc: 75.0000%\n",
      "\ttrain 22-107: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 22-108: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 22-109: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 22-110: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 22-111: Loss: 0.1783 Acc: 75.0000%\n",
      "\ttrain 22-112: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 22-113: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 22-114: Loss: 0.2576 Acc: 75.0000%\n",
      "\ttrain 22-115: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 22-116: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 22-117: Loss: 0.4133 Acc: 50.0000%\n",
      "\ttrain 22-118: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 22-119: Loss: 0.3372 Acc: 75.0000%\n",
      "\ttrain 22-120: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-121: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 22-122: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 22-123: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 22-124: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 22-125: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 22-126: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 22-127: Loss: 0.1606 Acc: 75.0000%\n",
      "\ttrain 22-128: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 22-129: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 22-130: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 22-131: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 22-132: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 22-133: Loss: 0.1799 Acc: 75.0000%\n",
      "\ttrain 22-134: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 22-135: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 22-136: Loss: 0.1925 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-137: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 22-138: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 22-139: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 22-140: Loss: 0.2865 Acc: 75.0000%\n",
      "\ttrain 22-141: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 22-142: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 22-143: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 22-144: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 22-145: Loss: 0.7454 Acc: 25.0000%\n",
      "\ttrain 22-146: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 22-147: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 22-148: Loss: 0.5451 Acc: 25.0000%\n",
      "\ttrain 22-149: Loss: 0.2025 Acc: 75.0000%\n",
      "\ttrain 22-150: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 22-151: Loss: 0.0804 Acc: 100.0000%\n",
      "\ttrain 22-152: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 22-153: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 22-154: Loss: 0.1804 Acc: 75.0000%\n",
      "\ttrain 22-155: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 22-156: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 22-157: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 22-158: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 22-159: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 22-160: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 22-161: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 22-162: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 22-163: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 22-164: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 22-165: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 22-166: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 22-167: Loss: 0.1510 Acc: 75.0000%\n",
      "\ttrain 22-168: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 22-169: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 22-170: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 22-171: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 22-172: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 22-173: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 22-174: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 22-175: Loss: 0.3328 Acc: 25.0000%\n",
      "\ttrain 22-176: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 22-177: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 22-178: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 22-179: Loss: 0.3096 Acc: 50.0000%\n",
      "\ttrain 22-180: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 22-181: Loss: 0.3378 Acc: 50.0000%\n",
      "\ttrain 22-182: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 22-183: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 22-184: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 22-185: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 22-186: Loss: 0.4329 Acc: 50.0000%\n",
      "\ttrain 22-187: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 22-188: Loss: 0.0847 Acc: 75.0000%\n",
      "\ttrain 22-189: Loss: 0.0753 Acc: 100.0000%\n",
      "\ttrain 22-190: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 22-191: Loss: 0.0622 Acc: 100.0000%\n",
      "\ttrain 22-192: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 22-193: Loss: 0.1837 Acc: 75.0000%\n",
      "\ttrain 22-194: Loss: 0.1966 Acc: 50.0000%\n",
      "\ttrain 22-195: Loss: 0.1969 Acc: 50.0000%\n",
      "\ttrain 22-196: Loss: 0.1479 Acc: 75.0000%\n",
      "\ttrain 22-197: Loss: 0.3594 Acc: 50.0000%\n",
      "\ttrain 22-198: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 22-199: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 22-200: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 22-201: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 22-202: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 22-203: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 22-204: Loss: 0.2107 Acc: 75.0000%\n",
      "\ttrain 22-205: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 22-206: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 22-207: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 22-208: Loss: 0.0885 Acc: 100.0000%\n",
      "\ttrain 22-209: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 22-210: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 22-211: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 22-212: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 22-213: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 22-214: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 22-215: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 22-216: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 22-217: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 22-218: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 22-219: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 22-220: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 22-221: Loss: 0.0841 Acc: 100.0000%\n",
      "\ttrain 22-222: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 22-223: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 22-224: Loss: 0.2418 Acc: 75.0000%\n",
      "\ttrain 22-225: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 22-226: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 22-227: Loss: 0.2411 Acc: 25.0000%\n",
      "\ttrain 22-228: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 22-229: Loss: 0.1896 Acc: 75.0000%\n",
      "\ttrain 22-230: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 22-231: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 22-232: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 22-233: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 22-234: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-235: Loss: 0.2370 Acc: 50.0000%\n",
      "\ttrain 22-236: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 22-237: Loss: 0.2289 Acc: 75.0000%\n",
      "\ttrain 22-238: Loss: 0.1109 Acc: 75.0000%\n",
      "\ttrain 22-239: Loss: 0.3003 Acc: 75.0000%\n",
      "\ttrain 22-240: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 22-241: Loss: 0.1656 Acc: 50.0000%\n",
      "\ttrain 22-242: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 22-243: Loss: 0.1861 Acc: 50.0000%\n",
      "\ttrain 22-244: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 22-245: Loss: 0.1440 Acc: 75.0000%\n",
      "\tvalidation 22-1: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 22-2: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 22-3: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 22-4: Loss: 0.1834 Acc: 75.0000%\n",
      "\tvalidation 22-5: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 22-6: Loss: 0.0716 Acc: 75.0000%\n",
      "\tvalidation 22-7: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-8: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 22-9: Loss: 0.1124 Acc: 75.0000%\n",
      "\tvalidation 22-10: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 22-11: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 22-12: Loss: 0.0667 Acc: 75.0000%\n",
      "\tvalidation 22-13: Loss: 0.0691 Acc: 75.0000%\n",
      "\tvalidation 22-14: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 22-15: Loss: 0.0419 Acc: 100.0000%\n",
      "\tvalidation 22-16: Loss: 0.1308 Acc: 75.0000%\n",
      "\tvalidation 22-17: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 22-18: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-19: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 22-20: Loss: 0.1002 Acc: 75.0000%\n",
      "\tvalidation 22-21: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 22-22: Loss: 0.0980 Acc: 75.0000%\n",
      "\tvalidation 22-23: Loss: 0.1160 Acc: 75.0000%\n",
      "\tvalidation 22-24: Loss: 0.1787 Acc: 50.0000%\n",
      "\tvalidation 22-25: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 22-26: Loss: 0.2763 Acc: 75.0000%\n",
      "\tvalidation 22-27: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 22-28: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 22-29: Loss: 0.1382 Acc: 75.0000%\n",
      "\tvalidation 22-30: Loss: 0.1113 Acc: 75.0000%\n",
      "\tvalidation 22-31: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 22-32: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 22-33: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 22-34: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-35: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 22-36: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 22-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 22-38: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 22-39: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 22-40: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-41: Loss: 0.0938 Acc: 75.0000%\n",
      "\tvalidation 22-42: Loss: 0.1796 Acc: 75.0000%\n",
      "\tvalidation 22-43: Loss: 0.0277 Acc: 100.0000%\n",
      "\tvalidation 22-44: Loss: 0.0538 Acc: 75.0000%\n",
      "\tvalidation 22-45: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 22-46: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-47: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 22-48: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 22-49: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 22-50: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 22-51: Loss: 0.1054 Acc: 75.0000%\n",
      "\tvalidation 22-52: Loss: 0.0612 Acc: 75.0000%\n",
      "\tvalidation 22-53: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 22-54: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 22-55: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 22-56: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 22-57: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 22-58: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 22-59: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 22-60: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 22-61: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 22-62: Loss: 0.0334 Acc: 100.0000%\n",
      "\tvalidation 22-63: Loss: 0.0269 Acc: 100.0000%\n",
      "\tvalidation 22-64: Loss: 0.0490 Acc: 100.0000%\n",
      "\tvalidation 22-65: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 22-66: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 22-67: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 22-68: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 22-69: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 22-70: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 22-71: Loss: 0.0637 Acc: 100.0000%\n",
      "\tvalidation 22-72: Loss: 0.1545 Acc: 75.0000%\n",
      "\tvalidation 22-73: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 22-74: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 22-75: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 22-76: Loss: 0.1641 Acc: 75.0000%\n",
      "\tvalidation 22-77: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 22-78: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 22-79: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 22-80: Loss: 0.0574 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 22-81: Loss: 0.1000 Acc: 75.0000%\n",
      "\tvalidation 22-82: Loss: 0.0488 Acc: 100.0000%\n",
      "\tvalidation 22-83: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 22-84: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 22-85: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 22-86: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 22-87: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 22-88: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 22-89: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 22-90: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 22-91: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 22-92: Loss: 0.0520 Acc: 75.0000%\n",
      "\tvalidation 22-93: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 22-94: Loss: 0.1341 Acc: 50.0000%\n",
      "\tvalidation 22-95: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 22-96: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 22-97: Loss: 0.0916 Acc: 75.0000%\n",
      "\tvalidation 22-98: Loss: 0.0665 Acc: 75.0000%\n",
      "\tvalidation 22-99: Loss: 0.2784 Acc: 75.0000%\n",
      "\tvalidation 22-100: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 22-101: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 22-102: Loss: 0.1932 Acc: 75.0000%\n",
      "\tvalidation 22-103: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-104: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 22-105: Loss: 0.3315 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0953 Acc: 86.2245%\n",
      "\tvalidation Loss: 0.0467 Acc: 92.6190%\n",
      "Time passed 0h 14m 37s\n",
      "--------------------\n",
      "Epoch [23/40]:\n",
      "\ttrain 23-1: Loss: 0.1408 Acc: 75.0000%\n",
      "\ttrain 23-2: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 23-3: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 23-4: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 23-5: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 23-6: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 23-7: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 23-8: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 23-9: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 23-10: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 23-11: Loss: 0.2660 Acc: 75.0000%\n",
      "\ttrain 23-12: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 23-13: Loss: 0.1425 Acc: 50.0000%\n",
      "\ttrain 23-14: Loss: 0.5142 Acc: 50.0000%\n",
      "\ttrain 23-15: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 23-16: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 23-17: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 23-18: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 23-19: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 23-20: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 23-21: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 23-22: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 23-23: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 23-24: Loss: 0.1726 Acc: 50.0000%\n",
      "\ttrain 23-25: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 23-26: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 23-27: Loss: 0.2258 Acc: 50.0000%\n",
      "\ttrain 23-28: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 23-29: Loss: 0.3000 Acc: 50.0000%\n",
      "\ttrain 23-30: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 23-31: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 23-32: Loss: 0.2702 Acc: 25.0000%\n",
      "\ttrain 23-33: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 23-34: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 23-35: Loss: 0.2863 Acc: 50.0000%\n",
      "\ttrain 23-36: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 23-37: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 23-38: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 23-39: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 23-40: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 23-41: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 23-42: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 23-43: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 23-44: Loss: 0.1891 Acc: 50.0000%\n",
      "\ttrain 23-45: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 23-46: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 23-47: Loss: 0.2617 Acc: 75.0000%\n",
      "\ttrain 23-48: Loss: 0.2221 Acc: 50.0000%\n",
      "\ttrain 23-49: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 23-50: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-51: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 23-52: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 23-53: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 23-54: Loss: 0.2685 Acc: 50.0000%\n",
      "\ttrain 23-55: Loss: 0.1728 Acc: 75.0000%\n",
      "\ttrain 23-56: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 23-57: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-58: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 23-59: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 23-60: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 23-61: Loss: 0.3978 Acc: 50.0000%\n",
      "\ttrain 23-62: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 23-63: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 23-64: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 23-65: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 23-66: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 23-67: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 23-68: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 23-69: Loss: 0.0768 Acc: 100.0000%\n",
      "\ttrain 23-70: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 23-71: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 23-72: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 23-73: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 23-74: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 23-75: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 23-76: Loss: 0.3896 Acc: 75.0000%\n",
      "\ttrain 23-77: Loss: 0.1711 Acc: 75.0000%\n",
      "\ttrain 23-78: Loss: 0.3106 Acc: 25.0000%\n",
      "\ttrain 23-79: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-80: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 23-81: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 23-82: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 23-83: Loss: 0.0842 Acc: 100.0000%\n",
      "\ttrain 23-84: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 23-85: Loss: 0.3748 Acc: 50.0000%\n",
      "\ttrain 23-86: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 23-87: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 23-88: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 23-89: Loss: 0.2457 Acc: 75.0000%\n",
      "\ttrain 23-90: Loss: 0.2144 Acc: 75.0000%\n",
      "\ttrain 23-91: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 23-92: Loss: 0.2255 Acc: 75.0000%\n",
      "\ttrain 23-93: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 23-94: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 23-95: Loss: 0.2711 Acc: 50.0000%\n",
      "\ttrain 23-96: Loss: 0.4744 Acc: 25.0000%\n",
      "\ttrain 23-97: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 23-98: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 23-99: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 23-100: Loss: 0.1731 Acc: 75.0000%\n",
      "\ttrain 23-101: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 23-102: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 23-103: Loss: 0.2104 Acc: 75.0000%\n",
      "\ttrain 23-104: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 23-105: Loss: 0.1593 Acc: 75.0000%\n",
      "\ttrain 23-106: Loss: 0.3920 Acc: 50.0000%\n",
      "\ttrain 23-107: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 23-108: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 23-109: Loss: 0.1665 Acc: 75.0000%\n",
      "\ttrain 23-110: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 23-111: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 23-112: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 23-113: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 23-114: Loss: 0.1450 Acc: 75.0000%\n",
      "\ttrain 23-115: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 23-116: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 23-117: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 23-118: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-119: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 23-120: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 23-121: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 23-122: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 23-123: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 23-124: Loss: 0.2932 Acc: 75.0000%\n",
      "\ttrain 23-125: Loss: 0.1705 Acc: 75.0000%\n",
      "\ttrain 23-126: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 23-127: Loss: 0.2096 Acc: 75.0000%\n",
      "\ttrain 23-128: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 23-129: Loss: 0.1392 Acc: 50.0000%\n",
      "\ttrain 23-130: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 23-131: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 23-132: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 23-133: Loss: 0.2293 Acc: 75.0000%\n",
      "\ttrain 23-134: Loss: 0.1271 Acc: 50.0000%\n",
      "\ttrain 23-135: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 23-136: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 23-137: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 23-138: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 23-139: Loss: 0.2669 Acc: 75.0000%\n",
      "\ttrain 23-140: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 23-141: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 23-142: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 23-143: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 23-144: Loss: 0.1094 Acc: 50.0000%\n",
      "\ttrain 23-145: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 23-146: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 23-147: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 23-148: Loss: 0.1938 Acc: 50.0000%\n",
      "\ttrain 23-149: Loss: 0.2069 Acc: 75.0000%\n",
      "\ttrain 23-150: Loss: 0.1379 Acc: 50.0000%\n",
      "\ttrain 23-151: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 23-152: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 23-153: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 23-154: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 23-155: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 23-156: Loss: 0.1864 Acc: 75.0000%\n",
      "\ttrain 23-157: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 23-158: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 23-159: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 23-160: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 23-161: Loss: 0.3127 Acc: 50.0000%\n",
      "\ttrain 23-162: Loss: 0.4620 Acc: 50.0000%\n",
      "\ttrain 23-163: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 23-164: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 23-165: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 23-166: Loss: 0.2589 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 23-167: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 23-168: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 23-169: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-170: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 23-171: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 23-172: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 23-173: Loss: 0.2121 Acc: 50.0000%\n",
      "\ttrain 23-174: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 23-175: Loss: 0.1122 Acc: 75.0000%\n",
      "\ttrain 23-176: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 23-177: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 23-178: Loss: 0.2954 Acc: 25.0000%\n",
      "\ttrain 23-179: Loss: 0.2871 Acc: 50.0000%\n",
      "\ttrain 23-180: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 23-181: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 23-182: Loss: 0.1705 Acc: 75.0000%\n",
      "\ttrain 23-183: Loss: 0.3624 Acc: 50.0000%\n",
      "\ttrain 23-184: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 23-185: Loss: 0.2324 Acc: 75.0000%\n",
      "\ttrain 23-186: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 23-187: Loss: 0.5667 Acc: 25.0000%\n",
      "\ttrain 23-188: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 23-189: Loss: 0.1555 Acc: 75.0000%\n",
      "\ttrain 23-190: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 23-191: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 23-192: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 23-193: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 23-194: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 23-195: Loss: 0.3538 Acc: 50.0000%\n",
      "\ttrain 23-196: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 23-197: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 23-198: Loss: 0.2511 Acc: 50.0000%\n",
      "\ttrain 23-199: Loss: 0.1517 Acc: 75.0000%\n",
      "\ttrain 23-200: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 23-201: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 23-202: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 23-203: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 23-204: Loss: 0.2635 Acc: 50.0000%\n",
      "\ttrain 23-205: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 23-206: Loss: 0.5903 Acc: 50.0000%\n",
      "\ttrain 23-207: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 23-208: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 23-209: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 23-210: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 23-211: Loss: 0.1581 Acc: 75.0000%\n",
      "\ttrain 23-212: Loss: 0.2740 Acc: 75.0000%\n",
      "\ttrain 23-213: Loss: 0.7014 Acc: 25.0000%\n",
      "\ttrain 23-214: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 23-215: Loss: 0.2032 Acc: 75.0000%\n",
      "\ttrain 23-216: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 23-217: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 23-218: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 23-219: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 23-220: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 23-221: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 23-222: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 23-223: Loss: 0.1027 Acc: 50.0000%\n",
      "\ttrain 23-224: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 23-225: Loss: 0.2102 Acc: 75.0000%\n",
      "\ttrain 23-226: Loss: 0.0659 Acc: 100.0000%\n",
      "\ttrain 23-227: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 23-228: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 23-229: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 23-230: Loss: 0.4504 Acc: 50.0000%\n",
      "\ttrain 23-231: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 23-232: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 23-233: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 23-234: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 23-235: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 23-236: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 23-237: Loss: 0.4903 Acc: 50.0000%\n",
      "\ttrain 23-238: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 23-239: Loss: 0.0776 Acc: 75.0000%\n",
      "\ttrain 23-240: Loss: 0.1519 Acc: 75.0000%\n",
      "\ttrain 23-241: Loss: 0.1380 Acc: 75.0000%\n",
      "\ttrain 23-242: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 23-243: Loss: 0.2219 Acc: 75.0000%\n",
      "\ttrain 23-244: Loss: 0.1824 Acc: 50.0000%\n",
      "\ttrain 23-245: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 23-1: Loss: 0.0818 Acc: 75.0000%\n",
      "\tvalidation 23-2: Loss: 0.0487 Acc: 75.0000%\n",
      "\tvalidation 23-3: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 23-4: Loss: 0.0826 Acc: 75.0000%\n",
      "\tvalidation 23-5: Loss: 1.6402 Acc: 75.0000%\n",
      "\tvalidation 23-6: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 23-7: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 23-8: Loss: 0.1273 Acc: 75.0000%\n",
      "\tvalidation 23-9: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 23-10: Loss: 0.1111 Acc: 75.0000%\n",
      "\tvalidation 23-11: Loss: 0.0973 Acc: 100.0000%\n",
      "\tvalidation 23-12: Loss: 0.1029 Acc: 75.0000%\n",
      "\tvalidation 23-13: Loss: 0.1766 Acc: 75.0000%\n",
      "\tvalidation 23-14: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 23-15: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-16: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 23-17: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 23-18: Loss: 0.3892 Acc: 25.0000%\n",
      "\tvalidation 23-19: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 23-20: Loss: 0.1223 Acc: 75.0000%\n",
      "\tvalidation 23-21: Loss: 0.0886 Acc: 75.0000%\n",
      "\tvalidation 23-22: Loss: 0.0967 Acc: 75.0000%\n",
      "\tvalidation 23-23: Loss: 0.2786 Acc: 25.0000%\n",
      "\tvalidation 23-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-25: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 23-26: Loss: 0.1404 Acc: 75.0000%\n",
      "\tvalidation 23-27: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 23-28: Loss: 0.1700 Acc: 75.0000%\n",
      "\tvalidation 23-29: Loss: 0.0547 Acc: 100.0000%\n",
      "\tvalidation 23-30: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 23-31: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 23-32: Loss: 0.1637 Acc: 75.0000%\n",
      "\tvalidation 23-33: Loss: 0.1465 Acc: 75.0000%\n",
      "\tvalidation 23-34: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 23-35: Loss: 0.1212 Acc: 75.0000%\n",
      "\tvalidation 23-36: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-37: Loss: 0.1844 Acc: 75.0000%\n",
      "\tvalidation 23-38: Loss: 0.4383 Acc: 50.0000%\n",
      "\tvalidation 23-39: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-40: Loss: 0.1657 Acc: 75.0000%\n",
      "\tvalidation 23-41: Loss: 0.1917 Acc: 75.0000%\n",
      "\tvalidation 23-42: Loss: 0.2202 Acc: 50.0000%\n",
      "\tvalidation 23-43: Loss: 0.1191 Acc: 75.0000%\n",
      "\tvalidation 23-44: Loss: 0.2039 Acc: 50.0000%\n",
      "\tvalidation 23-45: Loss: 0.1244 Acc: 75.0000%\n",
      "\tvalidation 23-46: Loss: 0.1374 Acc: 75.0000%\n",
      "\tvalidation 23-47: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 23-48: Loss: 0.2001 Acc: 75.0000%\n",
      "\tvalidation 23-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-50: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 23-51: Loss: 0.0859 Acc: 75.0000%\n",
      "\tvalidation 23-52: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 23-53: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 23-54: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 23-55: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-56: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-57: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 23-58: Loss: 0.3357 Acc: 75.0000%\n",
      "\tvalidation 23-59: Loss: 0.0456 Acc: 100.0000%\n",
      "\tvalidation 23-60: Loss: 0.0503 Acc: 100.0000%\n",
      "\tvalidation 23-61: Loss: 0.0525 Acc: 75.0000%\n",
      "\tvalidation 23-62: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 23-63: Loss: 0.2284 Acc: 50.0000%\n",
      "\tvalidation 23-64: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 23-65: Loss: 0.1459 Acc: 75.0000%\n",
      "\tvalidation 23-66: Loss: 0.1039 Acc: 75.0000%\n",
      "\tvalidation 23-67: Loss: 0.1130 Acc: 75.0000%\n",
      "\tvalidation 23-68: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 23-69: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 23-70: Loss: 0.3972 Acc: 75.0000%\n",
      "\tvalidation 23-71: Loss: 0.0567 Acc: 75.0000%\n",
      "\tvalidation 23-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 23-73: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-74: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-75: Loss: 2.3043 Acc: 75.0000%\n",
      "\tvalidation 23-76: Loss: 0.0640 Acc: 75.0000%\n",
      "\tvalidation 23-77: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 23-78: Loss: 0.1797 Acc: 75.0000%\n",
      "\tvalidation 23-79: Loss: 0.0923 Acc: 75.0000%\n",
      "\tvalidation 23-80: Loss: 0.0405 Acc: 100.0000%\n",
      "\tvalidation 23-81: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 23-82: Loss: 0.2910 Acc: 50.0000%\n",
      "\tvalidation 23-83: Loss: 0.0459 Acc: 75.0000%\n",
      "\tvalidation 23-84: Loss: 0.0890 Acc: 100.0000%\n",
      "\tvalidation 23-85: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-86: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-87: Loss: 1.5901 Acc: 50.0000%\n",
      "\tvalidation 23-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-89: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 23-90: Loss: 0.1930 Acc: 50.0000%\n",
      "\tvalidation 23-91: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 23-92: Loss: 0.2997 Acc: 50.0000%\n",
      "\tvalidation 23-93: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 23-94: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-95: Loss: 0.0758 Acc: 75.0000%\n",
      "\tvalidation 23-96: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 23-97: Loss: 0.1832 Acc: 75.0000%\n",
      "\tvalidation 23-98: Loss: 0.0805 Acc: 75.0000%\n",
      "\tvalidation 23-99: Loss: 0.2463 Acc: 75.0000%\n",
      "\tvalidation 23-100: Loss: 0.0416 Acc: 100.0000%\n",
      "\tvalidation 23-101: Loss: 0.1830 Acc: 50.0000%\n",
      "\tvalidation 23-102: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 23-103: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 23-104: Loss: 0.6887 Acc: 75.0000%\n",
      "\tvalidation 23-105: Loss: 0.1627 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1086 Acc: 83.7755%\n",
      "\tvalidation Loss: 0.1477 Acc: 83.3333%\n",
      "Time passed 0h 15m 17s\n",
      "--------------------\n",
      "Epoch [24/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-1: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 24-2: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 24-3: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 24-4: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 24-5: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 24-6: Loss: 0.1430 Acc: 75.0000%\n",
      "\ttrain 24-7: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 24-8: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 24-9: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-10: Loss: 0.3076 Acc: 50.0000%\n",
      "\ttrain 24-11: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 24-12: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 24-13: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 24-14: Loss: 0.0527 Acc: 75.0000%\n",
      "\ttrain 24-15: Loss: 0.2247 Acc: 75.0000%\n",
      "\ttrain 24-16: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 24-17: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 24-18: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 24-19: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 24-20: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 24-21: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 24-22: Loss: 0.2184 Acc: 75.0000%\n",
      "\ttrain 24-23: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 24-24: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 24-25: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 24-26: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 24-27: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 24-28: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 24-29: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 24-30: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 24-31: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 24-32: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 24-33: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 24-34: Loss: 0.2360 Acc: 75.0000%\n",
      "\ttrain 24-35: Loss: 0.1352 Acc: 75.0000%\n",
      "\ttrain 24-36: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 24-37: Loss: 0.1909 Acc: 75.0000%\n",
      "\ttrain 24-38: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 24-39: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 24-40: Loss: 0.3088 Acc: 75.0000%\n",
      "\ttrain 24-41: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 24-42: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 24-43: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-44: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 24-45: Loss: 0.0970 Acc: 100.0000%\n",
      "\ttrain 24-46: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 24-47: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 24-48: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 24-49: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 24-50: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 24-51: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 24-52: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 24-53: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 24-54: Loss: 0.1500 Acc: 50.0000%\n",
      "\ttrain 24-55: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 24-56: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 24-57: Loss: 0.4238 Acc: 75.0000%\n",
      "\ttrain 24-58: Loss: 0.0738 Acc: 75.0000%\n",
      "\ttrain 24-59: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 24-60: Loss: 0.1543 Acc: 75.0000%\n",
      "\ttrain 24-61: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 24-62: Loss: 0.4110 Acc: 25.0000%\n",
      "\ttrain 24-63: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 24-64: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 24-65: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 24-66: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-67: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 24-68: Loss: 0.5656 Acc: 50.0000%\n",
      "\ttrain 24-69: Loss: 0.1297 Acc: 50.0000%\n",
      "\ttrain 24-70: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 24-71: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 24-72: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 24-73: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-74: Loss: 0.1664 Acc: 50.0000%\n",
      "\ttrain 24-75: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 24-76: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 24-77: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 24-78: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 24-79: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 24-80: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 24-81: Loss: 0.1701 Acc: 75.0000%\n",
      "\ttrain 24-82: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 24-83: Loss: 0.1664 Acc: 75.0000%\n",
      "\ttrain 24-84: Loss: 0.0540 Acc: 75.0000%\n",
      "\ttrain 24-85: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 24-86: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 24-87: Loss: 0.0833 Acc: 75.0000%\n",
      "\ttrain 24-88: Loss: 0.3702 Acc: 25.0000%\n",
      "\ttrain 24-89: Loss: 0.3653 Acc: 75.0000%\n",
      "\ttrain 24-90: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 24-91: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 24-92: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 24-93: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 24-94: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 24-95: Loss: 0.2165 Acc: 50.0000%\n",
      "\ttrain 24-96: Loss: 0.2697 Acc: 50.0000%\n",
      "\ttrain 24-97: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 24-98: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 24-99: Loss: 0.0788 Acc: 75.0000%\n",
      "\ttrain 24-100: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 24-101: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 24-102: Loss: 0.3334 Acc: 25.0000%\n",
      "\ttrain 24-103: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 24-104: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 24-105: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 24-106: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 24-107: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 24-108: Loss: 0.2021 Acc: 75.0000%\n",
      "\ttrain 24-109: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 24-110: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 24-111: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 24-112: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 24-113: Loss: 0.2284 Acc: 50.0000%\n",
      "\ttrain 24-114: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 24-115: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 24-116: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 24-117: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 24-118: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 24-119: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 24-120: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 24-121: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 24-122: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 24-123: Loss: 0.2171 Acc: 75.0000%\n",
      "\ttrain 24-124: Loss: 0.2820 Acc: 75.0000%\n",
      "\ttrain 24-125: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 24-126: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 24-127: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 24-128: Loss: 0.3469 Acc: 50.0000%\n",
      "\ttrain 24-129: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 24-130: Loss: 0.2571 Acc: 50.0000%\n",
      "\ttrain 24-131: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 24-132: Loss: 0.1825 Acc: 50.0000%\n",
      "\ttrain 24-133: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 24-134: Loss: 0.1887 Acc: 75.0000%\n",
      "\ttrain 24-135: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 24-136: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 24-137: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 24-138: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 24-139: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 24-140: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 24-141: Loss: 0.0643 Acc: 100.0000%\n",
      "\ttrain 24-142: Loss: 0.2617 Acc: 50.0000%\n",
      "\ttrain 24-143: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 24-144: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 24-145: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 24-146: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 24-147: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 24-148: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 24-149: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 24-150: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 24-151: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 24-152: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 24-153: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 24-154: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-155: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 24-156: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 24-157: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 24-158: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 24-159: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 24-160: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 24-161: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 24-162: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 24-163: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 24-164: Loss: 0.1405 Acc: 75.0000%\n",
      "\ttrain 24-165: Loss: 0.2182 Acc: 50.0000%\n",
      "\ttrain 24-166: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 24-167: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-168: Loss: 0.3375 Acc: 50.0000%\n",
      "\ttrain 24-169: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 24-170: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 24-171: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 24-172: Loss: 0.4659 Acc: 50.0000%\n",
      "\ttrain 24-173: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 24-174: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 24-175: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 24-176: Loss: 0.4116 Acc: 50.0000%\n",
      "\ttrain 24-177: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 24-178: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 24-179: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 24-180: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 24-181: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 24-182: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 24-183: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 24-184: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 24-185: Loss: 0.2103 Acc: 75.0000%\n",
      "\ttrain 24-186: Loss: 0.2303 Acc: 50.0000%\n",
      "\ttrain 24-187: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-188: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 24-189: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 24-190: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 24-191: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 24-192: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 24-193: Loss: 0.1212 Acc: 50.0000%\n",
      "\ttrain 24-194: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 24-195: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 24-196: Loss: 0.3553 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-197: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 24-198: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 24-199: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 24-200: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 24-201: Loss: 0.4951 Acc: 0.0000%\n",
      "\ttrain 24-202: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 24-203: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 24-204: Loss: 0.2789 Acc: 25.0000%\n",
      "\ttrain 24-205: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 24-206: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 24-207: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 24-208: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-209: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 24-210: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 24-211: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 24-212: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 24-213: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-214: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 24-215: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 24-216: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 24-217: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 24-218: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 24-219: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 24-220: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 24-221: Loss: 0.2097 Acc: 50.0000%\n",
      "\ttrain 24-222: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 24-223: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 24-224: Loss: 0.3686 Acc: 50.0000%\n",
      "\ttrain 24-225: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 24-226: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 24-227: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-228: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 24-229: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 24-230: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 24-231: Loss: 0.3113 Acc: 75.0000%\n",
      "\ttrain 24-232: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 24-233: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 24-234: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 24-235: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 24-236: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 24-237: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 24-238: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 24-239: Loss: 0.1485 Acc: 75.0000%\n",
      "\ttrain 24-240: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 24-241: Loss: 0.2176 Acc: 75.0000%\n",
      "\ttrain 24-242: Loss: 0.4443 Acc: 25.0000%\n",
      "\ttrain 24-243: Loss: 0.1049 Acc: 75.0000%\n",
      "\ttrain 24-244: Loss: 0.1574 Acc: 75.0000%\n",
      "\ttrain 24-245: Loss: 0.1032 Acc: 75.0000%\n",
      "\tvalidation 24-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-2: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 24-3: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 24-4: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 24-5: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 24-6: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 24-7: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 24-8: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 24-9: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-10: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 24-11: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-12: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-13: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 24-14: Loss: 0.0604 Acc: 100.0000%\n",
      "\tvalidation 24-15: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 24-16: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 24-17: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 24-18: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-19: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-20: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 24-21: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 24-22: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 24-23: Loss: 0.1629 Acc: 75.0000%\n",
      "\tvalidation 24-24: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 24-25: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-26: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 24-27: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 24-28: Loss: 0.2790 Acc: 75.0000%\n",
      "\tvalidation 24-29: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-31: Loss: 0.4746 Acc: 75.0000%\n",
      "\tvalidation 24-32: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 24-33: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 24-34: Loss: 0.0783 Acc: 75.0000%\n",
      "\tvalidation 24-35: Loss: 0.0501 Acc: 75.0000%\n",
      "\tvalidation 24-36: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 24-37: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 24-38: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-39: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 24-40: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 24-41: Loss: 0.3971 Acc: 75.0000%\n",
      "\tvalidation 24-42: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 24-43: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-44: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 24-45: Loss: 1.2082 Acc: 75.0000%\n",
      "\tvalidation 24-46: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-47: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-48: Loss: 0.0483 Acc: 100.0000%\n",
      "\tvalidation 24-49: Loss: 0.1549 Acc: 75.0000%\n",
      "\tvalidation 24-50: Loss: 0.2808 Acc: 50.0000%\n",
      "\tvalidation 24-51: Loss: 0.2038 Acc: 75.0000%\n",
      "\tvalidation 24-52: Loss: 0.0657 Acc: 75.0000%\n",
      "\tvalidation 24-53: Loss: 0.1199 Acc: 75.0000%\n",
      "\tvalidation 24-54: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 24-55: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 24-56: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 24-57: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 24-58: Loss: 0.1198 Acc: 75.0000%\n",
      "\tvalidation 24-59: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-60: Loss: 0.0550 Acc: 100.0000%\n",
      "\tvalidation 24-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-62: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 24-63: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 24-64: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 24-65: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 24-66: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 24-67: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 24-68: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 24-69: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 24-70: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 24-71: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 24-72: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 24-73: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 24-74: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 24-75: Loss: 0.1096 Acc: 75.0000%\n",
      "\tvalidation 24-76: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 24-77: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 24-78: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-79: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 24-80: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 24-81: Loss: 0.6094 Acc: 50.0000%\n",
      "\tvalidation 24-82: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-83: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 24-84: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 24-85: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-86: Loss: 0.0637 Acc: 75.0000%\n",
      "\tvalidation 24-87: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-88: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 24-89: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 24-90: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 24-91: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 24-92: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 24-93: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 24-94: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 24-95: Loss: 0.1691 Acc: 75.0000%\n",
      "\tvalidation 24-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-97: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 24-98: Loss: 0.1247 Acc: 75.0000%\n",
      "\tvalidation 24-99: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 24-100: Loss: 0.0802 Acc: 100.0000%\n",
      "\tvalidation 24-101: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 24-102: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 24-103: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 24-104: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 24-105: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0946 Acc: 85.2041%\n",
      "\tvalidation Loss: 0.0527 Acc: 95.0000%\n",
      "Time passed 0h 15m 55s\n",
      "--------------------\n",
      "Epoch [25/40]:\n",
      "\ttrain 25-1: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 25-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 25-3: Loss: 0.2998 Acc: 50.0000%\n",
      "\ttrain 25-4: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 25-5: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 25-6: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 25-7: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 25-8: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 25-9: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 25-10: Loss: 0.0800 Acc: 100.0000%\n",
      "\ttrain 25-11: Loss: 0.3936 Acc: 50.0000%\n",
      "\ttrain 25-12: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 25-13: Loss: 0.1501 Acc: 50.0000%\n",
      "\ttrain 25-14: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 25-15: Loss: 0.5278 Acc: 50.0000%\n",
      "\ttrain 25-16: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 25-17: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 25-18: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-19: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 25-20: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 25-21: Loss: 0.1932 Acc: 75.0000%\n",
      "\ttrain 25-22: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 25-23: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 25-24: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-25: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 25-26: Loss: 0.2017 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-27: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-28: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 25-29: Loss: 0.5347 Acc: 50.0000%\n",
      "\ttrain 25-30: Loss: 0.3594 Acc: 50.0000%\n",
      "\ttrain 25-31: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 25-32: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 25-33: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 25-34: Loss: 0.1419 Acc: 50.0000%\n",
      "\ttrain 25-35: Loss: 0.3309 Acc: 50.0000%\n",
      "\ttrain 25-36: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 25-37: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 25-38: Loss: 0.1497 Acc: 75.0000%\n",
      "\ttrain 25-39: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 25-40: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 25-41: Loss: 0.3651 Acc: 50.0000%\n",
      "\ttrain 25-42: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 25-43: Loss: 0.6479 Acc: 25.0000%\n",
      "\ttrain 25-44: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 25-45: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 25-46: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 25-47: Loss: 0.7045 Acc: 50.0000%\n",
      "\ttrain 25-48: Loss: 0.6628 Acc: 25.0000%\n",
      "\ttrain 25-49: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 25-50: Loss: 0.3764 Acc: 75.0000%\n",
      "\ttrain 25-51: Loss: 0.3859 Acc: 75.0000%\n",
      "\ttrain 25-52: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 25-53: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 25-54: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-55: Loss: 0.2865 Acc: 75.0000%\n",
      "\ttrain 25-56: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 25-57: Loss: 0.1906 Acc: 75.0000%\n",
      "\ttrain 25-58: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 25-59: Loss: 0.4513 Acc: 50.0000%\n",
      "\ttrain 25-60: Loss: 0.2200 Acc: 50.0000%\n",
      "\ttrain 25-61: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 25-62: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 25-63: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 25-64: Loss: 0.1976 Acc: 75.0000%\n",
      "\ttrain 25-65: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 25-66: Loss: 0.0617 Acc: 100.0000%\n",
      "\ttrain 25-67: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 25-68: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 25-69: Loss: 0.2263 Acc: 75.0000%\n",
      "\ttrain 25-70: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 25-71: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 25-72: Loss: 0.0766 Acc: 100.0000%\n",
      "\ttrain 25-73: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 25-74: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 25-75: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 25-76: Loss: 0.1936 Acc: 75.0000%\n",
      "\ttrain 25-77: Loss: 0.2678 Acc: 75.0000%\n",
      "\ttrain 25-78: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 25-79: Loss: 0.2063 Acc: 50.0000%\n",
      "\ttrain 25-80: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 25-81: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 25-82: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 25-83: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 25-84: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 25-85: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 25-86: Loss: 0.4399 Acc: 50.0000%\n",
      "\ttrain 25-87: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 25-88: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 25-89: Loss: 0.2429 Acc: 75.0000%\n",
      "\ttrain 25-90: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 25-91: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 25-92: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 25-93: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 25-94: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 25-95: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-96: Loss: 0.0691 Acc: 100.0000%\n",
      "\ttrain 25-97: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 25-98: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 25-99: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 25-100: Loss: 0.0863 Acc: 100.0000%\n",
      "\ttrain 25-101: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 25-102: Loss: 0.2190 Acc: 50.0000%\n",
      "\ttrain 25-103: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 25-104: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 25-105: Loss: 0.2440 Acc: 50.0000%\n",
      "\ttrain 25-106: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 25-107: Loss: 0.2100 Acc: 50.0000%\n",
      "\ttrain 25-108: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 25-109: Loss: 0.1830 Acc: 50.0000%\n",
      "\ttrain 25-110: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 25-111: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 25-112: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 25-113: Loss: 0.0897 Acc: 100.0000%\n",
      "\ttrain 25-114: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 25-115: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 25-116: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 25-117: Loss: 0.2240 Acc: 50.0000%\n",
      "\ttrain 25-118: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 25-119: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 25-120: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 25-121: Loss: 0.2709 Acc: 75.0000%\n",
      "\ttrain 25-122: Loss: 0.2301 Acc: 75.0000%\n",
      "\ttrain 25-123: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 25-124: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 25-125: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 25-126: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 25-127: Loss: 0.0939 Acc: 75.0000%\n",
      "\ttrain 25-128: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 25-129: Loss: 0.2829 Acc: 75.0000%\n",
      "\ttrain 25-130: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 25-131: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 25-132: Loss: 0.0751 Acc: 100.0000%\n",
      "\ttrain 25-133: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 25-134: Loss: 0.4355 Acc: 25.0000%\n",
      "\ttrain 25-135: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 25-136: Loss: 0.0711 Acc: 100.0000%\n",
      "\ttrain 25-137: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 25-138: Loss: 0.0742 Acc: 75.0000%\n",
      "\ttrain 25-139: Loss: 0.2331 Acc: 75.0000%\n",
      "\ttrain 25-140: Loss: 0.3927 Acc: 50.0000%\n",
      "\ttrain 25-141: Loss: 0.0970 Acc: 75.0000%\n",
      "\ttrain 25-142: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-143: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 25-144: Loss: 0.3197 Acc: 75.0000%\n",
      "\ttrain 25-145: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 25-146: Loss: 0.2131 Acc: 75.0000%\n",
      "\ttrain 25-147: Loss: 0.1160 Acc: 75.0000%\n",
      "\ttrain 25-148: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 25-149: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 25-150: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 25-151: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 25-152: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 25-153: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 25-154: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 25-155: Loss: 0.1036 Acc: 100.0000%\n",
      "\ttrain 25-156: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 25-157: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 25-158: Loss: 0.0564 Acc: 75.0000%\n",
      "\ttrain 25-159: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 25-160: Loss: 0.2859 Acc: 75.0000%\n",
      "\ttrain 25-161: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 25-162: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 25-163: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 25-164: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 25-165: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 25-166: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 25-167: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 25-168: Loss: 0.6416 Acc: 25.0000%\n",
      "\ttrain 25-169: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 25-170: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 25-171: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 25-172: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 25-173: Loss: 0.0506 Acc: 75.0000%\n",
      "\ttrain 25-174: Loss: 0.5523 Acc: 25.0000%\n",
      "\ttrain 25-175: Loss: 0.1741 Acc: 75.0000%\n",
      "\ttrain 25-176: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 25-177: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 25-178: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-179: Loss: 0.4815 Acc: 50.0000%\n",
      "\ttrain 25-180: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 25-181: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 25-182: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 25-183: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 25-184: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 25-185: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 25-186: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 25-187: Loss: 0.0746 Acc: 75.0000%\n",
      "\ttrain 25-188: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 25-189: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 25-190: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 25-191: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 25-192: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 25-193: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 25-194: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 25-195: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 25-196: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 25-197: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 25-198: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 25-199: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 25-200: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 25-201: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 25-202: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 25-203: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 25-204: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 25-205: Loss: 0.0817 Acc: 100.0000%\n",
      "\ttrain 25-206: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 25-207: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 25-208: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 25-209: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 25-210: Loss: 0.1406 Acc: 75.0000%\n",
      "\ttrain 25-211: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 25-212: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 25-213: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 25-214: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 25-215: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 25-216: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 25-217: Loss: 0.2160 Acc: 75.0000%\n",
      "\ttrain 25-218: Loss: 0.3836 Acc: 50.0000%\n",
      "\ttrain 25-219: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 25-220: Loss: 0.2230 Acc: 75.0000%\n",
      "\ttrain 25-221: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 25-222: Loss: 0.0599 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-223: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 25-224: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 25-225: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 25-226: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 25-227: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 25-228: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 25-229: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 25-230: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 25-231: Loss: 0.3047 Acc: 50.0000%\n",
      "\ttrain 25-232: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 25-233: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 25-234: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 25-235: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 25-236: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 25-237: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 25-238: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 25-239: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 25-240: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 25-241: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 25-242: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 25-243: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 25-244: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 25-245: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 25-1: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 25-2: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 25-3: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 25-4: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-5: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 25-6: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-7: Loss: 0.0483 Acc: 75.0000%\n",
      "\tvalidation 25-8: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 25-9: Loss: 0.0453 Acc: 100.0000%\n",
      "\tvalidation 25-10: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 25-11: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-12: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 25-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-14: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 25-15: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 25-16: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 25-17: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-18: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 25-19: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 25-20: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 25-21: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-22: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 25-23: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 25-24: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 25-25: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 25-26: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 25-27: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 25-28: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 25-29: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 25-30: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 25-31: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 25-32: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 25-33: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 25-34: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 25-35: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-36: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 25-37: Loss: 0.1551 Acc: 75.0000%\n",
      "\tvalidation 25-38: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 25-39: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 25-40: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 25-41: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 25-42: Loss: 2.0807 Acc: 75.0000%\n",
      "\tvalidation 25-43: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-44: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 25-45: Loss: 0.0492 Acc: 75.0000%\n",
      "\tvalidation 25-46: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 25-47: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-48: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-49: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 25-50: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 25-51: Loss: 0.0227 Acc: 100.0000%\n",
      "\tvalidation 25-52: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 25-53: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-54: Loss: 0.0746 Acc: 75.0000%\n",
      "\tvalidation 25-55: Loss: 0.3242 Acc: 75.0000%\n",
      "\tvalidation 25-56: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 25-57: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 25-58: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-59: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 25-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 25-61: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 25-62: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 25-63: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 25-64: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 25-65: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 25-66: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 25-67: Loss: 0.1159 Acc: 75.0000%\n",
      "\tvalidation 25-68: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 25-69: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 25-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 25-72: Loss: 0.1734 Acc: 75.0000%\n",
      "\tvalidation 25-73: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 25-74: Loss: 1.4396 Acc: 75.0000%\n",
      "\tvalidation 25-75: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 25-76: Loss: 0.0610 Acc: 75.0000%\n",
      "\tvalidation 25-77: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 25-78: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 25-79: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 25-80: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 25-81: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 25-82: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 25-83: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 25-84: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 25-85: Loss: 1.1393 Acc: 75.0000%\n",
      "\tvalidation 25-86: Loss: 0.5061 Acc: 75.0000%\n",
      "\tvalidation 25-87: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 25-88: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 25-89: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 25-90: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 25-91: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 25-92: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 25-93: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 25-94: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 25-95: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 25-96: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 25-97: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 25-98: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 25-99: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 25-100: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 25-101: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 25-102: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 25-103: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 25-104: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 25-105: Loss: 0.0459 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1055 Acc: 85.2041%\n",
      "\tvalidation Loss: 0.0679 Acc: 96.9048%\n",
      "Time passed 0h 16m 34s\n",
      "--------------------\n",
      "Epoch [26/40]:\n",
      "\ttrain 26-1: Loss: 0.2698 Acc: 50.0000%\n",
      "\ttrain 26-2: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 26-3: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 26-4: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 26-5: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 26-6: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 26-7: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 26-8: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 26-9: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 26-10: Loss: 0.3473 Acc: 50.0000%\n",
      "\ttrain 26-11: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 26-12: Loss: 0.1890 Acc: 75.0000%\n",
      "\ttrain 26-13: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 26-14: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 26-15: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 26-16: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 26-17: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 26-18: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 26-19: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 26-20: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 26-21: Loss: 0.1924 Acc: 75.0000%\n",
      "\ttrain 26-22: Loss: 0.1601 Acc: 75.0000%\n",
      "\ttrain 26-23: Loss: 0.2455 Acc: 75.0000%\n",
      "\ttrain 26-24: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 26-25: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 26-26: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 26-27: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 26-28: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 26-29: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 26-30: Loss: 0.1387 Acc: 50.0000%\n",
      "\ttrain 26-31: Loss: 0.1554 Acc: 75.0000%\n",
      "\ttrain 26-32: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 26-33: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 26-34: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 26-35: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 26-36: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 26-37: Loss: 0.3207 Acc: 75.0000%\n",
      "\ttrain 26-38: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 26-39: Loss: 0.1350 Acc: 75.0000%\n",
      "\ttrain 26-40: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 26-41: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 26-42: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 26-43: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-44: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 26-45: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 26-46: Loss: 0.1365 Acc: 50.0000%\n",
      "\ttrain 26-47: Loss: 0.2770 Acc: 75.0000%\n",
      "\ttrain 26-48: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 26-49: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 26-50: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 26-51: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 26-52: Loss: 0.1189 Acc: 100.0000%\n",
      "\ttrain 26-53: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 26-54: Loss: 1.0010 Acc: 0.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-55: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 26-56: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 26-57: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 26-58: Loss: 0.1749 Acc: 75.0000%\n",
      "\ttrain 26-59: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 26-60: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 26-61: Loss: 0.8761 Acc: 50.0000%\n",
      "\ttrain 26-62: Loss: 0.5552 Acc: 50.0000%\n",
      "\ttrain 26-63: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 26-64: Loss: 0.2548 Acc: 75.0000%\n",
      "\ttrain 26-65: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 26-66: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 26-67: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 26-68: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 26-69: Loss: 0.3910 Acc: 75.0000%\n",
      "\ttrain 26-70: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 26-71: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 26-72: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 26-73: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 26-74: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 26-75: Loss: 0.6381 Acc: 25.0000%\n",
      "\ttrain 26-76: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 26-77: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 26-78: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 26-79: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 26-80: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 26-81: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 26-82: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 26-83: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 26-84: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 26-85: Loss: 0.1942 Acc: 75.0000%\n",
      "\ttrain 26-86: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 26-87: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 26-88: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 26-89: Loss: 0.3386 Acc: 50.0000%\n",
      "\ttrain 26-90: Loss: 0.0937 Acc: 100.0000%\n",
      "\ttrain 26-91: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 26-92: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 26-93: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 26-94: Loss: 0.1225 Acc: 100.0000%\n",
      "\ttrain 26-95: Loss: 0.0651 Acc: 100.0000%\n",
      "\ttrain 26-96: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 26-97: Loss: 0.0819 Acc: 75.0000%\n",
      "\ttrain 26-98: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 26-99: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 26-100: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 26-101: Loss: 0.2206 Acc: 50.0000%\n",
      "\ttrain 26-102: Loss: 0.1571 Acc: 50.0000%\n",
      "\ttrain 26-103: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 26-104: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 26-105: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 26-106: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 26-107: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 26-108: Loss: 0.1589 Acc: 50.0000%\n",
      "\ttrain 26-109: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 26-110: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 26-111: Loss: 0.3094 Acc: 25.0000%\n",
      "\ttrain 26-112: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 26-113: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 26-114: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 26-115: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 26-116: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 26-117: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 26-118: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 26-119: Loss: 0.2336 Acc: 75.0000%\n",
      "\ttrain 26-120: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 26-121: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 26-122: Loss: 0.1311 Acc: 100.0000%\n",
      "\ttrain 26-123: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 26-124: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 26-125: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-126: Loss: 0.1477 Acc: 75.0000%\n",
      "\ttrain 26-127: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 26-128: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 26-129: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 26-130: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-131: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 26-132: Loss: 0.3644 Acc: 50.0000%\n",
      "\ttrain 26-133: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 26-134: Loss: 0.2056 Acc: 75.0000%\n",
      "\ttrain 26-135: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 26-136: Loss: 0.3916 Acc: 50.0000%\n",
      "\ttrain 26-137: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 26-138: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 26-139: Loss: 0.3096 Acc: 75.0000%\n",
      "\ttrain 26-140: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 26-141: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 26-142: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 26-143: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 26-144: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 26-145: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 26-146: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 26-147: Loss: 0.2521 Acc: 75.0000%\n",
      "\ttrain 26-148: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 26-149: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 26-150: Loss: 0.3509 Acc: 75.0000%\n",
      "\ttrain 26-151: Loss: 0.0690 Acc: 100.0000%\n",
      "\ttrain 26-152: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 26-153: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 26-154: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 26-155: Loss: 0.5843 Acc: 0.0000%\n",
      "\ttrain 26-156: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 26-157: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 26-158: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 26-159: Loss: 0.1571 Acc: 50.0000%\n",
      "\ttrain 26-160: Loss: 0.7203 Acc: 0.0000%\n",
      "\ttrain 26-161: Loss: 0.0915 Acc: 75.0000%\n",
      "\ttrain 26-162: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 26-163: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-164: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 26-165: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 26-166: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 26-167: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 26-168: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 26-169: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 26-170: Loss: 0.0737 Acc: 100.0000%\n",
      "\ttrain 26-171: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 26-172: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-173: Loss: 0.1429 Acc: 75.0000%\n",
      "\ttrain 26-174: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 26-175: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 26-176: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 26-177: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 26-178: Loss: 0.1823 Acc: 75.0000%\n",
      "\ttrain 26-179: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-180: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 26-181: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 26-182: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 26-183: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 26-184: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 26-185: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 26-186: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 26-187: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 26-188: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 26-189: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 26-190: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 26-191: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 26-192: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 26-193: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 26-194: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 26-195: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 26-196: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 26-197: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 26-198: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 26-199: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 26-200: Loss: 0.2185 Acc: 75.0000%\n",
      "\ttrain 26-201: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 26-202: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 26-203: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 26-204: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 26-205: Loss: 0.0677 Acc: 75.0000%\n",
      "\ttrain 26-206: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 26-207: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 26-208: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 26-209: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 26-210: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 26-211: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 26-212: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 26-213: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 26-214: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 26-215: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 26-216: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 26-217: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 26-218: Loss: 0.3200 Acc: 75.0000%\n",
      "\ttrain 26-219: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 26-220: Loss: 0.1123 Acc: 75.0000%\n",
      "\ttrain 26-221: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 26-222: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 26-223: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 26-224: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 26-225: Loss: 0.0827 Acc: 100.0000%\n",
      "\ttrain 26-226: Loss: 0.1806 Acc: 75.0000%\n",
      "\ttrain 26-227: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 26-228: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 26-229: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 26-230: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 26-231: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 26-232: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 26-233: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 26-234: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 26-235: Loss: 0.2036 Acc: 75.0000%\n",
      "\ttrain 26-236: Loss: 0.2551 Acc: 75.0000%\n",
      "\ttrain 26-237: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 26-238: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 26-239: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 26-240: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 26-241: Loss: 0.0529 Acc: 75.0000%\n",
      "\ttrain 26-242: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 26-243: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 26-244: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 26-245: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 26-1: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-2: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 26-3: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-4: Loss: 0.0524 Acc: 100.0000%\n",
      "\tvalidation 26-5: Loss: 0.0048 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 26-6: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-7: Loss: 5.1701 Acc: 75.0000%\n",
      "\tvalidation 26-8: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 26-9: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 26-10: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-11: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 26-12: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 26-13: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 26-14: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 26-15: Loss: 5.3777 Acc: 75.0000%\n",
      "\tvalidation 26-16: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 26-17: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 26-18: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-19: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 26-20: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 26-21: Loss: 0.0204 Acc: 100.0000%\n",
      "\tvalidation 26-22: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-23: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 26-24: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 26-25: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 26-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-27: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 26-28: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-29: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 26-30: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-31: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 26-32: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 26-33: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 26-34: Loss: 0.4587 Acc: 75.0000%\n",
      "\tvalidation 26-35: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 26-36: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-37: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 26-38: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 26-39: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 26-40: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 26-41: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 26-42: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 26-43: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 26-44: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-45: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-46: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-47: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 26-48: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 26-49: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 26-50: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 26-51: Loss: 0.2516 Acc: 75.0000%\n",
      "\tvalidation 26-52: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 26-53: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-54: Loss: 2.0627 Acc: 50.0000%\n",
      "\tvalidation 26-55: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 26-56: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 26-57: Loss: 2.1014 Acc: 75.0000%\n",
      "\tvalidation 26-58: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-59: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-60: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-61: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 26-62: Loss: 0.7560 Acc: 75.0000%\n",
      "\tvalidation 26-63: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-64: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-65: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-66: Loss: 7.1595 Acc: 75.0000%\n",
      "\tvalidation 26-67: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 26-68: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 26-69: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 26-70: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 26-71: Loss: 1.2721 Acc: 75.0000%\n",
      "\tvalidation 26-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-73: Loss: 0.1852 Acc: 75.0000%\n",
      "\tvalidation 26-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 26-75: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 26-77: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-78: Loss: 1.6439 Acc: 75.0000%\n",
      "\tvalidation 26-79: Loss: 0.3588 Acc: 75.0000%\n",
      "\tvalidation 26-80: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 26-81: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 26-82: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-83: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 26-84: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 26-85: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 26-86: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-88: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 26-89: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-90: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 26-91: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-92: Loss: 1.1736 Acc: 75.0000%\n",
      "\tvalidation 26-93: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-94: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 26-95: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 26-96: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 26-97: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 26-98: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-99: Loss: 0.7341 Acc: 75.0000%\n",
      "\tvalidation 26-100: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 26-101: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 26-102: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-103: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 26-104: Loss: 0.1058 Acc: 75.0000%\n",
      "\tvalidation 26-105: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0899 Acc: 87.7551%\n",
      "\tvalidation Loss: 0.2811 Acc: 96.1905%\n",
      "Time passed 0h 17m 14s\n",
      "--------------------\n",
      "Epoch [27/40]:\n",
      "\ttrain 27-1: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 27-2: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 27-3: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-4: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 27-5: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 27-6: Loss: 0.2109 Acc: 75.0000%\n",
      "\ttrain 27-7: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 27-8: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 27-9: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 27-10: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 27-11: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 27-12: Loss: 0.4434 Acc: 50.0000%\n",
      "\ttrain 27-13: Loss: 0.1383 Acc: 75.0000%\n",
      "\ttrain 27-14: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 27-15: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 27-16: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 27-17: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 27-18: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 27-19: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 27-20: Loss: 0.0592 Acc: 100.0000%\n",
      "\ttrain 27-21: Loss: 0.0611 Acc: 75.0000%\n",
      "\ttrain 27-22: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 27-23: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 27-24: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 27-25: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 27-26: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 27-27: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 27-28: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 27-29: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 27-30: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 27-31: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-32: Loss: 0.2121 Acc: 75.0000%\n",
      "\ttrain 27-33: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 27-34: Loss: 0.3016 Acc: 50.0000%\n",
      "\ttrain 27-35: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 27-36: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 27-37: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 27-38: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 27-39: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 27-40: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 27-41: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 27-42: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 27-43: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 27-44: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 27-45: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 27-46: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 27-47: Loss: 0.0677 Acc: 75.0000%\n",
      "\ttrain 27-48: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 27-49: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 27-50: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 27-51: Loss: 0.1650 Acc: 75.0000%\n",
      "\ttrain 27-52: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 27-53: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 27-54: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-55: Loss: 0.1432 Acc: 50.0000%\n",
      "\ttrain 27-56: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 27-57: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 27-58: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 27-59: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 27-60: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-61: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 27-62: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 27-63: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 27-64: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 27-65: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 27-66: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 27-67: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 27-68: Loss: 0.2433 Acc: 75.0000%\n",
      "\ttrain 27-69: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-70: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 27-71: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 27-72: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 27-73: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 27-74: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 27-75: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 27-76: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 27-77: Loss: 0.4364 Acc: 75.0000%\n",
      "\ttrain 27-78: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 27-79: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 27-80: Loss: 0.2257 Acc: 75.0000%\n",
      "\ttrain 27-81: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 27-82: Loss: 0.0137 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-83: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-84: Loss: 0.0565 Acc: 100.0000%\n",
      "\ttrain 27-85: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 27-86: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-87: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 27-88: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 27-89: Loss: 0.2237 Acc: 50.0000%\n",
      "\ttrain 27-90: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 27-91: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 27-92: Loss: 0.0519 Acc: 75.0000%\n",
      "\ttrain 27-93: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 27-94: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 27-95: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 27-96: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 27-97: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 27-98: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 27-99: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-100: Loss: 0.2548 Acc: 75.0000%\n",
      "\ttrain 27-101: Loss: 0.2382 Acc: 75.0000%\n",
      "\ttrain 27-102: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 27-103: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 27-104: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-105: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 27-106: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 27-107: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 27-108: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 27-109: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 27-110: Loss: 0.1532 Acc: 75.0000%\n",
      "\ttrain 27-111: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 27-112: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-113: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 27-114: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 27-115: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 27-116: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 27-117: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 27-118: Loss: 0.0910 Acc: 100.0000%\n",
      "\ttrain 27-119: Loss: 0.8221 Acc: 25.0000%\n",
      "\ttrain 27-120: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 27-121: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-122: Loss: 1.1024 Acc: 0.0000%\n",
      "\ttrain 27-123: Loss: 0.0690 Acc: 100.0000%\n",
      "\ttrain 27-124: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 27-125: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 27-126: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 27-127: Loss: 0.3658 Acc: 50.0000%\n",
      "\ttrain 27-128: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 27-129: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-130: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 27-131: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 27-132: Loss: 0.3502 Acc: 75.0000%\n",
      "\ttrain 27-133: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 27-134: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 27-135: Loss: 0.2491 Acc: 75.0000%\n",
      "\ttrain 27-136: Loss: 0.1550 Acc: 75.0000%\n",
      "\ttrain 27-137: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 27-138: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 27-139: Loss: 0.1089 Acc: 75.0000%\n",
      "\ttrain 27-140: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 27-141: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 27-142: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 27-143: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 27-144: Loss: 0.3352 Acc: 75.0000%\n",
      "\ttrain 27-145: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 27-146: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 27-147: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 27-148: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 27-149: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 27-150: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 27-151: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 27-152: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 27-153: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 27-154: Loss: 0.7336 Acc: 50.0000%\n",
      "\ttrain 27-155: Loss: 0.2842 Acc: 75.0000%\n",
      "\ttrain 27-156: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 27-157: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 27-158: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 27-159: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-160: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 27-161: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 27-162: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 27-163: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 27-164: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 27-165: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 27-166: Loss: 0.0676 Acc: 100.0000%\n",
      "\ttrain 27-167: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 27-168: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 27-169: Loss: 0.4653 Acc: 25.0000%\n",
      "\ttrain 27-170: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 27-171: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 27-172: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 27-173: Loss: 0.1624 Acc: 50.0000%\n",
      "\ttrain 27-174: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 27-175: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 27-176: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 27-177: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 27-178: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 27-179: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-180: Loss: 0.1325 Acc: 50.0000%\n",
      "\ttrain 27-181: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 27-182: Loss: 0.6161 Acc: 50.0000%\n",
      "\ttrain 27-183: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 27-184: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 27-185: Loss: 0.1394 Acc: 50.0000%\n",
      "\ttrain 27-186: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 27-187: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 27-188: Loss: 0.4015 Acc: 50.0000%\n",
      "\ttrain 27-189: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 27-190: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 27-191: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 27-192: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 27-193: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 27-194: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 27-195: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 27-196: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 27-197: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 27-198: Loss: 0.1972 Acc: 75.0000%\n",
      "\ttrain 27-199: Loss: 0.3639 Acc: 50.0000%\n",
      "\ttrain 27-200: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 27-201: Loss: 0.1994 Acc: 50.0000%\n",
      "\ttrain 27-202: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 27-203: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 27-204: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 27-205: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 27-206: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 27-207: Loss: 0.3176 Acc: 25.0000%\n",
      "\ttrain 27-208: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 27-209: Loss: 0.3211 Acc: 25.0000%\n",
      "\ttrain 27-210: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 27-211: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 27-212: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 27-213: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 27-214: Loss: 0.2651 Acc: 50.0000%\n",
      "\ttrain 27-215: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 27-216: Loss: 0.2332 Acc: 75.0000%\n",
      "\ttrain 27-217: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 27-218: Loss: 0.3355 Acc: 75.0000%\n",
      "\ttrain 27-219: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 27-220: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 27-221: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 27-222: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 27-223: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 27-224: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 27-225: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 27-226: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 27-227: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 27-228: Loss: 0.0805 Acc: 100.0000%\n",
      "\ttrain 27-229: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 27-230: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 27-231: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 27-232: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 27-233: Loss: 0.2351 Acc: 50.0000%\n",
      "\ttrain 27-234: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 27-235: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 27-236: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 27-237: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 27-238: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 27-239: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 27-240: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 27-241: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 27-242: Loss: 0.1992 Acc: 75.0000%\n",
      "\ttrain 27-243: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 27-244: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 27-245: Loss: 0.2441 Acc: 75.0000%\n",
      "\tvalidation 27-1: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 27-2: Loss: 2.5266 Acc: 75.0000%\n",
      "\tvalidation 27-3: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 27-4: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-5: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 27-6: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 27-7: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 27-8: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 27-9: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 27-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 27-11: Loss: 0.1513 Acc: 75.0000%\n",
      "\tvalidation 27-12: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 27-13: Loss: 0.2820 Acc: 75.0000%\n",
      "\tvalidation 27-14: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 27-15: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-16: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 27-17: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 27-18: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 27-19: Loss: 0.0690 Acc: 100.0000%\n",
      "\tvalidation 27-20: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 27-21: Loss: 0.6735 Acc: 75.0000%\n",
      "\tvalidation 27-22: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 27-23: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 27-24: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 27-25: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 27-26: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-27: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-28: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 27-29: Loss: 0.1119 Acc: 75.0000%\n",
      "\tvalidation 27-30: Loss: 0.0117 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 27-31: Loss: 1.1001 Acc: 75.0000%\n",
      "\tvalidation 27-32: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 27-33: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 27-34: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 27-35: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 27-37: Loss: 0.1982 Acc: 75.0000%\n",
      "\tvalidation 27-38: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 27-39: Loss: 0.6638 Acc: 75.0000%\n",
      "\tvalidation 27-40: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 27-41: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 27-42: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 27-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 27-44: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 27-45: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 27-46: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 27-47: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 27-48: Loss: 0.0486 Acc: 100.0000%\n",
      "\tvalidation 27-49: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 27-50: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 27-51: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 27-52: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 27-53: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-54: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 27-55: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 27-56: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 27-57: Loss: 0.1134 Acc: 75.0000%\n",
      "\tvalidation 27-58: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 27-59: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 27-60: Loss: 0.0415 Acc: 100.0000%\n",
      "\tvalidation 27-61: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 27-62: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-63: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 27-64: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 27-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 27-66: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 27-67: Loss: 0.0616 Acc: 75.0000%\n",
      "\tvalidation 27-68: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 27-69: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-70: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 27-71: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 27-72: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 27-73: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 27-74: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 27-75: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-76: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 27-77: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-78: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 27-79: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 27-80: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 27-81: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 27-82: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 27-83: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 27-84: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 27-85: Loss: 1.2397 Acc: 75.0000%\n",
      "\tvalidation 27-86: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 27-87: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 27-88: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 27-89: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 27-90: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 27-91: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 27-92: Loss: 0.0459 Acc: 75.0000%\n",
      "\tvalidation 27-93: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 27-94: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 27-95: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 27-96: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 27-97: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 27-98: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 27-99: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 27-100: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 27-101: Loss: 0.0626 Acc: 75.0000%\n",
      "\tvalidation 27-102: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 27-103: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 27-104: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 27-105: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0841 Acc: 89.0816%\n",
      "\tvalidation Loss: 0.0774 Acc: 96.4286%\n",
      "Time passed 0h 17m 52s\n",
      "--------------------\n",
      "Epoch [28/40]:\n",
      "\ttrain 28-1: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 28-2: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 28-3: Loss: 0.1703 Acc: 75.0000%\n",
      "\ttrain 28-4: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 28-5: Loss: 0.0862 Acc: 100.0000%\n",
      "\ttrain 28-6: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 28-7: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 28-8: Loss: 0.3603 Acc: 25.0000%\n",
      "\ttrain 28-9: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 28-10: Loss: 0.1526 Acc: 50.0000%\n",
      "\ttrain 28-11: Loss: 0.1872 Acc: 75.0000%\n",
      "\ttrain 28-12: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 28-13: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 28-14: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 28-15: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 28-16: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 28-17: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 28-18: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 28-19: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 28-20: Loss: 0.2977 Acc: 75.0000%\n",
      "\ttrain 28-21: Loss: 0.0611 Acc: 100.0000%\n",
      "\ttrain 28-22: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 28-23: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 28-24: Loss: 0.1666 Acc: 75.0000%\n",
      "\ttrain 28-25: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-26: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-27: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 28-28: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 28-29: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 28-30: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 28-31: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 28-32: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 28-33: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 28-34: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 28-35: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 28-36: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 28-37: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 28-38: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 28-39: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 28-40: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 28-41: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 28-42: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 28-43: Loss: 0.2295 Acc: 75.0000%\n",
      "\ttrain 28-44: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-45: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 28-46: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-47: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-48: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 28-49: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 28-50: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 28-51: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 28-52: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 28-53: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 28-54: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 28-55: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 28-56: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 28-57: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 28-58: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 28-59: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 28-60: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-61: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 28-62: Loss: 0.2011 Acc: 75.0000%\n",
      "\ttrain 28-63: Loss: 0.1786 Acc: 75.0000%\n",
      "\ttrain 28-64: Loss: 0.1683 Acc: 50.0000%\n",
      "\ttrain 28-65: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 28-66: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 28-67: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 28-68: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 28-69: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 28-70: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 28-71: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-72: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 28-73: Loss: 0.3012 Acc: 75.0000%\n",
      "\ttrain 28-74: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 28-75: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 28-76: Loss: 0.0687 Acc: 75.0000%\n",
      "\ttrain 28-77: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 28-78: Loss: 0.3099 Acc: 75.0000%\n",
      "\ttrain 28-79: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 28-80: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 28-81: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 28-82: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 28-83: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 28-84: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 28-85: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 28-86: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 28-87: Loss: 0.2174 Acc: 50.0000%\n",
      "\ttrain 28-88: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 28-89: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 28-90: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 28-91: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 28-92: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 28-93: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 28-94: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 28-95: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 28-96: Loss: 0.1690 Acc: 50.0000%\n",
      "\ttrain 28-97: Loss: 0.2772 Acc: 75.0000%\n",
      "\ttrain 28-98: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 28-99: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 28-100: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-101: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 28-102: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 28-103: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 28-104: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 28-105: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 28-106: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 28-107: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-108: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 28-109: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 28-110: Loss: 0.0017 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-111: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 28-112: Loss: 0.2504 Acc: 75.0000%\n",
      "\ttrain 28-113: Loss: 0.3718 Acc: 50.0000%\n",
      "\ttrain 28-114: Loss: 0.9948 Acc: 0.0000%\n",
      "\ttrain 28-115: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 28-116: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 28-117: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 28-118: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 28-119: Loss: 0.3359 Acc: 50.0000%\n",
      "\ttrain 28-120: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 28-121: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-122: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 28-123: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 28-124: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 28-125: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 28-126: Loss: 0.0815 Acc: 75.0000%\n",
      "\ttrain 28-127: Loss: 0.1660 Acc: 50.0000%\n",
      "\ttrain 28-128: Loss: 0.2124 Acc: 75.0000%\n",
      "\ttrain 28-129: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 28-130: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 28-131: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 28-132: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 28-133: Loss: 0.1952 Acc: 75.0000%\n",
      "\ttrain 28-134: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 28-135: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 28-136: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 28-137: Loss: 0.1681 Acc: 50.0000%\n",
      "\ttrain 28-138: Loss: 0.0922 Acc: 100.0000%\n",
      "\ttrain 28-139: Loss: 0.1944 Acc: 50.0000%\n",
      "\ttrain 28-140: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 28-141: Loss: 0.1941 Acc: 75.0000%\n",
      "\ttrain 28-142: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 28-143: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 28-144: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 28-145: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 28-146: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 28-147: Loss: 0.1724 Acc: 75.0000%\n",
      "\ttrain 28-148: Loss: 0.2783 Acc: 75.0000%\n",
      "\ttrain 28-149: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-150: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 28-151: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 28-152: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 28-153: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 28-154: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 28-155: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-156: Loss: 0.3080 Acc: 50.0000%\n",
      "\ttrain 28-157: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 28-158: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-159: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 28-160: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 28-161: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 28-162: Loss: 0.0991 Acc: 100.0000%\n",
      "\ttrain 28-163: Loss: 0.2088 Acc: 75.0000%\n",
      "\ttrain 28-164: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 28-165: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 28-166: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 28-167: Loss: 0.1514 Acc: 75.0000%\n",
      "\ttrain 28-168: Loss: 0.2772 Acc: 50.0000%\n",
      "\ttrain 28-169: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 28-170: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-171: Loss: 0.2443 Acc: 75.0000%\n",
      "\ttrain 28-172: Loss: 0.4203 Acc: 75.0000%\n",
      "\ttrain 28-173: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 28-174: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 28-175: Loss: 0.0756 Acc: 100.0000%\n",
      "\ttrain 28-176: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 28-177: Loss: 0.3430 Acc: 75.0000%\n",
      "\ttrain 28-178: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 28-179: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 28-180: Loss: 0.1353 Acc: 75.0000%\n",
      "\ttrain 28-181: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 28-182: Loss: 0.0450 Acc: 75.0000%\n",
      "\ttrain 28-183: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 28-184: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 28-185: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 28-186: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 28-187: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 28-188: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 28-189: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 28-190: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 28-191: Loss: 0.1530 Acc: 75.0000%\n",
      "\ttrain 28-192: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 28-193: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 28-194: Loss: 0.2876 Acc: 75.0000%\n",
      "\ttrain 28-195: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 28-196: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 28-197: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 28-198: Loss: 0.2168 Acc: 50.0000%\n",
      "\ttrain 28-199: Loss: 0.1443 Acc: 50.0000%\n",
      "\ttrain 28-200: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 28-201: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 28-202: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 28-203: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 28-204: Loss: 0.3696 Acc: 75.0000%\n",
      "\ttrain 28-205: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-206: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 28-207: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 28-208: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 28-209: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 28-210: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 28-211: Loss: 0.4982 Acc: 50.0000%\n",
      "\ttrain 28-212: Loss: 0.0693 Acc: 100.0000%\n",
      "\ttrain 28-213: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 28-214: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 28-215: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 28-216: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 28-217: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-218: Loss: 0.2536 Acc: 75.0000%\n",
      "\ttrain 28-219: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 28-220: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 28-221: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 28-222: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 28-223: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 28-224: Loss: 0.1715 Acc: 50.0000%\n",
      "\ttrain 28-225: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 28-226: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 28-227: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 28-228: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 28-229: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 28-230: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 28-231: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 28-232: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 28-233: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 28-234: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-235: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 28-236: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 28-237: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 28-238: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 28-239: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 28-240: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 28-241: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 28-242: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 28-243: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 28-244: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 28-245: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 28-1: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 28-2: Loss: 2.4475 Acc: 50.0000%\n",
      "\tvalidation 28-3: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 28-4: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-5: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-6: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-7: Loss: 0.8210 Acc: 75.0000%\n",
      "\tvalidation 28-8: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-9: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 28-10: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-11: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 28-12: Loss: 2.0172 Acc: 75.0000%\n",
      "\tvalidation 28-13: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-14: Loss: 0.0777 Acc: 75.0000%\n",
      "\tvalidation 28-15: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 28-16: Loss: 10.8639 Acc: 75.0000%\n",
      "\tvalidation 28-17: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 28-18: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 28-19: Loss: 0.8173 Acc: 75.0000%\n",
      "\tvalidation 28-20: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 28-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 28-22: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-23: Loss: 0.2202 Acc: 75.0000%\n",
      "\tvalidation 28-24: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-25: Loss: 0.0569 Acc: 75.0000%\n",
      "\tvalidation 28-26: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 28-27: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 28-28: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 28-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-30: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 28-31: Loss: 1.7020 Acc: 75.0000%\n",
      "\tvalidation 28-32: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 28-33: Loss: 0.3026 Acc: 75.0000%\n",
      "\tvalidation 28-34: Loss: 1.4415 Acc: 75.0000%\n",
      "\tvalidation 28-35: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 28-36: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-37: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-38: Loss: 0.3858 Acc: 75.0000%\n",
      "\tvalidation 28-39: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 28-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-41: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 28-42: Loss: 0.0294 Acc: 100.0000%\n",
      "\tvalidation 28-43: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 28-44: Loss: 1.4927 Acc: 75.0000%\n",
      "\tvalidation 28-45: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 28-46: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-47: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-48: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 28-49: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 28-50: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 28-51: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-53: Loss: 0.0024 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 28-54: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 28-55: Loss: 0.0416 Acc: 100.0000%\n",
      "\tvalidation 28-56: Loss: 2.9276 Acc: 75.0000%\n",
      "\tvalidation 28-57: Loss: 0.4636 Acc: 75.0000%\n",
      "\tvalidation 28-58: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 28-59: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-60: Loss: 0.6088 Acc: 75.0000%\n",
      "\tvalidation 28-61: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 28-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-63: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 28-64: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 28-65: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-66: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 28-67: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 28-68: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 28-69: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-70: Loss: 0.1978 Acc: 75.0000%\n",
      "\tvalidation 28-71: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 28-72: Loss: 0.0209 Acc: 100.0000%\n",
      "\tvalidation 28-73: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-74: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 28-75: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 28-76: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 28-77: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-78: Loss: 8.6725 Acc: 50.0000%\n",
      "\tvalidation 28-79: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 28-80: Loss: 3.1821 Acc: 75.0000%\n",
      "\tvalidation 28-81: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 28-82: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 28-83: Loss: 7.5686 Acc: 50.0000%\n",
      "\tvalidation 28-84: Loss: 0.1619 Acc: 75.0000%\n",
      "\tvalidation 28-85: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 28-87: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 28-88: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 28-89: Loss: 1.3799 Acc: 75.0000%\n",
      "\tvalidation 28-90: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 28-91: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 28-92: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 28-93: Loss: 0.0771 Acc: 75.0000%\n",
      "\tvalidation 28-94: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 28-95: Loss: 0.0579 Acc: 75.0000%\n",
      "\tvalidation 28-96: Loss: 0.3652 Acc: 75.0000%\n",
      "\tvalidation 28-97: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 28-98: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 28-99: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 28-100: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 28-101: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-102: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-103: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 28-104: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-105: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0778 Acc: 89.3878%\n",
      "\tvalidation Loss: 0.4647 Acc: 93.3333%\n",
      "Time passed 0h 18m 35s\n",
      "--------------------\n",
      "Epoch [29/40]:\n",
      "\ttrain 29-1: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-2: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 29-3: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 29-4: Loss: 0.1885 Acc: 75.0000%\n",
      "\ttrain 29-5: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 29-6: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 29-7: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 29-8: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 29-9: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 29-10: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-11: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 29-12: Loss: 0.2342 Acc: 75.0000%\n",
      "\ttrain 29-13: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 29-14: Loss: 0.0760 Acc: 75.0000%\n",
      "\ttrain 29-15: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 29-16: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 29-17: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-18: Loss: 0.2340 Acc: 50.0000%\n",
      "\ttrain 29-19: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 29-20: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 29-21: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 29-22: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 29-23: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 29-24: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 29-25: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 29-26: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 29-27: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 29-28: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-29: Loss: 0.2868 Acc: 75.0000%\n",
      "\ttrain 29-30: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 29-31: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 29-32: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-33: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 29-34: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 29-35: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 29-36: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 29-37: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 29-38: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-39: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-40: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 29-41: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-42: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 29-43: Loss: 0.3527 Acc: 50.0000%\n",
      "\ttrain 29-44: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 29-45: Loss: 0.2891 Acc: 75.0000%\n",
      "\ttrain 29-46: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 29-47: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 29-48: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 29-49: Loss: 0.2242 Acc: 75.0000%\n",
      "\ttrain 29-50: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-51: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 29-52: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 29-53: Loss: 0.2139 Acc: 50.0000%\n",
      "\ttrain 29-54: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 29-55: Loss: 0.4807 Acc: 50.0000%\n",
      "\ttrain 29-56: Loss: 0.1414 Acc: 50.0000%\n",
      "\ttrain 29-57: Loss: 0.1996 Acc: 75.0000%\n",
      "\ttrain 29-58: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain 29-59: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 29-60: Loss: 0.0788 Acc: 100.0000%\n",
      "\ttrain 29-61: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 29-62: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 29-63: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 29-64: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-65: Loss: 0.2418 Acc: 50.0000%\n",
      "\ttrain 29-66: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 29-67: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 29-68: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 29-69: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-70: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 29-71: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-72: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 29-73: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 29-74: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 29-75: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 29-76: Loss: 0.1554 Acc: 50.0000%\n",
      "\ttrain 29-77: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 29-78: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 29-79: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 29-80: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-81: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 29-82: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 29-83: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 29-84: Loss: 0.4510 Acc: 75.0000%\n",
      "\ttrain 29-85: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 29-86: Loss: 0.2313 Acc: 50.0000%\n",
      "\ttrain 29-87: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 29-88: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 29-89: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 29-90: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 29-91: Loss: 0.0708 Acc: 100.0000%\n",
      "\ttrain 29-92: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 29-93: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 29-94: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 29-95: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 29-96: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-97: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 29-98: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 29-99: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 29-100: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 29-101: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 29-102: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 29-103: Loss: 0.1653 Acc: 75.0000%\n",
      "\ttrain 29-104: Loss: 0.1753 Acc: 75.0000%\n",
      "\ttrain 29-105: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 29-106: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 29-107: Loss: 0.1582 Acc: 75.0000%\n",
      "\ttrain 29-108: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 29-109: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 29-110: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 29-111: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-112: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 29-113: Loss: 0.0847 Acc: 75.0000%\n",
      "\ttrain 29-114: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 29-115: Loss: 0.4542 Acc: 75.0000%\n",
      "\ttrain 29-116: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-117: Loss: 0.0572 Acc: 75.0000%\n",
      "\ttrain 29-118: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 29-119: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 29-120: Loss: 0.2218 Acc: 75.0000%\n",
      "\ttrain 29-121: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 29-122: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 29-123: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-124: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 29-125: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 29-126: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 29-127: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 29-128: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 29-129: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-130: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 29-131: Loss: 0.3414 Acc: 50.0000%\n",
      "\ttrain 29-132: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 29-133: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 29-134: Loss: 0.0904 Acc: 100.0000%\n",
      "\ttrain 29-135: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 29-136: Loss: 0.1397 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-137: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 29-138: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 29-139: Loss: 0.1676 Acc: 75.0000%\n",
      "\ttrain 29-140: Loss: 0.3945 Acc: 75.0000%\n",
      "\ttrain 29-141: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 29-142: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 29-143: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 29-144: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 29-145: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-146: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 29-147: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 29-148: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 29-149: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 29-150: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 29-151: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 29-152: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 29-153: Loss: 0.2520 Acc: 50.0000%\n",
      "\ttrain 29-154: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-155: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 29-156: Loss: 0.4013 Acc: 75.0000%\n",
      "\ttrain 29-157: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-158: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 29-159: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-160: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 29-161: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 29-162: Loss: 0.0675 Acc: 100.0000%\n",
      "\ttrain 29-163: Loss: 0.2765 Acc: 50.0000%\n",
      "\ttrain 29-164: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 29-165: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 29-166: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 29-167: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 29-168: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 29-169: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-170: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 29-171: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 29-172: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 29-173: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 29-174: Loss: 0.1889 Acc: 75.0000%\n",
      "\ttrain 29-175: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 29-176: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 29-177: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 29-178: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 29-179: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-180: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 29-181: Loss: 0.1369 Acc: 75.0000%\n",
      "\ttrain 29-182: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 29-183: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 29-184: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 29-185: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 29-186: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 29-187: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 29-188: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-189: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 29-190: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 29-191: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-192: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 29-193: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-194: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 29-195: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 29-196: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 29-197: Loss: 0.3202 Acc: 75.0000%\n",
      "\ttrain 29-198: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 29-199: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 29-200: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 29-201: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-202: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 29-203: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 29-204: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 29-205: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 29-206: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-207: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 29-208: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 29-209: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-210: Loss: 0.2171 Acc: 75.0000%\n",
      "\ttrain 29-211: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 29-212: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-213: Loss: 0.1857 Acc: 75.0000%\n",
      "\ttrain 29-214: Loss: 0.3483 Acc: 25.0000%\n",
      "\ttrain 29-215: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 29-216: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-217: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 29-218: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 29-219: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 29-220: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 29-221: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 29-222: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 29-223: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 29-224: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 29-225: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 29-226: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-227: Loss: 0.4359 Acc: 50.0000%\n",
      "\ttrain 29-228: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-229: Loss: 0.2122 Acc: 75.0000%\n",
      "\ttrain 29-230: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 29-231: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 29-232: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 29-233: Loss: 0.0855 Acc: 100.0000%\n",
      "\ttrain 29-234: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 29-235: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-236: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 29-237: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 29-238: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 29-239: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-240: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 29-241: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-242: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 29-243: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 29-244: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 29-245: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 29-1: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 29-2: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-3: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-4: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 29-5: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-7: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-8: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 29-9: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 29-10: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-11: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 29-12: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-13: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-14: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 29-15: Loss: 0.1266 Acc: 75.0000%\n",
      "\tvalidation 29-16: Loss: 1.1925 Acc: 75.0000%\n",
      "\tvalidation 29-17: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 29-18: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-19: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-20: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 29-21: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 29-22: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-23: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 29-24: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-25: Loss: 0.0842 Acc: 75.0000%\n",
      "\tvalidation 29-26: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-27: Loss: 0.3338 Acc: 75.0000%\n",
      "\tvalidation 29-28: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 29-29: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-30: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 29-31: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-32: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 29-33: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-34: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 29-35: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 29-36: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 29-37: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-38: Loss: 0.1116 Acc: 75.0000%\n",
      "\tvalidation 29-39: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 29-40: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 29-41: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-43: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-44: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-45: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 29-46: Loss: 0.2109 Acc: 75.0000%\n",
      "\tvalidation 29-47: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 29-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-49: Loss: 0.3818 Acc: 75.0000%\n",
      "\tvalidation 29-50: Loss: 0.0590 Acc: 75.0000%\n",
      "\tvalidation 29-51: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 29-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-53: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 29-54: Loss: 0.4565 Acc: 75.0000%\n",
      "\tvalidation 29-55: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-56: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 29-57: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-59: Loss: 0.2392 Acc: 75.0000%\n",
      "\tvalidation 29-60: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-61: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-62: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 29-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-64: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 29-65: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 29-66: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 29-67: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-69: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-70: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-71: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 29-72: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 29-73: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 29-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-75: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 29-76: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 29-77: Loss: 0.0706 Acc: 75.0000%\n",
      "\tvalidation 29-78: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-79: Loss: 0.0004 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 29-80: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 29-81: Loss: 0.0420 Acc: 100.0000%\n",
      "\tvalidation 29-82: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-83: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-84: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-85: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-87: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 29-88: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 29-89: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-90: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 29-91: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-92: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-94: Loss: 0.4667 Acc: 75.0000%\n",
      "\tvalidation 29-95: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 29-96: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-98: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 29-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 29-100: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 29-101: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 29-102: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-103: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-104: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 29-105: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0694 Acc: 90.1020%\n",
      "\tvalidation Loss: 0.0406 Acc: 97.1429%\n",
      "网络参数更新\n",
      "Time passed 0h 19m 37s\n",
      "--------------------\n",
      "Epoch [30/40]:\n",
      "\ttrain 30-1: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 30-2: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 30-3: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-4: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 30-5: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 30-6: Loss: 0.1186 Acc: 75.0000%\n",
      "\ttrain 30-7: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 30-8: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 30-9: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-10: Loss: 0.2846 Acc: 50.0000%\n",
      "\ttrain 30-11: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 30-12: Loss: 0.3689 Acc: 75.0000%\n",
      "\ttrain 30-13: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 30-14: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 30-15: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 30-16: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-17: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 30-18: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-19: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 30-20: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-21: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 30-22: Loss: 0.7004 Acc: 75.0000%\n",
      "\ttrain 30-23: Loss: 0.1552 Acc: 50.0000%\n",
      "\ttrain 30-24: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 30-25: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-26: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 30-27: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 30-28: Loss: 0.1524 Acc: 75.0000%\n",
      "\ttrain 30-29: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 30-30: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 30-31: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 30-32: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 30-33: Loss: 0.1785 Acc: 75.0000%\n",
      "\ttrain 30-34: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 30-35: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 30-36: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 30-37: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 30-38: Loss: 0.1017 Acc: 75.0000%\n",
      "\ttrain 30-39: Loss: 0.0524 Acc: 75.0000%\n",
      "\ttrain 30-40: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 30-41: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 30-42: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 30-43: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 30-44: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 30-45: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 30-46: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-47: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 30-48: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 30-49: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 30-50: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 30-51: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 30-52: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 30-53: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 30-54: Loss: 0.1408 Acc: 75.0000%\n",
      "\ttrain 30-55: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 30-56: Loss: 0.2183 Acc: 50.0000%\n",
      "\ttrain 30-57: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 30-58: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 30-59: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 30-60: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 30-61: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 30-62: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 30-63: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 30-64: Loss: 0.1472 Acc: 50.0000%\n",
      "\ttrain 30-65: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 30-66: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 30-67: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 30-68: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 30-69: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 30-70: Loss: 0.1785 Acc: 50.0000%\n",
      "\ttrain 30-71: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 30-72: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 30-73: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 30-74: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 30-75: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 30-76: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 30-77: Loss: 0.1261 Acc: 75.0000%\n",
      "\ttrain 30-78: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 30-79: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 30-80: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 30-81: Loss: 0.0928 Acc: 100.0000%\n",
      "\ttrain 30-82: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-83: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 30-84: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 30-85: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 30-86: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 30-87: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 30-88: Loss: 0.5142 Acc: 75.0000%\n",
      "\ttrain 30-89: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 30-90: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 30-91: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 30-92: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 30-93: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 30-94: Loss: 0.3172 Acc: 50.0000%\n",
      "\ttrain 30-95: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 30-96: Loss: 0.1928 Acc: 75.0000%\n",
      "\ttrain 30-97: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 30-98: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-99: Loss: 0.1182 Acc: 75.0000%\n",
      "\ttrain 30-100: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 30-101: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 30-102: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 30-103: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 30-104: Loss: 0.1652 Acc: 75.0000%\n",
      "\ttrain 30-105: Loss: 0.4165 Acc: 50.0000%\n",
      "\ttrain 30-106: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 30-107: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 30-108: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 30-109: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 30-110: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 30-111: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-112: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 30-113: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-114: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 30-115: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 30-116: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 30-117: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-118: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-119: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-120: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-121: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 30-122: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 30-123: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 30-124: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-125: Loss: 0.2237 Acc: 75.0000%\n",
      "\ttrain 30-126: Loss: 0.0657 Acc: 100.0000%\n",
      "\ttrain 30-127: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 30-128: Loss: 0.3562 Acc: 75.0000%\n",
      "\ttrain 30-129: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 30-130: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 30-131: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 30-132: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 30-133: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-134: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 30-135: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 30-136: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 30-137: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 30-138: Loss: 0.1565 Acc: 75.0000%\n",
      "\ttrain 30-139: Loss: 0.0872 Acc: 100.0000%\n",
      "\ttrain 30-140: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-141: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 30-142: Loss: 0.8467 Acc: 75.0000%\n",
      "\ttrain 30-143: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-144: Loss: 0.6283 Acc: 25.0000%\n",
      "\ttrain 30-145: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 30-146: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 30-147: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 30-148: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 30-149: Loss: 0.2127 Acc: 75.0000%\n",
      "\ttrain 30-150: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 30-151: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-152: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 30-153: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 30-154: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 30-155: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 30-156: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-157: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-158: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 30-159: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 30-160: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 30-161: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 30-162: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 30-163: Loss: 0.0943 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 30-164: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 30-165: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-166: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 30-167: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 30-168: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 30-169: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 30-170: Loss: 0.3281 Acc: 75.0000%\n",
      "\ttrain 30-171: Loss: 0.1188 Acc: 75.0000%\n",
      "\ttrain 30-172: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-173: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 30-174: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 30-175: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 30-176: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 30-177: Loss: 0.1953 Acc: 75.0000%\n",
      "\ttrain 30-178: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 30-179: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 30-180: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 30-181: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 30-182: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 30-183: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 30-184: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 30-185: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 30-186: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 30-187: Loss: 0.3792 Acc: 75.0000%\n",
      "\ttrain 30-188: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 30-189: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 30-190: Loss: 0.2088 Acc: 50.0000%\n",
      "\ttrain 30-191: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 30-192: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 30-193: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 30-194: Loss: 0.3212 Acc: 50.0000%\n",
      "\ttrain 30-195: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 30-196: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 30-197: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 30-198: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 30-199: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 30-200: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 30-201: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 30-202: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 30-203: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 30-204: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 30-205: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 30-206: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 30-207: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 30-208: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 30-209: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-210: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 30-211: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 30-212: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-213: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 30-214: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 30-215: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-216: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 30-217: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-218: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 30-219: Loss: 0.2880 Acc: 75.0000%\n",
      "\ttrain 30-220: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 30-221: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 30-222: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 30-223: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 30-224: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 30-225: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 30-226: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 30-227: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 30-228: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-229: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 30-230: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 30-231: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 30-232: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 30-233: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 30-234: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 30-235: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 30-236: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 30-237: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 30-238: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 30-239: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-240: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-241: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 30-242: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 30-243: Loss: 0.1354 Acc: 75.0000%\n",
      "\ttrain 30-244: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 30-245: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 30-1: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-2: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-5: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-6: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-7: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-8: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-9: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 30-10: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-11: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-12: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-13: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 30-14: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-15: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-16: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-18: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 30-19: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 30-20: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 30-21: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-22: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-23: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-24: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-25: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-26: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-27: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-28: Loss: 0.0431 Acc: 100.0000%\n",
      "\tvalidation 30-29: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-30: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-32: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-33: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 30-34: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-35: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-36: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-37: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-38: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-39: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 30-40: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-42: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 30-43: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-45: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 30-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-47: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-48: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-49: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-50: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 30-51: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-52: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 30-53: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-54: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 30-55: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 30-56: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-57: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 30-58: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-59: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-60: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-61: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-62: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-63: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-64: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 30-65: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-66: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-67: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 30-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-69: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-70: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 30-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-72: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-74: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 30-75: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-77: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-78: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 30-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-80: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 30-81: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 30-82: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 30-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-86: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 30-87: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-88: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 30-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 30-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-92: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-93: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 30-94: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 30-95: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-96: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 30-97: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 30-98: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 30-99: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-100: Loss: 0.0022 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 30-101: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 30-102: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 30-103: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 30-104: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 30-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0685 Acc: 91.1224%\n",
      "\tvalidation Loss: 0.0033 Acc: 100.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 20m 38s\n",
      "--------------------\n",
      "Epoch [31/40]:\n",
      "\ttrain 31-1: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-2: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 31-3: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 31-4: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-5: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-6: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 31-7: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-8: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-9: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 31-10: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-11: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-12: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 31-13: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 31-14: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-15: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-16: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 31-17: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 31-18: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-19: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 31-20: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-21: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 31-22: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-23: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 31-24: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 31-25: Loss: 0.1394 Acc: 75.0000%\n",
      "\ttrain 31-26: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 31-27: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 31-28: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 31-29: Loss: 0.2198 Acc: 75.0000%\n",
      "\ttrain 31-30: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 31-31: Loss: 0.2552 Acc: 75.0000%\n",
      "\ttrain 31-32: Loss: 0.0554 Acc: 100.0000%\n",
      "\ttrain 31-33: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 31-34: Loss: 0.3746 Acc: 50.0000%\n",
      "\ttrain 31-35: Loss: 0.2409 Acc: 75.0000%\n",
      "\ttrain 31-36: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-37: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 31-38: Loss: 0.2869 Acc: 50.0000%\n",
      "\ttrain 31-39: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 31-40: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 31-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-42: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-43: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-44: Loss: 0.0629 Acc: 75.0000%\n",
      "\ttrain 31-45: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 31-46: Loss: 0.2937 Acc: 75.0000%\n",
      "\ttrain 31-47: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 31-48: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 31-49: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 31-50: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 31-51: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 31-52: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 31-53: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 31-54: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-55: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 31-56: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 31-57: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-58: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 31-59: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 31-60: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 31-61: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 31-62: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 31-63: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 31-64: Loss: 0.2711 Acc: 50.0000%\n",
      "\ttrain 31-65: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 31-66: Loss: 0.0835 Acc: 75.0000%\n",
      "\ttrain 31-67: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 31-68: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 31-69: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 31-70: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 31-71: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 31-72: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 31-73: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 31-74: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-75: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 31-76: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 31-77: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 31-78: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 31-79: Loss: 0.2831 Acc: 50.0000%\n",
      "\ttrain 31-80: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 31-81: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-82: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-83: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 31-84: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 31-85: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 31-86: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 31-87: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-88: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 31-89: Loss: 0.3800 Acc: 50.0000%\n",
      "\ttrain 31-90: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 31-91: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 31-92: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 31-93: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 31-94: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 31-95: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 31-96: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 31-97: Loss: 0.4061 Acc: 75.0000%\n",
      "\ttrain 31-98: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 31-99: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 31-100: Loss: 0.1090 Acc: 75.0000%\n",
      "\ttrain 31-101: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 31-102: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 31-103: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 31-104: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 31-105: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 31-106: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 31-107: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 31-108: Loss: 0.3764 Acc: 50.0000%\n",
      "\ttrain 31-109: Loss: 0.2093 Acc: 75.0000%\n",
      "\ttrain 31-110: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 31-111: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-112: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 31-113: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 31-114: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 31-115: Loss: 0.2655 Acc: 75.0000%\n",
      "\ttrain 31-116: Loss: 0.5196 Acc: 25.0000%\n",
      "\ttrain 31-117: Loss: 0.1232 Acc: 50.0000%\n",
      "\ttrain 31-118: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 31-119: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-120: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-121: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 31-122: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 31-123: Loss: 0.0810 Acc: 75.0000%\n",
      "\ttrain 31-124: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-125: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 31-126: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 31-127: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 31-128: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 31-129: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 31-130: Loss: 0.2315 Acc: 50.0000%\n",
      "\ttrain 31-131: Loss: 0.3725 Acc: 75.0000%\n",
      "\ttrain 31-132: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 31-133: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 31-134: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 31-135: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 31-136: Loss: 0.1026 Acc: 75.0000%\n",
      "\ttrain 31-137: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-138: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 31-139: Loss: 0.1672 Acc: 75.0000%\n",
      "\ttrain 31-140: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-141: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-142: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 31-143: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 31-144: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 31-145: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 31-146: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 31-147: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 31-148: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 31-149: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 31-150: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 31-151: Loss: 0.0719 Acc: 75.0000%\n",
      "\ttrain 31-152: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 31-153: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-154: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 31-155: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 31-156: Loss: 0.3252 Acc: 50.0000%\n",
      "\ttrain 31-157: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-158: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 31-159: Loss: 0.6525 Acc: 0.0000%\n",
      "\ttrain 31-160: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 31-161: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 31-162: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 31-163: Loss: 0.5162 Acc: 25.0000%\n",
      "\ttrain 31-164: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 31-165: Loss: 0.2433 Acc: 50.0000%\n",
      "\ttrain 31-166: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 31-167: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 31-168: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-169: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 31-170: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 31-171: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-172: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 31-173: Loss: 0.3119 Acc: 75.0000%\n",
      "\ttrain 31-174: Loss: 0.0836 Acc: 75.0000%\n",
      "\ttrain 31-175: Loss: 0.1423 Acc: 75.0000%\n",
      "\ttrain 31-176: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 31-177: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 31-178: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 31-179: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 31-180: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 31-181: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 31-182: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 31-183: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 31-184: Loss: 0.2646 Acc: 50.0000%\n",
      "\ttrain 31-185: Loss: 0.1628 Acc: 75.0000%\n",
      "\ttrain 31-186: Loss: 0.0064 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-187: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 31-188: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 31-189: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 31-190: Loss: 0.0839 Acc: 100.0000%\n",
      "\ttrain 31-191: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 31-192: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 31-193: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 31-194: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 31-195: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 31-196: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 31-197: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 31-198: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 31-199: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 31-200: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 31-201: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 31-202: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 31-203: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 31-204: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 31-205: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 31-206: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 31-207: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-208: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-209: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 31-210: Loss: 1.1489 Acc: 50.0000%\n",
      "\ttrain 31-211: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 31-212: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 31-213: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 31-214: Loss: 0.2932 Acc: 75.0000%\n",
      "\ttrain 31-215: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 31-216: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 31-217: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 31-218: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 31-219: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 31-220: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-221: Loss: 0.2144 Acc: 50.0000%\n",
      "\ttrain 31-222: Loss: 0.3304 Acc: 75.0000%\n",
      "\ttrain 31-223: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 31-224: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 31-225: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-226: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 31-227: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 31-228: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 31-229: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 31-230: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 31-231: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 31-232: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 31-233: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 31-234: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 31-235: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 31-236: Loss: 0.3105 Acc: 75.0000%\n",
      "\ttrain 31-237: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 31-238: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 31-239: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 31-240: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 31-241: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 31-242: Loss: 0.2739 Acc: 75.0000%\n",
      "\ttrain 31-243: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 31-244: Loss: 0.2942 Acc: 50.0000%\n",
      "\ttrain 31-245: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 31-1: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 31-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-3: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 31-4: Loss: 0.1497 Acc: 75.0000%\n",
      "\tvalidation 31-5: Loss: 3.0621 Acc: 75.0000%\n",
      "\tvalidation 31-6: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-7: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-8: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 31-9: Loss: 0.2475 Acc: 75.0000%\n",
      "\tvalidation 31-10: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-11: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-12: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-13: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-14: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 31-15: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 31-16: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-17: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 31-18: Loss: 0.0803 Acc: 75.0000%\n",
      "\tvalidation 31-19: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 31-20: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-21: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-22: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-23: Loss: 1.2323 Acc: 75.0000%\n",
      "\tvalidation 31-24: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 31-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-26: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-27: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-28: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 31-29: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 31-30: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 31-31: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-32: Loss: 0.0795 Acc: 75.0000%\n",
      "\tvalidation 31-33: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 31-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 31-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-37: Loss: 0.3100 Acc: 75.0000%\n",
      "\tvalidation 31-38: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-39: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 31-40: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-41: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-42: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 31-43: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 31-44: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-45: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 31-46: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-47: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 31-48: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-49: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 31-50: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-51: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-52: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-53: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-54: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-55: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 31-56: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-57: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-58: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-59: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-60: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-61: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-62: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 31-63: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-64: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-65: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-66: Loss: 4.2163 Acc: 75.0000%\n",
      "\tvalidation 31-67: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-68: Loss: 2.4316 Acc: 75.0000%\n",
      "\tvalidation 31-69: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 31-70: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-71: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-72: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 31-73: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 31-74: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-75: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-77: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 31-78: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 31-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-80: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 31-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-82: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-83: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 31-84: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 31-85: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 31-86: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 31-87: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-89: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 31-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-91: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 31-92: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-93: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 31-94: Loss: 0.1177 Acc: 75.0000%\n",
      "\tvalidation 31-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-96: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-97: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-98: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-99: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-100: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-101: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 31-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-103: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 31-104: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 31-105: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0719 Acc: 90.6122%\n",
      "\tvalidation Loss: 0.1170 Acc: 97.6190%\n",
      "Time passed 0h 21m 39s\n",
      "--------------------\n",
      "Epoch [32/40]:\n",
      "\ttrain 32-1: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 32-2: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 32-3: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 32-4: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 32-5: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-6: Loss: 0.4626 Acc: 75.0000%\n",
      "\ttrain 32-7: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 32-8: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 32-9: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 32-10: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 32-11: Loss: 0.4043 Acc: 75.0000%\n",
      "\ttrain 32-12: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 32-13: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-14: Loss: 0.1715 Acc: 75.0000%\n",
      "\ttrain 32-15: Loss: 0.4796 Acc: 25.0000%\n",
      "\ttrain 32-16: Loss: 0.1272 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-17: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 32-18: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 32-19: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 32-20: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 32-21: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 32-22: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 32-23: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 32-24: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 32-25: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-26: Loss: 0.2517 Acc: 75.0000%\n",
      "\ttrain 32-27: Loss: 0.0676 Acc: 100.0000%\n",
      "\ttrain 32-28: Loss: 0.2697 Acc: 50.0000%\n",
      "\ttrain 32-29: Loss: 0.0875 Acc: 100.0000%\n",
      "\ttrain 32-30: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 32-31: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 32-32: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 32-33: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 32-34: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 32-35: Loss: 0.1558 Acc: 75.0000%\n",
      "\ttrain 32-36: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 32-37: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 32-38: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 32-39: Loss: 0.1693 Acc: 50.0000%\n",
      "\ttrain 32-40: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 32-41: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 32-42: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 32-43: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 32-44: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-45: Loss: 0.2080 Acc: 75.0000%\n",
      "\ttrain 32-46: Loss: 0.3783 Acc: 50.0000%\n",
      "\ttrain 32-47: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-48: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 32-49: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-50: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-51: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 32-52: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 32-53: Loss: 0.2224 Acc: 75.0000%\n",
      "\ttrain 32-54: Loss: 0.1861 Acc: 75.0000%\n",
      "\ttrain 32-55: Loss: 0.1737 Acc: 75.0000%\n",
      "\ttrain 32-56: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 32-57: Loss: 0.2844 Acc: 50.0000%\n",
      "\ttrain 32-58: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 32-59: Loss: 0.7955 Acc: 50.0000%\n",
      "\ttrain 32-60: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 32-61: Loss: 0.1976 Acc: 50.0000%\n",
      "\ttrain 32-62: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 32-63: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 32-64: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 32-65: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 32-66: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 32-67: Loss: 0.1059 Acc: 75.0000%\n",
      "\ttrain 32-68: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 32-69: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 32-70: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 32-71: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 32-72: Loss: 0.1661 Acc: 50.0000%\n",
      "\ttrain 32-73: Loss: 0.4779 Acc: 25.0000%\n",
      "\ttrain 32-74: Loss: 0.0699 Acc: 100.0000%\n",
      "\ttrain 32-75: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 32-76: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 32-77: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 32-78: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 32-79: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-80: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 32-81: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-82: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 32-83: Loss: 0.1223 Acc: 50.0000%\n",
      "\ttrain 32-84: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 32-85: Loss: 0.1966 Acc: 50.0000%\n",
      "\ttrain 32-86: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 32-87: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 32-88: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 32-89: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 32-90: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 32-91: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 32-92: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 32-93: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 32-94: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 32-95: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-96: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 32-97: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 32-98: Loss: 0.1881 Acc: 75.0000%\n",
      "\ttrain 32-99: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 32-100: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 32-101: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 32-102: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 32-103: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 32-104: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 32-105: Loss: 0.2488 Acc: 75.0000%\n",
      "\ttrain 32-106: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-107: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 32-108: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-109: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 32-110: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 32-111: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 32-112: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-113: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 32-114: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 32-115: Loss: 0.2549 Acc: 75.0000%\n",
      "\ttrain 32-116: Loss: 0.0570 Acc: 100.0000%\n",
      "\ttrain 32-117: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 32-118: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 32-119: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 32-120: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 32-121: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-122: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 32-123: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 32-124: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 32-125: Loss: 0.1117 Acc: 50.0000%\n",
      "\ttrain 32-126: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 32-127: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-128: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 32-129: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 32-130: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 32-131: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-132: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 32-133: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 32-134: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 32-135: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 32-136: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-137: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 32-138: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 32-139: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 32-140: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 32-141: Loss: 0.0708 Acc: 75.0000%\n",
      "\ttrain 32-142: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 32-143: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 32-144: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-145: Loss: 0.5171 Acc: 75.0000%\n",
      "\ttrain 32-146: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 32-147: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-148: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 32-149: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-150: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-151: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 32-152: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-153: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 32-154: Loss: 0.0682 Acc: 75.0000%\n",
      "\ttrain 32-155: Loss: 0.1656 Acc: 75.0000%\n",
      "\ttrain 32-156: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 32-157: Loss: 0.7556 Acc: 50.0000%\n",
      "\ttrain 32-158: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 32-159: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 32-160: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 32-161: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 32-162: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 32-163: Loss: 0.2298 Acc: 75.0000%\n",
      "\ttrain 32-164: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 32-165: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 32-166: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 32-167: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 32-168: Loss: 0.2145 Acc: 75.0000%\n",
      "\ttrain 32-169: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 32-170: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 32-171: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 32-172: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 32-173: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 32-174: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 32-175: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 32-176: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 32-177: Loss: 0.0555 Acc: 75.0000%\n",
      "\ttrain 32-178: Loss: 0.0429 Acc: 100.0000%\n",
      "\ttrain 32-179: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 32-180: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 32-181: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 32-182: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 32-183: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-184: Loss: 0.3450 Acc: 75.0000%\n",
      "\ttrain 32-185: Loss: 0.2554 Acc: 75.0000%\n",
      "\ttrain 32-186: Loss: 0.5485 Acc: 0.0000%\n",
      "\ttrain 32-187: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 32-188: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 32-189: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 32-190: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 32-191: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-192: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 32-193: Loss: 0.2266 Acc: 50.0000%\n",
      "\ttrain 32-194: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 32-195: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 32-196: Loss: 0.0618 Acc: 100.0000%\n",
      "\ttrain 32-197: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 32-198: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 32-199: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 32-200: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 32-201: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 32-202: Loss: 0.2764 Acc: 75.0000%\n",
      "\ttrain 32-203: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 32-204: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 32-205: Loss: 0.1089 Acc: 75.0000%\n",
      "\ttrain 32-206: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 32-207: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 32-208: Loss: 0.3149 Acc: 50.0000%\n",
      "\ttrain 32-209: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-210: Loss: 0.1949 Acc: 75.0000%\n",
      "\ttrain 32-211: Loss: 0.0045 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-212: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-213: Loss: 0.2327 Acc: 75.0000%\n",
      "\ttrain 32-214: Loss: 0.1830 Acc: 50.0000%\n",
      "\ttrain 32-215: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 32-216: Loss: 0.0658 Acc: 75.0000%\n",
      "\ttrain 32-217: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 32-218: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 32-219: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 32-220: Loss: 0.2401 Acc: 75.0000%\n",
      "\ttrain 32-221: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 32-222: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-223: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 32-224: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 32-225: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 32-226: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 32-227: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 32-228: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 32-229: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 32-230: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 32-231: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 32-232: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 32-233: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 32-234: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 32-235: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 32-236: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-237: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-238: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 32-239: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 32-240: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 32-241: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-242: Loss: 0.0596 Acc: 75.0000%\n",
      "\ttrain 32-243: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 32-244: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 32-245: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 32-1: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 32-2: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 32-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-4: Loss: 0.0494 Acc: 100.0000%\n",
      "\tvalidation 32-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-6: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-7: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 32-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-9: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 32-10: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-11: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-13: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-15: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 32-16: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 32-17: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-18: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 32-19: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-20: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 32-21: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-22: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 32-23: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-24: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-25: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 32-26: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-27: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-28: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 32-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-30: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-32: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 32-33: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 32-34: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 32-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-37: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 32-38: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 32-39: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 32-40: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 32-41: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 32-42: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 32-43: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 32-44: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 32-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-47: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 32-48: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 32-49: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 32-50: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-51: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 32-52: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 32-53: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 32-54: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-55: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 32-56: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-57: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-58: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 32-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-60: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 32-61: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-62: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 32-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 32-64: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-65: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-67: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 32-68: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 32-69: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 32-70: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 32-71: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-72: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-73: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 32-74: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-75: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 32-76: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 32-77: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-78: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 32-79: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 32-80: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-81: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 32-82: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 32-83: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 32-84: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 32-85: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 32-86: Loss: 0.0237 Acc: 100.0000%\n",
      "\tvalidation 32-87: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 32-90: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 32-91: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 32-92: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 32-93: Loss: 0.0403 Acc: 100.0000%\n",
      "\tvalidation 32-94: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 32-95: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 32-96: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 32-97: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 32-98: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 32-99: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-100: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 32-102: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-103: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-104: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 32-105: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0768 Acc: 90.0000%\n",
      "\tvalidation Loss: 0.0063 Acc: 100.0000%\n",
      "Time passed 0h 22m 37s\n",
      "--------------------\n",
      "Epoch [33/40]:\n",
      "\ttrain 33-1: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 33-2: Loss: 0.1419 Acc: 75.0000%\n",
      "\ttrain 33-3: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-4: Loss: 0.2050 Acc: 75.0000%\n",
      "\ttrain 33-5: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 33-6: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 33-7: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-8: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-9: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-10: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-11: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 33-12: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 33-13: Loss: 0.1781 Acc: 50.0000%\n",
      "\ttrain 33-14: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 33-15: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 33-16: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 33-17: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 33-18: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 33-19: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-20: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 33-21: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 33-22: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 33-23: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-24: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-25: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 33-26: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-27: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 33-28: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-29: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 33-30: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 33-31: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 33-32: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 33-33: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 33-34: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-35: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 33-36: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 33-37: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 33-38: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 33-39: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 33-40: Loss: 0.1780 Acc: 50.0000%\n",
      "\ttrain 33-41: Loss: 0.0054 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-42: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 33-43: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-44: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 33-45: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-46: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-47: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 33-48: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 33-49: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 33-50: Loss: 0.1962 Acc: 75.0000%\n",
      "\ttrain 33-51: Loss: 0.2332 Acc: 75.0000%\n",
      "\ttrain 33-52: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-53: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 33-54: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-55: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 33-56: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 33-57: Loss: 0.2739 Acc: 50.0000%\n",
      "\ttrain 33-58: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 33-59: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 33-60: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 33-61: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 33-62: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 33-63: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 33-64: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-65: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 33-66: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 33-67: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-68: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 33-69: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 33-70: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-71: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 33-72: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 33-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-74: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 33-75: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 33-76: Loss: 0.0818 Acc: 100.0000%\n",
      "\ttrain 33-77: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 33-78: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 33-79: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 33-80: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-81: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 33-82: Loss: 0.1269 Acc: 75.0000%\n",
      "\ttrain 33-83: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 33-84: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 33-85: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 33-86: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 33-87: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 33-88: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 33-89: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-90: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 33-91: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-92: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 33-93: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 33-94: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 33-95: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 33-96: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 33-97: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 33-98: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 33-99: Loss: 0.1959 Acc: 50.0000%\n",
      "\ttrain 33-100: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-101: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 33-102: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 33-103: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-104: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 33-105: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 33-106: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 33-107: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 33-108: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 33-109: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 33-110: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 33-111: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 33-112: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 33-113: Loss: 0.2477 Acc: 75.0000%\n",
      "\ttrain 33-114: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 33-115: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 33-116: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 33-117: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 33-118: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 33-119: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-120: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-121: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-122: Loss: 0.2369 Acc: 75.0000%\n",
      "\ttrain 33-123: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 33-124: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 33-125: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-126: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 33-127: Loss: 0.2919 Acc: 50.0000%\n",
      "\ttrain 33-128: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 33-129: Loss: 0.8153 Acc: 0.0000%\n",
      "\ttrain 33-130: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 33-131: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 33-132: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-133: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-134: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 33-135: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 33-136: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 33-137: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 33-138: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 33-139: Loss: 0.1590 Acc: 75.0000%\n",
      "\ttrain 33-140: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-141: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 33-142: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 33-143: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 33-144: Loss: 0.1708 Acc: 75.0000%\n",
      "\ttrain 33-145: Loss: 0.4636 Acc: 75.0000%\n",
      "\ttrain 33-146: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 33-147: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 33-148: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 33-149: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 33-150: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 33-151: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 33-152: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-153: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-154: Loss: 0.2844 Acc: 75.0000%\n",
      "\ttrain 33-155: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 33-156: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 33-157: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 33-158: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 33-159: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 33-160: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 33-161: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 33-162: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-163: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 33-164: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 33-165: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 33-166: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-167: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 33-168: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 33-169: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 33-170: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 33-171: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 33-172: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 33-173: Loss: 0.1958 Acc: 75.0000%\n",
      "\ttrain 33-174: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 33-175: Loss: 0.0918 Acc: 100.0000%\n",
      "\ttrain 33-176: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 33-177: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 33-178: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 33-179: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 33-180: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 33-181: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 33-182: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 33-183: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 33-184: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 33-185: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-186: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-187: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 33-188: Loss: 0.9975 Acc: 25.0000%\n",
      "\ttrain 33-189: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 33-190: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 33-191: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 33-192: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 33-193: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 33-194: Loss: 0.6232 Acc: 25.0000%\n",
      "\ttrain 33-195: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-196: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 33-197: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 33-198: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 33-199: Loss: 0.0468 Acc: 75.0000%\n",
      "\ttrain 33-200: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 33-201: Loss: 0.9725 Acc: 50.0000%\n",
      "\ttrain 33-202: Loss: 0.1550 Acc: 75.0000%\n",
      "\ttrain 33-203: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 33-204: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 33-205: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-206: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 33-207: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 33-208: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 33-209: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 33-210: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 33-211: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 33-212: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 33-213: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-214: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 33-215: Loss: 0.0506 Acc: 75.0000%\n",
      "\ttrain 33-216: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 33-217: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-218: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 33-219: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 33-220: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 33-221: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 33-222: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 33-223: Loss: 0.2697 Acc: 50.0000%\n",
      "\ttrain 33-224: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 33-225: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 33-226: Loss: 0.8078 Acc: 50.0000%\n",
      "\ttrain 33-227: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-228: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 33-229: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 33-230: Loss: 0.2821 Acc: 75.0000%\n",
      "\ttrain 33-231: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 33-232: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 33-233: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-234: Loss: 0.2292 Acc: 50.0000%\n",
      "\ttrain 33-235: Loss: 0.0531 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-236: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 33-237: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 33-238: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 33-239: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 33-240: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 33-241: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 33-242: Loss: 0.3452 Acc: 50.0000%\n",
      "\ttrain 33-243: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-244: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 33-245: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 33-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-2: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 33-3: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-4: Loss: 0.2976 Acc: 75.0000%\n",
      "\tvalidation 33-5: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 33-6: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 33-7: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 33-8: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-9: Loss: 0.1588 Acc: 75.0000%\n",
      "\tvalidation 33-10: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 33-11: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 33-12: Loss: 1.4020 Acc: 75.0000%\n",
      "\tvalidation 33-13: Loss: 0.3294 Acc: 75.0000%\n",
      "\tvalidation 33-14: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 33-15: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 33-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-17: Loss: 0.2541 Acc: 75.0000%\n",
      "\tvalidation 33-18: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 33-19: Loss: 0.0647 Acc: 75.0000%\n",
      "\tvalidation 33-20: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-21: Loss: 2.0654 Acc: 75.0000%\n",
      "\tvalidation 33-22: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-23: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 33-24: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-25: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 33-26: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-27: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 33-28: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 33-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-30: Loss: 0.2744 Acc: 75.0000%\n",
      "\tvalidation 33-31: Loss: 2.9321 Acc: 75.0000%\n",
      "\tvalidation 33-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-33: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 33-34: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-36: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 33-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-38: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-39: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 33-40: Loss: 0.4579 Acc: 50.0000%\n",
      "\tvalidation 33-41: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-42: Loss: 1.1748 Acc: 75.0000%\n",
      "\tvalidation 33-43: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 33-44: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 33-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 33-46: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 33-47: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 33-48: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-49: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 33-50: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 33-51: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 33-52: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 33-53: Loss: 0.0728 Acc: 75.0000%\n",
      "\tvalidation 33-54: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-55: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 33-56: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 33-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 33-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-59: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 33-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-61: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 33-62: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-63: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 33-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-65: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 33-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 33-67: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 33-68: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 33-69: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-70: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 33-71: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-72: Loss: 0.3225 Acc: 75.0000%\n",
      "\tvalidation 33-73: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 33-74: Loss: 0.0970 Acc: 75.0000%\n",
      "\tvalidation 33-75: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 33-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-77: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-78: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 33-79: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 33-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 33-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-83: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 33-84: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 33-85: Loss: 0.0534 Acc: 75.0000%\n",
      "\tvalidation 33-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-87: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 33-88: Loss: 0.2392 Acc: 75.0000%\n",
      "\tvalidation 33-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 33-90: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 33-91: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 33-92: Loss: 0.2536 Acc: 75.0000%\n",
      "\tvalidation 33-93: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 33-94: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-95: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 33-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 33-97: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 33-98: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 33-99: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 33-100: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 33-101: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 33-103: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 33-104: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 33-105: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0677 Acc: 90.2041%\n",
      "\tvalidation Loss: 0.1048 Acc: 95.7143%\n",
      "Time passed 0h 23m 37s\n",
      "--------------------\n",
      "Epoch [34/40]:\n",
      "\ttrain 34-1: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-2: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 34-3: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 34-4: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-5: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 34-6: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 34-7: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-8: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-9: Loss: 0.1158 Acc: 75.0000%\n",
      "\ttrain 34-10: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 34-11: Loss: 0.1379 Acc: 75.0000%\n",
      "\ttrain 34-12: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 34-13: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 34-14: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 34-15: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 34-16: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 34-17: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 34-18: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 34-19: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 34-20: Loss: 0.0780 Acc: 75.0000%\n",
      "\ttrain 34-21: Loss: 0.1790 Acc: 75.0000%\n",
      "\ttrain 34-22: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 34-23: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 34-24: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 34-25: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 34-26: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-27: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 34-28: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 34-29: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 34-30: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 34-31: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 34-32: Loss: 0.1694 Acc: 50.0000%\n",
      "\ttrain 34-33: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 34-34: Loss: 0.8774 Acc: 0.0000%\n",
      "\ttrain 34-35: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 34-36: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-37: Loss: 0.3503 Acc: 25.0000%\n",
      "\ttrain 34-38: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 34-39: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 34-40: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 34-41: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-42: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-43: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 34-44: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-45: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 34-46: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 34-47: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 34-48: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-49: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 34-50: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 34-51: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-52: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 34-53: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 34-54: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 34-55: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 34-56: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 34-57: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 34-58: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 34-59: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-60: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-61: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-62: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 34-63: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 34-64: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 34-65: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 34-66: Loss: 0.0785 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-67: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 34-68: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 34-69: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 34-70: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 34-71: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 34-72: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 34-73: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-74: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 34-75: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-76: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 34-77: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 34-78: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 34-79: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 34-80: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 34-81: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 34-82: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 34-83: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 34-84: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 34-85: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-86: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 34-87: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-88: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-89: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 34-90: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 34-91: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-92: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 34-93: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 34-94: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 34-95: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 34-96: Loss: 0.0471 Acc: 75.0000%\n",
      "\ttrain 34-97: Loss: 0.2630 Acc: 75.0000%\n",
      "\ttrain 34-98: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 34-99: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 34-100: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-101: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 34-102: Loss: 0.1957 Acc: 75.0000%\n",
      "\ttrain 34-103: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 34-104: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 34-105: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-106: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 34-107: Loss: 0.2539 Acc: 75.0000%\n",
      "\ttrain 34-108: Loss: 0.1807 Acc: 75.0000%\n",
      "\ttrain 34-109: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 34-110: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 34-111: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 34-112: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 34-113: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 34-114: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 34-115: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 34-116: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 34-117: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 34-118: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 34-119: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-120: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 34-121: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 34-122: Loss: 0.2488 Acc: 50.0000%\n",
      "\ttrain 34-123: Loss: 0.1653 Acc: 50.0000%\n",
      "\ttrain 34-124: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-125: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 34-126: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 34-127: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 34-128: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-129: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-130: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 34-131: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 34-132: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 34-133: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 34-134: Loss: 0.3592 Acc: 50.0000%\n",
      "\ttrain 34-135: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 34-136: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 34-137: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-138: Loss: 0.3154 Acc: 75.0000%\n",
      "\ttrain 34-139: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 34-140: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 34-141: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-142: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 34-143: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 34-144: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 34-145: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 34-146: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 34-147: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-148: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 34-149: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 34-150: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 34-151: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 34-152: Loss: 0.2571 Acc: 75.0000%\n",
      "\ttrain 34-153: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 34-154: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 34-155: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-156: Loss: 0.1581 Acc: 75.0000%\n",
      "\ttrain 34-157: Loss: 0.0638 Acc: 100.0000%\n",
      "\ttrain 34-158: Loss: 0.7461 Acc: 0.0000%\n",
      "\ttrain 34-159: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 34-160: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 34-161: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 34-162: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 34-163: Loss: 0.4353 Acc: 75.0000%\n",
      "\ttrain 34-164: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 34-165: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 34-166: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 34-167: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 34-168: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 34-169: Loss: 0.1032 Acc: 50.0000%\n",
      "\ttrain 34-170: Loss: 0.4926 Acc: 25.0000%\n",
      "\ttrain 34-171: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 34-172: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 34-173: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 34-174: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 34-175: Loss: 0.0480 Acc: 75.0000%\n",
      "\ttrain 34-176: Loss: 0.0815 Acc: 75.0000%\n",
      "\ttrain 34-177: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 34-178: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 34-179: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 34-180: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 34-181: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 34-182: Loss: 0.2790 Acc: 50.0000%\n",
      "\ttrain 34-183: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 34-184: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 34-185: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 34-186: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 34-187: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 34-188: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 34-189: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 34-190: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 34-191: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 34-192: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-193: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 34-194: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 34-195: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 34-196: Loss: 0.2346 Acc: 50.0000%\n",
      "\ttrain 34-197: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-198: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-199: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-200: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 34-201: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 34-202: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 34-203: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 34-204: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 34-205: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-206: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 34-207: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 34-208: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-209: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-210: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 34-211: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-212: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 34-213: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 34-214: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 34-215: Loss: 0.1331 Acc: 75.0000%\n",
      "\ttrain 34-216: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 34-217: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 34-218: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 34-219: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 34-220: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 34-221: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 34-222: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 34-223: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 34-224: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 34-225: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 34-226: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 34-227: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 34-228: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 34-229: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 34-230: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 34-231: Loss: 0.0671 Acc: 75.0000%\n",
      "\ttrain 34-232: Loss: 0.3007 Acc: 75.0000%\n",
      "\ttrain 34-233: Loss: 0.2762 Acc: 75.0000%\n",
      "\ttrain 34-234: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 34-235: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 34-236: Loss: 0.1795 Acc: 75.0000%\n",
      "\ttrain 34-237: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 34-238: Loss: 0.1789 Acc: 75.0000%\n",
      "\ttrain 34-239: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-240: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 34-241: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 34-242: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 34-243: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 34-244: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 34-245: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 34-1: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-2: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 34-3: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 34-4: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-5: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-6: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 34-7: Loss: 0.2827 Acc: 75.0000%\n",
      "\tvalidation 34-8: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-9: Loss: 0.2987 Acc: 50.0000%\n",
      "\tvalidation 34-10: Loss: 0.1110 Acc: 75.0000%\n",
      "\tvalidation 34-11: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 34-12: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 34-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-14: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 34-15: Loss: 0.1143 Acc: 75.0000%\n",
      "\tvalidation 34-16: Loss: 0.0005 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 34-17: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 34-18: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 34-19: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 34-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-21: Loss: 0.0486 Acc: 75.0000%\n",
      "\tvalidation 34-22: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-23: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 34-24: Loss: 5.7602 Acc: 50.0000%\n",
      "\tvalidation 34-25: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 34-26: Loss: 0.5930 Acc: 50.0000%\n",
      "\tvalidation 34-27: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-28: Loss: 0.1564 Acc: 75.0000%\n",
      "\tvalidation 34-29: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 34-30: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 34-31: Loss: 2.2480 Acc: 75.0000%\n",
      "\tvalidation 34-32: Loss: 0.2426 Acc: 75.0000%\n",
      "\tvalidation 34-33: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-34: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 34-35: Loss: 0.2857 Acc: 75.0000%\n",
      "\tvalidation 34-36: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-37: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 34-38: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 34-39: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 34-40: Loss: 0.0793 Acc: 75.0000%\n",
      "\tvalidation 34-41: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 34-42: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 34-43: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 34-44: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 34-45: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 34-46: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 34-47: Loss: 0.1499 Acc: 75.0000%\n",
      "\tvalidation 34-48: Loss: 0.0750 Acc: 75.0000%\n",
      "\tvalidation 34-49: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-50: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 34-51: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-52: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 34-53: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 34-54: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-55: Loss: 0.1087 Acc: 75.0000%\n",
      "\tvalidation 34-56: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-57: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-58: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 34-59: Loss: 0.0614 Acc: 75.0000%\n",
      "\tvalidation 34-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-61: Loss: 0.3238 Acc: 75.0000%\n",
      "\tvalidation 34-62: Loss: 0.0997 Acc: 75.0000%\n",
      "\tvalidation 34-63: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 34-64: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 34-65: Loss: 0.0520 Acc: 75.0000%\n",
      "\tvalidation 34-66: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-67: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 34-68: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 34-69: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-70: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 34-71: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-72: Loss: 7.2566 Acc: 75.0000%\n",
      "\tvalidation 34-73: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-74: Loss: 0.9764 Acc: 75.0000%\n",
      "\tvalidation 34-75: Loss: 0.0801 Acc: 100.0000%\n",
      "\tvalidation 34-76: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-77: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-78: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 34-79: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-80: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 34-81: Loss: 0.9243 Acc: 75.0000%\n",
      "\tvalidation 34-82: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 34-83: Loss: 0.1095 Acc: 75.0000%\n",
      "\tvalidation 34-84: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-85: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 34-86: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 34-87: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 34-88: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-89: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 34-90: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 34-91: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 34-92: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 34-93: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 34-94: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 34-95: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 34-96: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 34-97: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 34-98: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 34-99: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 34-100: Loss: 0.2411 Acc: 75.0000%\n",
      "\tvalidation 34-101: Loss: 4.9100 Acc: 75.0000%\n",
      "\tvalidation 34-102: Loss: 0.6429 Acc: 50.0000%\n",
      "\tvalidation 34-103: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 34-104: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 34-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0533 Acc: 92.5510%\n",
      "\tvalidation Loss: 0.2542 Acc: 92.8571%\n",
      "Time passed 0h 24m 37s\n",
      "--------------------\n",
      "Epoch [35/40]:\n",
      "\ttrain 35-1: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 35-2: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 35-3: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 35-4: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 35-5: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-6: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 35-7: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 35-8: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 35-9: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 35-10: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 35-11: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 35-12: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 35-13: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 35-14: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 35-15: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 35-16: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 35-17: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 35-18: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 35-19: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 35-20: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 35-21: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 35-22: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-23: Loss: 0.1186 Acc: 100.0000%\n",
      "\ttrain 35-24: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-25: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 35-26: Loss: 0.3705 Acc: 75.0000%\n",
      "\ttrain 35-27: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-28: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 35-29: Loss: 0.3710 Acc: 75.0000%\n",
      "\ttrain 35-30: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 35-31: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 35-32: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-33: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 35-34: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 35-35: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 35-36: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 35-37: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 35-38: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 35-39: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 35-40: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 35-41: Loss: 0.0900 Acc: 75.0000%\n",
      "\ttrain 35-42: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-43: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 35-44: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-45: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 35-46: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 35-47: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 35-48: Loss: 0.2194 Acc: 75.0000%\n",
      "\ttrain 35-49: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 35-50: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 35-51: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 35-52: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 35-53: Loss: 0.0800 Acc: 75.0000%\n",
      "\ttrain 35-54: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 35-55: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 35-56: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 35-57: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 35-58: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 35-59: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 35-60: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 35-61: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 35-62: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 35-63: Loss: 0.1698 Acc: 75.0000%\n",
      "\ttrain 35-64: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 35-65: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-66: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-67: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-68: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 35-69: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 35-70: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-71: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-72: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-73: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 35-74: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 35-75: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 35-76: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-77: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 35-78: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 35-79: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 35-80: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 35-81: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 35-82: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-83: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 35-84: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 35-85: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 35-86: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 35-87: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-88: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 35-89: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 35-90: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 35-91: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-92: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 35-93: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 35-94: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-95: Loss: 0.0150 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-96: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 35-97: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 35-98: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-99: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 35-100: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 35-101: Loss: 0.1764 Acc: 75.0000%\n",
      "\ttrain 35-102: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 35-103: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 35-104: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 35-105: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-106: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 35-107: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 35-108: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-109: Loss: 0.2933 Acc: 75.0000%\n",
      "\ttrain 35-110: Loss: 0.3716 Acc: 50.0000%\n",
      "\ttrain 35-111: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 35-112: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 35-113: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 35-114: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 35-115: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 35-116: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 35-117: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-118: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 35-119: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 35-120: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 35-121: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-122: Loss: 0.5923 Acc: 50.0000%\n",
      "\ttrain 35-123: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-124: Loss: 0.2257 Acc: 50.0000%\n",
      "\ttrain 35-125: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 35-126: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 35-127: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 35-128: Loss: 0.4736 Acc: 25.0000%\n",
      "\ttrain 35-129: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-130: Loss: 0.4293 Acc: 50.0000%\n",
      "\ttrain 35-131: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-132: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 35-133: Loss: 0.3179 Acc: 50.0000%\n",
      "\ttrain 35-134: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 35-135: Loss: 0.1428 Acc: 75.0000%\n",
      "\ttrain 35-136: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 35-137: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-138: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 35-139: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 35-140: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-141: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 35-142: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-143: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 35-144: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-145: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-146: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 35-147: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 35-148: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 35-149: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 35-150: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 35-151: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 35-152: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 35-153: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 35-154: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-155: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 35-156: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 35-157: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 35-158: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-159: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-160: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 35-161: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 35-162: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 35-163: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 35-164: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 35-165: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 35-166: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 35-167: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-168: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 35-169: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 35-170: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 35-171: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 35-172: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-173: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-174: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 35-175: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 35-176: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-177: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 35-178: Loss: 0.2124 Acc: 75.0000%\n",
      "\ttrain 35-179: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 35-180: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-181: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 35-182: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 35-183: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 35-184: Loss: 0.3281 Acc: 75.0000%\n",
      "\ttrain 35-185: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 35-186: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 35-187: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 35-188: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 35-189: Loss: 0.1306 Acc: 75.0000%\n",
      "\ttrain 35-190: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 35-191: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 35-192: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-193: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 35-194: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 35-195: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 35-196: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 35-197: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 35-198: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 35-199: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 35-200: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-201: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 35-202: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 35-203: Loss: 0.0650 Acc: 75.0000%\n",
      "\ttrain 35-204: Loss: 0.1600 Acc: 75.0000%\n",
      "\ttrain 35-205: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-206: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-207: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-208: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-209: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 35-210: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 35-211: Loss: 0.0744 Acc: 100.0000%\n",
      "\ttrain 35-212: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 35-213: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 35-214: Loss: 0.4761 Acc: 50.0000%\n",
      "\ttrain 35-215: Loss: 0.0498 Acc: 75.0000%\n",
      "\ttrain 35-216: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 35-217: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-218: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 35-219: Loss: 0.4551 Acc: 75.0000%\n",
      "\ttrain 35-220: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-221: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 35-222: Loss: 0.2920 Acc: 50.0000%\n",
      "\ttrain 35-223: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 35-224: Loss: 0.0512 Acc: 75.0000%\n",
      "\ttrain 35-225: Loss: 0.1735 Acc: 75.0000%\n",
      "\ttrain 35-226: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 35-227: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 35-228: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 35-229: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 35-230: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 35-231: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 35-232: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 35-233: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 35-234: Loss: 0.3309 Acc: 50.0000%\n",
      "\ttrain 35-235: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 35-236: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-237: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 35-238: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 35-239: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 35-240: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-241: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 35-242: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-243: Loss: 0.2677 Acc: 75.0000%\n",
      "\ttrain 35-244: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 35-245: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-1: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 35-2: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 35-3: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 35-4: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-5: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-6: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-7: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 35-8: Loss: 0.0738 Acc: 75.0000%\n",
      "\tvalidation 35-9: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-10: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 35-11: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-12: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-13: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 35-14: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 35-15: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 35-16: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 35-17: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-18: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-19: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-20: Loss: 1.5133 Acc: 75.0000%\n",
      "\tvalidation 35-21: Loss: 0.0482 Acc: 75.0000%\n",
      "\tvalidation 35-22: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-23: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 35-24: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 35-25: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 35-26: Loss: 0.0639 Acc: 75.0000%\n",
      "\tvalidation 35-27: Loss: 0.0493 Acc: 100.0000%\n",
      "\tvalidation 35-28: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 35-29: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-30: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 35-31: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-32: Loss: 0.3402 Acc: 75.0000%\n",
      "\tvalidation 35-33: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-34: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-35: Loss: 0.0468 Acc: 100.0000%\n",
      "\tvalidation 35-36: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-37: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-38: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 35-39: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 35-40: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-41: Loss: 0.0287 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 35-42: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 35-43: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-44: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 35-45: Loss: 1.6933 Acc: 75.0000%\n",
      "\tvalidation 35-46: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 35-47: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 35-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-49: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-50: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 35-51: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-52: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 35-53: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 35-54: Loss: 0.0195 Acc: 100.0000%\n",
      "\tvalidation 35-55: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-56: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 35-57: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-58: Loss: 0.5398 Acc: 75.0000%\n",
      "\tvalidation 35-59: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 35-60: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-62: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 35-63: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 35-64: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-65: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 35-66: Loss: 0.0594 Acc: 75.0000%\n",
      "\tvalidation 35-67: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-68: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 35-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-70: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-71: Loss: 0.1400 Acc: 75.0000%\n",
      "\tvalidation 35-72: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-73: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 35-74: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 35-75: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-76: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-77: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-78: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 35-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-80: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 35-81: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 35-82: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 35-83: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 35-84: Loss: 2.8432 Acc: 75.0000%\n",
      "\tvalidation 35-85: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-86: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-87: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 35-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-89: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 35-90: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-91: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 35-92: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 35-93: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 35-94: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 35-95: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-96: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 35-97: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 35-98: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-99: Loss: 0.0356 Acc: 100.0000%\n",
      "\tvalidation 35-100: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-101: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 35-102: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-103: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 35-104: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 35-105: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0569 Acc: 92.7551%\n",
      "\tvalidation Loss: 0.0759 Acc: 97.6190%\n",
      "Time passed 0h 25m 35s\n",
      "--------------------\n",
      "Epoch [36/40]:\n",
      "\ttrain 36-1: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 36-2: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-3: Loss: 0.2680 Acc: 50.0000%\n",
      "\ttrain 36-4: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-5: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 36-6: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 36-7: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 36-8: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-9: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 36-10: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 36-11: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 36-12: Loss: 0.1114 Acc: 100.0000%\n",
      "\ttrain 36-13: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-14: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-15: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 36-16: Loss: 0.2919 Acc: 75.0000%\n",
      "\ttrain 36-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-18: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 36-19: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 36-20: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 36-21: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 36-22: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-23: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 36-24: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 36-25: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 36-26: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-27: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 36-28: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 36-29: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-30: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 36-31: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 36-32: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 36-33: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 36-34: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-35: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 36-36: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-37: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-38: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 36-39: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-40: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-41: Loss: 0.1241 Acc: 75.0000%\n",
      "\ttrain 36-42: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-43: Loss: 0.1676 Acc: 75.0000%\n",
      "\ttrain 36-44: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-45: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-46: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-47: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-48: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 36-49: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-50: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 36-51: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 36-52: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 36-53: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 36-54: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 36-55: Loss: 0.1707 Acc: 75.0000%\n",
      "\ttrain 36-56: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-57: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 36-58: Loss: 0.1305 Acc: 75.0000%\n",
      "\ttrain 36-59: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 36-60: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-61: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 36-62: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 36-63: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 36-64: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-65: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 36-66: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 36-67: Loss: 0.0867 Acc: 100.0000%\n",
      "\ttrain 36-68: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 36-69: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-70: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 36-71: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 36-72: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-73: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 36-74: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 36-75: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-76: Loss: 0.3440 Acc: 75.0000%\n",
      "\ttrain 36-77: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-78: Loss: 0.2775 Acc: 75.0000%\n",
      "\ttrain 36-79: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 36-80: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-81: Loss: 0.4177 Acc: 75.0000%\n",
      "\ttrain 36-82: Loss: 0.2461 Acc: 75.0000%\n",
      "\ttrain 36-83: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 36-84: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 36-85: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-86: Loss: 0.1657 Acc: 75.0000%\n",
      "\ttrain 36-87: Loss: 0.1839 Acc: 75.0000%\n",
      "\ttrain 36-88: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 36-89: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 36-90: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 36-91: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 36-92: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 36-93: Loss: 0.1400 Acc: 75.0000%\n",
      "\ttrain 36-94: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 36-95: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 36-96: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-97: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 36-98: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 36-99: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-100: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 36-101: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 36-102: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 36-103: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 36-104: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 36-105: Loss: 0.2845 Acc: 50.0000%\n",
      "\ttrain 36-106: Loss: 0.4356 Acc: 25.0000%\n",
      "\ttrain 36-107: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 36-108: Loss: 0.1230 Acc: 75.0000%\n",
      "\ttrain 36-109: Loss: 0.2395 Acc: 75.0000%\n",
      "\ttrain 36-110: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 36-111: Loss: 0.1995 Acc: 75.0000%\n",
      "\ttrain 36-112: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-113: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 36-114: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-115: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 36-116: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-117: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 36-118: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 36-119: Loss: 0.5349 Acc: 50.0000%\n",
      "\ttrain 36-120: Loss: 0.2159 Acc: 75.0000%\n",
      "\ttrain 36-121: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 36-122: Loss: 0.0880 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-123: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-124: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-125: Loss: 1.0476 Acc: 50.0000%\n",
      "\ttrain 36-126: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 36-127: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-128: Loss: 0.1788 Acc: 75.0000%\n",
      "\ttrain 36-129: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 36-130: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 36-131: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 36-132: Loss: 0.3922 Acc: 75.0000%\n",
      "\ttrain 36-133: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 36-134: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 36-135: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 36-136: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 36-137: Loss: 0.1185 Acc: 75.0000%\n",
      "\ttrain 36-138: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 36-139: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 36-140: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 36-141: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 36-142: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-143: Loss: 0.1362 Acc: 75.0000%\n",
      "\ttrain 36-144: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 36-145: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 36-146: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-147: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 36-148: Loss: 0.4245 Acc: 50.0000%\n",
      "\ttrain 36-149: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-150: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-151: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 36-152: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-153: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 36-154: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 36-155: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 36-156: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 36-157: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 36-158: Loss: 0.0996 Acc: 75.0000%\n",
      "\ttrain 36-159: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 36-160: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-161: Loss: 0.5361 Acc: 50.0000%\n",
      "\ttrain 36-162: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 36-163: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 36-164: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 36-165: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 36-166: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 36-167: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 36-168: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-169: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 36-170: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 36-171: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 36-172: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-173: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 36-174: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 36-175: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 36-176: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 36-177: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 36-178: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 36-179: Loss: 0.0890 Acc: 75.0000%\n",
      "\ttrain 36-180: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 36-181: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 36-182: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 36-183: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 36-184: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 36-185: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 36-186: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 36-187: Loss: 0.0704 Acc: 100.0000%\n",
      "\ttrain 36-188: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 36-189: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 36-190: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 36-191: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 36-192: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 36-193: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 36-194: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 36-195: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 36-196: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 36-197: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-198: Loss: 0.1364 Acc: 50.0000%\n",
      "\ttrain 36-199: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 36-200: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 36-201: Loss: 0.0721 Acc: 100.0000%\n",
      "\ttrain 36-202: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 36-203: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 36-204: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 36-205: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-206: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-207: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 36-208: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 36-209: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 36-210: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 36-211: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 36-212: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 36-213: Loss: 0.0523 Acc: 75.0000%\n",
      "\ttrain 36-214: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 36-215: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 36-216: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 36-217: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 36-218: Loss: 0.2508 Acc: 75.0000%\n",
      "\ttrain 36-219: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 36-220: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 36-221: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 36-222: Loss: 0.0568 Acc: 75.0000%\n",
      "\ttrain 36-223: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 36-224: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 36-225: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-226: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 36-227: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 36-228: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 36-229: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 36-230: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-231: Loss: 0.4542 Acc: 25.0000%\n",
      "\ttrain 36-232: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 36-233: Loss: 0.1051 Acc: 75.0000%\n",
      "\ttrain 36-234: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 36-235: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 36-236: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 36-237: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 36-238: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 36-239: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-240: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-241: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 36-242: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-243: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-244: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-245: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 36-1: Loss: 0.2984 Acc: 75.0000%\n",
      "\tvalidation 36-2: Loss: 0.1649 Acc: 75.0000%\n",
      "\tvalidation 36-3: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 36-4: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 36-5: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 36-6: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-8: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 36-9: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-10: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 36-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-13: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 36-14: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 36-15: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 36-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-17: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-22: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 36-23: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 36-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-26: Loss: 0.0162 Acc: 100.0000%\n",
      "\tvalidation 36-27: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-28: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 36-29: Loss: 0.1886 Acc: 50.0000%\n",
      "\tvalidation 36-30: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 36-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-32: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 36-33: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-34: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 36-35: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 36-36: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 36-37: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 36-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-39: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 36-40: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-41: Loss: 2.2985 Acc: 75.0000%\n",
      "\tvalidation 36-42: Loss: 5.4101 Acc: 75.0000%\n",
      "\tvalidation 36-43: Loss: 0.0376 Acc: 100.0000%\n",
      "\tvalidation 36-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-45: Loss: 0.9555 Acc: 75.0000%\n",
      "\tvalidation 36-46: Loss: 0.2669 Acc: 75.0000%\n",
      "\tvalidation 36-47: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 36-48: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 36-49: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 36-50: Loss: 0.0641 Acc: 75.0000%\n",
      "\tvalidation 36-51: Loss: 7.8033 Acc: 75.0000%\n",
      "\tvalidation 36-52: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-53: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 36-54: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 36-55: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 36-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-57: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 36-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-59: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 36-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-61: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 36-62: Loss: 1.0847 Acc: 75.0000%\n",
      "\tvalidation 36-63: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 36-64: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 36-65: Loss: 0.1532 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 36-66: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 36-67: Loss: 4.8946 Acc: 50.0000%\n",
      "\tvalidation 36-68: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 36-69: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 36-70: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 36-71: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-72: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 36-73: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 36-74: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 36-75: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 36-76: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 36-77: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 36-78: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-79: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 36-80: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 36-81: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 36-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-83: Loss: 1.0364 Acc: 75.0000%\n",
      "\tvalidation 36-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-85: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 36-86: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-87: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 36-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-90: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 36-91: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 36-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-94: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 36-95: Loss: 1.2429 Acc: 75.0000%\n",
      "\tvalidation 36-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-97: Loss: 0.0749 Acc: 75.0000%\n",
      "\tvalidation 36-98: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 36-99: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-100: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 36-101: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 36-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 36-103: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 36-104: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-105: Loss: 0.4366 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0631 Acc: 90.9184%\n",
      "\tvalidation Loss: 0.2571 Acc: 95.4762%\n",
      "Time passed 0h 26m 34s\n",
      "--------------------\n",
      "Epoch [37/40]:\n",
      "\ttrain 37-1: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-2: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-3: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-4: Loss: 0.4765 Acc: 50.0000%\n",
      "\ttrain 37-5: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 37-6: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 37-7: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 37-8: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-9: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 37-10: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 37-11: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 37-12: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 37-13: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 37-14: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 37-15: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-16: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-17: Loss: 0.2203 Acc: 75.0000%\n",
      "\ttrain 37-18: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-19: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 37-20: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-21: Loss: 0.2577 Acc: 75.0000%\n",
      "\ttrain 37-22: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 37-23: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 37-24: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 37-25: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 37-26: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 37-27: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 37-28: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 37-29: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 37-30: Loss: 0.2436 Acc: 75.0000%\n",
      "\ttrain 37-31: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 37-32: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 37-33: Loss: 0.2337 Acc: 75.0000%\n",
      "\ttrain 37-34: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 37-35: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-36: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 37-37: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-38: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 37-39: Loss: 0.2246 Acc: 50.0000%\n",
      "\ttrain 37-40: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 37-41: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 37-42: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 37-43: Loss: 0.4210 Acc: 50.0000%\n",
      "\ttrain 37-44: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 37-45: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 37-46: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-47: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 37-48: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-49: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 37-50: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-51: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 37-52: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 37-53: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-54: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 37-55: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 37-56: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-57: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 37-58: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 37-59: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 37-60: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 37-61: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 37-62: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-63: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 37-64: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 37-65: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 37-66: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 37-67: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 37-68: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 37-69: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 37-70: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 37-71: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 37-72: Loss: 0.0713 Acc: 100.0000%\n",
      "\ttrain 37-73: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-74: Loss: 0.0939 Acc: 75.0000%\n",
      "\ttrain 37-75: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-76: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-77: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 37-78: Loss: 0.2496 Acc: 75.0000%\n",
      "\ttrain 37-79: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 37-80: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 37-81: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-82: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 37-83: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-84: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 37-85: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 37-86: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 37-87: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-88: Loss: 0.0913 Acc: 100.0000%\n",
      "\ttrain 37-89: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-90: Loss: 0.2627 Acc: 50.0000%\n",
      "\ttrain 37-91: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-92: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 37-93: Loss: 0.1582 Acc: 75.0000%\n",
      "\ttrain 37-94: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 37-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-96: Loss: 0.0879 Acc: 75.0000%\n",
      "\ttrain 37-97: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-98: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 37-99: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 37-100: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 37-101: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 37-102: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 37-103: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-104: Loss: 0.1751 Acc: 50.0000%\n",
      "\ttrain 37-105: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 37-106: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 37-107: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 37-108: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 37-109: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 37-110: Loss: 0.2471 Acc: 75.0000%\n",
      "\ttrain 37-111: Loss: 0.0801 Acc: 75.0000%\n",
      "\ttrain 37-112: Loss: 0.1135 Acc: 75.0000%\n",
      "\ttrain 37-113: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 37-114: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 37-115: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-116: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 37-117: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 37-118: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 37-119: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 37-120: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 37-121: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 37-122: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 37-123: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 37-124: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-125: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 37-126: Loss: 0.4191 Acc: 75.0000%\n",
      "\ttrain 37-127: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-128: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-129: Loss: 0.2175 Acc: 75.0000%\n",
      "\ttrain 37-130: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 37-131: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 37-132: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 37-133: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 37-134: Loss: 0.1558 Acc: 50.0000%\n",
      "\ttrain 37-135: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 37-136: Loss: 0.2006 Acc: 75.0000%\n",
      "\ttrain 37-137: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-138: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 37-139: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 37-140: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 37-141: Loss: 0.2849 Acc: 50.0000%\n",
      "\ttrain 37-142: Loss: 0.2331 Acc: 75.0000%\n",
      "\ttrain 37-143: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 37-144: Loss: 0.2207 Acc: 75.0000%\n",
      "\ttrain 37-145: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 37-146: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 37-147: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 37-148: Loss: 0.0100 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-149: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 37-150: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 37-151: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 37-152: Loss: 0.7222 Acc: 50.0000%\n",
      "\ttrain 37-153: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-154: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 37-155: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 37-156: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 37-157: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 37-158: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 37-159: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-160: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 37-161: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 37-162: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-163: Loss: 0.3569 Acc: 75.0000%\n",
      "\ttrain 37-164: Loss: 0.1599 Acc: 75.0000%\n",
      "\ttrain 37-165: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-166: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 37-167: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 37-168: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 37-169: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 37-170: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 37-171: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-172: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 37-173: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 37-174: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 37-175: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 37-176: Loss: 0.1696 Acc: 50.0000%\n",
      "\ttrain 37-177: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 37-178: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 37-179: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-180: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 37-181: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 37-182: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 37-183: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-184: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 37-185: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 37-186: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-187: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 37-188: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-189: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-190: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 37-191: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 37-192: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 37-193: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 37-194: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 37-195: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 37-196: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-197: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 37-198: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 37-199: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 37-200: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 37-201: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 37-202: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 37-203: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 37-204: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 37-205: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 37-206: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 37-207: Loss: 0.6320 Acc: 75.0000%\n",
      "\ttrain 37-208: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-209: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-210: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 37-211: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 37-212: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 37-213: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 37-214: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 37-215: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 37-216: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 37-217: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-218: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 37-219: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-220: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 37-221: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-222: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-223: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 37-224: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 37-225: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-226: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-227: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 37-228: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 37-229: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 37-230: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 37-231: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 37-232: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-233: Loss: 0.0517 Acc: 75.0000%\n",
      "\ttrain 37-234: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 37-235: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 37-236: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 37-237: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 37-238: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-239: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 37-240: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 37-241: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-242: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 37-243: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 37-244: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 37-245: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 37-1: Loss: 3.7444 Acc: 75.0000%\n",
      "\tvalidation 37-2: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 37-3: Loss: 0.4458 Acc: 75.0000%\n",
      "\tvalidation 37-4: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-6: Loss: 0.1528 Acc: 75.0000%\n",
      "\tvalidation 37-7: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-8: Loss: 0.3312 Acc: 75.0000%\n",
      "\tvalidation 37-9: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-10: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 37-11: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-12: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 37-13: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-14: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-15: Loss: 0.8163 Acc: 75.0000%\n",
      "\tvalidation 37-16: Loss: 0.0810 Acc: 75.0000%\n",
      "\tvalidation 37-17: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-19: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-21: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 37-22: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-23: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-24: Loss: 0.0973 Acc: 75.0000%\n",
      "\tvalidation 37-25: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-27: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-28: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-30: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 37-31: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-33: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 37-34: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-38: Loss: 0.5466 Acc: 75.0000%\n",
      "\tvalidation 37-39: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 37-40: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-41: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 37-42: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-43: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-44: Loss: 1.3442 Acc: 75.0000%\n",
      "\tvalidation 37-45: Loss: 3.4052 Acc: 75.0000%\n",
      "\tvalidation 37-46: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-47: Loss: 0.0379 Acc: 100.0000%\n",
      "\tvalidation 37-48: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 37-49: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 37-50: Loss: 0.1131 Acc: 75.0000%\n",
      "\tvalidation 37-51: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-53: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-54: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 37-55: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 37-56: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 37-57: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 37-58: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-59: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-60: Loss: 0.0804 Acc: 75.0000%\n",
      "\tvalidation 37-61: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-62: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 37-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-64: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 37-65: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 37-66: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 37-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-68: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-69: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 37-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-71: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 37-72: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-74: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 37-75: Loss: 6.0277 Acc: 75.0000%\n",
      "\tvalidation 37-76: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 37-77: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 37-78: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 37-79: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-81: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-82: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-83: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-86: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 37-87: Loss: 0.0229 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 37-88: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-89: Loss: 0.1556 Acc: 75.0000%\n",
      "\tvalidation 37-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-91: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 37-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-94: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 37-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-96: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-97: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 37-98: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-99: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-100: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-101: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-102: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-103: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 37-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0552 Acc: 92.5510%\n",
      "\tvalidation Loss: 0.1694 Acc: 96.4286%\n",
      "Time passed 0h 27m 35s\n",
      "--------------------\n",
      "Epoch [38/40]:\n",
      "\ttrain 38-1: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 38-2: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-3: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 38-4: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-5: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 38-6: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-7: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 38-8: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-9: Loss: 0.0732 Acc: 100.0000%\n",
      "\ttrain 38-10: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-11: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 38-12: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 38-13: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-14: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 38-15: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-16: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-17: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-18: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-19: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 38-20: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 38-21: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-22: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-23: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 38-24: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-25: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 38-26: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 38-27: Loss: 0.3960 Acc: 50.0000%\n",
      "\ttrain 38-28: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-29: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 38-30: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-31: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-32: Loss: 0.2135 Acc: 75.0000%\n",
      "\ttrain 38-33: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-35: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-36: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 38-37: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-38: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-39: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 38-40: Loss: 0.7047 Acc: 0.0000%\n",
      "\ttrain 38-41: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 38-42: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-43: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-44: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-45: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 38-46: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-47: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 38-48: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 38-49: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 38-50: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 38-51: Loss: 0.2046 Acc: 75.0000%\n",
      "\ttrain 38-52: Loss: 0.4229 Acc: 75.0000%\n",
      "\ttrain 38-53: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 38-54: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 38-55: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 38-56: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 38-57: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 38-58: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 38-59: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 38-60: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 38-61: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 38-62: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 38-63: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 38-64: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 38-65: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-66: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 38-67: Loss: 0.1567 Acc: 75.0000%\n",
      "\ttrain 38-68: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 38-69: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 38-70: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 38-71: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 38-72: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 38-73: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 38-74: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-75: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 38-76: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 38-77: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 38-78: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-79: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 38-80: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 38-81: Loss: 1.1338 Acc: 25.0000%\n",
      "\ttrain 38-82: Loss: 0.0740 Acc: 75.0000%\n",
      "\ttrain 38-83: Loss: 0.0632 Acc: 75.0000%\n",
      "\ttrain 38-84: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-85: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 38-86: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-87: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 38-88: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-89: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-90: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 38-91: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 38-92: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-94: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-95: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 38-96: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-97: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 38-98: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 38-99: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 38-100: Loss: 0.2539 Acc: 75.0000%\n",
      "\ttrain 38-101: Loss: 0.2696 Acc: 75.0000%\n",
      "\ttrain 38-102: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-103: Loss: 0.0865 Acc: 100.0000%\n",
      "\ttrain 38-104: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 38-105: Loss: 0.2505 Acc: 75.0000%\n",
      "\ttrain 38-106: Loss: 0.1426 Acc: 75.0000%\n",
      "\ttrain 38-107: Loss: 0.1951 Acc: 75.0000%\n",
      "\ttrain 38-108: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 38-109: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 38-110: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 38-111: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 38-112: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 38-113: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 38-114: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 38-115: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-116: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 38-117: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-118: Loss: 0.2247 Acc: 50.0000%\n",
      "\ttrain 38-119: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 38-120: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 38-121: Loss: 0.0762 Acc: 100.0000%\n",
      "\ttrain 38-122: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 38-123: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 38-124: Loss: 0.2282 Acc: 75.0000%\n",
      "\ttrain 38-125: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 38-126: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 38-127: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 38-128: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-129: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-130: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 38-131: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-132: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 38-133: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 38-134: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 38-135: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 38-136: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 38-137: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 38-138: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-139: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 38-140: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 38-141: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-142: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 38-143: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 38-144: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 38-145: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 38-146: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 38-147: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 38-148: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 38-149: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 38-150: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 38-151: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 38-152: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-153: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 38-154: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-155: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 38-156: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 38-157: Loss: 0.0525 Acc: 75.0000%\n",
      "\ttrain 38-158: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-159: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 38-160: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 38-161: Loss: 0.1335 Acc: 75.0000%\n",
      "\ttrain 38-162: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 38-163: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 38-164: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 38-165: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 38-166: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 38-167: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 38-168: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 38-169: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-170: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 38-171: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 38-172: Loss: 0.0084 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 38-173: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-174: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 38-175: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 38-176: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 38-177: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 38-178: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 38-179: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-180: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 38-181: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 38-182: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 38-183: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-184: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-185: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 38-186: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 38-187: Loss: 0.2610 Acc: 75.0000%\n",
      "\ttrain 38-188: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 38-189: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-190: Loss: 0.1884 Acc: 75.0000%\n",
      "\ttrain 38-191: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 38-192: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 38-193: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 38-194: Loss: 0.4653 Acc: 50.0000%\n",
      "\ttrain 38-195: Loss: 0.0490 Acc: 100.0000%\n",
      "\ttrain 38-196: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 38-197: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 38-198: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 38-199: Loss: 0.2612 Acc: 75.0000%\n",
      "\ttrain 38-200: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-201: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 38-202: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-203: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 38-204: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-205: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 38-206: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 38-207: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 38-208: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-209: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 38-210: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-211: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 38-212: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 38-213: Loss: 0.2519 Acc: 50.0000%\n",
      "\ttrain 38-214: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 38-215: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-216: Loss: 1.1393 Acc: 50.0000%\n",
      "\ttrain 38-217: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 38-218: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-219: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 38-220: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-221: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-222: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-223: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 38-224: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 38-225: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 38-226: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 38-227: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-228: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-229: Loss: 0.3034 Acc: 75.0000%\n",
      "\ttrain 38-230: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 38-231: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 38-232: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 38-233: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 38-234: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-235: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 38-236: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 38-237: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 38-238: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-239: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 38-240: Loss: 0.5029 Acc: 50.0000%\n",
      "\ttrain 38-241: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 38-242: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 38-243: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 38-244: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 38-245: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 38-1: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-2: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-3: Loss: 0.3132 Acc: 75.0000%\n",
      "\tvalidation 38-4: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-5: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 38-6: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 38-7: Loss: 0.1872 Acc: 75.0000%\n",
      "\tvalidation 38-8: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-9: Loss: 0.0330 Acc: 100.0000%\n",
      "\tvalidation 38-10: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 38-11: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-12: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-13: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-14: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 38-15: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-16: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 38-17: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-18: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-19: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-20: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-21: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 38-22: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 38-23: Loss: 0.1164 Acc: 75.0000%\n",
      "\tvalidation 38-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-25: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 38-26: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-29: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-30: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 38-31: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 38-32: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 38-33: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-34: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 38-35: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-36: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 38-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-38: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 38-39: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 38-40: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-42: Loss: 1.3648 Acc: 75.0000%\n",
      "\tvalidation 38-43: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 38-44: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-45: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-46: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 38-47: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-48: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 38-49: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-50: Loss: 0.0273 Acc: 100.0000%\n",
      "\tvalidation 38-51: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-52: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-53: Loss: 0.1840 Acc: 75.0000%\n",
      "\tvalidation 38-54: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-55: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-56: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-57: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 38-58: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-60: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-62: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 38-63: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-65: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-66: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 38-67: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 38-68: Loss: 0.2497 Acc: 75.0000%\n",
      "\tvalidation 38-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-70: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-71: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 38-72: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 38-73: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-75: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-76: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 38-77: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-78: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 38-79: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-80: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-81: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 38-82: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 38-83: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 38-84: Loss: 0.0520 Acc: 75.0000%\n",
      "\tvalidation 38-85: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-86: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-87: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 38-88: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-89: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-90: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 38-91: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-92: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-93: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-94: Loss: 0.5997 Acc: 75.0000%\n",
      "\tvalidation 38-95: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-96: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 38-97: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-98: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-99: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 38-100: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-101: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 38-102: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-103: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 38-104: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 38-105: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0565 Acc: 93.0612%\n",
      "\tvalidation Loss: 0.0339 Acc: 98.0952%\n",
      "Time passed 0h 28m 35s\n",
      "--------------------\n",
      "Epoch [39/40]:\n",
      "\ttrain 39-1: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 39-2: Loss: 0.0249 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-3: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 39-4: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 39-5: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 39-6: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 39-7: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 39-8: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 39-9: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 39-10: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 39-11: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 39-12: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-13: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 39-14: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-15: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-16: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-17: Loss: 0.1499 Acc: 50.0000%\n",
      "\ttrain 39-18: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 39-19: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 39-20: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 39-21: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 39-22: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 39-23: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-24: Loss: 0.2496 Acc: 75.0000%\n",
      "\ttrain 39-25: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 39-26: Loss: 0.3045 Acc: 75.0000%\n",
      "\ttrain 39-27: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 39-28: Loss: 0.0581 Acc: 100.0000%\n",
      "\ttrain 39-29: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 39-30: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 39-31: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 39-32: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 39-33: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 39-34: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 39-35: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 39-36: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-37: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 39-38: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 39-39: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 39-40: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 39-41: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 39-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-43: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 39-44: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 39-45: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 39-46: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-47: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 39-48: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 39-49: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 39-50: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 39-51: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 39-52: Loss: 0.2978 Acc: 75.0000%\n",
      "\ttrain 39-53: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-54: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 39-55: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 39-56: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 39-57: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 39-58: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 39-59: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-60: Loss: 0.1293 Acc: 50.0000%\n",
      "\ttrain 39-61: Loss: 0.2061 Acc: 75.0000%\n",
      "\ttrain 39-62: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 39-63: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-64: Loss: 0.0778 Acc: 100.0000%\n",
      "\ttrain 39-65: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 39-66: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 39-67: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-68: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 39-69: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 39-70: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-71: Loss: 0.3648 Acc: 75.0000%\n",
      "\ttrain 39-72: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-73: Loss: 0.5007 Acc: 75.0000%\n",
      "\ttrain 39-74: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 39-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-76: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 39-77: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 39-78: Loss: 0.3310 Acc: 50.0000%\n",
      "\ttrain 39-79: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-80: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 39-81: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-82: Loss: 0.2654 Acc: 75.0000%\n",
      "\ttrain 39-83: Loss: 0.2547 Acc: 75.0000%\n",
      "\ttrain 39-84: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 39-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-86: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 39-87: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-88: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-89: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-90: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 39-91: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 39-92: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-93: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 39-94: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 39-95: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 39-96: Loss: 0.3268 Acc: 50.0000%\n",
      "\ttrain 39-97: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 39-98: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 39-99: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-100: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 39-101: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 39-102: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 39-103: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 39-104: Loss: 0.2264 Acc: 75.0000%\n",
      "\ttrain 39-105: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 39-106: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 39-107: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 39-108: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-109: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 39-110: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 39-111: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 39-112: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-113: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-114: Loss: 0.3482 Acc: 25.0000%\n",
      "\ttrain 39-115: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 39-116: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 39-117: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 39-118: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 39-119: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 39-120: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 39-121: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-122: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 39-123: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 39-124: Loss: 0.1851 Acc: 75.0000%\n",
      "\ttrain 39-125: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 39-126: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-127: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 39-128: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 39-129: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 39-130: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 39-131: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-132: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 39-133: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 39-134: Loss: 0.3945 Acc: 50.0000%\n",
      "\ttrain 39-135: Loss: 0.2230 Acc: 50.0000%\n",
      "\ttrain 39-136: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-137: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-138: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 39-139: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 39-140: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 39-141: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 39-142: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 39-143: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 39-144: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 39-145: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 39-146: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 39-147: Loss: 0.1763 Acc: 75.0000%\n",
      "\ttrain 39-148: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-149: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 39-150: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-151: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 39-152: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 39-153: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-154: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 39-155: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-156: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 39-157: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 39-158: Loss: 0.0746 Acc: 100.0000%\n",
      "\ttrain 39-159: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 39-160: Loss: 0.0810 Acc: 75.0000%\n",
      "\ttrain 39-161: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 39-162: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-163: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 39-164: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-165: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 39-166: Loss: 0.6085 Acc: 75.0000%\n",
      "\ttrain 39-167: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 39-168: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 39-169: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-170: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 39-171: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 39-172: Loss: 0.0768 Acc: 100.0000%\n",
      "\ttrain 39-173: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 39-174: Loss: 0.2320 Acc: 75.0000%\n",
      "\ttrain 39-175: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 39-176: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 39-177: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 39-178: Loss: 0.2425 Acc: 75.0000%\n",
      "\ttrain 39-179: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-180: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-181: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 39-182: Loss: 0.0892 Acc: 100.0000%\n",
      "\ttrain 39-183: Loss: 0.1902 Acc: 75.0000%\n",
      "\ttrain 39-184: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 39-185: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-186: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 39-187: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 39-188: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-189: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 39-190: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-191: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-192: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-193: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 39-194: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 39-195: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 39-196: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 39-197: Loss: 0.0074 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-198: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 39-199: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-200: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-201: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 39-202: Loss: 0.1511 Acc: 75.0000%\n",
      "\ttrain 39-203: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 39-204: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 39-205: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 39-206: Loss: 0.1224 Acc: 75.0000%\n",
      "\ttrain 39-207: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 39-208: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-209: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 39-210: Loss: 0.1531 Acc: 75.0000%\n",
      "\ttrain 39-211: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-212: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 39-213: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-214: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-215: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 39-216: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 39-217: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 39-218: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 39-219: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 39-220: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 39-221: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 39-222: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 39-223: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 39-224: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 39-225: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 39-226: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 39-227: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 39-228: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 39-229: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 39-230: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 39-231: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-232: Loss: 0.2166 Acc: 50.0000%\n",
      "\ttrain 39-233: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-234: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 39-235: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-236: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 39-237: Loss: 0.1660 Acc: 75.0000%\n",
      "\ttrain 39-238: Loss: 0.1903 Acc: 75.0000%\n",
      "\ttrain 39-239: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-240: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 39-241: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 39-242: Loss: 0.0806 Acc: 75.0000%\n",
      "\ttrain 39-243: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 39-244: Loss: 0.2184 Acc: 75.0000%\n",
      "\ttrain 39-245: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 39-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-2: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 39-3: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 39-4: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-7: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-8: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 39-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-10: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-11: Loss: 0.7839 Acc: 75.0000%\n",
      "\tvalidation 39-12: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-13: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 39-14: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-15: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-16: Loss: 0.3543 Acc: 75.0000%\n",
      "\tvalidation 39-17: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 39-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-19: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 39-20: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 39-21: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 39-22: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-23: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 39-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-25: Loss: 0.0854 Acc: 75.0000%\n",
      "\tvalidation 39-26: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-28: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 39-29: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 39-30: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-32: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-33: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 39-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-35: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-36: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-37: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 39-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-39: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 39-40: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-41: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-42: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 39-43: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 39-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-45: Loss: 1.9597 Acc: 75.0000%\n",
      "\tvalidation 39-46: Loss: 0.3470 Acc: 75.0000%\n",
      "\tvalidation 39-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-48: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-50: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-51: Loss: 0.0499 Acc: 100.0000%\n",
      "\tvalidation 39-52: Loss: 0.0370 Acc: 100.0000%\n",
      "\tvalidation 39-53: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 39-54: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-55: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-56: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 39-57: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 39-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-59: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 39-60: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 39-61: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-62: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 39-63: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 39-64: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 39-65: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-67: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-68: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-69: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-70: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 39-71: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-72: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-73: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 39-74: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-75: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 39-76: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 39-77: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-78: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-79: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-80: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 39-81: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-82: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-83: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 39-84: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 39-85: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 39-86: Loss: 3.2091 Acc: 75.0000%\n",
      "\tvalidation 39-87: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-88: Loss: 1.8520 Acc: 75.0000%\n",
      "\tvalidation 39-89: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-90: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-91: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-93: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 39-94: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 39-95: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-96: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-97: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 39-98: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-99: Loss: 0.0594 Acc: 100.0000%\n",
      "\tvalidation 39-100: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 39-101: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 39-102: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 39-103: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 39-104: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 39-105: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0548 Acc: 93.0612%\n",
      "\tvalidation Loss: 0.0863 Acc: 98.3333%\n",
      "Time passed 0h 29m 36s\n",
      "--------------------\n",
      "Epoch [40/40]:\n",
      "\ttrain 40-1: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-2: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 40-3: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-4: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 40-5: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 40-6: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-7: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 40-8: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 40-9: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 40-10: Loss: 0.2062 Acc: 50.0000%\n",
      "\ttrain 40-11: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 40-12: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-13: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-15: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 40-16: Loss: 0.2974 Acc: 75.0000%\n",
      "\ttrain 40-17: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 40-18: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-19: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-20: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-21: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 40-22: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-23: Loss: 0.4938 Acc: 50.0000%\n",
      "\ttrain 40-24: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 40-25: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 40-26: Loss: 0.0707 Acc: 75.0000%\n",
      "\ttrain 40-27: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 40-28: Loss: 0.0951 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-29: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-30: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 40-31: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-32: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 40-33: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 40-34: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 40-35: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 40-36: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 40-37: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 40-38: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 40-39: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 40-40: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-41: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 40-42: Loss: 0.6244 Acc: 25.0000%\n",
      "\ttrain 40-43: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 40-44: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 40-45: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 40-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-47: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 40-48: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 40-49: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-50: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 40-51: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 40-52: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-53: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 40-54: Loss: 0.3498 Acc: 50.0000%\n",
      "\ttrain 40-55: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-56: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 40-57: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 40-58: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 40-59: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 40-60: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 40-61: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 40-62: Loss: 0.1929 Acc: 50.0000%\n",
      "\ttrain 40-63: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 40-64: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 40-65: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-66: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-67: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-68: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 40-69: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 40-70: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 40-71: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-72: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-73: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-74: Loss: 0.1891 Acc: 75.0000%\n",
      "\ttrain 40-75: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 40-76: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-77: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 40-78: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 40-79: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 40-80: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-81: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-82: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 40-83: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-84: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 40-85: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 40-86: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 40-87: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-88: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 40-89: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 40-90: Loss: 0.7241 Acc: 25.0000%\n",
      "\ttrain 40-91: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 40-92: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-93: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 40-94: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 40-95: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-96: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 40-97: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-98: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 40-99: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-100: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 40-101: Loss: 0.1503 Acc: 75.0000%\n",
      "\ttrain 40-102: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 40-103: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 40-104: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 40-105: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 40-106: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 40-107: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-108: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 40-109: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-110: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 40-111: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 40-112: Loss: 0.3723 Acc: 50.0000%\n",
      "\ttrain 40-113: Loss: 0.1723 Acc: 75.0000%\n",
      "\ttrain 40-114: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-115: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 40-116: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 40-117: Loss: 0.2136 Acc: 50.0000%\n",
      "\ttrain 40-118: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 40-119: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 40-120: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-121: Loss: 0.0952 Acc: 75.0000%\n",
      "\ttrain 40-122: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 40-123: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 40-124: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 40-125: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 40-126: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-127: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 40-128: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-129: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 40-130: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-131: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 40-132: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 40-133: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-134: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-135: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 40-136: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-137: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-138: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-139: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-140: Loss: 0.0960 Acc: 75.0000%\n",
      "\ttrain 40-141: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 40-142: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 40-143: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 40-144: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 40-145: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-146: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 40-147: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 40-148: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-149: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 40-150: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 40-151: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 40-152: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-153: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 40-154: Loss: 0.1255 Acc: 75.0000%\n",
      "\ttrain 40-155: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 40-156: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 40-157: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 40-158: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 40-159: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-160: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 40-161: Loss: 0.0778 Acc: 100.0000%\n",
      "\ttrain 40-162: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 40-163: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-164: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 40-165: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 40-166: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 40-167: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 40-168: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 40-169: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 40-170: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 40-171: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 40-172: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 40-173: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-174: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 40-175: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-176: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 40-177: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 40-178: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 40-179: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-180: Loss: 0.0677 Acc: 100.0000%\n",
      "\ttrain 40-181: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-182: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 40-183: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 40-184: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-185: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-186: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-187: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 40-188: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-189: Loss: 0.1396 Acc: 75.0000%\n",
      "\ttrain 40-190: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 40-191: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 40-192: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 40-193: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 40-194: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 40-195: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-196: Loss: 0.1775 Acc: 75.0000%\n",
      "\ttrain 40-197: Loss: 0.2980 Acc: 75.0000%\n",
      "\ttrain 40-198: Loss: 0.3427 Acc: 75.0000%\n",
      "\ttrain 40-199: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-200: Loss: 0.2745 Acc: 50.0000%\n",
      "\ttrain 40-201: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 40-202: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-203: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 40-204: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 40-205: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 40-206: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 40-207: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 40-208: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-209: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 40-210: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-211: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 40-212: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 40-213: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 40-214: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 40-215: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-216: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-217: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-218: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 40-219: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 40-220: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 40-221: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 40-222: Loss: 0.0117 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-223: Loss: 0.0701 Acc: 75.0000%\n",
      "\ttrain 40-224: Loss: 0.2203 Acc: 50.0000%\n",
      "\ttrain 40-225: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-226: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 40-227: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 40-228: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 40-229: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 40-230: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 40-231: Loss: 0.2323 Acc: 75.0000%\n",
      "\ttrain 40-232: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 40-233: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 40-234: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 40-235: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 40-236: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 40-237: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 40-238: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 40-239: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 40-240: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 40-241: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 40-242: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-243: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 40-244: Loss: 0.1582 Acc: 50.0000%\n",
      "\ttrain 40-245: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 40-1: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-2: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 40-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-4: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-5: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 40-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-7: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-8: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-9: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-10: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-11: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-12: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-13: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 40-14: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-15: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 40-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-17: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 40-18: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 40-19: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-20: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-21: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 40-22: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-24: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 40-25: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 40-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-27: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 40-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-29: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-30: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-31: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 40-32: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 40-33: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 40-34: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 40-35: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 40-36: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-37: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 40-38: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-39: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-40: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 40-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-42: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-43: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-44: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 40-45: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-46: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-47: Loss: 0.0496 Acc: 100.0000%\n",
      "\tvalidation 40-48: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-49: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 40-50: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-52: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-53: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 40-54: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 40-55: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-56: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-57: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-58: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 40-59: Loss: 0.3427 Acc: 75.0000%\n",
      "\tvalidation 40-60: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 40-61: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-62: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 40-63: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 40-64: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 40-65: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 40-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-67: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 40-68: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 40-69: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 40-70: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-71: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 40-72: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-73: Loss: 0.8309 Acc: 75.0000%\n",
      "\tvalidation 40-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-75: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 40-76: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 40-77: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-78: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 40-79: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-80: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-81: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-82: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-83: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 40-84: Loss: 1.7769 Acc: 75.0000%\n",
      "\tvalidation 40-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-86: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 40-87: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-88: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-89: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 40-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-91: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-93: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-94: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-95: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 40-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 40-97: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 40-98: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-99: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 40-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-101: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-102: Loss: 0.9746 Acc: 75.0000%\n",
      "\tvalidation 40-103: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 40-104: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 40-105: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0496 Acc: 92.9592%\n",
      "\tvalidation Loss: 0.0409 Acc: 99.0476%\n",
      "Time passed 0h 30m 36s\n",
      "--------------------\n",
      "Training complete in 0h 30m 36s\n",
      "Best validation Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "loss_train = []  # 训练集loss\n",
    "acc_train = []  # 训练集正确率\n",
    "loss_val = []  # 验证集loss\n",
    "acc_val = []  # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "\n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            i = 1\n",
    "            j = 1\n",
    "            # exp_lr_scheduler.step()\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            i = 1\n",
    "            j = 2\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            # if use_gpu:\n",
    "            #     inputs = inputs.cuda()\n",
    "            #     labels = labels.cuda()\n",
    "            # else:\n",
    "            #     inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            # '_'就是一个变量，换成a也是可以的，没有特别的意思，不过一般用_表示的变量好像都是没什么用的一个临时变量，大概是\n",
    "            # 一个编程习惯吧。所以这边'_,'没有特殊的含义，'_'就是一个变量，只是为了让preds取到max函数返回值的第二项，\n",
    "            # 即找到的最大值的索引位置（对应到这里就是类别标签）\n",
    "            # （max函数解释见https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max）\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, num_classes):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "\n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, i, loss.item()/4, torch.sum(preds == labels.data).item()/4.0*100))\n",
    "            i = i + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if j == 1:\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and j == 2:\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'validation' and epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"网络参数更新\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/params_resnet152.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "#             print(\"Model's state_dict:\")\n",
    "#             for param_tensor in best_model_wts:\n",
    "#                 print(param_tensor, \"\\t\", best_model_wts[param_tensor].size())\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.5972101974244021, 0.3660341880455309, 0.35605091695882835, 0.2668613022079273, 0.26825632416472145, 0.2374134281764225, 0.22924327409389067, 0.24038017115422658, 0.21703809107444724, 0.22983110054415098, 0.18967661754209167, 0.19195297558088692, 0.16264223289124818, 0.15510592897023473, 0.17699359944280313, 0.1569082088312324, 0.1232576421937164, 0.14275178675140654, 0.14053596638295116, 0.12122170146630735, 0.1113564958985971, 0.09527665115132623, 0.10860238504044864, 0.09459431043692998, 0.10549084662782902, 0.08994080609813028, 0.08413488393535419, 0.07780150159889337, 0.06944022160403583, 0.06846217075172736, 0.0719209177153451, 0.07681836832542809, 0.06768585352265105, 0.0533339617203693, 0.05694379180061574, 0.06306148162301706, 0.05522293265984983, 0.0565449734427491, 0.05481208392551967, 0.04956032423948755]\n",
      "loss_val: [0.40376989252510526, 0.35448137642372224, 0.15803572471652713, 0.19272662216708775, 0.19842983888728277, 0.22188022789501008, 0.3128744237479709, 0.2208859845286324, 0.6545303145334834, 0.1359085232374214, 0.42925492979231333, 0.24859210607551394, 0.222989346016021, 0.07709471036990484, 0.0409795792329879, 0.08165315772805895, 0.1369904221523376, 0.05054116901897249, 0.2957947329396293, 0.10357668357236045, 0.28402678008590426, 0.0466583224989119, 0.14773295237904505, 0.05271289192494892, 0.06785730932440076, 0.2810708204905192, 0.07741236502215976, 0.46468941895734694, 0.04063371519247691, 0.003299598182950701, 0.11698003021024522, 0.0062511021182650615, 0.10484321642489661, 0.2541876378513518, 0.07591416197163718, 0.25709490463847207, 0.1693611739646821, 0.033935941117150446, 0.0862594139008295, 0.040895248452822365]\n",
      "acc_train: [0.28469387755102044, 0.4663265306122449, 0.5010204081632653, 0.55, 0.5724489795918367, 0.6020408163265306, 0.5959183673469388, 0.5918367346938775, 0.610204081632653, 0.636734693877551, 0.6459183673469387, 0.6714285714285714, 0.7, 0.7306122448979592, 0.7234693877551021, 0.7428571428571429, 0.8, 0.7806122448979592, 0.7928571428571428, 0.8071428571428572, 0.8326530612244898, 0.8622448979591837, 0.8377551020408164, 0.8520408163265306, 0.8520408163265306, 0.8775510204081632, 0.8908163265306123, 0.8938775510204081, 0.9010204081632653, 0.9112244897959184, 0.9061224489795918, 0.9, 0.9020408163265307, 0.9255102040816326, 0.9275510204081633, 0.9091836734693878, 0.9255102040816326, 0.9306122448979591, 0.9306122448979591, 0.9295918367346939]\n",
      "acc_val: [0.6785714285714286, 0.7023809523809523, 0.7547619047619047, 0.7476190476190476, 0.7285714285714285, 0.7047619047619048, 0.75, 0.7476190476190476, 0.6833333333333333, 0.7666666666666667, 0.7666666666666667, 0.8452380952380952, 0.7880952380952381, 0.8785714285714286, 0.9357142857142857, 0.8738095238095238, 0.9333333333333333, 0.969047619047619, 0.9, 0.9428571428571428, 0.9166666666666666, 0.9261904761904762, 0.8333333333333334, 0.95, 0.969047619047619, 0.9619047619047619, 0.9642857142857143, 0.9333333333333333, 0.9714285714285714, 1.0, 0.9761904761904762, 1.0, 0.9571428571428572, 0.9285714285714286, 0.9761904761904762, 0.9547619047619048, 0.9642857142857143, 0.9809523809523809, 0.9833333333333333, 0.9904761904761905]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss(ResNet152)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy(ResNet152)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "GroundTruth:     75    81    77    75\n",
      "Predicted:     75    81    77    75\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('75', '77', '79', '81')\n",
    "\n",
    "dataiter = iter(dataloders['validation'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[z]] for z in range(4)))\n",
    "\n",
    "# test\n",
    "outputs = model(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[z]] for z in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   Predicted\n",
      "\n",
      "\t   75\t77\t79\t81\n",
      "\n",
      "Actual 75  105\t0\t0\t0\t\n",
      "\n",
      "Actual 77  0\t105\t0\t0\t\n",
      "\n",
      "Actual 79  0\t0\t105\t0\t\n",
      "\n",
      "Actual 81  0\t0\t0\t105\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conc = {\n",
    "    '0': '75  ',\n",
    "    '1': '77  ',\n",
    "    '2': '79  ',\n",
    "    '3': '81  '\n",
    "}\n",
    "\n",
    "print(\"\\t   Predicted\\n\")\n",
    "print(\"\\t   75\\t77\\t79\\t81\\n\")\n",
    "for i in range(0, num_classes):\n",
    "    print(\"Actual \", end='')\n",
    "    print(conc[str(i)], end='')\n",
    "    for j in range(0, num_classes):\n",
    "        print(str(best_matrix[i][j]) + '\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
