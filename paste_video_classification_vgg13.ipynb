{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个代码每个epoch都跑一遍训练集和验证集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 40\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "shuffle = True\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载vgg13预训练模型\n",
    "model = models.vgg13(pretrained=False)\n",
    "model.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(4096, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(4096, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = shuffle,\n",
    "                                             num_workers = 10) for x in ['train', 'validation']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]:\n",
      "\ttrain 1-1: Loss: 0.3451 Acc: 25.0000%\n",
      "\ttrain 1-2: Loss: 0.3473 Acc: 0.0000%\n",
      "\ttrain 1-3: Loss: 0.3446 Acc: 25.0000%\n",
      "\ttrain 1-4: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 1-5: Loss: 0.3544 Acc: 25.0000%\n",
      "\ttrain 1-6: Loss: 0.3485 Acc: 25.0000%\n",
      "\ttrain 1-7: Loss: 0.3521 Acc: 25.0000%\n",
      "\ttrain 1-8: Loss: 0.3465 Acc: 25.0000%\n",
      "\ttrain 1-9: Loss: 0.3393 Acc: 50.0000%\n",
      "\ttrain 1-10: Loss: 0.3491 Acc: 0.0000%\n",
      "\ttrain 1-11: Loss: 0.3421 Acc: 50.0000%\n",
      "\ttrain 1-12: Loss: 0.3445 Acc: 0.0000%\n",
      "\ttrain 1-13: Loss: 0.3461 Acc: 50.0000%\n",
      "\ttrain 1-14: Loss: 0.3558 Acc: 25.0000%\n",
      "\ttrain 1-15: Loss: 0.3567 Acc: 0.0000%\n",
      "\ttrain 1-16: Loss: 0.3401 Acc: 50.0000%\n",
      "\ttrain 1-17: Loss: 0.3495 Acc: 25.0000%\n",
      "\ttrain 1-18: Loss: 0.3384 Acc: 50.0000%\n",
      "\ttrain 1-19: Loss: 0.3389 Acc: 50.0000%\n",
      "\ttrain 1-20: Loss: 0.3500 Acc: 0.0000%\n",
      "\ttrain 1-21: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 1-22: Loss: 0.3595 Acc: 0.0000%\n",
      "\ttrain 1-23: Loss: 0.3531 Acc: 25.0000%\n",
      "\ttrain 1-24: Loss: 0.3495 Acc: 25.0000%\n",
      "\ttrain 1-25: Loss: 0.3446 Acc: 25.0000%\n",
      "\ttrain 1-26: Loss: 0.3477 Acc: 0.0000%\n",
      "\ttrain 1-27: Loss: 0.3505 Acc: 25.0000%\n",
      "\ttrain 1-28: Loss: 0.3597 Acc: 0.0000%\n",
      "\ttrain 1-29: Loss: 0.3439 Acc: 25.0000%\n",
      "\ttrain 1-30: Loss: 0.3521 Acc: 25.0000%\n",
      "\ttrain 1-31: Loss: 0.3610 Acc: 0.0000%\n",
      "\ttrain 1-32: Loss: 0.3443 Acc: 25.0000%\n",
      "\ttrain 1-33: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 1-34: Loss: 0.3505 Acc: 50.0000%\n",
      "\ttrain 1-35: Loss: 0.3455 Acc: 0.0000%\n",
      "\ttrain 1-36: Loss: 0.3478 Acc: 25.0000%\n",
      "\ttrain 1-37: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 1-38: Loss: 0.3408 Acc: 25.0000%\n",
      "\ttrain 1-39: Loss: 0.3465 Acc: 50.0000%\n",
      "\ttrain 1-40: Loss: 0.3534 Acc: 25.0000%\n",
      "\ttrain 1-41: Loss: 0.3498 Acc: 25.0000%\n",
      "\ttrain 1-42: Loss: 0.3561 Acc: 0.0000%\n",
      "\ttrain 1-43: Loss: 0.3638 Acc: 0.0000%\n",
      "\ttrain 1-44: Loss: 0.3471 Acc: 25.0000%\n",
      "\ttrain 1-45: Loss: 0.3465 Acc: 0.0000%\n",
      "\ttrain 1-46: Loss: 0.3440 Acc: 50.0000%\n",
      "\ttrain 1-47: Loss: 0.3484 Acc: 25.0000%\n",
      "\ttrain 1-48: Loss: 0.3421 Acc: 0.0000%\n",
      "\ttrain 1-49: Loss: 0.3487 Acc: 25.0000%\n",
      "\ttrain 1-50: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 1-51: Loss: 0.3419 Acc: 50.0000%\n",
      "\ttrain 1-52: Loss: 0.3475 Acc: 50.0000%\n",
      "\ttrain 1-53: Loss: 0.3440 Acc: 75.0000%\n",
      "\ttrain 1-54: Loss: 0.3541 Acc: 0.0000%\n",
      "\ttrain 1-55: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 1-56: Loss: 0.3432 Acc: 50.0000%\n",
      "\ttrain 1-57: Loss: 0.3422 Acc: 25.0000%\n",
      "\ttrain 1-58: Loss: 0.3521 Acc: 0.0000%\n",
      "\ttrain 1-59: Loss: 0.3525 Acc: 0.0000%\n",
      "\ttrain 1-60: Loss: 0.3507 Acc: 0.0000%\n",
      "\ttrain 1-61: Loss: 0.3378 Acc: 50.0000%\n",
      "\ttrain 1-62: Loss: 0.3428 Acc: 25.0000%\n",
      "\ttrain 1-63: Loss: 0.3510 Acc: 0.0000%\n",
      "\ttrain 1-64: Loss: 0.3439 Acc: 0.0000%\n",
      "\ttrain 1-65: Loss: 0.3424 Acc: 25.0000%\n",
      "\ttrain 1-66: Loss: 0.3465 Acc: 0.0000%\n",
      "\ttrain 1-67: Loss: 0.3477 Acc: 25.0000%\n",
      "\ttrain 1-68: Loss: 0.3453 Acc: 25.0000%\n",
      "\ttrain 1-69: Loss: 0.3494 Acc: 25.0000%\n",
      "\ttrain 1-70: Loss: 0.3535 Acc: 0.0000%\n",
      "\ttrain 1-71: Loss: 0.3506 Acc: 50.0000%\n",
      "\ttrain 1-72: Loss: 0.3355 Acc: 50.0000%\n",
      "\ttrain 1-73: Loss: 0.3445 Acc: 50.0000%\n",
      "\ttrain 1-74: Loss: 0.3479 Acc: 25.0000%\n",
      "\ttrain 1-75: Loss: 0.3437 Acc: 50.0000%\n",
      "\ttrain 1-76: Loss: 0.3420 Acc: 0.0000%\n",
      "\ttrain 1-77: Loss: 0.3398 Acc: 0.0000%\n",
      "\ttrain 1-78: Loss: 0.3290 Acc: 25.0000%\n",
      "\ttrain 1-79: Loss: 0.3459 Acc: 25.0000%\n",
      "\ttrain 1-80: Loss: 0.3441 Acc: 25.0000%\n",
      "\ttrain 1-81: Loss: 0.3625 Acc: 0.0000%\n",
      "\ttrain 1-82: Loss: 0.3473 Acc: 25.0000%\n",
      "\ttrain 1-83: Loss: 0.3512 Acc: 0.0000%\n",
      "\ttrain 1-84: Loss: 0.3581 Acc: 0.0000%\n",
      "\ttrain 1-85: Loss: 0.3641 Acc: 0.0000%\n",
      "\ttrain 1-86: Loss: 0.3387 Acc: 50.0000%\n",
      "\ttrain 1-87: Loss: 0.3520 Acc: 50.0000%\n",
      "\ttrain 1-88: Loss: 0.3267 Acc: 50.0000%\n",
      "\ttrain 1-89: Loss: 0.3567 Acc: 0.0000%\n",
      "\ttrain 1-90: Loss: 0.3537 Acc: 25.0000%\n",
      "\ttrain 1-91: Loss: 0.3623 Acc: 0.0000%\n",
      "\ttrain 1-92: Loss: 0.3383 Acc: 50.0000%\n",
      "\ttrain 1-93: Loss: 0.3512 Acc: 0.0000%\n",
      "\ttrain 1-94: Loss: 0.3593 Acc: 0.0000%\n",
      "\ttrain 1-95: Loss: 0.3464 Acc: 25.0000%\n",
      "\ttrain 1-96: Loss: 0.3314 Acc: 50.0000%\n",
      "\ttrain 1-97: Loss: 0.3555 Acc: 25.0000%\n",
      "\ttrain 1-98: Loss: 0.3418 Acc: 50.0000%\n",
      "\ttrain 1-99: Loss: 0.3436 Acc: 25.0000%\n",
      "\ttrain 1-100: Loss: 0.3472 Acc: 25.0000%\n",
      "\ttrain 1-101: Loss: 0.3399 Acc: 50.0000%\n",
      "\ttrain 1-102: Loss: 0.3376 Acc: 25.0000%\n",
      "\ttrain 1-103: Loss: 0.3456 Acc: 25.0000%\n",
      "\ttrain 1-104: Loss: 0.3579 Acc: 0.0000%\n",
      "\ttrain 1-105: Loss: 0.3511 Acc: 25.0000%\n",
      "\ttrain 1-106: Loss: 0.3322 Acc: 50.0000%\n",
      "\ttrain 1-107: Loss: 0.3586 Acc: 0.0000%\n",
      "\ttrain 1-108: Loss: 0.3578 Acc: 0.0000%\n",
      "\ttrain 1-109: Loss: 0.3686 Acc: 0.0000%\n",
      "\ttrain 1-110: Loss: 0.3424 Acc: 25.0000%\n",
      "\ttrain 1-111: Loss: 0.3455 Acc: 25.0000%\n",
      "\ttrain 1-112: Loss: 0.3512 Acc: 25.0000%\n",
      "\ttrain 1-113: Loss: 0.3384 Acc: 50.0000%\n",
      "\ttrain 1-114: Loss: 0.3413 Acc: 25.0000%\n",
      "\ttrain 1-115: Loss: 0.3617 Acc: 0.0000%\n",
      "\ttrain 1-116: Loss: 0.3362 Acc: 50.0000%\n",
      "\ttrain 1-117: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 1-118: Loss: 0.3491 Acc: 0.0000%\n",
      "\ttrain 1-119: Loss: 0.3345 Acc: 50.0000%\n",
      "\ttrain 1-120: Loss: 0.3473 Acc: 0.0000%\n",
      "\ttrain 1-121: Loss: 0.3465 Acc: 25.0000%\n",
      "\ttrain 1-122: Loss: 0.3496 Acc: 25.0000%\n",
      "\ttrain 1-123: Loss: 0.3514 Acc: 25.0000%\n",
      "\ttrain 1-124: Loss: 0.3364 Acc: 50.0000%\n",
      "\ttrain 1-125: Loss: 0.3454 Acc: 0.0000%\n",
      "\ttrain 1-126: Loss: 0.3570 Acc: 0.0000%\n",
      "\ttrain 1-127: Loss: 0.3564 Acc: 0.0000%\n",
      "\ttrain 1-128: Loss: 0.3500 Acc: 0.0000%\n",
      "\ttrain 1-129: Loss: 0.3472 Acc: 0.0000%\n",
      "\ttrain 1-130: Loss: 0.3470 Acc: 25.0000%\n",
      "\ttrain 1-131: Loss: 0.3439 Acc: 25.0000%\n",
      "\ttrain 1-132: Loss: 0.3468 Acc: 0.0000%\n",
      "\ttrain 1-133: Loss: 0.3503 Acc: 25.0000%\n",
      "\ttrain 1-134: Loss: 0.3467 Acc: 0.0000%\n",
      "\ttrain 1-135: Loss: 0.3475 Acc: 0.0000%\n",
      "\ttrain 1-136: Loss: 0.3452 Acc: 25.0000%\n",
      "\ttrain 1-137: Loss: 0.3451 Acc: 50.0000%\n",
      "\ttrain 1-138: Loss: 0.3483 Acc: 25.0000%\n",
      "\ttrain 1-139: Loss: 0.3477 Acc: 0.0000%\n",
      "\ttrain 1-140: Loss: 0.3480 Acc: 25.0000%\n",
      "\ttrain 1-141: Loss: 0.3412 Acc: 75.0000%\n",
      "\ttrain 1-142: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 1-143: Loss: 0.3496 Acc: 0.0000%\n",
      "\ttrain 1-144: Loss: 0.3441 Acc: 25.0000%\n",
      "\ttrain 1-145: Loss: 0.3498 Acc: 0.0000%\n",
      "\ttrain 1-146: Loss: 0.3486 Acc: 25.0000%\n",
      "\ttrain 1-147: Loss: 0.3405 Acc: 50.0000%\n",
      "\ttrain 1-148: Loss: 0.3452 Acc: 0.0000%\n",
      "\ttrain 1-149: Loss: 0.3493 Acc: 0.0000%\n",
      "\ttrain 1-150: Loss: 0.3492 Acc: 25.0000%\n",
      "\ttrain 1-151: Loss: 0.3412 Acc: 50.0000%\n",
      "\ttrain 1-152: Loss: 0.3477 Acc: 25.0000%\n",
      "\ttrain 1-153: Loss: 0.3428 Acc: 25.0000%\n",
      "\ttrain 1-154: Loss: 0.3426 Acc: 50.0000%\n",
      "\ttrain 1-155: Loss: 0.3394 Acc: 50.0000%\n",
      "\ttrain 1-156: Loss: 0.3431 Acc: 25.0000%\n",
      "\ttrain 1-157: Loss: 0.3513 Acc: 25.0000%\n",
      "\ttrain 1-158: Loss: 0.3426 Acc: 50.0000%\n",
      "\ttrain 1-159: Loss: 0.3476 Acc: 25.0000%\n",
      "\ttrain 1-160: Loss: 0.3426 Acc: 50.0000%\n",
      "\ttrain 1-161: Loss: 0.3451 Acc: 0.0000%\n",
      "\ttrain 1-162: Loss: 0.3430 Acc: 50.0000%\n",
      "\ttrain 1-163: Loss: 0.3462 Acc: 25.0000%\n",
      "\ttrain 1-164: Loss: 0.3444 Acc: 25.0000%\n",
      "\ttrain 1-165: Loss: 0.3504 Acc: 0.0000%\n",
      "\ttrain 1-166: Loss: 0.3502 Acc: 0.0000%\n",
      "\ttrain 1-167: Loss: 0.3463 Acc: 25.0000%\n",
      "\ttrain 1-168: Loss: 0.3461 Acc: 25.0000%\n",
      "\ttrain 1-169: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 1-170: Loss: 0.3496 Acc: 0.0000%\n",
      "\ttrain 1-171: Loss: 0.3422 Acc: 50.0000%\n",
      "\ttrain 1-172: Loss: 0.3494 Acc: 25.0000%\n",
      "\ttrain 1-173: Loss: 0.3454 Acc: 50.0000%\n",
      "\ttrain 1-174: Loss: 0.3377 Acc: 100.0000%\n",
      "\ttrain 1-175: Loss: 0.3483 Acc: 0.0000%\n",
      "\ttrain 1-176: Loss: 0.3484 Acc: 0.0000%\n",
      "\ttrain 1-177: Loss: 0.3417 Acc: 50.0000%\n",
      "\ttrain 1-178: Loss: 0.3488 Acc: 0.0000%\n",
      "\ttrain 1-179: Loss: 0.3464 Acc: 25.0000%\n",
      "\ttrain 1-180: Loss: 0.3511 Acc: 25.0000%\n",
      "\ttrain 1-181: Loss: 0.3468 Acc: 25.0000%\n",
      "\ttrain 1-182: Loss: 0.3468 Acc: 25.0000%\n",
      "\ttrain 1-183: Loss: 0.3457 Acc: 25.0000%\n",
      "\ttrain 1-184: Loss: 0.3466 Acc: 0.0000%\n",
      "\ttrain 1-185: Loss: 0.3433 Acc: 50.0000%\n",
      "\ttrain 1-186: Loss: 0.3480 Acc: 25.0000%\n",
      "\ttrain 1-187: Loss: 0.3447 Acc: 25.0000%\n",
      "\ttrain 1-188: Loss: 0.3434 Acc: 25.0000%\n",
      "\ttrain 1-189: Loss: 0.3424 Acc: 25.0000%\n",
      "\ttrain 1-190: Loss: 0.3486 Acc: 0.0000%\n",
      "\ttrain 1-191: Loss: 0.3424 Acc: 25.0000%\n",
      "\ttrain 1-192: Loss: 0.3494 Acc: 0.0000%\n",
      "\ttrain 1-193: Loss: 0.3513 Acc: 0.0000%\n",
      "\ttrain 1-194: Loss: 0.3435 Acc: 50.0000%\n",
      "\ttrain 1-195: Loss: 0.3483 Acc: 25.0000%\n",
      "\ttrain 1-196: Loss: 0.3409 Acc: 50.0000%\n",
      "\ttrain 1-197: Loss: 0.3464 Acc: 25.0000%\n",
      "\ttrain 1-198: Loss: 0.3418 Acc: 50.0000%\n",
      "\ttrain 1-199: Loss: 0.3455 Acc: 50.0000%\n",
      "\ttrain 1-200: Loss: 0.3354 Acc: 50.0000%\n",
      "\ttrain 1-201: Loss: 0.3405 Acc: 50.0000%\n",
      "\ttrain 1-202: Loss: 0.3464 Acc: 25.0000%\n",
      "\ttrain 1-203: Loss: 0.3363 Acc: 50.0000%\n",
      "\ttrain 1-204: Loss: 0.3421 Acc: 25.0000%\n",
      "\ttrain 1-205: Loss: 0.3404 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-206: Loss: 0.3293 Acc: 75.0000%\n",
      "\ttrain 1-207: Loss: 0.3383 Acc: 25.0000%\n",
      "\ttrain 1-208: Loss: 0.3295 Acc: 50.0000%\n",
      "\ttrain 1-209: Loss: 0.3556 Acc: 25.0000%\n",
      "\ttrain 1-210: Loss: 0.3586 Acc: 0.0000%\n",
      "\ttrain 1-211: Loss: 0.3387 Acc: 50.0000%\n",
      "\ttrain 1-212: Loss: 0.3614 Acc: 0.0000%\n",
      "\ttrain 1-213: Loss: 0.3477 Acc: 50.0000%\n",
      "\ttrain 1-214: Loss: 0.3433 Acc: 25.0000%\n",
      "\ttrain 1-215: Loss: 0.3482 Acc: 25.0000%\n",
      "\ttrain 1-216: Loss: 0.3490 Acc: 0.0000%\n",
      "\ttrain 1-217: Loss: 0.3525 Acc: 25.0000%\n",
      "\ttrain 1-218: Loss: 0.3435 Acc: 25.0000%\n",
      "\ttrain 1-219: Loss: 0.3448 Acc: 50.0000%\n",
      "\ttrain 1-220: Loss: 0.3413 Acc: 25.0000%\n",
      "\ttrain 1-221: Loss: 0.3338 Acc: 25.0000%\n",
      "\ttrain 1-222: Loss: 0.3359 Acc: 50.0000%\n",
      "\ttrain 1-223: Loss: 0.3394 Acc: 25.0000%\n",
      "\ttrain 1-224: Loss: 0.3466 Acc: 0.0000%\n",
      "\ttrain 1-225: Loss: 0.3376 Acc: 0.0000%\n",
      "\ttrain 1-226: Loss: 0.3362 Acc: 0.0000%\n",
      "\ttrain 1-227: Loss: 0.3522 Acc: 25.0000%\n",
      "\ttrain 1-228: Loss: 0.3420 Acc: 25.0000%\n",
      "\ttrain 1-229: Loss: 0.3446 Acc: 25.0000%\n",
      "\ttrain 1-230: Loss: 0.3315 Acc: 25.0000%\n",
      "\ttrain 1-231: Loss: 0.3399 Acc: 25.0000%\n",
      "\ttrain 1-232: Loss: 0.3561 Acc: 25.0000%\n",
      "\ttrain 1-233: Loss: 0.3163 Acc: 50.0000%\n",
      "\ttrain 1-234: Loss: 0.3224 Acc: 75.0000%\n",
      "\ttrain 1-235: Loss: 0.3263 Acc: 50.0000%\n",
      "\ttrain 1-236: Loss: 0.3348 Acc: 25.0000%\n",
      "\ttrain 1-237: Loss: 0.3419 Acc: 0.0000%\n",
      "\ttrain 1-238: Loss: 0.3537 Acc: 0.0000%\n",
      "\ttrain 1-239: Loss: 0.3328 Acc: 50.0000%\n",
      "\ttrain 1-240: Loss: 0.3433 Acc: 50.0000%\n",
      "\ttrain 1-241: Loss: 0.3193 Acc: 50.0000%\n",
      "\ttrain 1-242: Loss: 0.3187 Acc: 50.0000%\n",
      "\ttrain 1-243: Loss: 0.3648 Acc: 0.0000%\n",
      "\ttrain 1-244: Loss: 0.3328 Acc: 50.0000%\n",
      "\ttrain 1-245: Loss: 0.3905 Acc: 0.0000%\n",
      "\tvalidation 1-1: Loss: 0.3824 Acc: 0.0000%\n",
      "\tvalidation 1-2: Loss: 0.3891 Acc: 0.0000%\n",
      "\tvalidation 1-3: Loss: 0.3148 Acc: 50.0000%\n",
      "\tvalidation 1-4: Loss: 0.2926 Acc: 50.0000%\n",
      "\tvalidation 1-5: Loss: 0.3364 Acc: 25.0000%\n",
      "\tvalidation 1-6: Loss: 0.3876 Acc: 0.0000%\n",
      "\tvalidation 1-7: Loss: 0.3727 Acc: 25.0000%\n",
      "\tvalidation 1-8: Loss: 0.3555 Acc: 25.0000%\n",
      "\tvalidation 1-9: Loss: 0.3644 Acc: 0.0000%\n",
      "\tvalidation 1-10: Loss: 0.3469 Acc: 25.0000%\n",
      "\tvalidation 1-11: Loss: 0.3749 Acc: 25.0000%\n",
      "\tvalidation 1-12: Loss: 0.3572 Acc: 25.0000%\n",
      "\tvalidation 1-13: Loss: 0.3730 Acc: 25.0000%\n",
      "\tvalidation 1-14: Loss: 0.3456 Acc: 25.0000%\n",
      "\tvalidation 1-15: Loss: 0.2954 Acc: 50.0000%\n",
      "\tvalidation 1-16: Loss: 0.3414 Acc: 50.0000%\n",
      "\tvalidation 1-17: Loss: 0.3665 Acc: 0.0000%\n",
      "\tvalidation 1-18: Loss: 0.3316 Acc: 50.0000%\n",
      "\tvalidation 1-19: Loss: 0.3846 Acc: 0.0000%\n",
      "\tvalidation 1-20: Loss: 0.2920 Acc: 50.0000%\n",
      "\tvalidation 1-21: Loss: 0.3395 Acc: 50.0000%\n",
      "\tvalidation 1-22: Loss: 0.3487 Acc: 25.0000%\n",
      "\tvalidation 1-23: Loss: 0.3198 Acc: 25.0000%\n",
      "\tvalidation 1-24: Loss: 0.2903 Acc: 75.0000%\n",
      "\tvalidation 1-25: Loss: 0.3805 Acc: 25.0000%\n",
      "\tvalidation 1-26: Loss: 0.3668 Acc: 0.0000%\n",
      "\tvalidation 1-27: Loss: 0.3507 Acc: 0.0000%\n",
      "\tvalidation 1-28: Loss: 0.3286 Acc: 50.0000%\n",
      "\tvalidation 1-29: Loss: 0.3062 Acc: 50.0000%\n",
      "\tvalidation 1-30: Loss: 0.3894 Acc: 0.0000%\n",
      "\tvalidation 1-31: Loss: 0.3223 Acc: 50.0000%\n",
      "\tvalidation 1-32: Loss: 0.3764 Acc: 0.0000%\n",
      "\tvalidation 1-33: Loss: 0.3714 Acc: 25.0000%\n",
      "\tvalidation 1-34: Loss: 0.3084 Acc: 50.0000%\n",
      "\tvalidation 1-35: Loss: 0.3863 Acc: 0.0000%\n",
      "\tvalidation 1-36: Loss: 0.3337 Acc: 25.0000%\n",
      "\tvalidation 1-37: Loss: 0.3899 Acc: 0.0000%\n",
      "\tvalidation 1-38: Loss: 0.3199 Acc: 50.0000%\n",
      "\tvalidation 1-39: Loss: 0.3594 Acc: 0.0000%\n",
      "\tvalidation 1-40: Loss: 0.3433 Acc: 25.0000%\n",
      "\tvalidation 1-41: Loss: 0.3887 Acc: 0.0000%\n",
      "\tvalidation 1-42: Loss: 0.3639 Acc: 0.0000%\n",
      "\tvalidation 1-43: Loss: 0.3591 Acc: 25.0000%\n",
      "\tvalidation 1-44: Loss: 0.3468 Acc: 50.0000%\n",
      "\tvalidation 1-45: Loss: 0.3342 Acc: 25.0000%\n",
      "\tvalidation 1-46: Loss: 0.3803 Acc: 25.0000%\n",
      "\tvalidation 1-47: Loss: 0.3705 Acc: 25.0000%\n",
      "\tvalidation 1-48: Loss: 0.3212 Acc: 25.0000%\n",
      "\tvalidation 1-49: Loss: 0.3533 Acc: 25.0000%\n",
      "\tvalidation 1-50: Loss: 0.3559 Acc: 25.0000%\n",
      "\tvalidation 1-51: Loss: 0.3197 Acc: 50.0000%\n",
      "\tvalidation 1-52: Loss: 0.3386 Acc: 25.0000%\n",
      "\tvalidation 1-53: Loss: 0.3707 Acc: 0.0000%\n",
      "\tvalidation 1-54: Loss: 0.3050 Acc: 50.0000%\n",
      "\tvalidation 1-55: Loss: 0.3223 Acc: 25.0000%\n",
      "\tvalidation 1-56: Loss: 0.3595 Acc: 0.0000%\n",
      "\tvalidation 1-57: Loss: 0.3230 Acc: 25.0000%\n",
      "\tvalidation 1-58: Loss: 0.3863 Acc: 0.0000%\n",
      "\tvalidation 1-59: Loss: 0.3622 Acc: 0.0000%\n",
      "\tvalidation 1-60: Loss: 0.3611 Acc: 25.0000%\n",
      "\tvalidation 1-61: Loss: 0.3773 Acc: 0.0000%\n",
      "\tvalidation 1-62: Loss: 0.3644 Acc: 0.0000%\n",
      "\tvalidation 1-63: Loss: 0.3121 Acc: 25.0000%\n",
      "\tvalidation 1-64: Loss: 0.3856 Acc: 25.0000%\n",
      "\tvalidation 1-65: Loss: 0.3514 Acc: 0.0000%\n",
      "\tvalidation 1-66: Loss: 0.3556 Acc: 25.0000%\n",
      "\tvalidation 1-67: Loss: 0.3741 Acc: 0.0000%\n",
      "\tvalidation 1-68: Loss: 0.3748 Acc: 0.0000%\n",
      "\tvalidation 1-69: Loss: 0.2658 Acc: 100.0000%\n",
      "\tvalidation 1-70: Loss: 0.3839 Acc: 0.0000%\n",
      "\tvalidation 1-71: Loss: 0.2914 Acc: 50.0000%\n",
      "\tvalidation 1-72: Loss: 0.3295 Acc: 25.0000%\n",
      "\tvalidation 1-73: Loss: 0.3895 Acc: 0.0000%\n",
      "\tvalidation 1-74: Loss: 0.3613 Acc: 25.0000%\n",
      "\tvalidation 1-75: Loss: 0.3344 Acc: 25.0000%\n",
      "\tvalidation 1-76: Loss: 0.2881 Acc: 75.0000%\n",
      "\tvalidation 1-77: Loss: 0.4067 Acc: 0.0000%\n",
      "\tvalidation 1-78: Loss: 0.3373 Acc: 0.0000%\n",
      "\tvalidation 1-79: Loss: 0.3361 Acc: 25.0000%\n",
      "\tvalidation 1-80: Loss: 0.3082 Acc: 50.0000%\n",
      "\tvalidation 1-81: Loss: 0.3299 Acc: 50.0000%\n",
      "\tvalidation 1-82: Loss: 0.3205 Acc: 50.0000%\n",
      "\tvalidation 1-83: Loss: 0.3072 Acc: 50.0000%\n",
      "\tvalidation 1-84: Loss: 0.3057 Acc: 50.0000%\n",
      "\tvalidation 1-85: Loss: 0.3715 Acc: 25.0000%\n",
      "\tvalidation 1-86: Loss: 0.3020 Acc: 50.0000%\n",
      "\tvalidation 1-87: Loss: 0.3492 Acc: 0.0000%\n",
      "\tvalidation 1-88: Loss: 0.3916 Acc: 0.0000%\n",
      "\tvalidation 1-89: Loss: 0.3512 Acc: 25.0000%\n",
      "\tvalidation 1-90: Loss: 0.3570 Acc: 25.0000%\n",
      "\tvalidation 1-91: Loss: 0.2955 Acc: 50.0000%\n",
      "\tvalidation 1-92: Loss: 0.3682 Acc: 25.0000%\n",
      "\tvalidation 1-93: Loss: 0.3734 Acc: 0.0000%\n",
      "\tvalidation 1-94: Loss: 0.3627 Acc: 25.0000%\n",
      "\tvalidation 1-95: Loss: 0.3227 Acc: 25.0000%\n",
      "\tvalidation 1-96: Loss: 0.3524 Acc: 0.0000%\n",
      "\tvalidation 1-97: Loss: 0.3621 Acc: 0.0000%\n",
      "\tvalidation 1-98: Loss: 0.3624 Acc: 25.0000%\n",
      "\tvalidation 1-99: Loss: 0.3060 Acc: 50.0000%\n",
      "\tvalidation 1-100: Loss: 0.2764 Acc: 75.0000%\n",
      "\tvalidation 1-101: Loss: 0.3578 Acc: 25.0000%\n",
      "\tvalidation 1-102: Loss: 0.3440 Acc: 25.0000%\n",
      "\tvalidation 1-103: Loss: 0.3408 Acc: 25.0000%\n",
      "\tvalidation 1-104: Loss: 0.3357 Acc: 25.0000%\n",
      "\tvalidation 1-105: Loss: 0.3364 Acc: 25.0000%\n",
      "\ttrain Loss: 0.3460 Acc: 25.0000%\n",
      "\tvalidation Loss: 0.3464 Acc: 25.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 0m 26s\n",
      "--------------------\n",
      "Epoch [2/40]:\n",
      "\ttrain 2-1: Loss: 0.3597 Acc: 25.0000%\n",
      "\ttrain 2-2: Loss: 0.3528 Acc: 50.0000%\n",
      "\ttrain 2-3: Loss: 0.3872 Acc: 0.0000%\n",
      "\ttrain 2-4: Loss: 0.3239 Acc: 25.0000%\n",
      "\ttrain 2-5: Loss: 0.3172 Acc: 50.0000%\n",
      "\ttrain 2-6: Loss: 0.3132 Acc: 75.0000%\n",
      "\ttrain 2-7: Loss: 0.3263 Acc: 50.0000%\n",
      "\ttrain 2-8: Loss: 0.3557 Acc: 0.0000%\n",
      "\ttrain 2-9: Loss: 0.3175 Acc: 50.0000%\n",
      "\ttrain 2-10: Loss: 0.3142 Acc: 50.0000%\n",
      "\ttrain 2-11: Loss: 0.3317 Acc: 25.0000%\n",
      "\ttrain 2-12: Loss: 0.3541 Acc: 25.0000%\n",
      "\ttrain 2-13: Loss: 0.3345 Acc: 25.0000%\n",
      "\ttrain 2-14: Loss: 0.3319 Acc: 50.0000%\n",
      "\ttrain 2-15: Loss: 0.3866 Acc: 0.0000%\n",
      "\ttrain 2-16: Loss: 0.2719 Acc: 75.0000%\n",
      "\ttrain 2-17: Loss: 0.2687 Acc: 75.0000%\n",
      "\ttrain 2-18: Loss: 0.3853 Acc: 0.0000%\n",
      "\ttrain 2-19: Loss: 0.3347 Acc: 25.0000%\n",
      "\ttrain 2-20: Loss: 0.3519 Acc: 0.0000%\n",
      "\ttrain 2-21: Loss: 0.3536 Acc: 25.0000%\n",
      "\ttrain 2-22: Loss: 0.3653 Acc: 25.0000%\n",
      "\ttrain 2-23: Loss: 0.3570 Acc: 25.0000%\n",
      "\ttrain 2-24: Loss: 0.3607 Acc: 25.0000%\n",
      "\ttrain 2-25: Loss: 0.3311 Acc: 25.0000%\n",
      "\ttrain 2-26: Loss: 0.3540 Acc: 25.0000%\n",
      "\ttrain 2-27: Loss: 0.3611 Acc: 0.0000%\n",
      "\ttrain 2-28: Loss: 0.3827 Acc: 0.0000%\n",
      "\ttrain 2-29: Loss: 0.3753 Acc: 0.0000%\n",
      "\ttrain 2-30: Loss: 0.3689 Acc: 0.0000%\n",
      "\ttrain 2-31: Loss: 0.3495 Acc: 25.0000%\n",
      "\ttrain 2-32: Loss: 0.3364 Acc: 25.0000%\n",
      "\ttrain 2-33: Loss: 0.3350 Acc: 25.0000%\n",
      "\ttrain 2-34: Loss: 0.3537 Acc: 25.0000%\n",
      "\ttrain 2-35: Loss: 0.3356 Acc: 50.0000%\n",
      "\ttrain 2-36: Loss: 0.3548 Acc: 0.0000%\n",
      "\ttrain 2-37: Loss: 0.3474 Acc: 0.0000%\n",
      "\ttrain 2-38: Loss: 0.3426 Acc: 25.0000%\n",
      "\ttrain 2-39: Loss: 0.3331 Acc: 75.0000%\n",
      "\ttrain 2-40: Loss: 0.3536 Acc: 0.0000%\n",
      "\ttrain 2-41: Loss: 0.3453 Acc: 25.0000%\n",
      "\ttrain 2-42: Loss: 0.3438 Acc: 25.0000%\n",
      "\ttrain 2-43: Loss: 0.3398 Acc: 75.0000%\n",
      "\ttrain 2-44: Loss: 0.3429 Acc: 25.0000%\n",
      "\ttrain 2-45: Loss: 0.3479 Acc: 25.0000%\n",
      "\ttrain 2-46: Loss: 0.3443 Acc: 25.0000%\n",
      "\ttrain 2-47: Loss: 0.3368 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-48: Loss: 0.3401 Acc: 100.0000%\n",
      "\ttrain 2-49: Loss: 0.3412 Acc: 75.0000%\n",
      "\ttrain 2-50: Loss: 0.3362 Acc: 75.0000%\n",
      "\ttrain 2-51: Loss: 0.3401 Acc: 50.0000%\n",
      "\ttrain 2-52: Loss: 0.3367 Acc: 75.0000%\n",
      "\ttrain 2-53: Loss: 0.3421 Acc: 25.0000%\n",
      "\ttrain 2-54: Loss: 0.3386 Acc: 75.0000%\n",
      "\ttrain 2-55: Loss: 0.3313 Acc: 50.0000%\n",
      "\ttrain 2-56: Loss: 0.3348 Acc: 25.0000%\n",
      "\ttrain 2-57: Loss: 0.3308 Acc: 50.0000%\n",
      "\ttrain 2-58: Loss: 0.3509 Acc: 0.0000%\n",
      "\ttrain 2-59: Loss: 0.3579 Acc: 0.0000%\n",
      "\ttrain 2-60: Loss: 0.3548 Acc: 0.0000%\n",
      "\ttrain 2-61: Loss: 0.3214 Acc: 50.0000%\n",
      "\ttrain 2-62: Loss: 0.3511 Acc: 0.0000%\n",
      "\ttrain 2-63: Loss: 0.3393 Acc: 25.0000%\n",
      "\ttrain 2-64: Loss: 0.3475 Acc: 0.0000%\n",
      "\ttrain 2-65: Loss: 0.3229 Acc: 50.0000%\n",
      "\ttrain 2-66: Loss: 0.3407 Acc: 25.0000%\n",
      "\ttrain 2-67: Loss: 0.3171 Acc: 50.0000%\n",
      "\ttrain 2-68: Loss: 0.3174 Acc: 50.0000%\n",
      "\ttrain 2-69: Loss: 0.3440 Acc: 0.0000%\n",
      "\ttrain 2-70: Loss: 0.3475 Acc: 25.0000%\n",
      "\ttrain 2-71: Loss: 0.3592 Acc: 0.0000%\n",
      "\ttrain 2-72: Loss: 0.3237 Acc: 25.0000%\n",
      "\ttrain 2-73: Loss: 0.3120 Acc: 75.0000%\n",
      "\ttrain 2-74: Loss: 0.3623 Acc: 0.0000%\n",
      "\ttrain 2-75: Loss: 0.3775 Acc: 0.0000%\n",
      "\ttrain 2-76: Loss: 0.3246 Acc: 0.0000%\n",
      "\ttrain 2-77: Loss: 0.3538 Acc: 25.0000%\n",
      "\ttrain 2-78: Loss: 0.3230 Acc: 50.0000%\n",
      "\ttrain 2-79: Loss: 0.3927 Acc: 0.0000%\n",
      "\ttrain 2-80: Loss: 0.2973 Acc: 50.0000%\n",
      "\ttrain 2-81: Loss: 0.2832 Acc: 75.0000%\n",
      "\ttrain 2-82: Loss: 0.3220 Acc: 50.0000%\n",
      "\ttrain 2-83: Loss: 0.3168 Acc: 0.0000%\n",
      "\ttrain 2-84: Loss: 0.3987 Acc: 0.0000%\n",
      "\ttrain 2-85: Loss: 0.3575 Acc: 0.0000%\n",
      "\ttrain 2-86: Loss: 0.3125 Acc: 25.0000%\n",
      "\ttrain 2-87: Loss: 0.3487 Acc: 25.0000%\n",
      "\ttrain 2-88: Loss: 0.3539 Acc: 0.0000%\n",
      "\ttrain 2-89: Loss: 0.3470 Acc: 50.0000%\n",
      "\ttrain 2-90: Loss: 0.3488 Acc: 25.0000%\n",
      "\ttrain 2-91: Loss: 0.3849 Acc: 0.0000%\n",
      "\ttrain 2-92: Loss: 0.2946 Acc: 50.0000%\n",
      "\ttrain 2-93: Loss: 0.3793 Acc: 25.0000%\n",
      "\ttrain 2-94: Loss: 0.3370 Acc: 25.0000%\n",
      "\ttrain 2-95: Loss: 0.3271 Acc: 50.0000%\n",
      "\ttrain 2-96: Loss: 0.3319 Acc: 25.0000%\n",
      "\ttrain 2-97: Loss: 0.3326 Acc: 0.0000%\n",
      "\ttrain 2-98: Loss: 0.3700 Acc: 0.0000%\n",
      "\ttrain 2-99: Loss: 0.3491 Acc: 25.0000%\n",
      "\ttrain 2-100: Loss: 0.3444 Acc: 50.0000%\n",
      "\ttrain 2-101: Loss: 0.3223 Acc: 50.0000%\n",
      "\ttrain 2-102: Loss: 0.3316 Acc: 50.0000%\n",
      "\ttrain 2-103: Loss: 0.3123 Acc: 75.0000%\n",
      "\ttrain 2-104: Loss: 0.3602 Acc: 25.0000%\n",
      "\ttrain 2-105: Loss: 0.3320 Acc: 25.0000%\n",
      "\ttrain 2-106: Loss: 0.3170 Acc: 50.0000%\n",
      "\ttrain 2-107: Loss: 0.3801 Acc: 0.0000%\n",
      "\ttrain 2-108: Loss: 0.3478 Acc: 25.0000%\n",
      "\ttrain 2-109: Loss: 0.3529 Acc: 25.0000%\n",
      "\ttrain 2-110: Loss: 0.3265 Acc: 25.0000%\n",
      "\ttrain 2-111: Loss: 0.3350 Acc: 25.0000%\n",
      "\ttrain 2-112: Loss: 0.3420 Acc: 25.0000%\n",
      "\ttrain 2-113: Loss: 0.3469 Acc: 0.0000%\n",
      "\ttrain 2-114: Loss: 0.3448 Acc: 25.0000%\n",
      "\ttrain 2-115: Loss: 0.3029 Acc: 100.0000%\n",
      "\ttrain 2-116: Loss: 0.3510 Acc: 25.0000%\n",
      "\ttrain 2-117: Loss: 0.3369 Acc: 0.0000%\n",
      "\ttrain 2-118: Loss: 0.3139 Acc: 75.0000%\n",
      "\ttrain 2-119: Loss: 0.3473 Acc: 0.0000%\n",
      "\ttrain 2-120: Loss: 0.3493 Acc: 25.0000%\n",
      "\ttrain 2-121: Loss: 0.3624 Acc: 0.0000%\n",
      "\ttrain 2-122: Loss: 0.3635 Acc: 0.0000%\n",
      "\ttrain 2-123: Loss: 0.3132 Acc: 50.0000%\n",
      "\ttrain 2-124: Loss: 0.3352 Acc: 25.0000%\n",
      "\ttrain 2-125: Loss: 0.3249 Acc: 25.0000%\n",
      "\ttrain 2-126: Loss: 0.3122 Acc: 25.0000%\n",
      "\ttrain 2-127: Loss: 0.3205 Acc: 25.0000%\n",
      "\ttrain 2-128: Loss: 0.3490 Acc: 25.0000%\n",
      "\ttrain 2-129: Loss: 0.3287 Acc: 25.0000%\n",
      "\ttrain 2-130: Loss: 0.3354 Acc: 25.0000%\n",
      "\ttrain 2-131: Loss: 0.3557 Acc: 0.0000%\n",
      "\ttrain 2-132: Loss: 0.3000 Acc: 75.0000%\n",
      "\ttrain 2-133: Loss: 0.3459 Acc: 25.0000%\n",
      "\ttrain 2-134: Loss: 0.3088 Acc: 50.0000%\n",
      "\ttrain 2-135: Loss: 0.3718 Acc: 0.0000%\n",
      "\ttrain 2-136: Loss: 0.3581 Acc: 0.0000%\n",
      "\ttrain 2-137: Loss: 0.3318 Acc: 25.0000%\n",
      "\ttrain 2-138: Loss: 0.3307 Acc: 0.0000%\n",
      "\ttrain 2-139: Loss: 0.3080 Acc: 50.0000%\n",
      "\ttrain 2-140: Loss: 0.3246 Acc: 25.0000%\n",
      "\ttrain 2-141: Loss: 0.3166 Acc: 25.0000%\n",
      "\ttrain 2-142: Loss: 0.3004 Acc: 25.0000%\n",
      "\ttrain 2-143: Loss: 0.3229 Acc: 50.0000%\n",
      "\ttrain 2-144: Loss: 0.3231 Acc: 25.0000%\n",
      "\ttrain 2-145: Loss: 0.2564 Acc: 50.0000%\n",
      "\ttrain 2-146: Loss: 0.3338 Acc: 0.0000%\n",
      "\ttrain 2-147: Loss: 0.3442 Acc: 0.0000%\n",
      "\ttrain 2-148: Loss: 0.3751 Acc: 0.0000%\n",
      "\ttrain 2-149: Loss: 0.3513 Acc: 25.0000%\n",
      "\ttrain 2-150: Loss: 0.3846 Acc: 0.0000%\n",
      "\ttrain 2-151: Loss: 0.3616 Acc: 25.0000%\n",
      "\ttrain 2-152: Loss: 0.3586 Acc: 0.0000%\n",
      "\ttrain 2-153: Loss: 0.3172 Acc: 50.0000%\n",
      "\ttrain 2-154: Loss: 0.3282 Acc: 25.0000%\n",
      "\ttrain 2-155: Loss: 0.3234 Acc: 25.0000%\n",
      "\ttrain 2-156: Loss: 0.3204 Acc: 25.0000%\n",
      "\ttrain 2-157: Loss: 0.3199 Acc: 75.0000%\n",
      "\ttrain 2-158: Loss: 0.3418 Acc: 25.0000%\n",
      "\ttrain 2-159: Loss: 0.3300 Acc: 50.0000%\n",
      "\ttrain 2-160: Loss: 0.3367 Acc: 25.0000%\n",
      "\ttrain 2-161: Loss: 0.3494 Acc: 0.0000%\n",
      "\ttrain 2-162: Loss: 0.3316 Acc: 50.0000%\n",
      "\ttrain 2-163: Loss: 0.3383 Acc: 50.0000%\n",
      "\ttrain 2-164: Loss: 0.3424 Acc: 25.0000%\n",
      "\ttrain 2-165: Loss: 0.3341 Acc: 25.0000%\n",
      "\ttrain 2-166: Loss: 0.3256 Acc: 25.0000%\n",
      "\ttrain 2-167: Loss: 0.3236 Acc: 0.0000%\n",
      "\ttrain 2-168: Loss: 0.3441 Acc: 0.0000%\n",
      "\ttrain 2-169: Loss: 0.3330 Acc: 25.0000%\n",
      "\ttrain 2-170: Loss: 0.3340 Acc: 25.0000%\n",
      "\ttrain 2-171: Loss: 0.3214 Acc: 0.0000%\n",
      "\ttrain 2-172: Loss: 0.3488 Acc: 25.0000%\n",
      "\ttrain 2-173: Loss: 0.2831 Acc: 50.0000%\n",
      "\ttrain 2-174: Loss: 0.3126 Acc: 25.0000%\n",
      "\ttrain 2-175: Loss: 0.2861 Acc: 75.0000%\n",
      "\ttrain 2-176: Loss: 0.3532 Acc: 0.0000%\n",
      "\ttrain 2-177: Loss: 0.3492 Acc: 25.0000%\n",
      "\ttrain 2-178: Loss: 0.3532 Acc: 0.0000%\n",
      "\ttrain 2-179: Loss: 0.3749 Acc: 0.0000%\n",
      "\ttrain 2-180: Loss: 0.3492 Acc: 0.0000%\n",
      "\ttrain 2-181: Loss: 0.3154 Acc: 25.0000%\n",
      "\ttrain 2-182: Loss: 0.3320 Acc: 25.0000%\n",
      "\ttrain 2-183: Loss: 0.3104 Acc: 50.0000%\n",
      "\ttrain 2-184: Loss: 0.2983 Acc: 75.0000%\n",
      "\ttrain 2-185: Loss: 0.3237 Acc: 50.0000%\n",
      "\ttrain 2-186: Loss: 0.3302 Acc: 0.0000%\n",
      "\ttrain 2-187: Loss: 0.3076 Acc: 25.0000%\n",
      "\ttrain 2-188: Loss: 0.3093 Acc: 75.0000%\n",
      "\ttrain 2-189: Loss: 0.3505 Acc: 0.0000%\n",
      "\ttrain 2-190: Loss: 0.3581 Acc: 0.0000%\n",
      "\ttrain 2-191: Loss: 0.2731 Acc: 75.0000%\n",
      "\ttrain 2-192: Loss: 0.3209 Acc: 25.0000%\n",
      "\ttrain 2-193: Loss: 0.3042 Acc: 50.0000%\n",
      "\ttrain 2-194: Loss: 0.2873 Acc: 25.0000%\n",
      "\ttrain 2-195: Loss: 0.2598 Acc: 75.0000%\n",
      "\ttrain 2-196: Loss: 0.3891 Acc: 0.0000%\n",
      "\ttrain 2-197: Loss: 0.4000 Acc: 0.0000%\n",
      "\ttrain 2-198: Loss: 0.3677 Acc: 25.0000%\n",
      "\ttrain 2-199: Loss: 0.3416 Acc: 25.0000%\n",
      "\ttrain 2-200: Loss: 0.3302 Acc: 25.0000%\n",
      "\ttrain 2-201: Loss: 0.3452 Acc: 50.0000%\n",
      "\ttrain 2-202: Loss: 0.3193 Acc: 50.0000%\n",
      "\ttrain 2-203: Loss: 0.3590 Acc: 25.0000%\n",
      "\ttrain 2-204: Loss: 0.3318 Acc: 75.0000%\n",
      "\ttrain 2-205: Loss: 0.3375 Acc: 0.0000%\n",
      "\ttrain 2-206: Loss: 0.3449 Acc: 25.0000%\n",
      "\ttrain 2-207: Loss: 0.3257 Acc: 25.0000%\n",
      "\ttrain 2-208: Loss: 0.3266 Acc: 25.0000%\n",
      "\ttrain 2-209: Loss: 0.3297 Acc: 50.0000%\n",
      "\ttrain 2-210: Loss: 0.3120 Acc: 50.0000%\n",
      "\ttrain 2-211: Loss: 0.3177 Acc: 50.0000%\n",
      "\ttrain 2-212: Loss: 0.3623 Acc: 0.0000%\n",
      "\ttrain 2-213: Loss: 0.2932 Acc: 50.0000%\n",
      "\ttrain 2-214: Loss: 0.2921 Acc: 25.0000%\n",
      "\ttrain 2-215: Loss: 0.2918 Acc: 50.0000%\n",
      "\ttrain 2-216: Loss: 0.3415 Acc: 0.0000%\n",
      "\ttrain 2-217: Loss: 0.3175 Acc: 25.0000%\n",
      "\ttrain 2-218: Loss: 0.3615 Acc: 0.0000%\n",
      "\ttrain 2-219: Loss: 0.3397 Acc: 0.0000%\n",
      "\ttrain 2-220: Loss: 0.3648 Acc: 0.0000%\n",
      "\ttrain 2-221: Loss: 0.3277 Acc: 50.0000%\n",
      "\ttrain 2-222: Loss: 0.3231 Acc: 25.0000%\n",
      "\ttrain 2-223: Loss: 0.2938 Acc: 50.0000%\n",
      "\ttrain 2-224: Loss: 0.3230 Acc: 25.0000%\n",
      "\ttrain 2-225: Loss: 0.3273 Acc: 25.0000%\n",
      "\ttrain 2-226: Loss: 0.2971 Acc: 75.0000%\n",
      "\ttrain 2-227: Loss: 0.3127 Acc: 75.0000%\n",
      "\ttrain 2-228: Loss: 0.3189 Acc: 25.0000%\n",
      "\ttrain 2-229: Loss: 0.3080 Acc: 50.0000%\n",
      "\ttrain 2-230: Loss: 0.3139 Acc: 25.0000%\n",
      "\ttrain 2-231: Loss: 0.3265 Acc: 50.0000%\n",
      "\ttrain 2-232: Loss: 0.3248 Acc: 50.0000%\n",
      "\ttrain 2-233: Loss: 0.3128 Acc: 50.0000%\n",
      "\ttrain 2-234: Loss: 0.3141 Acc: 50.0000%\n",
      "\ttrain 2-235: Loss: 0.2639 Acc: 50.0000%\n",
      "\ttrain 2-236: Loss: 0.2570 Acc: 50.0000%\n",
      "\ttrain 2-237: Loss: 0.2835 Acc: 25.0000%\n",
      "\ttrain 2-238: Loss: 0.3202 Acc: 25.0000%\n",
      "\ttrain 2-239: Loss: 0.3346 Acc: 0.0000%\n",
      "\ttrain 2-240: Loss: 0.2094 Acc: 75.0000%\n",
      "\ttrain 2-241: Loss: 0.2936 Acc: 75.0000%\n",
      "\ttrain 2-242: Loss: 0.2812 Acc: 25.0000%\n",
      "\ttrain 2-243: Loss: 0.3483 Acc: 25.0000%\n",
      "\ttrain 2-244: Loss: 0.2342 Acc: 75.0000%\n",
      "\ttrain 2-245: Loss: 0.2230 Acc: 50.0000%\n",
      "\tvalidation 2-1: Loss: 0.2324 Acc: 75.0000%\n",
      "\tvalidation 2-2: Loss: 0.2008 Acc: 75.0000%\n",
      "\tvalidation 2-3: Loss: 0.2491 Acc: 50.0000%\n",
      "\tvalidation 2-4: Loss: 0.2739 Acc: 50.0000%\n",
      "\tvalidation 2-5: Loss: 0.2791 Acc: 0.0000%\n",
      "\tvalidation 2-6: Loss: 0.1957 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-7: Loss: 0.2815 Acc: 50.0000%\n",
      "\tvalidation 2-8: Loss: 0.2217 Acc: 50.0000%\n",
      "\tvalidation 2-9: Loss: 0.3159 Acc: 75.0000%\n",
      "\tvalidation 2-10: Loss: 0.2461 Acc: 50.0000%\n",
      "\tvalidation 2-11: Loss: 0.2061 Acc: 100.0000%\n",
      "\tvalidation 2-12: Loss: 0.2947 Acc: 25.0000%\n",
      "\tvalidation 2-13: Loss: 0.2268 Acc: 25.0000%\n",
      "\tvalidation 2-14: Loss: 0.2389 Acc: 75.0000%\n",
      "\tvalidation 2-15: Loss: 0.2493 Acc: 50.0000%\n",
      "\tvalidation 2-16: Loss: 0.2525 Acc: 50.0000%\n",
      "\tvalidation 2-17: Loss: 0.2451 Acc: 75.0000%\n",
      "\tvalidation 2-18: Loss: 0.2725 Acc: 25.0000%\n",
      "\tvalidation 2-19: Loss: 0.2267 Acc: 50.0000%\n",
      "\tvalidation 2-20: Loss: 0.2706 Acc: 50.0000%\n",
      "\tvalidation 2-21: Loss: 0.2055 Acc: 100.0000%\n",
      "\tvalidation 2-22: Loss: 0.2884 Acc: 75.0000%\n",
      "\tvalidation 2-23: Loss: 0.2529 Acc: 50.0000%\n",
      "\tvalidation 2-24: Loss: 0.1827 Acc: 100.0000%\n",
      "\tvalidation 2-25: Loss: 0.3075 Acc: 25.0000%\n",
      "\tvalidation 2-26: Loss: 0.2333 Acc: 50.0000%\n",
      "\tvalidation 2-27: Loss: 0.3059 Acc: 75.0000%\n",
      "\tvalidation 2-28: Loss: 0.2726 Acc: 75.0000%\n",
      "\tvalidation 2-29: Loss: 0.2152 Acc: 75.0000%\n",
      "\tvalidation 2-30: Loss: 0.2620 Acc: 25.0000%\n",
      "\tvalidation 2-31: Loss: 0.2982 Acc: 0.0000%\n",
      "\tvalidation 2-32: Loss: 0.3106 Acc: 25.0000%\n",
      "\tvalidation 2-33: Loss: 0.2395 Acc: 50.0000%\n",
      "\tvalidation 2-34: Loss: 0.2789 Acc: 50.0000%\n",
      "\tvalidation 2-35: Loss: 0.2947 Acc: 50.0000%\n",
      "\tvalidation 2-36: Loss: 0.2673 Acc: 25.0000%\n",
      "\tvalidation 2-37: Loss: 0.1874 Acc: 75.0000%\n",
      "\tvalidation 2-38: Loss: 0.3016 Acc: 50.0000%\n",
      "\tvalidation 2-39: Loss: 0.3068 Acc: 50.0000%\n",
      "\tvalidation 2-40: Loss: 0.2178 Acc: 25.0000%\n",
      "\tvalidation 2-41: Loss: 0.2863 Acc: 25.0000%\n",
      "\tvalidation 2-42: Loss: 0.2429 Acc: 50.0000%\n",
      "\tvalidation 2-43: Loss: 0.1778 Acc: 50.0000%\n",
      "\tvalidation 2-44: Loss: 0.2285 Acc: 50.0000%\n",
      "\tvalidation 2-45: Loss: 0.2585 Acc: 50.0000%\n",
      "\tvalidation 2-46: Loss: 0.2780 Acc: 50.0000%\n",
      "\tvalidation 2-47: Loss: 0.2714 Acc: 50.0000%\n",
      "\tvalidation 2-48: Loss: 0.2924 Acc: 0.0000%\n",
      "\tvalidation 2-49: Loss: 0.2843 Acc: 50.0000%\n",
      "\tvalidation 2-50: Loss: 0.2330 Acc: 50.0000%\n",
      "\tvalidation 2-51: Loss: 0.2393 Acc: 25.0000%\n",
      "\tvalidation 2-52: Loss: 0.2914 Acc: 50.0000%\n",
      "\tvalidation 2-53: Loss: 0.2819 Acc: 25.0000%\n",
      "\tvalidation 2-54: Loss: 0.2479 Acc: 75.0000%\n",
      "\tvalidation 2-55: Loss: 0.2018 Acc: 75.0000%\n",
      "\tvalidation 2-56: Loss: 0.3035 Acc: 0.0000%\n",
      "\tvalidation 2-57: Loss: 0.2556 Acc: 75.0000%\n",
      "\tvalidation 2-58: Loss: 0.2534 Acc: 50.0000%\n",
      "\tvalidation 2-59: Loss: 0.2380 Acc: 25.0000%\n",
      "\tvalidation 2-60: Loss: 0.2215 Acc: 50.0000%\n",
      "\tvalidation 2-61: Loss: 0.2300 Acc: 100.0000%\n",
      "\tvalidation 2-62: Loss: 0.2435 Acc: 75.0000%\n",
      "\tvalidation 2-63: Loss: 0.2684 Acc: 50.0000%\n",
      "\tvalidation 2-64: Loss: 0.2713 Acc: 75.0000%\n",
      "\tvalidation 2-65: Loss: 0.2334 Acc: 50.0000%\n",
      "\tvalidation 2-66: Loss: 0.2391 Acc: 50.0000%\n",
      "\tvalidation 2-67: Loss: 0.2574 Acc: 50.0000%\n",
      "\tvalidation 2-68: Loss: 0.2299 Acc: 75.0000%\n",
      "\tvalidation 2-69: Loss: 0.2378 Acc: 75.0000%\n",
      "\tvalidation 2-70: Loss: 0.2580 Acc: 25.0000%\n",
      "\tvalidation 2-71: Loss: 0.2930 Acc: 25.0000%\n",
      "\tvalidation 2-72: Loss: 0.1911 Acc: 50.0000%\n",
      "\tvalidation 2-73: Loss: 0.2582 Acc: 75.0000%\n",
      "\tvalidation 2-74: Loss: 0.2459 Acc: 50.0000%\n",
      "\tvalidation 2-75: Loss: 0.3056 Acc: 25.0000%\n",
      "\tvalidation 2-76: Loss: 0.2326 Acc: 75.0000%\n",
      "\tvalidation 2-77: Loss: 0.1913 Acc: 75.0000%\n",
      "\tvalidation 2-78: Loss: 0.2539 Acc: 25.0000%\n",
      "\tvalidation 2-79: Loss: 0.2287 Acc: 50.0000%\n",
      "\tvalidation 2-80: Loss: 0.2134 Acc: 100.0000%\n",
      "\tvalidation 2-81: Loss: 0.2265 Acc: 25.0000%\n",
      "\tvalidation 2-82: Loss: 0.2645 Acc: 50.0000%\n",
      "\tvalidation 2-83: Loss: 0.2912 Acc: 75.0000%\n",
      "\tvalidation 2-84: Loss: 0.2869 Acc: 25.0000%\n",
      "\tvalidation 2-85: Loss: 0.1819 Acc: 50.0000%\n",
      "\tvalidation 2-86: Loss: 0.2714 Acc: 75.0000%\n",
      "\tvalidation 2-87: Loss: 0.2995 Acc: 50.0000%\n",
      "\tvalidation 2-88: Loss: 0.2779 Acc: 25.0000%\n",
      "\tvalidation 2-89: Loss: 0.3016 Acc: 25.0000%\n",
      "\tvalidation 2-90: Loss: 0.2230 Acc: 75.0000%\n",
      "\tvalidation 2-91: Loss: 0.2895 Acc: 25.0000%\n",
      "\tvalidation 2-92: Loss: 0.2874 Acc: 25.0000%\n",
      "\tvalidation 2-93: Loss: 0.2589 Acc: 75.0000%\n",
      "\tvalidation 2-94: Loss: 0.2305 Acc: 25.0000%\n",
      "\tvalidation 2-95: Loss: 0.2842 Acc: 0.0000%\n",
      "\tvalidation 2-96: Loss: 0.3163 Acc: 25.0000%\n",
      "\tvalidation 2-97: Loss: 0.2060 Acc: 50.0000%\n",
      "\tvalidation 2-98: Loss: 0.2886 Acc: 25.0000%\n",
      "\tvalidation 2-99: Loss: 0.2825 Acc: 0.0000%\n",
      "\tvalidation 2-100: Loss: 0.3018 Acc: 50.0000%\n",
      "\tvalidation 2-101: Loss: 0.3168 Acc: 75.0000%\n",
      "\tvalidation 2-102: Loss: 0.2572 Acc: 25.0000%\n",
      "\tvalidation 2-103: Loss: 0.2106 Acc: 50.0000%\n",
      "\tvalidation 2-104: Loss: 0.2198 Acc: 75.0000%\n",
      "\tvalidation 2-105: Loss: 0.2774 Acc: 75.0000%\n",
      "\ttrain Loss: 0.3330 Acc: 30.0000%\n",
      "\tvalidation Loss: 0.2555 Acc: 50.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 2s\n",
      "--------------------\n",
      "Epoch [3/40]:\n",
      "\ttrain 3-1: Loss: 0.2490 Acc: 100.0000%\n",
      "\ttrain 3-2: Loss: 0.2571 Acc: 50.0000%\n",
      "\ttrain 3-3: Loss: 0.2732 Acc: 50.0000%\n",
      "\ttrain 3-4: Loss: 0.3427 Acc: 0.0000%\n",
      "\ttrain 3-5: Loss: 0.2737 Acc: 50.0000%\n",
      "\ttrain 3-6: Loss: 0.1863 Acc: 75.0000%\n",
      "\ttrain 3-7: Loss: 0.2861 Acc: 25.0000%\n",
      "\ttrain 3-8: Loss: 0.3017 Acc: 50.0000%\n",
      "\ttrain 3-9: Loss: 0.1705 Acc: 75.0000%\n",
      "\ttrain 3-10: Loss: 0.2276 Acc: 75.0000%\n",
      "\ttrain 3-11: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 3-12: Loss: 0.2942 Acc: 50.0000%\n",
      "\ttrain 3-13: Loss: 0.2766 Acc: 50.0000%\n",
      "\ttrain 3-14: Loss: 0.2099 Acc: 75.0000%\n",
      "\ttrain 3-15: Loss: 0.2779 Acc: 75.0000%\n",
      "\ttrain 3-16: Loss: 0.3040 Acc: 25.0000%\n",
      "\ttrain 3-17: Loss: 0.2892 Acc: 0.0000%\n",
      "\ttrain 3-18: Loss: 0.2136 Acc: 50.0000%\n",
      "\ttrain 3-19: Loss: 0.2666 Acc: 25.0000%\n",
      "\ttrain 3-20: Loss: 0.1334 Acc: 100.0000%\n",
      "\ttrain 3-21: Loss: 0.2373 Acc: 50.0000%\n",
      "\ttrain 3-22: Loss: 0.2121 Acc: 75.0000%\n",
      "\ttrain 3-23: Loss: 0.2383 Acc: 75.0000%\n",
      "\ttrain 3-24: Loss: 0.3237 Acc: 0.0000%\n",
      "\ttrain 3-25: Loss: 0.3649 Acc: 50.0000%\n",
      "\ttrain 3-26: Loss: 0.2600 Acc: 75.0000%\n",
      "\ttrain 3-27: Loss: 0.4359 Acc: 0.0000%\n",
      "\ttrain 3-28: Loss: 0.2612 Acc: 25.0000%\n",
      "\ttrain 3-29: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 3-30: Loss: 0.1928 Acc: 75.0000%\n",
      "\ttrain 3-31: Loss: 0.2659 Acc: 50.0000%\n",
      "\ttrain 3-32: Loss: 0.1779 Acc: 75.0000%\n",
      "\ttrain 3-33: Loss: 0.2709 Acc: 25.0000%\n",
      "\ttrain 3-34: Loss: 0.2842 Acc: 25.0000%\n",
      "\ttrain 3-35: Loss: 0.3039 Acc: 0.0000%\n",
      "\ttrain 3-36: Loss: 0.2344 Acc: 50.0000%\n",
      "\ttrain 3-37: Loss: 0.2685 Acc: 50.0000%\n",
      "\ttrain 3-38: Loss: 0.1517 Acc: 75.0000%\n",
      "\ttrain 3-39: Loss: 0.2832 Acc: 25.0000%\n",
      "\ttrain 3-40: Loss: 0.3374 Acc: 0.0000%\n",
      "\ttrain 3-41: Loss: 0.3976 Acc: 0.0000%\n",
      "\ttrain 3-42: Loss: 0.1674 Acc: 75.0000%\n",
      "\ttrain 3-43: Loss: 0.1817 Acc: 50.0000%\n",
      "\ttrain 3-44: Loss: 0.2265 Acc: 50.0000%\n",
      "\ttrain 3-45: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 3-46: Loss: 0.3125 Acc: 25.0000%\n",
      "\ttrain 3-47: Loss: 0.3858 Acc: 50.0000%\n",
      "\ttrain 3-48: Loss: 0.2373 Acc: 25.0000%\n",
      "\ttrain 3-49: Loss: 0.1106 Acc: 100.0000%\n",
      "\ttrain 3-50: Loss: 0.3519 Acc: 50.0000%\n",
      "\ttrain 3-51: Loss: 0.1963 Acc: 50.0000%\n",
      "\ttrain 3-52: Loss: 0.2658 Acc: 25.0000%\n",
      "\ttrain 3-53: Loss: 0.1839 Acc: 75.0000%\n",
      "\ttrain 3-54: Loss: 0.2553 Acc: 25.0000%\n",
      "\ttrain 3-55: Loss: 0.2707 Acc: 0.0000%\n",
      "\ttrain 3-56: Loss: 0.2897 Acc: 50.0000%\n",
      "\ttrain 3-57: Loss: 0.2724 Acc: 50.0000%\n",
      "\ttrain 3-58: Loss: 0.3442 Acc: 25.0000%\n",
      "\ttrain 3-59: Loss: 0.2495 Acc: 25.0000%\n",
      "\ttrain 3-60: Loss: 0.1652 Acc: 75.0000%\n",
      "\ttrain 3-61: Loss: 0.2142 Acc: 25.0000%\n",
      "\ttrain 3-62: Loss: 0.2501 Acc: 25.0000%\n",
      "\ttrain 3-63: Loss: 0.3350 Acc: 25.0000%\n",
      "\ttrain 3-64: Loss: 0.2747 Acc: 25.0000%\n",
      "\ttrain 3-65: Loss: 0.2845 Acc: 25.0000%\n",
      "\ttrain 3-66: Loss: 0.2283 Acc: 50.0000%\n",
      "\ttrain 3-67: Loss: 0.2132 Acc: 75.0000%\n",
      "\ttrain 3-68: Loss: 0.2367 Acc: 50.0000%\n",
      "\ttrain 3-69: Loss: 0.2661 Acc: 50.0000%\n",
      "\ttrain 3-70: Loss: 0.2950 Acc: 25.0000%\n",
      "\ttrain 3-71: Loss: 0.3499 Acc: 25.0000%\n",
      "\ttrain 3-72: Loss: 0.3141 Acc: 50.0000%\n",
      "\ttrain 3-73: Loss: 0.2455 Acc: 25.0000%\n",
      "\ttrain 3-74: Loss: 0.2203 Acc: 0.0000%\n",
      "\ttrain 3-75: Loss: 0.3334 Acc: 25.0000%\n",
      "\ttrain 3-76: Loss: 0.2929 Acc: 75.0000%\n",
      "\ttrain 3-77: Loss: 0.1806 Acc: 75.0000%\n",
      "\ttrain 3-78: Loss: 0.2740 Acc: 75.0000%\n",
      "\ttrain 3-79: Loss: 0.2274 Acc: 50.0000%\n",
      "\ttrain 3-80: Loss: 0.2636 Acc: 50.0000%\n",
      "\ttrain 3-81: Loss: 0.1835 Acc: 75.0000%\n",
      "\ttrain 3-82: Loss: 0.3087 Acc: 25.0000%\n",
      "\ttrain 3-83: Loss: 0.2933 Acc: 25.0000%\n",
      "\ttrain 3-84: Loss: 0.2704 Acc: 50.0000%\n",
      "\ttrain 3-85: Loss: 0.2979 Acc: 25.0000%\n",
      "\ttrain 3-86: Loss: 0.1671 Acc: 100.0000%\n",
      "\ttrain 3-87: Loss: 0.2611 Acc: 50.0000%\n",
      "\ttrain 3-88: Loss: 0.2929 Acc: 50.0000%\n",
      "\ttrain 3-89: Loss: 0.3445 Acc: 25.0000%\n",
      "\ttrain 3-90: Loss: 0.2890 Acc: 50.0000%\n",
      "\ttrain 3-91: Loss: 0.3263 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-92: Loss: 0.2762 Acc: 50.0000%\n",
      "\ttrain 3-93: Loss: 0.2433 Acc: 75.0000%\n",
      "\ttrain 3-94: Loss: 0.2436 Acc: 50.0000%\n",
      "\ttrain 3-95: Loss: 0.3179 Acc: 25.0000%\n",
      "\ttrain 3-96: Loss: 0.2794 Acc: 25.0000%\n",
      "\ttrain 3-97: Loss: 0.1964 Acc: 50.0000%\n",
      "\ttrain 3-98: Loss: 0.2467 Acc: 25.0000%\n",
      "\ttrain 3-99: Loss: 0.2180 Acc: 50.0000%\n",
      "\ttrain 3-100: Loss: 0.4063 Acc: 25.0000%\n",
      "\ttrain 3-101: Loss: 0.2766 Acc: 50.0000%\n",
      "\ttrain 3-102: Loss: 0.1286 Acc: 75.0000%\n",
      "\ttrain 3-103: Loss: 0.2143 Acc: 100.0000%\n",
      "\ttrain 3-104: Loss: 0.2126 Acc: 75.0000%\n",
      "\ttrain 3-105: Loss: 0.2111 Acc: 75.0000%\n",
      "\ttrain 3-106: Loss: 0.4166 Acc: 0.0000%\n",
      "\ttrain 3-107: Loss: 0.3016 Acc: 50.0000%\n",
      "\ttrain 3-108: Loss: 0.3350 Acc: 0.0000%\n",
      "\ttrain 3-109: Loss: 0.2360 Acc: 50.0000%\n",
      "\ttrain 3-110: Loss: 0.1708 Acc: 50.0000%\n",
      "\ttrain 3-111: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 3-112: Loss: 0.3096 Acc: 50.0000%\n",
      "\ttrain 3-113: Loss: 0.2120 Acc: 75.0000%\n",
      "\ttrain 3-114: Loss: 0.2579 Acc: 50.0000%\n",
      "\ttrain 3-115: Loss: 0.1827 Acc: 50.0000%\n",
      "\ttrain 3-116: Loss: 0.3470 Acc: 25.0000%\n",
      "\ttrain 3-117: Loss: 0.2096 Acc: 50.0000%\n",
      "\ttrain 3-118: Loss: 0.2283 Acc: 25.0000%\n",
      "\ttrain 3-119: Loss: 0.2625 Acc: 50.0000%\n",
      "\ttrain 3-120: Loss: 0.2654 Acc: 50.0000%\n",
      "\ttrain 3-121: Loss: 0.2153 Acc: 50.0000%\n",
      "\ttrain 3-122: Loss: 0.2173 Acc: 50.0000%\n",
      "\ttrain 3-123: Loss: 0.2353 Acc: 25.0000%\n",
      "\ttrain 3-124: Loss: 0.2915 Acc: 50.0000%\n",
      "\ttrain 3-125: Loss: 0.2341 Acc: 75.0000%\n",
      "\ttrain 3-126: Loss: 0.2029 Acc: 50.0000%\n",
      "\ttrain 3-127: Loss: 0.2089 Acc: 75.0000%\n",
      "\ttrain 3-128: Loss: 0.2123 Acc: 50.0000%\n",
      "\ttrain 3-129: Loss: 0.1126 Acc: 100.0000%\n",
      "\ttrain 3-130: Loss: 0.1596 Acc: 75.0000%\n",
      "\ttrain 3-131: Loss: 0.4798 Acc: 0.0000%\n",
      "\ttrain 3-132: Loss: 0.2291 Acc: 50.0000%\n",
      "\ttrain 3-133: Loss: 0.2861 Acc: 50.0000%\n",
      "\ttrain 3-134: Loss: 0.2478 Acc: 50.0000%\n",
      "\ttrain 3-135: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 3-136: Loss: 0.3889 Acc: 25.0000%\n",
      "\ttrain 3-137: Loss: 0.4767 Acc: 25.0000%\n",
      "\ttrain 3-138: Loss: 0.3686 Acc: 0.0000%\n",
      "\ttrain 3-139: Loss: 0.2468 Acc: 50.0000%\n",
      "\ttrain 3-140: Loss: 0.3730 Acc: 0.0000%\n",
      "\ttrain 3-141: Loss: 0.3360 Acc: 25.0000%\n",
      "\ttrain 3-142: Loss: 0.2665 Acc: 50.0000%\n",
      "\ttrain 3-143: Loss: 0.2668 Acc: 50.0000%\n",
      "\ttrain 3-144: Loss: 0.2942 Acc: 25.0000%\n",
      "\ttrain 3-145: Loss: 0.2095 Acc: 50.0000%\n",
      "\ttrain 3-146: Loss: 0.3070 Acc: 50.0000%\n",
      "\ttrain 3-147: Loss: 0.2457 Acc: 75.0000%\n",
      "\ttrain 3-148: Loss: 0.2759 Acc: 25.0000%\n",
      "\ttrain 3-149: Loss: 0.2551 Acc: 25.0000%\n",
      "\ttrain 3-150: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 3-151: Loss: 0.2501 Acc: 25.0000%\n",
      "\ttrain 3-152: Loss: 0.2744 Acc: 75.0000%\n",
      "\ttrain 3-153: Loss: 0.2870 Acc: 0.0000%\n",
      "\ttrain 3-154: Loss: 0.2863 Acc: 50.0000%\n",
      "\ttrain 3-155: Loss: 0.2260 Acc: 25.0000%\n",
      "\ttrain 3-156: Loss: 0.1823 Acc: 100.0000%\n",
      "\ttrain 3-157: Loss: 0.2998 Acc: 50.0000%\n",
      "\ttrain 3-158: Loss: 0.2480 Acc: 50.0000%\n",
      "\ttrain 3-159: Loss: 0.2509 Acc: 50.0000%\n",
      "\ttrain 3-160: Loss: 0.2419 Acc: 25.0000%\n",
      "\ttrain 3-161: Loss: 0.1369 Acc: 75.0000%\n",
      "\ttrain 3-162: Loss: 0.2938 Acc: 50.0000%\n",
      "\ttrain 3-163: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 3-164: Loss: 0.2145 Acc: 75.0000%\n",
      "\ttrain 3-165: Loss: 0.2225 Acc: 50.0000%\n",
      "\ttrain 3-166: Loss: 0.2684 Acc: 25.0000%\n",
      "\ttrain 3-167: Loss: 0.2206 Acc: 100.0000%\n",
      "\ttrain 3-168: Loss: 0.2473 Acc: 50.0000%\n",
      "\ttrain 3-169: Loss: 0.2283 Acc: 25.0000%\n",
      "\ttrain 3-170: Loss: 0.2949 Acc: 25.0000%\n",
      "\ttrain 3-171: Loss: 0.2409 Acc: 75.0000%\n",
      "\ttrain 3-172: Loss: 0.3089 Acc: 25.0000%\n",
      "\ttrain 3-173: Loss: 0.2239 Acc: 25.0000%\n",
      "\ttrain 3-174: Loss: 0.2980 Acc: 25.0000%\n",
      "\ttrain 3-175: Loss: 0.1949 Acc: 50.0000%\n",
      "\ttrain 3-176: Loss: 0.2051 Acc: 75.0000%\n",
      "\ttrain 3-177: Loss: 0.1498 Acc: 75.0000%\n",
      "\ttrain 3-178: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 3-179: Loss: 0.2897 Acc: 50.0000%\n",
      "\ttrain 3-180: Loss: 0.2025 Acc: 50.0000%\n",
      "\ttrain 3-181: Loss: 0.2171 Acc: 75.0000%\n",
      "\ttrain 3-182: Loss: 0.1746 Acc: 50.0000%\n",
      "\ttrain 3-183: Loss: 0.2688 Acc: 50.0000%\n",
      "\ttrain 3-184: Loss: 0.2364 Acc: 75.0000%\n",
      "\ttrain 3-185: Loss: 0.2346 Acc: 25.0000%\n",
      "\ttrain 3-186: Loss: 0.1988 Acc: 25.0000%\n",
      "\ttrain 3-187: Loss: 0.1780 Acc: 25.0000%\n",
      "\ttrain 3-188: Loss: 0.2276 Acc: 25.0000%\n",
      "\ttrain 3-189: Loss: 0.1492 Acc: 75.0000%\n",
      "\ttrain 3-190: Loss: 0.2585 Acc: 50.0000%\n",
      "\ttrain 3-191: Loss: 0.2568 Acc: 50.0000%\n",
      "\ttrain 3-192: Loss: 0.2411 Acc: 75.0000%\n",
      "\ttrain 3-193: Loss: 0.2072 Acc: 75.0000%\n",
      "\ttrain 3-194: Loss: 0.2631 Acc: 25.0000%\n",
      "\ttrain 3-195: Loss: 0.2359 Acc: 50.0000%\n",
      "\ttrain 3-196: Loss: 0.1338 Acc: 75.0000%\n",
      "\ttrain 3-197: Loss: 0.1270 Acc: 100.0000%\n",
      "\ttrain 3-198: Loss: 0.2219 Acc: 50.0000%\n",
      "\ttrain 3-199: Loss: 0.2326 Acc: 25.0000%\n",
      "\ttrain 3-200: Loss: 0.1052 Acc: 100.0000%\n",
      "\ttrain 3-201: Loss: 0.1876 Acc: 75.0000%\n",
      "\ttrain 3-202: Loss: 0.1203 Acc: 75.0000%\n",
      "\ttrain 3-203: Loss: 0.3878 Acc: 0.0000%\n",
      "\ttrain 3-204: Loss: 0.2744 Acc: 25.0000%\n",
      "\ttrain 3-205: Loss: 0.2249 Acc: 25.0000%\n",
      "\ttrain 3-206: Loss: 0.4035 Acc: 50.0000%\n",
      "\ttrain 3-207: Loss: 0.1991 Acc: 25.0000%\n",
      "\ttrain 3-208: Loss: 0.6265 Acc: 0.0000%\n",
      "\ttrain 3-209: Loss: 0.1660 Acc: 75.0000%\n",
      "\ttrain 3-210: Loss: 0.2316 Acc: 75.0000%\n",
      "\ttrain 3-211: Loss: 0.1846 Acc: 50.0000%\n",
      "\ttrain 3-212: Loss: 0.4097 Acc: 0.0000%\n",
      "\ttrain 3-213: Loss: 0.3041 Acc: 75.0000%\n",
      "\ttrain 3-214: Loss: 0.2633 Acc: 75.0000%\n",
      "\ttrain 3-215: Loss: 0.2215 Acc: 50.0000%\n",
      "\ttrain 3-216: Loss: 0.2645 Acc: 25.0000%\n",
      "\ttrain 3-217: Loss: 0.2630 Acc: 25.0000%\n",
      "\ttrain 3-218: Loss: 0.2773 Acc: 25.0000%\n",
      "\ttrain 3-219: Loss: 0.1641 Acc: 50.0000%\n",
      "\ttrain 3-220: Loss: 0.1895 Acc: 25.0000%\n",
      "\ttrain 3-221: Loss: 0.2665 Acc: 25.0000%\n",
      "\ttrain 3-222: Loss: 0.1923 Acc: 50.0000%\n",
      "\ttrain 3-223: Loss: 0.2365 Acc: 75.0000%\n",
      "\ttrain 3-224: Loss: 0.2284 Acc: 75.0000%\n",
      "\ttrain 3-225: Loss: 0.1816 Acc: 75.0000%\n",
      "\ttrain 3-226: Loss: 0.2195 Acc: 25.0000%\n",
      "\ttrain 3-227: Loss: 0.1919 Acc: 75.0000%\n",
      "\ttrain 3-228: Loss: 0.2019 Acc: 50.0000%\n",
      "\ttrain 3-229: Loss: 0.2126 Acc: 50.0000%\n",
      "\ttrain 3-230: Loss: 0.2645 Acc: 75.0000%\n",
      "\ttrain 3-231: Loss: 0.2693 Acc: 25.0000%\n",
      "\ttrain 3-232: Loss: 0.2085 Acc: 75.0000%\n",
      "\ttrain 3-233: Loss: 0.2276 Acc: 75.0000%\n",
      "\ttrain 3-234: Loss: 0.1481 Acc: 50.0000%\n",
      "\ttrain 3-235: Loss: 0.2204 Acc: 75.0000%\n",
      "\ttrain 3-236: Loss: 0.1895 Acc: 50.0000%\n",
      "\ttrain 3-237: Loss: 0.2002 Acc: 25.0000%\n",
      "\ttrain 3-238: Loss: 0.4139 Acc: 25.0000%\n",
      "\ttrain 3-239: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 3-240: Loss: 0.2623 Acc: 0.0000%\n",
      "\ttrain 3-241: Loss: 0.2847 Acc: 25.0000%\n",
      "\ttrain 3-242: Loss: 0.2744 Acc: 25.0000%\n",
      "\ttrain 3-243: Loss: 0.1768 Acc: 75.0000%\n",
      "\ttrain 3-244: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 3-245: Loss: 0.1585 Acc: 50.0000%\n",
      "\tvalidation 3-1: Loss: 0.1979 Acc: 75.0000%\n",
      "\tvalidation 3-2: Loss: 0.1705 Acc: 50.0000%\n",
      "\tvalidation 3-3: Loss: 0.2973 Acc: 50.0000%\n",
      "\tvalidation 3-4: Loss: 0.1517 Acc: 75.0000%\n",
      "\tvalidation 3-5: Loss: 0.2031 Acc: 50.0000%\n",
      "\tvalidation 3-6: Loss: 0.1566 Acc: 75.0000%\n",
      "\tvalidation 3-7: Loss: 0.2101 Acc: 25.0000%\n",
      "\tvalidation 3-8: Loss: 0.1200 Acc: 100.0000%\n",
      "\tvalidation 3-9: Loss: 0.2087 Acc: 75.0000%\n",
      "\tvalidation 3-10: Loss: 0.1492 Acc: 100.0000%\n",
      "\tvalidation 3-11: Loss: 0.1382 Acc: 75.0000%\n",
      "\tvalidation 3-12: Loss: 0.1526 Acc: 75.0000%\n",
      "\tvalidation 3-13: Loss: 0.1754 Acc: 25.0000%\n",
      "\tvalidation 3-14: Loss: 0.1922 Acc: 50.0000%\n",
      "\tvalidation 3-15: Loss: 0.1940 Acc: 75.0000%\n",
      "\tvalidation 3-16: Loss: 0.1664 Acc: 75.0000%\n",
      "\tvalidation 3-17: Loss: 0.2257 Acc: 75.0000%\n",
      "\tvalidation 3-18: Loss: 0.1389 Acc: 75.0000%\n",
      "\tvalidation 3-19: Loss: 0.1354 Acc: 100.0000%\n",
      "\tvalidation 3-20: Loss: 0.1650 Acc: 75.0000%\n",
      "\tvalidation 3-21: Loss: 0.1576 Acc: 75.0000%\n",
      "\tvalidation 3-22: Loss: 0.2096 Acc: 25.0000%\n",
      "\tvalidation 3-23: Loss: 0.2406 Acc: 50.0000%\n",
      "\tvalidation 3-24: Loss: 0.1670 Acc: 75.0000%\n",
      "\tvalidation 3-25: Loss: 0.1753 Acc: 75.0000%\n",
      "\tvalidation 3-26: Loss: 0.1876 Acc: 25.0000%\n",
      "\tvalidation 3-27: Loss: 0.1968 Acc: 50.0000%\n",
      "\tvalidation 3-28: Loss: 0.1560 Acc: 75.0000%\n",
      "\tvalidation 3-29: Loss: 0.1062 Acc: 100.0000%\n",
      "\tvalidation 3-30: Loss: 0.2045 Acc: 75.0000%\n",
      "\tvalidation 3-31: Loss: 0.1905 Acc: 75.0000%\n",
      "\tvalidation 3-32: Loss: 0.2100 Acc: 75.0000%\n",
      "\tvalidation 3-33: Loss: 0.2086 Acc: 50.0000%\n",
      "\tvalidation 3-34: Loss: 0.1990 Acc: 75.0000%\n",
      "\tvalidation 3-35: Loss: 0.1748 Acc: 50.0000%\n",
      "\tvalidation 3-36: Loss: 0.1801 Acc: 50.0000%\n",
      "\tvalidation 3-37: Loss: 0.1681 Acc: 75.0000%\n",
      "\tvalidation 3-38: Loss: 0.1704 Acc: 75.0000%\n",
      "\tvalidation 3-39: Loss: 0.2264 Acc: 0.0000%\n",
      "\tvalidation 3-40: Loss: 0.1939 Acc: 50.0000%\n",
      "\tvalidation 3-41: Loss: 0.2416 Acc: 50.0000%\n",
      "\tvalidation 3-42: Loss: 0.2207 Acc: 25.0000%\n",
      "\tvalidation 3-43: Loss: 0.1874 Acc: 50.0000%\n",
      "\tvalidation 3-44: Loss: 0.1792 Acc: 75.0000%\n",
      "\tvalidation 3-45: Loss: 0.1765 Acc: 50.0000%\n",
      "\tvalidation 3-46: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 3-47: Loss: 0.2154 Acc: 50.0000%\n",
      "\tvalidation 3-48: Loss: 0.2213 Acc: 50.0000%\n",
      "\tvalidation 3-49: Loss: 0.1610 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-50: Loss: 0.1485 Acc: 75.0000%\n",
      "\tvalidation 3-51: Loss: 0.2075 Acc: 25.0000%\n",
      "\tvalidation 3-52: Loss: 0.0690 Acc: 100.0000%\n",
      "\tvalidation 3-53: Loss: 0.1587 Acc: 50.0000%\n",
      "\tvalidation 3-54: Loss: 0.1994 Acc: 100.0000%\n",
      "\tvalidation 3-55: Loss: 0.1834 Acc: 75.0000%\n",
      "\tvalidation 3-56: Loss: 0.2079 Acc: 50.0000%\n",
      "\tvalidation 3-57: Loss: 0.2059 Acc: 25.0000%\n",
      "\tvalidation 3-58: Loss: 0.1728 Acc: 25.0000%\n",
      "\tvalidation 3-59: Loss: 0.1942 Acc: 50.0000%\n",
      "\tvalidation 3-60: Loss: 0.1952 Acc: 75.0000%\n",
      "\tvalidation 3-61: Loss: 0.2102 Acc: 50.0000%\n",
      "\tvalidation 3-62: Loss: 0.1416 Acc: 100.0000%\n",
      "\tvalidation 3-63: Loss: 0.1414 Acc: 75.0000%\n",
      "\tvalidation 3-64: Loss: 0.1754 Acc: 50.0000%\n",
      "\tvalidation 3-65: Loss: 0.1287 Acc: 100.0000%\n",
      "\tvalidation 3-66: Loss: 0.1829 Acc: 50.0000%\n",
      "\tvalidation 3-67: Loss: 0.2513 Acc: 50.0000%\n",
      "\tvalidation 3-68: Loss: 0.1541 Acc: 100.0000%\n",
      "\tvalidation 3-69: Loss: 0.2035 Acc: 25.0000%\n",
      "\tvalidation 3-70: Loss: 0.2245 Acc: 25.0000%\n",
      "\tvalidation 3-71: Loss: 0.1958 Acc: 25.0000%\n",
      "\tvalidation 3-72: Loss: 0.2558 Acc: 25.0000%\n",
      "\tvalidation 3-73: Loss: 0.1957 Acc: 50.0000%\n",
      "\tvalidation 3-74: Loss: 0.2094 Acc: 50.0000%\n",
      "\tvalidation 3-75: Loss: 0.2137 Acc: 50.0000%\n",
      "\tvalidation 3-76: Loss: 0.1902 Acc: 50.0000%\n",
      "\tvalidation 3-77: Loss: 0.1457 Acc: 75.0000%\n",
      "\tvalidation 3-78: Loss: 0.2079 Acc: 75.0000%\n",
      "\tvalidation 3-79: Loss: 0.1359 Acc: 75.0000%\n",
      "\tvalidation 3-80: Loss: 0.2197 Acc: 25.0000%\n",
      "\tvalidation 3-81: Loss: 0.1533 Acc: 100.0000%\n",
      "\tvalidation 3-82: Loss: 0.1624 Acc: 75.0000%\n",
      "\tvalidation 3-83: Loss: 0.1791 Acc: 75.0000%\n",
      "\tvalidation 3-84: Loss: 0.2111 Acc: 50.0000%\n",
      "\tvalidation 3-85: Loss: 0.1877 Acc: 75.0000%\n",
      "\tvalidation 3-86: Loss: 0.1462 Acc: 50.0000%\n",
      "\tvalidation 3-87: Loss: 0.1849 Acc: 75.0000%\n",
      "\tvalidation 3-88: Loss: 0.1789 Acc: 50.0000%\n",
      "\tvalidation 3-89: Loss: 0.1574 Acc: 75.0000%\n",
      "\tvalidation 3-90: Loss: 0.1681 Acc: 50.0000%\n",
      "\tvalidation 3-91: Loss: 0.1715 Acc: 75.0000%\n",
      "\tvalidation 3-92: Loss: 0.1661 Acc: 75.0000%\n",
      "\tvalidation 3-93: Loss: 0.1703 Acc: 100.0000%\n",
      "\tvalidation 3-94: Loss: 0.1961 Acc: 50.0000%\n",
      "\tvalidation 3-95: Loss: 0.1582 Acc: 100.0000%\n",
      "\tvalidation 3-96: Loss: 0.2191 Acc: 50.0000%\n",
      "\tvalidation 3-97: Loss: 0.2064 Acc: 50.0000%\n",
      "\tvalidation 3-98: Loss: 0.1371 Acc: 75.0000%\n",
      "\tvalidation 3-99: Loss: 0.1427 Acc: 100.0000%\n",
      "\tvalidation 3-100: Loss: 0.2225 Acc: 50.0000%\n",
      "\tvalidation 3-101: Loss: 0.1506 Acc: 100.0000%\n",
      "\tvalidation 3-102: Loss: 0.2172 Acc: 0.0000%\n",
      "\tvalidation 3-103: Loss: 0.1703 Acc: 50.0000%\n",
      "\tvalidation 3-104: Loss: 0.2017 Acc: 50.0000%\n",
      "\tvalidation 3-105: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2494 Acc: 47.7551%\n",
      "\tvalidation Loss: 0.1821 Acc: 62.1429%\n",
      "网络参数更新\n",
      "Time passed 0h 1m 50s\n",
      "--------------------\n",
      "Epoch [4/40]:\n",
      "\ttrain 4-1: Loss: 0.1671 Acc: 75.0000%\n",
      "\ttrain 4-2: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 4-3: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 4-4: Loss: 0.2146 Acc: 50.0000%\n",
      "\ttrain 4-5: Loss: 0.2001 Acc: 25.0000%\n",
      "\ttrain 4-6: Loss: 0.1723 Acc: 75.0000%\n",
      "\ttrain 4-7: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 4-8: Loss: 0.2351 Acc: 50.0000%\n",
      "\ttrain 4-9: Loss: 0.2685 Acc: 0.0000%\n",
      "\ttrain 4-10: Loss: 0.1182 Acc: 50.0000%\n",
      "\ttrain 4-11: Loss: 0.1868 Acc: 50.0000%\n",
      "\ttrain 4-12: Loss: 0.2170 Acc: 25.0000%\n",
      "\ttrain 4-13: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 4-14: Loss: 0.4868 Acc: 25.0000%\n",
      "\ttrain 4-15: Loss: 0.2052 Acc: 50.0000%\n",
      "\ttrain 4-16: Loss: 0.1793 Acc: 25.0000%\n",
      "\ttrain 4-17: Loss: 0.6343 Acc: 25.0000%\n",
      "\ttrain 4-18: Loss: 0.2788 Acc: 50.0000%\n",
      "\ttrain 4-19: Loss: 0.1731 Acc: 75.0000%\n",
      "\ttrain 4-20: Loss: 0.1655 Acc: 100.0000%\n",
      "\ttrain 4-21: Loss: 0.3218 Acc: 50.0000%\n",
      "\ttrain 4-22: Loss: 0.2166 Acc: 25.0000%\n",
      "\ttrain 4-23: Loss: 0.2949 Acc: 25.0000%\n",
      "\ttrain 4-24: Loss: 0.2291 Acc: 50.0000%\n",
      "\ttrain 4-25: Loss: 0.2781 Acc: 0.0000%\n",
      "\ttrain 4-26: Loss: 0.2505 Acc: 0.0000%\n",
      "\ttrain 4-27: Loss: 0.3049 Acc: 0.0000%\n",
      "\ttrain 4-28: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 4-29: Loss: 0.2712 Acc: 25.0000%\n",
      "\ttrain 4-30: Loss: 0.2432 Acc: 50.0000%\n",
      "\ttrain 4-31: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 4-32: Loss: 0.3285 Acc: 25.0000%\n",
      "\ttrain 4-33: Loss: 0.2472 Acc: 75.0000%\n",
      "\ttrain 4-34: Loss: 0.2142 Acc: 75.0000%\n",
      "\ttrain 4-35: Loss: 0.3777 Acc: 0.0000%\n",
      "\ttrain 4-36: Loss: 0.3034 Acc: 25.0000%\n",
      "\ttrain 4-37: Loss: 0.2676 Acc: 25.0000%\n",
      "\ttrain 4-38: Loss: 0.2327 Acc: 50.0000%\n",
      "\ttrain 4-39: Loss: 0.2555 Acc: 50.0000%\n",
      "\ttrain 4-40: Loss: 0.2649 Acc: 75.0000%\n",
      "\ttrain 4-41: Loss: 0.2506 Acc: 50.0000%\n",
      "\ttrain 4-42: Loss: 0.2145 Acc: 50.0000%\n",
      "\ttrain 4-43: Loss: 0.2868 Acc: 25.0000%\n",
      "\ttrain 4-44: Loss: 0.2966 Acc: 50.0000%\n",
      "\ttrain 4-45: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 4-46: Loss: 0.3003 Acc: 0.0000%\n",
      "\ttrain 4-47: Loss: 0.2083 Acc: 50.0000%\n",
      "\ttrain 4-48: Loss: 0.2135 Acc: 100.0000%\n",
      "\ttrain 4-49: Loss: 0.2295 Acc: 50.0000%\n",
      "\ttrain 4-50: Loss: 0.3227 Acc: 50.0000%\n",
      "\ttrain 4-51: Loss: 0.3000 Acc: 50.0000%\n",
      "\ttrain 4-52: Loss: 0.1987 Acc: 25.0000%\n",
      "\ttrain 4-53: Loss: 0.2051 Acc: 100.0000%\n",
      "\ttrain 4-54: Loss: 0.1412 Acc: 50.0000%\n",
      "\ttrain 4-55: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 4-56: Loss: 0.2585 Acc: 50.0000%\n",
      "\ttrain 4-57: Loss: 0.3032 Acc: 50.0000%\n",
      "\ttrain 4-58: Loss: 0.2264 Acc: 50.0000%\n",
      "\ttrain 4-59: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 4-60: Loss: 0.1259 Acc: 75.0000%\n",
      "\ttrain 4-61: Loss: 0.1898 Acc: 50.0000%\n",
      "\ttrain 4-62: Loss: 0.1538 Acc: 75.0000%\n",
      "\ttrain 4-63: Loss: 0.2382 Acc: 50.0000%\n",
      "\ttrain 4-64: Loss: 0.1640 Acc: 50.0000%\n",
      "\ttrain 4-65: Loss: 0.2389 Acc: 50.0000%\n",
      "\ttrain 4-66: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 4-67: Loss: 0.3492 Acc: 0.0000%\n",
      "\ttrain 4-68: Loss: 0.1328 Acc: 50.0000%\n",
      "\ttrain 4-69: Loss: 0.2272 Acc: 25.0000%\n",
      "\ttrain 4-70: Loss: 0.2087 Acc: 50.0000%\n",
      "\ttrain 4-71: Loss: 0.1111 Acc: 100.0000%\n",
      "\ttrain 4-72: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 4-73: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 4-74: Loss: 0.2080 Acc: 75.0000%\n",
      "\ttrain 4-75: Loss: 0.2698 Acc: 75.0000%\n",
      "\ttrain 4-76: Loss: 0.2152 Acc: 50.0000%\n",
      "\ttrain 4-77: Loss: 0.3585 Acc: 25.0000%\n",
      "\ttrain 4-78: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 4-79: Loss: 0.2518 Acc: 25.0000%\n",
      "\ttrain 4-80: Loss: 0.3414 Acc: 25.0000%\n",
      "\ttrain 4-81: Loss: 0.2084 Acc: 25.0000%\n",
      "\ttrain 4-82: Loss: 0.2289 Acc: 50.0000%\n",
      "\ttrain 4-83: Loss: 0.2121 Acc: 50.0000%\n",
      "\ttrain 4-84: Loss: 0.2278 Acc: 50.0000%\n",
      "\ttrain 4-85: Loss: 0.3847 Acc: 25.0000%\n",
      "\ttrain 4-86: Loss: 0.1879 Acc: 75.0000%\n",
      "\ttrain 4-87: Loss: 0.4694 Acc: 25.0000%\n",
      "\ttrain 4-88: Loss: 0.1867 Acc: 50.0000%\n",
      "\ttrain 4-89: Loss: 0.2795 Acc: 50.0000%\n",
      "\ttrain 4-90: Loss: 0.1989 Acc: 75.0000%\n",
      "\ttrain 4-91: Loss: 0.1914 Acc: 50.0000%\n",
      "\ttrain 4-92: Loss: 0.2519 Acc: 0.0000%\n",
      "\ttrain 4-93: Loss: 0.2477 Acc: 25.0000%\n",
      "\ttrain 4-94: Loss: 0.1225 Acc: 75.0000%\n",
      "\ttrain 4-95: Loss: 0.1617 Acc: 75.0000%\n",
      "\ttrain 4-96: Loss: 0.3023 Acc: 25.0000%\n",
      "\ttrain 4-97: Loss: 0.1213 Acc: 50.0000%\n",
      "\ttrain 4-98: Loss: 0.1881 Acc: 75.0000%\n",
      "\ttrain 4-99: Loss: 0.2273 Acc: 25.0000%\n",
      "\ttrain 4-100: Loss: 0.2071 Acc: 50.0000%\n",
      "\ttrain 4-101: Loss: 0.2663 Acc: 25.0000%\n",
      "\ttrain 4-102: Loss: 0.2463 Acc: 50.0000%\n",
      "\ttrain 4-103: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 4-104: Loss: 0.2326 Acc: 25.0000%\n",
      "\ttrain 4-105: Loss: 0.2868 Acc: 25.0000%\n",
      "\ttrain 4-106: Loss: 0.2096 Acc: 75.0000%\n",
      "\ttrain 4-107: Loss: 0.2614 Acc: 50.0000%\n",
      "\ttrain 4-108: Loss: 0.2124 Acc: 50.0000%\n",
      "\ttrain 4-109: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 4-110: Loss: 0.2115 Acc: 50.0000%\n",
      "\ttrain 4-111: Loss: 0.2161 Acc: 25.0000%\n",
      "\ttrain 4-112: Loss: 0.2785 Acc: 50.0000%\n",
      "\ttrain 4-113: Loss: 0.2509 Acc: 0.0000%\n",
      "\ttrain 4-114: Loss: 0.1248 Acc: 100.0000%\n",
      "\ttrain 4-115: Loss: 0.1586 Acc: 75.0000%\n",
      "\ttrain 4-116: Loss: 0.1046 Acc: 50.0000%\n",
      "\ttrain 4-117: Loss: 0.3231 Acc: 0.0000%\n",
      "\ttrain 4-118: Loss: 0.3554 Acc: 50.0000%\n",
      "\ttrain 4-119: Loss: 0.2686 Acc: 25.0000%\n",
      "\ttrain 4-120: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 4-121: Loss: 0.1602 Acc: 50.0000%\n",
      "\ttrain 4-122: Loss: 0.1659 Acc: 50.0000%\n",
      "\ttrain 4-123: Loss: 0.1569 Acc: 50.0000%\n",
      "\ttrain 4-124: Loss: 0.1233 Acc: 50.0000%\n",
      "\ttrain 4-125: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 4-126: Loss: 0.1848 Acc: 50.0000%\n",
      "\ttrain 4-127: Loss: 0.3861 Acc: 25.0000%\n",
      "\ttrain 4-128: Loss: 0.3329 Acc: 0.0000%\n",
      "\ttrain 4-129: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 4-130: Loss: 0.1734 Acc: 100.0000%\n",
      "\ttrain 4-131: Loss: 0.1845 Acc: 50.0000%\n",
      "\ttrain 4-132: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 4-133: Loss: 0.1074 Acc: 100.0000%\n",
      "\ttrain 4-134: Loss: 0.2002 Acc: 50.0000%\n",
      "\ttrain 4-135: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 4-136: Loss: 0.1786 Acc: 50.0000%\n",
      "\ttrain 4-137: Loss: 0.1404 Acc: 75.0000%\n",
      "\ttrain 4-138: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 4-139: Loss: 0.2260 Acc: 50.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-140: Loss: 0.2324 Acc: 50.0000%\n",
      "\ttrain 4-141: Loss: 0.2693 Acc: 25.0000%\n",
      "\ttrain 4-142: Loss: 0.1725 Acc: 50.0000%\n",
      "\ttrain 4-143: Loss: 0.2062 Acc: 50.0000%\n",
      "\ttrain 4-144: Loss: 0.2853 Acc: 50.0000%\n",
      "\ttrain 4-145: Loss: 0.1032 Acc: 100.0000%\n",
      "\ttrain 4-146: Loss: 0.1519 Acc: 50.0000%\n",
      "\ttrain 4-147: Loss: 0.5301 Acc: 0.0000%\n",
      "\ttrain 4-148: Loss: 0.1481 Acc: 50.0000%\n",
      "\ttrain 4-149: Loss: 0.1582 Acc: 75.0000%\n",
      "\ttrain 4-150: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 4-151: Loss: 0.1785 Acc: 75.0000%\n",
      "\ttrain 4-152: Loss: 0.2237 Acc: 50.0000%\n",
      "\ttrain 4-153: Loss: 0.2352 Acc: 50.0000%\n",
      "\ttrain 4-154: Loss: 0.2031 Acc: 75.0000%\n",
      "\ttrain 4-155: Loss: 0.1924 Acc: 50.0000%\n",
      "\ttrain 4-156: Loss: 0.2007 Acc: 50.0000%\n",
      "\ttrain 4-157: Loss: 0.2678 Acc: 75.0000%\n",
      "\ttrain 4-158: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 4-159: Loss: 0.2307 Acc: 50.0000%\n",
      "\ttrain 4-160: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 4-161: Loss: 0.2368 Acc: 25.0000%\n",
      "\ttrain 4-162: Loss: 0.1949 Acc: 50.0000%\n",
      "\ttrain 4-163: Loss: 0.4050 Acc: 25.0000%\n",
      "\ttrain 4-164: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 4-165: Loss: 0.2475 Acc: 75.0000%\n",
      "\ttrain 4-166: Loss: 0.1918 Acc: 100.0000%\n",
      "\ttrain 4-167: Loss: 0.1495 Acc: 75.0000%\n",
      "\ttrain 4-168: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 4-169: Loss: 0.2915 Acc: 75.0000%\n",
      "\ttrain 4-170: Loss: 0.1852 Acc: 50.0000%\n",
      "\ttrain 4-171: Loss: 0.2023 Acc: 50.0000%\n",
      "\ttrain 4-172: Loss: 0.1866 Acc: 75.0000%\n",
      "\ttrain 4-173: Loss: 0.1860 Acc: 25.0000%\n",
      "\ttrain 4-174: Loss: 0.1040 Acc: 50.0000%\n",
      "\ttrain 4-175: Loss: 0.2517 Acc: 50.0000%\n",
      "\ttrain 4-176: Loss: 0.1800 Acc: 75.0000%\n",
      "\ttrain 4-177: Loss: 0.1536 Acc: 50.0000%\n",
      "\ttrain 4-178: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 4-179: Loss: 0.2290 Acc: 75.0000%\n",
      "\ttrain 4-180: Loss: 0.1659 Acc: 75.0000%\n",
      "\ttrain 4-181: Loss: 0.2067 Acc: 25.0000%\n",
      "\ttrain 4-182: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 4-183: Loss: 0.1092 Acc: 75.0000%\n",
      "\ttrain 4-184: Loss: 0.3864 Acc: 25.0000%\n",
      "\ttrain 4-185: Loss: 0.2525 Acc: 50.0000%\n",
      "\ttrain 4-186: Loss: 0.1761 Acc: 50.0000%\n",
      "\ttrain 4-187: Loss: 0.1326 Acc: 100.0000%\n",
      "\ttrain 4-188: Loss: 0.1745 Acc: 75.0000%\n",
      "\ttrain 4-189: Loss: 0.2174 Acc: 75.0000%\n",
      "\ttrain 4-190: Loss: 0.2681 Acc: 50.0000%\n",
      "\ttrain 4-191: Loss: 0.2440 Acc: 50.0000%\n",
      "\ttrain 4-192: Loss: 0.2341 Acc: 50.0000%\n",
      "\ttrain 4-193: Loss: 0.2656 Acc: 25.0000%\n",
      "\ttrain 4-194: Loss: 0.2351 Acc: 75.0000%\n",
      "\ttrain 4-195: Loss: 0.3041 Acc: 25.0000%\n",
      "\ttrain 4-196: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 4-197: Loss: 0.2575 Acc: 25.0000%\n",
      "\ttrain 4-198: Loss: 0.1457 Acc: 50.0000%\n",
      "\ttrain 4-199: Loss: 0.1908 Acc: 75.0000%\n",
      "\ttrain 4-200: Loss: 0.1899 Acc: 50.0000%\n",
      "\ttrain 4-201: Loss: 0.1359 Acc: 75.0000%\n",
      "\ttrain 4-202: Loss: 0.1725 Acc: 75.0000%\n",
      "\ttrain 4-203: Loss: 0.2467 Acc: 25.0000%\n",
      "\ttrain 4-204: Loss: 0.2100 Acc: 75.0000%\n",
      "\ttrain 4-205: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 4-206: Loss: 0.1978 Acc: 50.0000%\n",
      "\ttrain 4-207: Loss: 0.1500 Acc: 50.0000%\n",
      "\ttrain 4-208: Loss: 0.1933 Acc: 50.0000%\n",
      "\ttrain 4-209: Loss: 0.1640 Acc: 75.0000%\n",
      "\ttrain 4-210: Loss: 0.1077 Acc: 100.0000%\n",
      "\ttrain 4-211: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 4-212: Loss: 0.1318 Acc: 100.0000%\n",
      "\ttrain 4-213: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 4-214: Loss: 0.1782 Acc: 50.0000%\n",
      "\ttrain 4-215: Loss: 0.2614 Acc: 50.0000%\n",
      "\ttrain 4-216: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 4-217: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 4-218: Loss: 0.1336 Acc: 50.0000%\n",
      "\ttrain 4-219: Loss: 0.2450 Acc: 50.0000%\n",
      "\ttrain 4-220: Loss: 0.1677 Acc: 25.0000%\n",
      "\ttrain 4-221: Loss: 0.2013 Acc: 50.0000%\n",
      "\ttrain 4-222: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 4-223: Loss: 0.2445 Acc: 75.0000%\n",
      "\ttrain 4-224: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 4-225: Loss: 0.2860 Acc: 50.0000%\n",
      "\ttrain 4-226: Loss: 0.1011 Acc: 100.0000%\n",
      "\ttrain 4-227: Loss: 0.1615 Acc: 50.0000%\n",
      "\ttrain 4-228: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 4-229: Loss: 0.2110 Acc: 75.0000%\n",
      "\ttrain 4-230: Loss: 0.3826 Acc: 25.0000%\n",
      "\ttrain 4-231: Loss: 0.2169 Acc: 50.0000%\n",
      "\ttrain 4-232: Loss: 0.1877 Acc: 50.0000%\n",
      "\ttrain 4-233: Loss: 0.1226 Acc: 100.0000%\n",
      "\ttrain 4-234: Loss: 0.1589 Acc: 25.0000%\n",
      "\ttrain 4-235: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 4-236: Loss: 0.2318 Acc: 50.0000%\n",
      "\ttrain 4-237: Loss: 0.5608 Acc: 0.0000%\n",
      "\ttrain 4-238: Loss: 0.2260 Acc: 25.0000%\n",
      "\ttrain 4-239: Loss: 0.1856 Acc: 25.0000%\n",
      "\ttrain 4-240: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 4-241: Loss: 0.1623 Acc: 50.0000%\n",
      "\ttrain 4-242: Loss: 0.2079 Acc: 25.0000%\n",
      "\ttrain 4-243: Loss: 0.1513 Acc: 100.0000%\n",
      "\ttrain 4-244: Loss: 0.2560 Acc: 25.0000%\n",
      "\ttrain 4-245: Loss: 0.1569 Acc: 75.0000%\n",
      "\tvalidation 4-1: Loss: 0.2101 Acc: 25.0000%\n",
      "\tvalidation 4-2: Loss: 0.1924 Acc: 75.0000%\n",
      "\tvalidation 4-3: Loss: 0.1504 Acc: 50.0000%\n",
      "\tvalidation 4-4: Loss: 0.1829 Acc: 25.0000%\n",
      "\tvalidation 4-5: Loss: 0.2478 Acc: 50.0000%\n",
      "\tvalidation 4-6: Loss: 0.0978 Acc: 100.0000%\n",
      "\tvalidation 4-7: Loss: 0.1047 Acc: 100.0000%\n",
      "\tvalidation 4-8: Loss: 0.1742 Acc: 100.0000%\n",
      "\tvalidation 4-9: Loss: 0.1628 Acc: 75.0000%\n",
      "\tvalidation 4-10: Loss: 0.1919 Acc: 50.0000%\n",
      "\tvalidation 4-11: Loss: 0.1780 Acc: 75.0000%\n",
      "\tvalidation 4-12: Loss: 0.1134 Acc: 100.0000%\n",
      "\tvalidation 4-13: Loss: 0.1294 Acc: 50.0000%\n",
      "\tvalidation 4-14: Loss: 0.0590 Acc: 100.0000%\n",
      "\tvalidation 4-15: Loss: 0.1861 Acc: 75.0000%\n",
      "\tvalidation 4-16: Loss: 0.1595 Acc: 75.0000%\n",
      "\tvalidation 4-17: Loss: 0.1908 Acc: 100.0000%\n",
      "\tvalidation 4-18: Loss: 0.1237 Acc: 100.0000%\n",
      "\tvalidation 4-19: Loss: 0.1806 Acc: 50.0000%\n",
      "\tvalidation 4-20: Loss: 0.1810 Acc: 75.0000%\n",
      "\tvalidation 4-21: Loss: 0.1416 Acc: 75.0000%\n",
      "\tvalidation 4-22: Loss: 0.1462 Acc: 75.0000%\n",
      "\tvalidation 4-23: Loss: 0.2272 Acc: 75.0000%\n",
      "\tvalidation 4-24: Loss: 0.1713 Acc: 100.0000%\n",
      "\tvalidation 4-25: Loss: 0.1569 Acc: 50.0000%\n",
      "\tvalidation 4-26: Loss: 0.1957 Acc: 50.0000%\n",
      "\tvalidation 4-27: Loss: 0.1683 Acc: 75.0000%\n",
      "\tvalidation 4-28: Loss: 0.1019 Acc: 100.0000%\n",
      "\tvalidation 4-29: Loss: 0.1487 Acc: 100.0000%\n",
      "\tvalidation 4-30: Loss: 0.0508 Acc: 100.0000%\n",
      "\tvalidation 4-31: Loss: 0.1905 Acc: 75.0000%\n",
      "\tvalidation 4-32: Loss: 0.1982 Acc: 50.0000%\n",
      "\tvalidation 4-33: Loss: 0.1819 Acc: 75.0000%\n",
      "\tvalidation 4-34: Loss: 0.1939 Acc: 50.0000%\n",
      "\tvalidation 4-35: Loss: 0.1394 Acc: 100.0000%\n",
      "\tvalidation 4-36: Loss: 0.1835 Acc: 75.0000%\n",
      "\tvalidation 4-37: Loss: 0.2100 Acc: 50.0000%\n",
      "\tvalidation 4-38: Loss: 0.1505 Acc: 50.0000%\n",
      "\tvalidation 4-39: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 4-40: Loss: 0.1315 Acc: 100.0000%\n",
      "\tvalidation 4-41: Loss: 0.1491 Acc: 100.0000%\n",
      "\tvalidation 4-42: Loss: 0.1860 Acc: 75.0000%\n",
      "\tvalidation 4-43: Loss: 0.2150 Acc: 50.0000%\n",
      "\tvalidation 4-44: Loss: 0.1992 Acc: 50.0000%\n",
      "\tvalidation 4-45: Loss: 0.1103 Acc: 75.0000%\n",
      "\tvalidation 4-46: Loss: 0.1920 Acc: 75.0000%\n",
      "\tvalidation 4-47: Loss: 0.1087 Acc: 100.0000%\n",
      "\tvalidation 4-48: Loss: 0.1680 Acc: 100.0000%\n",
      "\tvalidation 4-49: Loss: 0.2105 Acc: 25.0000%\n",
      "\tvalidation 4-50: Loss: 0.0940 Acc: 100.0000%\n",
      "\tvalidation 4-51: Loss: 0.1635 Acc: 75.0000%\n",
      "\tvalidation 4-52: Loss: 0.1531 Acc: 100.0000%\n",
      "\tvalidation 4-53: Loss: 0.1403 Acc: 75.0000%\n",
      "\tvalidation 4-54: Loss: 0.1844 Acc: 75.0000%\n",
      "\tvalidation 4-55: Loss: 0.1581 Acc: 75.0000%\n",
      "\tvalidation 4-56: Loss: 0.1987 Acc: 25.0000%\n",
      "\tvalidation 4-57: Loss: 0.1446 Acc: 100.0000%\n",
      "\tvalidation 4-58: Loss: 0.1342 Acc: 50.0000%\n",
      "\tvalidation 4-59: Loss: 0.2018 Acc: 75.0000%\n",
      "\tvalidation 4-60: Loss: 0.1617 Acc: 50.0000%\n",
      "\tvalidation 4-61: Loss: 0.1845 Acc: 75.0000%\n",
      "\tvalidation 4-62: Loss: 0.1561 Acc: 100.0000%\n",
      "\tvalidation 4-63: Loss: 0.1907 Acc: 100.0000%\n",
      "\tvalidation 4-64: Loss: 0.0568 Acc: 100.0000%\n",
      "\tvalidation 4-65: Loss: 0.2140 Acc: 75.0000%\n",
      "\tvalidation 4-66: Loss: 0.2080 Acc: 50.0000%\n",
      "\tvalidation 4-67: Loss: 0.1494 Acc: 100.0000%\n",
      "\tvalidation 4-68: Loss: 0.0889 Acc: 100.0000%\n",
      "\tvalidation 4-69: Loss: 0.1481 Acc: 75.0000%\n",
      "\tvalidation 4-70: Loss: 0.1144 Acc: 100.0000%\n",
      "\tvalidation 4-71: Loss: 0.1711 Acc: 50.0000%\n",
      "\tvalidation 4-72: Loss: 0.0856 Acc: 100.0000%\n",
      "\tvalidation 4-73: Loss: 0.1098 Acc: 100.0000%\n",
      "\tvalidation 4-74: Loss: 0.1105 Acc: 50.0000%\n",
      "\tvalidation 4-75: Loss: 0.1398 Acc: 75.0000%\n",
      "\tvalidation 4-76: Loss: 0.1735 Acc: 75.0000%\n",
      "\tvalidation 4-77: Loss: 0.1317 Acc: 100.0000%\n",
      "\tvalidation 4-78: Loss: 0.1790 Acc: 50.0000%\n",
      "\tvalidation 4-79: Loss: 0.1694 Acc: 25.0000%\n",
      "\tvalidation 4-80: Loss: 0.1482 Acc: 75.0000%\n",
      "\tvalidation 4-81: Loss: 0.0709 Acc: 100.0000%\n",
      "\tvalidation 4-82: Loss: 0.1532 Acc: 75.0000%\n",
      "\tvalidation 4-83: Loss: 0.0737 Acc: 100.0000%\n",
      "\tvalidation 4-84: Loss: 0.2201 Acc: 75.0000%\n",
      "\tvalidation 4-85: Loss: 0.1728 Acc: 50.0000%\n",
      "\tvalidation 4-86: Loss: 0.1756 Acc: 50.0000%\n",
      "\tvalidation 4-87: Loss: 0.2053 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 4-88: Loss: 0.1760 Acc: 50.0000%\n",
      "\tvalidation 4-89: Loss: 0.1843 Acc: 50.0000%\n",
      "\tvalidation 4-90: Loss: 0.1970 Acc: 50.0000%\n",
      "\tvalidation 4-91: Loss: 0.1967 Acc: 75.0000%\n",
      "\tvalidation 4-92: Loss: 0.2026 Acc: 100.0000%\n",
      "\tvalidation 4-93: Loss: 0.2105 Acc: 50.0000%\n",
      "\tvalidation 4-94: Loss: 0.1358 Acc: 100.0000%\n",
      "\tvalidation 4-95: Loss: 0.1569 Acc: 75.0000%\n",
      "\tvalidation 4-96: Loss: 0.1072 Acc: 75.0000%\n",
      "\tvalidation 4-97: Loss: 0.2354 Acc: 0.0000%\n",
      "\tvalidation 4-98: Loss: 0.1591 Acc: 100.0000%\n",
      "\tvalidation 4-99: Loss: 0.1838 Acc: 50.0000%\n",
      "\tvalidation 4-100: Loss: 0.2173 Acc: 50.0000%\n",
      "\tvalidation 4-101: Loss: 0.0990 Acc: 75.0000%\n",
      "\tvalidation 4-102: Loss: 0.1706 Acc: 50.0000%\n",
      "\tvalidation 4-103: Loss: 0.1250 Acc: 75.0000%\n",
      "\tvalidation 4-104: Loss: 0.1057 Acc: 100.0000%\n",
      "\tvalidation 4-105: Loss: 0.1966 Acc: 75.0000%\n",
      "\ttrain Loss: 0.2140 Acc: 53.2653%\n",
      "\tvalidation Loss: 0.1594 Acc: 73.5714%\n",
      "网络参数更新\n",
      "Time passed 0h 2m 32s\n",
      "--------------------\n",
      "Epoch [5/40]:\n",
      "\ttrain 5-1: Loss: 0.1911 Acc: 75.0000%\n",
      "\ttrain 5-2: Loss: 0.1875 Acc: 100.0000%\n",
      "\ttrain 5-3: Loss: 0.1007 Acc: 100.0000%\n",
      "\ttrain 5-4: Loss: 0.1662 Acc: 75.0000%\n",
      "\ttrain 5-5: Loss: 0.1639 Acc: 75.0000%\n",
      "\ttrain 5-6: Loss: 0.1554 Acc: 75.0000%\n",
      "\ttrain 5-7: Loss: 0.1021 Acc: 100.0000%\n",
      "\ttrain 5-8: Loss: 0.2086 Acc: 25.0000%\n",
      "\ttrain 5-9: Loss: 0.1573 Acc: 50.0000%\n",
      "\ttrain 5-10: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 5-11: Loss: 0.0986 Acc: 100.0000%\n",
      "\ttrain 5-12: Loss: 0.2943 Acc: 25.0000%\n",
      "\ttrain 5-13: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 5-14: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 5-15: Loss: 0.2354 Acc: 50.0000%\n",
      "\ttrain 5-16: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 5-17: Loss: 0.2168 Acc: 75.0000%\n",
      "\ttrain 5-18: Loss: 0.2023 Acc: 50.0000%\n",
      "\ttrain 5-19: Loss: 0.1208 Acc: 75.0000%\n",
      "\ttrain 5-20: Loss: 0.2379 Acc: 25.0000%\n",
      "\ttrain 5-21: Loss: 0.0942 Acc: 100.0000%\n",
      "\ttrain 5-22: Loss: 0.2243 Acc: 50.0000%\n",
      "\ttrain 5-23: Loss: 0.3200 Acc: 25.0000%\n",
      "\ttrain 5-24: Loss: 0.2414 Acc: 50.0000%\n",
      "\ttrain 5-25: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 5-26: Loss: 0.0939 Acc: 100.0000%\n",
      "\ttrain 5-27: Loss: 0.0889 Acc: 100.0000%\n",
      "\ttrain 5-28: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 5-29: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 5-30: Loss: 0.1454 Acc: 50.0000%\n",
      "\ttrain 5-31: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 5-32: Loss: 0.1951 Acc: 75.0000%\n",
      "\ttrain 5-33: Loss: 0.1770 Acc: 75.0000%\n",
      "\ttrain 5-34: Loss: 0.1996 Acc: 75.0000%\n",
      "\ttrain 5-35: Loss: 0.1779 Acc: 50.0000%\n",
      "\ttrain 5-36: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 5-37: Loss: 0.1978 Acc: 50.0000%\n",
      "\ttrain 5-38: Loss: 0.1528 Acc: 75.0000%\n",
      "\ttrain 5-39: Loss: 0.2247 Acc: 25.0000%\n",
      "\ttrain 5-40: Loss: 0.1326 Acc: 75.0000%\n",
      "\ttrain 5-41: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 5-42: Loss: 0.1567 Acc: 50.0000%\n",
      "\ttrain 5-43: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 5-44: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 5-45: Loss: 0.2232 Acc: 25.0000%\n",
      "\ttrain 5-46: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 5-47: Loss: 0.0971 Acc: 100.0000%\n",
      "\ttrain 5-48: Loss: 0.1768 Acc: 50.0000%\n",
      "\ttrain 5-49: Loss: 0.5402 Acc: 25.0000%\n",
      "\ttrain 5-50: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 5-51: Loss: 0.0846 Acc: 100.0000%\n",
      "\ttrain 5-52: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 5-53: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 5-54: Loss: 0.1793 Acc: 50.0000%\n",
      "\ttrain 5-55: Loss: 0.2261 Acc: 50.0000%\n",
      "\ttrain 5-56: Loss: 0.1658 Acc: 100.0000%\n",
      "\ttrain 5-57: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 5-58: Loss: 0.1157 Acc: 100.0000%\n",
      "\ttrain 5-59: Loss: 0.2423 Acc: 75.0000%\n",
      "\ttrain 5-60: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 5-61: Loss: 0.1828 Acc: 75.0000%\n",
      "\ttrain 5-62: Loss: 0.2727 Acc: 75.0000%\n",
      "\ttrain 5-63: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 5-64: Loss: 0.2564 Acc: 50.0000%\n",
      "\ttrain 5-65: Loss: 0.1952 Acc: 75.0000%\n",
      "\ttrain 5-66: Loss: 0.1698 Acc: 50.0000%\n",
      "\ttrain 5-67: Loss: 0.2774 Acc: 50.0000%\n",
      "\ttrain 5-68: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 5-69: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 5-70: Loss: 0.2782 Acc: 50.0000%\n",
      "\ttrain 5-71: Loss: 0.1527 Acc: 75.0000%\n",
      "\ttrain 5-72: Loss: 0.0981 Acc: 100.0000%\n",
      "\ttrain 5-73: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 5-74: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 5-75: Loss: 0.4068 Acc: 0.0000%\n",
      "\ttrain 5-76: Loss: 0.2596 Acc: 50.0000%\n",
      "\ttrain 5-77: Loss: 0.0833 Acc: 100.0000%\n",
      "\ttrain 5-78: Loss: 0.1376 Acc: 75.0000%\n",
      "\ttrain 5-79: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 5-80: Loss: 0.1093 Acc: 75.0000%\n",
      "\ttrain 5-81: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 5-82: Loss: 0.3488 Acc: 50.0000%\n",
      "\ttrain 5-83: Loss: 0.0771 Acc: 100.0000%\n",
      "\ttrain 5-84: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 5-85: Loss: 0.1326 Acc: 50.0000%\n",
      "\ttrain 5-86: Loss: 0.2961 Acc: 50.0000%\n",
      "\ttrain 5-87: Loss: 0.2062 Acc: 75.0000%\n",
      "\ttrain 5-88: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 5-89: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 5-90: Loss: 0.3110 Acc: 25.0000%\n",
      "\ttrain 5-91: Loss: 0.3473 Acc: 25.0000%\n",
      "\ttrain 5-92: Loss: 0.3137 Acc: 50.0000%\n",
      "\ttrain 5-93: Loss: 0.1631 Acc: 50.0000%\n",
      "\ttrain 5-94: Loss: 0.1116 Acc: 100.0000%\n",
      "\ttrain 5-95: Loss: 0.1763 Acc: 50.0000%\n",
      "\ttrain 5-96: Loss: 0.1206 Acc: 50.0000%\n",
      "\ttrain 5-97: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 5-98: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 5-99: Loss: 0.1434 Acc: 100.0000%\n",
      "\ttrain 5-100: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 5-101: Loss: 0.1883 Acc: 75.0000%\n",
      "\ttrain 5-102: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 5-103: Loss: 0.1938 Acc: 50.0000%\n",
      "\ttrain 5-104: Loss: 0.1254 Acc: 50.0000%\n",
      "\ttrain 5-105: Loss: 0.1505 Acc: 50.0000%\n",
      "\ttrain 5-106: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 5-107: Loss: 0.2592 Acc: 75.0000%\n",
      "\ttrain 5-108: Loss: 0.1774 Acc: 25.0000%\n",
      "\ttrain 5-109: Loss: 0.1495 Acc: 25.0000%\n",
      "\ttrain 5-110: Loss: 0.1358 Acc: 75.0000%\n",
      "\ttrain 5-111: Loss: 0.1626 Acc: 100.0000%\n",
      "\ttrain 5-112: Loss: 0.2054 Acc: 25.0000%\n",
      "\ttrain 5-113: Loss: 0.1776 Acc: 50.0000%\n",
      "\ttrain 5-114: Loss: 0.2020 Acc: 50.0000%\n",
      "\ttrain 5-115: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 5-116: Loss: 0.1855 Acc: 25.0000%\n",
      "\ttrain 5-117: Loss: 0.1158 Acc: 100.0000%\n",
      "\ttrain 5-118: Loss: 0.2166 Acc: 50.0000%\n",
      "\ttrain 5-119: Loss: 0.2418 Acc: 50.0000%\n",
      "\ttrain 5-120: Loss: 0.1216 Acc: 100.0000%\n",
      "\ttrain 5-121: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 5-122: Loss: 0.1108 Acc: 50.0000%\n",
      "\ttrain 5-123: Loss: 0.1832 Acc: 25.0000%\n",
      "\ttrain 5-124: Loss: 0.1225 Acc: 100.0000%\n",
      "\ttrain 5-125: Loss: 0.0837 Acc: 100.0000%\n",
      "\ttrain 5-126: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 5-127: Loss: 0.1235 Acc: 100.0000%\n",
      "\ttrain 5-128: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 5-129: Loss: 0.1512 Acc: 75.0000%\n",
      "\ttrain 5-130: Loss: 0.1078 Acc: 100.0000%\n",
      "\ttrain 5-131: Loss: 0.4074 Acc: 50.0000%\n",
      "\ttrain 5-132: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 5-133: Loss: 0.1597 Acc: 25.0000%\n",
      "\ttrain 5-134: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 5-135: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 5-136: Loss: 0.1085 Acc: 100.0000%\n",
      "\ttrain 5-137: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 5-138: Loss: 0.0935 Acc: 100.0000%\n",
      "\ttrain 5-139: Loss: 0.1417 Acc: 50.0000%\n",
      "\ttrain 5-140: Loss: 0.1810 Acc: 50.0000%\n",
      "\ttrain 5-141: Loss: 0.1658 Acc: 50.0000%\n",
      "\ttrain 5-142: Loss: 0.2359 Acc: 50.0000%\n",
      "\ttrain 5-143: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 5-144: Loss: 0.1380 Acc: 100.0000%\n",
      "\ttrain 5-145: Loss: 0.1934 Acc: 25.0000%\n",
      "\ttrain 5-146: Loss: 0.0560 Acc: 75.0000%\n",
      "\ttrain 5-147: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 5-148: Loss: 0.1963 Acc: 25.0000%\n",
      "\ttrain 5-149: Loss: 0.0831 Acc: 100.0000%\n",
      "\ttrain 5-150: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 5-151: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 5-152: Loss: 0.2086 Acc: 25.0000%\n",
      "\ttrain 5-153: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 5-154: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 5-155: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 5-156: Loss: 0.0875 Acc: 100.0000%\n",
      "\ttrain 5-157: Loss: 0.1701 Acc: 50.0000%\n",
      "\ttrain 5-158: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 5-159: Loss: 0.2550 Acc: 50.0000%\n",
      "\ttrain 5-160: Loss: 0.2169 Acc: 50.0000%\n",
      "\ttrain 5-161: Loss: 0.1707 Acc: 75.0000%\n",
      "\ttrain 5-162: Loss: 0.1760 Acc: 50.0000%\n",
      "\ttrain 5-163: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 5-164: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 5-165: Loss: 0.2740 Acc: 75.0000%\n",
      "\ttrain 5-166: Loss: 0.2074 Acc: 50.0000%\n",
      "\ttrain 5-167: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 5-168: Loss: 0.2843 Acc: 75.0000%\n",
      "\ttrain 5-169: Loss: 0.2818 Acc: 75.0000%\n",
      "\ttrain 5-170: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 5-171: Loss: 0.1709 Acc: 25.0000%\n",
      "\ttrain 5-172: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 5-173: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 5-174: Loss: 0.1456 Acc: 50.0000%\n",
      "\ttrain 5-175: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 5-176: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 5-177: Loss: 0.2996 Acc: 50.0000%\n",
      "\ttrain 5-178: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 5-179: Loss: 0.1465 Acc: 50.0000%\n",
      "\ttrain 5-180: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 5-181: Loss: 0.0755 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 5-182: Loss: 0.1341 Acc: 75.0000%\n",
      "\ttrain 5-183: Loss: 0.1094 Acc: 100.0000%\n",
      "\ttrain 5-184: Loss: 0.1128 Acc: 50.0000%\n",
      "\ttrain 5-185: Loss: 0.3885 Acc: 50.0000%\n",
      "\ttrain 5-186: Loss: 0.2465 Acc: 75.0000%\n",
      "\ttrain 5-187: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 5-188: Loss: 0.3146 Acc: 50.0000%\n",
      "\ttrain 5-189: Loss: 0.1931 Acc: 50.0000%\n",
      "\ttrain 5-190: Loss: 0.1307 Acc: 50.0000%\n",
      "\ttrain 5-191: Loss: 0.6383 Acc: 50.0000%\n",
      "\ttrain 5-192: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 5-193: Loss: 0.4116 Acc: 50.0000%\n",
      "\ttrain 5-194: Loss: 0.3284 Acc: 25.0000%\n",
      "\ttrain 5-195: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 5-196: Loss: 0.2637 Acc: 25.0000%\n",
      "\ttrain 5-197: Loss: 0.2991 Acc: 50.0000%\n",
      "\ttrain 5-198: Loss: 0.1962 Acc: 50.0000%\n",
      "\ttrain 5-199: Loss: 0.3201 Acc: 25.0000%\n",
      "\ttrain 5-200: Loss: 0.2914 Acc: 25.0000%\n",
      "\ttrain 5-201: Loss: 0.2152 Acc: 75.0000%\n",
      "\ttrain 5-202: Loss: 0.1910 Acc: 75.0000%\n",
      "\ttrain 5-203: Loss: 0.2435 Acc: 75.0000%\n",
      "\ttrain 5-204: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 5-205: Loss: 0.2545 Acc: 50.0000%\n",
      "\ttrain 5-206: Loss: 0.1768 Acc: 25.0000%\n",
      "\ttrain 5-207: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 5-208: Loss: 0.0886 Acc: 100.0000%\n",
      "\ttrain 5-209: Loss: 0.2458 Acc: 25.0000%\n",
      "\ttrain 5-210: Loss: 0.2111 Acc: 75.0000%\n",
      "\ttrain 5-211: Loss: 0.1077 Acc: 100.0000%\n",
      "\ttrain 5-212: Loss: 0.2324 Acc: 75.0000%\n",
      "\ttrain 5-213: Loss: 0.2981 Acc: 0.0000%\n",
      "\ttrain 5-214: Loss: 0.0703 Acc: 100.0000%\n",
      "\ttrain 5-215: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 5-216: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 5-217: Loss: 0.1430 Acc: 50.0000%\n",
      "\ttrain 5-218: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 5-219: Loss: 0.1306 Acc: 75.0000%\n",
      "\ttrain 5-220: Loss: 0.1205 Acc: 75.0000%\n",
      "\ttrain 5-221: Loss: 0.1246 Acc: 75.0000%\n",
      "\ttrain 5-222: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 5-223: Loss: 0.2039 Acc: 50.0000%\n",
      "\ttrain 5-224: Loss: 0.2204 Acc: 25.0000%\n",
      "\ttrain 5-225: Loss: 0.3208 Acc: 25.0000%\n",
      "\ttrain 5-226: Loss: 0.2294 Acc: 50.0000%\n",
      "\ttrain 5-227: Loss: 0.1040 Acc: 75.0000%\n",
      "\ttrain 5-228: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 5-229: Loss: 0.2471 Acc: 50.0000%\n",
      "\ttrain 5-230: Loss: 0.1387 Acc: 50.0000%\n",
      "\ttrain 5-231: Loss: 0.1345 Acc: 75.0000%\n",
      "\ttrain 5-232: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 5-233: Loss: 0.2969 Acc: 50.0000%\n",
      "\ttrain 5-234: Loss: 0.1160 Acc: 50.0000%\n",
      "\ttrain 5-235: Loss: 0.1772 Acc: 25.0000%\n",
      "\ttrain 5-236: Loss: 0.0678 Acc: 75.0000%\n",
      "\ttrain 5-237: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 5-238: Loss: 0.2093 Acc: 50.0000%\n",
      "\ttrain 5-239: Loss: 0.1180 Acc: 100.0000%\n",
      "\ttrain 5-240: Loss: 0.1760 Acc: 50.0000%\n",
      "\ttrain 5-241: Loss: 0.1725 Acc: 25.0000%\n",
      "\ttrain 5-242: Loss: 0.0823 Acc: 100.0000%\n",
      "\ttrain 5-243: Loss: 0.2453 Acc: 75.0000%\n",
      "\ttrain 5-244: Loss: 0.0802 Acc: 100.0000%\n",
      "\ttrain 5-245: Loss: 0.1588 Acc: 50.0000%\n",
      "\tvalidation 5-1: Loss: 0.0995 Acc: 100.0000%\n",
      "\tvalidation 5-2: Loss: 0.0538 Acc: 100.0000%\n",
      "\tvalidation 5-3: Loss: 0.1210 Acc: 50.0000%\n",
      "\tvalidation 5-4: Loss: 0.1214 Acc: 75.0000%\n",
      "\tvalidation 5-5: Loss: 0.1068 Acc: 75.0000%\n",
      "\tvalidation 5-6: Loss: 0.1582 Acc: 50.0000%\n",
      "\tvalidation 5-7: Loss: 0.1775 Acc: 50.0000%\n",
      "\tvalidation 5-8: Loss: 0.1199 Acc: 50.0000%\n",
      "\tvalidation 5-9: Loss: 0.1193 Acc: 75.0000%\n",
      "\tvalidation 5-10: Loss: 0.1145 Acc: 100.0000%\n",
      "\tvalidation 5-11: Loss: 0.0483 Acc: 100.0000%\n",
      "\tvalidation 5-12: Loss: 0.0933 Acc: 75.0000%\n",
      "\tvalidation 5-13: Loss: 0.1558 Acc: 50.0000%\n",
      "\tvalidation 5-14: Loss: 0.0948 Acc: 75.0000%\n",
      "\tvalidation 5-15: Loss: 0.1365 Acc: 50.0000%\n",
      "\tvalidation 5-16: Loss: 0.0895 Acc: 75.0000%\n",
      "\tvalidation 5-17: Loss: 0.1328 Acc: 50.0000%\n",
      "\tvalidation 5-18: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 5-19: Loss: 0.1084 Acc: 75.0000%\n",
      "\tvalidation 5-20: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 5-21: Loss: 0.0803 Acc: 75.0000%\n",
      "\tvalidation 5-22: Loss: 0.1350 Acc: 100.0000%\n",
      "\tvalidation 5-23: Loss: 0.2227 Acc: 50.0000%\n",
      "\tvalidation 5-24: Loss: 0.1296 Acc: 50.0000%\n",
      "\tvalidation 5-25: Loss: 0.1068 Acc: 75.0000%\n",
      "\tvalidation 5-26: Loss: 0.1405 Acc: 75.0000%\n",
      "\tvalidation 5-27: Loss: 0.0730 Acc: 100.0000%\n",
      "\tvalidation 5-28: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 5-29: Loss: 0.1036 Acc: 100.0000%\n",
      "\tvalidation 5-30: Loss: 0.1256 Acc: 50.0000%\n",
      "\tvalidation 5-31: Loss: 0.1387 Acc: 50.0000%\n",
      "\tvalidation 5-32: Loss: 0.1760 Acc: 25.0000%\n",
      "\tvalidation 5-33: Loss: 0.0916 Acc: 75.0000%\n",
      "\tvalidation 5-34: Loss: 0.0658 Acc: 75.0000%\n",
      "\tvalidation 5-35: Loss: 0.0501 Acc: 100.0000%\n",
      "\tvalidation 5-36: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 5-37: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 5-38: Loss: 0.0613 Acc: 75.0000%\n",
      "\tvalidation 5-39: Loss: 0.1525 Acc: 50.0000%\n",
      "\tvalidation 5-40: Loss: 0.0838 Acc: 75.0000%\n",
      "\tvalidation 5-41: Loss: 0.1289 Acc: 75.0000%\n",
      "\tvalidation 5-42: Loss: 0.1296 Acc: 75.0000%\n",
      "\tvalidation 5-43: Loss: 0.0688 Acc: 100.0000%\n",
      "\tvalidation 5-44: Loss: 0.0788 Acc: 75.0000%\n",
      "\tvalidation 5-45: Loss: 0.0631 Acc: 100.0000%\n",
      "\tvalidation 5-46: Loss: 0.0448 Acc: 100.0000%\n",
      "\tvalidation 5-47: Loss: 0.0995 Acc: 75.0000%\n",
      "\tvalidation 5-48: Loss: 0.2088 Acc: 25.0000%\n",
      "\tvalidation 5-49: Loss: 0.0462 Acc: 100.0000%\n",
      "\tvalidation 5-50: Loss: 0.0951 Acc: 100.0000%\n",
      "\tvalidation 5-51: Loss: 0.1554 Acc: 50.0000%\n",
      "\tvalidation 5-52: Loss: 0.1222 Acc: 75.0000%\n",
      "\tvalidation 5-53: Loss: 0.1856 Acc: 50.0000%\n",
      "\tvalidation 5-54: Loss: 0.1516 Acc: 50.0000%\n",
      "\tvalidation 5-55: Loss: 0.1055 Acc: 100.0000%\n",
      "\tvalidation 5-56: Loss: 0.1532 Acc: 50.0000%\n",
      "\tvalidation 5-57: Loss: 0.1556 Acc: 50.0000%\n",
      "\tvalidation 5-58: Loss: 0.1450 Acc: 50.0000%\n",
      "\tvalidation 5-59: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 5-60: Loss: 0.0932 Acc: 100.0000%\n",
      "\tvalidation 5-61: Loss: 0.2302 Acc: 0.0000%\n",
      "\tvalidation 5-62: Loss: 0.0507 Acc: 75.0000%\n",
      "\tvalidation 5-63: Loss: 0.0949 Acc: 100.0000%\n",
      "\tvalidation 5-64: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 5-65: Loss: 0.1529 Acc: 50.0000%\n",
      "\tvalidation 5-66: Loss: 0.1531 Acc: 50.0000%\n",
      "\tvalidation 5-67: Loss: 0.1043 Acc: 75.0000%\n",
      "\tvalidation 5-68: Loss: 0.0712 Acc: 75.0000%\n",
      "\tvalidation 5-69: Loss: 0.0669 Acc: 100.0000%\n",
      "\tvalidation 5-70: Loss: 0.0877 Acc: 100.0000%\n",
      "\tvalidation 5-71: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 5-72: Loss: 0.1818 Acc: 25.0000%\n",
      "\tvalidation 5-73: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 5-74: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 5-75: Loss: 0.0960 Acc: 75.0000%\n",
      "\tvalidation 5-76: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 5-77: Loss: 0.0687 Acc: 100.0000%\n",
      "\tvalidation 5-78: Loss: 0.0706 Acc: 100.0000%\n",
      "\tvalidation 5-79: Loss: 0.1285 Acc: 75.0000%\n",
      "\tvalidation 5-80: Loss: 0.1715 Acc: 25.0000%\n",
      "\tvalidation 5-81: Loss: 0.0967 Acc: 75.0000%\n",
      "\tvalidation 5-82: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 5-83: Loss: 0.1411 Acc: 75.0000%\n",
      "\tvalidation 5-84: Loss: 0.1095 Acc: 75.0000%\n",
      "\tvalidation 5-85: Loss: 0.1392 Acc: 50.0000%\n",
      "\tvalidation 5-86: Loss: 0.1138 Acc: 75.0000%\n",
      "\tvalidation 5-87: Loss: 0.1451 Acc: 50.0000%\n",
      "\tvalidation 5-88: Loss: 0.0955 Acc: 100.0000%\n",
      "\tvalidation 5-89: Loss: 0.0931 Acc: 75.0000%\n",
      "\tvalidation 5-90: Loss: 0.2605 Acc: 25.0000%\n",
      "\tvalidation 5-91: Loss: 0.1208 Acc: 75.0000%\n",
      "\tvalidation 5-92: Loss: 0.0608 Acc: 75.0000%\n",
      "\tvalidation 5-93: Loss: 0.0872 Acc: 75.0000%\n",
      "\tvalidation 5-94: Loss: 0.0990 Acc: 75.0000%\n",
      "\tvalidation 5-95: Loss: 0.0635 Acc: 75.0000%\n",
      "\tvalidation 5-96: Loss: 0.1627 Acc: 75.0000%\n",
      "\tvalidation 5-97: Loss: 0.1364 Acc: 75.0000%\n",
      "\tvalidation 5-98: Loss: 0.1287 Acc: 75.0000%\n",
      "\tvalidation 5-99: Loss: 0.0726 Acc: 100.0000%\n",
      "\tvalidation 5-100: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 5-101: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 5-102: Loss: 0.0909 Acc: 75.0000%\n",
      "\tvalidation 5-103: Loss: 0.1554 Acc: 50.0000%\n",
      "\tvalidation 5-104: Loss: 0.0518 Acc: 100.0000%\n",
      "\tvalidation 5-105: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1673 Acc: 66.8367%\n",
      "\tvalidation Loss: 0.1072 Acc: 73.8095%\n",
      "网络参数更新\n",
      "Time passed 0h 3m 18s\n",
      "--------------------\n",
      "Epoch [6/40]:\n",
      "\ttrain 6-1: Loss: 0.2060 Acc: 75.0000%\n",
      "\ttrain 6-2: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 6-3: Loss: 0.2394 Acc: 50.0000%\n",
      "\ttrain 6-4: Loss: 0.1469 Acc: 75.0000%\n",
      "\ttrain 6-5: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 6-6: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 6-7: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 6-8: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 6-9: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 6-10: Loss: 0.3228 Acc: 50.0000%\n",
      "\ttrain 6-11: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 6-12: Loss: 0.2026 Acc: 50.0000%\n",
      "\ttrain 6-13: Loss: 0.2387 Acc: 50.0000%\n",
      "\ttrain 6-14: Loss: 0.3051 Acc: 25.0000%\n",
      "\ttrain 6-15: Loss: 0.2071 Acc: 50.0000%\n",
      "\ttrain 6-16: Loss: 0.3271 Acc: 25.0000%\n",
      "\ttrain 6-17: Loss: 0.1460 Acc: 50.0000%\n",
      "\ttrain 6-18: Loss: 0.1441 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-19: Loss: 0.1495 Acc: 50.0000%\n",
      "\ttrain 6-20: Loss: 0.1793 Acc: 25.0000%\n",
      "\ttrain 6-21: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 6-22: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 6-23: Loss: 0.2099 Acc: 50.0000%\n",
      "\ttrain 6-24: Loss: 0.2087 Acc: 75.0000%\n",
      "\ttrain 6-25: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 6-26: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 6-27: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 6-28: Loss: 0.1593 Acc: 50.0000%\n",
      "\ttrain 6-29: Loss: 0.1530 Acc: 50.0000%\n",
      "\ttrain 6-30: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 6-31: Loss: 0.1439 Acc: 50.0000%\n",
      "\ttrain 6-32: Loss: 0.1127 Acc: 100.0000%\n",
      "\ttrain 6-33: Loss: 0.1356 Acc: 75.0000%\n",
      "\ttrain 6-34: Loss: 0.2734 Acc: 50.0000%\n",
      "\ttrain 6-35: Loss: 0.1901 Acc: 75.0000%\n",
      "\ttrain 6-36: Loss: 0.1970 Acc: 50.0000%\n",
      "\ttrain 6-37: Loss: 0.2189 Acc: 50.0000%\n",
      "\ttrain 6-38: Loss: 0.1436 Acc: 75.0000%\n",
      "\ttrain 6-39: Loss: 0.1001 Acc: 75.0000%\n",
      "\ttrain 6-40: Loss: 0.1170 Acc: 75.0000%\n",
      "\ttrain 6-41: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 6-42: Loss: 0.1213 Acc: 50.0000%\n",
      "\ttrain 6-43: Loss: 0.1951 Acc: 75.0000%\n",
      "\ttrain 6-44: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 6-45: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 6-46: Loss: 0.3038 Acc: 25.0000%\n",
      "\ttrain 6-47: Loss: 0.1635 Acc: 50.0000%\n",
      "\ttrain 6-48: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 6-49: Loss: 0.0764 Acc: 100.0000%\n",
      "\ttrain 6-50: Loss: 0.0717 Acc: 100.0000%\n",
      "\ttrain 6-51: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 6-52: Loss: 0.3368 Acc: 25.0000%\n",
      "\ttrain 6-53: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 6-54: Loss: 0.2707 Acc: 75.0000%\n",
      "\ttrain 6-55: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 6-56: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 6-57: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 6-58: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 6-59: Loss: 0.0701 Acc: 100.0000%\n",
      "\ttrain 6-60: Loss: 0.1978 Acc: 50.0000%\n",
      "\ttrain 6-61: Loss: 0.1763 Acc: 50.0000%\n",
      "\ttrain 6-62: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 6-63: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 6-64: Loss: 0.1581 Acc: 50.0000%\n",
      "\ttrain 6-65: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 6-66: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 6-67: Loss: 0.1287 Acc: 100.0000%\n",
      "\ttrain 6-68: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 6-69: Loss: 0.1501 Acc: 50.0000%\n",
      "\ttrain 6-70: Loss: 0.0790 Acc: 75.0000%\n",
      "\ttrain 6-71: Loss: 0.1564 Acc: 50.0000%\n",
      "\ttrain 6-72: Loss: 0.1868 Acc: 25.0000%\n",
      "\ttrain 6-73: Loss: 0.1688 Acc: 75.0000%\n",
      "\ttrain 6-74: Loss: 0.2082 Acc: 25.0000%\n",
      "\ttrain 6-75: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 6-76: Loss: 0.1682 Acc: 50.0000%\n",
      "\ttrain 6-77: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 6-78: Loss: 0.0524 Acc: 75.0000%\n",
      "\ttrain 6-79: Loss: 0.1611 Acc: 75.0000%\n",
      "\ttrain 6-80: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 6-81: Loss: 0.1239 Acc: 75.0000%\n",
      "\ttrain 6-82: Loss: 0.0508 Acc: 75.0000%\n",
      "\ttrain 6-83: Loss: 0.1296 Acc: 50.0000%\n",
      "\ttrain 6-84: Loss: 0.1056 Acc: 50.0000%\n",
      "\ttrain 6-85: Loss: 0.0756 Acc: 75.0000%\n",
      "\ttrain 6-86: Loss: 0.1183 Acc: 50.0000%\n",
      "\ttrain 6-87: Loss: 0.1218 Acc: 75.0000%\n",
      "\ttrain 6-88: Loss: 0.1411 Acc: 50.0000%\n",
      "\ttrain 6-89: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 6-90: Loss: 0.3736 Acc: 50.0000%\n",
      "\ttrain 6-91: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 6-92: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 6-93: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 6-94: Loss: 0.3422 Acc: 75.0000%\n",
      "\ttrain 6-95: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 6-96: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 6-97: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 6-98: Loss: 0.2668 Acc: 75.0000%\n",
      "\ttrain 6-99: Loss: 0.1569 Acc: 50.0000%\n",
      "\ttrain 6-100: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 6-101: Loss: 0.1520 Acc: 50.0000%\n",
      "\ttrain 6-102: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 6-103: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 6-104: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 6-105: Loss: 0.1268 Acc: 75.0000%\n",
      "\ttrain 6-106: Loss: 0.1958 Acc: 50.0000%\n",
      "\ttrain 6-107: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 6-108: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 6-109: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 6-110: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 6-111: Loss: 0.2553 Acc: 50.0000%\n",
      "\ttrain 6-112: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 6-113: Loss: 0.1825 Acc: 75.0000%\n",
      "\ttrain 6-114: Loss: 0.1811 Acc: 50.0000%\n",
      "\ttrain 6-115: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 6-116: Loss: 0.1446 Acc: 50.0000%\n",
      "\ttrain 6-117: Loss: 0.8660 Acc: 25.0000%\n",
      "\ttrain 6-118: Loss: 0.2156 Acc: 75.0000%\n",
      "\ttrain 6-119: Loss: 0.2207 Acc: 50.0000%\n",
      "\ttrain 6-120: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 6-121: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 6-122: Loss: 0.2473 Acc: 50.0000%\n",
      "\ttrain 6-123: Loss: 0.5576 Acc: 25.0000%\n",
      "\ttrain 6-124: Loss: 0.1302 Acc: 75.0000%\n",
      "\ttrain 6-125: Loss: 0.1865 Acc: 75.0000%\n",
      "\ttrain 6-126: Loss: 0.1768 Acc: 25.0000%\n",
      "\ttrain 6-127: Loss: 0.1497 Acc: 75.0000%\n",
      "\ttrain 6-128: Loss: 0.2395 Acc: 50.0000%\n",
      "\ttrain 6-129: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 6-130: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 6-131: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 6-132: Loss: 0.2081 Acc: 75.0000%\n",
      "\ttrain 6-133: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 6-134: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 6-135: Loss: 0.2168 Acc: 25.0000%\n",
      "\ttrain 6-136: Loss: 0.2373 Acc: 50.0000%\n",
      "\ttrain 6-137: Loss: 0.0859 Acc: 100.0000%\n",
      "\ttrain 6-138: Loss: 0.1794 Acc: 50.0000%\n",
      "\ttrain 6-139: Loss: 0.2046 Acc: 50.0000%\n",
      "\ttrain 6-140: Loss: 0.1386 Acc: 75.0000%\n",
      "\ttrain 6-141: Loss: 0.1602 Acc: 50.0000%\n",
      "\ttrain 6-142: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 6-143: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 6-144: Loss: 0.2419 Acc: 50.0000%\n",
      "\ttrain 6-145: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 6-146: Loss: 0.1385 Acc: 100.0000%\n",
      "\ttrain 6-147: Loss: 0.2229 Acc: 25.0000%\n",
      "\ttrain 6-148: Loss: 0.1408 Acc: 75.0000%\n",
      "\ttrain 6-149: Loss: 0.1000 Acc: 100.0000%\n",
      "\ttrain 6-150: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 6-151: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 6-152: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 6-153: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 6-154: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 6-155: Loss: 0.2775 Acc: 25.0000%\n",
      "\ttrain 6-156: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 6-157: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 6-158: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 6-159: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 6-160: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 6-161: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 6-162: Loss: 0.2067 Acc: 25.0000%\n",
      "\ttrain 6-163: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 6-164: Loss: 0.1012 Acc: 50.0000%\n",
      "\ttrain 6-165: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 6-166: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 6-167: Loss: 0.1643 Acc: 75.0000%\n",
      "\ttrain 6-168: Loss: 0.0979 Acc: 100.0000%\n",
      "\ttrain 6-169: Loss: 0.1706 Acc: 50.0000%\n",
      "\ttrain 6-170: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 6-171: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 6-172: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 6-173: Loss: 0.2900 Acc: 25.0000%\n",
      "\ttrain 6-174: Loss: 0.0756 Acc: 75.0000%\n",
      "\ttrain 6-175: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 6-176: Loss: 0.1795 Acc: 75.0000%\n",
      "\ttrain 6-177: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 6-178: Loss: 0.0774 Acc: 100.0000%\n",
      "\ttrain 6-179: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 6-180: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 6-181: Loss: 0.2171 Acc: 75.0000%\n",
      "\ttrain 6-182: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 6-183: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 6-184: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 6-185: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 6-186: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 6-187: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 6-188: Loss: 0.0840 Acc: 75.0000%\n",
      "\ttrain 6-189: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 6-190: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 6-191: Loss: 0.0454 Acc: 75.0000%\n",
      "\ttrain 6-192: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 6-193: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 6-194: Loss: 0.2552 Acc: 50.0000%\n",
      "\ttrain 6-195: Loss: 0.3946 Acc: 50.0000%\n",
      "\ttrain 6-196: Loss: 0.1624 Acc: 50.0000%\n",
      "\ttrain 6-197: Loss: 0.1592 Acc: 50.0000%\n",
      "\ttrain 6-198: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 6-199: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 6-200: Loss: 0.1280 Acc: 75.0000%\n",
      "\ttrain 6-201: Loss: 0.3142 Acc: 75.0000%\n",
      "\ttrain 6-202: Loss: 0.0882 Acc: 75.0000%\n",
      "\ttrain 6-203: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 6-204: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 6-205: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 6-206: Loss: 0.1919 Acc: 50.0000%\n",
      "\ttrain 6-207: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 6-208: Loss: 0.3649 Acc: 50.0000%\n",
      "\ttrain 6-209: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 6-210: Loss: 0.4128 Acc: 0.0000%\n",
      "\ttrain 6-211: Loss: 0.2247 Acc: 50.0000%\n",
      "\ttrain 6-212: Loss: 0.1201 Acc: 50.0000%\n",
      "\ttrain 6-213: Loss: 0.2001 Acc: 50.0000%\n",
      "\ttrain 6-214: Loss: 0.1877 Acc: 50.0000%\n",
      "\ttrain 6-215: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 6-216: Loss: 0.1093 Acc: 100.0000%\n",
      "\ttrain 6-217: Loss: 0.3415 Acc: 25.0000%\n",
      "\ttrain 6-218: Loss: 0.2986 Acc: 25.0000%\n",
      "\ttrain 6-219: Loss: 0.2543 Acc: 50.0000%\n",
      "\ttrain 6-220: Loss: 0.1160 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 6-221: Loss: 0.1034 Acc: 75.0000%\n",
      "\ttrain 6-222: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 6-223: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 6-224: Loss: 0.1889 Acc: 75.0000%\n",
      "\ttrain 6-225: Loss: 0.1324 Acc: 100.0000%\n",
      "\ttrain 6-226: Loss: 0.1251 Acc: 75.0000%\n",
      "\ttrain 6-227: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 6-228: Loss: 0.1609 Acc: 50.0000%\n",
      "\ttrain 6-229: Loss: 0.1529 Acc: 75.0000%\n",
      "\ttrain 6-230: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 6-231: Loss: 0.1227 Acc: 50.0000%\n",
      "\ttrain 6-232: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 6-233: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 6-234: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 6-235: Loss: 0.1674 Acc: 75.0000%\n",
      "\ttrain 6-236: Loss: 0.2603 Acc: 75.0000%\n",
      "\ttrain 6-237: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 6-238: Loss: 0.3529 Acc: 50.0000%\n",
      "\ttrain 6-239: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 6-240: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 6-241: Loss: 0.1501 Acc: 50.0000%\n",
      "\ttrain 6-242: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 6-243: Loss: 0.1750 Acc: 50.0000%\n",
      "\ttrain 6-244: Loss: 0.1479 Acc: 50.0000%\n",
      "\ttrain 6-245: Loss: 0.1116 Acc: 75.0000%\n",
      "\tvalidation 6-1: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 6-2: Loss: 0.0661 Acc: 75.0000%\n",
      "\tvalidation 6-3: Loss: 0.1003 Acc: 75.0000%\n",
      "\tvalidation 6-4: Loss: 0.1680 Acc: 25.0000%\n",
      "\tvalidation 6-5: Loss: 0.1192 Acc: 75.0000%\n",
      "\tvalidation 6-6: Loss: 0.1168 Acc: 75.0000%\n",
      "\tvalidation 6-7: Loss: 0.0845 Acc: 75.0000%\n",
      "\tvalidation 6-8: Loss: 0.0572 Acc: 75.0000%\n",
      "\tvalidation 6-9: Loss: 0.1216 Acc: 75.0000%\n",
      "\tvalidation 6-10: Loss: 0.0696 Acc: 75.0000%\n",
      "\tvalidation 6-11: Loss: 0.3455 Acc: 50.0000%\n",
      "\tvalidation 6-12: Loss: 0.1573 Acc: 50.0000%\n",
      "\tvalidation 6-13: Loss: 0.1437 Acc: 100.0000%\n",
      "\tvalidation 6-14: Loss: 0.1617 Acc: 75.0000%\n",
      "\tvalidation 6-15: Loss: 0.1914 Acc: 75.0000%\n",
      "\tvalidation 6-16: Loss: 0.1867 Acc: 50.0000%\n",
      "\tvalidation 6-17: Loss: 0.1359 Acc: 50.0000%\n",
      "\tvalidation 6-18: Loss: 0.0923 Acc: 75.0000%\n",
      "\tvalidation 6-19: Loss: 0.2632 Acc: 25.0000%\n",
      "\tvalidation 6-20: Loss: 0.1309 Acc: 75.0000%\n",
      "\tvalidation 6-21: Loss: 0.1480 Acc: 75.0000%\n",
      "\tvalidation 6-22: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 6-23: Loss: 0.0858 Acc: 75.0000%\n",
      "\tvalidation 6-24: Loss: 0.0587 Acc: 100.0000%\n",
      "\tvalidation 6-25: Loss: 0.2138 Acc: 25.0000%\n",
      "\tvalidation 6-26: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 6-27: Loss: 0.1087 Acc: 75.0000%\n",
      "\tvalidation 6-28: Loss: 0.4199 Acc: 50.0000%\n",
      "\tvalidation 6-29: Loss: 0.1036 Acc: 100.0000%\n",
      "\tvalidation 6-30: Loss: 0.1803 Acc: 50.0000%\n",
      "\tvalidation 6-31: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 6-32: Loss: 0.0611 Acc: 75.0000%\n",
      "\tvalidation 6-33: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 6-34: Loss: 0.1174 Acc: 50.0000%\n",
      "\tvalidation 6-35: Loss: 0.1869 Acc: 50.0000%\n",
      "\tvalidation 6-36: Loss: 0.1087 Acc: 75.0000%\n",
      "\tvalidation 6-37: Loss: 0.1055 Acc: 75.0000%\n",
      "\tvalidation 6-38: Loss: 0.1571 Acc: 50.0000%\n",
      "\tvalidation 6-39: Loss: 0.0827 Acc: 75.0000%\n",
      "\tvalidation 6-40: Loss: 0.1136 Acc: 50.0000%\n",
      "\tvalidation 6-41: Loss: 0.1437 Acc: 75.0000%\n",
      "\tvalidation 6-42: Loss: 0.0536 Acc: 75.0000%\n",
      "\tvalidation 6-43: Loss: 0.2057 Acc: 50.0000%\n",
      "\tvalidation 6-44: Loss: 0.1823 Acc: 50.0000%\n",
      "\tvalidation 6-45: Loss: 0.4029 Acc: 50.0000%\n",
      "\tvalidation 6-46: Loss: 0.0726 Acc: 100.0000%\n",
      "\tvalidation 6-47: Loss: 0.2424 Acc: 50.0000%\n",
      "\tvalidation 6-48: Loss: 0.1785 Acc: 25.0000%\n",
      "\tvalidation 6-49: Loss: 0.1468 Acc: 50.0000%\n",
      "\tvalidation 6-50: Loss: 0.2749 Acc: 25.0000%\n",
      "\tvalidation 6-51: Loss: 0.0787 Acc: 100.0000%\n",
      "\tvalidation 6-52: Loss: 0.1249 Acc: 75.0000%\n",
      "\tvalidation 6-53: Loss: 0.0636 Acc: 100.0000%\n",
      "\tvalidation 6-54: Loss: 0.1110 Acc: 75.0000%\n",
      "\tvalidation 6-55: Loss: 0.1394 Acc: 50.0000%\n",
      "\tvalidation 6-56: Loss: 0.1363 Acc: 75.0000%\n",
      "\tvalidation 6-57: Loss: 0.1117 Acc: 50.0000%\n",
      "\tvalidation 6-58: Loss: 0.1358 Acc: 75.0000%\n",
      "\tvalidation 6-59: Loss: 0.2327 Acc: 50.0000%\n",
      "\tvalidation 6-60: Loss: 0.1687 Acc: 25.0000%\n",
      "\tvalidation 6-61: Loss: 0.1257 Acc: 75.0000%\n",
      "\tvalidation 6-62: Loss: 0.1218 Acc: 75.0000%\n",
      "\tvalidation 6-63: Loss: 0.2538 Acc: 25.0000%\n",
      "\tvalidation 6-64: Loss: 0.0998 Acc: 100.0000%\n",
      "\tvalidation 6-65: Loss: 0.0740 Acc: 75.0000%\n",
      "\tvalidation 6-66: Loss: 0.1935 Acc: 25.0000%\n",
      "\tvalidation 6-67: Loss: 0.0789 Acc: 75.0000%\n",
      "\tvalidation 6-68: Loss: 0.1605 Acc: 75.0000%\n",
      "\tvalidation 6-69: Loss: 0.1402 Acc: 50.0000%\n",
      "\tvalidation 6-70: Loss: 0.0811 Acc: 100.0000%\n",
      "\tvalidation 6-71: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 6-72: Loss: 0.1471 Acc: 75.0000%\n",
      "\tvalidation 6-73: Loss: 0.1461 Acc: 50.0000%\n",
      "\tvalidation 6-74: Loss: 0.2327 Acc: 25.0000%\n",
      "\tvalidation 6-75: Loss: 0.0664 Acc: 75.0000%\n",
      "\tvalidation 6-76: Loss: 0.2333 Acc: 50.0000%\n",
      "\tvalidation 6-77: Loss: 0.3124 Acc: 50.0000%\n",
      "\tvalidation 6-78: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 6-79: Loss: 0.1160 Acc: 75.0000%\n",
      "\tvalidation 6-80: Loss: 0.2936 Acc: 50.0000%\n",
      "\tvalidation 6-81: Loss: 0.1529 Acc: 50.0000%\n",
      "\tvalidation 6-82: Loss: 0.3174 Acc: 50.0000%\n",
      "\tvalidation 6-83: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 6-84: Loss: 0.1201 Acc: 75.0000%\n",
      "\tvalidation 6-85: Loss: 0.1901 Acc: 75.0000%\n",
      "\tvalidation 6-86: Loss: 0.0947 Acc: 75.0000%\n",
      "\tvalidation 6-87: Loss: 0.1001 Acc: 100.0000%\n",
      "\tvalidation 6-88: Loss: 0.1101 Acc: 50.0000%\n",
      "\tvalidation 6-89: Loss: 0.1042 Acc: 75.0000%\n",
      "\tvalidation 6-90: Loss: 0.1372 Acc: 50.0000%\n",
      "\tvalidation 6-91: Loss: 0.0978 Acc: 75.0000%\n",
      "\tvalidation 6-92: Loss: 0.1344 Acc: 75.0000%\n",
      "\tvalidation 6-93: Loss: 0.1335 Acc: 50.0000%\n",
      "\tvalidation 6-94: Loss: 0.0565 Acc: 100.0000%\n",
      "\tvalidation 6-95: Loss: 0.1523 Acc: 50.0000%\n",
      "\tvalidation 6-96: Loss: 0.1011 Acc: 50.0000%\n",
      "\tvalidation 6-97: Loss: 0.2330 Acc: 50.0000%\n",
      "\tvalidation 6-98: Loss: 0.0567 Acc: 100.0000%\n",
      "\tvalidation 6-99: Loss: 0.1387 Acc: 75.0000%\n",
      "\tvalidation 6-100: Loss: 0.1173 Acc: 50.0000%\n",
      "\tvalidation 6-101: Loss: 0.1743 Acc: 50.0000%\n",
      "\tvalidation 6-102: Loss: 0.1713 Acc: 50.0000%\n",
      "\tvalidation 6-103: Loss: 0.1235 Acc: 75.0000%\n",
      "\tvalidation 6-104: Loss: 0.1093 Acc: 50.0000%\n",
      "\tvalidation 6-105: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1446 Acc: 69.4898%\n",
      "\tvalidation Loss: 0.1406 Acc: 65.9524%\n",
      "Time passed 0h 3m 60s\n",
      "--------------------\n",
      "Epoch [7/40]:\n",
      "\ttrain 7-1: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 7-2: Loss: 0.1188 Acc: 75.0000%\n",
      "\ttrain 7-3: Loss: 0.1055 Acc: 100.0000%\n",
      "\ttrain 7-4: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 7-5: Loss: 0.2613 Acc: 50.0000%\n",
      "\ttrain 7-6: Loss: 0.1186 Acc: 50.0000%\n",
      "\ttrain 7-7: Loss: 0.0755 Acc: 100.0000%\n",
      "\ttrain 7-8: Loss: 0.2331 Acc: 25.0000%\n",
      "\ttrain 7-9: Loss: 0.1316 Acc: 50.0000%\n",
      "\ttrain 7-10: Loss: 0.1435 Acc: 75.0000%\n",
      "\ttrain 7-11: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 7-12: Loss: 0.1770 Acc: 25.0000%\n",
      "\ttrain 7-13: Loss: 0.1556 Acc: 100.0000%\n",
      "\ttrain 7-14: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 7-15: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 7-16: Loss: 0.1421 Acc: 75.0000%\n",
      "\ttrain 7-17: Loss: 0.1959 Acc: 75.0000%\n",
      "\ttrain 7-18: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 7-19: Loss: 0.1518 Acc: 50.0000%\n",
      "\ttrain 7-20: Loss: 0.0690 Acc: 100.0000%\n",
      "\ttrain 7-21: Loss: 0.1779 Acc: 50.0000%\n",
      "\ttrain 7-22: Loss: 0.2300 Acc: 25.0000%\n",
      "\ttrain 7-23: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 7-24: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 7-25: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 7-26: Loss: 0.1315 Acc: 50.0000%\n",
      "\ttrain 7-27: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 7-28: Loss: 0.1352 Acc: 100.0000%\n",
      "\ttrain 7-29: Loss: 0.1341 Acc: 50.0000%\n",
      "\ttrain 7-30: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 7-31: Loss: 0.1795 Acc: 50.0000%\n",
      "\ttrain 7-32: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 7-33: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 7-34: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 7-35: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 7-36: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 7-37: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 7-38: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 7-39: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 7-40: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 7-41: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 7-42: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 7-43: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 7-44: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 7-45: Loss: 0.1264 Acc: 50.0000%\n",
      "\ttrain 7-46: Loss: 0.1694 Acc: 50.0000%\n",
      "\ttrain 7-47: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 7-48: Loss: 0.1651 Acc: 50.0000%\n",
      "\ttrain 7-49: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 7-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 7-51: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 7-52: Loss: 0.1863 Acc: 50.0000%\n",
      "\ttrain 7-53: Loss: 0.0832 Acc: 100.0000%\n",
      "\ttrain 7-54: Loss: 0.1054 Acc: 50.0000%\n",
      "\ttrain 7-55: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 7-56: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 7-57: Loss: 0.1581 Acc: 25.0000%\n",
      "\ttrain 7-58: Loss: 0.1089 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 7-59: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 7-60: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 7-61: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 7-62: Loss: 0.1074 Acc: 75.0000%\n",
      "\ttrain 7-63: Loss: 0.0785 Acc: 75.0000%\n",
      "\ttrain 7-64: Loss: 0.0810 Acc: 75.0000%\n",
      "\ttrain 7-65: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 7-66: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 7-67: Loss: 0.0832 Acc: 75.0000%\n",
      "\ttrain 7-68: Loss: 0.1904 Acc: 75.0000%\n",
      "\ttrain 7-69: Loss: 0.1862 Acc: 50.0000%\n",
      "\ttrain 7-70: Loss: 0.1126 Acc: 75.0000%\n",
      "\ttrain 7-71: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 7-72: Loss: 0.2044 Acc: 50.0000%\n",
      "\ttrain 7-73: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 7-74: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 7-75: Loss: 0.1757 Acc: 50.0000%\n",
      "\ttrain 7-76: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 7-77: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 7-78: Loss: 0.1808 Acc: 50.0000%\n",
      "\ttrain 7-79: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 7-80: Loss: 0.0701 Acc: 100.0000%\n",
      "\ttrain 7-81: Loss: 0.1435 Acc: 100.0000%\n",
      "\ttrain 7-82: Loss: 0.0911 Acc: 100.0000%\n",
      "\ttrain 7-83: Loss: 0.0673 Acc: 75.0000%\n",
      "\ttrain 7-84: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 7-85: Loss: 0.2092 Acc: 50.0000%\n",
      "\ttrain 7-86: Loss: 0.1407 Acc: 50.0000%\n",
      "\ttrain 7-87: Loss: 0.1641 Acc: 75.0000%\n",
      "\ttrain 7-88: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 7-89: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 7-90: Loss: 0.1498 Acc: 50.0000%\n",
      "\ttrain 7-91: Loss: 0.1423 Acc: 50.0000%\n",
      "\ttrain 7-92: Loss: 0.0809 Acc: 100.0000%\n",
      "\ttrain 7-93: Loss: 0.2049 Acc: 50.0000%\n",
      "\ttrain 7-94: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 7-95: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 7-96: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 7-97: Loss: 0.1330 Acc: 50.0000%\n",
      "\ttrain 7-98: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 7-99: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 7-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 7-101: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 7-102: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 7-103: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 7-104: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 7-105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 7-106: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 7-107: Loss: 0.1463 Acc: 50.0000%\n",
      "\ttrain 7-108: Loss: 0.1389 Acc: 50.0000%\n",
      "\ttrain 7-109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 7-110: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 7-111: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 7-112: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 7-113: Loss: 0.1013 Acc: 50.0000%\n",
      "\ttrain 7-114: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 7-115: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 7-116: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 7-117: Loss: 0.0829 Acc: 100.0000%\n",
      "\ttrain 7-118: Loss: 0.1238 Acc: 50.0000%\n",
      "\ttrain 7-119: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 7-120: Loss: 0.1962 Acc: 25.0000%\n",
      "\ttrain 7-121: Loss: 0.2492 Acc: 0.0000%\n",
      "\ttrain 7-122: Loss: 0.1760 Acc: 50.0000%\n",
      "\ttrain 7-123: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 7-124: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 7-125: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 7-126: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 7-127: Loss: 0.0706 Acc: 100.0000%\n",
      "\ttrain 7-128: Loss: 0.1796 Acc: 75.0000%\n",
      "\ttrain 7-129: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 7-130: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 7-131: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 7-132: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 7-133: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 7-134: Loss: 0.1838 Acc: 50.0000%\n",
      "\ttrain 7-135: Loss: 0.1101 Acc: 75.0000%\n",
      "\ttrain 7-136: Loss: 0.2423 Acc: 75.0000%\n",
      "\ttrain 7-137: Loss: 0.1485 Acc: 50.0000%\n",
      "\ttrain 7-138: Loss: 0.1928 Acc: 50.0000%\n",
      "\ttrain 7-139: Loss: 0.2732 Acc: 50.0000%\n",
      "\ttrain 7-140: Loss: 0.2582 Acc: 50.0000%\n",
      "\ttrain 7-141: Loss: 0.3159 Acc: 0.0000%\n",
      "\ttrain 7-142: Loss: 0.1172 Acc: 75.0000%\n",
      "\ttrain 7-143: Loss: 1.0614 Acc: 25.0000%\n",
      "\ttrain 7-144: Loss: 0.2528 Acc: 50.0000%\n",
      "\ttrain 7-145: Loss: 0.1204 Acc: 50.0000%\n",
      "\ttrain 7-146: Loss: 0.0997 Acc: 100.0000%\n",
      "\ttrain 7-147: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 7-148: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 7-149: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 7-150: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 7-151: Loss: 0.2996 Acc: 75.0000%\n",
      "\ttrain 7-152: Loss: 0.2921 Acc: 75.0000%\n",
      "\ttrain 7-153: Loss: 0.2550 Acc: 75.0000%\n",
      "\ttrain 7-154: Loss: 0.2830 Acc: 75.0000%\n",
      "\ttrain 7-155: Loss: 0.1538 Acc: 100.0000%\n",
      "\ttrain 7-156: Loss: 0.2681 Acc: 25.0000%\n",
      "\ttrain 7-157: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 7-158: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 7-159: Loss: 0.1453 Acc: 50.0000%\n",
      "\ttrain 7-160: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 7-161: Loss: 0.1467 Acc: 75.0000%\n",
      "\ttrain 7-162: Loss: 0.2336 Acc: 50.0000%\n",
      "\ttrain 7-163: Loss: 0.1474 Acc: 75.0000%\n",
      "\ttrain 7-164: Loss: 0.3335 Acc: 50.0000%\n",
      "\ttrain 7-165: Loss: 0.1514 Acc: 50.0000%\n",
      "\ttrain 7-166: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 7-167: Loss: 0.1825 Acc: 75.0000%\n",
      "\ttrain 7-168: Loss: 0.1196 Acc: 100.0000%\n",
      "\ttrain 7-169: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 7-170: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 7-171: Loss: 0.1418 Acc: 75.0000%\n",
      "\ttrain 7-172: Loss: 0.2520 Acc: 25.0000%\n",
      "\ttrain 7-173: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 7-174: Loss: 0.1364 Acc: 50.0000%\n",
      "\ttrain 7-175: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 7-176: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 7-177: Loss: 0.1404 Acc: 50.0000%\n",
      "\ttrain 7-178: Loss: 0.2469 Acc: 25.0000%\n",
      "\ttrain 7-179: Loss: 0.1346 Acc: 50.0000%\n",
      "\ttrain 7-180: Loss: 0.2791 Acc: 50.0000%\n",
      "\ttrain 7-181: Loss: 0.0563 Acc: 75.0000%\n",
      "\ttrain 7-182: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 7-183: Loss: 0.1178 Acc: 100.0000%\n",
      "\ttrain 7-184: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 7-185: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 7-186: Loss: 0.1635 Acc: 25.0000%\n",
      "\ttrain 7-187: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 7-188: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 7-189: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 7-190: Loss: 0.2609 Acc: 25.0000%\n",
      "\ttrain 7-191: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 7-192: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 7-193: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 7-194: Loss: 0.1388 Acc: 75.0000%\n",
      "\ttrain 7-195: Loss: 0.1043 Acc: 100.0000%\n",
      "\ttrain 7-196: Loss: 0.3617 Acc: 25.0000%\n",
      "\ttrain 7-197: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 7-198: Loss: 0.1301 Acc: 75.0000%\n",
      "\ttrain 7-199: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 7-200: Loss: 0.1217 Acc: 100.0000%\n",
      "\ttrain 7-201: Loss: 0.1821 Acc: 75.0000%\n",
      "\ttrain 7-202: Loss: 0.1773 Acc: 50.0000%\n",
      "\ttrain 7-203: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 7-204: Loss: 0.1801 Acc: 50.0000%\n",
      "\ttrain 7-205: Loss: 0.1164 Acc: 75.0000%\n",
      "\ttrain 7-206: Loss: 0.0874 Acc: 75.0000%\n",
      "\ttrain 7-207: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 7-208: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 7-209: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 7-210: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 7-211: Loss: 0.1868 Acc: 50.0000%\n",
      "\ttrain 7-212: Loss: 0.2190 Acc: 50.0000%\n",
      "\ttrain 7-213: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 7-214: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 7-215: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 7-216: Loss: 0.1494 Acc: 25.0000%\n",
      "\ttrain 7-217: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 7-218: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 7-219: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 7-220: Loss: 0.2574 Acc: 50.0000%\n",
      "\ttrain 7-221: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 7-222: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 7-223: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 7-224: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 7-225: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 7-226: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 7-227: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 7-228: Loss: 0.2731 Acc: 50.0000%\n",
      "\ttrain 7-229: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 7-230: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 7-231: Loss: 0.1667 Acc: 50.0000%\n",
      "\ttrain 7-232: Loss: 0.1821 Acc: 25.0000%\n",
      "\ttrain 7-233: Loss: 0.1751 Acc: 50.0000%\n",
      "\ttrain 7-234: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 7-235: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 7-236: Loss: 0.0854 Acc: 100.0000%\n",
      "\ttrain 7-237: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 7-238: Loss: 0.0797 Acc: 100.0000%\n",
      "\ttrain 7-239: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 7-240: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 7-241: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 7-242: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 7-243: Loss: 0.1068 Acc: 100.0000%\n",
      "\ttrain 7-244: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 7-245: Loss: 0.1574 Acc: 50.0000%\n",
      "\tvalidation 7-1: Loss: 0.1291 Acc: 75.0000%\n",
      "\tvalidation 7-2: Loss: 0.1367 Acc: 75.0000%\n",
      "\tvalidation 7-3: Loss: 0.0504 Acc: 75.0000%\n",
      "\tvalidation 7-4: Loss: 0.0976 Acc: 100.0000%\n",
      "\tvalidation 7-5: Loss: 0.1043 Acc: 50.0000%\n",
      "\tvalidation 7-6: Loss: 0.1380 Acc: 50.0000%\n",
      "\tvalidation 7-7: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 7-8: Loss: 0.0510 Acc: 75.0000%\n",
      "\tvalidation 7-9: Loss: 0.1704 Acc: 75.0000%\n",
      "\tvalidation 7-10: Loss: 0.0455 Acc: 100.0000%\n",
      "\tvalidation 7-11: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 7-12: Loss: 0.0523 Acc: 75.0000%\n",
      "\tvalidation 7-13: Loss: 0.0890 Acc: 75.0000%\n",
      "\tvalidation 7-14: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 7-15: Loss: 0.0431 Acc: 100.0000%\n",
      "\tvalidation 7-16: Loss: 0.1408 Acc: 50.0000%\n",
      "\tvalidation 7-17: Loss: 0.1353 Acc: 75.0000%\n",
      "\tvalidation 7-18: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 7-19: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 7-20: Loss: 0.0921 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 7-21: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 7-22: Loss: 0.1838 Acc: 50.0000%\n",
      "\tvalidation 7-23: Loss: 0.1890 Acc: 25.0000%\n",
      "\tvalidation 7-24: Loss: 0.0401 Acc: 100.0000%\n",
      "\tvalidation 7-25: Loss: 0.1689 Acc: 75.0000%\n",
      "\tvalidation 7-26: Loss: 0.0450 Acc: 100.0000%\n",
      "\tvalidation 7-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 7-28: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 7-29: Loss: 0.1277 Acc: 75.0000%\n",
      "\tvalidation 7-30: Loss: 0.0938 Acc: 100.0000%\n",
      "\tvalidation 7-31: Loss: 0.2719 Acc: 75.0000%\n",
      "\tvalidation 7-32: Loss: 0.0955 Acc: 75.0000%\n",
      "\tvalidation 7-33: Loss: 0.2776 Acc: 75.0000%\n",
      "\tvalidation 7-34: Loss: 0.0752 Acc: 100.0000%\n",
      "\tvalidation 7-35: Loss: 0.1354 Acc: 75.0000%\n",
      "\tvalidation 7-36: Loss: 0.1394 Acc: 50.0000%\n",
      "\tvalidation 7-37: Loss: 0.1014 Acc: 50.0000%\n",
      "\tvalidation 7-38: Loss: 0.0976 Acc: 75.0000%\n",
      "\tvalidation 7-39: Loss: 0.1299 Acc: 75.0000%\n",
      "\tvalidation 7-40: Loss: 0.1559 Acc: 100.0000%\n",
      "\tvalidation 7-41: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 7-42: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 7-43: Loss: 0.1530 Acc: 25.0000%\n",
      "\tvalidation 7-44: Loss: 0.0967 Acc: 50.0000%\n",
      "\tvalidation 7-45: Loss: 0.0490 Acc: 75.0000%\n",
      "\tvalidation 7-46: Loss: 0.0862 Acc: 75.0000%\n",
      "\tvalidation 7-47: Loss: 0.0500 Acc: 75.0000%\n",
      "\tvalidation 7-48: Loss: 0.0943 Acc: 75.0000%\n",
      "\tvalidation 7-49: Loss: 0.1296 Acc: 100.0000%\n",
      "\tvalidation 7-50: Loss: 0.0909 Acc: 75.0000%\n",
      "\tvalidation 7-51: Loss: 0.1577 Acc: 25.0000%\n",
      "\tvalidation 7-52: Loss: 0.1254 Acc: 75.0000%\n",
      "\tvalidation 7-53: Loss: 0.0935 Acc: 75.0000%\n",
      "\tvalidation 7-54: Loss: 0.0916 Acc: 75.0000%\n",
      "\tvalidation 7-55: Loss: 0.0776 Acc: 100.0000%\n",
      "\tvalidation 7-56: Loss: 0.1809 Acc: 50.0000%\n",
      "\tvalidation 7-57: Loss: 0.1449 Acc: 50.0000%\n",
      "\tvalidation 7-58: Loss: 0.1599 Acc: 75.0000%\n",
      "\tvalidation 7-59: Loss: 0.0521 Acc: 75.0000%\n",
      "\tvalidation 7-60: Loss: 0.1507 Acc: 25.0000%\n",
      "\tvalidation 7-61: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 7-62: Loss: 0.1282 Acc: 75.0000%\n",
      "\tvalidation 7-63: Loss: 0.1385 Acc: 50.0000%\n",
      "\tvalidation 7-64: Loss: 0.0405 Acc: 100.0000%\n",
      "\tvalidation 7-65: Loss: 0.1563 Acc: 25.0000%\n",
      "\tvalidation 7-66: Loss: 0.1001 Acc: 75.0000%\n",
      "\tvalidation 7-67: Loss: 0.0940 Acc: 75.0000%\n",
      "\tvalidation 7-68: Loss: 0.1048 Acc: 50.0000%\n",
      "\tvalidation 7-69: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 7-70: Loss: 0.0865 Acc: 75.0000%\n",
      "\tvalidation 7-71: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 7-72: Loss: 0.0510 Acc: 75.0000%\n",
      "\tvalidation 7-73: Loss: 0.0753 Acc: 100.0000%\n",
      "\tvalidation 7-74: Loss: 0.1262 Acc: 75.0000%\n",
      "\tvalidation 7-75: Loss: 0.0498 Acc: 75.0000%\n",
      "\tvalidation 7-76: Loss: 0.1127 Acc: 75.0000%\n",
      "\tvalidation 7-77: Loss: 0.0383 Acc: 100.0000%\n",
      "\tvalidation 7-78: Loss: 0.0449 Acc: 100.0000%\n",
      "\tvalidation 7-79: Loss: 0.1271 Acc: 75.0000%\n",
      "\tvalidation 7-80: Loss: 0.1784 Acc: 50.0000%\n",
      "\tvalidation 7-81: Loss: 0.1894 Acc: 25.0000%\n",
      "\tvalidation 7-82: Loss: 0.0495 Acc: 75.0000%\n",
      "\tvalidation 7-83: Loss: 0.1359 Acc: 75.0000%\n",
      "\tvalidation 7-84: Loss: 0.1118 Acc: 50.0000%\n",
      "\tvalidation 7-85: Loss: 0.2163 Acc: 75.0000%\n",
      "\tvalidation 7-86: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 7-87: Loss: 0.0573 Acc: 100.0000%\n",
      "\tvalidation 7-88: Loss: 0.1454 Acc: 50.0000%\n",
      "\tvalidation 7-89: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 7-90: Loss: 0.1806 Acc: 50.0000%\n",
      "\tvalidation 7-91: Loss: 0.0550 Acc: 75.0000%\n",
      "\tvalidation 7-92: Loss: 0.0542 Acc: 75.0000%\n",
      "\tvalidation 7-93: Loss: 0.1262 Acc: 75.0000%\n",
      "\tvalidation 7-94: Loss: 0.4143 Acc: 50.0000%\n",
      "\tvalidation 7-95: Loss: 0.1789 Acc: 25.0000%\n",
      "\tvalidation 7-96: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 7-97: Loss: 0.1423 Acc: 50.0000%\n",
      "\tvalidation 7-98: Loss: 0.0725 Acc: 100.0000%\n",
      "\tvalidation 7-99: Loss: 0.0846 Acc: 75.0000%\n",
      "\tvalidation 7-100: Loss: 0.0531 Acc: 75.0000%\n",
      "\tvalidation 7-101: Loss: 0.0897 Acc: 75.0000%\n",
      "\tvalidation 7-102: Loss: 0.1035 Acc: 50.0000%\n",
      "\tvalidation 7-103: Loss: 0.1540 Acc: 25.0000%\n",
      "\tvalidation 7-104: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 7-105: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1261 Acc: 72.9592%\n",
      "\tvalidation Loss: 0.1009 Acc: 74.5238%\n",
      "网络参数更新\n",
      "Time passed 0h 4m 43s\n",
      "--------------------\n",
      "Epoch [8/40]:\n",
      "\ttrain 8-1: Loss: 0.0979 Acc: 100.0000%\n",
      "\ttrain 8-2: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 8-3: Loss: 0.1550 Acc: 100.0000%\n",
      "\ttrain 8-4: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 8-5: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 8-6: Loss: 0.1427 Acc: 50.0000%\n",
      "\ttrain 8-7: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 8-8: Loss: 0.1861 Acc: 75.0000%\n",
      "\ttrain 8-9: Loss: 0.1798 Acc: 25.0000%\n",
      "\ttrain 8-10: Loss: 0.1201 Acc: 75.0000%\n",
      "\ttrain 8-11: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 8-12: Loss: 0.0805 Acc: 75.0000%\n",
      "\ttrain 8-13: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 8-14: Loss: 0.1169 Acc: 50.0000%\n",
      "\ttrain 8-15: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 8-16: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 8-17: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 8-18: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 8-19: Loss: 0.1873 Acc: 75.0000%\n",
      "\ttrain 8-20: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 8-21: Loss: 0.1386 Acc: 50.0000%\n",
      "\ttrain 8-22: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 8-23: Loss: 0.1853 Acc: 25.0000%\n",
      "\ttrain 8-24: Loss: 0.1323 Acc: 50.0000%\n",
      "\ttrain 8-25: Loss: 0.1500 Acc: 75.0000%\n",
      "\ttrain 8-26: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 8-27: Loss: 0.1617 Acc: 50.0000%\n",
      "\ttrain 8-28: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 8-29: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 8-30: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 8-31: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 8-32: Loss: 0.1775 Acc: 25.0000%\n",
      "\ttrain 8-33: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 8-34: Loss: 0.1629 Acc: 50.0000%\n",
      "\ttrain 8-35: Loss: 0.1662 Acc: 50.0000%\n",
      "\ttrain 8-36: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 8-37: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 8-38: Loss: 0.0791 Acc: 100.0000%\n",
      "\ttrain 8-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 8-40: Loss: 0.1022 Acc: 75.0000%\n",
      "\ttrain 8-41: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 8-42: Loss: 0.1354 Acc: 50.0000%\n",
      "\ttrain 8-43: Loss: 0.1137 Acc: 100.0000%\n",
      "\ttrain 8-44: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 8-45: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 8-46: Loss: 0.3286 Acc: 75.0000%\n",
      "\ttrain 8-47: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 8-48: Loss: 0.1177 Acc: 50.0000%\n",
      "\ttrain 8-49: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 8-50: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 8-51: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 8-52: Loss: 0.0558 Acc: 75.0000%\n",
      "\ttrain 8-53: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 8-54: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 8-55: Loss: 0.1857 Acc: 0.0000%\n",
      "\ttrain 8-56: Loss: 0.1415 Acc: 50.0000%\n",
      "\ttrain 8-57: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 8-58: Loss: 0.0707 Acc: 100.0000%\n",
      "\ttrain 8-59: Loss: 0.1692 Acc: 75.0000%\n",
      "\ttrain 8-60: Loss: 0.1510 Acc: 50.0000%\n",
      "\ttrain 8-61: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 8-62: Loss: 0.1726 Acc: 25.0000%\n",
      "\ttrain 8-63: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 8-64: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 8-65: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 8-66: Loss: 0.1174 Acc: 100.0000%\n",
      "\ttrain 8-67: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 8-68: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 8-69: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 8-70: Loss: 0.1068 Acc: 100.0000%\n",
      "\ttrain 8-71: Loss: 0.2074 Acc: 50.0000%\n",
      "\ttrain 8-72: Loss: 0.1039 Acc: 50.0000%\n",
      "\ttrain 8-73: Loss: 0.0565 Acc: 75.0000%\n",
      "\ttrain 8-74: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 8-75: Loss: 0.0907 Acc: 75.0000%\n",
      "\ttrain 8-76: Loss: 0.1483 Acc: 50.0000%\n",
      "\ttrain 8-77: Loss: 0.1472 Acc: 50.0000%\n",
      "\ttrain 8-78: Loss: 0.1046 Acc: 50.0000%\n",
      "\ttrain 8-79: Loss: 0.0796 Acc: 75.0000%\n",
      "\ttrain 8-80: Loss: 0.1398 Acc: 75.0000%\n",
      "\ttrain 8-81: Loss: 0.3872 Acc: 25.0000%\n",
      "\ttrain 8-82: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 8-83: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 8-84: Loss: 0.0907 Acc: 100.0000%\n",
      "\ttrain 8-85: Loss: 0.1668 Acc: 50.0000%\n",
      "\ttrain 8-86: Loss: 0.1992 Acc: 50.0000%\n",
      "\ttrain 8-87: Loss: 0.1515 Acc: 50.0000%\n",
      "\ttrain 8-88: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 8-89: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 8-90: Loss: 0.3590 Acc: 25.0000%\n",
      "\ttrain 8-91: Loss: 0.1869 Acc: 25.0000%\n",
      "\ttrain 8-92: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 8-93: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 8-94: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 8-95: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 8-96: Loss: 0.2189 Acc: 75.0000%\n",
      "\ttrain 8-97: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 8-98: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 8-99: Loss: 0.1172 Acc: 100.0000%\n",
      "\ttrain 8-100: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 8-101: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 8-102: Loss: 0.1052 Acc: 75.0000%\n",
      "\ttrain 8-103: Loss: 0.0472 Acc: 75.0000%\n",
      "\ttrain 8-104: Loss: 0.4138 Acc: 50.0000%\n",
      "\ttrain 8-105: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 8-106: Loss: 0.0768 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 8-107: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 8-108: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 8-109: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 8-110: Loss: 0.1476 Acc: 50.0000%\n",
      "\ttrain 8-111: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 8-112: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 8-113: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 8-114: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 8-115: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 8-116: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 8-117: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 8-118: Loss: 0.2428 Acc: 25.0000%\n",
      "\ttrain 8-119: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 8-120: Loss: 0.1218 Acc: 50.0000%\n",
      "\ttrain 8-121: Loss: 0.1625 Acc: 50.0000%\n",
      "\ttrain 8-122: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 8-123: Loss: 0.1581 Acc: 50.0000%\n",
      "\ttrain 8-124: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 8-125: Loss: 0.2266 Acc: 0.0000%\n",
      "\ttrain 8-126: Loss: 0.1233 Acc: 75.0000%\n",
      "\ttrain 8-127: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 8-128: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 8-129: Loss: 0.0498 Acc: 75.0000%\n",
      "\ttrain 8-130: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 8-131: Loss: 0.0798 Acc: 100.0000%\n",
      "\ttrain 8-132: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 8-133: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 8-134: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 8-135: Loss: 0.1226 Acc: 50.0000%\n",
      "\ttrain 8-136: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 8-137: Loss: 0.2456 Acc: 50.0000%\n",
      "\ttrain 8-138: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 8-139: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 8-140: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 8-141: Loss: 0.0964 Acc: 50.0000%\n",
      "\ttrain 8-142: Loss: 0.0930 Acc: 75.0000%\n",
      "\ttrain 8-143: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 8-144: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 8-145: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 8-146: Loss: 0.1738 Acc: 50.0000%\n",
      "\ttrain 8-147: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 8-148: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 8-149: Loss: 0.1848 Acc: 50.0000%\n",
      "\ttrain 8-150: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 8-151: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 8-152: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 8-153: Loss: 0.1588 Acc: 50.0000%\n",
      "\ttrain 8-154: Loss: 0.0453 Acc: 75.0000%\n",
      "\ttrain 8-155: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 8-156: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 8-157: Loss: 0.1476 Acc: 50.0000%\n",
      "\ttrain 8-158: Loss: 0.0975 Acc: 100.0000%\n",
      "\ttrain 8-159: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 8-160: Loss: 0.0915 Acc: 100.0000%\n",
      "\ttrain 8-161: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 8-162: Loss: 0.1632 Acc: 25.0000%\n",
      "\ttrain 8-163: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 8-164: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 8-165: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 8-166: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 8-167: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 8-168: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 8-169: Loss: 0.2613 Acc: 25.0000%\n",
      "\ttrain 8-170: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 8-171: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 8-172: Loss: 0.0573 Acc: 75.0000%\n",
      "\ttrain 8-173: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 8-174: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 8-175: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 8-176: Loss: 0.0603 Acc: 75.0000%\n",
      "\ttrain 8-177: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 8-178: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 8-179: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 8-180: Loss: 0.1442 Acc: 50.0000%\n",
      "\ttrain 8-181: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 8-182: Loss: 0.2326 Acc: 0.0000%\n",
      "\ttrain 8-183: Loss: 0.0592 Acc: 75.0000%\n",
      "\ttrain 8-184: Loss: 0.0444 Acc: 75.0000%\n",
      "\ttrain 8-185: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 8-186: Loss: 0.2093 Acc: 75.0000%\n",
      "\ttrain 8-187: Loss: 0.1975 Acc: 75.0000%\n",
      "\ttrain 8-188: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 8-189: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 8-190: Loss: 0.1633 Acc: 50.0000%\n",
      "\ttrain 8-191: Loss: 0.1554 Acc: 75.0000%\n",
      "\ttrain 8-192: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 8-193: Loss: 0.2074 Acc: 50.0000%\n",
      "\ttrain 8-194: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 8-195: Loss: 0.3006 Acc: 50.0000%\n",
      "\ttrain 8-196: Loss: 0.1993 Acc: 50.0000%\n",
      "\ttrain 8-197: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 8-198: Loss: 0.2350 Acc: 50.0000%\n",
      "\ttrain 8-199: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 8-200: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 8-201: Loss: 0.0718 Acc: 100.0000%\n",
      "\ttrain 8-202: Loss: 0.3276 Acc: 50.0000%\n",
      "\ttrain 8-203: Loss: 0.1363 Acc: 50.0000%\n",
      "\ttrain 8-204: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 8-205: Loss: 0.1753 Acc: 50.0000%\n",
      "\ttrain 8-206: Loss: 0.1654 Acc: 75.0000%\n",
      "\ttrain 8-207: Loss: 0.1386 Acc: 50.0000%\n",
      "\ttrain 8-208: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 8-209: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 8-210: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 8-211: Loss: 0.1392 Acc: 50.0000%\n",
      "\ttrain 8-212: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 8-213: Loss: 0.1688 Acc: 75.0000%\n",
      "\ttrain 8-214: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 8-215: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 8-216: Loss: 0.1918 Acc: 75.0000%\n",
      "\ttrain 8-217: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 8-218: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 8-219: Loss: 0.1534 Acc: 50.0000%\n",
      "\ttrain 8-220: Loss: 0.1256 Acc: 75.0000%\n",
      "\ttrain 8-221: Loss: 0.1319 Acc: 50.0000%\n",
      "\ttrain 8-222: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 8-223: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 8-224: Loss: 0.1166 Acc: 50.0000%\n",
      "\ttrain 8-225: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 8-226: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 8-227: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 8-228: Loss: 0.1978 Acc: 75.0000%\n",
      "\ttrain 8-229: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 8-230: Loss: 0.2500 Acc: 75.0000%\n",
      "\ttrain 8-231: Loss: 0.1513 Acc: 75.0000%\n",
      "\ttrain 8-232: Loss: 0.0962 Acc: 75.0000%\n",
      "\ttrain 8-233: Loss: 0.0618 Acc: 100.0000%\n",
      "\ttrain 8-234: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 8-235: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 8-236: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 8-237: Loss: 0.1566 Acc: 50.0000%\n",
      "\ttrain 8-238: Loss: 0.1422 Acc: 50.0000%\n",
      "\ttrain 8-239: Loss: 0.2504 Acc: 25.0000%\n",
      "\ttrain 8-240: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 8-241: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 8-242: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 8-243: Loss: 0.1067 Acc: 100.0000%\n",
      "\ttrain 8-244: Loss: 0.6231 Acc: 75.0000%\n",
      "\ttrain 8-245: Loss: 0.3986 Acc: 50.0000%\n",
      "\tvalidation 8-1: Loss: 0.1804 Acc: 75.0000%\n",
      "\tvalidation 8-2: Loss: 0.0398 Acc: 100.0000%\n",
      "\tvalidation 8-3: Loss: 0.0283 Acc: 100.0000%\n",
      "\tvalidation 8-4: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 8-5: Loss: 0.0849 Acc: 100.0000%\n",
      "\tvalidation 8-6: Loss: 0.1384 Acc: 50.0000%\n",
      "\tvalidation 8-7: Loss: 0.1458 Acc: 50.0000%\n",
      "\tvalidation 8-8: Loss: 0.0646 Acc: 75.0000%\n",
      "\tvalidation 8-9: Loss: 0.2761 Acc: 50.0000%\n",
      "\tvalidation 8-10: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 8-11: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 8-12: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 8-13: Loss: 0.1215 Acc: 50.0000%\n",
      "\tvalidation 8-14: Loss: 0.2959 Acc: 50.0000%\n",
      "\tvalidation 8-15: Loss: 0.1981 Acc: 50.0000%\n",
      "\tvalidation 8-16: Loss: 0.1058 Acc: 75.0000%\n",
      "\tvalidation 8-17: Loss: 0.0724 Acc: 75.0000%\n",
      "\tvalidation 8-18: Loss: 0.1525 Acc: 75.0000%\n",
      "\tvalidation 8-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-20: Loss: 0.1929 Acc: 75.0000%\n",
      "\tvalidation 8-21: Loss: 0.0634 Acc: 75.0000%\n",
      "\tvalidation 8-22: Loss: 0.1262 Acc: 75.0000%\n",
      "\tvalidation 8-23: Loss: 0.1768 Acc: 25.0000%\n",
      "\tvalidation 8-24: Loss: 0.0477 Acc: 75.0000%\n",
      "\tvalidation 8-25: Loss: 0.1197 Acc: 75.0000%\n",
      "\tvalidation 8-26: Loss: 0.1073 Acc: 75.0000%\n",
      "\tvalidation 8-27: Loss: 0.1204 Acc: 75.0000%\n",
      "\tvalidation 8-28: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 8-29: Loss: 0.0442 Acc: 75.0000%\n",
      "\tvalidation 8-30: Loss: 0.0712 Acc: 100.0000%\n",
      "\tvalidation 8-31: Loss: 0.1564 Acc: 50.0000%\n",
      "\tvalidation 8-32: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 8-33: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 8-34: Loss: 0.0941 Acc: 75.0000%\n",
      "\tvalidation 8-35: Loss: 0.1376 Acc: 75.0000%\n",
      "\tvalidation 8-36: Loss: 0.0652 Acc: 75.0000%\n",
      "\tvalidation 8-37: Loss: 0.2609 Acc: 50.0000%\n",
      "\tvalidation 8-38: Loss: 0.1399 Acc: 50.0000%\n",
      "\tvalidation 8-39: Loss: 0.2287 Acc: 25.0000%\n",
      "\tvalidation 8-40: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 8-41: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 8-42: Loss: 0.0447 Acc: 75.0000%\n",
      "\tvalidation 8-43: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 8-44: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 8-45: Loss: 0.0481 Acc: 75.0000%\n",
      "\tvalidation 8-46: Loss: 0.1334 Acc: 75.0000%\n",
      "\tvalidation 8-47: Loss: 0.1406 Acc: 50.0000%\n",
      "\tvalidation 8-48: Loss: 0.1124 Acc: 75.0000%\n",
      "\tvalidation 8-49: Loss: 0.1207 Acc: 50.0000%\n",
      "\tvalidation 8-50: Loss: 0.0999 Acc: 75.0000%\n",
      "\tvalidation 8-51: Loss: 0.2506 Acc: 50.0000%\n",
      "\tvalidation 8-52: Loss: 0.0933 Acc: 75.0000%\n",
      "\tvalidation 8-53: Loss: 0.1440 Acc: 50.0000%\n",
      "\tvalidation 8-54: Loss: 0.1608 Acc: 50.0000%\n",
      "\tvalidation 8-55: Loss: 0.1849 Acc: 25.0000%\n",
      "\tvalidation 8-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 8-57: Loss: 0.0521 Acc: 75.0000%\n",
      "\tvalidation 8-58: Loss: 0.0695 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 8-59: Loss: 0.0648 Acc: 75.0000%\n",
      "\tvalidation 8-60: Loss: 0.1554 Acc: 50.0000%\n",
      "\tvalidation 8-61: Loss: 0.0455 Acc: 75.0000%\n",
      "\tvalidation 8-62: Loss: 0.1278 Acc: 50.0000%\n",
      "\tvalidation 8-63: Loss: 0.0547 Acc: 75.0000%\n",
      "\tvalidation 8-64: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 8-65: Loss: 0.1602 Acc: 50.0000%\n",
      "\tvalidation 8-66: Loss: 0.2160 Acc: 50.0000%\n",
      "\tvalidation 8-67: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 8-68: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 8-69: Loss: 0.1139 Acc: 75.0000%\n",
      "\tvalidation 8-70: Loss: 0.0679 Acc: 75.0000%\n",
      "\tvalidation 8-71: Loss: 0.0303 Acc: 100.0000%\n",
      "\tvalidation 8-72: Loss: 0.1147 Acc: 75.0000%\n",
      "\tvalidation 8-73: Loss: 0.2044 Acc: 75.0000%\n",
      "\tvalidation 8-74: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 8-75: Loss: 0.0355 Acc: 100.0000%\n",
      "\tvalidation 8-76: Loss: 0.1106 Acc: 75.0000%\n",
      "\tvalidation 8-77: Loss: 0.0293 Acc: 100.0000%\n",
      "\tvalidation 8-78: Loss: 0.0437 Acc: 100.0000%\n",
      "\tvalidation 8-79: Loss: 0.1267 Acc: 50.0000%\n",
      "\tvalidation 8-80: Loss: 0.0603 Acc: 100.0000%\n",
      "\tvalidation 8-81: Loss: 0.2162 Acc: 50.0000%\n",
      "\tvalidation 8-82: Loss: 0.1174 Acc: 75.0000%\n",
      "\tvalidation 8-83: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 8-84: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 8-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 8-86: Loss: 0.1795 Acc: 50.0000%\n",
      "\tvalidation 8-87: Loss: 0.1124 Acc: 75.0000%\n",
      "\tvalidation 8-88: Loss: 0.2269 Acc: 50.0000%\n",
      "\tvalidation 8-89: Loss: 0.2369 Acc: 25.0000%\n",
      "\tvalidation 8-90: Loss: 0.1179 Acc: 50.0000%\n",
      "\tvalidation 8-91: Loss: 0.1032 Acc: 75.0000%\n",
      "\tvalidation 8-92: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 8-93: Loss: 0.0614 Acc: 100.0000%\n",
      "\tvalidation 8-94: Loss: 0.2116 Acc: 50.0000%\n",
      "\tvalidation 8-95: Loss: 0.1319 Acc: 75.0000%\n",
      "\tvalidation 8-96: Loss: 0.1518 Acc: 50.0000%\n",
      "\tvalidation 8-97: Loss: 0.0694 Acc: 75.0000%\n",
      "\tvalidation 8-98: Loss: 0.0515 Acc: 75.0000%\n",
      "\tvalidation 8-99: Loss: 0.0228 Acc: 100.0000%\n",
      "\tvalidation 8-100: Loss: 0.1658 Acc: 75.0000%\n",
      "\tvalidation 8-101: Loss: 0.1502 Acc: 50.0000%\n",
      "\tvalidation 8-102: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 8-103: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 8-104: Loss: 0.1642 Acc: 25.0000%\n",
      "\tvalidation 8-105: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1146 Acc: 73.3673%\n",
      "\tvalidation Loss: 0.1041 Acc: 73.3333%\n",
      "Time passed 0h 5m 21s\n",
      "--------------------\n",
      "Epoch [9/40]:\n",
      "\ttrain 9-1: Loss: 0.1629 Acc: 75.0000%\n",
      "\ttrain 9-2: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 9-3: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 9-4: Loss: 0.0880 Acc: 75.0000%\n",
      "\ttrain 9-5: Loss: 0.1670 Acc: 75.0000%\n",
      "\ttrain 9-6: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 9-7: Loss: 0.1649 Acc: 50.0000%\n",
      "\ttrain 9-8: Loss: 0.2278 Acc: 75.0000%\n",
      "\ttrain 9-9: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 9-10: Loss: 0.1406 Acc: 50.0000%\n",
      "\ttrain 9-11: Loss: 0.1280 Acc: 50.0000%\n",
      "\ttrain 9-12: Loss: 0.1282 Acc: 75.0000%\n",
      "\ttrain 9-13: Loss: 0.0564 Acc: 75.0000%\n",
      "\ttrain 9-14: Loss: 0.1392 Acc: 100.0000%\n",
      "\ttrain 9-15: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 9-16: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 9-17: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 9-18: Loss: 0.1159 Acc: 50.0000%\n",
      "\ttrain 9-19: Loss: 0.1612 Acc: 50.0000%\n",
      "\ttrain 9-20: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 9-21: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 9-22: Loss: 0.0484 Acc: 75.0000%\n",
      "\ttrain 9-23: Loss: 0.1577 Acc: 75.0000%\n",
      "\ttrain 9-24: Loss: 0.1337 Acc: 100.0000%\n",
      "\ttrain 9-25: Loss: 0.1429 Acc: 50.0000%\n",
      "\ttrain 9-26: Loss: 0.1294 Acc: 50.0000%\n",
      "\ttrain 9-27: Loss: 0.1442 Acc: 75.0000%\n",
      "\ttrain 9-28: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 9-29: Loss: 0.0997 Acc: 100.0000%\n",
      "\ttrain 9-30: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 9-31: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 9-32: Loss: 0.1756 Acc: 50.0000%\n",
      "\ttrain 9-33: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 9-34: Loss: 0.4039 Acc: 25.0000%\n",
      "\ttrain 9-35: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 9-36: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 9-37: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 9-38: Loss: 0.1047 Acc: 50.0000%\n",
      "\ttrain 9-39: Loss: 0.0497 Acc: 75.0000%\n",
      "\ttrain 9-40: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 9-41: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 9-42: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 9-43: Loss: 0.3811 Acc: 50.0000%\n",
      "\ttrain 9-44: Loss: 0.0560 Acc: 75.0000%\n",
      "\ttrain 9-45: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 9-46: Loss: 0.1090 Acc: 50.0000%\n",
      "\ttrain 9-47: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 9-48: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 9-49: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 9-50: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 9-51: Loss: 0.1975 Acc: 50.0000%\n",
      "\ttrain 9-52: Loss: 0.0957 Acc: 75.0000%\n",
      "\ttrain 9-53: Loss: 0.0789 Acc: 75.0000%\n",
      "\ttrain 9-54: Loss: 0.1330 Acc: 75.0000%\n",
      "\ttrain 9-55: Loss: 0.2234 Acc: 50.0000%\n",
      "\ttrain 9-56: Loss: 0.1035 Acc: 50.0000%\n",
      "\ttrain 9-57: Loss: 0.1908 Acc: 50.0000%\n",
      "\ttrain 9-58: Loss: 0.2434 Acc: 0.0000%\n",
      "\ttrain 9-59: Loss: 0.1494 Acc: 75.0000%\n",
      "\ttrain 9-60: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 9-61: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 9-62: Loss: 0.2013 Acc: 50.0000%\n",
      "\ttrain 9-63: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 9-64: Loss: 0.1043 Acc: 50.0000%\n",
      "\ttrain 9-65: Loss: 0.1121 Acc: 75.0000%\n",
      "\ttrain 9-66: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 9-67: Loss: 0.1576 Acc: 25.0000%\n",
      "\ttrain 9-68: Loss: 0.1509 Acc: 100.0000%\n",
      "\ttrain 9-69: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 9-70: Loss: 0.1550 Acc: 50.0000%\n",
      "\ttrain 9-71: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 9-72: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 9-73: Loss: 0.1485 Acc: 50.0000%\n",
      "\ttrain 9-74: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 9-75: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 9-76: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 9-77: Loss: 0.1243 Acc: 100.0000%\n",
      "\ttrain 9-78: Loss: 0.1169 Acc: 50.0000%\n",
      "\ttrain 9-79: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 9-80: Loss: 0.1841 Acc: 50.0000%\n",
      "\ttrain 9-81: Loss: 0.1097 Acc: 50.0000%\n",
      "\ttrain 9-82: Loss: 0.0813 Acc: 75.0000%\n",
      "\ttrain 9-83: Loss: 0.2022 Acc: 75.0000%\n",
      "\ttrain 9-84: Loss: 0.1600 Acc: 50.0000%\n",
      "\ttrain 9-85: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 9-86: Loss: 0.2220 Acc: 50.0000%\n",
      "\ttrain 9-87: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 9-88: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 9-89: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 9-90: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 9-91: Loss: 0.1846 Acc: 50.0000%\n",
      "\ttrain 9-92: Loss: 0.0922 Acc: 75.0000%\n",
      "\ttrain 9-93: Loss: 0.1706 Acc: 25.0000%\n",
      "\ttrain 9-94: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 9-95: Loss: 0.0773 Acc: 100.0000%\n",
      "\ttrain 9-96: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 9-97: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 9-98: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 9-99: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 9-100: Loss: 0.1778 Acc: 50.0000%\n",
      "\ttrain 9-101: Loss: 0.1449 Acc: 75.0000%\n",
      "\ttrain 9-102: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 9-103: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 9-104: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 9-105: Loss: 0.2035 Acc: 50.0000%\n",
      "\ttrain 9-106: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 9-107: Loss: 0.1213 Acc: 75.0000%\n",
      "\ttrain 9-108: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 9-109: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 9-110: Loss: 0.4494 Acc: 50.0000%\n",
      "\ttrain 9-111: Loss: 0.2074 Acc: 50.0000%\n",
      "\ttrain 9-112: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 9-113: Loss: 0.1568 Acc: 50.0000%\n",
      "\ttrain 9-114: Loss: 0.1631 Acc: 50.0000%\n",
      "\ttrain 9-115: Loss: 0.1357 Acc: 50.0000%\n",
      "\ttrain 9-116: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 9-117: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 9-118: Loss: 0.4571 Acc: 25.0000%\n",
      "\ttrain 9-119: Loss: 0.2222 Acc: 0.0000%\n",
      "\ttrain 9-120: Loss: 0.1426 Acc: 50.0000%\n",
      "\ttrain 9-121: Loss: 0.2204 Acc: 50.0000%\n",
      "\ttrain 9-122: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 9-123: Loss: 0.2151 Acc: 75.0000%\n",
      "\ttrain 9-124: Loss: 0.1498 Acc: 50.0000%\n",
      "\ttrain 9-125: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 9-126: Loss: 0.1348 Acc: 75.0000%\n",
      "\ttrain 9-127: Loss: 0.0891 Acc: 100.0000%\n",
      "\ttrain 9-128: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 9-129: Loss: 0.3133 Acc: 50.0000%\n",
      "\ttrain 9-130: Loss: 0.1280 Acc: 75.0000%\n",
      "\ttrain 9-131: Loss: 0.1044 Acc: 100.0000%\n",
      "\ttrain 9-132: Loss: 0.1343 Acc: 100.0000%\n",
      "\ttrain 9-133: Loss: 0.1330 Acc: 50.0000%\n",
      "\ttrain 9-134: Loss: 0.1250 Acc: 50.0000%\n",
      "\ttrain 9-135: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 9-136: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 9-137: Loss: 0.1837 Acc: 50.0000%\n",
      "\ttrain 9-138: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 9-139: Loss: 0.4818 Acc: 75.0000%\n",
      "\ttrain 9-140: Loss: 0.1470 Acc: 75.0000%\n",
      "\ttrain 9-141: Loss: 0.1159 Acc: 75.0000%\n",
      "\ttrain 9-142: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 9-143: Loss: 0.2436 Acc: 25.0000%\n",
      "\ttrain 9-144: Loss: 0.1050 Acc: 100.0000%\n",
      "\ttrain 9-145: Loss: 0.0884 Acc: 100.0000%\n",
      "\ttrain 9-146: Loss: 0.0527 Acc: 75.0000%\n",
      "\ttrain 9-147: Loss: 0.1404 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 9-148: Loss: 0.2007 Acc: 50.0000%\n",
      "\ttrain 9-149: Loss: 0.1628 Acc: 50.0000%\n",
      "\ttrain 9-150: Loss: 0.1881 Acc: 50.0000%\n",
      "\ttrain 9-151: Loss: 0.0885 Acc: 75.0000%\n",
      "\ttrain 9-152: Loss: 0.5518 Acc: 25.0000%\n",
      "\ttrain 9-153: Loss: 0.1187 Acc: 100.0000%\n",
      "\ttrain 9-154: Loss: 0.1631 Acc: 50.0000%\n",
      "\ttrain 9-155: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 9-156: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 9-157: Loss: 0.2217 Acc: 50.0000%\n",
      "\ttrain 9-158: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 9-159: Loss: 0.1463 Acc: 75.0000%\n",
      "\ttrain 9-160: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 9-161: Loss: 0.0988 Acc: 50.0000%\n",
      "\ttrain 9-162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 9-163: Loss: 0.0781 Acc: 100.0000%\n",
      "\ttrain 9-164: Loss: 0.1734 Acc: 75.0000%\n",
      "\ttrain 9-165: Loss: 0.1078 Acc: 50.0000%\n",
      "\ttrain 9-166: Loss: 0.0969 Acc: 100.0000%\n",
      "\ttrain 9-167: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 9-168: Loss: 0.1831 Acc: 50.0000%\n",
      "\ttrain 9-169: Loss: 0.0961 Acc: 100.0000%\n",
      "\ttrain 9-170: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 9-171: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 9-172: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 9-173: Loss: 0.0824 Acc: 100.0000%\n",
      "\ttrain 9-174: Loss: 0.1311 Acc: 75.0000%\n",
      "\ttrain 9-175: Loss: 0.0493 Acc: 75.0000%\n",
      "\ttrain 9-176: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 9-177: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 9-178: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 9-179: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 9-180: Loss: 0.2985 Acc: 75.0000%\n",
      "\ttrain 9-181: Loss: 0.1636 Acc: 50.0000%\n",
      "\ttrain 9-182: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 9-183: Loss: 0.1418 Acc: 50.0000%\n",
      "\ttrain 9-184: Loss: 0.1384 Acc: 75.0000%\n",
      "\ttrain 9-185: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 9-186: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 9-187: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 9-188: Loss: 0.1285 Acc: 75.0000%\n",
      "\ttrain 9-189: Loss: 0.0749 Acc: 100.0000%\n",
      "\ttrain 9-190: Loss: 0.1517 Acc: 50.0000%\n",
      "\ttrain 9-191: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 9-192: Loss: 0.1301 Acc: 50.0000%\n",
      "\ttrain 9-193: Loss: 0.1718 Acc: 75.0000%\n",
      "\ttrain 9-194: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 9-195: Loss: 0.2086 Acc: 25.0000%\n",
      "\ttrain 9-196: Loss: 0.1875 Acc: 50.0000%\n",
      "\ttrain 9-197: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 9-198: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 9-199: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 9-200: Loss: 0.1570 Acc: 50.0000%\n",
      "\ttrain 9-201: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 9-202: Loss: 0.2327 Acc: 25.0000%\n",
      "\ttrain 9-203: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 9-204: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 9-205: Loss: 0.1560 Acc: 50.0000%\n",
      "\ttrain 9-206: Loss: 0.0475 Acc: 75.0000%\n",
      "\ttrain 9-207: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 9-208: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 9-209: Loss: 0.1218 Acc: 50.0000%\n",
      "\ttrain 9-210: Loss: 0.3287 Acc: 75.0000%\n",
      "\ttrain 9-211: Loss: 0.1746 Acc: 25.0000%\n",
      "\ttrain 9-212: Loss: 0.1529 Acc: 75.0000%\n",
      "\ttrain 9-213: Loss: 0.0701 Acc: 75.0000%\n",
      "\ttrain 9-214: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 9-215: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 9-216: Loss: 0.2219 Acc: 50.0000%\n",
      "\ttrain 9-217: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 9-218: Loss: 0.2490 Acc: 25.0000%\n",
      "\ttrain 9-219: Loss: 0.2457 Acc: 0.0000%\n",
      "\ttrain 9-220: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 9-221: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 9-222: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 9-223: Loss: 0.1153 Acc: 50.0000%\n",
      "\ttrain 9-224: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 9-225: Loss: 0.1081 Acc: 75.0000%\n",
      "\ttrain 9-226: Loss: 0.1715 Acc: 50.0000%\n",
      "\ttrain 9-227: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 9-228: Loss: 0.1076 Acc: 100.0000%\n",
      "\ttrain 9-229: Loss: 0.1481 Acc: 50.0000%\n",
      "\ttrain 9-230: Loss: 0.1792 Acc: 75.0000%\n",
      "\ttrain 9-231: Loss: 0.2283 Acc: 50.0000%\n",
      "\ttrain 9-232: Loss: 0.1625 Acc: 50.0000%\n",
      "\ttrain 9-233: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 9-234: Loss: 0.1012 Acc: 100.0000%\n",
      "\ttrain 9-235: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 9-236: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 9-237: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 9-238: Loss: 0.1903 Acc: 25.0000%\n",
      "\ttrain 9-239: Loss: 0.0561 Acc: 75.0000%\n",
      "\ttrain 9-240: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 9-241: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 9-242: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 9-243: Loss: 0.1054 Acc: 50.0000%\n",
      "\ttrain 9-244: Loss: 0.1512 Acc: 75.0000%\n",
      "\ttrain 9-245: Loss: 0.0847 Acc: 75.0000%\n",
      "\tvalidation 9-1: Loss: 0.2201 Acc: 0.0000%\n",
      "\tvalidation 9-2: Loss: 0.1496 Acc: 25.0000%\n",
      "\tvalidation 9-3: Loss: 0.0755 Acc: 100.0000%\n",
      "\tvalidation 9-4: Loss: 0.0982 Acc: 50.0000%\n",
      "\tvalidation 9-5: Loss: 0.2187 Acc: 50.0000%\n",
      "\tvalidation 9-6: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 9-7: Loss: 0.1015 Acc: 50.0000%\n",
      "\tvalidation 9-8: Loss: 0.1859 Acc: 50.0000%\n",
      "\tvalidation 9-9: Loss: 0.1985 Acc: 50.0000%\n",
      "\tvalidation 9-10: Loss: 0.1966 Acc: 25.0000%\n",
      "\tvalidation 9-11: Loss: 0.0522 Acc: 75.0000%\n",
      "\tvalidation 9-12: Loss: 0.1748 Acc: 75.0000%\n",
      "\tvalidation 9-13: Loss: 0.1020 Acc: 50.0000%\n",
      "\tvalidation 9-14: Loss: 0.1220 Acc: 75.0000%\n",
      "\tvalidation 9-15: Loss: 0.1309 Acc: 50.0000%\n",
      "\tvalidation 9-16: Loss: 0.0507 Acc: 75.0000%\n",
      "\tvalidation 9-17: Loss: 0.0866 Acc: 75.0000%\n",
      "\tvalidation 9-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 9-19: Loss: 0.0512 Acc: 75.0000%\n",
      "\tvalidation 9-20: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-21: Loss: 0.0408 Acc: 100.0000%\n",
      "\tvalidation 9-22: Loss: 0.1272 Acc: 75.0000%\n",
      "\tvalidation 9-23: Loss: 0.1095 Acc: 50.0000%\n",
      "\tvalidation 9-24: Loss: 0.0893 Acc: 75.0000%\n",
      "\tvalidation 9-25: Loss: 0.1240 Acc: 100.0000%\n",
      "\tvalidation 9-26: Loss: 0.1367 Acc: 75.0000%\n",
      "\tvalidation 9-27: Loss: 0.0505 Acc: 75.0000%\n",
      "\tvalidation 9-28: Loss: 0.0892 Acc: 75.0000%\n",
      "\tvalidation 9-29: Loss: 0.1499 Acc: 50.0000%\n",
      "\tvalidation 9-30: Loss: 0.0689 Acc: 100.0000%\n",
      "\tvalidation 9-31: Loss: 0.1204 Acc: 75.0000%\n",
      "\tvalidation 9-32: Loss: 0.0484 Acc: 75.0000%\n",
      "\tvalidation 9-33: Loss: 0.0792 Acc: 100.0000%\n",
      "\tvalidation 9-34: Loss: 0.1638 Acc: 50.0000%\n",
      "\tvalidation 9-35: Loss: 0.1127 Acc: 50.0000%\n",
      "\tvalidation 9-36: Loss: 0.1032 Acc: 75.0000%\n",
      "\tvalidation 9-37: Loss: 0.1284 Acc: 75.0000%\n",
      "\tvalidation 9-38: Loss: 0.1371 Acc: 50.0000%\n",
      "\tvalidation 9-39: Loss: 0.0843 Acc: 100.0000%\n",
      "\tvalidation 9-40: Loss: 0.1173 Acc: 50.0000%\n",
      "\tvalidation 9-41: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 9-42: Loss: 0.1446 Acc: 50.0000%\n",
      "\tvalidation 9-43: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 9-44: Loss: 0.0507 Acc: 75.0000%\n",
      "\tvalidation 9-45: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 9-46: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 9-47: Loss: 0.1812 Acc: 25.0000%\n",
      "\tvalidation 9-48: Loss: 0.0832 Acc: 75.0000%\n",
      "\tvalidation 9-49: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 9-50: Loss: 0.0424 Acc: 100.0000%\n",
      "\tvalidation 9-51: Loss: 0.1429 Acc: 50.0000%\n",
      "\tvalidation 9-52: Loss: 0.1421 Acc: 50.0000%\n",
      "\tvalidation 9-53: Loss: 0.1826 Acc: 25.0000%\n",
      "\tvalidation 9-54: Loss: 0.0552 Acc: 100.0000%\n",
      "\tvalidation 9-55: Loss: 0.0666 Acc: 75.0000%\n",
      "\tvalidation 9-56: Loss: 0.1302 Acc: 50.0000%\n",
      "\tvalidation 9-57: Loss: 0.1235 Acc: 100.0000%\n",
      "\tvalidation 9-58: Loss: 0.0793 Acc: 100.0000%\n",
      "\tvalidation 9-59: Loss: 0.0886 Acc: 75.0000%\n",
      "\tvalidation 9-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-61: Loss: 0.0617 Acc: 75.0000%\n",
      "\tvalidation 9-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 9-63: Loss: 0.0903 Acc: 75.0000%\n",
      "\tvalidation 9-64: Loss: 0.1764 Acc: 50.0000%\n",
      "\tvalidation 9-65: Loss: 0.1250 Acc: 75.0000%\n",
      "\tvalidation 9-66: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 9-67: Loss: 0.0534 Acc: 75.0000%\n",
      "\tvalidation 9-68: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 9-69: Loss: 0.1339 Acc: 50.0000%\n",
      "\tvalidation 9-70: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 9-71: Loss: 0.1435 Acc: 50.0000%\n",
      "\tvalidation 9-72: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 9-73: Loss: 0.0854 Acc: 75.0000%\n",
      "\tvalidation 9-74: Loss: 0.0501 Acc: 75.0000%\n",
      "\tvalidation 9-75: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 9-76: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 9-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 9-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 9-79: Loss: 0.0761 Acc: 100.0000%\n",
      "\tvalidation 9-80: Loss: 0.0581 Acc: 75.0000%\n",
      "\tvalidation 9-81: Loss: 0.1094 Acc: 100.0000%\n",
      "\tvalidation 9-82: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 9-83: Loss: 0.0581 Acc: 75.0000%\n",
      "\tvalidation 9-84: Loss: 0.0831 Acc: 100.0000%\n",
      "\tvalidation 9-85: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 9-86: Loss: 0.1249 Acc: 75.0000%\n",
      "\tvalidation 9-87: Loss: 0.0415 Acc: 100.0000%\n",
      "\tvalidation 9-88: Loss: 0.1386 Acc: 75.0000%\n",
      "\tvalidation 9-89: Loss: 0.1405 Acc: 50.0000%\n",
      "\tvalidation 9-90: Loss: 0.1205 Acc: 75.0000%\n",
      "\tvalidation 9-91: Loss: 0.1129 Acc: 50.0000%\n",
      "\tvalidation 9-92: Loss: 0.0321 Acc: 100.0000%\n",
      "\tvalidation 9-93: Loss: 0.0719 Acc: 100.0000%\n",
      "\tvalidation 9-94: Loss: 0.0629 Acc: 100.0000%\n",
      "\tvalidation 9-95: Loss: 0.0985 Acc: 50.0000%\n",
      "\tvalidation 9-96: Loss: 0.0845 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 9-97: Loss: 0.0856 Acc: 75.0000%\n",
      "\tvalidation 9-98: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 9-99: Loss: 0.1338 Acc: 75.0000%\n",
      "\tvalidation 9-100: Loss: 0.0844 Acc: 75.0000%\n",
      "\tvalidation 9-101: Loss: 0.0827 Acc: 100.0000%\n",
      "\tvalidation 9-102: Loss: 0.1062 Acc: 100.0000%\n",
      "\tvalidation 9-103: Loss: 0.0672 Acc: 100.0000%\n",
      "\tvalidation 9-104: Loss: 0.0464 Acc: 75.0000%\n",
      "\tvalidation 9-105: Loss: 0.1127 Acc: 50.0000%\n",
      "\ttrain Loss: 0.1263 Acc: 71.2245%\n",
      "\tvalidation Loss: 0.0920 Acc: 75.2381%\n",
      "网络参数更新\n",
      "Time passed 0h 6m 9s\n",
      "--------------------\n",
      "Epoch [10/40]:\n",
      "\ttrain 10-1: Loss: 0.1283 Acc: 75.0000%\n",
      "\ttrain 10-2: Loss: 0.1399 Acc: 50.0000%\n",
      "\ttrain 10-3: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 10-4: Loss: 0.1333 Acc: 75.0000%\n",
      "\ttrain 10-5: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 10-6: Loss: 0.1543 Acc: 50.0000%\n",
      "\ttrain 10-7: Loss: 0.1209 Acc: 50.0000%\n",
      "\ttrain 10-8: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 10-9: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 10-10: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 10-11: Loss: 0.1051 Acc: 75.0000%\n",
      "\ttrain 10-12: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 10-13: Loss: 0.1117 Acc: 100.0000%\n",
      "\ttrain 10-14: Loss: 0.1347 Acc: 50.0000%\n",
      "\ttrain 10-15: Loss: 0.1950 Acc: 50.0000%\n",
      "\ttrain 10-16: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 10-17: Loss: 0.1097 Acc: 100.0000%\n",
      "\ttrain 10-18: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 10-19: Loss: 0.1666 Acc: 50.0000%\n",
      "\ttrain 10-20: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 10-21: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 10-22: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 10-23: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 10-24: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 10-25: Loss: 0.1949 Acc: 75.0000%\n",
      "\ttrain 10-26: Loss: 0.2193 Acc: 50.0000%\n",
      "\ttrain 10-27: Loss: 0.1668 Acc: 100.0000%\n",
      "\ttrain 10-28: Loss: 0.0987 Acc: 100.0000%\n",
      "\ttrain 10-29: Loss: 0.1446 Acc: 50.0000%\n",
      "\ttrain 10-30: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 10-31: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 10-32: Loss: 0.1253 Acc: 100.0000%\n",
      "\ttrain 10-33: Loss: 0.1873 Acc: 25.0000%\n",
      "\ttrain 10-34: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 10-35: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 10-36: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 10-37: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 10-38: Loss: 0.2990 Acc: 75.0000%\n",
      "\ttrain 10-39: Loss: 0.1103 Acc: 50.0000%\n",
      "\ttrain 10-40: Loss: 0.1533 Acc: 75.0000%\n",
      "\ttrain 10-41: Loss: 0.0813 Acc: 100.0000%\n",
      "\ttrain 10-42: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 10-43: Loss: 0.1355 Acc: 50.0000%\n",
      "\ttrain 10-44: Loss: 0.2641 Acc: 0.0000%\n",
      "\ttrain 10-45: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 10-46: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 10-47: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 10-48: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 10-49: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 10-50: Loss: 0.0971 Acc: 100.0000%\n",
      "\ttrain 10-51: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 10-52: Loss: 0.1679 Acc: 50.0000%\n",
      "\ttrain 10-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-54: Loss: 0.1004 Acc: 50.0000%\n",
      "\ttrain 10-55: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 10-56: Loss: 0.0935 Acc: 50.0000%\n",
      "\ttrain 10-57: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 10-58: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 10-59: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 10-60: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 10-61: Loss: 0.1414 Acc: 50.0000%\n",
      "\ttrain 10-62: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 10-63: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 10-64: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 10-65: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 10-66: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 10-67: Loss: 0.2774 Acc: 50.0000%\n",
      "\ttrain 10-68: Loss: 0.3202 Acc: 50.0000%\n",
      "\ttrain 10-69: Loss: 0.1003 Acc: 50.0000%\n",
      "\ttrain 10-70: Loss: 0.1870 Acc: 50.0000%\n",
      "\ttrain 10-71: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 10-72: Loss: 0.1513 Acc: 50.0000%\n",
      "\ttrain 10-73: Loss: 0.1335 Acc: 75.0000%\n",
      "\ttrain 10-74: Loss: 0.1379 Acc: 50.0000%\n",
      "\ttrain 10-75: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 10-76: Loss: 0.1446 Acc: 50.0000%\n",
      "\ttrain 10-77: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 10-78: Loss: 0.1197 Acc: 50.0000%\n",
      "\ttrain 10-79: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 10-80: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 10-81: Loss: 0.1196 Acc: 50.0000%\n",
      "\ttrain 10-82: Loss: 0.2641 Acc: 25.0000%\n",
      "\ttrain 10-83: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 10-84: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 10-85: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 10-86: Loss: 0.1702 Acc: 25.0000%\n",
      "\ttrain 10-87: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 10-88: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 10-89: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 10-90: Loss: 0.0851 Acc: 100.0000%\n",
      "\ttrain 10-91: Loss: 0.1072 Acc: 50.0000%\n",
      "\ttrain 10-92: Loss: 0.0581 Acc: 75.0000%\n",
      "\ttrain 10-93: Loss: 0.1363 Acc: 50.0000%\n",
      "\ttrain 10-94: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 10-95: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 10-96: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 10-97: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 10-98: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 10-99: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 10-100: Loss: 0.1363 Acc: 50.0000%\n",
      "\ttrain 10-101: Loss: 0.0697 Acc: 100.0000%\n",
      "\ttrain 10-102: Loss: 0.1564 Acc: 75.0000%\n",
      "\ttrain 10-103: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 10-104: Loss: 0.1350 Acc: 50.0000%\n",
      "\ttrain 10-105: Loss: 0.1783 Acc: 50.0000%\n",
      "\ttrain 10-106: Loss: 0.0907 Acc: 100.0000%\n",
      "\ttrain 10-107: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 10-108: Loss: 0.0698 Acc: 100.0000%\n",
      "\ttrain 10-109: Loss: 0.1315 Acc: 100.0000%\n",
      "\ttrain 10-110: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 10-111: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 10-112: Loss: 0.0624 Acc: 75.0000%\n",
      "\ttrain 10-113: Loss: 0.2653 Acc: 25.0000%\n",
      "\ttrain 10-114: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 10-115: Loss: 0.1636 Acc: 75.0000%\n",
      "\ttrain 10-116: Loss: 0.1656 Acc: 50.0000%\n",
      "\ttrain 10-117: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 10-118: Loss: 0.1534 Acc: 50.0000%\n",
      "\ttrain 10-119: Loss: 0.1513 Acc: 75.0000%\n",
      "\ttrain 10-120: Loss: 0.0709 Acc: 75.0000%\n",
      "\ttrain 10-121: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 10-122: Loss: 0.2087 Acc: 50.0000%\n",
      "\ttrain 10-123: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 10-124: Loss: 0.2165 Acc: 75.0000%\n",
      "\ttrain 10-125: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 10-126: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 10-127: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 10-128: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 10-129: Loss: 0.1470 Acc: 75.0000%\n",
      "\ttrain 10-130: Loss: 0.0968 Acc: 50.0000%\n",
      "\ttrain 10-131: Loss: 0.2648 Acc: 25.0000%\n",
      "\ttrain 10-132: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 10-133: Loss: 0.1946 Acc: 50.0000%\n",
      "\ttrain 10-134: Loss: 0.1831 Acc: 25.0000%\n",
      "\ttrain 10-135: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 10-136: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 10-137: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 10-138: Loss: 0.3765 Acc: 25.0000%\n",
      "\ttrain 10-139: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 10-140: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 10-141: Loss: 0.0757 Acc: 100.0000%\n",
      "\ttrain 10-142: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 10-143: Loss: 0.1425 Acc: 75.0000%\n",
      "\ttrain 10-144: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 10-145: Loss: 0.1040 Acc: 100.0000%\n",
      "\ttrain 10-146: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 10-147: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 10-148: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 10-149: Loss: 0.1319 Acc: 75.0000%\n",
      "\ttrain 10-150: Loss: 0.2245 Acc: 0.0000%\n",
      "\ttrain 10-151: Loss: 0.0459 Acc: 75.0000%\n",
      "\ttrain 10-152: Loss: 0.1558 Acc: 50.0000%\n",
      "\ttrain 10-153: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 10-154: Loss: 0.1207 Acc: 75.0000%\n",
      "\ttrain 10-155: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 10-156: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 10-157: Loss: 0.1137 Acc: 75.0000%\n",
      "\ttrain 10-158: Loss: 0.0983 Acc: 75.0000%\n",
      "\ttrain 10-159: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 10-160: Loss: 0.1252 Acc: 75.0000%\n",
      "\ttrain 10-161: Loss: 0.1499 Acc: 50.0000%\n",
      "\ttrain 10-162: Loss: 0.1504 Acc: 50.0000%\n",
      "\ttrain 10-163: Loss: 0.0899 Acc: 50.0000%\n",
      "\ttrain 10-164: Loss: 0.0845 Acc: 100.0000%\n",
      "\ttrain 10-165: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 10-166: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 10-167: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 10-168: Loss: 0.1018 Acc: 50.0000%\n",
      "\ttrain 10-169: Loss: 0.2817 Acc: 25.0000%\n",
      "\ttrain 10-170: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 10-171: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 10-172: Loss: 0.2235 Acc: 0.0000%\n",
      "\ttrain 10-173: Loss: 0.1886 Acc: 25.0000%\n",
      "\ttrain 10-174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-175: Loss: 0.2472 Acc: 50.0000%\n",
      "\ttrain 10-176: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 10-177: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 10-178: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 10-179: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 10-180: Loss: 0.0941 Acc: 50.0000%\n",
      "\ttrain 10-181: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 10-182: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 10-183: Loss: 0.1732 Acc: 50.0000%\n",
      "\ttrain 10-184: Loss: 0.0309 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 10-185: Loss: 0.1009 Acc: 75.0000%\n",
      "\ttrain 10-186: Loss: 0.1683 Acc: 50.0000%\n",
      "\ttrain 10-187: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 10-188: Loss: 0.2008 Acc: 25.0000%\n",
      "\ttrain 10-189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-190: Loss: 0.1137 Acc: 100.0000%\n",
      "\ttrain 10-191: Loss: 0.1399 Acc: 75.0000%\n",
      "\ttrain 10-192: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 10-193: Loss: 0.1312 Acc: 75.0000%\n",
      "\ttrain 10-194: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 10-195: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 10-196: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 10-197: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 10-198: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 10-199: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 10-200: Loss: 0.1398 Acc: 50.0000%\n",
      "\ttrain 10-201: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 10-202: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 10-203: Loss: 0.2257 Acc: 25.0000%\n",
      "\ttrain 10-204: Loss: 0.0493 Acc: 75.0000%\n",
      "\ttrain 10-205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 10-206: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 10-207: Loss: 0.0579 Acc: 75.0000%\n",
      "\ttrain 10-208: Loss: 0.1789 Acc: 50.0000%\n",
      "\ttrain 10-209: Loss: 0.2083 Acc: 25.0000%\n",
      "\ttrain 10-210: Loss: 0.0799 Acc: 75.0000%\n",
      "\ttrain 10-211: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 10-212: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 10-213: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 10-214: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 10-215: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 10-216: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 10-217: Loss: 0.1413 Acc: 50.0000%\n",
      "\ttrain 10-218: Loss: 0.1622 Acc: 50.0000%\n",
      "\ttrain 10-219: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 10-220: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 10-221: Loss: 0.2074 Acc: 50.0000%\n",
      "\ttrain 10-222: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 10-223: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 10-224: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 10-225: Loss: 0.2286 Acc: 50.0000%\n",
      "\ttrain 10-226: Loss: 0.0965 Acc: 75.0000%\n",
      "\ttrain 10-227: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 10-228: Loss: 0.1386 Acc: 75.0000%\n",
      "\ttrain 10-229: Loss: 0.1331 Acc: 75.0000%\n",
      "\ttrain 10-230: Loss: 0.1783 Acc: 25.0000%\n",
      "\ttrain 10-231: Loss: 0.1343 Acc: 50.0000%\n",
      "\ttrain 10-232: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 10-233: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 10-234: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 10-235: Loss: 0.1660 Acc: 75.0000%\n",
      "\ttrain 10-236: Loss: 0.1292 Acc: 100.0000%\n",
      "\ttrain 10-237: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 10-238: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 10-239: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 10-240: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 10-241: Loss: 0.1472 Acc: 75.0000%\n",
      "\ttrain 10-242: Loss: 0.3320 Acc: 75.0000%\n",
      "\ttrain 10-243: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 10-244: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 10-245: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 10-1: Loss: 0.1979 Acc: 50.0000%\n",
      "\tvalidation 10-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 10-3: Loss: 0.1457 Acc: 50.0000%\n",
      "\tvalidation 10-4: Loss: 0.1268 Acc: 75.0000%\n",
      "\tvalidation 10-5: Loss: 0.0738 Acc: 75.0000%\n",
      "\tvalidation 10-6: Loss: 0.0917 Acc: 75.0000%\n",
      "\tvalidation 10-7: Loss: 0.1819 Acc: 50.0000%\n",
      "\tvalidation 10-8: Loss: 0.2295 Acc: 25.0000%\n",
      "\tvalidation 10-9: Loss: 0.1519 Acc: 50.0000%\n",
      "\tvalidation 10-10: Loss: 0.1680 Acc: 50.0000%\n",
      "\tvalidation 10-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 10-12: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 10-13: Loss: 0.0717 Acc: 75.0000%\n",
      "\tvalidation 10-14: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 10-15: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 10-16: Loss: 0.0739 Acc: 75.0000%\n",
      "\tvalidation 10-17: Loss: 0.1730 Acc: 50.0000%\n",
      "\tvalidation 10-18: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 10-19: Loss: 0.1582 Acc: 50.0000%\n",
      "\tvalidation 10-20: Loss: 0.0734 Acc: 75.0000%\n",
      "\tvalidation 10-21: Loss: 0.0661 Acc: 100.0000%\n",
      "\tvalidation 10-22: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 10-23: Loss: 0.1503 Acc: 50.0000%\n",
      "\tvalidation 10-24: Loss: 0.0519 Acc: 100.0000%\n",
      "\tvalidation 10-25: Loss: 0.1271 Acc: 75.0000%\n",
      "\tvalidation 10-26: Loss: 0.1544 Acc: 50.0000%\n",
      "\tvalidation 10-27: Loss: 0.1011 Acc: 75.0000%\n",
      "\tvalidation 10-28: Loss: 0.1007 Acc: 75.0000%\n",
      "\tvalidation 10-29: Loss: 0.0640 Acc: 100.0000%\n",
      "\tvalidation 10-30: Loss: 0.1488 Acc: 50.0000%\n",
      "\tvalidation 10-31: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 10-32: Loss: 0.1499 Acc: 50.0000%\n",
      "\tvalidation 10-33: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 10-34: Loss: 0.1621 Acc: 50.0000%\n",
      "\tvalidation 10-35: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 10-36: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 10-37: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 10-38: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 10-39: Loss: 0.0900 Acc: 75.0000%\n",
      "\tvalidation 10-40: Loss: 0.0459 Acc: 100.0000%\n",
      "\tvalidation 10-41: Loss: 0.0951 Acc: 75.0000%\n",
      "\tvalidation 10-42: Loss: 0.0317 Acc: 100.0000%\n",
      "\tvalidation 10-43: Loss: 0.0674 Acc: 100.0000%\n",
      "\tvalidation 10-44: Loss: 0.0950 Acc: 75.0000%\n",
      "\tvalidation 10-45: Loss: 0.1431 Acc: 50.0000%\n",
      "\tvalidation 10-46: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 10-47: Loss: 0.1436 Acc: 50.0000%\n",
      "\tvalidation 10-48: Loss: 0.1430 Acc: 50.0000%\n",
      "\tvalidation 10-49: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 10-50: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 10-51: Loss: 0.1924 Acc: 50.0000%\n",
      "\tvalidation 10-52: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 10-53: Loss: 0.0964 Acc: 75.0000%\n",
      "\tvalidation 10-54: Loss: 0.2303 Acc: 25.0000%\n",
      "\tvalidation 10-55: Loss: 0.0505 Acc: 100.0000%\n",
      "\tvalidation 10-56: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 10-57: Loss: 0.1124 Acc: 75.0000%\n",
      "\tvalidation 10-58: Loss: 0.1180 Acc: 75.0000%\n",
      "\tvalidation 10-59: Loss: 0.0936 Acc: 75.0000%\n",
      "\tvalidation 10-60: Loss: 0.1402 Acc: 50.0000%\n",
      "\tvalidation 10-61: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 10-62: Loss: 0.1757 Acc: 50.0000%\n",
      "\tvalidation 10-63: Loss: 0.0740 Acc: 75.0000%\n",
      "\tvalidation 10-64: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 10-65: Loss: 0.1135 Acc: 75.0000%\n",
      "\tvalidation 10-66: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 10-67: Loss: 0.1114 Acc: 75.0000%\n",
      "\tvalidation 10-68: Loss: 0.0959 Acc: 75.0000%\n",
      "\tvalidation 10-69: Loss: 0.0759 Acc: 75.0000%\n",
      "\tvalidation 10-70: Loss: 0.0816 Acc: 75.0000%\n",
      "\tvalidation 10-71: Loss: 0.0734 Acc: 75.0000%\n",
      "\tvalidation 10-72: Loss: 0.2276 Acc: 25.0000%\n",
      "\tvalidation 10-73: Loss: 0.1472 Acc: 50.0000%\n",
      "\tvalidation 10-74: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 10-75: Loss: 0.0732 Acc: 75.0000%\n",
      "\tvalidation 10-76: Loss: 0.1077 Acc: 75.0000%\n",
      "\tvalidation 10-77: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 10-78: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 10-79: Loss: 0.0205 Acc: 100.0000%\n",
      "\tvalidation 10-80: Loss: 0.0737 Acc: 75.0000%\n",
      "\tvalidation 10-81: Loss: 0.0687 Acc: 100.0000%\n",
      "\tvalidation 10-82: Loss: 0.1880 Acc: 50.0000%\n",
      "\tvalidation 10-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 10-84: Loss: 0.0791 Acc: 75.0000%\n",
      "\tvalidation 10-85: Loss: 0.0943 Acc: 75.0000%\n",
      "\tvalidation 10-86: Loss: 0.0945 Acc: 75.0000%\n",
      "\tvalidation 10-87: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 10-88: Loss: 0.0984 Acc: 75.0000%\n",
      "\tvalidation 10-89: Loss: 0.1591 Acc: 50.0000%\n",
      "\tvalidation 10-90: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 10-91: Loss: 0.0932 Acc: 75.0000%\n",
      "\tvalidation 10-92: Loss: 0.0949 Acc: 75.0000%\n",
      "\tvalidation 10-93: Loss: 0.0507 Acc: 100.0000%\n",
      "\tvalidation 10-94: Loss: 0.0759 Acc: 75.0000%\n",
      "\tvalidation 10-95: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 10-96: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 10-97: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 10-98: Loss: 0.1225 Acc: 75.0000%\n",
      "\tvalidation 10-99: Loss: 0.1178 Acc: 75.0000%\n",
      "\tvalidation 10-100: Loss: 0.1246 Acc: 75.0000%\n",
      "\tvalidation 10-101: Loss: 0.0867 Acc: 75.0000%\n",
      "\tvalidation 10-102: Loss: 0.1956 Acc: 50.0000%\n",
      "\tvalidation 10-103: Loss: 0.1445 Acc: 50.0000%\n",
      "\tvalidation 10-104: Loss: 0.0972 Acc: 75.0000%\n",
      "\tvalidation 10-105: Loss: 0.2204 Acc: 25.0000%\n",
      "\ttrain Loss: 0.1080 Acc: 73.7755%\n",
      "\tvalidation Loss: 0.0960 Acc: 75.0000%\n",
      "Time passed 0h 6m 52s\n",
      "--------------------\n",
      "Epoch [11/40]:\n",
      "\ttrain 11-1: Loss: 0.1613 Acc: 50.0000%\n",
      "\ttrain 11-2: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 11-3: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 11-4: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 11-5: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 11-6: Loss: 0.0898 Acc: 75.0000%\n",
      "\ttrain 11-7: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 11-8: Loss: 0.1405 Acc: 75.0000%\n",
      "\ttrain 11-9: Loss: 0.1858 Acc: 50.0000%\n",
      "\ttrain 11-10: Loss: 0.3213 Acc: 25.0000%\n",
      "\ttrain 11-11: Loss: 0.1994 Acc: 25.0000%\n",
      "\ttrain 11-12: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 11-13: Loss: 0.1941 Acc: 25.0000%\n",
      "\ttrain 11-14: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 11-15: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 11-16: Loss: 0.1692 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-17: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 11-18: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 11-19: Loss: 0.1440 Acc: 50.0000%\n",
      "\ttrain 11-20: Loss: 0.0947 Acc: 100.0000%\n",
      "\ttrain 11-21: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 11-22: Loss: 0.1715 Acc: 25.0000%\n",
      "\ttrain 11-23: Loss: 0.2324 Acc: 25.0000%\n",
      "\ttrain 11-24: Loss: 0.0957 Acc: 50.0000%\n",
      "\ttrain 11-25: Loss: 0.0844 Acc: 100.0000%\n",
      "\ttrain 11-26: Loss: 0.1372 Acc: 50.0000%\n",
      "\ttrain 11-27: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 11-28: Loss: 0.0824 Acc: 100.0000%\n",
      "\ttrain 11-29: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 11-30: Loss: 0.1848 Acc: 75.0000%\n",
      "\ttrain 11-31: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 11-32: Loss: 0.1382 Acc: 50.0000%\n",
      "\ttrain 11-33: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 11-34: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 11-35: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 11-36: Loss: 0.2071 Acc: 75.0000%\n",
      "\ttrain 11-37: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 11-38: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 11-39: Loss: 0.1751 Acc: 25.0000%\n",
      "\ttrain 11-40: Loss: 0.1956 Acc: 25.0000%\n",
      "\ttrain 11-41: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 11-42: Loss: 0.1312 Acc: 100.0000%\n",
      "\ttrain 11-43: Loss: 0.1399 Acc: 50.0000%\n",
      "\ttrain 11-44: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 11-45: Loss: 0.1712 Acc: 50.0000%\n",
      "\ttrain 11-46: Loss: 0.1310 Acc: 75.0000%\n",
      "\ttrain 11-47: Loss: 0.1534 Acc: 75.0000%\n",
      "\ttrain 11-48: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 11-49: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 11-50: Loss: 0.0872 Acc: 100.0000%\n",
      "\ttrain 11-51: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 11-52: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 11-53: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 11-54: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 11-55: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 11-56: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 11-57: Loss: 0.2419 Acc: 25.0000%\n",
      "\ttrain 11-58: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 11-59: Loss: 0.0837 Acc: 75.0000%\n",
      "\ttrain 11-60: Loss: 0.1195 Acc: 50.0000%\n",
      "\ttrain 11-61: Loss: 0.1431 Acc: 50.0000%\n",
      "\ttrain 11-62: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 11-63: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 11-64: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 11-65: Loss: 0.1539 Acc: 75.0000%\n",
      "\ttrain 11-66: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 11-67: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 11-68: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 11-69: Loss: 0.0875 Acc: 75.0000%\n",
      "\ttrain 11-70: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 11-71: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 11-72: Loss: 0.1660 Acc: 75.0000%\n",
      "\ttrain 11-73: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 11-74: Loss: 0.1070 Acc: 75.0000%\n",
      "\ttrain 11-75: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 11-76: Loss: 0.1056 Acc: 75.0000%\n",
      "\ttrain 11-77: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 11-78: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 11-79: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 11-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 11-81: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 11-82: Loss: 0.1063 Acc: 50.0000%\n",
      "\ttrain 11-83: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 11-84: Loss: 0.0512 Acc: 75.0000%\n",
      "\ttrain 11-85: Loss: 0.1484 Acc: 50.0000%\n",
      "\ttrain 11-86: Loss: 0.0692 Acc: 100.0000%\n",
      "\ttrain 11-87: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 11-88: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 11-89: Loss: 0.0911 Acc: 75.0000%\n",
      "\ttrain 11-90: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 11-91: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 11-92: Loss: 0.1278 Acc: 75.0000%\n",
      "\ttrain 11-93: Loss: 0.1859 Acc: 50.0000%\n",
      "\ttrain 11-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 11-95: Loss: 0.0914 Acc: 100.0000%\n",
      "\ttrain 11-96: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 11-97: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 11-98: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 11-99: Loss: 0.0643 Acc: 75.0000%\n",
      "\ttrain 11-100: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 11-101: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 11-102: Loss: 0.1535 Acc: 25.0000%\n",
      "\ttrain 11-103: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 11-104: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 11-105: Loss: 0.1099 Acc: 75.0000%\n",
      "\ttrain 11-106: Loss: 0.1844 Acc: 50.0000%\n",
      "\ttrain 11-107: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 11-108: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 11-109: Loss: 0.2580 Acc: 75.0000%\n",
      "\ttrain 11-110: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 11-111: Loss: 0.2276 Acc: 75.0000%\n",
      "\ttrain 11-112: Loss: 0.1149 Acc: 100.0000%\n",
      "\ttrain 11-113: Loss: 0.1597 Acc: 50.0000%\n",
      "\ttrain 11-114: Loss: 0.3737 Acc: 75.0000%\n",
      "\ttrain 11-115: Loss: 0.1378 Acc: 50.0000%\n",
      "\ttrain 11-116: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 11-117: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 11-118: Loss: 0.2067 Acc: 0.0000%\n",
      "\ttrain 11-119: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 11-120: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 11-121: Loss: 0.2153 Acc: 25.0000%\n",
      "\ttrain 11-122: Loss: 0.1944 Acc: 75.0000%\n",
      "\ttrain 11-123: Loss: 0.1972 Acc: 25.0000%\n",
      "\ttrain 11-124: Loss: 0.1087 Acc: 100.0000%\n",
      "\ttrain 11-125: Loss: 0.1906 Acc: 25.0000%\n",
      "\ttrain 11-126: Loss: 0.0985 Acc: 50.0000%\n",
      "\ttrain 11-127: Loss: 0.1569 Acc: 75.0000%\n",
      "\ttrain 11-128: Loss: 0.1407 Acc: 50.0000%\n",
      "\ttrain 11-129: Loss: 0.1506 Acc: 50.0000%\n",
      "\ttrain 11-130: Loss: 0.1281 Acc: 50.0000%\n",
      "\ttrain 11-131: Loss: 0.1368 Acc: 50.0000%\n",
      "\ttrain 11-132: Loss: 0.3605 Acc: 50.0000%\n",
      "\ttrain 11-133: Loss: 0.3824 Acc: 50.0000%\n",
      "\ttrain 11-134: Loss: 0.2970 Acc: 50.0000%\n",
      "\ttrain 11-135: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 11-136: Loss: 0.1978 Acc: 25.0000%\n",
      "\ttrain 11-137: Loss: 0.2042 Acc: 25.0000%\n",
      "\ttrain 11-138: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 11-139: Loss: 0.3946 Acc: 50.0000%\n",
      "\ttrain 11-140: Loss: 0.0955 Acc: 100.0000%\n",
      "\ttrain 11-141: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 11-142: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 11-143: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 11-144: Loss: 0.1849 Acc: 25.0000%\n",
      "\ttrain 11-145: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 11-146: Loss: 0.0644 Acc: 100.0000%\n",
      "\ttrain 11-147: Loss: 0.1677 Acc: 75.0000%\n",
      "\ttrain 11-148: Loss: 0.1680 Acc: 75.0000%\n",
      "\ttrain 11-149: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 11-150: Loss: 0.1013 Acc: 100.0000%\n",
      "\ttrain 11-151: Loss: 0.1314 Acc: 50.0000%\n",
      "\ttrain 11-152: Loss: 0.1492 Acc: 50.0000%\n",
      "\ttrain 11-153: Loss: 0.1342 Acc: 50.0000%\n",
      "\ttrain 11-154: Loss: 0.1772 Acc: 25.0000%\n",
      "\ttrain 11-155: Loss: 0.1273 Acc: 75.0000%\n",
      "\ttrain 11-156: Loss: 0.2021 Acc: 50.0000%\n",
      "\ttrain 11-157: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 11-158: Loss: 0.0974 Acc: 100.0000%\n",
      "\ttrain 11-159: Loss: 0.1684 Acc: 75.0000%\n",
      "\ttrain 11-160: Loss: 0.1322 Acc: 75.0000%\n",
      "\ttrain 11-161: Loss: 0.0683 Acc: 75.0000%\n",
      "\ttrain 11-162: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 11-163: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 11-164: Loss: 0.1010 Acc: 50.0000%\n",
      "\ttrain 11-165: Loss: 0.1548 Acc: 75.0000%\n",
      "\ttrain 11-166: Loss: 0.1680 Acc: 75.0000%\n",
      "\ttrain 11-167: Loss: 0.1357 Acc: 75.0000%\n",
      "\ttrain 11-168: Loss: 0.2260 Acc: 75.0000%\n",
      "\ttrain 11-169: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 11-170: Loss: 0.1264 Acc: 100.0000%\n",
      "\ttrain 11-171: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 11-172: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 11-173: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 11-174: Loss: 0.0848 Acc: 100.0000%\n",
      "\ttrain 11-175: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 11-176: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 11-177: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 11-178: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 11-179: Loss: 0.1198 Acc: 50.0000%\n",
      "\ttrain 11-180: Loss: 0.2251 Acc: 50.0000%\n",
      "\ttrain 11-181: Loss: 0.1670 Acc: 50.0000%\n",
      "\ttrain 11-182: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 11-183: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 11-184: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 11-185: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 11-186: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 11-187: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 11-188: Loss: 0.0767 Acc: 100.0000%\n",
      "\ttrain 11-189: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 11-190: Loss: 0.0999 Acc: 100.0000%\n",
      "\ttrain 11-191: Loss: 0.1086 Acc: 75.0000%\n",
      "\ttrain 11-192: Loss: 0.2182 Acc: 50.0000%\n",
      "\ttrain 11-193: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 11-194: Loss: 0.0784 Acc: 100.0000%\n",
      "\ttrain 11-195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 11-196: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 11-197: Loss: 0.1327 Acc: 50.0000%\n",
      "\ttrain 11-198: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 11-199: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 11-200: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 11-201: Loss: 0.0704 Acc: 100.0000%\n",
      "\ttrain 11-202: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 11-203: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 11-204: Loss: 0.0630 Acc: 75.0000%\n",
      "\ttrain 11-205: Loss: 0.2185 Acc: 25.0000%\n",
      "\ttrain 11-206: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 11-207: Loss: 0.2939 Acc: 25.0000%\n",
      "\ttrain 11-208: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 11-209: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 11-210: Loss: 0.1535 Acc: 50.0000%\n",
      "\ttrain 11-211: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 11-212: Loss: 0.1119 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 11-213: Loss: 0.4337 Acc: 25.0000%\n",
      "\ttrain 11-214: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 11-215: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 11-216: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 11-217: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 11-218: Loss: 0.1370 Acc: 25.0000%\n",
      "\ttrain 11-219: Loss: 0.0796 Acc: 100.0000%\n",
      "\ttrain 11-220: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 11-221: Loss: 0.1680 Acc: 50.0000%\n",
      "\ttrain 11-222: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 11-223: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 11-224: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 11-225: Loss: 0.1369 Acc: 50.0000%\n",
      "\ttrain 11-226: Loss: 0.0842 Acc: 100.0000%\n",
      "\ttrain 11-227: Loss: 0.2222 Acc: 50.0000%\n",
      "\ttrain 11-228: Loss: 0.1811 Acc: 75.0000%\n",
      "\ttrain 11-229: Loss: 0.0754 Acc: 100.0000%\n",
      "\ttrain 11-230: Loss: 0.2082 Acc: 50.0000%\n",
      "\ttrain 11-231: Loss: 0.1555 Acc: 50.0000%\n",
      "\ttrain 11-232: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 11-233: Loss: 0.1487 Acc: 50.0000%\n",
      "\ttrain 11-234: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 11-235: Loss: 0.1451 Acc: 50.0000%\n",
      "\ttrain 11-236: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 11-237: Loss: 0.1308 Acc: 50.0000%\n",
      "\ttrain 11-238: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 11-239: Loss: 0.4476 Acc: 25.0000%\n",
      "\ttrain 11-240: Loss: 0.3160 Acc: 50.0000%\n",
      "\ttrain 11-241: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 11-242: Loss: 0.1525 Acc: 25.0000%\n",
      "\ttrain 11-243: Loss: 0.1413 Acc: 75.0000%\n",
      "\ttrain 11-244: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 11-245: Loss: 0.0560 Acc: 75.0000%\n",
      "\tvalidation 11-1: Loss: 0.1282 Acc: 50.0000%\n",
      "\tvalidation 11-2: Loss: 0.0539 Acc: 75.0000%\n",
      "\tvalidation 11-3: Loss: 0.1339 Acc: 100.0000%\n",
      "\tvalidation 11-4: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 11-5: Loss: 0.1238 Acc: 75.0000%\n",
      "\tvalidation 11-6: Loss: 0.1453 Acc: 50.0000%\n",
      "\tvalidation 11-7: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 11-8: Loss: 0.1361 Acc: 100.0000%\n",
      "\tvalidation 11-9: Loss: 0.1416 Acc: 75.0000%\n",
      "\tvalidation 11-10: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 11-11: Loss: 0.0941 Acc: 100.0000%\n",
      "\tvalidation 11-12: Loss: 0.2504 Acc: 50.0000%\n",
      "\tvalidation 11-13: Loss: 0.1399 Acc: 100.0000%\n",
      "\tvalidation 11-14: Loss: 0.1000 Acc: 75.0000%\n",
      "\tvalidation 11-15: Loss: 0.0909 Acc: 100.0000%\n",
      "\tvalidation 11-16: Loss: 0.0937 Acc: 100.0000%\n",
      "\tvalidation 11-17: Loss: 0.1060 Acc: 75.0000%\n",
      "\tvalidation 11-18: Loss: 0.1377 Acc: 75.0000%\n",
      "\tvalidation 11-19: Loss: 0.1172 Acc: 75.0000%\n",
      "\tvalidation 11-20: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 11-21: Loss: 0.1007 Acc: 100.0000%\n",
      "\tvalidation 11-22: Loss: 0.1022 Acc: 75.0000%\n",
      "\tvalidation 11-23: Loss: 0.0978 Acc: 50.0000%\n",
      "\tvalidation 11-24: Loss: 0.1086 Acc: 100.0000%\n",
      "\tvalidation 11-25: Loss: 0.1432 Acc: 75.0000%\n",
      "\tvalidation 11-26: Loss: 0.1005 Acc: 75.0000%\n",
      "\tvalidation 11-27: Loss: 0.0934 Acc: 75.0000%\n",
      "\tvalidation 11-28: Loss: 0.0913 Acc: 100.0000%\n",
      "\tvalidation 11-29: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 11-30: Loss: 0.0648 Acc: 100.0000%\n",
      "\tvalidation 11-31: Loss: 0.1405 Acc: 75.0000%\n",
      "\tvalidation 11-32: Loss: 0.0518 Acc: 75.0000%\n",
      "\tvalidation 11-33: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 11-34: Loss: 0.2344 Acc: 50.0000%\n",
      "\tvalidation 11-35: Loss: 0.1558 Acc: 100.0000%\n",
      "\tvalidation 11-36: Loss: 0.0412 Acc: 100.0000%\n",
      "\tvalidation 11-37: Loss: 0.0458 Acc: 75.0000%\n",
      "\tvalidation 11-38: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 11-39: Loss: 0.1426 Acc: 25.0000%\n",
      "\tvalidation 11-40: Loss: 0.1454 Acc: 75.0000%\n",
      "\tvalidation 11-41: Loss: 0.0859 Acc: 100.0000%\n",
      "\tvalidation 11-42: Loss: 0.0406 Acc: 100.0000%\n",
      "\tvalidation 11-43: Loss: 0.0946 Acc: 75.0000%\n",
      "\tvalidation 11-44: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 11-45: Loss: 0.0496 Acc: 100.0000%\n",
      "\tvalidation 11-46: Loss: 0.1139 Acc: 50.0000%\n",
      "\tvalidation 11-47: Loss: 0.3101 Acc: 0.0000%\n",
      "\tvalidation 11-48: Loss: 0.0490 Acc: 75.0000%\n",
      "\tvalidation 11-49: Loss: 0.1026 Acc: 75.0000%\n",
      "\tvalidation 11-50: Loss: 0.0918 Acc: 75.0000%\n",
      "\tvalidation 11-51: Loss: 0.1359 Acc: 100.0000%\n",
      "\tvalidation 11-52: Loss: 0.0886 Acc: 100.0000%\n",
      "\tvalidation 11-53: Loss: 0.1000 Acc: 75.0000%\n",
      "\tvalidation 11-54: Loss: 0.0505 Acc: 100.0000%\n",
      "\tvalidation 11-55: Loss: 0.0923 Acc: 100.0000%\n",
      "\tvalidation 11-56: Loss: 0.1491 Acc: 75.0000%\n",
      "\tvalidation 11-57: Loss: 0.1486 Acc: 50.0000%\n",
      "\tvalidation 11-58: Loss: 0.1018 Acc: 75.0000%\n",
      "\tvalidation 11-59: Loss: 0.0565 Acc: 100.0000%\n",
      "\tvalidation 11-60: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 11-61: Loss: 0.0960 Acc: 100.0000%\n",
      "\tvalidation 11-62: Loss: 0.0959 Acc: 75.0000%\n",
      "\tvalidation 11-63: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 11-64: Loss: 0.0464 Acc: 75.0000%\n",
      "\tvalidation 11-65: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 11-66: Loss: 0.0945 Acc: 100.0000%\n",
      "\tvalidation 11-67: Loss: 0.0926 Acc: 100.0000%\n",
      "\tvalidation 11-68: Loss: 0.1068 Acc: 100.0000%\n",
      "\tvalidation 11-69: Loss: 0.0506 Acc: 100.0000%\n",
      "\tvalidation 11-70: Loss: 0.0692 Acc: 100.0000%\n",
      "\tvalidation 11-71: Loss: 0.0916 Acc: 50.0000%\n",
      "\tvalidation 11-72: Loss: 0.1466 Acc: 75.0000%\n",
      "\tvalidation 11-73: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 11-74: Loss: 0.0638 Acc: 75.0000%\n",
      "\tvalidation 11-75: Loss: 0.0515 Acc: 75.0000%\n",
      "\tvalidation 11-76: Loss: 0.1451 Acc: 50.0000%\n",
      "\tvalidation 11-77: Loss: 0.0927 Acc: 100.0000%\n",
      "\tvalidation 11-78: Loss: 0.1411 Acc: 75.0000%\n",
      "\tvalidation 11-79: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 11-80: Loss: 0.1868 Acc: 100.0000%\n",
      "\tvalidation 11-81: Loss: 0.1585 Acc: 100.0000%\n",
      "\tvalidation 11-82: Loss: 0.0998 Acc: 100.0000%\n",
      "\tvalidation 11-83: Loss: 0.1609 Acc: 50.0000%\n",
      "\tvalidation 11-84: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 11-85: Loss: 0.1033 Acc: 50.0000%\n",
      "\tvalidation 11-86: Loss: 0.0944 Acc: 75.0000%\n",
      "\tvalidation 11-87: Loss: 0.1037 Acc: 50.0000%\n",
      "\tvalidation 11-88: Loss: 0.1033 Acc: 100.0000%\n",
      "\tvalidation 11-89: Loss: 0.1658 Acc: 50.0000%\n",
      "\tvalidation 11-90: Loss: 0.1365 Acc: 75.0000%\n",
      "\tvalidation 11-91: Loss: 0.1082 Acc: 75.0000%\n",
      "\tvalidation 11-92: Loss: 0.0931 Acc: 75.0000%\n",
      "\tvalidation 11-93: Loss: 0.0963 Acc: 75.0000%\n",
      "\tvalidation 11-94: Loss: 0.1398 Acc: 75.0000%\n",
      "\tvalidation 11-95: Loss: 0.1346 Acc: 75.0000%\n",
      "\tvalidation 11-96: Loss: 0.0902 Acc: 100.0000%\n",
      "\tvalidation 11-97: Loss: 0.0873 Acc: 75.0000%\n",
      "\tvalidation 11-98: Loss: 0.1508 Acc: 50.0000%\n",
      "\tvalidation 11-99: Loss: 0.0924 Acc: 100.0000%\n",
      "\tvalidation 11-100: Loss: 0.0553 Acc: 100.0000%\n",
      "\tvalidation 11-101: Loss: 0.0933 Acc: 75.0000%\n",
      "\tvalidation 11-102: Loss: 0.0907 Acc: 75.0000%\n",
      "\tvalidation 11-103: Loss: 0.1030 Acc: 50.0000%\n",
      "\tvalidation 11-104: Loss: 0.1410 Acc: 75.0000%\n",
      "\tvalidation 11-105: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1181 Acc: 72.8571%\n",
      "\tvalidation Loss: 0.1025 Acc: 80.4762%\n",
      "网络参数更新\n",
      "Time passed 0h 7m 36s\n",
      "--------------------\n",
      "Epoch [12/40]:\n",
      "\ttrain 12-1: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 12-2: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 12-3: Loss: 0.1264 Acc: 100.0000%\n",
      "\ttrain 12-4: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 12-5: Loss: 0.0944 Acc: 100.0000%\n",
      "\ttrain 12-6: Loss: 0.1952 Acc: 75.0000%\n",
      "\ttrain 12-7: Loss: 0.1670 Acc: 50.0000%\n",
      "\ttrain 12-8: Loss: 0.1639 Acc: 50.0000%\n",
      "\ttrain 12-9: Loss: 0.1519 Acc: 100.0000%\n",
      "\ttrain 12-10: Loss: 0.0992 Acc: 75.0000%\n",
      "\ttrain 12-11: Loss: 0.0988 Acc: 100.0000%\n",
      "\ttrain 12-12: Loss: 0.1172 Acc: 100.0000%\n",
      "\ttrain 12-13: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 12-14: Loss: 0.0531 Acc: 75.0000%\n",
      "\ttrain 12-15: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 12-16: Loss: 0.1274 Acc: 100.0000%\n",
      "\ttrain 12-17: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 12-18: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 12-19: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 12-20: Loss: 0.1540 Acc: 50.0000%\n",
      "\ttrain 12-21: Loss: 0.1229 Acc: 75.0000%\n",
      "\ttrain 12-22: Loss: 0.1641 Acc: 50.0000%\n",
      "\ttrain 12-23: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 12-24: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 12-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 12-26: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 12-27: Loss: 0.1859 Acc: 75.0000%\n",
      "\ttrain 12-28: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 12-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 12-30: Loss: 0.1075 Acc: 75.0000%\n",
      "\ttrain 12-31: Loss: 0.1525 Acc: 50.0000%\n",
      "\ttrain 12-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 12-33: Loss: 0.1192 Acc: 50.0000%\n",
      "\ttrain 12-34: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 12-35: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 12-36: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 12-37: Loss: 0.0446 Acc: 75.0000%\n",
      "\ttrain 12-38: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 12-39: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 12-40: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 12-41: Loss: 0.1941 Acc: 75.0000%\n",
      "\ttrain 12-42: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 12-43: Loss: 0.3169 Acc: 50.0000%\n",
      "\ttrain 12-44: Loss: 0.0839 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-45: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 12-46: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 12-47: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 12-48: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 12-49: Loss: 0.0882 Acc: 100.0000%\n",
      "\ttrain 12-50: Loss: 0.1394 Acc: 50.0000%\n",
      "\ttrain 12-51: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 12-52: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 12-53: Loss: 0.2443 Acc: 50.0000%\n",
      "\ttrain 12-54: Loss: 0.1538 Acc: 50.0000%\n",
      "\ttrain 12-55: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 12-56: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 12-57: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 12-58: Loss: 0.1249 Acc: 75.0000%\n",
      "\ttrain 12-59: Loss: 0.2336 Acc: 50.0000%\n",
      "\ttrain 12-60: Loss: 0.1631 Acc: 50.0000%\n",
      "\ttrain 12-61: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 12-62: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 12-63: Loss: 0.0711 Acc: 75.0000%\n",
      "\ttrain 12-64: Loss: 0.0760 Acc: 100.0000%\n",
      "\ttrain 12-65: Loss: 0.0464 Acc: 75.0000%\n",
      "\ttrain 12-66: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 12-67: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 12-68: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 12-69: Loss: 0.3330 Acc: 75.0000%\n",
      "\ttrain 12-70: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 12-71: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 12-72: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 12-73: Loss: 0.3588 Acc: 50.0000%\n",
      "\ttrain 12-74: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 12-75: Loss: 0.0868 Acc: 75.0000%\n",
      "\ttrain 12-76: Loss: 0.0911 Acc: 100.0000%\n",
      "\ttrain 12-77: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 12-78: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 12-79: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 12-80: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 12-81: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 12-82: Loss: 0.1487 Acc: 75.0000%\n",
      "\ttrain 12-83: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 12-84: Loss: 0.1696 Acc: 50.0000%\n",
      "\ttrain 12-85: Loss: 0.1778 Acc: 25.0000%\n",
      "\ttrain 12-86: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 12-87: Loss: 0.0463 Acc: 75.0000%\n",
      "\ttrain 12-88: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 12-89: Loss: 0.0576 Acc: 75.0000%\n",
      "\ttrain 12-90: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 12-91: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 12-92: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 12-93: Loss: 0.1038 Acc: 50.0000%\n",
      "\ttrain 12-94: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 12-95: Loss: 0.0770 Acc: 100.0000%\n",
      "\ttrain 12-96: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 12-97: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 12-98: Loss: 0.1114 Acc: 50.0000%\n",
      "\ttrain 12-99: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 12-100: Loss: 0.4347 Acc: 50.0000%\n",
      "\ttrain 12-101: Loss: 0.0947 Acc: 75.0000%\n",
      "\ttrain 12-102: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 12-103: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 12-104: Loss: 0.0954 Acc: 100.0000%\n",
      "\ttrain 12-105: Loss: 0.1038 Acc: 50.0000%\n",
      "\ttrain 12-106: Loss: 0.1184 Acc: 100.0000%\n",
      "\ttrain 12-107: Loss: 0.1550 Acc: 50.0000%\n",
      "\ttrain 12-108: Loss: 0.3113 Acc: 75.0000%\n",
      "\ttrain 12-109: Loss: 0.1342 Acc: 75.0000%\n",
      "\ttrain 12-110: Loss: 0.2449 Acc: 50.0000%\n",
      "\ttrain 12-111: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 12-112: Loss: 0.1063 Acc: 100.0000%\n",
      "\ttrain 12-113: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 12-114: Loss: 0.1315 Acc: 75.0000%\n",
      "\ttrain 12-115: Loss: 0.1499 Acc: 75.0000%\n",
      "\ttrain 12-116: Loss: 0.1613 Acc: 75.0000%\n",
      "\ttrain 12-117: Loss: 0.2091 Acc: 50.0000%\n",
      "\ttrain 12-118: Loss: 0.4210 Acc: 50.0000%\n",
      "\ttrain 12-119: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 12-120: Loss: 0.1283 Acc: 100.0000%\n",
      "\ttrain 12-121: Loss: 0.2630 Acc: 50.0000%\n",
      "\ttrain 12-122: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 12-123: Loss: 0.1816 Acc: 25.0000%\n",
      "\ttrain 12-124: Loss: 0.1734 Acc: 75.0000%\n",
      "\ttrain 12-125: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 12-126: Loss: 0.4200 Acc: 50.0000%\n",
      "\ttrain 12-127: Loss: 0.0991 Acc: 100.0000%\n",
      "\ttrain 12-128: Loss: 0.3066 Acc: 75.0000%\n",
      "\ttrain 12-129: Loss: 0.1098 Acc: 50.0000%\n",
      "\ttrain 12-130: Loss: 0.1554 Acc: 75.0000%\n",
      "\ttrain 12-131: Loss: 0.1093 Acc: 100.0000%\n",
      "\ttrain 12-132: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 12-133: Loss: 0.1147 Acc: 50.0000%\n",
      "\ttrain 12-134: Loss: 0.2925 Acc: 50.0000%\n",
      "\ttrain 12-135: Loss: 0.1071 Acc: 75.0000%\n",
      "\ttrain 12-136: Loss: 0.1664 Acc: 75.0000%\n",
      "\ttrain 12-137: Loss: 0.1119 Acc: 50.0000%\n",
      "\ttrain 12-138: Loss: 0.0926 Acc: 75.0000%\n",
      "\ttrain 12-139: Loss: 0.1117 Acc: 50.0000%\n",
      "\ttrain 12-140: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 12-141: Loss: 0.1708 Acc: 100.0000%\n",
      "\ttrain 12-142: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 12-143: Loss: 0.0522 Acc: 75.0000%\n",
      "\ttrain 12-144: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 12-145: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 12-146: Loss: 0.0766 Acc: 100.0000%\n",
      "\ttrain 12-147: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 12-148: Loss: 0.1317 Acc: 50.0000%\n",
      "\ttrain 12-149: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 12-150: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 12-151: Loss: 0.1920 Acc: 50.0000%\n",
      "\ttrain 12-152: Loss: 0.1155 Acc: 75.0000%\n",
      "\ttrain 12-153: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 12-154: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 12-155: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 12-156: Loss: 0.0442 Acc: 75.0000%\n",
      "\ttrain 12-157: Loss: 0.1596 Acc: 50.0000%\n",
      "\ttrain 12-158: Loss: 0.1074 Acc: 100.0000%\n",
      "\ttrain 12-159: Loss: 0.1045 Acc: 75.0000%\n",
      "\ttrain 12-160: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 12-161: Loss: 0.1520 Acc: 75.0000%\n",
      "\ttrain 12-162: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 12-163: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 12-164: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 12-165: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 12-166: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 12-167: Loss: 0.1284 Acc: 50.0000%\n",
      "\ttrain 12-168: Loss: 0.0703 Acc: 100.0000%\n",
      "\ttrain 12-169: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 12-170: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 12-171: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 12-172: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 12-173: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 12-174: Loss: 0.2007 Acc: 50.0000%\n",
      "\ttrain 12-175: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 12-176: Loss: 0.1565 Acc: 50.0000%\n",
      "\ttrain 12-177: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 12-178: Loss: 0.2085 Acc: 50.0000%\n",
      "\ttrain 12-179: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 12-180: Loss: 0.1994 Acc: 25.0000%\n",
      "\ttrain 12-181: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 12-182: Loss: 0.0999 Acc: 50.0000%\n",
      "\ttrain 12-183: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 12-184: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 12-185: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 12-186: Loss: 0.1498 Acc: 50.0000%\n",
      "\ttrain 12-187: Loss: 0.0448 Acc: 75.0000%\n",
      "\ttrain 12-188: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 12-189: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 12-190: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 12-191: Loss: 0.2923 Acc: 50.0000%\n",
      "\ttrain 12-192: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 12-193: Loss: 0.0825 Acc: 75.0000%\n",
      "\ttrain 12-194: Loss: 0.1847 Acc: 50.0000%\n",
      "\ttrain 12-195: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 12-196: Loss: 0.0889 Acc: 100.0000%\n",
      "\ttrain 12-197: Loss: 0.0996 Acc: 50.0000%\n",
      "\ttrain 12-198: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 12-199: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 12-200: Loss: 0.1445 Acc: 100.0000%\n",
      "\ttrain 12-201: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 12-202: Loss: 0.1191 Acc: 100.0000%\n",
      "\ttrain 12-203: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 12-204: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 12-205: Loss: 0.1383 Acc: 50.0000%\n",
      "\ttrain 12-206: Loss: 0.0674 Acc: 100.0000%\n",
      "\ttrain 12-207: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 12-208: Loss: 0.0974 Acc: 75.0000%\n",
      "\ttrain 12-209: Loss: 0.1111 Acc: 100.0000%\n",
      "\ttrain 12-210: Loss: 0.1064 Acc: 75.0000%\n",
      "\ttrain 12-211: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain 12-212: Loss: 0.1602 Acc: 75.0000%\n",
      "\ttrain 12-213: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 12-214: Loss: 0.2934 Acc: 50.0000%\n",
      "\ttrain 12-215: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 12-216: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 12-217: Loss: 0.1708 Acc: 50.0000%\n",
      "\ttrain 12-218: Loss: 0.1357 Acc: 50.0000%\n",
      "\ttrain 12-219: Loss: 0.0888 Acc: 100.0000%\n",
      "\ttrain 12-220: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 12-221: Loss: 0.3809 Acc: 50.0000%\n",
      "\ttrain 12-222: Loss: 0.0807 Acc: 100.0000%\n",
      "\ttrain 12-223: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 12-224: Loss: 0.1763 Acc: 50.0000%\n",
      "\ttrain 12-225: Loss: 0.0900 Acc: 100.0000%\n",
      "\ttrain 12-226: Loss: 0.1342 Acc: 75.0000%\n",
      "\ttrain 12-227: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 12-228: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 12-229: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 12-230: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 12-231: Loss: 0.2148 Acc: 25.0000%\n",
      "\ttrain 12-232: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 12-233: Loss: 0.1400 Acc: 50.0000%\n",
      "\ttrain 12-234: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 12-235: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 12-236: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 12-237: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 12-238: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 12-239: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 12-240: Loss: 0.0419 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 12-241: Loss: 0.1259 Acc: 50.0000%\n",
      "\ttrain 12-242: Loss: 0.1017 Acc: 75.0000%\n",
      "\ttrain 12-243: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 12-244: Loss: 0.0462 Acc: 75.0000%\n",
      "\ttrain 12-245: Loss: 0.2000 Acc: 50.0000%\n",
      "\tvalidation 12-1: Loss: 0.3069 Acc: 75.0000%\n",
      "\tvalidation 12-2: Loss: 0.0610 Acc: 100.0000%\n",
      "\tvalidation 12-3: Loss: 0.0654 Acc: 100.0000%\n",
      "\tvalidation 12-4: Loss: 0.0648 Acc: 100.0000%\n",
      "\tvalidation 12-5: Loss: 0.1666 Acc: 75.0000%\n",
      "\tvalidation 12-6: Loss: 0.4347 Acc: 75.0000%\n",
      "\tvalidation 12-7: Loss: 0.0573 Acc: 100.0000%\n",
      "\tvalidation 12-8: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 12-9: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 12-10: Loss: 0.0723 Acc: 75.0000%\n",
      "\tvalidation 12-11: Loss: 0.0818 Acc: 100.0000%\n",
      "\tvalidation 12-12: Loss: 0.1055 Acc: 50.0000%\n",
      "\tvalidation 12-13: Loss: 0.2566 Acc: 50.0000%\n",
      "\tvalidation 12-14: Loss: 0.1163 Acc: 100.0000%\n",
      "\tvalidation 12-15: Loss: 0.1938 Acc: 75.0000%\n",
      "\tvalidation 12-16: Loss: 0.0928 Acc: 75.0000%\n",
      "\tvalidation 12-17: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 12-18: Loss: 0.0987 Acc: 50.0000%\n",
      "\tvalidation 12-19: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 12-20: Loss: 0.0552 Acc: 100.0000%\n",
      "\tvalidation 12-21: Loss: 0.0378 Acc: 100.0000%\n",
      "\tvalidation 12-22: Loss: 0.0735 Acc: 100.0000%\n",
      "\tvalidation 12-23: Loss: 0.1593 Acc: 75.0000%\n",
      "\tvalidation 12-24: Loss: 0.1440 Acc: 75.0000%\n",
      "\tvalidation 12-25: Loss: 0.0910 Acc: 75.0000%\n",
      "\tvalidation 12-26: Loss: 0.1654 Acc: 50.0000%\n",
      "\tvalidation 12-27: Loss: 0.0594 Acc: 100.0000%\n",
      "\tvalidation 12-28: Loss: 0.0499 Acc: 100.0000%\n",
      "\tvalidation 12-29: Loss: 0.0923 Acc: 75.0000%\n",
      "\tvalidation 12-30: Loss: 0.0463 Acc: 75.0000%\n",
      "\tvalidation 12-31: Loss: 0.0691 Acc: 75.0000%\n",
      "\tvalidation 12-32: Loss: 0.0750 Acc: 75.0000%\n",
      "\tvalidation 12-33: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 12-34: Loss: 0.0981 Acc: 100.0000%\n",
      "\tvalidation 12-35: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 12-36: Loss: 0.0447 Acc: 75.0000%\n",
      "\tvalidation 12-37: Loss: 0.0711 Acc: 100.0000%\n",
      "\tvalidation 12-38: Loss: 0.0849 Acc: 75.0000%\n",
      "\tvalidation 12-39: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 12-40: Loss: 0.1356 Acc: 75.0000%\n",
      "\tvalidation 12-41: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 12-42: Loss: 0.1440 Acc: 75.0000%\n",
      "\tvalidation 12-43: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 12-44: Loss: 0.1325 Acc: 75.0000%\n",
      "\tvalidation 12-45: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 12-46: Loss: 0.0942 Acc: 75.0000%\n",
      "\tvalidation 12-47: Loss: 0.0697 Acc: 100.0000%\n",
      "\tvalidation 12-48: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 12-49: Loss: 0.1997 Acc: 75.0000%\n",
      "\tvalidation 12-50: Loss: 0.0674 Acc: 75.0000%\n",
      "\tvalidation 12-51: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 12-52: Loss: 0.1311 Acc: 50.0000%\n",
      "\tvalidation 12-53: Loss: 0.1132 Acc: 75.0000%\n",
      "\tvalidation 12-54: Loss: 0.0981 Acc: 75.0000%\n",
      "\tvalidation 12-55: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 12-56: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 12-57: Loss: 0.1367 Acc: 50.0000%\n",
      "\tvalidation 12-58: Loss: 0.0902 Acc: 75.0000%\n",
      "\tvalidation 12-59: Loss: 0.0955 Acc: 100.0000%\n",
      "\tvalidation 12-60: Loss: 0.0974 Acc: 75.0000%\n",
      "\tvalidation 12-61: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 12-62: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 12-63: Loss: 0.1047 Acc: 100.0000%\n",
      "\tvalidation 12-64: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 12-65: Loss: 0.0798 Acc: 75.0000%\n",
      "\tvalidation 12-66: Loss: 0.0965 Acc: 100.0000%\n",
      "\tvalidation 12-67: Loss: 0.0834 Acc: 100.0000%\n",
      "\tvalidation 12-68: Loss: 0.0876 Acc: 75.0000%\n",
      "\tvalidation 12-69: Loss: 0.0557 Acc: 100.0000%\n",
      "\tvalidation 12-70: Loss: 0.0652 Acc: 100.0000%\n",
      "\tvalidation 12-71: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 12-72: Loss: 0.0745 Acc: 100.0000%\n",
      "\tvalidation 12-73: Loss: 0.0268 Acc: 100.0000%\n",
      "\tvalidation 12-74: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 12-75: Loss: 0.0769 Acc: 100.0000%\n",
      "\tvalidation 12-76: Loss: 0.0924 Acc: 75.0000%\n",
      "\tvalidation 12-77: Loss: 0.1014 Acc: 100.0000%\n",
      "\tvalidation 12-78: Loss: 0.1703 Acc: 50.0000%\n",
      "\tvalidation 12-79: Loss: 0.0757 Acc: 75.0000%\n",
      "\tvalidation 12-80: Loss: 0.0499 Acc: 75.0000%\n",
      "\tvalidation 12-81: Loss: 0.0655 Acc: 100.0000%\n",
      "\tvalidation 12-82: Loss: 0.0865 Acc: 100.0000%\n",
      "\tvalidation 12-83: Loss: 0.0870 Acc: 75.0000%\n",
      "\tvalidation 12-84: Loss: 0.0583 Acc: 75.0000%\n",
      "\tvalidation 12-85: Loss: 0.0830 Acc: 75.0000%\n",
      "\tvalidation 12-86: Loss: 0.0782 Acc: 100.0000%\n",
      "\tvalidation 12-87: Loss: 0.0899 Acc: 75.0000%\n",
      "\tvalidation 12-88: Loss: 0.0928 Acc: 100.0000%\n",
      "\tvalidation 12-89: Loss: 0.0901 Acc: 100.0000%\n",
      "\tvalidation 12-90: Loss: 0.0488 Acc: 100.0000%\n",
      "\tvalidation 12-91: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 12-92: Loss: 0.2004 Acc: 50.0000%\n",
      "\tvalidation 12-93: Loss: 0.1028 Acc: 75.0000%\n",
      "\tvalidation 12-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 12-95: Loss: 0.0882 Acc: 100.0000%\n",
      "\tvalidation 12-96: Loss: 0.0812 Acc: 75.0000%\n",
      "\tvalidation 12-97: Loss: 0.0652 Acc: 100.0000%\n",
      "\tvalidation 12-98: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 12-99: Loss: 0.1425 Acc: 75.0000%\n",
      "\tvalidation 12-100: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 12-101: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 12-102: Loss: 0.1026 Acc: 75.0000%\n",
      "\tvalidation 12-103: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 12-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 12-105: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1095 Acc: 78.3673%\n",
      "\tvalidation Loss: 0.0836 Acc: 87.1429%\n",
      "网络参数更新\n",
      "Time passed 0h 8m 23s\n",
      "--------------------\n",
      "Epoch [13/40]:\n",
      "\ttrain 13-1: Loss: 0.1828 Acc: 50.0000%\n",
      "\ttrain 13-2: Loss: 0.1827 Acc: 50.0000%\n",
      "\ttrain 13-3: Loss: 0.0906 Acc: 100.0000%\n",
      "\ttrain 13-4: Loss: 0.1682 Acc: 75.0000%\n",
      "\ttrain 13-5: Loss: 0.1222 Acc: 50.0000%\n",
      "\ttrain 13-6: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 13-7: Loss: 0.0655 Acc: 100.0000%\n",
      "\ttrain 13-8: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 13-9: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 13-10: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 13-11: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 13-12: Loss: 0.2708 Acc: 50.0000%\n",
      "\ttrain 13-13: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 13-14: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 13-15: Loss: 0.2057 Acc: 25.0000%\n",
      "\ttrain 13-16: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 13-17: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 13-18: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 13-19: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 13-20: Loss: 0.0594 Acc: 75.0000%\n",
      "\ttrain 13-21: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 13-22: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 13-23: Loss: 0.1669 Acc: 50.0000%\n",
      "\ttrain 13-24: Loss: 0.1171 Acc: 75.0000%\n",
      "\ttrain 13-25: Loss: 0.1289 Acc: 50.0000%\n",
      "\ttrain 13-26: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 13-27: Loss: 0.1543 Acc: 50.0000%\n",
      "\ttrain 13-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-29: Loss: 0.0517 Acc: 75.0000%\n",
      "\ttrain 13-30: Loss: 0.1135 Acc: 100.0000%\n",
      "\ttrain 13-31: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 13-32: Loss: 0.1826 Acc: 50.0000%\n",
      "\ttrain 13-33: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 13-34: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 13-35: Loss: 0.1461 Acc: 75.0000%\n",
      "\ttrain 13-36: Loss: 0.2738 Acc: 50.0000%\n",
      "\ttrain 13-37: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 13-38: Loss: 0.1348 Acc: 50.0000%\n",
      "\ttrain 13-39: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 13-40: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 13-41: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 13-42: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 13-43: Loss: 0.3593 Acc: 75.0000%\n",
      "\ttrain 13-44: Loss: 0.1185 Acc: 50.0000%\n",
      "\ttrain 13-45: Loss: 0.0585 Acc: 100.0000%\n",
      "\ttrain 13-46: Loss: 0.1096 Acc: 100.0000%\n",
      "\ttrain 13-47: Loss: 0.2560 Acc: 75.0000%\n",
      "\ttrain 13-48: Loss: 0.0663 Acc: 100.0000%\n",
      "\ttrain 13-49: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 13-50: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 13-51: Loss: 0.1239 Acc: 50.0000%\n",
      "\ttrain 13-52: Loss: 0.0634 Acc: 100.0000%\n",
      "\ttrain 13-53: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 13-54: Loss: 0.1560 Acc: 50.0000%\n",
      "\ttrain 13-55: Loss: 0.1344 Acc: 100.0000%\n",
      "\ttrain 13-56: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 13-57: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 13-58: Loss: 0.0626 Acc: 100.0000%\n",
      "\ttrain 13-59: Loss: 0.1994 Acc: 50.0000%\n",
      "\ttrain 13-60: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 13-61: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 13-62: Loss: 0.1486 Acc: 50.0000%\n",
      "\ttrain 13-63: Loss: 0.2000 Acc: 50.0000%\n",
      "\ttrain 13-64: Loss: 0.3636 Acc: 0.0000%\n",
      "\ttrain 13-65: Loss: 0.1608 Acc: 25.0000%\n",
      "\ttrain 13-66: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 13-67: Loss: 0.0488 Acc: 75.0000%\n",
      "\ttrain 13-68: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 13-69: Loss: 0.1032 Acc: 50.0000%\n",
      "\ttrain 13-70: Loss: 0.0825 Acc: 100.0000%\n",
      "\ttrain 13-71: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 13-72: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 13-73: Loss: 0.0562 Acc: 75.0000%\n",
      "\ttrain 13-74: Loss: 0.1190 Acc: 75.0000%\n",
      "\ttrain 13-75: Loss: 0.0315 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 13-76: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 13-77: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 13-78: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 13-79: Loss: 0.1288 Acc: 75.0000%\n",
      "\ttrain 13-80: Loss: 0.0964 Acc: 75.0000%\n",
      "\ttrain 13-81: Loss: 0.1088 Acc: 100.0000%\n",
      "\ttrain 13-82: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 13-83: Loss: 0.0964 Acc: 100.0000%\n",
      "\ttrain 13-84: Loss: 0.1198 Acc: 75.0000%\n",
      "\ttrain 13-85: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 13-86: Loss: 0.1453 Acc: 50.0000%\n",
      "\ttrain 13-87: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 13-88: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 13-89: Loss: 0.1820 Acc: 75.0000%\n",
      "\ttrain 13-90: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 13-91: Loss: 0.1229 Acc: 50.0000%\n",
      "\ttrain 13-92: Loss: 0.1326 Acc: 100.0000%\n",
      "\ttrain 13-93: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 13-94: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 13-95: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 13-96: Loss: 0.1981 Acc: 50.0000%\n",
      "\ttrain 13-97: Loss: 0.0814 Acc: 100.0000%\n",
      "\ttrain 13-98: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 13-99: Loss: 0.1023 Acc: 100.0000%\n",
      "\ttrain 13-100: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 13-101: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 13-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-103: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 13-104: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 13-105: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 13-106: Loss: 0.3052 Acc: 75.0000%\n",
      "\ttrain 13-107: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 13-108: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 13-109: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 13-110: Loss: 0.1781 Acc: 75.0000%\n",
      "\ttrain 13-111: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 13-112: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 13-113: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 13-114: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 13-115: Loss: 0.2081 Acc: 50.0000%\n",
      "\ttrain 13-116: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 13-117: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 13-118: Loss: 0.3137 Acc: 50.0000%\n",
      "\ttrain 13-119: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 13-120: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 13-121: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 13-122: Loss: 0.2407 Acc: 50.0000%\n",
      "\ttrain 13-123: Loss: 0.1179 Acc: 50.0000%\n",
      "\ttrain 13-124: Loss: 0.3445 Acc: 75.0000%\n",
      "\ttrain 13-125: Loss: 0.2978 Acc: 25.0000%\n",
      "\ttrain 13-126: Loss: 0.0408 Acc: 100.0000%\n",
      "\ttrain 13-127: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 13-128: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 13-129: Loss: 0.1035 Acc: 75.0000%\n",
      "\ttrain 13-130: Loss: 0.2274 Acc: 50.0000%\n",
      "\ttrain 13-131: Loss: 0.2024 Acc: 50.0000%\n",
      "\ttrain 13-132: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 13-133: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 13-134: Loss: 0.1532 Acc: 50.0000%\n",
      "\ttrain 13-135: Loss: 0.1091 Acc: 100.0000%\n",
      "\ttrain 13-136: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 13-137: Loss: 0.1575 Acc: 50.0000%\n",
      "\ttrain 13-138: Loss: 0.1679 Acc: 50.0000%\n",
      "\ttrain 13-139: Loss: 0.1295 Acc: 50.0000%\n",
      "\ttrain 13-140: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 13-141: Loss: 0.0959 Acc: 75.0000%\n",
      "\ttrain 13-142: Loss: 0.0927 Acc: 75.0000%\n",
      "\ttrain 13-143: Loss: 0.1180 Acc: 100.0000%\n",
      "\ttrain 13-144: Loss: 0.0521 Acc: 100.0000%\n",
      "\ttrain 13-145: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 13-146: Loss: 0.1062 Acc: 75.0000%\n",
      "\ttrain 13-147: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 13-148: Loss: 0.0608 Acc: 75.0000%\n",
      "\ttrain 13-149: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 13-150: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 13-151: Loss: 0.2391 Acc: 25.0000%\n",
      "\ttrain 13-152: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 13-153: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 13-154: Loss: 0.1227 Acc: 50.0000%\n",
      "\ttrain 13-155: Loss: 0.1390 Acc: 50.0000%\n",
      "\ttrain 13-156: Loss: 0.1730 Acc: 25.0000%\n",
      "\ttrain 13-157: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 13-158: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 13-159: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 13-160: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 13-161: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 13-162: Loss: 0.1899 Acc: 50.0000%\n",
      "\ttrain 13-163: Loss: 0.2426 Acc: 25.0000%\n",
      "\ttrain 13-164: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 13-165: Loss: 0.1371 Acc: 75.0000%\n",
      "\ttrain 13-166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 13-167: Loss: 0.2205 Acc: 75.0000%\n",
      "\ttrain 13-168: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 13-169: Loss: 0.2477 Acc: 50.0000%\n",
      "\ttrain 13-170: Loss: 0.1222 Acc: 50.0000%\n",
      "\ttrain 13-171: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 13-172: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 13-173: Loss: 0.1048 Acc: 50.0000%\n",
      "\ttrain 13-174: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 13-175: Loss: 0.1653 Acc: 100.0000%\n",
      "\ttrain 13-176: Loss: 0.1284 Acc: 50.0000%\n",
      "\ttrain 13-177: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 13-178: Loss: 0.1214 Acc: 100.0000%\n",
      "\ttrain 13-179: Loss: 0.1042 Acc: 75.0000%\n",
      "\ttrain 13-180: Loss: 0.0546 Acc: 75.0000%\n",
      "\ttrain 13-181: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 13-182: Loss: 0.1268 Acc: 50.0000%\n",
      "\ttrain 13-183: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 13-184: Loss: 0.1146 Acc: 75.0000%\n",
      "\ttrain 13-185: Loss: 0.1882 Acc: 50.0000%\n",
      "\ttrain 13-186: Loss: 0.1595 Acc: 50.0000%\n",
      "\ttrain 13-187: Loss: 0.2170 Acc: 50.0000%\n",
      "\ttrain 13-188: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 13-189: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 13-190: Loss: 0.0747 Acc: 100.0000%\n",
      "\ttrain 13-191: Loss: 0.0920 Acc: 75.0000%\n",
      "\ttrain 13-192: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 13-193: Loss: 0.1700 Acc: 75.0000%\n",
      "\ttrain 13-194: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 13-195: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 13-196: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 13-197: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 13-198: Loss: 0.0947 Acc: 100.0000%\n",
      "\ttrain 13-199: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 13-200: Loss: 0.1068 Acc: 100.0000%\n",
      "\ttrain 13-201: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 13-202: Loss: 0.1847 Acc: 50.0000%\n",
      "\ttrain 13-203: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 13-204: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 13-205: Loss: 0.2288 Acc: 50.0000%\n",
      "\ttrain 13-206: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 13-207: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 13-208: Loss: 0.1817 Acc: 75.0000%\n",
      "\ttrain 13-209: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 13-210: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 13-211: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 13-212: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 13-213: Loss: 0.0844 Acc: 100.0000%\n",
      "\ttrain 13-214: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 13-215: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 13-216: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 13-217: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 13-218: Loss: 0.0685 Acc: 100.0000%\n",
      "\ttrain 13-219: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 13-220: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 13-221: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 13-222: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 13-223: Loss: 0.3030 Acc: 50.0000%\n",
      "\ttrain 13-224: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 13-225: Loss: 0.1739 Acc: 25.0000%\n",
      "\ttrain 13-226: Loss: 0.0743 Acc: 100.0000%\n",
      "\ttrain 13-227: Loss: 0.2443 Acc: 50.0000%\n",
      "\ttrain 13-228: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 13-229: Loss: 0.1466 Acc: 50.0000%\n",
      "\ttrain 13-230: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 13-231: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 13-232: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 13-233: Loss: 0.5198 Acc: 0.0000%\n",
      "\ttrain 13-234: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 13-235: Loss: 0.1773 Acc: 75.0000%\n",
      "\ttrain 13-236: Loss: 0.2340 Acc: 25.0000%\n",
      "\ttrain 13-237: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 13-238: Loss: 0.1677 Acc: 50.0000%\n",
      "\ttrain 13-239: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 13-240: Loss: 0.1628 Acc: 75.0000%\n",
      "\ttrain 13-241: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 13-242: Loss: 0.0751 Acc: 75.0000%\n",
      "\ttrain 13-243: Loss: 0.0741 Acc: 75.0000%\n",
      "\ttrain 13-244: Loss: 0.0649 Acc: 75.0000%\n",
      "\ttrain 13-245: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 13-1: Loss: 0.1454 Acc: 50.0000%\n",
      "\tvalidation 13-2: Loss: 0.1458 Acc: 50.0000%\n",
      "\tvalidation 13-3: Loss: 0.0979 Acc: 75.0000%\n",
      "\tvalidation 13-4: Loss: 0.1275 Acc: 75.0000%\n",
      "\tvalidation 13-5: Loss: 0.0575 Acc: 100.0000%\n",
      "\tvalidation 13-6: Loss: 0.2530 Acc: 50.0000%\n",
      "\tvalidation 13-7: Loss: 0.1149 Acc: 75.0000%\n",
      "\tvalidation 13-8: Loss: 0.1215 Acc: 75.0000%\n",
      "\tvalidation 13-9: Loss: 0.1202 Acc: 75.0000%\n",
      "\tvalidation 13-10: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 13-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-12: Loss: 0.1242 Acc: 75.0000%\n",
      "\tvalidation 13-13: Loss: 0.0563 Acc: 75.0000%\n",
      "\tvalidation 13-14: Loss: 0.0485 Acc: 100.0000%\n",
      "\tvalidation 13-15: Loss: 0.6392 Acc: 25.0000%\n",
      "\tvalidation 13-16: Loss: 0.4546 Acc: 25.0000%\n",
      "\tvalidation 13-17: Loss: 0.2082 Acc: 50.0000%\n",
      "\tvalidation 13-18: Loss: 0.1624 Acc: 50.0000%\n",
      "\tvalidation 13-19: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 13-20: Loss: 0.4246 Acc: 50.0000%\n",
      "\tvalidation 13-21: Loss: 0.1140 Acc: 75.0000%\n",
      "\tvalidation 13-22: Loss: 0.1366 Acc: 75.0000%\n",
      "\tvalidation 13-23: Loss: 0.2262 Acc: 50.0000%\n",
      "\tvalidation 13-24: Loss: 0.1168 Acc: 75.0000%\n",
      "\tvalidation 13-25: Loss: 0.0570 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 13-26: Loss: 0.2202 Acc: 50.0000%\n",
      "\tvalidation 13-27: Loss: 0.2094 Acc: 75.0000%\n",
      "\tvalidation 13-28: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 13-29: Loss: 0.3390 Acc: 25.0000%\n",
      "\tvalidation 13-30: Loss: 0.4420 Acc: 0.0000%\n",
      "\tvalidation 13-31: Loss: 0.1303 Acc: 75.0000%\n",
      "\tvalidation 13-32: Loss: 0.2308 Acc: 50.0000%\n",
      "\tvalidation 13-33: Loss: 0.0989 Acc: 75.0000%\n",
      "\tvalidation 13-34: Loss: 0.1048 Acc: 75.0000%\n",
      "\tvalidation 13-35: Loss: 0.3008 Acc: 50.0000%\n",
      "\tvalidation 13-36: Loss: 0.0779 Acc: 100.0000%\n",
      "\tvalidation 13-37: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 13-38: Loss: 0.0306 Acc: 100.0000%\n",
      "\tvalidation 13-39: Loss: 0.0778 Acc: 100.0000%\n",
      "\tvalidation 13-40: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 13-41: Loss: 0.0634 Acc: 75.0000%\n",
      "\tvalidation 13-42: Loss: 0.1855 Acc: 75.0000%\n",
      "\tvalidation 13-43: Loss: 0.0870 Acc: 75.0000%\n",
      "\tvalidation 13-44: Loss: 0.0598 Acc: 75.0000%\n",
      "\tvalidation 13-45: Loss: 0.1384 Acc: 50.0000%\n",
      "\tvalidation 13-46: Loss: 0.0788 Acc: 75.0000%\n",
      "\tvalidation 13-47: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 13-48: Loss: 0.0756 Acc: 100.0000%\n",
      "\tvalidation 13-49: Loss: 0.0883 Acc: 75.0000%\n",
      "\tvalidation 13-50: Loss: 0.1430 Acc: 75.0000%\n",
      "\tvalidation 13-51: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 13-52: Loss: 0.0706 Acc: 75.0000%\n",
      "\tvalidation 13-53: Loss: 0.1379 Acc: 75.0000%\n",
      "\tvalidation 13-54: Loss: 0.1576 Acc: 50.0000%\n",
      "\tvalidation 13-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-56: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 13-57: Loss: 0.2833 Acc: 75.0000%\n",
      "\tvalidation 13-58: Loss: 0.1288 Acc: 50.0000%\n",
      "\tvalidation 13-59: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 13-60: Loss: 0.0815 Acc: 75.0000%\n",
      "\tvalidation 13-61: Loss: 0.2018 Acc: 75.0000%\n",
      "\tvalidation 13-62: Loss: 0.1616 Acc: 50.0000%\n",
      "\tvalidation 13-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 13-64: Loss: 0.1916 Acc: 50.0000%\n",
      "\tvalidation 13-65: Loss: 0.5760 Acc: 50.0000%\n",
      "\tvalidation 13-66: Loss: 0.2409 Acc: 50.0000%\n",
      "\tvalidation 13-67: Loss: 0.1800 Acc: 50.0000%\n",
      "\tvalidation 13-68: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-69: Loss: 0.2143 Acc: 50.0000%\n",
      "\tvalidation 13-70: Loss: 0.1856 Acc: 75.0000%\n",
      "\tvalidation 13-71: Loss: 0.2185 Acc: 25.0000%\n",
      "\tvalidation 13-72: Loss: 0.1995 Acc: 50.0000%\n",
      "\tvalidation 13-73: Loss: 0.2520 Acc: 50.0000%\n",
      "\tvalidation 13-74: Loss: 0.3752 Acc: 0.0000%\n",
      "\tvalidation 13-75: Loss: 0.2842 Acc: 25.0000%\n",
      "\tvalidation 13-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-77: Loss: 0.3565 Acc: 50.0000%\n",
      "\tvalidation 13-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-79: Loss: 0.2497 Acc: 75.0000%\n",
      "\tvalidation 13-80: Loss: 0.1368 Acc: 75.0000%\n",
      "\tvalidation 13-81: Loss: 0.2735 Acc: 25.0000%\n",
      "\tvalidation 13-82: Loss: 0.1008 Acc: 75.0000%\n",
      "\tvalidation 13-83: Loss: 0.2246 Acc: 25.0000%\n",
      "\tvalidation 13-84: Loss: 0.1857 Acc: 50.0000%\n",
      "\tvalidation 13-85: Loss: 0.3009 Acc: 50.0000%\n",
      "\tvalidation 13-86: Loss: 0.0634 Acc: 75.0000%\n",
      "\tvalidation 13-87: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 13-88: Loss: 0.3243 Acc: 50.0000%\n",
      "\tvalidation 13-89: Loss: 0.4833 Acc: 50.0000%\n",
      "\tvalidation 13-90: Loss: 0.1053 Acc: 100.0000%\n",
      "\tvalidation 13-91: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 13-92: Loss: 0.0711 Acc: 75.0000%\n",
      "\tvalidation 13-93: Loss: 0.2972 Acc: 25.0000%\n",
      "\tvalidation 13-94: Loss: 0.0847 Acc: 75.0000%\n",
      "\tvalidation 13-95: Loss: 0.0918 Acc: 75.0000%\n",
      "\tvalidation 13-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 13-97: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 13-98: Loss: 0.2152 Acc: 50.0000%\n",
      "\tvalidation 13-99: Loss: 0.2074 Acc: 50.0000%\n",
      "\tvalidation 13-100: Loss: 0.0677 Acc: 75.0000%\n",
      "\tvalidation 13-101: Loss: 0.1240 Acc: 75.0000%\n",
      "\tvalidation 13-102: Loss: 0.2503 Acc: 25.0000%\n",
      "\tvalidation 13-103: Loss: 0.2973 Acc: 25.0000%\n",
      "\tvalidation 13-104: Loss: 0.1744 Acc: 50.0000%\n",
      "\tvalidation 13-105: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain Loss: 0.1059 Acc: 78.3673%\n",
      "\tvalidation Loss: 0.1554 Acc: 68.0952%\n",
      "Time passed 0h 9m 6s\n",
      "--------------------\n",
      "Epoch [14/40]:\n",
      "\ttrain 14-1: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 14-2: Loss: 0.1917 Acc: 50.0000%\n",
      "\ttrain 14-3: Loss: 0.2343 Acc: 25.0000%\n",
      "\ttrain 14-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 14-5: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 14-6: Loss: 0.2506 Acc: 50.0000%\n",
      "\ttrain 14-7: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 14-8: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 14-9: Loss: 0.1779 Acc: 50.0000%\n",
      "\ttrain 14-10: Loss: 0.1674 Acc: 50.0000%\n",
      "\ttrain 14-11: Loss: 0.1518 Acc: 50.0000%\n",
      "\ttrain 14-12: Loss: 0.1158 Acc: 100.0000%\n",
      "\ttrain 14-13: Loss: 0.0771 Acc: 100.0000%\n",
      "\ttrain 14-14: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 14-15: Loss: 0.1435 Acc: 50.0000%\n",
      "\ttrain 14-16: Loss: 0.2586 Acc: 25.0000%\n",
      "\ttrain 14-17: Loss: 0.1859 Acc: 75.0000%\n",
      "\ttrain 14-18: Loss: 0.1087 Acc: 100.0000%\n",
      "\ttrain 14-19: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 14-20: Loss: 0.1909 Acc: 50.0000%\n",
      "\ttrain 14-21: Loss: 0.1027 Acc: 50.0000%\n",
      "\ttrain 14-22: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 14-23: Loss: 0.0827 Acc: 100.0000%\n",
      "\ttrain 14-24: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 14-25: Loss: 0.4652 Acc: 75.0000%\n",
      "\ttrain 14-26: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 14-27: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 14-28: Loss: 0.1551 Acc: 50.0000%\n",
      "\ttrain 14-29: Loss: 0.1163 Acc: 100.0000%\n",
      "\ttrain 14-30: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 14-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 14-32: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 14-33: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 14-34: Loss: 0.2013 Acc: 50.0000%\n",
      "\ttrain 14-35: Loss: 0.1211 Acc: 100.0000%\n",
      "\ttrain 14-36: Loss: 0.0463 Acc: 75.0000%\n",
      "\ttrain 14-37: Loss: 0.1027 Acc: 50.0000%\n",
      "\ttrain 14-38: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 14-39: Loss: 0.1162 Acc: 50.0000%\n",
      "\ttrain 14-40: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 14-41: Loss: 0.1214 Acc: 75.0000%\n",
      "\ttrain 14-42: Loss: 0.1038 Acc: 50.0000%\n",
      "\ttrain 14-43: Loss: 0.2372 Acc: 50.0000%\n",
      "\ttrain 14-44: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 14-45: Loss: 0.1356 Acc: 100.0000%\n",
      "\ttrain 14-46: Loss: 0.0943 Acc: 50.0000%\n",
      "\ttrain 14-47: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 14-48: Loss: 0.1243 Acc: 75.0000%\n",
      "\ttrain 14-49: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 14-50: Loss: 0.1092 Acc: 100.0000%\n",
      "\ttrain 14-51: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 14-52: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 14-53: Loss: 0.1593 Acc: 25.0000%\n",
      "\ttrain 14-54: Loss: 0.3222 Acc: 50.0000%\n",
      "\ttrain 14-55: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 14-56: Loss: 0.1976 Acc: 50.0000%\n",
      "\ttrain 14-57: Loss: 0.3103 Acc: 50.0000%\n",
      "\ttrain 14-58: Loss: 0.0483 Acc: 75.0000%\n",
      "\ttrain 14-59: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 14-60: Loss: 0.1965 Acc: 50.0000%\n",
      "\ttrain 14-61: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 14-62: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 14-63: Loss: 0.0728 Acc: 75.0000%\n",
      "\ttrain 14-64: Loss: 0.0991 Acc: 100.0000%\n",
      "\ttrain 14-65: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 14-66: Loss: 0.0942 Acc: 100.0000%\n",
      "\ttrain 14-67: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 14-68: Loss: 0.1193 Acc: 100.0000%\n",
      "\ttrain 14-69: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 14-70: Loss: 0.1306 Acc: 50.0000%\n",
      "\ttrain 14-71: Loss: 0.0458 Acc: 75.0000%\n",
      "\ttrain 14-72: Loss: 0.1160 Acc: 50.0000%\n",
      "\ttrain 14-73: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 14-74: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 14-75: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 14-76: Loss: 0.1111 Acc: 50.0000%\n",
      "\ttrain 14-77: Loss: 0.0921 Acc: 100.0000%\n",
      "\ttrain 14-78: Loss: 0.2959 Acc: 25.0000%\n",
      "\ttrain 14-79: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 14-80: Loss: 0.0967 Acc: 100.0000%\n",
      "\ttrain 14-81: Loss: 0.0491 Acc: 75.0000%\n",
      "\ttrain 14-82: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 14-83: Loss: 0.2646 Acc: 25.0000%\n",
      "\ttrain 14-84: Loss: 0.1838 Acc: 75.0000%\n",
      "\ttrain 14-85: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 14-86: Loss: 0.1637 Acc: 50.0000%\n",
      "\ttrain 14-87: Loss: 0.0787 Acc: 100.0000%\n",
      "\ttrain 14-88: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 14-89: Loss: 0.2052 Acc: 50.0000%\n",
      "\ttrain 14-90: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 14-91: Loss: 0.0929 Acc: 75.0000%\n",
      "\ttrain 14-92: Loss: 0.1426 Acc: 50.0000%\n",
      "\ttrain 14-93: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 14-94: Loss: 0.1111 Acc: 75.0000%\n",
      "\ttrain 14-95: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 14-96: Loss: 0.0842 Acc: 75.0000%\n",
      "\ttrain 14-97: Loss: 0.0539 Acc: 75.0000%\n",
      "\ttrain 14-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 14-99: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 14-100: Loss: 0.1411 Acc: 50.0000%\n",
      "\ttrain 14-101: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 14-102: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 14-103: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 14-104: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 14-105: Loss: 0.5853 Acc: 25.0000%\n",
      "\ttrain 14-106: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 14-107: Loss: 0.0624 Acc: 100.0000%\n",
      "\ttrain 14-108: Loss: 0.1113 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 14-109: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 14-110: Loss: 0.4995 Acc: 50.0000%\n",
      "\ttrain 14-111: Loss: 0.2067 Acc: 75.0000%\n",
      "\ttrain 14-112: Loss: 0.2298 Acc: 25.0000%\n",
      "\ttrain 14-113: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 14-114: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 14-115: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 14-116: Loss: 0.1139 Acc: 50.0000%\n",
      "\ttrain 14-117: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 14-118: Loss: 0.1183 Acc: 100.0000%\n",
      "\ttrain 14-119: Loss: 0.2537 Acc: 50.0000%\n",
      "\ttrain 14-120: Loss: 0.1274 Acc: 75.0000%\n",
      "\ttrain 14-121: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 14-122: Loss: 0.1110 Acc: 100.0000%\n",
      "\ttrain 14-123: Loss: 0.1060 Acc: 100.0000%\n",
      "\ttrain 14-124: Loss: 0.0897 Acc: 100.0000%\n",
      "\ttrain 14-125: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 14-126: Loss: 0.0823 Acc: 100.0000%\n",
      "\ttrain 14-127: Loss: 0.1714 Acc: 50.0000%\n",
      "\ttrain 14-128: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 14-129: Loss: 0.1107 Acc: 50.0000%\n",
      "\ttrain 14-130: Loss: 0.1727 Acc: 50.0000%\n",
      "\ttrain 14-131: Loss: 0.0805 Acc: 100.0000%\n",
      "\ttrain 14-132: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 14-133: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 14-134: Loss: 0.0513 Acc: 75.0000%\n",
      "\ttrain 14-135: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 14-136: Loss: 0.0725 Acc: 100.0000%\n",
      "\ttrain 14-137: Loss: 0.1790 Acc: 25.0000%\n",
      "\ttrain 14-138: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 14-139: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 14-140: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 14-141: Loss: 0.1087 Acc: 100.0000%\n",
      "\ttrain 14-142: Loss: 0.0761 Acc: 75.0000%\n",
      "\ttrain 14-143: Loss: 0.1198 Acc: 100.0000%\n",
      "\ttrain 14-144: Loss: 0.1021 Acc: 75.0000%\n",
      "\ttrain 14-145: Loss: 0.1230 Acc: 50.0000%\n",
      "\ttrain 14-146: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 14-147: Loss: 0.1166 Acc: 50.0000%\n",
      "\ttrain 14-148: Loss: 0.1250 Acc: 75.0000%\n",
      "\ttrain 14-149: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 14-150: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 14-151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 14-152: Loss: 0.1300 Acc: 75.0000%\n",
      "\ttrain 14-153: Loss: 0.2613 Acc: 50.0000%\n",
      "\ttrain 14-154: Loss: 0.1111 Acc: 50.0000%\n",
      "\ttrain 14-155: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 14-156: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 14-157: Loss: 0.1093 Acc: 100.0000%\n",
      "\ttrain 14-158: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 14-159: Loss: 0.1819 Acc: 50.0000%\n",
      "\ttrain 14-160: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 14-161: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 14-162: Loss: 0.1130 Acc: 75.0000%\n",
      "\ttrain 14-163: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 14-164: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 14-165: Loss: 0.1163 Acc: 75.0000%\n",
      "\ttrain 14-166: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 14-167: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 14-168: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 14-169: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 14-170: Loss: 0.0788 Acc: 100.0000%\n",
      "\ttrain 14-171: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 14-172: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 14-173: Loss: 0.1224 Acc: 50.0000%\n",
      "\ttrain 14-174: Loss: 0.2044 Acc: 50.0000%\n",
      "\ttrain 14-175: Loss: 0.1267 Acc: 75.0000%\n",
      "\ttrain 14-176: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 14-177: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 14-178: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 14-179: Loss: 0.1677 Acc: 75.0000%\n",
      "\ttrain 14-180: Loss: 0.4370 Acc: 50.0000%\n",
      "\ttrain 14-181: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 14-182: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 14-183: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 14-184: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 14-185: Loss: 0.1280 Acc: 50.0000%\n",
      "\ttrain 14-186: Loss: 0.0444 Acc: 75.0000%\n",
      "\ttrain 14-187: Loss: 0.3126 Acc: 25.0000%\n",
      "\ttrain 14-188: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 14-189: Loss: 0.3016 Acc: 25.0000%\n",
      "\ttrain 14-190: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 14-191: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 14-192: Loss: 0.1013 Acc: 50.0000%\n",
      "\ttrain 14-193: Loss: 0.0809 Acc: 75.0000%\n",
      "\ttrain 14-194: Loss: 0.0886 Acc: 100.0000%\n",
      "\ttrain 14-195: Loss: 0.2057 Acc: 25.0000%\n",
      "\ttrain 14-196: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 14-197: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 14-198: Loss: 0.1292 Acc: 50.0000%\n",
      "\ttrain 14-199: Loss: 0.1853 Acc: 50.0000%\n",
      "\ttrain 14-200: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 14-201: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 14-202: Loss: 0.1728 Acc: 50.0000%\n",
      "\ttrain 14-203: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 14-204: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 14-205: Loss: 0.1242 Acc: 50.0000%\n",
      "\ttrain 14-206: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 14-207: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 14-208: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 14-209: Loss: 0.1839 Acc: 50.0000%\n",
      "\ttrain 14-210: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 14-211: Loss: 0.1557 Acc: 50.0000%\n",
      "\ttrain 14-212: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 14-213: Loss: 0.0681 Acc: 75.0000%\n",
      "\ttrain 14-214: Loss: 0.1173 Acc: 75.0000%\n",
      "\ttrain 14-215: Loss: 0.1470 Acc: 50.0000%\n",
      "\ttrain 14-216: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 14-217: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 14-218: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 14-219: Loss: 0.0750 Acc: 100.0000%\n",
      "\ttrain 14-220: Loss: 0.1528 Acc: 50.0000%\n",
      "\ttrain 14-221: Loss: 0.0774 Acc: 100.0000%\n",
      "\ttrain 14-222: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 14-223: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 14-224: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 14-225: Loss: 0.2378 Acc: 25.0000%\n",
      "\ttrain 14-226: Loss: 0.1490 Acc: 75.0000%\n",
      "\ttrain 14-227: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 14-228: Loss: 0.0598 Acc: 75.0000%\n",
      "\ttrain 14-229: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 14-230: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 14-231: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 14-232: Loss: 0.1198 Acc: 50.0000%\n",
      "\ttrain 14-233: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 14-234: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 14-235: Loss: 0.2406 Acc: 25.0000%\n",
      "\ttrain 14-236: Loss: 0.2651 Acc: 50.0000%\n",
      "\ttrain 14-237: Loss: 0.1620 Acc: 50.0000%\n",
      "\ttrain 14-238: Loss: 0.1527 Acc: 50.0000%\n",
      "\ttrain 14-239: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 14-240: Loss: 0.2442 Acc: 50.0000%\n",
      "\ttrain 14-241: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 14-242: Loss: 0.1970 Acc: 50.0000%\n",
      "\ttrain 14-243: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 14-244: Loss: 0.1374 Acc: 75.0000%\n",
      "\ttrain 14-245: Loss: 0.0894 Acc: 50.0000%\n",
      "\tvalidation 14-1: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 14-2: Loss: 0.1055 Acc: 50.0000%\n",
      "\tvalidation 14-3: Loss: 0.0455 Acc: 75.0000%\n",
      "\tvalidation 14-4: Loss: 0.0683 Acc: 100.0000%\n",
      "\tvalidation 14-5: Loss: 0.0807 Acc: 75.0000%\n",
      "\tvalidation 14-6: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 14-7: Loss: 0.1391 Acc: 75.0000%\n",
      "\tvalidation 14-8: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 14-9: Loss: 0.0648 Acc: 100.0000%\n",
      "\tvalidation 14-10: Loss: 0.1390 Acc: 50.0000%\n",
      "\tvalidation 14-11: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 14-12: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 14-13: Loss: 0.0808 Acc: 75.0000%\n",
      "\tvalidation 14-14: Loss: 0.0647 Acc: 100.0000%\n",
      "\tvalidation 14-15: Loss: 0.0901 Acc: 75.0000%\n",
      "\tvalidation 14-16: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 14-17: Loss: 0.1268 Acc: 50.0000%\n",
      "\tvalidation 14-18: Loss: 0.1380 Acc: 50.0000%\n",
      "\tvalidation 14-19: Loss: 0.0595 Acc: 100.0000%\n",
      "\tvalidation 14-20: Loss: 0.0848 Acc: 100.0000%\n",
      "\tvalidation 14-21: Loss: 0.0762 Acc: 100.0000%\n",
      "\tvalidation 14-22: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 14-23: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 14-24: Loss: 0.0613 Acc: 100.0000%\n",
      "\tvalidation 14-25: Loss: 0.0792 Acc: 75.0000%\n",
      "\tvalidation 14-26: Loss: 0.0603 Acc: 75.0000%\n",
      "\tvalidation 14-27: Loss: 0.0484 Acc: 75.0000%\n",
      "\tvalidation 14-28: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 14-29: Loss: 0.0583 Acc: 100.0000%\n",
      "\tvalidation 14-30: Loss: 0.1069 Acc: 50.0000%\n",
      "\tvalidation 14-31: Loss: 0.0761 Acc: 75.0000%\n",
      "\tvalidation 14-32: Loss: 0.1230 Acc: 75.0000%\n",
      "\tvalidation 14-33: Loss: 0.1198 Acc: 75.0000%\n",
      "\tvalidation 14-34: Loss: 0.1250 Acc: 50.0000%\n",
      "\tvalidation 14-35: Loss: 0.0533 Acc: 75.0000%\n",
      "\tvalidation 14-36: Loss: 0.0904 Acc: 75.0000%\n",
      "\tvalidation 14-37: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 14-38: Loss: 0.1091 Acc: 100.0000%\n",
      "\tvalidation 14-39: Loss: 0.0635 Acc: 100.0000%\n",
      "\tvalidation 14-40: Loss: 0.1542 Acc: 75.0000%\n",
      "\tvalidation 14-41: Loss: 0.0472 Acc: 100.0000%\n",
      "\tvalidation 14-42: Loss: 0.0783 Acc: 100.0000%\n",
      "\tvalidation 14-43: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 14-44: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 14-45: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 14-46: Loss: 0.0472 Acc: 75.0000%\n",
      "\tvalidation 14-47: Loss: 0.1249 Acc: 75.0000%\n",
      "\tvalidation 14-48: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 14-49: Loss: 0.1549 Acc: 25.0000%\n",
      "\tvalidation 14-50: Loss: 0.0970 Acc: 100.0000%\n",
      "\tvalidation 14-51: Loss: 0.0510 Acc: 75.0000%\n",
      "\tvalidation 14-52: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 14-53: Loss: 0.1311 Acc: 75.0000%\n",
      "\tvalidation 14-54: Loss: 0.0918 Acc: 100.0000%\n",
      "\tvalidation 14-55: Loss: 0.1259 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 14-56: Loss: 0.0848 Acc: 75.0000%\n",
      "\tvalidation 14-57: Loss: 0.0574 Acc: 75.0000%\n",
      "\tvalidation 14-58: Loss: 0.1232 Acc: 75.0000%\n",
      "\tvalidation 14-59: Loss: 0.1309 Acc: 50.0000%\n",
      "\tvalidation 14-60: Loss: 0.0287 Acc: 100.0000%\n",
      "\tvalidation 14-61: Loss: 0.0640 Acc: 100.0000%\n",
      "\tvalidation 14-62: Loss: 0.0786 Acc: 75.0000%\n",
      "\tvalidation 14-63: Loss: 0.0995 Acc: 50.0000%\n",
      "\tvalidation 14-64: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 14-65: Loss: 0.1232 Acc: 75.0000%\n",
      "\tvalidation 14-66: Loss: 0.1754 Acc: 50.0000%\n",
      "\tvalidation 14-67: Loss: 0.0630 Acc: 100.0000%\n",
      "\tvalidation 14-68: Loss: 0.1101 Acc: 75.0000%\n",
      "\tvalidation 14-69: Loss: 0.1039 Acc: 75.0000%\n",
      "\tvalidation 14-70: Loss: 0.1097 Acc: 50.0000%\n",
      "\tvalidation 14-71: Loss: 0.0740 Acc: 100.0000%\n",
      "\tvalidation 14-72: Loss: 0.0735 Acc: 75.0000%\n",
      "\tvalidation 14-73: Loss: 0.0771 Acc: 100.0000%\n",
      "\tvalidation 14-74: Loss: 0.1054 Acc: 75.0000%\n",
      "\tvalidation 14-75: Loss: 0.1564 Acc: 25.0000%\n",
      "\tvalidation 14-76: Loss: 0.0874 Acc: 75.0000%\n",
      "\tvalidation 14-77: Loss: 0.0543 Acc: 75.0000%\n",
      "\tvalidation 14-78: Loss: 0.1497 Acc: 50.0000%\n",
      "\tvalidation 14-79: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 14-80: Loss: 0.1900 Acc: 50.0000%\n",
      "\tvalidation 14-81: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 14-82: Loss: 0.0858 Acc: 100.0000%\n",
      "\tvalidation 14-83: Loss: 0.1376 Acc: 100.0000%\n",
      "\tvalidation 14-84: Loss: 0.0769 Acc: 100.0000%\n",
      "\tvalidation 14-85: Loss: 0.1600 Acc: 50.0000%\n",
      "\tvalidation 14-86: Loss: 0.0966 Acc: 50.0000%\n",
      "\tvalidation 14-87: Loss: 0.1796 Acc: 25.0000%\n",
      "\tvalidation 14-88: Loss: 0.0508 Acc: 75.0000%\n",
      "\tvalidation 14-89: Loss: 0.1996 Acc: 25.0000%\n",
      "\tvalidation 14-90: Loss: 0.0892 Acc: 50.0000%\n",
      "\tvalidation 14-91: Loss: 0.0676 Acc: 100.0000%\n",
      "\tvalidation 14-92: Loss: 0.0578 Acc: 100.0000%\n",
      "\tvalidation 14-93: Loss: 0.0501 Acc: 75.0000%\n",
      "\tvalidation 14-94: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 14-95: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 14-96: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 14-97: Loss: 0.1132 Acc: 100.0000%\n",
      "\tvalidation 14-98: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 14-99: Loss: 0.0968 Acc: 75.0000%\n",
      "\tvalidation 14-100: Loss: 0.0629 Acc: 100.0000%\n",
      "\tvalidation 14-101: Loss: 0.1207 Acc: 75.0000%\n",
      "\tvalidation 14-102: Loss: 0.0600 Acc: 75.0000%\n",
      "\tvalidation 14-103: Loss: 0.0811 Acc: 75.0000%\n",
      "\tvalidation 14-104: Loss: 0.1244 Acc: 75.0000%\n",
      "\tvalidation 14-105: Loss: 0.0705 Acc: 100.0000%\n",
      "\ttrain Loss: 0.1126 Acc: 75.8163%\n",
      "\tvalidation Loss: 0.0816 Acc: 80.7143%\n",
      "Time passed 0h 9m 45s\n",
      "--------------------\n",
      "Epoch [15/40]:\n",
      "\ttrain 15-1: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 15-2: Loss: 0.1229 Acc: 100.0000%\n",
      "\ttrain 15-3: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 15-4: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 15-5: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 15-6: Loss: 0.0968 Acc: 100.0000%\n",
      "\ttrain 15-7: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 15-8: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 15-9: Loss: 0.1148 Acc: 100.0000%\n",
      "\ttrain 15-10: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 15-11: Loss: 0.1361 Acc: 50.0000%\n",
      "\ttrain 15-12: Loss: 0.1647 Acc: 50.0000%\n",
      "\ttrain 15-13: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 15-14: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 15-15: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 15-16: Loss: 0.0645 Acc: 100.0000%\n",
      "\ttrain 15-17: Loss: 0.0640 Acc: 75.0000%\n",
      "\ttrain 15-18: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 15-19: Loss: 0.2797 Acc: 50.0000%\n",
      "\ttrain 15-20: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 15-21: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 15-22: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 15-23: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 15-24: Loss: 0.1921 Acc: 25.0000%\n",
      "\ttrain 15-25: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 15-26: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 15-27: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 15-28: Loss: 0.1164 Acc: 50.0000%\n",
      "\ttrain 15-29: Loss: 0.1401 Acc: 50.0000%\n",
      "\ttrain 15-30: Loss: 0.1326 Acc: 75.0000%\n",
      "\ttrain 15-31: Loss: 0.0746 Acc: 75.0000%\n",
      "\ttrain 15-32: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 15-33: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 15-34: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 15-35: Loss: 0.1842 Acc: 50.0000%\n",
      "\ttrain 15-36: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 15-37: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 15-38: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 15-39: Loss: 0.2308 Acc: 75.0000%\n",
      "\ttrain 15-40: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 15-41: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 15-42: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 15-43: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 15-44: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 15-45: Loss: 0.1902 Acc: 50.0000%\n",
      "\ttrain 15-46: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 15-47: Loss: 0.0642 Acc: 75.0000%\n",
      "\ttrain 15-48: Loss: 0.1323 Acc: 50.0000%\n",
      "\ttrain 15-49: Loss: 0.2200 Acc: 75.0000%\n",
      "\ttrain 15-50: Loss: 0.0795 Acc: 100.0000%\n",
      "\ttrain 15-51: Loss: 0.1350 Acc: 100.0000%\n",
      "\ttrain 15-52: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 15-53: Loss: 0.1498 Acc: 50.0000%\n",
      "\ttrain 15-54: Loss: 0.0863 Acc: 100.0000%\n",
      "\ttrain 15-55: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 15-56: Loss: 0.1518 Acc: 75.0000%\n",
      "\ttrain 15-57: Loss: 0.1049 Acc: 100.0000%\n",
      "\ttrain 15-58: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 15-59: Loss: 0.1089 Acc: 100.0000%\n",
      "\ttrain 15-60: Loss: 0.1381 Acc: 50.0000%\n",
      "\ttrain 15-61: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 15-62: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 15-63: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 15-64: Loss: 0.1816 Acc: 75.0000%\n",
      "\ttrain 15-65: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 15-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 15-67: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 15-68: Loss: 0.1349 Acc: 50.0000%\n",
      "\ttrain 15-69: Loss: 0.1362 Acc: 75.0000%\n",
      "\ttrain 15-70: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 15-71: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 15-72: Loss: 0.0966 Acc: 100.0000%\n",
      "\ttrain 15-73: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 15-74: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 15-75: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 15-76: Loss: 0.2415 Acc: 50.0000%\n",
      "\ttrain 15-77: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 15-78: Loss: 0.5840 Acc: 50.0000%\n",
      "\ttrain 15-79: Loss: 0.1591 Acc: 75.0000%\n",
      "\ttrain 15-80: Loss: 0.1480 Acc: 75.0000%\n",
      "\ttrain 15-81: Loss: 0.0976 Acc: 75.0000%\n",
      "\ttrain 15-82: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 15-83: Loss: 0.1076 Acc: 100.0000%\n",
      "\ttrain 15-84: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 15-85: Loss: 0.2386 Acc: 50.0000%\n",
      "\ttrain 15-86: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 15-87: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 15-88: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 15-89: Loss: 0.1162 Acc: 75.0000%\n",
      "\ttrain 15-90: Loss: 0.0893 Acc: 75.0000%\n",
      "\ttrain 15-91: Loss: 0.0604 Acc: 75.0000%\n",
      "\ttrain 15-92: Loss: 0.0864 Acc: 75.0000%\n",
      "\ttrain 15-93: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 15-94: Loss: 0.0610 Acc: 100.0000%\n",
      "\ttrain 15-95: Loss: 0.1844 Acc: 75.0000%\n",
      "\ttrain 15-96: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 15-97: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 15-98: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 15-99: Loss: 0.1326 Acc: 75.0000%\n",
      "\ttrain 15-100: Loss: 0.2257 Acc: 50.0000%\n",
      "\ttrain 15-101: Loss: 0.1895 Acc: 75.0000%\n",
      "\ttrain 15-102: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 15-103: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 15-104: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 15-105: Loss: 0.1057 Acc: 75.0000%\n",
      "\ttrain 15-106: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 15-107: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 15-108: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 15-109: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 15-110: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 15-111: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 15-112: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 15-113: Loss: 0.0704 Acc: 100.0000%\n",
      "\ttrain 15-114: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 15-115: Loss: 0.1674 Acc: 50.0000%\n",
      "\ttrain 15-116: Loss: 0.1415 Acc: 50.0000%\n",
      "\ttrain 15-117: Loss: 0.0849 Acc: 100.0000%\n",
      "\ttrain 15-118: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 15-119: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 15-120: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 15-121: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 15-122: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 15-123: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 15-124: Loss: 0.1299 Acc: 50.0000%\n",
      "\ttrain 15-125: Loss: 0.1438 Acc: 100.0000%\n",
      "\ttrain 15-126: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 15-127: Loss: 0.1150 Acc: 50.0000%\n",
      "\ttrain 15-128: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 15-129: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 15-130: Loss: 0.1295 Acc: 75.0000%\n",
      "\ttrain 15-131: Loss: 0.0993 Acc: 75.0000%\n",
      "\ttrain 15-132: Loss: 0.1929 Acc: 50.0000%\n",
      "\ttrain 15-133: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 15-134: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 15-135: Loss: 0.2095 Acc: 50.0000%\n",
      "\ttrain 15-136: Loss: 0.4565 Acc: 50.0000%\n",
      "\ttrain 15-137: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 15-138: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 15-139: Loss: 0.0722 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 15-140: Loss: 0.1168 Acc: 75.0000%\n",
      "\ttrain 15-141: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 15-142: Loss: 0.0687 Acc: 100.0000%\n",
      "\ttrain 15-143: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 15-144: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 15-145: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 15-146: Loss: 0.1746 Acc: 75.0000%\n",
      "\ttrain 15-147: Loss: 0.1127 Acc: 75.0000%\n",
      "\ttrain 15-148: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 15-149: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 15-150: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 15-151: Loss: 0.0473 Acc: 75.0000%\n",
      "\ttrain 15-152: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 15-153: Loss: 0.1372 Acc: 75.0000%\n",
      "\ttrain 15-154: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 15-155: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 15-156: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 15-157: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 15-158: Loss: 0.0681 Acc: 100.0000%\n",
      "\ttrain 15-159: Loss: 0.1526 Acc: 75.0000%\n",
      "\ttrain 15-160: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 15-161: Loss: 0.0527 Acc: 100.0000%\n",
      "\ttrain 15-162: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 15-163: Loss: 0.2316 Acc: 50.0000%\n",
      "\ttrain 15-164: Loss: 0.2079 Acc: 50.0000%\n",
      "\ttrain 15-165: Loss: 0.0721 Acc: 100.0000%\n",
      "\ttrain 15-166: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 15-167: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 15-168: Loss: 0.1101 Acc: 100.0000%\n",
      "\ttrain 15-169: Loss: 0.7217 Acc: 75.0000%\n",
      "\ttrain 15-170: Loss: 0.1497 Acc: 75.0000%\n",
      "\ttrain 15-171: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 15-172: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 15-173: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 15-174: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 15-175: Loss: 0.1228 Acc: 75.0000%\n",
      "\ttrain 15-176: Loss: 0.2171 Acc: 50.0000%\n",
      "\ttrain 15-177: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 15-178: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 15-179: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 15-180: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 15-181: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 15-182: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 15-183: Loss: 0.3287 Acc: 50.0000%\n",
      "\ttrain 15-184: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 15-185: Loss: 0.0800 Acc: 100.0000%\n",
      "\ttrain 15-186: Loss: 0.1264 Acc: 75.0000%\n",
      "\ttrain 15-187: Loss: 0.0936 Acc: 75.0000%\n",
      "\ttrain 15-188: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 15-189: Loss: 0.2517 Acc: 25.0000%\n",
      "\ttrain 15-190: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 15-191: Loss: 0.1993 Acc: 25.0000%\n",
      "\ttrain 15-192: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 15-193: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 15-194: Loss: 0.0835 Acc: 100.0000%\n",
      "\ttrain 15-195: Loss: 0.0670 Acc: 100.0000%\n",
      "\ttrain 15-196: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 15-197: Loss: 0.0756 Acc: 100.0000%\n",
      "\ttrain 15-198: Loss: 0.0676 Acc: 100.0000%\n",
      "\ttrain 15-199: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 15-200: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 15-201: Loss: 0.1672 Acc: 50.0000%\n",
      "\ttrain 15-202: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 15-203: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 15-204: Loss: 0.0602 Acc: 100.0000%\n",
      "\ttrain 15-205: Loss: 0.1015 Acc: 75.0000%\n",
      "\ttrain 15-206: Loss: 0.1294 Acc: 50.0000%\n",
      "\ttrain 15-207: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 15-208: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 15-209: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 15-210: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 15-211: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 15-212: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 15-213: Loss: 0.1052 Acc: 100.0000%\n",
      "\ttrain 15-214: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 15-215: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 15-216: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 15-217: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 15-218: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 15-219: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 15-220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 15-221: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 15-222: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 15-223: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 15-224: Loss: 0.2111 Acc: 50.0000%\n",
      "\ttrain 15-225: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 15-226: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 15-227: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 15-228: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 15-229: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 15-230: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 15-231: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 15-232: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 15-233: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 15-234: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 15-235: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 15-236: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 15-237: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 15-238: Loss: 0.0962 Acc: 100.0000%\n",
      "\ttrain 15-239: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 15-240: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 15-241: Loss: 0.1121 Acc: 100.0000%\n",
      "\ttrain 15-242: Loss: 0.0650 Acc: 100.0000%\n",
      "\ttrain 15-243: Loss: 0.1635 Acc: 50.0000%\n",
      "\ttrain 15-244: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 15-245: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 15-1: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 15-2: Loss: 0.1292 Acc: 75.0000%\n",
      "\tvalidation 15-3: Loss: 0.0684 Acc: 100.0000%\n",
      "\tvalidation 15-4: Loss: 0.0454 Acc: 100.0000%\n",
      "\tvalidation 15-5: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 15-6: Loss: 0.1023 Acc: 75.0000%\n",
      "\tvalidation 15-7: Loss: 0.1716 Acc: 75.0000%\n",
      "\tvalidation 15-8: Loss: 0.0469 Acc: 100.0000%\n",
      "\tvalidation 15-9: Loss: 0.0864 Acc: 75.0000%\n",
      "\tvalidation 15-10: Loss: 0.0530 Acc: 75.0000%\n",
      "\tvalidation 15-11: Loss: 0.1078 Acc: 100.0000%\n",
      "\tvalidation 15-12: Loss: 0.0431 Acc: 100.0000%\n",
      "\tvalidation 15-13: Loss: 0.0379 Acc: 100.0000%\n",
      "\tvalidation 15-14: Loss: 0.0579 Acc: 100.0000%\n",
      "\tvalidation 15-15: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 15-16: Loss: 0.1847 Acc: 75.0000%\n",
      "\tvalidation 15-17: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 15-18: Loss: 0.0996 Acc: 75.0000%\n",
      "\tvalidation 15-19: Loss: 0.0550 Acc: 75.0000%\n",
      "\tvalidation 15-20: Loss: 0.1016 Acc: 75.0000%\n",
      "\tvalidation 15-21: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 15-22: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 15-23: Loss: 0.0505 Acc: 100.0000%\n",
      "\tvalidation 15-24: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 15-25: Loss: 0.0663 Acc: 75.0000%\n",
      "\tvalidation 15-26: Loss: 0.1264 Acc: 75.0000%\n",
      "\tvalidation 15-27: Loss: 0.0957 Acc: 100.0000%\n",
      "\tvalidation 15-28: Loss: 0.0504 Acc: 100.0000%\n",
      "\tvalidation 15-29: Loss: 0.0548 Acc: 100.0000%\n",
      "\tvalidation 15-30: Loss: 0.0425 Acc: 100.0000%\n",
      "\tvalidation 15-31: Loss: 0.0473 Acc: 75.0000%\n",
      "\tvalidation 15-32: Loss: 0.1190 Acc: 75.0000%\n",
      "\tvalidation 15-33: Loss: 0.0539 Acc: 75.0000%\n",
      "\tvalidation 15-34: Loss: 0.0777 Acc: 75.0000%\n",
      "\tvalidation 15-35: Loss: 0.0770 Acc: 100.0000%\n",
      "\tvalidation 15-36: Loss: 0.1019 Acc: 75.0000%\n",
      "\tvalidation 15-37: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 15-38: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 15-39: Loss: 0.0768 Acc: 100.0000%\n",
      "\tvalidation 15-40: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 15-41: Loss: 0.1152 Acc: 75.0000%\n",
      "\tvalidation 15-42: Loss: 0.0544 Acc: 100.0000%\n",
      "\tvalidation 15-43: Loss: 0.0519 Acc: 75.0000%\n",
      "\tvalidation 15-44: Loss: 0.0972 Acc: 75.0000%\n",
      "\tvalidation 15-45: Loss: 0.0719 Acc: 100.0000%\n",
      "\tvalidation 15-46: Loss: 0.0660 Acc: 100.0000%\n",
      "\tvalidation 15-47: Loss: 0.0481 Acc: 75.0000%\n",
      "\tvalidation 15-48: Loss: 0.0478 Acc: 100.0000%\n",
      "\tvalidation 15-49: Loss: 0.1137 Acc: 75.0000%\n",
      "\tvalidation 15-50: Loss: 0.0462 Acc: 100.0000%\n",
      "\tvalidation 15-51: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 15-52: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 15-53: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 15-54: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 15-55: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 15-56: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 15-57: Loss: 0.1011 Acc: 75.0000%\n",
      "\tvalidation 15-58: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 15-59: Loss: 0.1649 Acc: 75.0000%\n",
      "\tvalidation 15-60: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 15-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-62: Loss: 0.0519 Acc: 100.0000%\n",
      "\tvalidation 15-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-64: Loss: 0.0413 Acc: 100.0000%\n",
      "\tvalidation 15-65: Loss: 0.1447 Acc: 50.0000%\n",
      "\tvalidation 15-66: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 15-67: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 15-68: Loss: 0.0829 Acc: 75.0000%\n",
      "\tvalidation 15-69: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 15-70: Loss: 0.0507 Acc: 75.0000%\n",
      "\tvalidation 15-71: Loss: 0.0618 Acc: 100.0000%\n",
      "\tvalidation 15-72: Loss: 0.0587 Acc: 100.0000%\n",
      "\tvalidation 15-73: Loss: 0.0574 Acc: 75.0000%\n",
      "\tvalidation 15-74: Loss: 0.0404 Acc: 100.0000%\n",
      "\tvalidation 15-75: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 15-76: Loss: 0.1118 Acc: 75.0000%\n",
      "\tvalidation 15-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 15-79: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 15-80: Loss: 0.1012 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 15-81: Loss: 0.0315 Acc: 100.0000%\n",
      "\tvalidation 15-82: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 15-83: Loss: 0.1810 Acc: 50.0000%\n",
      "\tvalidation 15-84: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 15-85: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 15-86: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 15-87: Loss: 0.0799 Acc: 75.0000%\n",
      "\tvalidation 15-88: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 15-89: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 15-90: Loss: 0.0687 Acc: 100.0000%\n",
      "\tvalidation 15-91: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 15-92: Loss: 0.0706 Acc: 100.0000%\n",
      "\tvalidation 15-93: Loss: 0.0396 Acc: 100.0000%\n",
      "\tvalidation 15-94: Loss: 0.0517 Acc: 75.0000%\n",
      "\tvalidation 15-95: Loss: 0.1190 Acc: 75.0000%\n",
      "\tvalidation 15-96: Loss: 0.0872 Acc: 75.0000%\n",
      "\tvalidation 15-97: Loss: 0.0761 Acc: 100.0000%\n",
      "\tvalidation 15-98: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 15-99: Loss: 0.0311 Acc: 100.0000%\n",
      "\tvalidation 15-100: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 15-101: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 15-102: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 15-103: Loss: 0.1339 Acc: 75.0000%\n",
      "\tvalidation 15-104: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 15-105: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0963 Acc: 83.5714%\n",
      "\tvalidation Loss: 0.0575 Acc: 90.7143%\n",
      "网络参数更新\n",
      "Time passed 0h 10m 32s\n",
      "--------------------\n",
      "Epoch [16/40]:\n",
      "\ttrain 16-1: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 16-2: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 16-3: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 16-4: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 16-5: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 16-6: Loss: 0.1212 Acc: 75.0000%\n",
      "\ttrain 16-7: Loss: 0.0937 Acc: 50.0000%\n",
      "\ttrain 16-8: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 16-9: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 16-10: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 16-11: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 16-12: Loss: 0.0896 Acc: 75.0000%\n",
      "\ttrain 16-13: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 16-14: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 16-15: Loss: 0.0891 Acc: 75.0000%\n",
      "\ttrain 16-16: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 16-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-18: Loss: 0.1801 Acc: 75.0000%\n",
      "\ttrain 16-19: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 16-20: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 16-21: Loss: 0.3004 Acc: 50.0000%\n",
      "\ttrain 16-22: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 16-23: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 16-24: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 16-25: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 16-26: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 16-27: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 16-28: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 16-29: Loss: 0.1219 Acc: 75.0000%\n",
      "\ttrain 16-30: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 16-31: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 16-32: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 16-33: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 16-34: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 16-35: Loss: 0.0990 Acc: 75.0000%\n",
      "\ttrain 16-36: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 16-37: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 16-38: Loss: 0.1812 Acc: 50.0000%\n",
      "\ttrain 16-39: Loss: 0.0822 Acc: 75.0000%\n",
      "\ttrain 16-40: Loss: 0.0695 Acc: 100.0000%\n",
      "\ttrain 16-41: Loss: 0.2353 Acc: 75.0000%\n",
      "\ttrain 16-42: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 16-43: Loss: 0.0574 Acc: 100.0000%\n",
      "\ttrain 16-44: Loss: 0.1108 Acc: 75.0000%\n",
      "\ttrain 16-45: Loss: 0.2734 Acc: 75.0000%\n",
      "\ttrain 16-46: Loss: 0.1073 Acc: 75.0000%\n",
      "\ttrain 16-47: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 16-48: Loss: 0.0859 Acc: 100.0000%\n",
      "\ttrain 16-49: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 16-50: Loss: 0.1557 Acc: 50.0000%\n",
      "\ttrain 16-51: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 16-52: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 16-53: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 16-54: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 16-55: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 16-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 16-57: Loss: 0.0643 Acc: 100.0000%\n",
      "\ttrain 16-58: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 16-59: Loss: 0.1442 Acc: 50.0000%\n",
      "\ttrain 16-60: Loss: 0.0502 Acc: 100.0000%\n",
      "\ttrain 16-61: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 16-62: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 16-63: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 16-64: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 16-65: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 16-66: Loss: 0.0853 Acc: 100.0000%\n",
      "\ttrain 16-67: Loss: 0.4210 Acc: 50.0000%\n",
      "\ttrain 16-68: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 16-69: Loss: 0.0583 Acc: 75.0000%\n",
      "\ttrain 16-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 16-71: Loss: 0.2352 Acc: 75.0000%\n",
      "\ttrain 16-72: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 16-73: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 16-74: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 16-75: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 16-76: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 16-77: Loss: 0.0514 Acc: 75.0000%\n",
      "\ttrain 16-78: Loss: 0.3629 Acc: 50.0000%\n",
      "\ttrain 16-79: Loss: 0.0955 Acc: 75.0000%\n",
      "\ttrain 16-80: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 16-81: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 16-82: Loss: 0.2141 Acc: 25.0000%\n",
      "\ttrain 16-83: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 16-84: Loss: 0.1328 Acc: 75.0000%\n",
      "\ttrain 16-85: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 16-86: Loss: 0.1542 Acc: 50.0000%\n",
      "\ttrain 16-87: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 16-88: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 16-89: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 16-90: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 16-91: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 16-92: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 16-93: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 16-94: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 16-95: Loss: 0.1035 Acc: 100.0000%\n",
      "\ttrain 16-96: Loss: 0.0995 Acc: 75.0000%\n",
      "\ttrain 16-97: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 16-98: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 16-99: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 16-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 16-101: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 16-102: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 16-103: Loss: 0.0761 Acc: 75.0000%\n",
      "\ttrain 16-104: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 16-105: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 16-106: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 16-107: Loss: 0.1271 Acc: 75.0000%\n",
      "\ttrain 16-108: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 16-109: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 16-110: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 16-111: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 16-112: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 16-113: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 16-114: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 16-115: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 16-116: Loss: 0.2407 Acc: 75.0000%\n",
      "\ttrain 16-117: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 16-118: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 16-119: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 16-120: Loss: 0.1717 Acc: 75.0000%\n",
      "\ttrain 16-121: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 16-122: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 16-123: Loss: 0.1528 Acc: 50.0000%\n",
      "\ttrain 16-124: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 16-125: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 16-126: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 16-127: Loss: 0.1033 Acc: 75.0000%\n",
      "\ttrain 16-128: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 16-129: Loss: 0.1239 Acc: 75.0000%\n",
      "\ttrain 16-130: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 16-131: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 16-132: Loss: 0.0803 Acc: 100.0000%\n",
      "\ttrain 16-133: Loss: 0.1068 Acc: 75.0000%\n",
      "\ttrain 16-134: Loss: 0.3832 Acc: 50.0000%\n",
      "\ttrain 16-135: Loss: 0.6350 Acc: 50.0000%\n",
      "\ttrain 16-136: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 16-137: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 16-138: Loss: 0.1977 Acc: 50.0000%\n",
      "\ttrain 16-139: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 16-140: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 16-141: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 16-142: Loss: 0.2519 Acc: 50.0000%\n",
      "\ttrain 16-143: Loss: 0.1507 Acc: 75.0000%\n",
      "\ttrain 16-144: Loss: 0.1319 Acc: 50.0000%\n",
      "\ttrain 16-145: Loss: 0.1929 Acc: 50.0000%\n",
      "\ttrain 16-146: Loss: 0.2065 Acc: 50.0000%\n",
      "\ttrain 16-147: Loss: 0.2087 Acc: 50.0000%\n",
      "\ttrain 16-148: Loss: 0.1772 Acc: 50.0000%\n",
      "\ttrain 16-149: Loss: 0.0658 Acc: 100.0000%\n",
      "\ttrain 16-150: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 16-151: Loss: 0.0598 Acc: 100.0000%\n",
      "\ttrain 16-152: Loss: 0.0564 Acc: 100.0000%\n",
      "\ttrain 16-153: Loss: 0.0728 Acc: 100.0000%\n",
      "\ttrain 16-154: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 16-155: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 16-156: Loss: 0.1793 Acc: 75.0000%\n",
      "\ttrain 16-157: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 16-158: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 16-159: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 16-160: Loss: 0.2335 Acc: 50.0000%\n",
      "\ttrain 16-161: Loss: 0.0931 Acc: 75.0000%\n",
      "\ttrain 16-162: Loss: 0.0453 Acc: 100.0000%\n",
      "\ttrain 16-163: Loss: 0.1909 Acc: 50.0000%\n",
      "\ttrain 16-164: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 16-165: Loss: 0.1225 Acc: 75.0000%\n",
      "\ttrain 16-166: Loss: 0.1243 Acc: 50.0000%\n",
      "\ttrain 16-167: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 16-168: Loss: 0.1714 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 16-169: Loss: 0.0948 Acc: 75.0000%\n",
      "\ttrain 16-170: Loss: 0.1612 Acc: 50.0000%\n",
      "\ttrain 16-171: Loss: 0.2118 Acc: 50.0000%\n",
      "\ttrain 16-172: Loss: 0.1067 Acc: 100.0000%\n",
      "\ttrain 16-173: Loss: 0.1382 Acc: 75.0000%\n",
      "\ttrain 16-174: Loss: 0.0745 Acc: 100.0000%\n",
      "\ttrain 16-175: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 16-176: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 16-177: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 16-178: Loss: 0.1269 Acc: 50.0000%\n",
      "\ttrain 16-179: Loss: 0.1118 Acc: 50.0000%\n",
      "\ttrain 16-180: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 16-181: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 16-182: Loss: 0.2417 Acc: 25.0000%\n",
      "\ttrain 16-183: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 16-184: Loss: 0.1554 Acc: 50.0000%\n",
      "\ttrain 16-185: Loss: 0.1695 Acc: 75.0000%\n",
      "\ttrain 16-186: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 16-187: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 16-188: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 16-189: Loss: 0.2029 Acc: 75.0000%\n",
      "\ttrain 16-190: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 16-191: Loss: 0.0772 Acc: 75.0000%\n",
      "\ttrain 16-192: Loss: 0.1158 Acc: 50.0000%\n",
      "\ttrain 16-193: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 16-194: Loss: 0.2226 Acc: 25.0000%\n",
      "\ttrain 16-195: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 16-196: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 16-197: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 16-198: Loss: 0.0680 Acc: 100.0000%\n",
      "\ttrain 16-199: Loss: 0.1535 Acc: 50.0000%\n",
      "\ttrain 16-200: Loss: 0.0525 Acc: 100.0000%\n",
      "\ttrain 16-201: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 16-202: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 16-203: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 16-204: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 16-205: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 16-206: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 16-207: Loss: 0.2370 Acc: 75.0000%\n",
      "\ttrain 16-208: Loss: 0.0809 Acc: 100.0000%\n",
      "\ttrain 16-209: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 16-210: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 16-211: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 16-212: Loss: 0.0666 Acc: 75.0000%\n",
      "\ttrain 16-213: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 16-214: Loss: 0.1357 Acc: 50.0000%\n",
      "\ttrain 16-215: Loss: 0.1197 Acc: 100.0000%\n",
      "\ttrain 16-216: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 16-217: Loss: 0.0934 Acc: 100.0000%\n",
      "\ttrain 16-218: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 16-219: Loss: 0.2675 Acc: 25.0000%\n",
      "\ttrain 16-220: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 16-221: Loss: 0.0975 Acc: 100.0000%\n",
      "\ttrain 16-222: Loss: 0.2712 Acc: 75.0000%\n",
      "\ttrain 16-223: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 16-224: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 16-225: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 16-226: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 16-227: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 16-228: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 16-229: Loss: 0.4686 Acc: 50.0000%\n",
      "\ttrain 16-230: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 16-231: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 16-232: Loss: 0.1471 Acc: 75.0000%\n",
      "\ttrain 16-233: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 16-234: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 16-235: Loss: 0.2415 Acc: 50.0000%\n",
      "\ttrain 16-236: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 16-237: Loss: 0.1287 Acc: 75.0000%\n",
      "\ttrain 16-238: Loss: 0.1548 Acc: 50.0000%\n",
      "\ttrain 16-239: Loss: 0.1199 Acc: 75.0000%\n",
      "\ttrain 16-240: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 16-241: Loss: 0.0755 Acc: 100.0000%\n",
      "\ttrain 16-242: Loss: 0.1133 Acc: 75.0000%\n",
      "\ttrain 16-243: Loss: 0.2854 Acc: 50.0000%\n",
      "\ttrain 16-244: Loss: 0.1443 Acc: 75.0000%\n",
      "\ttrain 16-245: Loss: 0.1548 Acc: 50.0000%\n",
      "\tvalidation 16-1: Loss: 0.0575 Acc: 100.0000%\n",
      "\tvalidation 16-2: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 16-3: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 16-4: Loss: 0.0607 Acc: 75.0000%\n",
      "\tvalidation 16-5: Loss: 0.1787 Acc: 75.0000%\n",
      "\tvalidation 16-6: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 16-7: Loss: 0.1295 Acc: 75.0000%\n",
      "\tvalidation 16-8: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 16-9: Loss: 0.1150 Acc: 75.0000%\n",
      "\tvalidation 16-10: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 16-11: Loss: 0.1841 Acc: 50.0000%\n",
      "\tvalidation 16-12: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 16-13: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 16-14: Loss: 0.1186 Acc: 100.0000%\n",
      "\tvalidation 16-15: Loss: 0.0489 Acc: 75.0000%\n",
      "\tvalidation 16-16: Loss: 0.0564 Acc: 75.0000%\n",
      "\tvalidation 16-17: Loss: 0.0459 Acc: 100.0000%\n",
      "\tvalidation 16-18: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-19: Loss: 0.1301 Acc: 50.0000%\n",
      "\tvalidation 16-20: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 16-21: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 16-22: Loss: 0.0499 Acc: 75.0000%\n",
      "\tvalidation 16-23: Loss: 0.0751 Acc: 75.0000%\n",
      "\tvalidation 16-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 16-25: Loss: 0.0742 Acc: 75.0000%\n",
      "\tvalidation 16-26: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 16-27: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 16-28: Loss: 0.1961 Acc: 50.0000%\n",
      "\tvalidation 16-29: Loss: 0.1363 Acc: 50.0000%\n",
      "\tvalidation 16-30: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 16-31: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 16-32: Loss: 0.0536 Acc: 75.0000%\n",
      "\tvalidation 16-33: Loss: 0.0440 Acc: 75.0000%\n",
      "\tvalidation 16-34: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 16-35: Loss: 0.0882 Acc: 75.0000%\n",
      "\tvalidation 16-36: Loss: 0.1223 Acc: 75.0000%\n",
      "\tvalidation 16-37: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 16-38: Loss: 0.1884 Acc: 75.0000%\n",
      "\tvalidation 16-39: Loss: 0.0560 Acc: 75.0000%\n",
      "\tvalidation 16-40: Loss: 0.0863 Acc: 75.0000%\n",
      "\tvalidation 16-41: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 16-42: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 16-43: Loss: 0.0599 Acc: 75.0000%\n",
      "\tvalidation 16-44: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 16-45: Loss: 0.0391 Acc: 100.0000%\n",
      "\tvalidation 16-46: Loss: 0.0471 Acc: 75.0000%\n",
      "\tvalidation 16-47: Loss: 0.0666 Acc: 75.0000%\n",
      "\tvalidation 16-48: Loss: 0.0917 Acc: 75.0000%\n",
      "\tvalidation 16-49: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 16-50: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 16-51: Loss: 0.2857 Acc: 75.0000%\n",
      "\tvalidation 16-52: Loss: 0.0957 Acc: 75.0000%\n",
      "\tvalidation 16-53: Loss: 0.0493 Acc: 75.0000%\n",
      "\tvalidation 16-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-55: Loss: 0.0953 Acc: 75.0000%\n",
      "\tvalidation 16-56: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 16-57: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 16-58: Loss: 0.1854 Acc: 50.0000%\n",
      "\tvalidation 16-59: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 16-60: Loss: 0.1362 Acc: 50.0000%\n",
      "\tvalidation 16-61: Loss: 0.2281 Acc: 75.0000%\n",
      "\tvalidation 16-62: Loss: 0.1981 Acc: 25.0000%\n",
      "\tvalidation 16-63: Loss: 0.0607 Acc: 75.0000%\n",
      "\tvalidation 16-64: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 16-65: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 16-66: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 16-67: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 16-68: Loss: 0.1068 Acc: 100.0000%\n",
      "\tvalidation 16-69: Loss: 0.0830 Acc: 75.0000%\n",
      "\tvalidation 16-70: Loss: 0.2124 Acc: 50.0000%\n",
      "\tvalidation 16-71: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 16-72: Loss: 0.0649 Acc: 75.0000%\n",
      "\tvalidation 16-73: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 16-74: Loss: 0.0836 Acc: 75.0000%\n",
      "\tvalidation 16-75: Loss: 0.2001 Acc: 75.0000%\n",
      "\tvalidation 16-76: Loss: 0.0463 Acc: 100.0000%\n",
      "\tvalidation 16-77: Loss: 0.1341 Acc: 50.0000%\n",
      "\tvalidation 16-78: Loss: 0.0717 Acc: 75.0000%\n",
      "\tvalidation 16-79: Loss: 0.4639 Acc: 50.0000%\n",
      "\tvalidation 16-80: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 16-81: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 16-82: Loss: 0.0530 Acc: 75.0000%\n",
      "\tvalidation 16-83: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 16-84: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 16-85: Loss: 0.2056 Acc: 75.0000%\n",
      "\tvalidation 16-86: Loss: 0.0506 Acc: 75.0000%\n",
      "\tvalidation 16-87: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 16-88: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 16-89: Loss: 0.1066 Acc: 75.0000%\n",
      "\tvalidation 16-90: Loss: 0.0921 Acc: 75.0000%\n",
      "\tvalidation 16-91: Loss: 0.0434 Acc: 100.0000%\n",
      "\tvalidation 16-92: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 16-93: Loss: 0.1956 Acc: 50.0000%\n",
      "\tvalidation 16-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 16-95: Loss: 0.1685 Acc: 50.0000%\n",
      "\tvalidation 16-96: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 16-97: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 16-98: Loss: 0.0344 Acc: 100.0000%\n",
      "\tvalidation 16-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 16-100: Loss: 0.1705 Acc: 50.0000%\n",
      "\tvalidation 16-101: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 16-102: Loss: 0.0462 Acc: 75.0000%\n",
      "\tvalidation 16-103: Loss: 0.0884 Acc: 75.0000%\n",
      "\tvalidation 16-104: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 16-105: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0968 Acc: 82.9592%\n",
      "\tvalidation Loss: 0.0706 Acc: 84.0476%\n",
      "Time passed 0h 11m 14s\n",
      "--------------------\n",
      "Epoch [17/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-1: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 17-2: Loss: 0.0803 Acc: 75.0000%\n",
      "\ttrain 17-3: Loss: 0.1100 Acc: 50.0000%\n",
      "\ttrain 17-4: Loss: 0.6997 Acc: 75.0000%\n",
      "\ttrain 17-5: Loss: 0.1762 Acc: 50.0000%\n",
      "\ttrain 17-6: Loss: 0.1361 Acc: 75.0000%\n",
      "\ttrain 17-7: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 17-8: Loss: 0.1040 Acc: 75.0000%\n",
      "\ttrain 17-9: Loss: 0.1629 Acc: 50.0000%\n",
      "\ttrain 17-10: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 17-11: Loss: 0.4793 Acc: 25.0000%\n",
      "\ttrain 17-12: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 17-13: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 17-14: Loss: 0.0629 Acc: 100.0000%\n",
      "\ttrain 17-15: Loss: 0.1605 Acc: 50.0000%\n",
      "\ttrain 17-16: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 17-17: Loss: 0.0621 Acc: 75.0000%\n",
      "\ttrain 17-18: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 17-19: Loss: 0.4099 Acc: 50.0000%\n",
      "\ttrain 17-20: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 17-21: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 17-22: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 17-23: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 17-24: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain 17-25: Loss: 0.1032 Acc: 75.0000%\n",
      "\ttrain 17-26: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 17-27: Loss: 0.1407 Acc: 75.0000%\n",
      "\ttrain 17-28: Loss: 0.2713 Acc: 75.0000%\n",
      "\ttrain 17-29: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 17-30: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 17-31: Loss: 0.1537 Acc: 50.0000%\n",
      "\ttrain 17-32: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 17-33: Loss: 0.1002 Acc: 75.0000%\n",
      "\ttrain 17-34: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 17-35: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 17-36: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 17-37: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 17-38: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 17-39: Loss: 0.1238 Acc: 75.0000%\n",
      "\ttrain 17-40: Loss: 0.1331 Acc: 50.0000%\n",
      "\ttrain 17-41: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 17-42: Loss: 0.0484 Acc: 75.0000%\n",
      "\ttrain 17-43: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 17-44: Loss: 0.1084 Acc: 75.0000%\n",
      "\ttrain 17-45: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 17-46: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 17-47: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 17-48: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 17-49: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 17-50: Loss: 0.0602 Acc: 75.0000%\n",
      "\ttrain 17-51: Loss: 0.2333 Acc: 75.0000%\n",
      "\ttrain 17-52: Loss: 0.1027 Acc: 50.0000%\n",
      "\ttrain 17-53: Loss: 0.1184 Acc: 50.0000%\n",
      "\ttrain 17-54: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 17-55: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 17-56: Loss: 0.1849 Acc: 75.0000%\n",
      "\ttrain 17-57: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 17-58: Loss: 0.1759 Acc: 25.0000%\n",
      "\ttrain 17-59: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 17-60: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 17-61: Loss: 0.0954 Acc: 100.0000%\n",
      "\ttrain 17-62: Loss: 0.0808 Acc: 100.0000%\n",
      "\ttrain 17-63: Loss: 0.0737 Acc: 100.0000%\n",
      "\ttrain 17-64: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 17-65: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 17-66: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 17-67: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 17-68: Loss: 0.0999 Acc: 75.0000%\n",
      "\ttrain 17-69: Loss: 0.0850 Acc: 75.0000%\n",
      "\ttrain 17-70: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 17-71: Loss: 0.0897 Acc: 75.0000%\n",
      "\ttrain 17-72: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 17-73: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 17-74: Loss: 0.0635 Acc: 100.0000%\n",
      "\ttrain 17-75: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 17-76: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 17-77: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 17-78: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 17-79: Loss: 0.1103 Acc: 100.0000%\n",
      "\ttrain 17-80: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 17-81: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 17-82: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 17-83: Loss: 0.1648 Acc: 75.0000%\n",
      "\ttrain 17-84: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 17-85: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 17-86: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 17-87: Loss: 0.1618 Acc: 75.0000%\n",
      "\ttrain 17-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 17-89: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 17-90: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 17-91: Loss: 0.0631 Acc: 75.0000%\n",
      "\ttrain 17-92: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 17-93: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 17-94: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 17-95: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 17-96: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 17-97: Loss: 0.1521 Acc: 50.0000%\n",
      "\ttrain 17-98: Loss: 0.2324 Acc: 75.0000%\n",
      "\ttrain 17-99: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 17-100: Loss: 0.5948 Acc: 75.0000%\n",
      "\ttrain 17-101: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 17-102: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 17-103: Loss: 0.1875 Acc: 75.0000%\n",
      "\ttrain 17-104: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 17-105: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 17-106: Loss: 0.0937 Acc: 75.0000%\n",
      "\ttrain 17-107: Loss: 0.1656 Acc: 75.0000%\n",
      "\ttrain 17-108: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 17-109: Loss: 0.0838 Acc: 100.0000%\n",
      "\ttrain 17-110: Loss: 0.1066 Acc: 75.0000%\n",
      "\ttrain 17-111: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 17-112: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 17-113: Loss: 0.0909 Acc: 75.0000%\n",
      "\ttrain 17-114: Loss: 0.1334 Acc: 75.0000%\n",
      "\ttrain 17-115: Loss: 0.0619 Acc: 75.0000%\n",
      "\ttrain 17-116: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 17-117: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 17-118: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 17-119: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 17-120: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 17-121: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 17-122: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 17-123: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 17-124: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 17-125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 17-126: Loss: 0.2476 Acc: 75.0000%\n",
      "\ttrain 17-127: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 17-128: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 17-129: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 17-130: Loss: 0.3086 Acc: 75.0000%\n",
      "\ttrain 17-131: Loss: 0.0551 Acc: 75.0000%\n",
      "\ttrain 17-132: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 17-133: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 17-134: Loss: 0.1103 Acc: 50.0000%\n",
      "\ttrain 17-135: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 17-136: Loss: 0.0855 Acc: 75.0000%\n",
      "\ttrain 17-137: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 17-138: Loss: 0.0460 Acc: 100.0000%\n",
      "\ttrain 17-139: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 17-140: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 17-141: Loss: 0.1226 Acc: 75.0000%\n",
      "\ttrain 17-142: Loss: 0.0695 Acc: 100.0000%\n",
      "\ttrain 17-143: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 17-144: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 17-145: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 17-146: Loss: 0.2041 Acc: 75.0000%\n",
      "\ttrain 17-147: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 17-148: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 17-149: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 17-150: Loss: 0.1504 Acc: 50.0000%\n",
      "\ttrain 17-151: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 17-152: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 17-153: Loss: 0.0845 Acc: 100.0000%\n",
      "\ttrain 17-154: Loss: 0.1097 Acc: 75.0000%\n",
      "\ttrain 17-155: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 17-156: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 17-157: Loss: 0.3585 Acc: 75.0000%\n",
      "\ttrain 17-158: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 17-159: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 17-160: Loss: 0.2346 Acc: 50.0000%\n",
      "\ttrain 17-161: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 17-162: Loss: 0.2283 Acc: 50.0000%\n",
      "\ttrain 17-163: Loss: 0.0982 Acc: 75.0000%\n",
      "\ttrain 17-164: Loss: 0.1418 Acc: 75.0000%\n",
      "\ttrain 17-165: Loss: 0.1304 Acc: 75.0000%\n",
      "\ttrain 17-166: Loss: 0.1714 Acc: 75.0000%\n",
      "\ttrain 17-167: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 17-168: Loss: 0.1293 Acc: 75.0000%\n",
      "\ttrain 17-169: Loss: 0.2238 Acc: 75.0000%\n",
      "\ttrain 17-170: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 17-171: Loss: 0.0734 Acc: 100.0000%\n",
      "\ttrain 17-172: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 17-173: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 17-174: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 17-175: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 17-176: Loss: 0.4709 Acc: 50.0000%\n",
      "\ttrain 17-177: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 17-178: Loss: 0.1141 Acc: 75.0000%\n",
      "\ttrain 17-179: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 17-180: Loss: 0.3476 Acc: 75.0000%\n",
      "\ttrain 17-181: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 17-182: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 17-183: Loss: 0.0716 Acc: 75.0000%\n",
      "\ttrain 17-184: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 17-185: Loss: 0.1012 Acc: 75.0000%\n",
      "\ttrain 17-186: Loss: 0.1747 Acc: 50.0000%\n",
      "\ttrain 17-187: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 17-188: Loss: 0.1736 Acc: 50.0000%\n",
      "\ttrain 17-189: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 17-190: Loss: 0.1552 Acc: 50.0000%\n",
      "\ttrain 17-191: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 17-192: Loss: 0.3616 Acc: 75.0000%\n",
      "\ttrain 17-193: Loss: 0.0998 Acc: 100.0000%\n",
      "\ttrain 17-194: Loss: 0.3867 Acc: 75.0000%\n",
      "\ttrain 17-195: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 17-196: Loss: 0.0719 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 17-197: Loss: 0.0898 Acc: 100.0000%\n",
      "\ttrain 17-198: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 17-199: Loss: 0.1027 Acc: 100.0000%\n",
      "\ttrain 17-200: Loss: 0.0581 Acc: 100.0000%\n",
      "\ttrain 17-201: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 17-202: Loss: 0.0777 Acc: 100.0000%\n",
      "\ttrain 17-203: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 17-204: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 17-205: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 17-206: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 17-207: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 17-208: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 17-209: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 17-210: Loss: 0.1592 Acc: 75.0000%\n",
      "\ttrain 17-211: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 17-212: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 17-213: Loss: 0.0903 Acc: 75.0000%\n",
      "\ttrain 17-214: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 17-215: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 17-216: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 17-217: Loss: 0.3499 Acc: 50.0000%\n",
      "\ttrain 17-218: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 17-219: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 17-220: Loss: 0.1400 Acc: 75.0000%\n",
      "\ttrain 17-221: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 17-222: Loss: 0.0756 Acc: 75.0000%\n",
      "\ttrain 17-223: Loss: 0.2702 Acc: 75.0000%\n",
      "\ttrain 17-224: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 17-225: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 17-226: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 17-227: Loss: 0.1564 Acc: 75.0000%\n",
      "\ttrain 17-228: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 17-229: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 17-230: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 17-231: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 17-232: Loss: 0.2381 Acc: 25.0000%\n",
      "\ttrain 17-233: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 17-234: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 17-235: Loss: 0.2110 Acc: 50.0000%\n",
      "\ttrain 17-236: Loss: 0.1055 Acc: 75.0000%\n",
      "\ttrain 17-237: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 17-238: Loss: 0.0941 Acc: 75.0000%\n",
      "\ttrain 17-239: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 17-240: Loss: 0.1410 Acc: 50.0000%\n",
      "\ttrain 17-241: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 17-242: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 17-243: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 17-244: Loss: 0.1634 Acc: 75.0000%\n",
      "\ttrain 17-245: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 17-1: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 17-2: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 17-3: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 17-4: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 17-5: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 17-6: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 17-7: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 17-8: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 17-9: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 17-10: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 17-11: Loss: 0.0461 Acc: 100.0000%\n",
      "\tvalidation 17-12: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 17-13: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 17-14: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-15: Loss: 0.0183 Acc: 100.0000%\n",
      "\tvalidation 17-16: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 17-17: Loss: 0.0614 Acc: 75.0000%\n",
      "\tvalidation 17-18: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 17-19: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 17-20: Loss: 0.0971 Acc: 75.0000%\n",
      "\tvalidation 17-21: Loss: 0.0169 Acc: 100.0000%\n",
      "\tvalidation 17-22: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 17-23: Loss: 0.0948 Acc: 75.0000%\n",
      "\tvalidation 17-24: Loss: 0.0136 Acc: 100.0000%\n",
      "\tvalidation 17-25: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 17-26: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 17-27: Loss: 0.0249 Acc: 100.0000%\n",
      "\tvalidation 17-28: Loss: 0.0442 Acc: 100.0000%\n",
      "\tvalidation 17-29: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 17-30: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 17-31: Loss: 0.1439 Acc: 75.0000%\n",
      "\tvalidation 17-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 17-33: Loss: 0.0925 Acc: 75.0000%\n",
      "\tvalidation 17-34: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 17-35: Loss: 0.0663 Acc: 100.0000%\n",
      "\tvalidation 17-36: Loss: 0.0636 Acc: 100.0000%\n",
      "\tvalidation 17-37: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 17-38: Loss: 0.0346 Acc: 100.0000%\n",
      "\tvalidation 17-39: Loss: 0.0799 Acc: 100.0000%\n",
      "\tvalidation 17-40: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 17-41: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 17-42: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 17-43: Loss: 0.1142 Acc: 75.0000%\n",
      "\tvalidation 17-44: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 17-45: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 17-46: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 17-47: Loss: 0.0833 Acc: 100.0000%\n",
      "\tvalidation 17-48: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 17-49: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 17-50: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 17-51: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 17-52: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 17-53: Loss: 0.0661 Acc: 75.0000%\n",
      "\tvalidation 17-54: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 17-55: Loss: 0.0821 Acc: 75.0000%\n",
      "\tvalidation 17-56: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 17-57: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 17-58: Loss: 0.1019 Acc: 75.0000%\n",
      "\tvalidation 17-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 17-60: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-61: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 17-62: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 17-63: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 17-64: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 17-65: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 17-66: Loss: 0.0564 Acc: 100.0000%\n",
      "\tvalidation 17-67: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 17-68: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 17-69: Loss: 0.0611 Acc: 100.0000%\n",
      "\tvalidation 17-70: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 17-71: Loss: 0.0616 Acc: 100.0000%\n",
      "\tvalidation 17-72: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 17-73: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 17-74: Loss: 0.0598 Acc: 75.0000%\n",
      "\tvalidation 17-75: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 17-76: Loss: 0.1813 Acc: 75.0000%\n",
      "\tvalidation 17-77: Loss: 0.1246 Acc: 75.0000%\n",
      "\tvalidation 17-78: Loss: 0.1763 Acc: 75.0000%\n",
      "\tvalidation 17-79: Loss: 0.0300 Acc: 100.0000%\n",
      "\tvalidation 17-80: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 17-81: Loss: 0.0518 Acc: 100.0000%\n",
      "\tvalidation 17-82: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 17-83: Loss: 0.0555 Acc: 100.0000%\n",
      "\tvalidation 17-84: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 17-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 17-86: Loss: 0.0804 Acc: 75.0000%\n",
      "\tvalidation 17-87: Loss: 0.1140 Acc: 75.0000%\n",
      "\tvalidation 17-88: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 17-89: Loss: 0.1482 Acc: 50.0000%\n",
      "\tvalidation 17-90: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 17-91: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 17-92: Loss: 0.0350 Acc: 100.0000%\n",
      "\tvalidation 17-93: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 17-94: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 17-95: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 17-96: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 17-97: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 17-98: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 17-99: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 17-100: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 17-101: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 17-102: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 17-103: Loss: 0.0710 Acc: 75.0000%\n",
      "\tvalidation 17-104: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 17-105: Loss: 0.0674 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0957 Acc: 84.2857%\n",
      "\tvalidation Loss: 0.0374 Acc: 95.2381%\n",
      "网络参数更新\n",
      "Time passed 0h 12m 1s\n",
      "--------------------\n",
      "Epoch [18/40]:\n",
      "\ttrain 18-1: Loss: 0.1161 Acc: 75.0000%\n",
      "\ttrain 18-2: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 18-3: Loss: 0.1524 Acc: 50.0000%\n",
      "\ttrain 18-4: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 18-5: Loss: 0.0765 Acc: 75.0000%\n",
      "\ttrain 18-6: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 18-7: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 18-8: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 18-9: Loss: 0.0892 Acc: 75.0000%\n",
      "\ttrain 18-10: Loss: 0.1113 Acc: 75.0000%\n",
      "\ttrain 18-11: Loss: 0.2419 Acc: 50.0000%\n",
      "\ttrain 18-12: Loss: 0.0682 Acc: 75.0000%\n",
      "\ttrain 18-13: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 18-14: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-15: Loss: 0.1944 Acc: 50.0000%\n",
      "\ttrain 18-16: Loss: 0.2269 Acc: 50.0000%\n",
      "\ttrain 18-17: Loss: 0.1228 Acc: 50.0000%\n",
      "\ttrain 18-18: Loss: 0.1692 Acc: 75.0000%\n",
      "\ttrain 18-19: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 18-20: Loss: 0.2344 Acc: 50.0000%\n",
      "\ttrain 18-21: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 18-22: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 18-23: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 18-24: Loss: 0.0769 Acc: 100.0000%\n",
      "\ttrain 18-25: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 18-26: Loss: 0.1158 Acc: 75.0000%\n",
      "\ttrain 18-27: Loss: 0.0651 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-28: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 18-29: Loss: 0.1690 Acc: 50.0000%\n",
      "\ttrain 18-30: Loss: 0.0904 Acc: 100.0000%\n",
      "\ttrain 18-31: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 18-32: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 18-33: Loss: 0.1153 Acc: 75.0000%\n",
      "\ttrain 18-34: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 18-35: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 18-36: Loss: 0.0880 Acc: 100.0000%\n",
      "\ttrain 18-37: Loss: 0.1709 Acc: 50.0000%\n",
      "\ttrain 18-38: Loss: 0.2449 Acc: 50.0000%\n",
      "\ttrain 18-39: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 18-40: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 18-41: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 18-42: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 18-43: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 18-44: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 18-45: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 18-46: Loss: 0.1699 Acc: 50.0000%\n",
      "\ttrain 18-47: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 18-48: Loss: 0.0683 Acc: 100.0000%\n",
      "\ttrain 18-49: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 18-50: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 18-51: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 18-52: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 18-53: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 18-54: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 18-55: Loss: 0.1060 Acc: 100.0000%\n",
      "\ttrain 18-56: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 18-57: Loss: 0.0540 Acc: 100.0000%\n",
      "\ttrain 18-58: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 18-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 18-60: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 18-61: Loss: 0.2084 Acc: 75.0000%\n",
      "\ttrain 18-62: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 18-63: Loss: 0.1344 Acc: 75.0000%\n",
      "\ttrain 18-64: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 18-65: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 18-66: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 18-67: Loss: 0.1317 Acc: 75.0000%\n",
      "\ttrain 18-68: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 18-69: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 18-70: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 18-71: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 18-72: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 18-73: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 18-74: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 18-75: Loss: 0.3278 Acc: 50.0000%\n",
      "\ttrain 18-76: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 18-77: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 18-78: Loss: 0.0865 Acc: 75.0000%\n",
      "\ttrain 18-79: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 18-80: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 18-81: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 18-82: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 18-83: Loss: 0.1391 Acc: 75.0000%\n",
      "\ttrain 18-84: Loss: 0.0513 Acc: 100.0000%\n",
      "\ttrain 18-85: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-86: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 18-87: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 18-88: Loss: 0.1392 Acc: 75.0000%\n",
      "\ttrain 18-89: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 18-90: Loss: 0.1555 Acc: 75.0000%\n",
      "\ttrain 18-91: Loss: 0.2036 Acc: 75.0000%\n",
      "\ttrain 18-92: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 18-93: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 18-94: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 18-95: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 18-96: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 18-97: Loss: 0.1160 Acc: 50.0000%\n",
      "\ttrain 18-98: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 18-99: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 18-100: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 18-101: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 18-102: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 18-103: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 18-104: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 18-105: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 18-106: Loss: 0.3489 Acc: 75.0000%\n",
      "\ttrain 18-107: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 18-108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 18-109: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 18-110: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 18-111: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 18-112: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 18-113: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 18-114: Loss: 0.0508 Acc: 100.0000%\n",
      "\ttrain 18-115: Loss: 0.1118 Acc: 50.0000%\n",
      "\ttrain 18-116: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 18-117: Loss: 0.3585 Acc: 25.0000%\n",
      "\ttrain 18-118: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 18-119: Loss: 0.1302 Acc: 75.0000%\n",
      "\ttrain 18-120: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 18-121: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 18-122: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 18-123: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 18-124: Loss: 0.2892 Acc: 50.0000%\n",
      "\ttrain 18-125: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 18-126: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 18-127: Loss: 0.1729 Acc: 75.0000%\n",
      "\ttrain 18-128: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 18-129: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 18-130: Loss: 0.0667 Acc: 75.0000%\n",
      "\ttrain 18-131: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 18-132: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 18-133: Loss: 0.1539 Acc: 50.0000%\n",
      "\ttrain 18-134: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 18-135: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 18-136: Loss: 0.1204 Acc: 75.0000%\n",
      "\ttrain 18-137: Loss: 0.0372 Acc: 100.0000%\n",
      "\ttrain 18-138: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 18-139: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 18-140: Loss: 0.2044 Acc: 50.0000%\n",
      "\ttrain 18-141: Loss: 0.1544 Acc: 75.0000%\n",
      "\ttrain 18-142: Loss: 0.1812 Acc: 75.0000%\n",
      "\ttrain 18-143: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 18-144: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 18-145: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 18-146: Loss: 0.1839 Acc: 75.0000%\n",
      "\ttrain 18-147: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 18-148: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 18-149: Loss: 0.0540 Acc: 75.0000%\n",
      "\ttrain 18-150: Loss: 0.1381 Acc: 75.0000%\n",
      "\ttrain 18-151: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 18-152: Loss: 0.0782 Acc: 100.0000%\n",
      "\ttrain 18-153: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 18-154: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 18-155: Loss: 0.1006 Acc: 75.0000%\n",
      "\ttrain 18-156: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 18-157: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 18-158: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 18-159: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 18-160: Loss: 0.3404 Acc: 75.0000%\n",
      "\ttrain 18-161: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 18-162: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 18-163: Loss: 0.1082 Acc: 75.0000%\n",
      "\ttrain 18-164: Loss: 0.1251 Acc: 50.0000%\n",
      "\ttrain 18-165: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 18-166: Loss: 0.2063 Acc: 75.0000%\n",
      "\ttrain 18-167: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 18-168: Loss: 0.0625 Acc: 100.0000%\n",
      "\ttrain 18-169: Loss: 0.0902 Acc: 100.0000%\n",
      "\ttrain 18-170: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 18-171: Loss: 0.1037 Acc: 75.0000%\n",
      "\ttrain 18-172: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 18-173: Loss: 0.0552 Acc: 75.0000%\n",
      "\ttrain 18-174: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 18-175: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 18-176: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 18-177: Loss: 0.3686 Acc: 50.0000%\n",
      "\ttrain 18-178: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 18-179: Loss: 0.0744 Acc: 100.0000%\n",
      "\ttrain 18-180: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 18-181: Loss: 0.1523 Acc: 50.0000%\n",
      "\ttrain 18-182: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 18-183: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 18-184: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 18-185: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 18-186: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 18-187: Loss: 0.3898 Acc: 50.0000%\n",
      "\ttrain 18-188: Loss: 0.2079 Acc: 75.0000%\n",
      "\ttrain 18-189: Loss: 0.1641 Acc: 50.0000%\n",
      "\ttrain 18-190: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 18-191: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 18-192: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 18-193: Loss: 0.1379 Acc: 50.0000%\n",
      "\ttrain 18-194: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 18-195: Loss: 0.2998 Acc: 25.0000%\n",
      "\ttrain 18-196: Loss: 0.2236 Acc: 75.0000%\n",
      "\ttrain 18-197: Loss: 0.2932 Acc: 50.0000%\n",
      "\ttrain 18-198: Loss: 0.1316 Acc: 50.0000%\n",
      "\ttrain 18-199: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 18-200: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 18-201: Loss: 0.2428 Acc: 75.0000%\n",
      "\ttrain 18-202: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 18-203: Loss: 0.0823 Acc: 75.0000%\n",
      "\ttrain 18-204: Loss: 0.2175 Acc: 0.0000%\n",
      "\ttrain 18-205: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 18-206: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 18-207: Loss: 0.1004 Acc: 75.0000%\n",
      "\ttrain 18-208: Loss: 0.1075 Acc: 100.0000%\n",
      "\ttrain 18-209: Loss: 0.2026 Acc: 50.0000%\n",
      "\ttrain 18-210: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 18-211: Loss: 0.1291 Acc: 50.0000%\n",
      "\ttrain 18-212: Loss: 0.1844 Acc: 75.0000%\n",
      "\ttrain 18-213: Loss: 0.1395 Acc: 75.0000%\n",
      "\ttrain 18-214: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 18-215: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 18-216: Loss: 0.2229 Acc: 75.0000%\n",
      "\ttrain 18-217: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 18-218: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 18-219: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 18-220: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 18-221: Loss: 0.0819 Acc: 100.0000%\n",
      "\ttrain 18-222: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 18-223: Loss: 0.0717 Acc: 75.0000%\n",
      "\ttrain 18-224: Loss: 0.0818 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 18-225: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 18-226: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 18-227: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 18-228: Loss: 0.0456 Acc: 100.0000%\n",
      "\ttrain 18-229: Loss: 0.1016 Acc: 75.0000%\n",
      "\ttrain 18-230: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 18-231: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 18-232: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 18-233: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 18-234: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 18-235: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 18-236: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 18-237: Loss: 0.1298 Acc: 75.0000%\n",
      "\ttrain 18-238: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 18-239: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 18-240: Loss: 0.1263 Acc: 100.0000%\n",
      "\ttrain 18-241: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 18-242: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 18-243: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 18-244: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 18-245: Loss: 0.1119 Acc: 75.0000%\n",
      "\tvalidation 18-1: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 18-2: Loss: 0.0276 Acc: 100.0000%\n",
      "\tvalidation 18-3: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 18-4: Loss: 0.0965 Acc: 75.0000%\n",
      "\tvalidation 18-5: Loss: 0.0601 Acc: 100.0000%\n",
      "\tvalidation 18-6: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 18-7: Loss: 0.0153 Acc: 100.0000%\n",
      "\tvalidation 18-8: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 18-9: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 18-10: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 18-11: Loss: 0.0427 Acc: 100.0000%\n",
      "\tvalidation 18-12: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 18-13: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 18-14: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 18-15: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 18-16: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 18-17: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 18-18: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 18-19: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 18-20: Loss: 0.0298 Acc: 100.0000%\n",
      "\tvalidation 18-21: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 18-22: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 18-23: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 18-24: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 18-25: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 18-26: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 18-27: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 18-28: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 18-29: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 18-30: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 18-31: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 18-32: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 18-33: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 18-34: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 18-35: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 18-36: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 18-37: Loss: 0.0627 Acc: 75.0000%\n",
      "\tvalidation 18-38: Loss: 0.1072 Acc: 75.0000%\n",
      "\tvalidation 18-39: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 18-40: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 18-41: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 18-42: Loss: 0.1127 Acc: 50.0000%\n",
      "\tvalidation 18-43: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 18-44: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 18-45: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 18-46: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 18-47: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 18-48: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 18-49: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 18-50: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 18-51: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 18-52: Loss: 0.0627 Acc: 75.0000%\n",
      "\tvalidation 18-53: Loss: 0.1014 Acc: 75.0000%\n",
      "\tvalidation 18-54: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 18-55: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 18-56: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 18-57: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 18-58: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 18-59: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 18-60: Loss: 0.0500 Acc: 75.0000%\n",
      "\tvalidation 18-61: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 18-62: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 18-63: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 18-64: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 18-65: Loss: 0.0339 Acc: 100.0000%\n",
      "\tvalidation 18-66: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 18-67: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 18-68: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 18-69: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 18-70: Loss: 0.0760 Acc: 75.0000%\n",
      "\tvalidation 18-71: Loss: 0.0639 Acc: 75.0000%\n",
      "\tvalidation 18-72: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 18-73: Loss: 0.1213 Acc: 75.0000%\n",
      "\tvalidation 18-74: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 18-75: Loss: 0.0561 Acc: 75.0000%\n",
      "\tvalidation 18-76: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 18-77: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 18-78: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 18-79: Loss: 0.0476 Acc: 100.0000%\n",
      "\tvalidation 18-80: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 18-81: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 18-82: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 18-83: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 18-84: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 18-85: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 18-86: Loss: 0.0969 Acc: 75.0000%\n",
      "\tvalidation 18-87: Loss: 0.1132 Acc: 75.0000%\n",
      "\tvalidation 18-88: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 18-89: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 18-90: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 18-91: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 18-92: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 18-93: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 18-94: Loss: 0.0243 Acc: 100.0000%\n",
      "\tvalidation 18-95: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 18-96: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 18-97: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 18-98: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 18-99: Loss: 0.0946 Acc: 75.0000%\n",
      "\tvalidation 18-100: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 18-101: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 18-102: Loss: 0.0357 Acc: 100.0000%\n",
      "\tvalidation 18-103: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 18-104: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 18-105: Loss: 0.2002 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0815 Acc: 86.1224%\n",
      "\tvalidation Loss: 0.0281 Acc: 96.1905%\n",
      "网络参数更新\n",
      "Time passed 0h 12m 47s\n",
      "--------------------\n",
      "Epoch [19/40]:\n",
      "\ttrain 19-1: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 19-2: Loss: 0.2173 Acc: 50.0000%\n",
      "\ttrain 19-3: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 19-4: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 19-5: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 19-6: Loss: 0.2656 Acc: 75.0000%\n",
      "\ttrain 19-7: Loss: 0.2255 Acc: 75.0000%\n",
      "\ttrain 19-8: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 19-9: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 19-10: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 19-11: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 19-12: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 19-13: Loss: 0.1647 Acc: 50.0000%\n",
      "\ttrain 19-14: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 19-15: Loss: 0.1521 Acc: 75.0000%\n",
      "\ttrain 19-16: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 19-17: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 19-18: Loss: 0.1061 Acc: 75.0000%\n",
      "\ttrain 19-19: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 19-20: Loss: 0.1848 Acc: 75.0000%\n",
      "\ttrain 19-21: Loss: 0.2108 Acc: 75.0000%\n",
      "\ttrain 19-22: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 19-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 19-24: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 19-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 19-26: Loss: 0.1465 Acc: 75.0000%\n",
      "\ttrain 19-27: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 19-28: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 19-29: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 19-30: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 19-31: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 19-32: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 19-33: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 19-34: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 19-35: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 19-36: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 19-37: Loss: 0.0554 Acc: 75.0000%\n",
      "\ttrain 19-38: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 19-39: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 19-40: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 19-41: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 19-42: Loss: 0.0679 Acc: 100.0000%\n",
      "\ttrain 19-43: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 19-44: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 19-45: Loss: 0.1933 Acc: 75.0000%\n",
      "\ttrain 19-46: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 19-47: Loss: 0.1860 Acc: 75.0000%\n",
      "\ttrain 19-48: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 19-49: Loss: 0.0849 Acc: 75.0000%\n",
      "\ttrain 19-50: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 19-51: Loss: 0.2277 Acc: 50.0000%\n",
      "\ttrain 19-52: Loss: 0.1877 Acc: 75.0000%\n",
      "\ttrain 19-53: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 19-54: Loss: 0.0562 Acc: 100.0000%\n",
      "\ttrain 19-55: Loss: 0.0102 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 19-56: Loss: 0.0783 Acc: 100.0000%\n",
      "\ttrain 19-57: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 19-58: Loss: 0.1466 Acc: 75.0000%\n",
      "\ttrain 19-59: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 19-60: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 19-61: Loss: 0.0582 Acc: 100.0000%\n",
      "\ttrain 19-62: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 19-63: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 19-64: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 19-65: Loss: 0.1407 Acc: 50.0000%\n",
      "\ttrain 19-66: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 19-67: Loss: 0.0980 Acc: 75.0000%\n",
      "\ttrain 19-68: Loss: 0.2238 Acc: 75.0000%\n",
      "\ttrain 19-69: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 19-70: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 19-71: Loss: 0.1904 Acc: 50.0000%\n",
      "\ttrain 19-72: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 19-73: Loss: 0.0662 Acc: 100.0000%\n",
      "\ttrain 19-74: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 19-75: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 19-76: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 19-77: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 19-78: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 19-79: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 19-80: Loss: 0.0520 Acc: 75.0000%\n",
      "\ttrain 19-81: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 19-82: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 19-83: Loss: 0.0547 Acc: 100.0000%\n",
      "\ttrain 19-84: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 19-85: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 19-86: Loss: 0.0636 Acc: 100.0000%\n",
      "\ttrain 19-87: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 19-88: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 19-89: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 19-90: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 19-91: Loss: 0.1721 Acc: 75.0000%\n",
      "\ttrain 19-92: Loss: 0.2348 Acc: 75.0000%\n",
      "\ttrain 19-93: Loss: 0.3524 Acc: 25.0000%\n",
      "\ttrain 19-94: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 19-95: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 19-96: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 19-97: Loss: 0.1410 Acc: 100.0000%\n",
      "\ttrain 19-98: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 19-99: Loss: 0.0923 Acc: 75.0000%\n",
      "\ttrain 19-100: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 19-101: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 19-102: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 19-103: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 19-104: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 19-105: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 19-106: Loss: 0.0238 Acc: 100.0000%\n",
      "\ttrain 19-107: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 19-108: Loss: 0.1546 Acc: 75.0000%\n",
      "\ttrain 19-109: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 19-110: Loss: 0.1067 Acc: 75.0000%\n",
      "\ttrain 19-111: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 19-112: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 19-113: Loss: 0.0830 Acc: 75.0000%\n",
      "\ttrain 19-114: Loss: 0.1991 Acc: 75.0000%\n",
      "\ttrain 19-115: Loss: 0.1045 Acc: 75.0000%\n",
      "\ttrain 19-116: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 19-117: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 19-118: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 19-119: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 19-120: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 19-121: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 19-122: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 19-123: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 19-124: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 19-125: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 19-126: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 19-127: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 19-128: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 19-129: Loss: 0.5177 Acc: 50.0000%\n",
      "\ttrain 19-130: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 19-131: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 19-132: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 19-133: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 19-134: Loss: 0.0492 Acc: 100.0000%\n",
      "\ttrain 19-135: Loss: 0.2796 Acc: 75.0000%\n",
      "\ttrain 19-136: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 19-137: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 19-138: Loss: 0.1852 Acc: 75.0000%\n",
      "\ttrain 19-139: Loss: 0.1466 Acc: 50.0000%\n",
      "\ttrain 19-140: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 19-141: Loss: 0.0726 Acc: 100.0000%\n",
      "\ttrain 19-142: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 19-143: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 19-144: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 19-145: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 19-146: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 19-147: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 19-148: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 19-149: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 19-150: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 19-151: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 19-152: Loss: 0.0943 Acc: 75.0000%\n",
      "\ttrain 19-153: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 19-154: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 19-155: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 19-156: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 19-157: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 19-158: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 19-159: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 19-160: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 19-161: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 19-162: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 19-163: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 19-164: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 19-165: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 19-166: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 19-167: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 19-168: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 19-169: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 19-170: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 19-171: Loss: 0.1452 Acc: 75.0000%\n",
      "\ttrain 19-172: Loss: 0.0998 Acc: 75.0000%\n",
      "\ttrain 19-173: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 19-174: Loss: 0.2529 Acc: 75.0000%\n",
      "\ttrain 19-175: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 19-176: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 19-177: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 19-178: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 19-179: Loss: 0.1080 Acc: 75.0000%\n",
      "\ttrain 19-180: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 19-181: Loss: 0.2738 Acc: 50.0000%\n",
      "\ttrain 19-182: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 19-183: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 19-184: Loss: 0.3730 Acc: 50.0000%\n",
      "\ttrain 19-185: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 19-186: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 19-187: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 19-188: Loss: 0.1842 Acc: 50.0000%\n",
      "\ttrain 19-189: Loss: 0.1091 Acc: 75.0000%\n",
      "\ttrain 19-190: Loss: 0.0894 Acc: 75.0000%\n",
      "\ttrain 19-191: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 19-192: Loss: 0.0942 Acc: 75.0000%\n",
      "\ttrain 19-193: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 19-194: Loss: 0.0719 Acc: 100.0000%\n",
      "\ttrain 19-195: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 19-196: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 19-197: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 19-198: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 19-199: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 19-200: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 19-201: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 19-202: Loss: 0.1403 Acc: 75.0000%\n",
      "\ttrain 19-203: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 19-204: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 19-205: Loss: 0.3508 Acc: 75.0000%\n",
      "\ttrain 19-206: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 19-207: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 19-208: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 19-209: Loss: 0.2789 Acc: 25.0000%\n",
      "\ttrain 19-210: Loss: 0.2178 Acc: 50.0000%\n",
      "\ttrain 19-211: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 19-212: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 19-213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 19-214: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 19-215: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 19-216: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 19-217: Loss: 0.1922 Acc: 75.0000%\n",
      "\ttrain 19-218: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 19-219: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 19-220: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 19-221: Loss: 0.1907 Acc: 75.0000%\n",
      "\ttrain 19-222: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 19-223: Loss: 0.0689 Acc: 100.0000%\n",
      "\ttrain 19-224: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 19-225: Loss: 0.1709 Acc: 75.0000%\n",
      "\ttrain 19-226: Loss: 0.1285 Acc: 100.0000%\n",
      "\ttrain 19-227: Loss: 0.0695 Acc: 100.0000%\n",
      "\ttrain 19-228: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 19-229: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 19-230: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 19-231: Loss: 0.1200 Acc: 75.0000%\n",
      "\ttrain 19-232: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 19-233: Loss: 0.0545 Acc: 100.0000%\n",
      "\ttrain 19-234: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 19-235: Loss: 0.0988 Acc: 75.0000%\n",
      "\ttrain 19-236: Loss: 0.3161 Acc: 75.0000%\n",
      "\ttrain 19-237: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 19-238: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 19-239: Loss: 0.2175 Acc: 50.0000%\n",
      "\ttrain 19-240: Loss: 0.0498 Acc: 75.0000%\n",
      "\ttrain 19-241: Loss: 0.0575 Acc: 75.0000%\n",
      "\ttrain 19-242: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 19-243: Loss: 0.1362 Acc: 75.0000%\n",
      "\ttrain 19-244: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 19-245: Loss: 0.0641 Acc: 75.0000%\n",
      "\tvalidation 19-1: Loss: 0.0484 Acc: 100.0000%\n",
      "\tvalidation 19-2: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 19-3: Loss: 0.1310 Acc: 75.0000%\n",
      "\tvalidation 19-4: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 19-5: Loss: 0.0083 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 19-6: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 19-7: Loss: 0.0535 Acc: 100.0000%\n",
      "\tvalidation 19-8: Loss: 0.0935 Acc: 100.0000%\n",
      "\tvalidation 19-9: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 19-10: Loss: 0.0361 Acc: 100.0000%\n",
      "\tvalidation 19-11: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 19-12: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 19-13: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 19-14: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 19-15: Loss: 0.0415 Acc: 100.0000%\n",
      "\tvalidation 19-16: Loss: 0.0394 Acc: 100.0000%\n",
      "\tvalidation 19-17: Loss: 0.0684 Acc: 75.0000%\n",
      "\tvalidation 19-18: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 19-19: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 19-20: Loss: 0.0634 Acc: 100.0000%\n",
      "\tvalidation 19-21: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 19-22: Loss: 0.0133 Acc: 100.0000%\n",
      "\tvalidation 19-23: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 19-24: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 19-25: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 19-26: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 19-27: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 19-28: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 19-29: Loss: 0.0516 Acc: 100.0000%\n",
      "\tvalidation 19-30: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 19-31: Loss: 0.0470 Acc: 100.0000%\n",
      "\tvalidation 19-32: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 19-33: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 19-34: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 19-35: Loss: 0.0278 Acc: 100.0000%\n",
      "\tvalidation 19-36: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 19-37: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 19-38: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 19-39: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 19-40: Loss: 0.0562 Acc: 100.0000%\n",
      "\tvalidation 19-41: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 19-42: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 19-43: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 19-44: Loss: 0.0650 Acc: 75.0000%\n",
      "\tvalidation 19-45: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 19-46: Loss: 0.0721 Acc: 75.0000%\n",
      "\tvalidation 19-47: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 19-48: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 19-49: Loss: 0.0455 Acc: 100.0000%\n",
      "\tvalidation 19-50: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 19-51: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 19-52: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 19-53: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 19-54: Loss: 0.0324 Acc: 100.0000%\n",
      "\tvalidation 19-55: Loss: 0.0393 Acc: 100.0000%\n",
      "\tvalidation 19-56: Loss: 0.0305 Acc: 100.0000%\n",
      "\tvalidation 19-57: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 19-58: Loss: 0.0673 Acc: 75.0000%\n",
      "\tvalidation 19-59: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 19-60: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 19-61: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 19-62: Loss: 0.0426 Acc: 100.0000%\n",
      "\tvalidation 19-63: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 19-64: Loss: 0.0659 Acc: 100.0000%\n",
      "\tvalidation 19-65: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 19-66: Loss: 0.0530 Acc: 100.0000%\n",
      "\tvalidation 19-67: Loss: 0.0426 Acc: 100.0000%\n",
      "\tvalidation 19-68: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 19-69: Loss: 0.0601 Acc: 75.0000%\n",
      "\tvalidation 19-70: Loss: 0.0596 Acc: 100.0000%\n",
      "\tvalidation 19-71: Loss: 0.0501 Acc: 100.0000%\n",
      "\tvalidation 19-72: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 19-73: Loss: 0.0534 Acc: 100.0000%\n",
      "\tvalidation 19-74: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 19-75: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 19-76: Loss: 0.0317 Acc: 100.0000%\n",
      "\tvalidation 19-77: Loss: 0.0313 Acc: 100.0000%\n",
      "\tvalidation 19-78: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 19-79: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 19-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 19-81: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 19-82: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 19-83: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 19-84: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 19-85: Loss: 0.0529 Acc: 100.0000%\n",
      "\tvalidation 19-86: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 19-87: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 19-88: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 19-89: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 19-90: Loss: 0.0280 Acc: 100.0000%\n",
      "\tvalidation 19-91: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 19-92: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 19-93: Loss: 0.0545 Acc: 100.0000%\n",
      "\tvalidation 19-94: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 19-95: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 19-96: Loss: 0.0494 Acc: 100.0000%\n",
      "\tvalidation 19-97: Loss: 0.0234 Acc: 100.0000%\n",
      "\tvalidation 19-98: Loss: 0.0478 Acc: 100.0000%\n",
      "\tvalidation 19-99: Loss: 0.0228 Acc: 100.0000%\n",
      "\tvalidation 19-100: Loss: 0.0642 Acc: 100.0000%\n",
      "\tvalidation 19-101: Loss: 0.0352 Acc: 100.0000%\n",
      "\tvalidation 19-102: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 19-103: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 19-104: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 19-105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0713 Acc: 89.4898%\n",
      "\tvalidation Loss: 0.0284 Acc: 98.5714%\n",
      "网络参数更新\n",
      "Time passed 0h 13m 32s\n",
      "--------------------\n",
      "Epoch [20/40]:\n",
      "\ttrain 20-1: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 20-2: Loss: 0.3065 Acc: 50.0000%\n",
      "\ttrain 20-3: Loss: 0.0544 Acc: 100.0000%\n",
      "\ttrain 20-4: Loss: 0.1210 Acc: 75.0000%\n",
      "\ttrain 20-5: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 20-6: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 20-7: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 20-8: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 20-9: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 20-10: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 20-11: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 20-12: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 20-13: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 20-14: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 20-15: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 20-16: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 20-17: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 20-18: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 20-19: Loss: 0.1365 Acc: 75.0000%\n",
      "\ttrain 20-20: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 20-21: Loss: 0.1658 Acc: 75.0000%\n",
      "\ttrain 20-22: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 20-23: Loss: 0.2596 Acc: 50.0000%\n",
      "\ttrain 20-24: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 20-25: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 20-26: Loss: 0.1060 Acc: 75.0000%\n",
      "\ttrain 20-27: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 20-28: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 20-29: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 20-30: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 20-31: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 20-32: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 20-33: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 20-34: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 20-35: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 20-36: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 20-37: Loss: 0.0612 Acc: 100.0000%\n",
      "\ttrain 20-38: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 20-39: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 20-40: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 20-41: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 20-42: Loss: 0.2490 Acc: 75.0000%\n",
      "\ttrain 20-43: Loss: 0.0488 Acc: 100.0000%\n",
      "\ttrain 20-44: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 20-45: Loss: 0.0730 Acc: 100.0000%\n",
      "\ttrain 20-46: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 20-47: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 20-48: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 20-49: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 20-50: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 20-51: Loss: 0.1842 Acc: 50.0000%\n",
      "\ttrain 20-52: Loss: 0.1240 Acc: 75.0000%\n",
      "\ttrain 20-53: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 20-54: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 20-55: Loss: 0.0549 Acc: 75.0000%\n",
      "\ttrain 20-56: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 20-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 20-58: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 20-59: Loss: 0.9764 Acc: 25.0000%\n",
      "\ttrain 20-60: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 20-61: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 20-62: Loss: 0.3188 Acc: 25.0000%\n",
      "\ttrain 20-63: Loss: 0.5236 Acc: 25.0000%\n",
      "\ttrain 20-64: Loss: 0.7988 Acc: 25.0000%\n",
      "\ttrain 20-65: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 20-66: Loss: 0.1414 Acc: 50.0000%\n",
      "\ttrain 20-67: Loss: 0.1639 Acc: 50.0000%\n",
      "\ttrain 20-68: Loss: 0.0843 Acc: 75.0000%\n",
      "\ttrain 20-69: Loss: 0.1725 Acc: 50.0000%\n",
      "\ttrain 20-70: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 20-71: Loss: 0.3025 Acc: 25.0000%\n",
      "\ttrain 20-72: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 20-73: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 20-74: Loss: 0.2516 Acc: 50.0000%\n",
      "\ttrain 20-75: Loss: 0.0735 Acc: 100.0000%\n",
      "\ttrain 20-76: Loss: 0.1414 Acc: 50.0000%\n",
      "\ttrain 20-77: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 20-78: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 20-79: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 20-80: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 20-81: Loss: 0.0567 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 20-82: Loss: 0.1062 Acc: 100.0000%\n",
      "\ttrain 20-83: Loss: 0.0856 Acc: 100.0000%\n",
      "\ttrain 20-84: Loss: 0.1378 Acc: 75.0000%\n",
      "\ttrain 20-85: Loss: 0.0739 Acc: 100.0000%\n",
      "\ttrain 20-86: Loss: 0.1364 Acc: 50.0000%\n",
      "\ttrain 20-87: Loss: 0.0593 Acc: 100.0000%\n",
      "\ttrain 20-88: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 20-89: Loss: 0.1548 Acc: 25.0000%\n",
      "\ttrain 20-90: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 20-91: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 20-92: Loss: 0.2211 Acc: 50.0000%\n",
      "\ttrain 20-93: Loss: 0.0799 Acc: 100.0000%\n",
      "\ttrain 20-94: Loss: 0.0763 Acc: 100.0000%\n",
      "\ttrain 20-95: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 20-96: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 20-97: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 20-98: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 20-99: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 20-100: Loss: 0.4396 Acc: 50.0000%\n",
      "\ttrain 20-101: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 20-102: Loss: 0.0806 Acc: 100.0000%\n",
      "\ttrain 20-103: Loss: 0.0846 Acc: 100.0000%\n",
      "\ttrain 20-104: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 20-105: Loss: 0.1861 Acc: 75.0000%\n",
      "\ttrain 20-106: Loss: 0.0904 Acc: 100.0000%\n",
      "\ttrain 20-107: Loss: 0.1237 Acc: 75.0000%\n",
      "\ttrain 20-108: Loss: 0.0716 Acc: 100.0000%\n",
      "\ttrain 20-109: Loss: 0.1483 Acc: 50.0000%\n",
      "\ttrain 20-110: Loss: 0.1118 Acc: 50.0000%\n",
      "\ttrain 20-111: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 20-112: Loss: 0.0950 Acc: 75.0000%\n",
      "\ttrain 20-113: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 20-114: Loss: 0.1100 Acc: 75.0000%\n",
      "\ttrain 20-115: Loss: 0.0913 Acc: 100.0000%\n",
      "\ttrain 20-116: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 20-117: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 20-118: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 20-119: Loss: 0.0504 Acc: 100.0000%\n",
      "\ttrain 20-120: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 20-121: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 20-122: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 20-123: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 20-124: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 20-125: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 20-126: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 20-127: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 20-128: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 20-129: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 20-130: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 20-131: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 20-132: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 20-133: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 20-134: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 20-135: Loss: 0.0733 Acc: 100.0000%\n",
      "\ttrain 20-136: Loss: 0.0740 Acc: 100.0000%\n",
      "\ttrain 20-137: Loss: 0.1504 Acc: 75.0000%\n",
      "\ttrain 20-138: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 20-139: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 20-140: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 20-141: Loss: 0.0786 Acc: 75.0000%\n",
      "\ttrain 20-142: Loss: 0.0764 Acc: 75.0000%\n",
      "\ttrain 20-143: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 20-144: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 20-145: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 20-146: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 20-147: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 20-148: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 20-149: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 20-150: Loss: 0.1018 Acc: 75.0000%\n",
      "\ttrain 20-151: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 20-152: Loss: 0.0647 Acc: 100.0000%\n",
      "\ttrain 20-153: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 20-154: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 20-155: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 20-156: Loss: 0.0597 Acc: 100.0000%\n",
      "\ttrain 20-157: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 20-158: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 20-159: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 20-160: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 20-161: Loss: 0.2888 Acc: 50.0000%\n",
      "\ttrain 20-162: Loss: 0.1231 Acc: 75.0000%\n",
      "\ttrain 20-163: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 20-164: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 20-165: Loss: 0.3374 Acc: 75.0000%\n",
      "\ttrain 20-166: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 20-167: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 20-168: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-169: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 20-170: Loss: 0.2398 Acc: 50.0000%\n",
      "\ttrain 20-171: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 20-172: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 20-173: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 20-174: Loss: 0.1630 Acc: 75.0000%\n",
      "\ttrain 20-175: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 20-176: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 20-177: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 20-178: Loss: 0.1380 Acc: 50.0000%\n",
      "\ttrain 20-179: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 20-180: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 20-181: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 20-182: Loss: 0.2470 Acc: 75.0000%\n",
      "\ttrain 20-183: Loss: 0.0813 Acc: 100.0000%\n",
      "\ttrain 20-184: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 20-185: Loss: 0.0805 Acc: 100.0000%\n",
      "\ttrain 20-186: Loss: 0.1120 Acc: 75.0000%\n",
      "\ttrain 20-187: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 20-188: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 20-189: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 20-190: Loss: 0.0620 Acc: 75.0000%\n",
      "\ttrain 20-191: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 20-192: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 20-193: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 20-194: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 20-195: Loss: 0.2425 Acc: 50.0000%\n",
      "\ttrain 20-196: Loss: 0.1632 Acc: 75.0000%\n",
      "\ttrain 20-197: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 20-198: Loss: 0.1362 Acc: 75.0000%\n",
      "\ttrain 20-199: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 20-200: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 20-201: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 20-202: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 20-203: Loss: 0.0756 Acc: 75.0000%\n",
      "\ttrain 20-204: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 20-205: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 20-206: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 20-207: Loss: 0.2179 Acc: 50.0000%\n",
      "\ttrain 20-208: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 20-209: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 20-210: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 20-211: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 20-212: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 20-213: Loss: 0.1924 Acc: 75.0000%\n",
      "\ttrain 20-214: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 20-215: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 20-216: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 20-217: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 20-218: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 20-219: Loss: 0.5799 Acc: 75.0000%\n",
      "\ttrain 20-220: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 20-221: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 20-222: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 20-223: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 20-224: Loss: 0.1593 Acc: 75.0000%\n",
      "\ttrain 20-225: Loss: 0.0718 Acc: 75.0000%\n",
      "\ttrain 20-226: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 20-227: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 20-228: Loss: 0.1320 Acc: 75.0000%\n",
      "\ttrain 20-229: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 20-230: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 20-231: Loss: 0.1351 Acc: 75.0000%\n",
      "\ttrain 20-232: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 20-233: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 20-234: Loss: 0.1884 Acc: 75.0000%\n",
      "\ttrain 20-235: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 20-236: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 20-237: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 20-238: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 20-239: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 20-240: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 20-241: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 20-242: Loss: 0.4290 Acc: 75.0000%\n",
      "\ttrain 20-243: Loss: 0.2921 Acc: 75.0000%\n",
      "\ttrain 20-244: Loss: 0.2009 Acc: 75.0000%\n",
      "\ttrain 20-245: Loss: 0.0767 Acc: 75.0000%\n",
      "\tvalidation 20-1: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 20-2: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 20-3: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 20-4: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 20-5: Loss: 0.0127 Acc: 100.0000%\n",
      "\tvalidation 20-6: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 20-7: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 20-8: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 20-9: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 20-10: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 20-11: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 20-12: Loss: 0.0727 Acc: 75.0000%\n",
      "\tvalidation 20-13: Loss: 0.0447 Acc: 100.0000%\n",
      "\tvalidation 20-14: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 20-15: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 20-16: Loss: 0.0402 Acc: 100.0000%\n",
      "\tvalidation 20-17: Loss: 0.0585 Acc: 100.0000%\n",
      "\tvalidation 20-18: Loss: 0.0387 Acc: 100.0000%\n",
      "\tvalidation 20-19: Loss: 0.0303 Acc: 100.0000%\n",
      "\tvalidation 20-20: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 20-21: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 20-22: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 20-23: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 20-24: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 20-25: Loss: 0.0246 Acc: 100.0000%\n",
      "\tvalidation 20-26: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 20-27: Loss: 0.0403 Acc: 100.0000%\n",
      "\tvalidation 20-28: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 20-29: Loss: 0.0260 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 20-30: Loss: 0.0359 Acc: 100.0000%\n",
      "\tvalidation 20-31: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 20-32: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 20-33: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 20-34: Loss: 0.0738 Acc: 100.0000%\n",
      "\tvalidation 20-35: Loss: 0.0780 Acc: 75.0000%\n",
      "\tvalidation 20-36: Loss: 0.0368 Acc: 100.0000%\n",
      "\tvalidation 20-37: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 20-38: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 20-39: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 20-40: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 20-41: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 20-42: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 20-43: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 20-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 20-45: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 20-46: Loss: 0.0206 Acc: 100.0000%\n",
      "\tvalidation 20-47: Loss: 0.0573 Acc: 75.0000%\n",
      "\tvalidation 20-48: Loss: 0.0288 Acc: 100.0000%\n",
      "\tvalidation 20-49: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 20-50: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 20-51: Loss: 0.0531 Acc: 100.0000%\n",
      "\tvalidation 20-52: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 20-53: Loss: 0.1376 Acc: 75.0000%\n",
      "\tvalidation 20-54: Loss: 0.1080 Acc: 75.0000%\n",
      "\tvalidation 20-55: Loss: 0.0658 Acc: 100.0000%\n",
      "\tvalidation 20-56: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 20-57: Loss: 0.1692 Acc: 50.0000%\n",
      "\tvalidation 20-58: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 20-59: Loss: 0.0403 Acc: 100.0000%\n",
      "\tvalidation 20-60: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 20-61: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 20-62: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 20-63: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 20-64: Loss: 0.0755 Acc: 75.0000%\n",
      "\tvalidation 20-65: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 20-66: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 20-67: Loss: 0.0325 Acc: 100.0000%\n",
      "\tvalidation 20-68: Loss: 0.0559 Acc: 100.0000%\n",
      "\tvalidation 20-69: Loss: 0.0879 Acc: 75.0000%\n",
      "\tvalidation 20-70: Loss: 0.0184 Acc: 100.0000%\n",
      "\tvalidation 20-71: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 20-72: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 20-73: Loss: 0.0829 Acc: 75.0000%\n",
      "\tvalidation 20-74: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 20-75: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 20-76: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 20-77: Loss: 0.0540 Acc: 100.0000%\n",
      "\tvalidation 20-78: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 20-79: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 20-80: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 20-81: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 20-82: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 20-83: Loss: 0.2921 Acc: 75.0000%\n",
      "\tvalidation 20-84: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 20-85: Loss: 0.0775 Acc: 75.0000%\n",
      "\tvalidation 20-86: Loss: 0.1084 Acc: 75.0000%\n",
      "\tvalidation 20-87: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 20-88: Loss: 0.0706 Acc: 75.0000%\n",
      "\tvalidation 20-89: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 20-90: Loss: 0.0316 Acc: 100.0000%\n",
      "\tvalidation 20-91: Loss: 0.0902 Acc: 75.0000%\n",
      "\tvalidation 20-92: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 20-93: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 20-94: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 20-95: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 20-96: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 20-97: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 20-98: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 20-99: Loss: 0.0285 Acc: 100.0000%\n",
      "\tvalidation 20-100: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 20-101: Loss: 0.1005 Acc: 75.0000%\n",
      "\tvalidation 20-102: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 20-103: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 20-104: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 20-105: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0827 Acc: 88.0612%\n",
      "\tvalidation Loss: 0.0357 Acc: 95.9524%\n",
      "Time passed 0h 14m 14s\n",
      "--------------------\n",
      "Epoch [21/40]:\n",
      "\ttrain 21-1: Loss: 0.1046 Acc: 75.0000%\n",
      "\ttrain 21-2: Loss: 0.0398 Acc: 100.0000%\n",
      "\ttrain 21-3: Loss: 0.1196 Acc: 75.0000%\n",
      "\ttrain 21-4: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 21-5: Loss: 0.0738 Acc: 100.0000%\n",
      "\ttrain 21-6: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 21-7: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 21-8: Loss: 0.1922 Acc: 75.0000%\n",
      "\ttrain 21-9: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 21-10: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 21-11: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 21-12: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 21-13: Loss: 0.2392 Acc: 50.0000%\n",
      "\ttrain 21-14: Loss: 0.1497 Acc: 75.0000%\n",
      "\ttrain 21-15: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 21-16: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 21-17: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 21-18: Loss: 0.0569 Acc: 100.0000%\n",
      "\ttrain 21-19: Loss: 0.0356 Acc: 100.0000%\n",
      "\ttrain 21-20: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 21-21: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 21-22: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 21-23: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 21-24: Loss: 0.0888 Acc: 100.0000%\n",
      "\ttrain 21-25: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 21-26: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 21-27: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 21-28: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 21-29: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 21-30: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 21-31: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 21-32: Loss: 0.0779 Acc: 75.0000%\n",
      "\ttrain 21-33: Loss: 0.1503 Acc: 50.0000%\n",
      "\ttrain 21-34: Loss: 0.0580 Acc: 100.0000%\n",
      "\ttrain 21-35: Loss: 0.0609 Acc: 75.0000%\n",
      "\ttrain 21-36: Loss: 0.1515 Acc: 75.0000%\n",
      "\ttrain 21-37: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 21-38: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 21-39: Loss: 0.1756 Acc: 75.0000%\n",
      "\ttrain 21-40: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-41: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 21-42: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 21-43: Loss: 0.1115 Acc: 75.0000%\n",
      "\ttrain 21-44: Loss: 0.0560 Acc: 100.0000%\n",
      "\ttrain 21-45: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 21-46: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 21-47: Loss: 0.0621 Acc: 100.0000%\n",
      "\ttrain 21-48: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 21-49: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-50: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 21-51: Loss: 0.1396 Acc: 50.0000%\n",
      "\ttrain 21-52: Loss: 0.1454 Acc: 75.0000%\n",
      "\ttrain 21-53: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 21-54: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 21-55: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 21-56: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 21-57: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 21-58: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 21-59: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 21-60: Loss: 0.0794 Acc: 75.0000%\n",
      "\ttrain 21-61: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 21-62: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 21-63: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 21-64: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 21-65: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 21-66: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 21-67: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 21-68: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 21-69: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 21-70: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-71: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 21-72: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 21-73: Loss: 0.2115 Acc: 50.0000%\n",
      "\ttrain 21-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 21-75: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 21-76: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 21-77: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 21-78: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 21-79: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 21-80: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 21-81: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 21-82: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 21-83: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 21-84: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 21-85: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 21-86: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 21-87: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 21-88: Loss: 0.0667 Acc: 100.0000%\n",
      "\ttrain 21-89: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 21-90: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 21-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 21-92: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 21-93: Loss: 0.0777 Acc: 75.0000%\n",
      "\ttrain 21-94: Loss: 0.4268 Acc: 25.0000%\n",
      "\ttrain 21-95: Loss: 0.0862 Acc: 75.0000%\n",
      "\ttrain 21-96: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 21-97: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 21-98: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 21-99: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 21-100: Loss: 0.0733 Acc: 75.0000%\n",
      "\ttrain 21-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 21-102: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 21-103: Loss: 0.0845 Acc: 100.0000%\n",
      "\ttrain 21-104: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 21-105: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 21-106: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 21-107: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 21-108: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 21-109: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 21-110: Loss: 0.0121 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 21-111: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 21-112: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 21-113: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 21-114: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 21-115: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 21-116: Loss: 0.2369 Acc: 50.0000%\n",
      "\ttrain 21-117: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 21-118: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-119: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-120: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 21-121: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 21-122: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 21-123: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 21-124: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 21-125: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 21-126: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 21-127: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 21-128: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 21-129: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-130: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 21-131: Loss: 0.2162 Acc: 50.0000%\n",
      "\ttrain 21-132: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 21-133: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 21-134: Loss: 0.3561 Acc: 50.0000%\n",
      "\ttrain 21-135: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 21-136: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 21-137: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 21-138: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 21-139: Loss: 0.0511 Acc: 100.0000%\n",
      "\ttrain 21-140: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 21-141: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 21-142: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 21-143: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 21-144: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 21-145: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 21-146: Loss: 0.1623 Acc: 75.0000%\n",
      "\ttrain 21-147: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 21-148: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 21-149: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 21-150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-151: Loss: 0.0567 Acc: 100.0000%\n",
      "\ttrain 21-152: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 21-153: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 21-154: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 21-155: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 21-156: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 21-157: Loss: 0.1980 Acc: 50.0000%\n",
      "\ttrain 21-158: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 21-159: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 21-160: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 21-161: Loss: 0.3584 Acc: 50.0000%\n",
      "\ttrain 21-162: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 21-163: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 21-164: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 21-165: Loss: 0.2104 Acc: 75.0000%\n",
      "\ttrain 21-166: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 21-167: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 21-168: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 21-169: Loss: 0.1096 Acc: 75.0000%\n",
      "\ttrain 21-170: Loss: 0.1000 Acc: 75.0000%\n",
      "\ttrain 21-171: Loss: 0.1944 Acc: 75.0000%\n",
      "\ttrain 21-172: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 21-173: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 21-174: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 21-175: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 21-176: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 21-177: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 21-178: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 21-179: Loss: 0.0905 Acc: 75.0000%\n",
      "\ttrain 21-180: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 21-181: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 21-182: Loss: 0.1393 Acc: 75.0000%\n",
      "\ttrain 21-183: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 21-184: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 21-185: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 21-186: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 21-187: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 21-188: Loss: 0.3630 Acc: 75.0000%\n",
      "\ttrain 21-189: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 21-190: Loss: 0.2190 Acc: 75.0000%\n",
      "\ttrain 21-191: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 21-192: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 21-193: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 21-194: Loss: 0.2152 Acc: 50.0000%\n",
      "\ttrain 21-195: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 21-196: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 21-197: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 21-198: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 21-199: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 21-200: Loss: 0.1739 Acc: 75.0000%\n",
      "\ttrain 21-201: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 21-202: Loss: 0.0511 Acc: 75.0000%\n",
      "\ttrain 21-203: Loss: 0.0774 Acc: 100.0000%\n",
      "\ttrain 21-204: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 21-205: Loss: 0.0524 Acc: 75.0000%\n",
      "\ttrain 21-206: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 21-207: Loss: 0.2763 Acc: 75.0000%\n",
      "\ttrain 21-208: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 21-209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 21-210: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-211: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 21-212: Loss: 0.1617 Acc: 50.0000%\n",
      "\ttrain 21-213: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 21-214: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 21-215: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 21-216: Loss: 0.0663 Acc: 100.0000%\n",
      "\ttrain 21-217: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 21-218: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 21-219: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 21-220: Loss: 0.0672 Acc: 75.0000%\n",
      "\ttrain 21-221: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 21-222: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 21-223: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 21-224: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 21-225: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 21-226: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 21-227: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 21-228: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 21-229: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 21-230: Loss: 0.1842 Acc: 75.0000%\n",
      "\ttrain 21-231: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 21-232: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 21-233: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 21-234: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 21-235: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 21-236: Loss: 0.0719 Acc: 75.0000%\n",
      "\ttrain 21-237: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 21-238: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 21-239: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 21-240: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 21-241: Loss: 0.0476 Acc: 75.0000%\n",
      "\ttrain 21-242: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 21-243: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 21-244: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 21-245: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 21-1: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 21-2: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 21-3: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 21-4: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-5: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-6: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 21-7: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 21-8: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 21-9: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 21-10: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 21-11: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 21-12: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 21-13: Loss: 0.0907 Acc: 75.0000%\n",
      "\tvalidation 21-14: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 21-15: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 21-16: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 21-17: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 21-18: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 21-19: Loss: 0.0146 Acc: 100.0000%\n",
      "\tvalidation 21-20: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 21-21: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 21-22: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 21-23: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-24: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 21-25: Loss: 0.0296 Acc: 100.0000%\n",
      "\tvalidation 21-26: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 21-27: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 21-28: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 21-29: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 21-30: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 21-31: Loss: 0.0885 Acc: 75.0000%\n",
      "\tvalidation 21-32: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 21-33: Loss: 0.0598 Acc: 75.0000%\n",
      "\tvalidation 21-34: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 21-35: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 21-36: Loss: 0.1081 Acc: 75.0000%\n",
      "\tvalidation 21-37: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 21-38: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 21-39: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 21-40: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 21-41: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 21-42: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 21-43: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 21-44: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 21-45: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 21-46: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 21-47: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 21-48: Loss: 0.0499 Acc: 75.0000%\n",
      "\tvalidation 21-49: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 21-50: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 21-51: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 21-52: Loss: 0.1042 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 21-53: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 21-54: Loss: 0.0228 Acc: 100.0000%\n",
      "\tvalidation 21-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 21-56: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 21-57: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 21-58: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 21-59: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 21-60: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 21-61: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 21-62: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 21-63: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 21-64: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 21-65: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 21-66: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 21-67: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 21-68: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 21-69: Loss: 0.0812 Acc: 75.0000%\n",
      "\tvalidation 21-70: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 21-71: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 21-72: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 21-73: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 21-74: Loss: 0.0473 Acc: 100.0000%\n",
      "\tvalidation 21-75: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 21-76: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 21-77: Loss: 0.0201 Acc: 100.0000%\n",
      "\tvalidation 21-78: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 21-79: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 21-80: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 21-81: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 21-82: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 21-83: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 21-84: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 21-85: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 21-86: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 21-87: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 21-88: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 21-89: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 21-90: Loss: 0.1327 Acc: 75.0000%\n",
      "\tvalidation 21-91: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 21-92: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 21-93: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 21-94: Loss: 0.0824 Acc: 100.0000%\n",
      "\tvalidation 21-95: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 21-96: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 21-97: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 21-98: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 21-99: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 21-100: Loss: 0.0371 Acc: 100.0000%\n",
      "\tvalidation 21-101: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 21-102: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 21-103: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 21-104: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 21-105: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0554 Acc: 91.9388%\n",
      "\tvalidation Loss: 0.0152 Acc: 98.0952%\n",
      "Time passed 0h 14m 56s\n",
      "--------------------\n",
      "Epoch [22/40]:\n",
      "\ttrain 22-1: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 22-2: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 22-3: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 22-4: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 22-5: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 22-6: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 22-7: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 22-8: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 22-9: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 22-10: Loss: 0.1875 Acc: 75.0000%\n",
      "\ttrain 22-11: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 22-12: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 22-13: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 22-14: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 22-15: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 22-16: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 22-17: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 22-18: Loss: 0.2917 Acc: 75.0000%\n",
      "\ttrain 22-19: Loss: 0.4641 Acc: 50.0000%\n",
      "\ttrain 22-20: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 22-21: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 22-22: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 22-23: Loss: 0.1447 Acc: 75.0000%\n",
      "\ttrain 22-24: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 22-25: Loss: 0.0820 Acc: 75.0000%\n",
      "\ttrain 22-26: Loss: 0.1373 Acc: 75.0000%\n",
      "\ttrain 22-27: Loss: 0.0497 Acc: 100.0000%\n",
      "\ttrain 22-28: Loss: 0.1861 Acc: 75.0000%\n",
      "\ttrain 22-29: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 22-30: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 22-31: Loss: 0.0792 Acc: 75.0000%\n",
      "\ttrain 22-32: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 22-33: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 22-34: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 22-35: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 22-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 22-37: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 22-38: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 22-39: Loss: 0.0526 Acc: 100.0000%\n",
      "\ttrain 22-40: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 22-41: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 22-42: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 22-43: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 22-44: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 22-45: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 22-46: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 22-47: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 22-48: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 22-49: Loss: 0.0471 Acc: 100.0000%\n",
      "\ttrain 22-50: Loss: 0.0725 Acc: 75.0000%\n",
      "\ttrain 22-51: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 22-52: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 22-53: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 22-54: Loss: 0.0614 Acc: 75.0000%\n",
      "\ttrain 22-55: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 22-56: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 22-57: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 22-58: Loss: 0.1294 Acc: 75.0000%\n",
      "\ttrain 22-59: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 22-60: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 22-61: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 22-62: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 22-63: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 22-64: Loss: 0.0367 Acc: 100.0000%\n",
      "\ttrain 22-65: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 22-66: Loss: 0.0642 Acc: 75.0000%\n",
      "\ttrain 22-67: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 22-68: Loss: 0.1065 Acc: 50.0000%\n",
      "\ttrain 22-69: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 22-70: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 22-71: Loss: 0.1680 Acc: 75.0000%\n",
      "\ttrain 22-72: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 22-73: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 22-74: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 22-75: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 22-76: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 22-77: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 22-78: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 22-79: Loss: 0.1713 Acc: 75.0000%\n",
      "\ttrain 22-80: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 22-81: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 22-82: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 22-83: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 22-84: Loss: 0.1795 Acc: 50.0000%\n",
      "\ttrain 22-85: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 22-86: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 22-87: Loss: 0.0589 Acc: 100.0000%\n",
      "\ttrain 22-88: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 22-89: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 22-90: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 22-91: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 22-92: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 22-93: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 22-94: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 22-95: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 22-96: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 22-97: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 22-98: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 22-99: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 22-100: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 22-101: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 22-102: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 22-103: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 22-104: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 22-105: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 22-106: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 22-107: Loss: 0.3102 Acc: 50.0000%\n",
      "\ttrain 22-108: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 22-109: Loss: 0.1014 Acc: 75.0000%\n",
      "\ttrain 22-110: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 22-111: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 22-112: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 22-113: Loss: 0.1747 Acc: 75.0000%\n",
      "\ttrain 22-114: Loss: 0.0856 Acc: 75.0000%\n",
      "\ttrain 22-115: Loss: 0.1458 Acc: 75.0000%\n",
      "\ttrain 22-116: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 22-117: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 22-118: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 22-119: Loss: 0.2011 Acc: 75.0000%\n",
      "\ttrain 22-120: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 22-121: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 22-122: Loss: 0.4236 Acc: 75.0000%\n",
      "\ttrain 22-123: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 22-124: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 22-125: Loss: 0.2714 Acc: 75.0000%\n",
      "\ttrain 22-126: Loss: 0.0752 Acc: 75.0000%\n",
      "\ttrain 22-127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 22-128: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 22-129: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 22-130: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 22-131: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 22-132: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 22-133: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 22-134: Loss: 0.0289 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 22-135: Loss: 0.1603 Acc: 50.0000%\n",
      "\ttrain 22-136: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 22-137: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 22-138: Loss: 0.3240 Acc: 50.0000%\n",
      "\ttrain 22-139: Loss: 0.2347 Acc: 75.0000%\n",
      "\ttrain 22-140: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 22-141: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 22-142: Loss: 0.6741 Acc: 25.0000%\n",
      "\ttrain 22-143: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 22-144: Loss: 0.0698 Acc: 75.0000%\n",
      "\ttrain 22-145: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 22-146: Loss: 0.1417 Acc: 75.0000%\n",
      "\ttrain 22-147: Loss: 0.0958 Acc: 75.0000%\n",
      "\ttrain 22-148: Loss: 0.3823 Acc: 25.0000%\n",
      "\ttrain 22-149: Loss: 0.2314 Acc: 50.0000%\n",
      "\ttrain 22-150: Loss: 0.3893 Acc: 25.0000%\n",
      "\ttrain 22-151: Loss: 0.2635 Acc: 50.0000%\n",
      "\ttrain 22-152: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 22-153: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 22-154: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 22-155: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 22-156: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 22-157: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 22-158: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 22-159: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 22-160: Loss: 0.3040 Acc: 50.0000%\n",
      "\ttrain 22-161: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 22-162: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 22-163: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 22-164: Loss: 0.1258 Acc: 75.0000%\n",
      "\ttrain 22-165: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 22-166: Loss: 0.1559 Acc: 75.0000%\n",
      "\ttrain 22-167: Loss: 0.2374 Acc: 75.0000%\n",
      "\ttrain 22-168: Loss: 0.8617 Acc: 75.0000%\n",
      "\ttrain 22-169: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 22-170: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 22-171: Loss: 0.0542 Acc: 75.0000%\n",
      "\ttrain 22-172: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 22-173: Loss: 0.1005 Acc: 75.0000%\n",
      "\ttrain 22-174: Loss: 0.1457 Acc: 50.0000%\n",
      "\ttrain 22-175: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 22-176: Loss: 0.0960 Acc: 100.0000%\n",
      "\ttrain 22-177: Loss: 0.0609 Acc: 100.0000%\n",
      "\ttrain 22-178: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 22-179: Loss: 0.0906 Acc: 75.0000%\n",
      "\ttrain 22-180: Loss: 0.0714 Acc: 100.0000%\n",
      "\ttrain 22-181: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 22-182: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 22-183: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 22-184: Loss: 0.0715 Acc: 100.0000%\n",
      "\ttrain 22-185: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 22-186: Loss: 0.1543 Acc: 75.0000%\n",
      "\ttrain 22-187: Loss: 0.1058 Acc: 75.0000%\n",
      "\ttrain 22-188: Loss: 0.0963 Acc: 100.0000%\n",
      "\ttrain 22-189: Loss: 0.0668 Acc: 100.0000%\n",
      "\ttrain 22-190: Loss: 0.2227 Acc: 50.0000%\n",
      "\ttrain 22-191: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 22-192: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 22-193: Loss: 0.1830 Acc: 75.0000%\n",
      "\ttrain 22-194: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 22-195: Loss: 0.0618 Acc: 100.0000%\n",
      "\ttrain 22-196: Loss: 0.1263 Acc: 75.0000%\n",
      "\ttrain 22-197: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 22-198: Loss: 0.0933 Acc: 100.0000%\n",
      "\ttrain 22-199: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 22-200: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 22-201: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 22-202: Loss: 0.0757 Acc: 75.0000%\n",
      "\ttrain 22-203: Loss: 0.0785 Acc: 100.0000%\n",
      "\ttrain 22-204: Loss: 0.2000 Acc: 75.0000%\n",
      "\ttrain 22-205: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 22-206: Loss: 0.1299 Acc: 75.0000%\n",
      "\ttrain 22-207: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 22-208: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 22-209: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 22-210: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 22-211: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 22-212: Loss: 0.3650 Acc: 75.0000%\n",
      "\ttrain 22-213: Loss: 0.0703 Acc: 75.0000%\n",
      "\ttrain 22-214: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 22-215: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 22-216: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 22-217: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 22-218: Loss: 0.0684 Acc: 100.0000%\n",
      "\ttrain 22-219: Loss: 0.1587 Acc: 75.0000%\n",
      "\ttrain 22-220: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 22-221: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 22-222: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 22-223: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 22-224: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 22-225: Loss: 0.1785 Acc: 50.0000%\n",
      "\ttrain 22-226: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 22-227: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 22-228: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 22-229: Loss: 0.0894 Acc: 100.0000%\n",
      "\ttrain 22-230: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 22-231: Loss: 0.0495 Acc: 100.0000%\n",
      "\ttrain 22-232: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 22-233: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 22-234: Loss: 0.3439 Acc: 75.0000%\n",
      "\ttrain 22-235: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 22-236: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 22-237: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 22-238: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 22-239: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 22-240: Loss: 0.1220 Acc: 75.0000%\n",
      "\ttrain 22-241: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 22-242: Loss: 0.0475 Acc: 100.0000%\n",
      "\ttrain 22-243: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 22-244: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 22-245: Loss: 0.1034 Acc: 75.0000%\n",
      "\tvalidation 22-1: Loss: 0.0822 Acc: 75.0000%\n",
      "\tvalidation 22-2: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 22-3: Loss: 0.0468 Acc: 100.0000%\n",
      "\tvalidation 22-4: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 22-5: Loss: 0.0360 Acc: 100.0000%\n",
      "\tvalidation 22-6: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 22-7: Loss: 0.0795 Acc: 75.0000%\n",
      "\tvalidation 22-8: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 22-9: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 22-10: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 22-11: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 22-12: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 22-13: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 22-14: Loss: 0.0641 Acc: 100.0000%\n",
      "\tvalidation 22-15: Loss: 0.0252 Acc: 100.0000%\n",
      "\tvalidation 22-16: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-17: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 22-18: Loss: 0.0516 Acc: 75.0000%\n",
      "\tvalidation 22-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-20: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 22-21: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 22-22: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-23: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 22-24: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 22-25: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 22-26: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 22-27: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 22-28: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 22-29: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 22-30: Loss: 0.1126 Acc: 75.0000%\n",
      "\tvalidation 22-31: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 22-32: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 22-33: Loss: 0.0208 Acc: 100.0000%\n",
      "\tvalidation 22-34: Loss: 0.0528 Acc: 75.0000%\n",
      "\tvalidation 22-35: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 22-36: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 22-37: Loss: 0.1229 Acc: 75.0000%\n",
      "\tvalidation 22-38: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 22-39: Loss: 0.0831 Acc: 75.0000%\n",
      "\tvalidation 22-40: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 22-41: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 22-42: Loss: 0.0528 Acc: 100.0000%\n",
      "\tvalidation 22-43: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-44: Loss: 0.0995 Acc: 75.0000%\n",
      "\tvalidation 22-45: Loss: 0.0134 Acc: 100.0000%\n",
      "\tvalidation 22-46: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 22-47: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 22-48: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 22-49: Loss: 0.2645 Acc: 75.0000%\n",
      "\tvalidation 22-50: Loss: 0.1054 Acc: 75.0000%\n",
      "\tvalidation 22-51: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 22-52: Loss: 0.1580 Acc: 50.0000%\n",
      "\tvalidation 22-53: Loss: 0.0706 Acc: 100.0000%\n",
      "\tvalidation 22-54: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 22-55: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 22-56: Loss: 0.1030 Acc: 75.0000%\n",
      "\tvalidation 22-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-58: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-59: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 22-60: Loss: 0.0458 Acc: 100.0000%\n",
      "\tvalidation 22-61: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 22-62: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 22-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-64: Loss: 0.0609 Acc: 75.0000%\n",
      "\tvalidation 22-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-66: Loss: 0.0414 Acc: 100.0000%\n",
      "\tvalidation 22-67: Loss: 0.0723 Acc: 75.0000%\n",
      "\tvalidation 22-68: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 22-69: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 22-70: Loss: 0.0915 Acc: 75.0000%\n",
      "\tvalidation 22-71: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 22-72: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 22-73: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 22-74: Loss: 0.0331 Acc: 100.0000%\n",
      "\tvalidation 22-75: Loss: 0.0327 Acc: 100.0000%\n",
      "\tvalidation 22-76: Loss: 0.0028 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 22-77: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 22-78: Loss: 0.0585 Acc: 75.0000%\n",
      "\tvalidation 22-79: Loss: 0.0592 Acc: 100.0000%\n",
      "\tvalidation 22-80: Loss: 0.0202 Acc: 100.0000%\n",
      "\tvalidation 22-81: Loss: 0.0644 Acc: 100.0000%\n",
      "\tvalidation 22-82: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 22-83: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 22-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 22-86: Loss: 0.0302 Acc: 100.0000%\n",
      "\tvalidation 22-87: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 22-88: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 22-89: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 22-90: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 22-91: Loss: 0.0167 Acc: 100.0000%\n",
      "\tvalidation 22-92: Loss: 0.1898 Acc: 50.0000%\n",
      "\tvalidation 22-93: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 22-94: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 22-95: Loss: 0.0753 Acc: 100.0000%\n",
      "\tvalidation 22-96: Loss: 0.0303 Acc: 100.0000%\n",
      "\tvalidation 22-97: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 22-98: Loss: 0.0484 Acc: 100.0000%\n",
      "\tvalidation 22-99: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 22-100: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 22-101: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 22-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 22-103: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 22-104: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 22-105: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0751 Acc: 89.1837%\n",
      "\tvalidation Loss: 0.0334 Acc: 95.4762%\n",
      "Time passed 0h 15m 39s\n",
      "--------------------\n",
      "Epoch [23/40]:\n",
      "\ttrain 23-1: Loss: 0.0491 Acc: 100.0000%\n",
      "\ttrain 23-2: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 23-3: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 23-4: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 23-5: Loss: 0.1770 Acc: 75.0000%\n",
      "\ttrain 23-6: Loss: 0.2927 Acc: 50.0000%\n",
      "\ttrain 23-7: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 23-8: Loss: 0.1969 Acc: 75.0000%\n",
      "\ttrain 23-9: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 23-10: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 23-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 23-12: Loss: 0.0665 Acc: 75.0000%\n",
      "\ttrain 23-13: Loss: 0.1222 Acc: 75.0000%\n",
      "\ttrain 23-14: Loss: 0.1572 Acc: 75.0000%\n",
      "\ttrain 23-15: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 23-16: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 23-17: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 23-18: Loss: 0.0758 Acc: 100.0000%\n",
      "\ttrain 23-19: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 23-20: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 23-21: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 23-22: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 23-23: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 23-24: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 23-25: Loss: 0.0563 Acc: 75.0000%\n",
      "\ttrain 23-26: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 23-27: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 23-28: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 23-29: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 23-30: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 23-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 23-32: Loss: 0.0541 Acc: 100.0000%\n",
      "\ttrain 23-33: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 23-34: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 23-35: Loss: 0.1315 Acc: 50.0000%\n",
      "\ttrain 23-36: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 23-37: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 23-38: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 23-39: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 23-40: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 23-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 23-42: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 23-43: Loss: 0.0634 Acc: 75.0000%\n",
      "\ttrain 23-44: Loss: 0.0470 Acc: 100.0000%\n",
      "\ttrain 23-45: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 23-46: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 23-47: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 23-48: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 23-49: Loss: 0.1132 Acc: 75.0000%\n",
      "\ttrain 23-50: Loss: 0.1624 Acc: 75.0000%\n",
      "\ttrain 23-51: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 23-52: Loss: 0.2349 Acc: 75.0000%\n",
      "\ttrain 23-53: Loss: 0.1726 Acc: 50.0000%\n",
      "\ttrain 23-54: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 23-55: Loss: 0.0453 Acc: 75.0000%\n",
      "\ttrain 23-56: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 23-57: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 23-58: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 23-59: Loss: 0.1227 Acc: 75.0000%\n",
      "\ttrain 23-60: Loss: 0.1346 Acc: 75.0000%\n",
      "\ttrain 23-61: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 23-62: Loss: 0.0262 Acc: 100.0000%\n",
      "\ttrain 23-63: Loss: 0.1897 Acc: 75.0000%\n",
      "\ttrain 23-64: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 23-65: Loss: 0.0632 Acc: 100.0000%\n",
      "\ttrain 23-66: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 23-67: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 23-68: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 23-69: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 23-70: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 23-71: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 23-72: Loss: 0.0934 Acc: 50.0000%\n",
      "\ttrain 23-73: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 23-74: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 23-75: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 23-76: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 23-77: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 23-78: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 23-79: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 23-80: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 23-81: Loss: 0.3093 Acc: 75.0000%\n",
      "\ttrain 23-82: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 23-83: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 23-84: Loss: 0.1947 Acc: 75.0000%\n",
      "\ttrain 23-85: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 23-86: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 23-87: Loss: 0.1748 Acc: 75.0000%\n",
      "\ttrain 23-88: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 23-89: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 23-90: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 23-91: Loss: 0.1851 Acc: 50.0000%\n",
      "\ttrain 23-92: Loss: 0.1668 Acc: 75.0000%\n",
      "\ttrain 23-93: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 23-94: Loss: 0.1187 Acc: 75.0000%\n",
      "\ttrain 23-95: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 23-96: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 23-97: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 23-98: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 23-99: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 23-100: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 23-101: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 23-102: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-103: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 23-104: Loss: 0.1439 Acc: 75.0000%\n",
      "\ttrain 23-105: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 23-106: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 23-107: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 23-108: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 23-109: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 23-110: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 23-111: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 23-112: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 23-113: Loss: 0.0787 Acc: 100.0000%\n",
      "\ttrain 23-114: Loss: 0.0535 Acc: 75.0000%\n",
      "\ttrain 23-115: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 23-116: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-117: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-118: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 23-119: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 23-120: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 23-121: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 23-122: Loss: 0.0455 Acc: 100.0000%\n",
      "\ttrain 23-123: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 23-124: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 23-125: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 23-126: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 23-127: Loss: 0.1257 Acc: 75.0000%\n",
      "\ttrain 23-128: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 23-129: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 23-130: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 23-131: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 23-132: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 23-133: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 23-134: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 23-135: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 23-136: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 23-137: Loss: 0.0924 Acc: 75.0000%\n",
      "\ttrain 23-138: Loss: 0.0490 Acc: 75.0000%\n",
      "\ttrain 23-139: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 23-140: Loss: 0.1337 Acc: 75.0000%\n",
      "\ttrain 23-141: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 23-142: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 23-143: Loss: 0.1011 Acc: 75.0000%\n",
      "\ttrain 23-144: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-145: Loss: 0.1534 Acc: 50.0000%\n",
      "\ttrain 23-146: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-147: Loss: 0.0940 Acc: 75.0000%\n",
      "\ttrain 23-148: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 23-149: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 23-150: Loss: 0.1721 Acc: 75.0000%\n",
      "\ttrain 23-151: Loss: 0.0633 Acc: 100.0000%\n",
      "\ttrain 23-152: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 23-153: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 23-154: Loss: 0.1761 Acc: 75.0000%\n",
      "\ttrain 23-155: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-156: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 23-157: Loss: 0.0853 Acc: 75.0000%\n",
      "\ttrain 23-158: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 23-159: Loss: 0.0551 Acc: 100.0000%\n",
      "\ttrain 23-160: Loss: 0.0696 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 23-161: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 23-162: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 23-163: Loss: 0.2531 Acc: 75.0000%\n",
      "\ttrain 23-164: Loss: 0.3785 Acc: 75.0000%\n",
      "\ttrain 23-165: Loss: 0.0676 Acc: 75.0000%\n",
      "\ttrain 23-166: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 23-167: Loss: 0.0593 Acc: 75.0000%\n",
      "\ttrain 23-168: Loss: 0.0684 Acc: 75.0000%\n",
      "\ttrain 23-169: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 23-170: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 23-171: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 23-172: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 23-173: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 23-174: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 23-175: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 23-176: Loss: 0.0566 Acc: 100.0000%\n",
      "\ttrain 23-177: Loss: 0.0791 Acc: 75.0000%\n",
      "\ttrain 23-178: Loss: 0.2056 Acc: 75.0000%\n",
      "\ttrain 23-179: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 23-180: Loss: 0.0568 Acc: 100.0000%\n",
      "\ttrain 23-181: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 23-182: Loss: 0.0641 Acc: 100.0000%\n",
      "\ttrain 23-183: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 23-184: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 23-185: Loss: 0.1244 Acc: 75.0000%\n",
      "\ttrain 23-186: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 23-187: Loss: 0.2335 Acc: 75.0000%\n",
      "\ttrain 23-188: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 23-189: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 23-190: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 23-191: Loss: 0.2441 Acc: 75.0000%\n",
      "\ttrain 23-192: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 23-193: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 23-194: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 23-195: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 23-196: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 23-197: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 23-198: Loss: 0.0626 Acc: 75.0000%\n",
      "\ttrain 23-199: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 23-200: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 23-201: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 23-202: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 23-203: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 23-204: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 23-205: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-206: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 23-207: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 23-208: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 23-209: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 23-210: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 23-211: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 23-212: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 23-213: Loss: 0.0339 Acc: 100.0000%\n",
      "\ttrain 23-214: Loss: 0.3146 Acc: 75.0000%\n",
      "\ttrain 23-215: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 23-216: Loss: 0.0512 Acc: 100.0000%\n",
      "\ttrain 23-217: Loss: 0.0633 Acc: 75.0000%\n",
      "\ttrain 23-218: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 23-219: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 23-220: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 23-221: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 23-222: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 23-223: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 23-224: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 23-225: Loss: 0.0531 Acc: 100.0000%\n",
      "\ttrain 23-226: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 23-227: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 23-228: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 23-229: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 23-230: Loss: 0.1771 Acc: 75.0000%\n",
      "\ttrain 23-231: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 23-232: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 23-233: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 23-234: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 23-235: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 23-236: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 23-237: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 23-238: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 23-239: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 23-240: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 23-241: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 23-242: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 23-243: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 23-244: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 23-245: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 23-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 23-2: Loss: 0.0400 Acc: 100.0000%\n",
      "\tvalidation 23-3: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 23-4: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 23-5: Loss: 0.0605 Acc: 75.0000%\n",
      "\tvalidation 23-6: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 23-7: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 23-8: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 23-9: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 23-10: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 23-11: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-13: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 23-14: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 23-15: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 23-16: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-17: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 23-18: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 23-19: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-20: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-21: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 23-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-23: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 23-24: Loss: 0.0295 Acc: 100.0000%\n",
      "\tvalidation 23-25: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 23-26: Loss: 0.0304 Acc: 100.0000%\n",
      "\tvalidation 23-27: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 23-28: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 23-29: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-30: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 23-31: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-32: Loss: 0.1351 Acc: 75.0000%\n",
      "\tvalidation 23-33: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 23-34: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-35: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 23-36: Loss: 0.1004 Acc: 75.0000%\n",
      "\tvalidation 23-37: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 23-38: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 23-39: Loss: 0.0200 Acc: 100.0000%\n",
      "\tvalidation 23-40: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 23-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-42: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 23-43: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-44: Loss: 0.0478 Acc: 75.0000%\n",
      "\tvalidation 23-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-46: Loss: 0.0272 Acc: 100.0000%\n",
      "\tvalidation 23-47: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 23-48: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 23-49: Loss: 0.1183 Acc: 75.0000%\n",
      "\tvalidation 23-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-51: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 23-52: Loss: 0.0851 Acc: 75.0000%\n",
      "\tvalidation 23-53: Loss: 0.1182 Acc: 75.0000%\n",
      "\tvalidation 23-54: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 23-55: Loss: 0.0813 Acc: 75.0000%\n",
      "\tvalidation 23-56: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 23-57: Loss: 0.1497 Acc: 75.0000%\n",
      "\tvalidation 23-58: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-60: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-61: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-62: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 23-63: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-64: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-65: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 23-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-67: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 23-68: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 23-69: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-70: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 23-71: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 23-73: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 23-74: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 23-75: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-76: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-77: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-78: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 23-79: Loss: 0.0428 Acc: 100.0000%\n",
      "\tvalidation 23-80: Loss: 0.0494 Acc: 75.0000%\n",
      "\tvalidation 23-81: Loss: 0.0373 Acc: 100.0000%\n",
      "\tvalidation 23-82: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 23-83: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 23-84: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 23-85: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 23-86: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 23-87: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-88: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 23-89: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 23-90: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-91: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 23-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-93: Loss: 0.0312 Acc: 100.0000%\n",
      "\tvalidation 23-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-95: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 23-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 23-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 23-98: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 23-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 23-100: Loss: 0.0008 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 23-101: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 23-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 23-103: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 23-104: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 23-105: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0531 Acc: 92.0408%\n",
      "\tvalidation Loss: 0.0152 Acc: 97.6190%\n",
      "Time passed 0h 16m 22s\n",
      "--------------------\n",
      "Epoch [24/40]:\n",
      "\ttrain 24-1: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 24-2: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 24-3: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 24-4: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 24-5: Loss: 0.2376 Acc: 75.0000%\n",
      "\ttrain 24-6: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-7: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 24-8: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 24-9: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-10: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-11: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 24-12: Loss: 0.0610 Acc: 75.0000%\n",
      "\ttrain 24-13: Loss: 0.1489 Acc: 75.0000%\n",
      "\ttrain 24-14: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 24-15: Loss: 0.2790 Acc: 75.0000%\n",
      "\ttrain 24-16: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 24-17: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 24-18: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 24-19: Loss: 0.1128 Acc: 75.0000%\n",
      "\ttrain 24-20: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 24-21: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 24-22: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-23: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 24-24: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 24-25: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 24-26: Loss: 0.0923 Acc: 100.0000%\n",
      "\ttrain 24-27: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 24-28: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 24-29: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 24-30: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 24-31: Loss: 0.0374 Acc: 100.0000%\n",
      "\ttrain 24-32: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 24-33: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 24-34: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 24-35: Loss: 0.0343 Acc: 100.0000%\n",
      "\ttrain 24-36: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 24-37: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 24-38: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 24-39: Loss: 0.0945 Acc: 75.0000%\n",
      "\ttrain 24-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-41: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 24-42: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 24-43: Loss: 0.1139 Acc: 75.0000%\n",
      "\ttrain 24-44: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 24-45: Loss: 0.1087 Acc: 75.0000%\n",
      "\ttrain 24-46: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 24-47: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 24-48: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 24-49: Loss: 0.3417 Acc: 50.0000%\n",
      "\ttrain 24-50: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 24-51: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 24-52: Loss: 0.2489 Acc: 50.0000%\n",
      "\ttrain 24-53: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 24-54: Loss: 0.0883 Acc: 75.0000%\n",
      "\ttrain 24-55: Loss: 0.1930 Acc: 75.0000%\n",
      "\ttrain 24-56: Loss: 0.0241 Acc: 100.0000%\n",
      "\ttrain 24-57: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 24-58: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 24-59: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 24-60: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 24-61: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 24-62: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 24-63: Loss: 0.1215 Acc: 75.0000%\n",
      "\ttrain 24-64: Loss: 0.0523 Acc: 100.0000%\n",
      "\ttrain 24-65: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 24-66: Loss: 0.3877 Acc: 75.0000%\n",
      "\ttrain 24-67: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 24-68: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 24-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 24-70: Loss: 0.0605 Acc: 100.0000%\n",
      "\ttrain 24-71: Loss: 0.2759 Acc: 75.0000%\n",
      "\ttrain 24-72: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 24-73: Loss: 0.0595 Acc: 100.0000%\n",
      "\ttrain 24-74: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-75: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 24-76: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 24-77: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 24-78: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 24-79: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 24-80: Loss: 0.3040 Acc: 75.0000%\n",
      "\ttrain 24-81: Loss: 0.0515 Acc: 100.0000%\n",
      "\ttrain 24-82: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 24-83: Loss: 0.0737 Acc: 75.0000%\n",
      "\ttrain 24-84: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 24-85: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 24-86: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 24-87: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 24-88: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 24-89: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-90: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 24-91: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 24-92: Loss: 0.1385 Acc: 75.0000%\n",
      "\ttrain 24-93: Loss: 0.2917 Acc: 50.0000%\n",
      "\ttrain 24-94: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 24-95: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 24-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 24-97: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 24-98: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 24-99: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 24-100: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 24-101: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 24-102: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 24-103: Loss: 0.0876 Acc: 75.0000%\n",
      "\ttrain 24-104: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 24-105: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 24-106: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 24-107: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 24-108: Loss: 0.1686 Acc: 75.0000%\n",
      "\ttrain 24-109: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 24-110: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 24-111: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 24-112: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 24-113: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 24-114: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 24-115: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-116: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 24-117: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 24-118: Loss: 0.0720 Acc: 100.0000%\n",
      "\ttrain 24-119: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 24-120: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 24-121: Loss: 0.2078 Acc: 75.0000%\n",
      "\ttrain 24-122: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 24-123: Loss: 0.2057 Acc: 75.0000%\n",
      "\ttrain 24-124: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 24-125: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 24-126: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 24-127: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 24-128: Loss: 0.2253 Acc: 75.0000%\n",
      "\ttrain 24-129: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 24-130: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 24-131: Loss: 0.3195 Acc: 75.0000%\n",
      "\ttrain 24-132: Loss: 0.0887 Acc: 75.0000%\n",
      "\ttrain 24-133: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 24-134: Loss: 0.5369 Acc: 75.0000%\n",
      "\ttrain 24-135: Loss: 0.1079 Acc: 75.0000%\n",
      "\ttrain 24-136: Loss: 0.0808 Acc: 75.0000%\n",
      "\ttrain 24-137: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 24-138: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 24-139: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 24-140: Loss: 0.0361 Acc: 100.0000%\n",
      "\ttrain 24-141: Loss: 0.0389 Acc: 100.0000%\n",
      "\ttrain 24-142: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 24-143: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 24-144: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 24-145: Loss: 0.1968 Acc: 75.0000%\n",
      "\ttrain 24-146: Loss: 0.1313 Acc: 75.0000%\n",
      "\ttrain 24-147: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 24-148: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 24-149: Loss: 0.0669 Acc: 75.0000%\n",
      "\ttrain 24-150: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 24-151: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 24-152: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 24-153: Loss: 0.0682 Acc: 100.0000%\n",
      "\ttrain 24-154: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 24-155: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 24-156: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 24-157: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 24-158: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 24-159: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 24-160: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 24-161: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 24-162: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 24-163: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 24-164: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 24-165: Loss: 0.0616 Acc: 100.0000%\n",
      "\ttrain 24-166: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 24-167: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 24-168: Loss: 0.1444 Acc: 75.0000%\n",
      "\ttrain 24-169: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 24-170: Loss: 0.0641 Acc: 75.0000%\n",
      "\ttrain 24-171: Loss: 0.0321 Acc: 100.0000%\n",
      "\ttrain 24-172: Loss: 0.0811 Acc: 75.0000%\n",
      "\ttrain 24-173: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 24-174: Loss: 0.3177 Acc: 75.0000%\n",
      "\ttrain 24-175: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 24-176: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 24-177: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 24-178: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 24-179: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 24-180: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 24-181: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 24-182: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 24-183: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 24-184: Loss: 0.0985 Acc: 75.0000%\n",
      "\ttrain 24-185: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 24-186: Loss: 0.3245 Acc: 25.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 24-187: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 24-188: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 24-189: Loss: 0.0655 Acc: 75.0000%\n",
      "\ttrain 24-190: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 24-191: Loss: 0.2120 Acc: 75.0000%\n",
      "\ttrain 24-192: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 24-193: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 24-194: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 24-195: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 24-196: Loss: 0.0689 Acc: 75.0000%\n",
      "\ttrain 24-197: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 24-198: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 24-199: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 24-200: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 24-201: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 24-202: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 24-203: Loss: 0.0841 Acc: 75.0000%\n",
      "\ttrain 24-204: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 24-205: Loss: 0.4307 Acc: 75.0000%\n",
      "\ttrain 24-206: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 24-207: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 24-208: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 24-209: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 24-210: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 24-211: Loss: 0.1821 Acc: 50.0000%\n",
      "\ttrain 24-212: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 24-213: Loss: 0.0723 Acc: 75.0000%\n",
      "\ttrain 24-214: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 24-215: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 24-216: Loss: 0.0239 Acc: 100.0000%\n",
      "\ttrain 24-217: Loss: 0.0859 Acc: 75.0000%\n",
      "\ttrain 24-218: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 24-219: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 24-220: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 24-221: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 24-222: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 24-223: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 24-224: Loss: 0.1148 Acc: 75.0000%\n",
      "\ttrain 24-225: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 24-226: Loss: 0.4688 Acc: 50.0000%\n",
      "\ttrain 24-227: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 24-228: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 24-229: Loss: 0.1221 Acc: 75.0000%\n",
      "\ttrain 24-230: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 24-231: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 24-232: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 24-233: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 24-234: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 24-235: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 24-236: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 24-237: Loss: 0.1281 Acc: 75.0000%\n",
      "\ttrain 24-238: Loss: 0.2271 Acc: 50.0000%\n",
      "\ttrain 24-239: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 24-240: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 24-241: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 24-242: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 24-243: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 24-244: Loss: 0.0350 Acc: 100.0000%\n",
      "\ttrain 24-245: Loss: 0.1164 Acc: 75.0000%\n",
      "\tvalidation 24-1: Loss: 0.0920 Acc: 75.0000%\n",
      "\tvalidation 24-2: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-3: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 24-4: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 24-5: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 24-6: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 24-7: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 24-8: Loss: 0.0900 Acc: 75.0000%\n",
      "\tvalidation 24-9: Loss: 0.0450 Acc: 100.0000%\n",
      "\tvalidation 24-10: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 24-11: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 24-12: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 24-13: Loss: 0.0605 Acc: 75.0000%\n",
      "\tvalidation 24-14: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 24-15: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 24-16: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 24-17: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 24-18: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 24-19: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 24-20: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 24-21: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 24-22: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 24-23: Loss: 0.0444 Acc: 100.0000%\n",
      "\tvalidation 24-24: Loss: 0.1418 Acc: 75.0000%\n",
      "\tvalidation 24-25: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 24-26: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 24-27: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 24-28: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 24-29: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 24-30: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 24-31: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 24-32: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 24-33: Loss: 0.0398 Acc: 100.0000%\n",
      "\tvalidation 24-34: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 24-35: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 24-36: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 24-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 24-38: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 24-39: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 24-40: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 24-41: Loss: 0.0539 Acc: 75.0000%\n",
      "\tvalidation 24-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-43: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 24-44: Loss: 0.1018 Acc: 75.0000%\n",
      "\tvalidation 24-45: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 24-46: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 24-47: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 24-48: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 24-49: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 24-50: Loss: 0.1868 Acc: 75.0000%\n",
      "\tvalidation 24-51: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 24-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-53: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 24-54: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 24-55: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 24-56: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 24-57: Loss: 0.0365 Acc: 100.0000%\n",
      "\tvalidation 24-58: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 24-59: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 24-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 24-61: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 24-62: Loss: 0.1073 Acc: 75.0000%\n",
      "\tvalidation 24-63: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 24-64: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 24-65: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 24-66: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 24-67: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 24-68: Loss: 0.0395 Acc: 100.0000%\n",
      "\tvalidation 24-69: Loss: 0.0747 Acc: 75.0000%\n",
      "\tvalidation 24-70: Loss: 0.0114 Acc: 100.0000%\n",
      "\tvalidation 24-71: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 24-72: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 24-73: Loss: 0.0946 Acc: 75.0000%\n",
      "\tvalidation 24-74: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 24-75: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 24-76: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 24-77: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 24-78: Loss: 0.0663 Acc: 75.0000%\n",
      "\tvalidation 24-79: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 24-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-81: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 24-82: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 24-83: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 24-84: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 24-85: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 24-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 24-87: Loss: 0.1304 Acc: 75.0000%\n",
      "\tvalidation 24-88: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 24-89: Loss: 0.0789 Acc: 75.0000%\n",
      "\tvalidation 24-90: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 24-91: Loss: 0.0126 Acc: 100.0000%\n",
      "\tvalidation 24-92: Loss: 0.0816 Acc: 75.0000%\n",
      "\tvalidation 24-93: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 24-94: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 24-95: Loss: 0.0347 Acc: 100.0000%\n",
      "\tvalidation 24-96: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 24-97: Loss: 0.0388 Acc: 100.0000%\n",
      "\tvalidation 24-98: Loss: 0.1260 Acc: 75.0000%\n",
      "\tvalidation 24-99: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 24-100: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 24-101: Loss: 0.0319 Acc: 100.0000%\n",
      "\tvalidation 24-102: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 24-103: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 24-104: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 24-105: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0655 Acc: 90.9184%\n",
      "\tvalidation Loss: 0.0248 Acc: 96.4286%\n",
      "Time passed 0h 17m 5s\n",
      "--------------------\n",
      "Epoch [25/40]:\n",
      "\ttrain 25-1: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 25-2: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 25-3: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 25-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-5: Loss: 0.3771 Acc: 75.0000%\n",
      "\ttrain 25-6: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 25-7: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 25-8: Loss: 0.0596 Acc: 100.0000%\n",
      "\ttrain 25-9: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 25-10: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 25-11: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 25-12: Loss: 0.0671 Acc: 75.0000%\n",
      "\ttrain 25-13: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 25-14: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 25-15: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 25-16: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 25-17: Loss: 0.0090 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-18: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 25-19: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 25-20: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 25-21: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 25-22: Loss: 0.1491 Acc: 50.0000%\n",
      "\ttrain 25-23: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 25-24: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-25: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 25-26: Loss: 0.0533 Acc: 75.0000%\n",
      "\ttrain 25-27: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 25-28: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 25-29: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 25-30: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 25-31: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 25-32: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 25-33: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 25-34: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 25-35: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 25-36: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 25-37: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 25-38: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-39: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 25-40: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 25-41: Loss: 0.2996 Acc: 25.0000%\n",
      "\ttrain 25-42: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 25-43: Loss: 0.0646 Acc: 75.0000%\n",
      "\ttrain 25-44: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 25-45: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 25-46: Loss: 0.2048 Acc: 75.0000%\n",
      "\ttrain 25-47: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 25-48: Loss: 0.2016 Acc: 75.0000%\n",
      "\ttrain 25-49: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 25-50: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 25-51: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-52: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 25-53: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 25-54: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 25-55: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 25-56: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 25-57: Loss: 0.2554 Acc: 75.0000%\n",
      "\ttrain 25-58: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 25-59: Loss: 0.2062 Acc: 75.0000%\n",
      "\ttrain 25-60: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 25-61: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 25-62: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 25-63: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 25-64: Loss: 0.1339 Acc: 75.0000%\n",
      "\ttrain 25-65: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 25-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 25-67: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 25-68: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 25-69: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 25-70: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 25-71: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 25-72: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 25-73: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 25-74: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 25-75: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 25-76: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 25-77: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 25-78: Loss: 0.2067 Acc: 75.0000%\n",
      "\ttrain 25-79: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 25-80: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 25-81: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 25-82: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 25-83: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 25-84: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 25-85: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-86: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 25-87: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 25-88: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 25-89: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 25-90: Loss: 0.1924 Acc: 50.0000%\n",
      "\ttrain 25-91: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 25-92: Loss: 0.1478 Acc: 75.0000%\n",
      "\ttrain 25-93: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 25-94: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 25-95: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 25-96: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 25-97: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 25-98: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 25-99: Loss: 0.0832 Acc: 100.0000%\n",
      "\ttrain 25-100: Loss: 0.0283 Acc: 100.0000%\n",
      "\ttrain 25-101: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 25-102: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-103: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 25-104: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 25-105: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-106: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 25-107: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 25-108: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 25-109: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 25-110: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 25-111: Loss: 0.0566 Acc: 75.0000%\n",
      "\ttrain 25-112: Loss: 0.0873 Acc: 75.0000%\n",
      "\ttrain 25-113: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 25-114: Loss: 0.0828 Acc: 75.0000%\n",
      "\ttrain 25-115: Loss: 0.1561 Acc: 75.0000%\n",
      "\ttrain 25-116: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 25-117: Loss: 0.1543 Acc: 75.0000%\n",
      "\ttrain 25-118: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-119: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-120: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 25-121: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 25-122: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 25-123: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 25-124: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 25-125: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 25-126: Loss: 0.0605 Acc: 75.0000%\n",
      "\ttrain 25-127: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 25-128: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 25-129: Loss: 0.1752 Acc: 75.0000%\n",
      "\ttrain 25-130: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 25-131: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 25-132: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 25-133: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 25-134: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 25-135: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 25-136: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 25-137: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 25-138: Loss: 0.0934 Acc: 75.0000%\n",
      "\ttrain 25-139: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 25-140: Loss: 0.0956 Acc: 75.0000%\n",
      "\ttrain 25-141: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 25-142: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 25-143: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 25-144: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 25-145: Loss: 0.0559 Acc: 75.0000%\n",
      "\ttrain 25-146: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 25-147: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 25-148: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 25-149: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-150: Loss: 0.0773 Acc: 75.0000%\n",
      "\ttrain 25-151: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 25-152: Loss: 0.3869 Acc: 25.0000%\n",
      "\ttrain 25-153: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 25-154: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 25-155: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 25-156: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 25-157: Loss: 0.0271 Acc: 100.0000%\n",
      "\ttrain 25-158: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 25-159: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 25-160: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 25-161: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 25-162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 25-163: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 25-164: Loss: 0.1932 Acc: 75.0000%\n",
      "\ttrain 25-165: Loss: 0.3711 Acc: 50.0000%\n",
      "\ttrain 25-166: Loss: 0.1020 Acc: 75.0000%\n",
      "\ttrain 25-167: Loss: 0.1554 Acc: 75.0000%\n",
      "\ttrain 25-168: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 25-169: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 25-170: Loss: 0.1176 Acc: 75.0000%\n",
      "\ttrain 25-171: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 25-172: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 25-173: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 25-174: Loss: 0.1987 Acc: 75.0000%\n",
      "\ttrain 25-175: Loss: 0.0763 Acc: 75.0000%\n",
      "\ttrain 25-176: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 25-177: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 25-178: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 25-179: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 25-180: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 25-181: Loss: 0.0824 Acc: 75.0000%\n",
      "\ttrain 25-182: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 25-183: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 25-184: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 25-185: Loss: 0.0691 Acc: 100.0000%\n",
      "\ttrain 25-186: Loss: 0.2169 Acc: 75.0000%\n",
      "\ttrain 25-187: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 25-188: Loss: 0.0516 Acc: 100.0000%\n",
      "\ttrain 25-189: Loss: 0.0661 Acc: 100.0000%\n",
      "\ttrain 25-190: Loss: 0.0518 Acc: 75.0000%\n",
      "\ttrain 25-191: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 25-192: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-193: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 25-194: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 25-195: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 25-196: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 25-197: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 25-198: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 25-199: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 25-200: Loss: 0.0824 Acc: 100.0000%\n",
      "\ttrain 25-201: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 25-202: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 25-203: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 25-204: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 25-205: Loss: 0.0884 Acc: 75.0000%\n",
      "\ttrain 25-206: Loss: 0.1640 Acc: 75.0000%\n",
      "\ttrain 25-207: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 25-208: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 25-209: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 25-210: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 25-211: Loss: 0.0062 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 25-212: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 25-213: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 25-214: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 25-215: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 25-216: Loss: 0.1013 Acc: 75.0000%\n",
      "\ttrain 25-217: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 25-218: Loss: 0.1552 Acc: 50.0000%\n",
      "\ttrain 25-219: Loss: 0.1072 Acc: 75.0000%\n",
      "\ttrain 25-220: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 25-221: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 25-222: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 25-223: Loss: 0.0452 Acc: 100.0000%\n",
      "\ttrain 25-224: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 25-225: Loss: 0.1523 Acc: 75.0000%\n",
      "\ttrain 25-226: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 25-227: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 25-228: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 25-229: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 25-230: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 25-231: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 25-232: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 25-233: Loss: 0.1851 Acc: 75.0000%\n",
      "\ttrain 25-234: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 25-235: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 25-236: Loss: 0.2974 Acc: 75.0000%\n",
      "\ttrain 25-237: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 25-238: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 25-239: Loss: 0.0803 Acc: 100.0000%\n",
      "\ttrain 25-240: Loss: 0.0653 Acc: 75.0000%\n",
      "\ttrain 25-241: Loss: 0.0619 Acc: 100.0000%\n",
      "\ttrain 25-242: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 25-243: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 25-244: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 25-245: Loss: 0.0533 Acc: 75.0000%\n",
      "\tvalidation 25-1: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 25-2: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 25-3: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-4: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 25-5: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 25-6: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 25-7: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 25-8: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-9: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 25-10: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 25-11: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-12: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 25-13: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-14: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 25-15: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 25-16: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 25-17: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 25-18: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 25-19: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 25-20: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 25-21: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 25-22: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 25-23: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 25-24: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-25: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 25-26: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 25-27: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 25-28: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 25-29: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 25-30: Loss: 0.1384 Acc: 75.0000%\n",
      "\tvalidation 25-31: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 25-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-33: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 25-34: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 25-35: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 25-36: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 25-37: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 25-38: Loss: 0.0230 Acc: 100.0000%\n",
      "\tvalidation 25-39: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 25-40: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 25-41: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-42: Loss: 0.0257 Acc: 100.0000%\n",
      "\tvalidation 25-43: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 25-44: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-45: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 25-46: Loss: 0.0593 Acc: 75.0000%\n",
      "\tvalidation 25-47: Loss: 0.0179 Acc: 100.0000%\n",
      "\tvalidation 25-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-49: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-50: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-51: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 25-52: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 25-53: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 25-54: Loss: 0.0489 Acc: 100.0000%\n",
      "\tvalidation 25-55: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 25-56: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 25-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 25-58: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 25-59: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-60: Loss: 0.0225 Acc: 100.0000%\n",
      "\tvalidation 25-61: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 25-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-63: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 25-64: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 25-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-66: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 25-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-68: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 25-69: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 25-71: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 25-72: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 25-73: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 25-74: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 25-75: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 25-76: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 25-77: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-78: Loss: 0.0335 Acc: 100.0000%\n",
      "\tvalidation 25-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-80: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 25-81: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 25-82: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 25-83: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 25-84: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 25-85: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 25-86: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 25-87: Loss: 0.0282 Acc: 100.0000%\n",
      "\tvalidation 25-88: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 25-89: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 25-90: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 25-91: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 25-92: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 25-93: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 25-94: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 25-95: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 25-96: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 25-97: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 25-98: Loss: 0.0492 Acc: 75.0000%\n",
      "\tvalidation 25-99: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 25-100: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 25-101: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 25-102: Loss: 0.0189 Acc: 100.0000%\n",
      "\tvalidation 25-103: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 25-104: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 25-105: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0484 Acc: 92.4490%\n",
      "\tvalidation Loss: 0.0094 Acc: 99.2857%\n",
      "网络参数更新\n",
      "Time passed 0h 18m 4s\n",
      "--------------------\n",
      "Epoch [26/40]:\n",
      "\ttrain 26-1: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-2: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-3: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 26-4: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 26-5: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 26-6: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 26-7: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 26-8: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 26-9: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 26-10: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 26-11: Loss: 0.1234 Acc: 75.0000%\n",
      "\ttrain 26-12: Loss: 0.2391 Acc: 50.0000%\n",
      "\ttrain 26-13: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 26-14: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-15: Loss: 0.0916 Acc: 75.0000%\n",
      "\ttrain 26-16: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 26-17: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 26-18: Loss: 0.0260 Acc: 100.0000%\n",
      "\ttrain 26-19: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 26-20: Loss: 0.2163 Acc: 75.0000%\n",
      "\ttrain 26-21: Loss: 0.1225 Acc: 75.0000%\n",
      "\ttrain 26-22: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 26-23: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 26-24: Loss: 0.3730 Acc: 50.0000%\n",
      "\ttrain 26-25: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 26-26: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-27: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 26-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 26-29: Loss: 0.0387 Acc: 100.0000%\n",
      "\ttrain 26-30: Loss: 0.4157 Acc: 50.0000%\n",
      "\ttrain 26-31: Loss: 0.4973 Acc: 75.0000%\n",
      "\ttrain 26-32: Loss: 0.0445 Acc: 100.0000%\n",
      "\ttrain 26-33: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 26-34: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 26-35: Loss: 0.1184 Acc: 75.0000%\n",
      "\ttrain 26-36: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 26-37: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 26-38: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 26-39: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 26-40: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 26-41: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 26-42: Loss: 0.0840 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-43: Loss: 0.1051 Acc: 75.0000%\n",
      "\ttrain 26-44: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 26-45: Loss: 0.2356 Acc: 75.0000%\n",
      "\ttrain 26-46: Loss: 0.0446 Acc: 100.0000%\n",
      "\ttrain 26-47: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 26-48: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 26-49: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 26-50: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 26-51: Loss: 0.2227 Acc: 50.0000%\n",
      "\ttrain 26-52: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 26-53: Loss: 0.0267 Acc: 100.0000%\n",
      "\ttrain 26-54: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 26-55: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 26-56: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 26-57: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 26-58: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 26-59: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 26-60: Loss: 0.1427 Acc: 75.0000%\n",
      "\ttrain 26-61: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 26-62: Loss: 0.1637 Acc: 75.0000%\n",
      "\ttrain 26-63: Loss: 0.1325 Acc: 75.0000%\n",
      "\ttrain 26-64: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 26-65: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 26-66: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 26-67: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 26-68: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 26-69: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 26-70: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 26-71: Loss: 0.1481 Acc: 75.0000%\n",
      "\ttrain 26-72: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-73: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 26-74: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 26-75: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 26-76: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 26-77: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 26-78: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 26-79: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 26-80: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 26-81: Loss: 0.1405 Acc: 75.0000%\n",
      "\ttrain 26-82: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 26-83: Loss: 0.0404 Acc: 100.0000%\n",
      "\ttrain 26-84: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 26-85: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 26-86: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 26-87: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 26-88: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 26-89: Loss: 0.0575 Acc: 100.0000%\n",
      "\ttrain 26-90: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 26-91: Loss: 0.1318 Acc: 75.0000%\n",
      "\ttrain 26-92: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 26-93: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 26-94: Loss: 0.1609 Acc: 75.0000%\n",
      "\ttrain 26-95: Loss: 0.1900 Acc: 75.0000%\n",
      "\ttrain 26-96: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 26-97: Loss: 0.2647 Acc: 75.0000%\n",
      "\ttrain 26-98: Loss: 0.1198 Acc: 50.0000%\n",
      "\ttrain 26-99: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 26-100: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 26-101: Loss: 0.0845 Acc: 100.0000%\n",
      "\ttrain 26-102: Loss: 0.0848 Acc: 75.0000%\n",
      "\ttrain 26-103: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 26-104: Loss: 0.1063 Acc: 75.0000%\n",
      "\ttrain 26-105: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 26-106: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 26-107: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 26-108: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 26-109: Loss: 0.0775 Acc: 75.0000%\n",
      "\ttrain 26-110: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 26-111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 26-112: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 26-113: Loss: 0.0758 Acc: 75.0000%\n",
      "\ttrain 26-114: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 26-115: Loss: 0.0827 Acc: 75.0000%\n",
      "\ttrain 26-116: Loss: 0.0461 Acc: 100.0000%\n",
      "\ttrain 26-117: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 26-118: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 26-119: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 26-120: Loss: 0.1727 Acc: 75.0000%\n",
      "\ttrain 26-121: Loss: 0.0870 Acc: 75.0000%\n",
      "\ttrain 26-122: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 26-123: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 26-124: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 26-125: Loss: 0.1502 Acc: 75.0000%\n",
      "\ttrain 26-126: Loss: 0.2274 Acc: 75.0000%\n",
      "\ttrain 26-127: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 26-128: Loss: 0.1886 Acc: 75.0000%\n",
      "\ttrain 26-129: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 26-130: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 26-131: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 26-132: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 26-133: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 26-134: Loss: 0.2154 Acc: 75.0000%\n",
      "\ttrain 26-135: Loss: 0.0768 Acc: 100.0000%\n",
      "\ttrain 26-136: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 26-137: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 26-138: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 26-139: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 26-140: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 26-141: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 26-142: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-143: Loss: 0.0500 Acc: 75.0000%\n",
      "\ttrain 26-144: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 26-145: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 26-146: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 26-147: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 26-148: Loss: 0.0750 Acc: 75.0000%\n",
      "\ttrain 26-149: Loss: 0.1477 Acc: 75.0000%\n",
      "\ttrain 26-150: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 26-151: Loss: 0.1540 Acc: 75.0000%\n",
      "\ttrain 26-152: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 26-153: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 26-154: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 26-155: Loss: 0.1335 Acc: 75.0000%\n",
      "\ttrain 26-156: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 26-157: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 26-158: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 26-159: Loss: 0.0444 Acc: 100.0000%\n",
      "\ttrain 26-160: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 26-161: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 26-162: Loss: 0.0648 Acc: 75.0000%\n",
      "\ttrain 26-163: Loss: 0.0352 Acc: 100.0000%\n",
      "\ttrain 26-164: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 26-165: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 26-166: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 26-167: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 26-168: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 26-169: Loss: 0.1730 Acc: 75.0000%\n",
      "\ttrain 26-170: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 26-171: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 26-172: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 26-173: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 26-174: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 26-175: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 26-176: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 26-177: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 26-178: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 26-179: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 26-180: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 26-181: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 26-182: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 26-183: Loss: 0.1303 Acc: 75.0000%\n",
      "\ttrain 26-184: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 26-185: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-186: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 26-187: Loss: 0.0608 Acc: 100.0000%\n",
      "\ttrain 26-188: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 26-189: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 26-190: Loss: 0.1320 Acc: 50.0000%\n",
      "\ttrain 26-191: Loss: 0.3438 Acc: 50.0000%\n",
      "\ttrain 26-192: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 26-193: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 26-194: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 26-195: Loss: 0.0547 Acc: 75.0000%\n",
      "\ttrain 26-196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 26-197: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 26-198: Loss: 0.0481 Acc: 75.0000%\n",
      "\ttrain 26-199: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 26-200: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 26-201: Loss: 0.2436 Acc: 75.0000%\n",
      "\ttrain 26-202: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 26-203: Loss: 0.0328 Acc: 100.0000%\n",
      "\ttrain 26-204: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 26-205: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 26-206: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 26-207: Loss: 0.7564 Acc: 50.0000%\n",
      "\ttrain 26-208: Loss: 0.0509 Acc: 100.0000%\n",
      "\ttrain 26-209: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-210: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 26-211: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 26-212: Loss: 0.1948 Acc: 75.0000%\n",
      "\ttrain 26-213: Loss: 0.0963 Acc: 75.0000%\n",
      "\ttrain 26-214: Loss: 0.3838 Acc: 25.0000%\n",
      "\ttrain 26-215: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 26-216: Loss: 0.0407 Acc: 100.0000%\n",
      "\ttrain 26-217: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 26-218: Loss: 0.0574 Acc: 75.0000%\n",
      "\ttrain 26-219: Loss: 0.1456 Acc: 75.0000%\n",
      "\ttrain 26-220: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 26-221: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 26-222: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 26-223: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 26-224: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 26-225: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 26-226: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 26-227: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 26-228: Loss: 0.0864 Acc: 100.0000%\n",
      "\ttrain 26-229: Loss: 0.0428 Acc: 100.0000%\n",
      "\ttrain 26-230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 26-231: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 26-232: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 26-233: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 26-234: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 26-235: Loss: 0.2614 Acc: 75.0000%\n",
      "\ttrain 26-236: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 26-237: Loss: 0.0110 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 26-238: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 26-239: Loss: 0.1756 Acc: 75.0000%\n",
      "\ttrain 26-240: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 26-241: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 26-242: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 26-243: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 26-244: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 26-245: Loss: 0.0236 Acc: 100.0000%\n",
      "\tvalidation 26-1: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 26-2: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 26-3: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-4: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 26-5: Loss: 0.0397 Acc: 100.0000%\n",
      "\tvalidation 26-6: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 26-7: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 26-8: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 26-9: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 26-10: Loss: 0.0460 Acc: 75.0000%\n",
      "\tvalidation 26-11: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 26-12: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 26-13: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 26-14: Loss: 0.0527 Acc: 100.0000%\n",
      "\tvalidation 26-15: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 26-16: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 26-17: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 26-18: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-19: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 26-20: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 26-21: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-22: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 26-23: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-24: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 26-25: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 26-26: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 26-27: Loss: 0.0554 Acc: 75.0000%\n",
      "\tvalidation 26-28: Loss: 0.0284 Acc: 100.0000%\n",
      "\tvalidation 26-29: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 26-30: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 26-31: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 26-32: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 26-33: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 26-34: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 26-35: Loss: 0.0722 Acc: 100.0000%\n",
      "\tvalidation 26-36: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 26-37: Loss: 0.0812 Acc: 75.0000%\n",
      "\tvalidation 26-38: Loss: 0.1397 Acc: 75.0000%\n",
      "\tvalidation 26-39: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 26-40: Loss: 0.0604 Acc: 100.0000%\n",
      "\tvalidation 26-41: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 26-42: Loss: 0.0438 Acc: 100.0000%\n",
      "\tvalidation 26-43: Loss: 0.0192 Acc: 100.0000%\n",
      "\tvalidation 26-44: Loss: 0.1208 Acc: 75.0000%\n",
      "\tvalidation 26-45: Loss: 0.0656 Acc: 75.0000%\n",
      "\tvalidation 26-46: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 26-47: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-48: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 26-49: Loss: 0.0805 Acc: 75.0000%\n",
      "\tvalidation 26-50: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 26-51: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 26-52: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 26-53: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 26-54: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 26-55: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 26-56: Loss: 0.0526 Acc: 75.0000%\n",
      "\tvalidation 26-57: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 26-58: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 26-59: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 26-60: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 26-61: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 26-62: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 26-63: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 26-64: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 26-65: Loss: 0.0586 Acc: 75.0000%\n",
      "\tvalidation 26-66: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 26-67: Loss: 0.0089 Acc: 100.0000%\n",
      "\tvalidation 26-68: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 26-69: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 26-70: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 26-71: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 26-72: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 26-73: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 26-74: Loss: 0.0310 Acc: 100.0000%\n",
      "\tvalidation 26-75: Loss: 0.0857 Acc: 75.0000%\n",
      "\tvalidation 26-76: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 26-77: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 26-78: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 26-79: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 26-80: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 26-81: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 26-82: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 26-83: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 26-84: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 26-85: Loss: 0.0584 Acc: 75.0000%\n",
      "\tvalidation 26-86: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 26-87: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 26-88: Loss: 0.0518 Acc: 75.0000%\n",
      "\tvalidation 26-89: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 26-90: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 26-91: Loss: 0.0338 Acc: 100.0000%\n",
      "\tvalidation 26-92: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 26-93: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 26-94: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 26-95: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 26-96: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 26-97: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 26-98: Loss: 0.0217 Acc: 100.0000%\n",
      "\tvalidation 26-99: Loss: 0.0199 Acc: 100.0000%\n",
      "\tvalidation 26-100: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 26-101: Loss: 0.0492 Acc: 75.0000%\n",
      "\tvalidation 26-102: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 26-103: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 26-104: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 26-105: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0601 Acc: 91.4286%\n",
      "\tvalidation Loss: 0.0205 Acc: 96.9048%\n",
      "Time passed 0h 18m 49s\n",
      "--------------------\n",
      "Epoch [27/40]:\n",
      "\ttrain 27-1: Loss: 0.0485 Acc: 100.0000%\n",
      "\ttrain 27-2: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 27-3: Loss: 0.0829 Acc: 75.0000%\n",
      "\ttrain 27-4: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 27-5: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 27-6: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 27-7: Loss: 0.1106 Acc: 75.0000%\n",
      "\ttrain 27-8: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 27-9: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 27-10: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 27-11: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 27-12: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 27-13: Loss: 0.2577 Acc: 50.0000%\n",
      "\ttrain 27-14: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 27-15: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 27-16: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 27-17: Loss: 0.0419 Acc: 100.0000%\n",
      "\ttrain 27-18: Loss: 0.0714 Acc: 75.0000%\n",
      "\ttrain 27-19: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 27-20: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 27-21: Loss: 0.0669 Acc: 100.0000%\n",
      "\ttrain 27-22: Loss: 0.0434 Acc: 100.0000%\n",
      "\ttrain 27-23: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 27-24: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 27-25: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 27-26: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 27-27: Loss: 0.0910 Acc: 75.0000%\n",
      "\ttrain 27-28: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 27-29: Loss: 0.1817 Acc: 50.0000%\n",
      "\ttrain 27-30: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 27-31: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 27-32: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 27-33: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 27-34: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 27-35: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-36: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 27-37: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 27-38: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 27-39: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 27-40: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-41: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-42: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 27-43: Loss: 0.3542 Acc: 25.0000%\n",
      "\ttrain 27-44: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 27-45: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 27-46: Loss: 0.0470 Acc: 75.0000%\n",
      "\ttrain 27-47: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 27-48: Loss: 0.1892 Acc: 75.0000%\n",
      "\ttrain 27-49: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 27-50: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 27-51: Loss: 0.1931 Acc: 50.0000%\n",
      "\ttrain 27-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-53: Loss: 0.0218 Acc: 100.0000%\n",
      "\ttrain 27-54: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 27-55: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 27-56: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 27-57: Loss: 0.1438 Acc: 75.0000%\n",
      "\ttrain 27-58: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 27-59: Loss: 0.0540 Acc: 75.0000%\n",
      "\ttrain 27-60: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-61: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 27-62: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 27-63: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 27-64: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 27-65: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 27-66: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 27-67: Loss: 0.1432 Acc: 75.0000%\n",
      "\ttrain 27-68: Loss: 0.0024 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 27-69: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-70: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 27-71: Loss: 0.0991 Acc: 100.0000%\n",
      "\ttrain 27-72: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 27-73: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 27-74: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 27-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-76: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 27-77: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 27-78: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 27-79: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 27-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-81: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 27-82: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 27-83: Loss: 0.0720 Acc: 75.0000%\n",
      "\ttrain 27-84: Loss: 0.2345 Acc: 75.0000%\n",
      "\ttrain 27-85: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 27-86: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-87: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 27-88: Loss: 0.2172 Acc: 75.0000%\n",
      "\ttrain 27-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-90: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 27-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 27-92: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 27-93: Loss: 0.0510 Acc: 75.0000%\n",
      "\ttrain 27-94: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 27-95: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 27-96: Loss: 0.1685 Acc: 75.0000%\n",
      "\ttrain 27-97: Loss: 0.2961 Acc: 50.0000%\n",
      "\ttrain 27-98: Loss: 0.0953 Acc: 75.0000%\n",
      "\ttrain 27-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 27-100: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-101: Loss: 0.2442 Acc: 75.0000%\n",
      "\ttrain 27-102: Loss: 0.0284 Acc: 100.0000%\n",
      "\ttrain 27-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-104: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 27-105: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 27-106: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-107: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 27-108: Loss: 0.1266 Acc: 75.0000%\n",
      "\ttrain 27-109: Loss: 0.0975 Acc: 75.0000%\n",
      "\ttrain 27-110: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 27-111: Loss: 0.1112 Acc: 75.0000%\n",
      "\ttrain 27-112: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 27-113: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 27-114: Loss: 0.0680 Acc: 75.0000%\n",
      "\ttrain 27-115: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 27-116: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 27-117: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 27-118: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 27-119: Loss: 0.2342 Acc: 50.0000%\n",
      "\ttrain 27-120: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 27-121: Loss: 0.1242 Acc: 75.0000%\n",
      "\ttrain 27-122: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 27-123: Loss: 0.1744 Acc: 75.0000%\n",
      "\ttrain 27-124: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 27-125: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 27-126: Loss: 0.1592 Acc: 50.0000%\n",
      "\ttrain 27-127: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 27-128: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 27-129: Loss: 0.3007 Acc: 50.0000%\n",
      "\ttrain 27-130: Loss: 0.0637 Acc: 75.0000%\n",
      "\ttrain 27-131: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 27-132: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 27-133: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 27-134: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 27-135: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 27-136: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 27-137: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 27-138: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 27-139: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 27-140: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain 27-141: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 27-142: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 27-143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-144: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 27-145: Loss: 0.0604 Acc: 100.0000%\n",
      "\ttrain 27-146: Loss: 0.0635 Acc: 75.0000%\n",
      "\ttrain 27-147: Loss: 0.0918 Acc: 75.0000%\n",
      "\ttrain 27-148: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 27-149: Loss: 0.1047 Acc: 75.0000%\n",
      "\ttrain 27-150: Loss: 0.0421 Acc: 100.0000%\n",
      "\ttrain 27-151: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-152: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 27-153: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 27-154: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-155: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 27-156: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 27-157: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 27-158: Loss: 0.0685 Acc: 100.0000%\n",
      "\ttrain 27-159: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 27-160: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 27-161: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 27-162: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 27-163: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 27-164: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 27-165: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 27-166: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 27-167: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 27-168: Loss: 0.1397 Acc: 75.0000%\n",
      "\ttrain 27-169: Loss: 0.0755 Acc: 75.0000%\n",
      "\ttrain 27-170: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 27-171: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 27-172: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 27-173: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 27-174: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 27-175: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 27-176: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 27-177: Loss: 0.0782 Acc: 75.0000%\n",
      "\ttrain 27-178: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 27-179: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 27-180: Loss: 0.4019 Acc: 75.0000%\n",
      "\ttrain 27-181: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 27-182: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 27-183: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 27-184: Loss: 0.0316 Acc: 100.0000%\n",
      "\ttrain 27-185: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 27-186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-187: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 27-188: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 27-189: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 27-190: Loss: 0.1039 Acc: 75.0000%\n",
      "\ttrain 27-191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-192: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 27-193: Loss: 0.1023 Acc: 75.0000%\n",
      "\ttrain 27-194: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 27-195: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 27-196: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 27-197: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 27-198: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 27-199: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 27-200: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-201: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 27-202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-203: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 27-204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-205: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 27-206: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 27-207: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 27-208: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 27-209: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 27-210: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 27-211: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 27-212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 27-213: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 27-214: Loss: 0.0362 Acc: 100.0000%\n",
      "\ttrain 27-215: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 27-216: Loss: 0.2530 Acc: 75.0000%\n",
      "\ttrain 27-217: Loss: 0.6057 Acc: 50.0000%\n",
      "\ttrain 27-218: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 27-219: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 27-220: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 27-221: Loss: 0.3333 Acc: 25.0000%\n",
      "\ttrain 27-222: Loss: 0.1545 Acc: 75.0000%\n",
      "\ttrain 27-223: Loss: 0.2323 Acc: 75.0000%\n",
      "\ttrain 27-224: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 27-225: Loss: 0.1493 Acc: 75.0000%\n",
      "\ttrain 27-226: Loss: 0.1556 Acc: 75.0000%\n",
      "\ttrain 27-227: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 27-228: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 27-229: Loss: 0.6440 Acc: 50.0000%\n",
      "\ttrain 27-230: Loss: 0.4147 Acc: 50.0000%\n",
      "\ttrain 27-231: Loss: 0.5237 Acc: 50.0000%\n",
      "\ttrain 27-232: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 27-233: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 27-234: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 27-235: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 27-236: Loss: 0.0678 Acc: 100.0000%\n",
      "\ttrain 27-237: Loss: 0.0848 Acc: 100.0000%\n",
      "\ttrain 27-238: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 27-239: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 27-240: Loss: 0.1169 Acc: 75.0000%\n",
      "\ttrain 27-241: Loss: 0.0510 Acc: 100.0000%\n",
      "\ttrain 27-242: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 27-243: Loss: 0.0607 Acc: 100.0000%\n",
      "\ttrain 27-244: Loss: 0.0765 Acc: 100.0000%\n",
      "\ttrain 27-245: Loss: 0.1540 Acc: 75.0000%\n",
      "\tvalidation 27-1: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 27-2: Loss: 0.0609 Acc: 100.0000%\n",
      "\tvalidation 27-3: Loss: 0.1494 Acc: 50.0000%\n",
      "\tvalidation 27-4: Loss: 0.0814 Acc: 100.0000%\n",
      "\tvalidation 27-5: Loss: 0.0804 Acc: 75.0000%\n",
      "\tvalidation 27-6: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 27-7: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 27-8: Loss: 0.1325 Acc: 75.0000%\n",
      "\tvalidation 27-9: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 27-10: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 27-11: Loss: 0.0539 Acc: 100.0000%\n",
      "\tvalidation 27-12: Loss: 0.0958 Acc: 75.0000%\n",
      "\tvalidation 27-13: Loss: 0.0574 Acc: 75.0000%\n",
      "\tvalidation 27-14: Loss: 0.0533 Acc: 100.0000%\n",
      "\tvalidation 27-15: Loss: 0.0621 Acc: 100.0000%\n",
      "\tvalidation 27-16: Loss: 0.0648 Acc: 100.0000%\n",
      "\tvalidation 27-17: Loss: 0.0270 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 27-18: Loss: 0.0881 Acc: 100.0000%\n",
      "\tvalidation 27-19: Loss: 0.1062 Acc: 75.0000%\n",
      "\tvalidation 27-20: Loss: 0.1129 Acc: 75.0000%\n",
      "\tvalidation 27-21: Loss: 0.0670 Acc: 75.0000%\n",
      "\tvalidation 27-22: Loss: 0.1147 Acc: 50.0000%\n",
      "\tvalidation 27-23: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 27-24: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 27-25: Loss: 0.0824 Acc: 75.0000%\n",
      "\tvalidation 27-26: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 27-27: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 27-28: Loss: 0.0238 Acc: 100.0000%\n",
      "\tvalidation 27-29: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 27-30: Loss: 0.0363 Acc: 100.0000%\n",
      "\tvalidation 27-31: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 27-32: Loss: 0.0988 Acc: 75.0000%\n",
      "\tvalidation 27-33: Loss: 0.0547 Acc: 75.0000%\n",
      "\tvalidation 27-34: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 27-35: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 27-36: Loss: 0.0839 Acc: 75.0000%\n",
      "\tvalidation 27-37: Loss: 0.0887 Acc: 75.0000%\n",
      "\tvalidation 27-38: Loss: 0.0224 Acc: 100.0000%\n",
      "\tvalidation 27-39: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 27-40: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 27-41: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 27-42: Loss: 0.0827 Acc: 75.0000%\n",
      "\tvalidation 27-43: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 27-44: Loss: 0.0507 Acc: 100.0000%\n",
      "\tvalidation 27-45: Loss: 0.0783 Acc: 100.0000%\n",
      "\tvalidation 27-46: Loss: 0.0367 Acc: 100.0000%\n",
      "\tvalidation 27-47: Loss: 0.0818 Acc: 75.0000%\n",
      "\tvalidation 27-48: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 27-49: Loss: 0.0451 Acc: 100.0000%\n",
      "\tvalidation 27-50: Loss: 0.1635 Acc: 75.0000%\n",
      "\tvalidation 27-51: Loss: 0.2006 Acc: 50.0000%\n",
      "\tvalidation 27-52: Loss: 0.1351 Acc: 75.0000%\n",
      "\tvalidation 27-53: Loss: 0.0548 Acc: 100.0000%\n",
      "\tvalidation 27-54: Loss: 0.0798 Acc: 75.0000%\n",
      "\tvalidation 27-55: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 27-56: Loss: 0.0771 Acc: 100.0000%\n",
      "\tvalidation 27-57: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 27-58: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 27-59: Loss: 0.0872 Acc: 75.0000%\n",
      "\tvalidation 27-60: Loss: 0.0821 Acc: 75.0000%\n",
      "\tvalidation 27-61: Loss: 0.0984 Acc: 75.0000%\n",
      "\tvalidation 27-62: Loss: 0.0423 Acc: 100.0000%\n",
      "\tvalidation 27-63: Loss: 0.0415 Acc: 100.0000%\n",
      "\tvalidation 27-64: Loss: 0.0542 Acc: 100.0000%\n",
      "\tvalidation 27-65: Loss: 0.0709 Acc: 75.0000%\n",
      "\tvalidation 27-66: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 27-67: Loss: 0.0647 Acc: 75.0000%\n",
      "\tvalidation 27-68: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 27-69: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 27-70: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 27-71: Loss: 0.0321 Acc: 100.0000%\n",
      "\tvalidation 27-72: Loss: 0.0264 Acc: 100.0000%\n",
      "\tvalidation 27-73: Loss: 0.0562 Acc: 100.0000%\n",
      "\tvalidation 27-74: Loss: 0.0721 Acc: 75.0000%\n",
      "\tvalidation 27-75: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 27-76: Loss: 0.0662 Acc: 100.0000%\n",
      "\tvalidation 27-77: Loss: 0.0382 Acc: 100.0000%\n",
      "\tvalidation 27-78: Loss: 0.0223 Acc: 100.0000%\n",
      "\tvalidation 27-79: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 27-80: Loss: 0.0279 Acc: 100.0000%\n",
      "\tvalidation 27-81: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 27-82: Loss: 0.0769 Acc: 75.0000%\n",
      "\tvalidation 27-83: Loss: 0.0757 Acc: 100.0000%\n",
      "\tvalidation 27-84: Loss: 0.0784 Acc: 100.0000%\n",
      "\tvalidation 27-85: Loss: 0.0255 Acc: 100.0000%\n",
      "\tvalidation 27-86: Loss: 0.0567 Acc: 75.0000%\n",
      "\tvalidation 27-87: Loss: 0.1069 Acc: 75.0000%\n",
      "\tvalidation 27-88: Loss: 0.1076 Acc: 50.0000%\n",
      "\tvalidation 27-89: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 27-90: Loss: 0.1239 Acc: 75.0000%\n",
      "\tvalidation 27-91: Loss: 0.0693 Acc: 100.0000%\n",
      "\tvalidation 27-92: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 27-93: Loss: 0.0691 Acc: 75.0000%\n",
      "\tvalidation 27-94: Loss: 0.0178 Acc: 100.0000%\n",
      "\tvalidation 27-95: Loss: 0.0758 Acc: 75.0000%\n",
      "\tvalidation 27-96: Loss: 0.0258 Acc: 100.0000%\n",
      "\tvalidation 27-97: Loss: 0.0348 Acc: 100.0000%\n",
      "\tvalidation 27-98: Loss: 0.0665 Acc: 100.0000%\n",
      "\tvalidation 27-99: Loss: 0.0152 Acc: 100.0000%\n",
      "\tvalidation 27-100: Loss: 0.0654 Acc: 100.0000%\n",
      "\tvalidation 27-101: Loss: 0.1219 Acc: 75.0000%\n",
      "\tvalidation 27-102: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 27-103: Loss: 0.1471 Acc: 75.0000%\n",
      "\tvalidation 27-104: Loss: 0.0956 Acc: 75.0000%\n",
      "\tvalidation 27-105: Loss: 0.1025 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0579 Acc: 91.7347%\n",
      "\tvalidation Loss: 0.0580 Acc: 90.0000%\n",
      "Time passed 0h 19m 30s\n",
      "--------------------\n",
      "Epoch [28/40]:\n",
      "\ttrain 28-1: Loss: 0.1941 Acc: 50.0000%\n",
      "\ttrain 28-2: Loss: 0.0216 Acc: 100.0000%\n",
      "\ttrain 28-3: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 28-4: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 28-5: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 28-6: Loss: 0.0590 Acc: 75.0000%\n",
      "\ttrain 28-7: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 28-8: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 28-9: Loss: 0.1046 Acc: 100.0000%\n",
      "\ttrain 28-10: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-11: Loss: 0.0994 Acc: 75.0000%\n",
      "\ttrain 28-12: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 28-13: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 28-14: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 28-15: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 28-16: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 28-17: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-18: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-19: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 28-20: Loss: 0.0615 Acc: 100.0000%\n",
      "\ttrain 28-21: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 28-22: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 28-23: Loss: 0.1635 Acc: 75.0000%\n",
      "\ttrain 28-24: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 28-25: Loss: 0.0401 Acc: 100.0000%\n",
      "\ttrain 28-26: Loss: 0.0441 Acc: 100.0000%\n",
      "\ttrain 28-27: Loss: 0.0524 Acc: 100.0000%\n",
      "\ttrain 28-28: Loss: 0.0465 Acc: 100.0000%\n",
      "\ttrain 28-29: Loss: 0.0213 Acc: 100.0000%\n",
      "\ttrain 28-30: Loss: 0.1742 Acc: 75.0000%\n",
      "\ttrain 28-31: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 28-32: Loss: 0.1576 Acc: 75.0000%\n",
      "\ttrain 28-33: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 28-34: Loss: 0.0556 Acc: 100.0000%\n",
      "\ttrain 28-35: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 28-36: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 28-37: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 28-38: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 28-39: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 28-40: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 28-41: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-42: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 28-43: Loss: 0.0578 Acc: 100.0000%\n",
      "\ttrain 28-44: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 28-45: Loss: 0.1560 Acc: 75.0000%\n",
      "\ttrain 28-46: Loss: 0.2655 Acc: 75.0000%\n",
      "\ttrain 28-47: Loss: 0.2380 Acc: 75.0000%\n",
      "\ttrain 28-48: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 28-49: Loss: 0.1971 Acc: 75.0000%\n",
      "\ttrain 28-50: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 28-51: Loss: 0.0327 Acc: 100.0000%\n",
      "\ttrain 28-52: Loss: 0.1342 Acc: 75.0000%\n",
      "\ttrain 28-53: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 28-54: Loss: 0.2623 Acc: 50.0000%\n",
      "\ttrain 28-55: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 28-56: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 28-57: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 28-58: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 28-59: Loss: 0.2096 Acc: 75.0000%\n",
      "\ttrain 28-60: Loss: 0.0436 Acc: 100.0000%\n",
      "\ttrain 28-61: Loss: 0.0981 Acc: 75.0000%\n",
      "\ttrain 28-62: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 28-63: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 28-64: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 28-65: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 28-66: Loss: 0.1899 Acc: 75.0000%\n",
      "\ttrain 28-67: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 28-68: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 28-69: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 28-70: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 28-71: Loss: 0.2972 Acc: 50.0000%\n",
      "\ttrain 28-72: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 28-73: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 28-74: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 28-75: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 28-76: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 28-77: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 28-78: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 28-79: Loss: 0.2872 Acc: 50.0000%\n",
      "\ttrain 28-80: Loss: 0.0949 Acc: 75.0000%\n",
      "\ttrain 28-81: Loss: 0.0454 Acc: 100.0000%\n",
      "\ttrain 28-82: Loss: 0.0821 Acc: 100.0000%\n",
      "\ttrain 28-83: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 28-84: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 28-85: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 28-86: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 28-87: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 28-88: Loss: 0.0878 Acc: 75.0000%\n",
      "\ttrain 28-89: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 28-90: Loss: 0.4051 Acc: 50.0000%\n",
      "\ttrain 28-91: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 28-92: Loss: 0.0225 Acc: 100.0000%\n",
      "\ttrain 28-93: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 28-94: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-95: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 28-96: Loss: 0.0583 Acc: 100.0000%\n",
      "\ttrain 28-97: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 28-98: Loss: 0.0115 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 28-99: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 28-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 28-101: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 28-102: Loss: 0.0590 Acc: 100.0000%\n",
      "\ttrain 28-103: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 28-104: Loss: 0.0715 Acc: 75.0000%\n",
      "\ttrain 28-105: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 28-106: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 28-107: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 28-108: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 28-109: Loss: 0.2105 Acc: 50.0000%\n",
      "\ttrain 28-110: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 28-111: Loss: 0.0544 Acc: 75.0000%\n",
      "\ttrain 28-112: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 28-113: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 28-114: Loss: 0.0648 Acc: 100.0000%\n",
      "\ttrain 28-115: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 28-116: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 28-117: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 28-118: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 28-119: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 28-120: Loss: 0.0459 Acc: 100.0000%\n",
      "\ttrain 28-121: Loss: 0.0895 Acc: 75.0000%\n",
      "\ttrain 28-122: Loss: 0.0871 Acc: 100.0000%\n",
      "\ttrain 28-123: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 28-124: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 28-125: Loss: 0.0496 Acc: 75.0000%\n",
      "\ttrain 28-126: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 28-127: Loss: 0.0685 Acc: 75.0000%\n",
      "\ttrain 28-128: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 28-129: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 28-130: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 28-131: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 28-132: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 28-133: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 28-134: Loss: 0.0410 Acc: 100.0000%\n",
      "\ttrain 28-135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 28-136: Loss: 0.0382 Acc: 100.0000%\n",
      "\ttrain 28-137: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 28-138: Loss: 0.2313 Acc: 75.0000%\n",
      "\ttrain 28-139: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 28-140: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 28-141: Loss: 0.1336 Acc: 75.0000%\n",
      "\ttrain 28-142: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 28-143: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 28-144: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 28-145: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 28-146: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 28-147: Loss: 0.0961 Acc: 75.0000%\n",
      "\ttrain 28-148: Loss: 0.1420 Acc: 75.0000%\n",
      "\ttrain 28-149: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 28-150: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 28-151: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 28-152: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 28-153: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 28-154: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 28-155: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 28-156: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 28-157: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 28-158: Loss: 0.0724 Acc: 75.0000%\n",
      "\ttrain 28-159: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 28-160: Loss: 0.1094 Acc: 75.0000%\n",
      "\ttrain 28-161: Loss: 0.0935 Acc: 75.0000%\n",
      "\ttrain 28-162: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 28-163: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 28-164: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-165: Loss: 0.0866 Acc: 75.0000%\n",
      "\ttrain 28-166: Loss: 0.0539 Acc: 100.0000%\n",
      "\ttrain 28-167: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 28-168: Loss: 0.1041 Acc: 75.0000%\n",
      "\ttrain 28-169: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 28-170: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 28-171: Loss: 0.0710 Acc: 100.0000%\n",
      "\ttrain 28-172: Loss: 0.1149 Acc: 75.0000%\n",
      "\ttrain 28-173: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 28-174: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 28-175: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 28-176: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 28-177: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 28-178: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 28-179: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 28-180: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 28-181: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 28-182: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 28-183: Loss: 0.1156 Acc: 75.0000%\n",
      "\ttrain 28-184: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 28-185: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 28-186: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 28-187: Loss: 0.2962 Acc: 50.0000%\n",
      "\ttrain 28-188: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 28-189: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 28-190: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 28-191: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 28-192: Loss: 0.0786 Acc: 100.0000%\n",
      "\ttrain 28-193: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 28-194: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 28-195: Loss: 0.0815 Acc: 75.0000%\n",
      "\ttrain 28-196: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 28-197: Loss: 0.1129 Acc: 75.0000%\n",
      "\ttrain 28-198: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 28-199: Loss: 0.4264 Acc: 50.0000%\n",
      "\ttrain 28-200: Loss: 0.1157 Acc: 75.0000%\n",
      "\ttrain 28-201: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 28-202: Loss: 0.2210 Acc: 75.0000%\n",
      "\ttrain 28-203: Loss: 0.1381 Acc: 50.0000%\n",
      "\ttrain 28-204: Loss: 0.1446 Acc: 75.0000%\n",
      "\ttrain 28-205: Loss: 0.0854 Acc: 75.0000%\n",
      "\ttrain 28-206: Loss: 0.0098 Acc: 100.0000%\n",
      "\ttrain 28-207: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 28-208: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 28-209: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 28-210: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 28-211: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 28-212: Loss: 0.0652 Acc: 100.0000%\n",
      "\ttrain 28-213: Loss: 0.1040 Acc: 75.0000%\n",
      "\ttrain 28-214: Loss: 0.0282 Acc: 100.0000%\n",
      "\ttrain 28-215: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 28-216: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 28-217: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 28-218: Loss: 0.1178 Acc: 75.0000%\n",
      "\ttrain 28-219: Loss: 0.0217 Acc: 100.0000%\n",
      "\ttrain 28-220: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 28-221: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 28-222: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 28-223: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 28-224: Loss: 0.1658 Acc: 50.0000%\n",
      "\ttrain 28-225: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 28-226: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 28-227: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 28-228: Loss: 0.0209 Acc: 100.0000%\n",
      "\ttrain 28-229: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 28-230: Loss: 0.3994 Acc: 75.0000%\n",
      "\ttrain 28-231: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 28-232: Loss: 0.2258 Acc: 75.0000%\n",
      "\ttrain 28-233: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 28-234: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 28-235: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 28-236: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 28-237: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 28-238: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 28-239: Loss: 0.0438 Acc: 100.0000%\n",
      "\ttrain 28-240: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 28-241: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 28-242: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 28-243: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 28-244: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 28-245: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 28-1: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 28-2: Loss: 0.0323 Acc: 100.0000%\n",
      "\tvalidation 28-3: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 28-4: Loss: 0.0231 Acc: 100.0000%\n",
      "\tvalidation 28-5: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 28-6: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-7: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 28-8: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 28-9: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 28-10: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 28-11: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 28-12: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 28-13: Loss: 0.0786 Acc: 75.0000%\n",
      "\tvalidation 28-14: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-15: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 28-16: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 28-17: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 28-18: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 28-19: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 28-20: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 28-21: Loss: 0.0868 Acc: 75.0000%\n",
      "\tvalidation 28-22: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 28-23: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 28-24: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-25: Loss: 0.0190 Acc: 100.0000%\n",
      "\tvalidation 28-26: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 28-27: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 28-28: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 28-29: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 28-30: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 28-31: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 28-32: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 28-33: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 28-34: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 28-35: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 28-36: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 28-37: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 28-38: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 28-39: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 28-40: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 28-41: Loss: 0.0332 Acc: 100.0000%\n",
      "\tvalidation 28-42: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 28-43: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-44: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 28-45: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 28-46: Loss: 0.0067 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 28-47: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-48: Loss: 0.0410 Acc: 100.0000%\n",
      "\tvalidation 28-49: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 28-50: Loss: 0.0390 Acc: 100.0000%\n",
      "\tvalidation 28-51: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 28-52: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 28-53: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 28-54: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 28-55: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 28-56: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 28-57: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 28-58: Loss: 0.0366 Acc: 100.0000%\n",
      "\tvalidation 28-59: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 28-60: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 28-61: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-62: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 28-63: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 28-64: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 28-65: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 28-66: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 28-67: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 28-68: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 28-69: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 28-70: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 28-71: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 28-72: Loss: 0.0120 Acc: 100.0000%\n",
      "\tvalidation 28-73: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 28-74: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-75: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 28-76: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-77: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 28-78: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 28-79: Loss: 0.0091 Acc: 100.0000%\n",
      "\tvalidation 28-80: Loss: 0.0262 Acc: 100.0000%\n",
      "\tvalidation 28-81: Loss: 0.0173 Acc: 100.0000%\n",
      "\tvalidation 28-82: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 28-83: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 28-84: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 28-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 28-86: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 28-87: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 28-88: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 28-89: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 28-90: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 28-91: Loss: 0.0176 Acc: 100.0000%\n",
      "\tvalidation 28-92: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 28-93: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 28-94: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 28-95: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 28-96: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 28-97: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 28-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 28-99: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 28-100: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 28-101: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 28-102: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 28-103: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 28-104: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 28-105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0594 Acc: 91.2245%\n",
      "\tvalidation Loss: 0.0099 Acc: 99.5238%\n",
      "网络参数更新\n",
      "Time passed 0h 20m 15s\n",
      "--------------------\n",
      "Epoch [29/40]:\n",
      "\ttrain 29-1: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 29-2: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 29-3: Loss: 0.2049 Acc: 75.0000%\n",
      "\ttrain 29-4: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 29-5: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 29-6: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 29-7: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 29-8: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 29-9: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 29-10: Loss: 0.0586 Acc: 75.0000%\n",
      "\ttrain 29-11: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-12: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 29-13: Loss: 0.1703 Acc: 75.0000%\n",
      "\ttrain 29-14: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 29-15: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 29-16: Loss: 0.1448 Acc: 75.0000%\n",
      "\ttrain 29-17: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 29-18: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 29-19: Loss: 0.0581 Acc: 100.0000%\n",
      "\ttrain 29-20: Loss: 0.0686 Acc: 100.0000%\n",
      "\ttrain 29-21: Loss: 0.0851 Acc: 75.0000%\n",
      "\ttrain 29-22: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 29-23: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 29-24: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 29-25: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 29-26: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 29-27: Loss: 0.0495 Acc: 75.0000%\n",
      "\ttrain 29-28: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 29-29: Loss: 0.2357 Acc: 75.0000%\n",
      "\ttrain 29-30: Loss: 0.0458 Acc: 100.0000%\n",
      "\ttrain 29-31: Loss: 0.1501 Acc: 75.0000%\n",
      "\ttrain 29-32: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 29-33: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-34: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 29-35: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 29-36: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-37: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 29-38: Loss: 0.2254 Acc: 75.0000%\n",
      "\ttrain 29-39: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 29-40: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 29-41: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 29-42: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 29-43: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 29-44: Loss: 0.0743 Acc: 75.0000%\n",
      "\ttrain 29-45: Loss: 0.1138 Acc: 75.0000%\n",
      "\ttrain 29-46: Loss: 0.1573 Acc: 75.0000%\n",
      "\ttrain 29-47: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-48: Loss: 0.0726 Acc: 75.0000%\n",
      "\ttrain 29-49: Loss: 0.1340 Acc: 75.0000%\n",
      "\ttrain 29-50: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-51: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 29-52: Loss: 0.1044 Acc: 75.0000%\n",
      "\ttrain 29-53: Loss: 0.2356 Acc: 75.0000%\n",
      "\ttrain 29-54: Loss: 0.1610 Acc: 75.0000%\n",
      "\ttrain 29-55: Loss: 0.0971 Acc: 75.0000%\n",
      "\ttrain 29-56: Loss: 0.1179 Acc: 75.0000%\n",
      "\ttrain 29-57: Loss: 0.1424 Acc: 75.0000%\n",
      "\ttrain 29-58: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 29-59: Loss: 0.0704 Acc: 75.0000%\n",
      "\ttrain 29-60: Loss: 0.0342 Acc: 100.0000%\n",
      "\ttrain 29-61: Loss: 0.1036 Acc: 75.0000%\n",
      "\ttrain 29-62: Loss: 0.0748 Acc: 75.0000%\n",
      "\ttrain 29-63: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 29-64: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 29-65: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 29-66: Loss: 0.0759 Acc: 75.0000%\n",
      "\ttrain 29-67: Loss: 0.0412 Acc: 100.0000%\n",
      "\ttrain 29-68: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 29-69: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 29-70: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 29-71: Loss: 0.0473 Acc: 100.0000%\n",
      "\ttrain 29-72: Loss: 0.0659 Acc: 75.0000%\n",
      "\ttrain 29-73: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 29-74: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 29-75: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 29-76: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-77: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 29-78: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 29-79: Loss: 0.0657 Acc: 75.0000%\n",
      "\ttrain 29-80: Loss: 0.2081 Acc: 75.0000%\n",
      "\ttrain 29-81: Loss: 0.0653 Acc: 100.0000%\n",
      "\ttrain 29-82: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 29-83: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 29-84: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 29-85: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 29-86: Loss: 0.0536 Acc: 75.0000%\n",
      "\ttrain 29-87: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 29-88: Loss: 0.0224 Acc: 100.0000%\n",
      "\ttrain 29-89: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 29-90: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 29-91: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 29-92: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 29-93: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 29-94: Loss: 0.1352 Acc: 75.0000%\n",
      "\ttrain 29-95: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 29-96: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 29-97: Loss: 0.0486 Acc: 100.0000%\n",
      "\ttrain 29-98: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 29-99: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 29-100: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 29-101: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 29-102: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 29-103: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-104: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 29-105: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 29-106: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 29-107: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 29-108: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 29-109: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-110: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 29-111: Loss: 0.1729 Acc: 75.0000%\n",
      "\ttrain 29-112: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 29-113: Loss: 0.1378 Acc: 50.0000%\n",
      "\ttrain 29-114: Loss: 0.0426 Acc: 100.0000%\n",
      "\ttrain 29-115: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 29-116: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 29-117: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 29-118: Loss: 0.0176 Acc: 100.0000%\n",
      "\ttrain 29-119: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 29-120: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 29-121: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 29-122: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-123: Loss: 0.0166 Acc: 100.0000%\n",
      "\ttrain 29-124: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 29-125: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 29-126: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-127: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-128: Loss: 0.0107 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 29-129: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 29-130: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 29-131: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 29-132: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 29-133: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 29-134: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 29-135: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 29-136: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 29-137: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 29-138: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-139: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 29-140: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 29-141: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 29-142: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 29-143: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 29-144: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-145: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 29-146: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 29-147: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-148: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 29-149: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 29-150: Loss: 0.1668 Acc: 75.0000%\n",
      "\ttrain 29-151: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 29-152: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 29-153: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-154: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 29-155: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 29-156: Loss: 0.2695 Acc: 50.0000%\n",
      "\ttrain 29-157: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 29-158: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 29-159: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 29-160: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 29-161: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 29-162: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 29-163: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 29-164: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 29-165: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 29-166: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 29-167: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 29-168: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 29-169: Loss: 0.0686 Acc: 100.0000%\n",
      "\ttrain 29-170: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 29-171: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 29-172: Loss: 0.0489 Acc: 75.0000%\n",
      "\ttrain 29-173: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 29-174: Loss: 0.1603 Acc: 75.0000%\n",
      "\ttrain 29-175: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 29-176: Loss: 0.1321 Acc: 75.0000%\n",
      "\ttrain 29-177: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 29-178: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 29-179: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 29-180: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 29-181: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 29-182: Loss: 0.1177 Acc: 75.0000%\n",
      "\ttrain 29-183: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 29-184: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 29-185: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 29-186: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 29-187: Loss: 0.4008 Acc: 50.0000%\n",
      "\ttrain 29-188: Loss: 0.2090 Acc: 75.0000%\n",
      "\ttrain 29-189: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-190: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 29-191: Loss: 0.0798 Acc: 75.0000%\n",
      "\ttrain 29-192: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 29-193: Loss: 0.0423 Acc: 100.0000%\n",
      "\ttrain 29-194: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 29-195: Loss: 0.0483 Acc: 75.0000%\n",
      "\ttrain 29-196: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 29-197: Loss: 0.0686 Acc: 75.0000%\n",
      "\ttrain 29-198: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 29-199: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 29-200: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 29-201: Loss: 0.1193 Acc: 75.0000%\n",
      "\ttrain 29-202: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 29-203: Loss: 0.0606 Acc: 100.0000%\n",
      "\ttrain 29-204: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 29-205: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 29-206: Loss: 0.0584 Acc: 75.0000%\n",
      "\ttrain 29-207: Loss: 0.2845 Acc: 50.0000%\n",
      "\ttrain 29-208: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 29-209: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 29-210: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 29-211: Loss: 0.1116 Acc: 100.0000%\n",
      "\ttrain 29-212: Loss: 0.3902 Acc: 50.0000%\n",
      "\ttrain 29-213: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 29-214: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 29-215: Loss: 0.0616 Acc: 75.0000%\n",
      "\ttrain 29-216: Loss: 0.1588 Acc: 75.0000%\n",
      "\ttrain 29-217: Loss: 0.1743 Acc: 75.0000%\n",
      "\ttrain 29-218: Loss: 0.0817 Acc: 75.0000%\n",
      "\ttrain 29-219: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 29-220: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 29-221: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 29-222: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 29-223: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 29-224: Loss: 0.1107 Acc: 75.0000%\n",
      "\ttrain 29-225: Loss: 0.1975 Acc: 50.0000%\n",
      "\ttrain 29-226: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 29-227: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 29-228: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 29-229: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 29-230: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 29-231: Loss: 0.1855 Acc: 75.0000%\n",
      "\ttrain 29-232: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 29-233: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 29-234: Loss: 0.2331 Acc: 75.0000%\n",
      "\ttrain 29-235: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 29-236: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 29-237: Loss: 0.0338 Acc: 100.0000%\n",
      "\ttrain 29-238: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 29-239: Loss: 0.1125 Acc: 75.0000%\n",
      "\ttrain 29-240: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 29-241: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 29-242: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 29-243: Loss: 0.0645 Acc: 100.0000%\n",
      "\ttrain 29-244: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 29-245: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 29-1: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-2: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-3: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 29-4: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-5: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-6: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-7: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 29-8: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-9: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 29-10: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 29-11: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-12: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-13: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-14: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-15: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 29-16: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 29-17: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-18: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 29-19: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-20: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 29-21: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 29-22: Loss: 0.0682 Acc: 75.0000%\n",
      "\tvalidation 29-23: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-24: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 29-25: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-26: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-27: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-28: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 29-29: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 29-30: Loss: 0.0900 Acc: 75.0000%\n",
      "\tvalidation 29-31: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 29-32: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 29-33: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 29-34: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-35: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 29-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-37: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 29-38: Loss: 0.0156 Acc: 100.0000%\n",
      "\tvalidation 29-39: Loss: 0.1391 Acc: 75.0000%\n",
      "\tvalidation 29-40: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-41: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 29-42: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-43: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 29-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-45: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 29-46: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-47: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 29-48: Loss: 0.0129 Acc: 100.0000%\n",
      "\tvalidation 29-49: Loss: 0.0259 Acc: 100.0000%\n",
      "\tvalidation 29-50: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-51: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-52: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 29-53: Loss: 0.0270 Acc: 100.0000%\n",
      "\tvalidation 29-54: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 29-55: Loss: 0.0496 Acc: 75.0000%\n",
      "\tvalidation 29-56: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 29-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-58: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 29-59: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 29-60: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-61: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 29-62: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-63: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 29-64: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-66: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 29-67: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 29-68: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-69: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 29-70: Loss: 0.0016 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 29-71: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 29-72: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 29-73: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 29-74: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-75: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 29-76: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-77: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 29-78: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 29-79: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 29-80: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 29-81: Loss: 0.0894 Acc: 75.0000%\n",
      "\tvalidation 29-82: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 29-83: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-84: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 29-85: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-86: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 29-87: Loss: 0.0461 Acc: 75.0000%\n",
      "\tvalidation 29-88: Loss: 0.0891 Acc: 75.0000%\n",
      "\tvalidation 29-89: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 29-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 29-91: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 29-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 29-93: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 29-94: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 29-95: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 29-96: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 29-97: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 29-98: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 29-99: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 29-100: Loss: 0.0874 Acc: 75.0000%\n",
      "\tvalidation 29-101: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 29-102: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 29-103: Loss: 0.0705 Acc: 75.0000%\n",
      "\tvalidation 29-104: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 29-105: Loss: 0.0305 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0488 Acc: 92.4490%\n",
      "\tvalidation Loss: 0.0112 Acc: 97.8571%\n",
      "Time passed 0h 21m 7s\n",
      "--------------------\n",
      "Epoch [30/40]:\n",
      "\ttrain 30-1: Loss: 0.0932 Acc: 100.0000%\n",
      "\ttrain 30-2: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 30-3: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 30-4: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-5: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 30-6: Loss: 0.1290 Acc: 75.0000%\n",
      "\ttrain 30-7: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 30-8: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 30-9: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 30-10: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 30-11: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 30-12: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-13: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 30-14: Loss: 0.0656 Acc: 75.0000%\n",
      "\ttrain 30-15: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 30-16: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 30-17: Loss: 0.0256 Acc: 100.0000%\n",
      "\ttrain 30-18: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 30-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-20: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-21: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 30-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-23: Loss: 0.0863 Acc: 75.0000%\n",
      "\ttrain 30-24: Loss: 0.3188 Acc: 75.0000%\n",
      "\ttrain 30-25: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-26: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 30-27: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 30-28: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 30-29: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 30-30: Loss: 0.0787 Acc: 75.0000%\n",
      "\ttrain 30-31: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 30-32: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 30-33: Loss: 0.1291 Acc: 75.0000%\n",
      "\ttrain 30-34: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 30-35: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 30-36: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 30-37: Loss: 0.0973 Acc: 75.0000%\n",
      "\ttrain 30-38: Loss: 0.0518 Acc: 100.0000%\n",
      "\ttrain 30-39: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-40: Loss: 0.1574 Acc: 50.0000%\n",
      "\ttrain 30-41: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 30-42: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 30-43: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 30-44: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 30-45: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 30-46: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 30-47: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 30-48: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-49: Loss: 0.1841 Acc: 75.0000%\n",
      "\ttrain 30-50: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 30-51: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-52: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-53: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 30-54: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 30-55: Loss: 0.0506 Acc: 100.0000%\n",
      "\ttrain 30-56: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 30-57: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-58: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 30-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-60: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 30-61: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 30-62: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-63: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 30-64: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 30-65: Loss: 0.1642 Acc: 75.0000%\n",
      "\ttrain 30-66: Loss: 0.1910 Acc: 75.0000%\n",
      "\ttrain 30-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-68: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 30-69: Loss: 0.2164 Acc: 75.0000%\n",
      "\ttrain 30-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-71: Loss: 0.0473 Acc: 75.0000%\n",
      "\ttrain 30-72: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 30-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-74: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 30-75: Loss: 0.1114 Acc: 75.0000%\n",
      "\ttrain 30-76: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 30-77: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-78: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 30-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 30-80: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 30-81: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 30-82: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 30-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-84: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-85: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 30-86: Loss: 0.0834 Acc: 75.0000%\n",
      "\ttrain 30-87: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 30-88: Loss: 0.1327 Acc: 75.0000%\n",
      "\ttrain 30-89: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 30-90: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 30-91: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 30-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-93: Loss: 0.0221 Acc: 100.0000%\n",
      "\ttrain 30-94: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 30-95: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 30-96: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 30-97: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 30-98: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 30-99: Loss: 0.1364 Acc: 75.0000%\n",
      "\ttrain 30-100: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 30-101: Loss: 0.0538 Acc: 100.0000%\n",
      "\ttrain 30-102: Loss: 0.0587 Acc: 75.0000%\n",
      "\ttrain 30-103: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-104: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 30-105: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 30-106: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 30-107: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 30-108: Loss: 0.0972 Acc: 75.0000%\n",
      "\ttrain 30-109: Loss: 0.0435 Acc: 100.0000%\n",
      "\ttrain 30-110: Loss: 0.0807 Acc: 75.0000%\n",
      "\ttrain 30-111: Loss: 0.1583 Acc: 75.0000%\n",
      "\ttrain 30-112: Loss: 0.2004 Acc: 75.0000%\n",
      "\ttrain 30-113: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 30-114: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 30-115: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-116: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-117: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 30-118: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 30-119: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 30-120: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 30-121: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 30-122: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 30-123: Loss: 0.1038 Acc: 75.0000%\n",
      "\ttrain 30-124: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 30-125: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 30-126: Loss: 0.2515 Acc: 50.0000%\n",
      "\ttrain 30-127: Loss: 0.1387 Acc: 75.0000%\n",
      "\ttrain 30-128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-129: Loss: 0.0644 Acc: 75.0000%\n",
      "\ttrain 30-130: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 30-131: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 30-132: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-133: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-134: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 30-135: Loss: 0.2236 Acc: 75.0000%\n",
      "\ttrain 30-136: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 30-137: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 30-138: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 30-139: Loss: 0.0480 Acc: 100.0000%\n",
      "\ttrain 30-140: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 30-141: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 30-142: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 30-143: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 30-144: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 30-145: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 30-146: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 30-147: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-148: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 30-149: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 30-150: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 30-151: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 30-152: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 30-153: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 30-154: Loss: 0.0068 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 30-155: Loss: 0.1693 Acc: 50.0000%\n",
      "\ttrain 30-156: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 30-157: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 30-158: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 30-159: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 30-160: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 30-161: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 30-162: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 30-163: Loss: 0.0482 Acc: 75.0000%\n",
      "\ttrain 30-164: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 30-165: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-166: Loss: 0.1209 Acc: 75.0000%\n",
      "\ttrain 30-167: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 30-168: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 30-169: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 30-170: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 30-171: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 30-172: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 30-173: Loss: 0.2413 Acc: 75.0000%\n",
      "\ttrain 30-174: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 30-175: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 30-176: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 30-177: Loss: 0.0578 Acc: 75.0000%\n",
      "\ttrain 30-178: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 30-179: Loss: 0.1883 Acc: 75.0000%\n",
      "\ttrain 30-180: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 30-181: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 30-182: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 30-183: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 30-184: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 30-185: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 30-186: Loss: 0.0987 Acc: 75.0000%\n",
      "\ttrain 30-187: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 30-188: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 30-189: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 30-190: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 30-191: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 30-192: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 30-193: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 30-194: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 30-195: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 30-196: Loss: 0.0683 Acc: 100.0000%\n",
      "\ttrain 30-197: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 30-198: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 30-199: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 30-200: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 30-201: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 30-202: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 30-203: Loss: 0.0496 Acc: 100.0000%\n",
      "\ttrain 30-204: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 30-205: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 30-206: Loss: 0.0623 Acc: 100.0000%\n",
      "\ttrain 30-207: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 30-208: Loss: 0.0594 Acc: 75.0000%\n",
      "\ttrain 30-209: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 30-210: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 30-211: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 30-212: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-213: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-214: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-215: Loss: 0.0846 Acc: 75.0000%\n",
      "\ttrain 30-216: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 30-217: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 30-218: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 30-219: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-220: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 30-221: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 30-222: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 30-223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 30-224: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 30-225: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 30-226: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 30-227: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 30-228: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 30-229: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 30-230: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 30-231: Loss: 0.1268 Acc: 75.0000%\n",
      "\ttrain 30-232: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 30-233: Loss: 0.0272 Acc: 100.0000%\n",
      "\ttrain 30-234: Loss: 0.2975 Acc: 75.0000%\n",
      "\ttrain 30-235: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 30-236: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 30-237: Loss: 0.2414 Acc: 75.0000%\n",
      "\ttrain 30-238: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 30-239: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 30-240: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 30-241: Loss: 0.0370 Acc: 100.0000%\n",
      "\ttrain 30-242: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 30-243: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 30-244: Loss: 0.2136 Acc: 75.0000%\n",
      "\ttrain 30-245: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 30-1: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 30-2: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 30-3: Loss: 0.1865 Acc: 75.0000%\n",
      "\tvalidation 30-4: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 30-5: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-6: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 30-7: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 30-8: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 30-9: Loss: 0.0610 Acc: 75.0000%\n",
      "\tvalidation 30-10: Loss: 0.1104 Acc: 75.0000%\n",
      "\tvalidation 30-11: Loss: 0.0827 Acc: 75.0000%\n",
      "\tvalidation 30-12: Loss: 0.0080 Acc: 100.0000%\n",
      "\tvalidation 30-13: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 30-14: Loss: 0.0226 Acc: 100.0000%\n",
      "\tvalidation 30-15: Loss: 0.0314 Acc: 100.0000%\n",
      "\tvalidation 30-16: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-17: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-18: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 30-19: Loss: 0.0076 Acc: 100.0000%\n",
      "\tvalidation 30-20: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 30-21: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 30-22: Loss: 0.0514 Acc: 100.0000%\n",
      "\tvalidation 30-23: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-24: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-25: Loss: 0.0426 Acc: 100.0000%\n",
      "\tvalidation 30-26: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 30-27: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 30-28: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 30-29: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 30-30: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-31: Loss: 0.1284 Acc: 75.0000%\n",
      "\tvalidation 30-32: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 30-33: Loss: 0.0763 Acc: 100.0000%\n",
      "\tvalidation 30-34: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 30-35: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 30-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 30-37: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 30-38: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 30-39: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 30-40: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 30-41: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 30-42: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 30-43: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 30-44: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 30-45: Loss: 0.3519 Acc: 50.0000%\n",
      "\tvalidation 30-46: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-47: Loss: 0.1472 Acc: 75.0000%\n",
      "\tvalidation 30-48: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 30-49: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 30-50: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 30-51: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 30-52: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 30-53: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 30-54: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 30-55: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 30-56: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 30-57: Loss: 0.2017 Acc: 75.0000%\n",
      "\tvalidation 30-58: Loss: 0.0720 Acc: 75.0000%\n",
      "\tvalidation 30-59: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 30-60: Loss: 0.0251 Acc: 100.0000%\n",
      "\tvalidation 30-61: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-62: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 30-63: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 30-64: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 30-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 30-66: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 30-67: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 30-68: Loss: 0.0271 Acc: 100.0000%\n",
      "\tvalidation 30-69: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 30-70: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 30-71: Loss: 0.2402 Acc: 75.0000%\n",
      "\tvalidation 30-72: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 30-73: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 30-74: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 30-75: Loss: 0.0556 Acc: 75.0000%\n",
      "\tvalidation 30-76: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 30-77: Loss: 0.0077 Acc: 100.0000%\n",
      "\tvalidation 30-78: Loss: 0.1997 Acc: 75.0000%\n",
      "\tvalidation 30-79: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 30-80: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 30-81: Loss: 0.3634 Acc: 75.0000%\n",
      "\tvalidation 30-82: Loss: 0.0439 Acc: 100.0000%\n",
      "\tvalidation 30-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 30-84: Loss: 0.0230 Acc: 100.0000%\n",
      "\tvalidation 30-85: Loss: 0.0952 Acc: 75.0000%\n",
      "\tvalidation 30-86: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 30-87: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 30-88: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 30-89: Loss: 0.0761 Acc: 75.0000%\n",
      "\tvalidation 30-90: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 30-91: Loss: 0.0175 Acc: 100.0000%\n",
      "\tvalidation 30-92: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 30-93: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 30-94: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 30-95: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 30-96: Loss: 0.0992 Acc: 100.0000%\n",
      "\tvalidation 30-97: Loss: 0.1096 Acc: 75.0000%\n",
      "\tvalidation 30-98: Loss: 0.0278 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 30-99: Loss: 0.1173 Acc: 75.0000%\n",
      "\tvalidation 30-100: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 30-101: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 30-102: Loss: 0.2647 Acc: 75.0000%\n",
      "\tvalidation 30-103: Loss: 0.0187 Acc: 100.0000%\n",
      "\tvalidation 30-104: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 30-105: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain Loss: 0.0410 Acc: 93.7755%\n",
      "\tvalidation Loss: 0.0374 Acc: 95.2381%\n",
      "Time passed 0h 22m 3s\n",
      "--------------------\n",
      "Epoch [31/40]:\n",
      "\ttrain 31-1: Loss: 0.2179 Acc: 75.0000%\n",
      "\ttrain 31-2: Loss: 0.0933 Acc: 75.0000%\n",
      "\ttrain 31-3: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 31-4: Loss: 0.0737 Acc: 100.0000%\n",
      "\ttrain 31-5: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 31-6: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 31-7: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 31-8: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 31-9: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 31-10: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-11: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 31-12: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 31-13: Loss: 0.0654 Acc: 75.0000%\n",
      "\ttrain 31-14: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-15: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-16: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 31-17: Loss: 0.0548 Acc: 75.0000%\n",
      "\ttrain 31-18: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 31-19: Loss: 0.3875 Acc: 75.0000%\n",
      "\ttrain 31-20: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 31-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-22: Loss: 0.0951 Acc: 75.0000%\n",
      "\ttrain 31-23: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-24: Loss: 0.0558 Acc: 100.0000%\n",
      "\ttrain 31-25: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 31-26: Loss: 0.0821 Acc: 75.0000%\n",
      "\ttrain 31-27: Loss: 0.0609 Acc: 75.0000%\n",
      "\ttrain 31-28: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 31-29: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-30: Loss: 0.0471 Acc: 75.0000%\n",
      "\ttrain 31-31: Loss: 0.0448 Acc: 100.0000%\n",
      "\ttrain 31-32: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 31-33: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 31-34: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 31-35: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 31-36: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 31-37: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 31-38: Loss: 0.1694 Acc: 50.0000%\n",
      "\ttrain 31-39: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 31-40: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 31-41: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 31-42: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 31-43: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 31-44: Loss: 0.1167 Acc: 75.0000%\n",
      "\ttrain 31-45: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 31-46: Loss: 0.0917 Acc: 75.0000%\n",
      "\ttrain 31-47: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 31-48: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-49: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 31-50: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-51: Loss: 0.0561 Acc: 100.0000%\n",
      "\ttrain 31-52: Loss: 0.0567 Acc: 75.0000%\n",
      "\ttrain 31-53: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 31-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-55: Loss: 0.0814 Acc: 75.0000%\n",
      "\ttrain 31-56: Loss: 0.0889 Acc: 75.0000%\n",
      "\ttrain 31-57: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 31-58: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 31-59: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-60: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 31-61: Loss: 0.2849 Acc: 50.0000%\n",
      "\ttrain 31-62: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-63: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 31-64: Loss: 0.0392 Acc: 100.0000%\n",
      "\ttrain 31-65: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 31-66: Loss: 0.3162 Acc: 50.0000%\n",
      "\ttrain 31-67: Loss: 0.1357 Acc: 75.0000%\n",
      "\ttrain 31-68: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 31-69: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 31-70: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 31-71: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 31-72: Loss: 0.0147 Acc: 100.0000%\n",
      "\ttrain 31-73: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 31-74: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 31-75: Loss: 0.3163 Acc: 75.0000%\n",
      "\ttrain 31-76: Loss: 0.1422 Acc: 75.0000%\n",
      "\ttrain 31-77: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 31-78: Loss: 0.0705 Acc: 75.0000%\n",
      "\ttrain 31-79: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 31-80: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 31-81: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 31-82: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 31-83: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 31-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-85: Loss: 0.0326 Acc: 100.0000%\n",
      "\ttrain 31-86: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 31-87: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 31-88: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 31-89: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 31-90: Loss: 0.0563 Acc: 100.0000%\n",
      "\ttrain 31-91: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 31-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-93: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 31-94: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 31-95: Loss: 0.3395 Acc: 75.0000%\n",
      "\ttrain 31-96: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 31-97: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 31-98: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 31-99: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 31-100: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 31-101: Loss: 0.0664 Acc: 100.0000%\n",
      "\ttrain 31-102: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 31-103: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 31-104: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 31-105: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 31-106: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 31-107: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 31-108: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 31-109: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 31-110: Loss: 0.0572 Acc: 100.0000%\n",
      "\ttrain 31-111: Loss: 0.2665 Acc: 75.0000%\n",
      "\ttrain 31-112: Loss: 0.1024 Acc: 75.0000%\n",
      "\ttrain 31-113: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-114: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-115: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 31-116: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-117: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 31-118: Loss: 0.2987 Acc: 75.0000%\n",
      "\ttrain 31-119: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 31-120: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 31-121: Loss: 0.0921 Acc: 75.0000%\n",
      "\ttrain 31-122: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 31-123: Loss: 0.0487 Acc: 100.0000%\n",
      "\ttrain 31-124: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-125: Loss: 0.0236 Acc: 100.0000%\n",
      "\ttrain 31-126: Loss: 0.0606 Acc: 75.0000%\n",
      "\ttrain 31-127: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 31-128: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 31-129: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 31-130: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 31-131: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 31-132: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 31-133: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 31-134: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-135: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 31-136: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 31-137: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 31-138: Loss: 0.1204 Acc: 50.0000%\n",
      "\ttrain 31-139: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 31-140: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 31-141: Loss: 0.0762 Acc: 75.0000%\n",
      "\ttrain 31-142: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 31-143: Loss: 0.2239 Acc: 75.0000%\n",
      "\ttrain 31-144: Loss: 0.0478 Acc: 100.0000%\n",
      "\ttrain 31-145: Loss: 0.0493 Acc: 100.0000%\n",
      "\ttrain 31-146: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 31-147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-148: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 31-149: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 31-150: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 31-151: Loss: 0.1400 Acc: 75.0000%\n",
      "\ttrain 31-152: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 31-153: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 31-154: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 31-155: Loss: 0.0883 Acc: 100.0000%\n",
      "\ttrain 31-156: Loss: 0.0647 Acc: 75.0000%\n",
      "\ttrain 31-157: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 31-158: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 31-159: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 31-160: Loss: 0.0804 Acc: 75.0000%\n",
      "\ttrain 31-161: Loss: 0.3101 Acc: 50.0000%\n",
      "\ttrain 31-162: Loss: 0.0193 Acc: 100.0000%\n",
      "\ttrain 31-163: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 31-164: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-165: Loss: 0.0474 Acc: 100.0000%\n",
      "\ttrain 31-166: Loss: 0.2561 Acc: 75.0000%\n",
      "\ttrain 31-167: Loss: 0.0303 Acc: 100.0000%\n",
      "\ttrain 31-168: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 31-169: Loss: 0.0654 Acc: 100.0000%\n",
      "\ttrain 31-170: Loss: 0.1798 Acc: 75.0000%\n",
      "\ttrain 31-171: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-172: Loss: 0.0416 Acc: 100.0000%\n",
      "\ttrain 31-173: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 31-174: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 31-175: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 31-176: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 31-177: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 31-178: Loss: 0.0872 Acc: 75.0000%\n",
      "\ttrain 31-179: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 31-180: Loss: 0.0478 Acc: 75.0000%\n",
      "\ttrain 31-181: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 31-182: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 31-183: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 31-184: Loss: 0.0097 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 31-185: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 31-186: Loss: 0.2687 Acc: 75.0000%\n",
      "\ttrain 31-187: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-188: Loss: 0.0776 Acc: 75.0000%\n",
      "\ttrain 31-189: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 31-190: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 31-191: Loss: 0.1594 Acc: 75.0000%\n",
      "\ttrain 31-192: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 31-193: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 31-194: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 31-195: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 31-196: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 31-197: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 31-198: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 31-199: Loss: 0.0550 Acc: 75.0000%\n",
      "\ttrain 31-200: Loss: 0.0700 Acc: 75.0000%\n",
      "\ttrain 31-201: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 31-202: Loss: 0.0504 Acc: 75.0000%\n",
      "\ttrain 31-203: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 31-204: Loss: 0.1191 Acc: 75.0000%\n",
      "\ttrain 31-205: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 31-206: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 31-207: Loss: 0.1391 Acc: 50.0000%\n",
      "\ttrain 31-208: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 31-209: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 31-210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-211: Loss: 0.1223 Acc: 75.0000%\n",
      "\ttrain 31-212: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 31-213: Loss: 0.1547 Acc: 75.0000%\n",
      "\ttrain 31-214: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 31-215: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 31-216: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-217: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 31-218: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 31-219: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 31-220: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-221: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 31-222: Loss: 0.2223 Acc: 75.0000%\n",
      "\ttrain 31-223: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 31-224: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-225: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 31-226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 31-227: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 31-228: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-229: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 31-230: Loss: 0.1651 Acc: 75.0000%\n",
      "\ttrain 31-231: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 31-232: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 31-233: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 31-234: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 31-235: Loss: 0.0877 Acc: 75.0000%\n",
      "\ttrain 31-236: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 31-237: Loss: 0.0628 Acc: 100.0000%\n",
      "\ttrain 31-238: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 31-239: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 31-240: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 31-241: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 31-242: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 31-243: Loss: 0.2328 Acc: 50.0000%\n",
      "\ttrain 31-244: Loss: 0.1483 Acc: 75.0000%\n",
      "\ttrain 31-245: Loss: 0.0117 Acc: 100.0000%\n",
      "\tvalidation 31-1: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-2: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 31-3: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 31-4: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 31-5: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 31-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-7: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 31-8: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-9: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 31-10: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-11: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-13: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 31-14: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-15: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-16: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-18: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 31-19: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 31-20: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 31-21: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 31-22: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 31-23: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-24: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 31-25: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 31-26: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-27: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 31-28: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-29: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 31-30: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 31-31: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 31-32: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-33: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 31-34: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 31-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-36: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 31-37: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-38: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-39: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 31-40: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-41: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-43: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 31-44: Loss: 0.0358 Acc: 100.0000%\n",
      "\tvalidation 31-45: Loss: 0.0230 Acc: 100.0000%\n",
      "\tvalidation 31-46: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-47: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-48: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-49: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 31-50: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-51: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-52: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-53: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 31-54: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 31-55: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 31-56: Loss: 0.0105 Acc: 100.0000%\n",
      "\tvalidation 31-57: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-58: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-59: Loss: 0.0274 Acc: 100.0000%\n",
      "\tvalidation 31-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-61: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 31-62: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 31-63: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-65: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 31-66: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 31-67: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 31-68: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 31-69: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-70: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 31-71: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 31-72: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-73: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 31-74: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 31-75: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 31-76: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 31-77: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 31-78: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-79: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 31-80: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-81: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 31-82: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 31-83: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 31-84: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-85: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 31-86: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 31-87: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 31-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 31-89: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-90: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 31-91: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 31-92: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 31-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 31-95: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 31-96: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 31-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 31-98: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 31-99: Loss: 0.0165 Acc: 100.0000%\n",
      "\tvalidation 31-100: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 31-101: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 31-102: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 31-103: Loss: 0.0289 Acc: 100.0000%\n",
      "\tvalidation 31-104: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 31-105: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0495 Acc: 92.3469%\n",
      "\tvalidation Loss: 0.0043 Acc: 100.0000%\n",
      "网络参数更新\n",
      "Time passed 0h 23m 6s\n",
      "--------------------\n",
      "Epoch [32/40]:\n",
      "\ttrain 32-1: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 32-2: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 32-3: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-4: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 32-5: Loss: 0.1360 Acc: 75.0000%\n",
      "\ttrain 32-6: Loss: 0.1777 Acc: 75.0000%\n",
      "\ttrain 32-7: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 32-8: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 32-9: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 32-10: Loss: 0.2413 Acc: 75.0000%\n",
      "\ttrain 32-11: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-12: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 32-13: Loss: 0.0333 Acc: 100.0000%\n",
      "\ttrain 32-14: Loss: 0.0882 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-15: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 32-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-17: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 32-18: Loss: 0.1937 Acc: 50.0000%\n",
      "\ttrain 32-19: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-20: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 32-21: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-22: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 32-23: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-25: Loss: 0.0499 Acc: 75.0000%\n",
      "\ttrain 32-26: Loss: 0.0266 Acc: 100.0000%\n",
      "\ttrain 32-27: Loss: 0.0411 Acc: 100.0000%\n",
      "\ttrain 32-28: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 32-29: Loss: 0.1284 Acc: 75.0000%\n",
      "\ttrain 32-30: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-31: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 32-32: Loss: 0.0546 Acc: 100.0000%\n",
      "\ttrain 32-33: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 32-34: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 32-35: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 32-36: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 32-37: Loss: 0.0838 Acc: 75.0000%\n",
      "\ttrain 32-38: Loss: 0.2058 Acc: 75.0000%\n",
      "\ttrain 32-39: Loss: 0.0363 Acc: 100.0000%\n",
      "\ttrain 32-40: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-41: Loss: 0.2739 Acc: 50.0000%\n",
      "\ttrain 32-42: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 32-43: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 32-44: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 32-45: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 32-46: Loss: 0.0478 Acc: 75.0000%\n",
      "\ttrain 32-47: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-48: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 32-49: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 32-50: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 32-51: Loss: 0.0507 Acc: 75.0000%\n",
      "\ttrain 32-52: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 32-53: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 32-54: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 32-55: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 32-56: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 32-57: Loss: 0.1614 Acc: 75.0000%\n",
      "\ttrain 32-58: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 32-59: Loss: 0.2713 Acc: 75.0000%\n",
      "\ttrain 32-60: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 32-61: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 32-62: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 32-63: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 32-64: Loss: 0.0191 Acc: 100.0000%\n",
      "\ttrain 32-65: Loss: 0.3062 Acc: 75.0000%\n",
      "\ttrain 32-66: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 32-67: Loss: 0.0460 Acc: 75.0000%\n",
      "\ttrain 32-68: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-69: Loss: 0.0477 Acc: 100.0000%\n",
      "\ttrain 32-70: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 32-71: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 32-72: Loss: 0.2411 Acc: 50.0000%\n",
      "\ttrain 32-73: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 32-74: Loss: 0.0220 Acc: 100.0000%\n",
      "\ttrain 32-75: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-76: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 32-77: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 32-78: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 32-79: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 32-80: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-81: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 32-82: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 32-83: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 32-84: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 32-85: Loss: 0.1085 Acc: 75.0000%\n",
      "\ttrain 32-86: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 32-87: Loss: 0.0390 Acc: 100.0000%\n",
      "\ttrain 32-88: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 32-89: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 32-90: Loss: 0.0529 Acc: 75.0000%\n",
      "\ttrain 32-91: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-92: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-93: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 32-94: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-95: Loss: 0.0913 Acc: 75.0000%\n",
      "\ttrain 32-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-97: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 32-98: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 32-99: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 32-100: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 32-101: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 32-102: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 32-103: Loss: 0.0270 Acc: 100.0000%\n",
      "\ttrain 32-104: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 32-105: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 32-106: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 32-107: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 32-108: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 32-109: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 32-110: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-111: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-112: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 32-113: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 32-114: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 32-115: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 32-116: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 32-117: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 32-118: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 32-119: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 32-120: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-121: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 32-122: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-123: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 32-124: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 32-125: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-126: Loss: 0.0345 Acc: 100.0000%\n",
      "\ttrain 32-127: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 32-128: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-130: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-131: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 32-132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-133: Loss: 0.1116 Acc: 75.0000%\n",
      "\ttrain 32-134: Loss: 0.5665 Acc: 25.0000%\n",
      "\ttrain 32-135: Loss: 0.2728 Acc: 75.0000%\n",
      "\ttrain 32-136: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 32-137: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-138: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 32-139: Loss: 0.1527 Acc: 75.0000%\n",
      "\ttrain 32-140: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 32-141: Loss: 0.4120 Acc: 75.0000%\n",
      "\ttrain 32-142: Loss: 0.2202 Acc: 75.0000%\n",
      "\ttrain 32-143: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-144: Loss: 0.5290 Acc: 50.0000%\n",
      "\ttrain 32-145: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 32-146: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 32-147: Loss: 0.1741 Acc: 75.0000%\n",
      "\ttrain 32-148: Loss: 0.1951 Acc: 50.0000%\n",
      "\ttrain 32-149: Loss: 0.0938 Acc: 75.0000%\n",
      "\ttrain 32-150: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 32-151: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 32-152: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 32-153: Loss: 0.0871 Acc: 75.0000%\n",
      "\ttrain 32-154: Loss: 0.0666 Acc: 100.0000%\n",
      "\ttrain 32-155: Loss: 0.0468 Acc: 100.0000%\n",
      "\ttrain 32-156: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 32-157: Loss: 0.1272 Acc: 75.0000%\n",
      "\ttrain 32-158: Loss: 0.1030 Acc: 75.0000%\n",
      "\ttrain 32-159: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-160: Loss: 0.0672 Acc: 100.0000%\n",
      "\ttrain 32-161: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 32-162: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 32-163: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-164: Loss: 0.0591 Acc: 100.0000%\n",
      "\ttrain 32-165: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 32-166: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 32-167: Loss: 0.0577 Acc: 100.0000%\n",
      "\ttrain 32-168: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 32-169: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 32-170: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 32-171: Loss: 0.0741 Acc: 100.0000%\n",
      "\ttrain 32-172: Loss: 0.0948 Acc: 100.0000%\n",
      "\ttrain 32-173: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 32-174: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 32-175: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 32-176: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 32-177: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 32-178: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 32-179: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 32-180: Loss: 0.0405 Acc: 100.0000%\n",
      "\ttrain 32-181: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 32-182: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 32-183: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 32-184: Loss: 0.1183 Acc: 75.0000%\n",
      "\ttrain 32-185: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 32-186: Loss: 0.2207 Acc: 50.0000%\n",
      "\ttrain 32-187: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-188: Loss: 0.0645 Acc: 75.0000%\n",
      "\ttrain 32-189: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 32-190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 32-191: Loss: 0.3601 Acc: 50.0000%\n",
      "\ttrain 32-192: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 32-193: Loss: 0.0337 Acc: 100.0000%\n",
      "\ttrain 32-194: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 32-195: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 32-196: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 32-197: Loss: 0.0235 Acc: 100.0000%\n",
      "\ttrain 32-198: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-199: Loss: 0.0383 Acc: 100.0000%\n",
      "\ttrain 32-200: Loss: 0.1010 Acc: 75.0000%\n",
      "\ttrain 32-201: Loss: 0.0664 Acc: 75.0000%\n",
      "\ttrain 32-202: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 32-203: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 32-204: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 32-205: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 32-206: Loss: 0.0311 Acc: 100.0000%\n",
      "\ttrain 32-207: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 32-208: Loss: 0.1307 Acc: 75.0000%\n",
      "\ttrain 32-209: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 32-210: Loss: 0.1853 Acc: 75.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 32-211: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 32-212: Loss: 0.1279 Acc: 75.0000%\n",
      "\ttrain 32-213: Loss: 0.1814 Acc: 50.0000%\n",
      "\ttrain 32-214: Loss: 0.0579 Acc: 75.0000%\n",
      "\ttrain 32-215: Loss: 0.0433 Acc: 100.0000%\n",
      "\ttrain 32-216: Loss: 0.0793 Acc: 75.0000%\n",
      "\ttrain 32-217: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 32-218: Loss: 0.1152 Acc: 75.0000%\n",
      "\ttrain 32-219: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 32-220: Loss: 0.0631 Acc: 100.0000%\n",
      "\ttrain 32-221: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 32-222: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-223: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 32-224: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 32-225: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 32-226: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 32-227: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-228: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 32-229: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 32-230: Loss: 0.0597 Acc: 75.0000%\n",
      "\ttrain 32-231: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 32-232: Loss: 0.1104 Acc: 75.0000%\n",
      "\ttrain 32-233: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 32-234: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 32-235: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 32-236: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 32-237: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 32-238: Loss: 0.0722 Acc: 75.0000%\n",
      "\ttrain 32-239: Loss: 0.1050 Acc: 75.0000%\n",
      "\ttrain 32-240: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 32-241: Loss: 0.1608 Acc: 75.0000%\n",
      "\ttrain 32-242: Loss: 0.1402 Acc: 75.0000%\n",
      "\ttrain 32-243: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 32-244: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 32-245: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 32-1: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 32-2: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 32-3: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 32-4: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 32-5: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 32-6: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 32-7: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 32-8: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 32-9: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 32-10: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 32-11: Loss: 0.0564 Acc: 100.0000%\n",
      "\tvalidation 32-12: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 32-13: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 32-14: Loss: 0.0353 Acc: 100.0000%\n",
      "\tvalidation 32-15: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 32-16: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 32-17: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-18: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 32-19: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 32-20: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-21: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 32-22: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 32-23: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 32-24: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 32-25: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 32-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-28: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 32-29: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 32-30: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 32-31: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 32-32: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 32-33: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 32-34: Loss: 0.0215 Acc: 100.0000%\n",
      "\tvalidation 32-35: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 32-36: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 32-37: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 32-38: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 32-39: Loss: 0.0182 Acc: 100.0000%\n",
      "\tvalidation 32-40: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 32-41: Loss: 0.0121 Acc: 100.0000%\n",
      "\tvalidation 32-42: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 32-43: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 32-44: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-45: Loss: 0.0111 Acc: 100.0000%\n",
      "\tvalidation 32-46: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 32-47: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 32-48: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 32-49: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 32-50: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 32-51: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 32-52: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 32-53: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 32-54: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 32-55: Loss: 0.0700 Acc: 75.0000%\n",
      "\tvalidation 32-56: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-57: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 32-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-59: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 32-60: Loss: 0.0066 Acc: 100.0000%\n",
      "\tvalidation 32-61: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-62: Loss: 0.0131 Acc: 100.0000%\n",
      "\tvalidation 32-63: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 32-64: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 32-65: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 32-66: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 32-67: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 32-68: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 32-69: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 32-70: Loss: 0.0132 Acc: 100.0000%\n",
      "\tvalidation 32-71: Loss: 0.0059 Acc: 100.0000%\n",
      "\tvalidation 32-72: Loss: 0.0058 Acc: 100.0000%\n",
      "\tvalidation 32-73: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 32-74: Loss: 0.0256 Acc: 100.0000%\n",
      "\tvalidation 32-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-76: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 32-77: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 32-78: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 32-79: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-80: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 32-81: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 32-82: Loss: 0.0147 Acc: 100.0000%\n",
      "\tvalidation 32-83: Loss: 0.0301 Acc: 100.0000%\n",
      "\tvalidation 32-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-85: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 32-86: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-87: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 32-88: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 32-89: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 32-90: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 32-91: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 32-92: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 32-93: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 32-94: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 32-95: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 32-96: Loss: 0.0145 Acc: 100.0000%\n",
      "\tvalidation 32-97: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 32-98: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 32-99: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 32-100: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 32-101: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 32-102: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 32-103: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 32-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 32-105: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0501 Acc: 92.7551%\n",
      "\tvalidation Loss: 0.0087 Acc: 99.7619%\n",
      "Time passed 0h 24m 2s\n",
      "--------------------\n",
      "Epoch [33/40]:\n",
      "\ttrain 33-1: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 33-2: Loss: 0.1440 Acc: 75.0000%\n",
      "\ttrain 33-3: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 33-4: Loss: 0.1460 Acc: 75.0000%\n",
      "\ttrain 33-5: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 33-6: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 33-7: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 33-8: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 33-9: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 33-10: Loss: 0.0888 Acc: 75.0000%\n",
      "\ttrain 33-11: Loss: 0.1476 Acc: 75.0000%\n",
      "\ttrain 33-12: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 33-13: Loss: 0.0614 Acc: 100.0000%\n",
      "\ttrain 33-14: Loss: 0.0754 Acc: 75.0000%\n",
      "\ttrain 33-15: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 33-16: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 33-17: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 33-18: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-19: Loss: 0.1840 Acc: 50.0000%\n",
      "\ttrain 33-20: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 33-21: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-22: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 33-23: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-24: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 33-25: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 33-26: Loss: 0.1434 Acc: 75.0000%\n",
      "\ttrain 33-27: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 33-28: Loss: 0.0607 Acc: 75.0000%\n",
      "\ttrain 33-29: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 33-30: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 33-31: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 33-32: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 33-33: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 33-34: Loss: 0.1065 Acc: 75.0000%\n",
      "\ttrain 33-35: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 33-36: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 33-37: Loss: 0.3489 Acc: 75.0000%\n",
      "\ttrain 33-38: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 33-39: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 33-40: Loss: 0.0208 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-41: Loss: 0.1694 Acc: 75.0000%\n",
      "\ttrain 33-42: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 33-43: Loss: 0.0783 Acc: 75.0000%\n",
      "\ttrain 33-44: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 33-45: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 33-46: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 33-47: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 33-48: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 33-49: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 33-50: Loss: 0.0172 Acc: 100.0000%\n",
      "\ttrain 33-51: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-52: Loss: 0.0375 Acc: 100.0000%\n",
      "\ttrain 33-53: Loss: 0.0723 Acc: 100.0000%\n",
      "\ttrain 33-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-55: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 33-56: Loss: 0.1124 Acc: 75.0000%\n",
      "\ttrain 33-57: Loss: 0.1206 Acc: 75.0000%\n",
      "\ttrain 33-58: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 33-59: Loss: 0.0201 Acc: 100.0000%\n",
      "\ttrain 33-60: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 33-61: Loss: 0.0347 Acc: 100.0000%\n",
      "\ttrain 33-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-63: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-64: Loss: 0.0503 Acc: 100.0000%\n",
      "\ttrain 33-65: Loss: 0.0730 Acc: 75.0000%\n",
      "\ttrain 33-66: Loss: 0.1505 Acc: 75.0000%\n",
      "\ttrain 33-67: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 33-68: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-69: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 33-70: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 33-71: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 33-72: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-73: Loss: 0.0169 Acc: 100.0000%\n",
      "\ttrain 33-74: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 33-75: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 33-76: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-77: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 33-78: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 33-79: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 33-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-81: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-82: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 33-83: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 33-84: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-85: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 33-86: Loss: 0.0472 Acc: 100.0000%\n",
      "\ttrain 33-87: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 33-88: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 33-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-90: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 33-91: Loss: 0.0589 Acc: 75.0000%\n",
      "\ttrain 33-92: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-93: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 33-94: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 33-95: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 33-96: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 33-97: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 33-98: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-99: Loss: 0.1222 Acc: 50.0000%\n",
      "\ttrain 33-100: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 33-101: Loss: 0.0569 Acc: 75.0000%\n",
      "\ttrain 33-102: Loss: 0.2173 Acc: 50.0000%\n",
      "\ttrain 33-103: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 33-104: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 33-105: Loss: 0.1525 Acc: 75.0000%\n",
      "\ttrain 33-106: Loss: 0.1630 Acc: 75.0000%\n",
      "\ttrain 33-107: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-108: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 33-109: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 33-110: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 33-111: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 33-112: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 33-113: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 33-114: Loss: 0.0564 Acc: 75.0000%\n",
      "\ttrain 33-115: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 33-116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-117: Loss: 0.0108 Acc: 100.0000%\n",
      "\ttrain 33-118: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 33-119: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-120: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 33-121: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 33-122: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 33-123: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 33-124: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 33-125: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 33-126: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-127: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-128: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 33-129: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 33-130: Loss: 0.0732 Acc: 75.0000%\n",
      "\ttrain 33-131: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-132: Loss: 0.0310 Acc: 100.0000%\n",
      "\ttrain 33-133: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 33-134: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 33-135: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 33-136: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-137: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-138: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-139: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 33-140: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-141: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 33-142: Loss: 0.0599 Acc: 75.0000%\n",
      "\ttrain 33-143: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 33-144: Loss: 0.1622 Acc: 75.0000%\n",
      "\ttrain 33-145: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 33-146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-147: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 33-148: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 33-149: Loss: 0.2378 Acc: 75.0000%\n",
      "\ttrain 33-150: Loss: 0.0833 Acc: 75.0000%\n",
      "\ttrain 33-151: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 33-152: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 33-153: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-154: Loss: 0.0928 Acc: 75.0000%\n",
      "\ttrain 33-155: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 33-156: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 33-157: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 33-158: Loss: 0.0639 Acc: 75.0000%\n",
      "\ttrain 33-159: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 33-160: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 33-161: Loss: 0.1343 Acc: 75.0000%\n",
      "\ttrain 33-162: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-163: Loss: 0.0280 Acc: 100.0000%\n",
      "\ttrain 33-164: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 33-165: Loss: 0.2620 Acc: 50.0000%\n",
      "\ttrain 33-166: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 33-167: Loss: 0.0139 Acc: 100.0000%\n",
      "\ttrain 33-168: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 33-169: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 33-170: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 33-171: Loss: 0.0515 Acc: 75.0000%\n",
      "\ttrain 33-172: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 33-173: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 33-174: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 33-175: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 33-176: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 33-177: Loss: 0.3342 Acc: 75.0000%\n",
      "\ttrain 33-178: Loss: 0.0767 Acc: 100.0000%\n",
      "\ttrain 33-179: Loss: 0.2704 Acc: 75.0000%\n",
      "\ttrain 33-180: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 33-181: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 33-182: Loss: 0.0845 Acc: 75.0000%\n",
      "\ttrain 33-183: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-184: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 33-185: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 33-186: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 33-187: Loss: 0.5223 Acc: 50.0000%\n",
      "\ttrain 33-188: Loss: 0.2240 Acc: 50.0000%\n",
      "\ttrain 33-189: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 33-190: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 33-191: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-192: Loss: 0.0439 Acc: 100.0000%\n",
      "\ttrain 33-193: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-195: Loss: 0.0553 Acc: 75.0000%\n",
      "\ttrain 33-196: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 33-197: Loss: 0.0642 Acc: 100.0000%\n",
      "\ttrain 33-198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 33-199: Loss: 0.1449 Acc: 50.0000%\n",
      "\ttrain 33-200: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 33-201: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 33-202: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 33-203: Loss: 0.1253 Acc: 75.0000%\n",
      "\ttrain 33-204: Loss: 0.1412 Acc: 75.0000%\n",
      "\ttrain 33-205: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 33-206: Loss: 0.1777 Acc: 75.0000%\n",
      "\ttrain 33-207: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 33-208: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 33-209: Loss: 0.0692 Acc: 75.0000%\n",
      "\ttrain 33-210: Loss: 0.0111 Acc: 100.0000%\n",
      "\ttrain 33-211: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 33-212: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 33-213: Loss: 0.0710 Acc: 75.0000%\n",
      "\ttrain 33-214: Loss: 0.0543 Acc: 100.0000%\n",
      "\ttrain 33-215: Loss: 0.3098 Acc: 50.0000%\n",
      "\ttrain 33-216: Loss: 0.0774 Acc: 75.0000%\n",
      "\ttrain 33-217: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 33-218: Loss: 0.0553 Acc: 100.0000%\n",
      "\ttrain 33-219: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 33-220: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 33-221: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 33-222: Loss: 0.0126 Acc: 100.0000%\n",
      "\ttrain 33-223: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 33-224: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 33-225: Loss: 0.3125 Acc: 50.0000%\n",
      "\ttrain 33-226: Loss: 0.0649 Acc: 100.0000%\n",
      "\ttrain 33-227: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 33-228: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 33-229: Loss: 0.0302 Acc: 100.0000%\n",
      "\ttrain 33-230: Loss: 0.7362 Acc: 75.0000%\n",
      "\ttrain 33-231: Loss: 0.1207 Acc: 50.0000%\n",
      "\ttrain 33-232: Loss: 0.1542 Acc: 75.0000%\n",
      "\ttrain 33-233: Loss: 0.1254 Acc: 75.0000%\n",
      "\ttrain 33-234: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 33-235: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 33-236: Loss: 0.0083 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 33-237: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 33-238: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 33-239: Loss: 0.0646 Acc: 100.0000%\n",
      "\ttrain 33-240: Loss: 0.1738 Acc: 75.0000%\n",
      "\ttrain 33-241: Loss: 0.4291 Acc: 50.0000%\n",
      "\ttrain 33-242: Loss: 0.2462 Acc: 75.0000%\n",
      "\ttrain 33-243: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 33-244: Loss: 0.1906 Acc: 50.0000%\n",
      "\ttrain 33-245: Loss: 0.1318 Acc: 75.0000%\n",
      "\tvalidation 33-1: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 33-2: Loss: 0.0239 Acc: 100.0000%\n",
      "\tvalidation 33-3: Loss: 0.0135 Acc: 100.0000%\n",
      "\tvalidation 33-4: Loss: 0.0361 Acc: 100.0000%\n",
      "\tvalidation 33-5: Loss: 0.0349 Acc: 100.0000%\n",
      "\tvalidation 33-6: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 33-7: Loss: 0.0161 Acc: 100.0000%\n",
      "\tvalidation 33-8: Loss: 0.0198 Acc: 100.0000%\n",
      "\tvalidation 33-9: Loss: 0.0315 Acc: 100.0000%\n",
      "\tvalidation 33-10: Loss: 0.0377 Acc: 100.0000%\n",
      "\tvalidation 33-11: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 33-12: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 33-13: Loss: 0.0267 Acc: 100.0000%\n",
      "\tvalidation 33-14: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 33-15: Loss: 0.0556 Acc: 100.0000%\n",
      "\tvalidation 33-16: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-17: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 33-18: Loss: 0.0606 Acc: 75.0000%\n",
      "\tvalidation 33-19: Loss: 0.0315 Acc: 100.0000%\n",
      "\tvalidation 33-20: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 33-21: Loss: 0.0430 Acc: 100.0000%\n",
      "\tvalidation 33-22: Loss: 0.0452 Acc: 100.0000%\n",
      "\tvalidation 33-23: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 33-24: Loss: 0.0261 Acc: 100.0000%\n",
      "\tvalidation 33-25: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 33-26: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 33-27: Loss: 0.0219 Acc: 100.0000%\n",
      "\tvalidation 33-28: Loss: 0.0367 Acc: 100.0000%\n",
      "\tvalidation 33-29: Loss: 0.0526 Acc: 100.0000%\n",
      "\tvalidation 33-30: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 33-31: Loss: 0.0386 Acc: 100.0000%\n",
      "\tvalidation 33-32: Loss: 0.0345 Acc: 100.0000%\n",
      "\tvalidation 33-33: Loss: 0.0309 Acc: 100.0000%\n",
      "\tvalidation 33-34: Loss: 0.0433 Acc: 100.0000%\n",
      "\tvalidation 33-35: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 33-36: Loss: 0.0222 Acc: 100.0000%\n",
      "\tvalidation 33-37: Loss: 0.0827 Acc: 100.0000%\n",
      "\tvalidation 33-38: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 33-39: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 33-40: Loss: 0.0750 Acc: 100.0000%\n",
      "\tvalidation 33-41: Loss: 0.0240 Acc: 100.0000%\n",
      "\tvalidation 33-42: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 33-43: Loss: 0.0235 Acc: 100.0000%\n",
      "\tvalidation 33-44: Loss: 0.0808 Acc: 75.0000%\n",
      "\tvalidation 33-45: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 33-46: Loss: 0.0149 Acc: 100.0000%\n",
      "\tvalidation 33-47: Loss: 0.0426 Acc: 100.0000%\n",
      "\tvalidation 33-48: Loss: 0.0244 Acc: 100.0000%\n",
      "\tvalidation 33-49: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 33-50: Loss: 0.0744 Acc: 100.0000%\n",
      "\tvalidation 33-51: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 33-52: Loss: 0.0292 Acc: 100.0000%\n",
      "\tvalidation 33-53: Loss: 0.0333 Acc: 100.0000%\n",
      "\tvalidation 33-54: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 33-55: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 33-56: Loss: 0.0389 Acc: 100.0000%\n",
      "\tvalidation 33-57: Loss: 0.0832 Acc: 100.0000%\n",
      "\tvalidation 33-58: Loss: 0.0518 Acc: 100.0000%\n",
      "\tvalidation 33-59: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 33-60: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 33-61: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 33-62: Loss: 0.0265 Acc: 100.0000%\n",
      "\tvalidation 33-63: Loss: 0.0341 Acc: 100.0000%\n",
      "\tvalidation 33-64: Loss: 0.0716 Acc: 100.0000%\n",
      "\tvalidation 33-65: Loss: 0.0471 Acc: 100.0000%\n",
      "\tvalidation 33-66: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 33-67: Loss: 0.0144 Acc: 100.0000%\n",
      "\tvalidation 33-68: Loss: 0.0218 Acc: 100.0000%\n",
      "\tvalidation 33-69: Loss: 0.0286 Acc: 100.0000%\n",
      "\tvalidation 33-70: Loss: 0.0128 Acc: 100.0000%\n",
      "\tvalidation 33-71: Loss: 0.0291 Acc: 100.0000%\n",
      "\tvalidation 33-72: Loss: 0.0299 Acc: 100.0000%\n",
      "\tvalidation 33-73: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 33-74: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 33-75: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 33-76: Loss: 0.0470 Acc: 100.0000%\n",
      "\tvalidation 33-77: Loss: 0.0248 Acc: 100.0000%\n",
      "\tvalidation 33-78: Loss: 0.0572 Acc: 100.0000%\n",
      "\tvalidation 33-79: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 33-80: Loss: 0.0260 Acc: 100.0000%\n",
      "\tvalidation 33-81: Loss: 0.0587 Acc: 100.0000%\n",
      "\tvalidation 33-82: Loss: 0.0458 Acc: 100.0000%\n",
      "\tvalidation 33-83: Loss: 0.0786 Acc: 100.0000%\n",
      "\tvalidation 33-84: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 33-85: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 33-86: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 33-87: Loss: 0.0594 Acc: 100.0000%\n",
      "\tvalidation 33-88: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 33-89: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 33-90: Loss: 0.0195 Acc: 100.0000%\n",
      "\tvalidation 33-91: Loss: 0.0508 Acc: 100.0000%\n",
      "\tvalidation 33-92: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 33-93: Loss: 0.1157 Acc: 100.0000%\n",
      "\tvalidation 33-94: Loss: 0.0614 Acc: 100.0000%\n",
      "\tvalidation 33-95: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 33-96: Loss: 0.0160 Acc: 100.0000%\n",
      "\tvalidation 33-97: Loss: 0.0445 Acc: 100.0000%\n",
      "\tvalidation 33-98: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 33-99: Loss: 0.0784 Acc: 100.0000%\n",
      "\tvalidation 33-100: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 33-101: Loss: 0.0337 Acc: 100.0000%\n",
      "\tvalidation 33-102: Loss: 0.0242 Acc: 100.0000%\n",
      "\tvalidation 33-103: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 33-104: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 33-105: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0523 Acc: 91.9388%\n",
      "\tvalidation Loss: 0.0308 Acc: 99.5238%\n",
      "Time passed 0h 25m 1s\n",
      "--------------------\n",
      "Epoch [34/40]:\n",
      "\ttrain 34-1: Loss: 0.0587 Acc: 100.0000%\n",
      "\ttrain 34-2: Loss: 0.2414 Acc: 75.0000%\n",
      "\ttrain 34-3: Loss: 0.0696 Acc: 100.0000%\n",
      "\ttrain 34-4: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 34-5: Loss: 0.0550 Acc: 100.0000%\n",
      "\ttrain 34-6: Loss: 0.0925 Acc: 75.0000%\n",
      "\ttrain 34-7: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 34-8: Loss: 0.0528 Acc: 100.0000%\n",
      "\ttrain 34-9: Loss: 0.1457 Acc: 75.0000%\n",
      "\ttrain 34-10: Loss: 0.2130 Acc: 50.0000%\n",
      "\ttrain 34-11: Loss: 0.1520 Acc: 50.0000%\n",
      "\ttrain 34-12: Loss: 0.0965 Acc: 100.0000%\n",
      "\ttrain 34-13: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 34-14: Loss: 0.0811 Acc: 100.0000%\n",
      "\ttrain 34-15: Loss: 0.0852 Acc: 100.0000%\n",
      "\ttrain 34-16: Loss: 0.0736 Acc: 100.0000%\n",
      "\ttrain 34-17: Loss: 0.0897 Acc: 100.0000%\n",
      "\ttrain 34-18: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 34-19: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 34-20: Loss: 0.1750 Acc: 50.0000%\n",
      "\ttrain 34-21: Loss: 0.1676 Acc: 75.0000%\n",
      "\ttrain 34-22: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 34-23: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 34-24: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 34-25: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 34-26: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 34-27: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 34-28: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 34-29: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 34-30: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-31: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 34-32: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 34-33: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 34-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 34-35: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 34-36: Loss: 0.3021 Acc: 75.0000%\n",
      "\ttrain 34-37: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 34-38: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 34-39: Loss: 0.2039 Acc: 75.0000%\n",
      "\ttrain 34-40: Loss: 0.0379 Acc: 100.0000%\n",
      "\ttrain 34-41: Loss: 0.0688 Acc: 100.0000%\n",
      "\ttrain 34-42: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 34-43: Loss: 0.0482 Acc: 100.0000%\n",
      "\ttrain 34-44: Loss: 0.0099 Acc: 100.0000%\n",
      "\ttrain 34-45: Loss: 0.0991 Acc: 75.0000%\n",
      "\ttrain 34-46: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 34-47: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 34-48: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 34-49: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 34-50: Loss: 0.0767 Acc: 75.0000%\n",
      "\ttrain 34-51: Loss: 0.2303 Acc: 75.0000%\n",
      "\ttrain 34-52: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 34-53: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 34-54: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 34-55: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 34-56: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 34-57: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 34-58: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 34-59: Loss: 0.0123 Acc: 100.0000%\n",
      "\ttrain 34-60: Loss: 0.0481 Acc: 100.0000%\n",
      "\ttrain 34-61: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 34-62: Loss: 0.0600 Acc: 75.0000%\n",
      "\ttrain 34-63: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 34-64: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 34-65: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-66: Loss: 0.2687 Acc: 50.0000%\n",
      "\ttrain 34-67: Loss: 0.0035 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 34-68: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 34-69: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 34-70: Loss: 0.1054 Acc: 75.0000%\n",
      "\ttrain 34-71: Loss: 0.1003 Acc: 75.0000%\n",
      "\ttrain 34-72: Loss: 0.0380 Acc: 100.0000%\n",
      "\ttrain 34-73: Loss: 0.4102 Acc: 25.0000%\n",
      "\ttrain 34-74: Loss: 0.1370 Acc: 75.0000%\n",
      "\ttrain 34-75: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 34-76: Loss: 0.2026 Acc: 50.0000%\n",
      "\ttrain 34-77: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 34-78: Loss: 0.1486 Acc: 75.0000%\n",
      "\ttrain 34-79: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 34-80: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 34-81: Loss: 0.1697 Acc: 75.0000%\n",
      "\ttrain 34-82: Loss: 0.0695 Acc: 100.0000%\n",
      "\ttrain 34-83: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 34-84: Loss: 0.1175 Acc: 75.0000%\n",
      "\ttrain 34-85: Loss: 0.1732 Acc: 75.0000%\n",
      "\ttrain 34-86: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 34-87: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 34-88: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 34-89: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 34-90: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 34-91: Loss: 0.0778 Acc: 100.0000%\n",
      "\ttrain 34-92: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 34-93: Loss: 0.0301 Acc: 100.0000%\n",
      "\ttrain 34-94: Loss: 0.1477 Acc: 75.0000%\n",
      "\ttrain 34-95: Loss: 0.3049 Acc: 75.0000%\n",
      "\ttrain 34-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-97: Loss: 0.0753 Acc: 75.0000%\n",
      "\ttrain 34-98: Loss: 0.0420 Acc: 100.0000%\n",
      "\ttrain 34-99: Loss: 0.1568 Acc: 50.0000%\n",
      "\ttrain 34-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 34-101: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 34-102: Loss: 0.0144 Acc: 100.0000%\n",
      "\ttrain 34-103: Loss: 0.0622 Acc: 75.0000%\n",
      "\ttrain 34-104: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 34-105: Loss: 0.0810 Acc: 100.0000%\n",
      "\ttrain 34-106: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 34-107: Loss: 0.0257 Acc: 100.0000%\n",
      "\ttrain 34-108: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 34-109: Loss: 0.0255 Acc: 100.0000%\n",
      "\ttrain 34-110: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 34-111: Loss: 0.0197 Acc: 100.0000%\n",
      "\ttrain 34-112: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 34-113: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 34-114: Loss: 0.1389 Acc: 75.0000%\n",
      "\ttrain 34-115: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 34-116: Loss: 0.1411 Acc: 75.0000%\n",
      "\ttrain 34-117: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 34-118: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 34-119: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 34-120: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 34-121: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 34-122: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 34-123: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 34-124: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 34-125: Loss: 0.2349 Acc: 75.0000%\n",
      "\ttrain 34-126: Loss: 0.0901 Acc: 75.0000%\n",
      "\ttrain 34-127: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 34-128: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 34-129: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 34-130: Loss: 0.3896 Acc: 50.0000%\n",
      "\ttrain 34-131: Loss: 0.1974 Acc: 50.0000%\n",
      "\ttrain 34-132: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 34-133: Loss: 0.1928 Acc: 75.0000%\n",
      "\ttrain 34-134: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 34-135: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 34-136: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 34-137: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 34-138: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 34-139: Loss: 0.0537 Acc: 100.0000%\n",
      "\ttrain 34-140: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 34-141: Loss: 0.1324 Acc: 75.0000%\n",
      "\ttrain 34-142: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 34-143: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 34-144: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-145: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 34-146: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 34-147: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-148: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 34-149: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-150: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 34-151: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 34-152: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 34-153: Loss: 0.1796 Acc: 75.0000%\n",
      "\ttrain 34-154: Loss: 0.0877 Acc: 100.0000%\n",
      "\ttrain 34-155: Loss: 0.0470 Acc: 75.0000%\n",
      "\ttrain 34-156: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 34-157: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 34-158: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 34-159: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 34-160: Loss: 0.0489 Acc: 100.0000%\n",
      "\ttrain 34-161: Loss: 0.0640 Acc: 100.0000%\n",
      "\ttrain 34-162: Loss: 0.0530 Acc: 75.0000%\n",
      "\ttrain 34-163: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 34-164: Loss: 0.0317 Acc: 100.0000%\n",
      "\ttrain 34-165: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-166: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 34-167: Loss: 0.3412 Acc: 75.0000%\n",
      "\ttrain 34-168: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 34-169: Loss: 0.0354 Acc: 100.0000%\n",
      "\ttrain 34-170: Loss: 0.2270 Acc: 75.0000%\n",
      "\ttrain 34-171: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 34-172: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 34-173: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 34-174: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 34-175: Loss: 0.1089 Acc: 75.0000%\n",
      "\ttrain 34-176: Loss: 0.1008 Acc: 75.0000%\n",
      "\ttrain 34-177: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 34-178: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 34-179: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 34-180: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 34-181: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 34-182: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 34-183: Loss: 0.0430 Acc: 100.0000%\n",
      "\ttrain 34-184: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 34-185: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-186: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 34-187: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 34-188: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 34-189: Loss: 0.6292 Acc: 50.0000%\n",
      "\ttrain 34-190: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 34-191: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 34-192: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 34-193: Loss: 0.1309 Acc: 75.0000%\n",
      "\ttrain 34-194: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 34-195: Loss: 0.0505 Acc: 100.0000%\n",
      "\ttrain 34-196: Loss: 0.1048 Acc: 75.0000%\n",
      "\ttrain 34-197: Loss: 0.5440 Acc: 25.0000%\n",
      "\ttrain 34-198: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 34-199: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 34-200: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 34-201: Loss: 0.0259 Acc: 100.0000%\n",
      "\ttrain 34-202: Loss: 0.2526 Acc: 75.0000%\n",
      "\ttrain 34-203: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 34-204: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 34-205: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 34-206: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 34-207: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 34-208: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 34-209: Loss: 0.0776 Acc: 75.0000%\n",
      "\ttrain 34-210: Loss: 0.0944 Acc: 75.0000%\n",
      "\ttrain 34-211: Loss: 0.1174 Acc: 75.0000%\n",
      "\ttrain 34-212: Loss: 0.1323 Acc: 75.0000%\n",
      "\ttrain 34-213: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 34-214: Loss: 0.0688 Acc: 75.0000%\n",
      "\ttrain 34-215: Loss: 0.0499 Acc: 100.0000%\n",
      "\ttrain 34-216: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-217: Loss: 0.2779 Acc: 50.0000%\n",
      "\ttrain 34-218: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 34-219: Loss: 0.0976 Acc: 100.0000%\n",
      "\ttrain 34-220: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 34-221: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 34-222: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 34-223: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 34-224: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 34-225: Loss: 0.1088 Acc: 75.0000%\n",
      "\ttrain 34-226: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 34-227: Loss: 0.1176 Acc: 75.0000%\n",
      "\ttrain 34-228: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 34-229: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 34-230: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 34-231: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 34-232: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 34-233: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 34-234: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 34-235: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 34-236: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 34-237: Loss: 0.3960 Acc: 50.0000%\n",
      "\ttrain 34-238: Loss: 0.0520 Acc: 100.0000%\n",
      "\ttrain 34-239: Loss: 0.1853 Acc: 75.0000%\n",
      "\ttrain 34-240: Loss: 0.2558 Acc: 50.0000%\n",
      "\ttrain 34-241: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 34-242: Loss: 0.1509 Acc: 75.0000%\n",
      "\ttrain 34-243: Loss: 0.0137 Acc: 100.0000%\n",
      "\ttrain 34-244: Loss: 0.0369 Acc: 100.0000%\n",
      "\ttrain 34-245: Loss: 0.1003 Acc: 75.0000%\n",
      "\tvalidation 34-1: Loss: 0.0212 Acc: 100.0000%\n",
      "\tvalidation 34-2: Loss: 0.0372 Acc: 100.0000%\n",
      "\tvalidation 34-3: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 34-4: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-5: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 34-6: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-7: Loss: 0.0512 Acc: 100.0000%\n",
      "\tvalidation 34-8: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 34-9: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 34-10: Loss: 0.0099 Acc: 100.0000%\n",
      "\tvalidation 34-11: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 34-12: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 34-13: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 34-14: Loss: 0.0211 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 34-15: Loss: 0.0216 Acc: 100.0000%\n",
      "\tvalidation 34-16: Loss: 0.0593 Acc: 75.0000%\n",
      "\tvalidation 34-17: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 34-18: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 34-19: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 34-20: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 34-21: Loss: 0.0138 Acc: 100.0000%\n",
      "\tvalidation 34-22: Loss: 0.0150 Acc: 100.0000%\n",
      "\tvalidation 34-23: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-24: Loss: 0.0250 Acc: 100.0000%\n",
      "\tvalidation 34-25: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-26: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 34-27: Loss: 0.0078 Acc: 100.0000%\n",
      "\tvalidation 34-28: Loss: 0.0088 Acc: 100.0000%\n",
      "\tvalidation 34-29: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 34-30: Loss: 0.0197 Acc: 100.0000%\n",
      "\tvalidation 34-31: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 34-32: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 34-33: Loss: 0.0188 Acc: 100.0000%\n",
      "\tvalidation 34-34: Loss: 0.0336 Acc: 100.0000%\n",
      "\tvalidation 34-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-36: Loss: 0.0166 Acc: 100.0000%\n",
      "\tvalidation 34-37: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 34-38: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 34-39: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 34-40: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 34-41: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 34-42: Loss: 0.0174 Acc: 100.0000%\n",
      "\tvalidation 34-43: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 34-44: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 34-45: Loss: 0.0112 Acc: 100.0000%\n",
      "\tvalidation 34-46: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 34-47: Loss: 0.0343 Acc: 100.0000%\n",
      "\tvalidation 34-48: Loss: 0.0090 Acc: 100.0000%\n",
      "\tvalidation 34-49: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 34-50: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 34-51: Loss: 0.0141 Acc: 100.0000%\n",
      "\tvalidation 34-52: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 34-53: Loss: 0.0247 Acc: 100.0000%\n",
      "\tvalidation 34-54: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-55: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 34-56: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 34-57: Loss: 0.0350 Acc: 100.0000%\n",
      "\tvalidation 34-58: Loss: 0.0157 Acc: 100.0000%\n",
      "\tvalidation 34-59: Loss: 0.0193 Acc: 100.0000%\n",
      "\tvalidation 34-60: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 34-61: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 34-62: Loss: 0.0329 Acc: 100.0000%\n",
      "\tvalidation 34-63: Loss: 0.0093 Acc: 100.0000%\n",
      "\tvalidation 34-64: Loss: 0.0062 Acc: 100.0000%\n",
      "\tvalidation 34-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-66: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 34-67: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 34-68: Loss: 0.0263 Acc: 100.0000%\n",
      "\tvalidation 34-69: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 34-70: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-71: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 34-72: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 34-73: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 34-74: Loss: 0.0275 Acc: 100.0000%\n",
      "\tvalidation 34-75: Loss: 0.0159 Acc: 100.0000%\n",
      "\tvalidation 34-76: Loss: 0.0418 Acc: 100.0000%\n",
      "\tvalidation 34-77: Loss: 0.0308 Acc: 100.0000%\n",
      "\tvalidation 34-78: Loss: 0.0130 Acc: 100.0000%\n",
      "\tvalidation 34-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 34-80: Loss: 0.0374 Acc: 100.0000%\n",
      "\tvalidation 34-81: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 34-82: Loss: 0.0143 Acc: 100.0000%\n",
      "\tvalidation 34-83: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 34-84: Loss: 0.0232 Acc: 100.0000%\n",
      "\tvalidation 34-85: Loss: 0.0172 Acc: 100.0000%\n",
      "\tvalidation 34-86: Loss: 0.0326 Acc: 100.0000%\n",
      "\tvalidation 34-87: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 34-88: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 34-89: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 34-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 34-91: Loss: 0.0211 Acc: 100.0000%\n",
      "\tvalidation 34-92: Loss: 0.0115 Acc: 100.0000%\n",
      "\tvalidation 34-93: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 34-94: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 34-95: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 34-96: Loss: 0.0065 Acc: 100.0000%\n",
      "\tvalidation 34-97: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 34-98: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 34-99: Loss: 0.0444 Acc: 100.0000%\n",
      "\tvalidation 34-100: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 34-101: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 34-102: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 34-103: Loss: 0.0148 Acc: 100.0000%\n",
      "\tvalidation 34-104: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 34-105: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0633 Acc: 91.5306%\n",
      "\tvalidation Loss: 0.0130 Acc: 99.7619%\n",
      "Time passed 0h 25m 56s\n",
      "--------------------\n",
      "Epoch [35/40]:\n",
      "\ttrain 35-1: Loss: 0.0967 Acc: 75.0000%\n",
      "\ttrain 35-2: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-4: Loss: 0.0295 Acc: 100.0000%\n",
      "\ttrain 35-5: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 35-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-7: Loss: 0.0997 Acc: 75.0000%\n",
      "\ttrain 35-8: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 35-9: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 35-10: Loss: 0.0670 Acc: 75.0000%\n",
      "\ttrain 35-11: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 35-12: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 35-13: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 35-14: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 35-15: Loss: 0.0627 Acc: 75.0000%\n",
      "\ttrain 35-16: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 35-17: Loss: 0.0214 Acc: 100.0000%\n",
      "\ttrain 35-18: Loss: 0.0860 Acc: 75.0000%\n",
      "\ttrain 35-19: Loss: 0.0483 Acc: 100.0000%\n",
      "\ttrain 35-20: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-21: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 35-22: Loss: 0.0208 Acc: 100.0000%\n",
      "\ttrain 35-23: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 35-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-25: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 35-26: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-27: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 35-28: Loss: 0.0161 Acc: 100.0000%\n",
      "\ttrain 35-29: Loss: 0.0199 Acc: 100.0000%\n",
      "\ttrain 35-30: Loss: 0.2612 Acc: 50.0000%\n",
      "\ttrain 35-31: Loss: 0.1974 Acc: 75.0000%\n",
      "\ttrain 35-32: Loss: 0.0330 Acc: 100.0000%\n",
      "\ttrain 35-33: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 35-34: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-35: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-36: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 35-37: Loss: 0.0914 Acc: 75.0000%\n",
      "\ttrain 35-38: Loss: 0.2049 Acc: 75.0000%\n",
      "\ttrain 35-39: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-40: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 35-41: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 35-42: Loss: 0.0699 Acc: 75.0000%\n",
      "\ttrain 35-43: Loss: 0.0519 Acc: 100.0000%\n",
      "\ttrain 35-44: Loss: 0.0133 Acc: 100.0000%\n",
      "\ttrain 35-45: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 35-46: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 35-47: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 35-48: Loss: 0.0047 Acc: 100.0000%\n",
      "\ttrain 35-49: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 35-50: Loss: 0.1258 Acc: 50.0000%\n",
      "\ttrain 35-51: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 35-52: Loss: 0.1165 Acc: 75.0000%\n",
      "\ttrain 35-53: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 35-54: Loss: 0.0735 Acc: 75.0000%\n",
      "\ttrain 35-55: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 35-56: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 35-57: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-58: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 35-59: Loss: 0.1276 Acc: 75.0000%\n",
      "\ttrain 35-60: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 35-61: Loss: 0.0360 Acc: 100.0000%\n",
      "\ttrain 35-62: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 35-63: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-64: Loss: 0.0573 Acc: 100.0000%\n",
      "\ttrain 35-65: Loss: 0.0695 Acc: 75.0000%\n",
      "\ttrain 35-66: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 35-67: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 35-68: Loss: 0.1364 Acc: 50.0000%\n",
      "\ttrain 35-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-70: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-71: Loss: 0.1589 Acc: 75.0000%\n",
      "\ttrain 35-72: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 35-73: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 35-74: Loss: 0.0535 Acc: 100.0000%\n",
      "\ttrain 35-75: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 35-76: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 35-77: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 35-78: Loss: 0.0662 Acc: 75.0000%\n",
      "\ttrain 35-79: Loss: 0.5765 Acc: 50.0000%\n",
      "\ttrain 35-80: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-81: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 35-82: Loss: 0.2684 Acc: 50.0000%\n",
      "\ttrain 35-83: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-84: Loss: 0.1409 Acc: 75.0000%\n",
      "\ttrain 35-85: Loss: 0.0187 Acc: 100.0000%\n",
      "\ttrain 35-86: Loss: 0.0384 Acc: 100.0000%\n",
      "\ttrain 35-87: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 35-88: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 35-89: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 35-90: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 35-91: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 35-92: Loss: 0.0224 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 35-93: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 35-94: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-95: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 35-96: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 35-97: Loss: 0.0628 Acc: 75.0000%\n",
      "\ttrain 35-98: Loss: 0.0237 Acc: 100.0000%\n",
      "\ttrain 35-99: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-100: Loss: 0.0852 Acc: 75.0000%\n",
      "\ttrain 35-101: Loss: 0.0377 Acc: 100.0000%\n",
      "\ttrain 35-102: Loss: 0.1484 Acc: 75.0000%\n",
      "\ttrain 35-103: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 35-104: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 35-105: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 35-106: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 35-107: Loss: 0.1565 Acc: 75.0000%\n",
      "\ttrain 35-108: Loss: 0.1154 Acc: 75.0000%\n",
      "\ttrain 35-109: Loss: 0.0242 Acc: 100.0000%\n",
      "\ttrain 35-110: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-111: Loss: 0.2864 Acc: 75.0000%\n",
      "\ttrain 35-112: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-113: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 35-114: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 35-115: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 35-116: Loss: 0.1352 Acc: 75.0000%\n",
      "\ttrain 35-117: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 35-118: Loss: 0.2013 Acc: 75.0000%\n",
      "\ttrain 35-119: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 35-120: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-121: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-122: Loss: 0.1475 Acc: 75.0000%\n",
      "\ttrain 35-123: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-124: Loss: 0.0348 Acc: 100.0000%\n",
      "\ttrain 35-125: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 35-126: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 35-127: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 35-128: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 35-129: Loss: 0.1189 Acc: 75.0000%\n",
      "\ttrain 35-130: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 35-131: Loss: 0.0577 Acc: 75.0000%\n",
      "\ttrain 35-132: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 35-133: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 35-134: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 35-135: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 35-136: Loss: 0.1032 Acc: 100.0000%\n",
      "\ttrain 35-137: Loss: 0.0413 Acc: 100.0000%\n",
      "\ttrain 35-138: Loss: 0.0044 Acc: 100.0000%\n",
      "\ttrain 35-139: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 35-140: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 35-141: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-142: Loss: 0.0125 Acc: 100.0000%\n",
      "\ttrain 35-143: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-144: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 35-145: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 35-146: Loss: 0.0501 Acc: 100.0000%\n",
      "\ttrain 35-147: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 35-148: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 35-149: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-150: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 35-151: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 35-152: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 35-153: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 35-154: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 35-155: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 35-156: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 35-157: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 35-158: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 35-159: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 35-160: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-161: Loss: 0.0456 Acc: 75.0000%\n",
      "\ttrain 35-162: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 35-163: Loss: 0.0158 Acc: 100.0000%\n",
      "\ttrain 35-164: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 35-165: Loss: 0.0268 Acc: 100.0000%\n",
      "\ttrain 35-166: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 35-167: Loss: 0.1766 Acc: 75.0000%\n",
      "\ttrain 35-168: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 35-169: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 35-170: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 35-171: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 35-172: Loss: 0.2831 Acc: 75.0000%\n",
      "\ttrain 35-173: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-174: Loss: 0.0548 Acc: 100.0000%\n",
      "\ttrain 35-175: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 35-176: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 35-177: Loss: 0.0618 Acc: 75.0000%\n",
      "\ttrain 35-178: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 35-179: Loss: 0.0447 Acc: 100.0000%\n",
      "\ttrain 35-180: Loss: 0.0424 Acc: 100.0000%\n",
      "\ttrain 35-181: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 35-182: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 35-183: Loss: 0.3388 Acc: 50.0000%\n",
      "\ttrain 35-184: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 35-185: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 35-186: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 35-187: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 35-188: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-189: Loss: 0.0946 Acc: 75.0000%\n",
      "\ttrain 35-190: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 35-191: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 35-192: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 35-193: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 35-194: Loss: 0.0542 Acc: 100.0000%\n",
      "\ttrain 35-195: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 35-196: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 35-197: Loss: 0.0376 Acc: 100.0000%\n",
      "\ttrain 35-198: Loss: 0.0736 Acc: 75.0000%\n",
      "\ttrain 35-199: Loss: 0.0198 Acc: 100.0000%\n",
      "\ttrain 35-200: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-201: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 35-202: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 35-203: Loss: 0.1192 Acc: 75.0000%\n",
      "\ttrain 35-204: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 35-205: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 35-206: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-207: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 35-208: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 35-209: Loss: 0.2589 Acc: 75.0000%\n",
      "\ttrain 35-210: Loss: 0.0549 Acc: 100.0000%\n",
      "\ttrain 35-211: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-212: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 35-213: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 35-214: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 35-215: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 35-216: Loss: 0.0557 Acc: 100.0000%\n",
      "\ttrain 35-217: Loss: 0.0340 Acc: 100.0000%\n",
      "\ttrain 35-218: Loss: 0.1874 Acc: 50.0000%\n",
      "\ttrain 35-219: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 35-220: Loss: 0.0269 Acc: 100.0000%\n",
      "\ttrain 35-221: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 35-222: Loss: 0.0211 Acc: 100.0000%\n",
      "\ttrain 35-223: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-224: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 35-225: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-226: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-227: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 35-228: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 35-229: Loss: 0.2347 Acc: 75.0000%\n",
      "\ttrain 35-230: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 35-231: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 35-232: Loss: 0.1315 Acc: 50.0000%\n",
      "\ttrain 35-233: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 35-234: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 35-235: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 35-236: Loss: 0.0400 Acc: 100.0000%\n",
      "\ttrain 35-237: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 35-238: Loss: 0.1597 Acc: 75.0000%\n",
      "\ttrain 35-239: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 35-240: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 35-241: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 35-242: Loss: 0.1794 Acc: 75.0000%\n",
      "\ttrain 35-243: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 35-244: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 35-245: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-1: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-2: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-3: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-4: Loss: 0.0340 Acc: 100.0000%\n",
      "\tvalidation 35-5: Loss: 0.0075 Acc: 100.0000%\n",
      "\tvalidation 35-6: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-7: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 35-8: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-9: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 35-10: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 35-11: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 35-12: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 35-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-14: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-15: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 35-16: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 35-17: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 35-18: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-19: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 35-20: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-21: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 35-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 35-23: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 35-24: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 35-25: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 35-26: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-27: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 35-28: Loss: 0.0945 Acc: 75.0000%\n",
      "\tvalidation 35-29: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-30: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-31: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 35-32: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 35-33: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-34: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 35-35: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 35-36: Loss: 0.0009 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 35-37: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 35-38: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-39: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 35-40: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-41: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-44: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-46: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-47: Loss: 0.0108 Acc: 100.0000%\n",
      "\tvalidation 35-48: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-49: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 35-50: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-51: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-52: Loss: 0.0067 Acc: 100.0000%\n",
      "\tvalidation 35-53: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 35-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-55: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-56: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 35-57: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-58: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-59: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 35-60: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 35-61: Loss: 0.0158 Acc: 100.0000%\n",
      "\tvalidation 35-62: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 35-63: Loss: 0.0039 Acc: 100.0000%\n",
      "\tvalidation 35-64: Loss: 0.0073 Acc: 100.0000%\n",
      "\tvalidation 35-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 35-67: Loss: 0.0119 Acc: 100.0000%\n",
      "\tvalidation 35-68: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-70: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 35-71: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 35-72: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 35-73: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-74: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-75: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 35-76: Loss: 0.0079 Acc: 100.0000%\n",
      "\tvalidation 35-77: Loss: 0.0140 Acc: 100.0000%\n",
      "\tvalidation 35-78: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 35-79: Loss: 0.0478 Acc: 100.0000%\n",
      "\tvalidation 35-80: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 35-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-82: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 35-83: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 35-84: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-85: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 35-86: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 35-87: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-88: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 35-89: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-90: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 35-91: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-92: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 35-93: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 35-94: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 35-95: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 35-96: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-97: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 35-98: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 35-99: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 35-100: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 35-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 35-102: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 35-103: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 35-104: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 35-105: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0411 Acc: 94.0816%\n",
      "\tvalidation Loss: 0.0050 Acc: 99.7619%\n",
      "Time passed 0h 26m 57s\n",
      "--------------------\n",
      "Epoch [36/40]:\n",
      "\ttrain 36-1: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 36-2: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 36-3: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-4: Loss: 0.0515 Acc: 75.0000%\n",
      "\ttrain 36-5: Loss: 0.1972 Acc: 75.0000%\n",
      "\ttrain 36-6: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 36-7: Loss: 0.1076 Acc: 75.0000%\n",
      "\ttrain 36-8: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-9: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-10: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-11: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 36-12: Loss: 0.0660 Acc: 75.0000%\n",
      "\ttrain 36-13: Loss: 0.0479 Acc: 100.0000%\n",
      "\ttrain 36-14: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 36-15: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-16: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-17: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 36-18: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-19: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 36-20: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 36-21: Loss: 0.0192 Acc: 100.0000%\n",
      "\ttrain 36-22: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-23: Loss: 0.0500 Acc: 100.0000%\n",
      "\ttrain 36-24: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 36-25: Loss: 0.0721 Acc: 100.0000%\n",
      "\ttrain 36-26: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-27: Loss: 0.0391 Acc: 100.0000%\n",
      "\ttrain 36-28: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 36-29: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 36-30: Loss: 0.0639 Acc: 100.0000%\n",
      "\ttrain 36-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-32: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 36-33: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-34: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-35: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-36: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 36-37: Loss: 0.0202 Acc: 100.0000%\n",
      "\ttrain 36-38: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 36-39: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 36-40: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 36-41: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-42: Loss: 0.0112 Acc: 100.0000%\n",
      "\ttrain 36-43: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-44: Loss: 0.0263 Acc: 100.0000%\n",
      "\ttrain 36-45: Loss: 0.0784 Acc: 75.0000%\n",
      "\ttrain 36-46: Loss: 0.0636 Acc: 75.0000%\n",
      "\ttrain 36-47: Loss: 0.1248 Acc: 75.0000%\n",
      "\ttrain 36-48: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 36-49: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 36-50: Loss: 0.0485 Acc: 75.0000%\n",
      "\ttrain 36-51: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 36-52: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 36-53: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 36-54: Loss: 0.2890 Acc: 50.0000%\n",
      "\ttrain 36-55: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-56: Loss: 0.0693 Acc: 75.0000%\n",
      "\ttrain 36-57: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 36-58: Loss: 0.0795 Acc: 75.0000%\n",
      "\ttrain 36-59: Loss: 0.0232 Acc: 100.0000%\n",
      "\ttrain 36-60: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 36-61: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-62: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-63: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 36-64: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 36-65: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 36-66: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 36-67: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 36-68: Loss: 0.0245 Acc: 100.0000%\n",
      "\ttrain 36-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-70: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-71: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 36-72: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 36-73: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 36-74: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 36-75: Loss: 0.3652 Acc: 50.0000%\n",
      "\ttrain 36-76: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 36-77: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 36-78: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 36-79: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 36-80: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 36-81: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-82: Loss: 0.0476 Acc: 100.0000%\n",
      "\ttrain 36-83: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 36-84: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 36-85: Loss: 0.0244 Acc: 100.0000%\n",
      "\ttrain 36-86: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 36-87: Loss: 0.0415 Acc: 100.0000%\n",
      "\ttrain 36-88: Loss: 0.2135 Acc: 75.0000%\n",
      "\ttrain 36-89: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 36-90: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 36-91: Loss: 0.0149 Acc: 100.0000%\n",
      "\ttrain 36-92: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 36-93: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 36-94: Loss: 0.7337 Acc: 50.0000%\n",
      "\ttrain 36-95: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 36-96: Loss: 0.1997 Acc: 75.0000%\n",
      "\ttrain 36-97: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 36-98: Loss: 0.2188 Acc: 75.0000%\n",
      "\ttrain 36-99: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-100: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 36-101: Loss: 0.1919 Acc: 50.0000%\n",
      "\ttrain 36-102: Loss: 0.0977 Acc: 75.0000%\n",
      "\ttrain 36-103: Loss: 0.0768 Acc: 75.0000%\n",
      "\ttrain 36-104: Loss: 0.0051 Acc: 100.0000%\n",
      "\ttrain 36-105: Loss: 0.0371 Acc: 100.0000%\n",
      "\ttrain 36-106: Loss: 0.0873 Acc: 100.0000%\n",
      "\ttrain 36-107: Loss: 0.2503 Acc: 50.0000%\n",
      "\ttrain 36-108: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 36-109: Loss: 0.0731 Acc: 75.0000%\n",
      "\ttrain 36-110: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 36-111: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 36-112: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 36-113: Loss: 0.0530 Acc: 100.0000%\n",
      "\ttrain 36-114: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 36-115: Loss: 0.0466 Acc: 100.0000%\n",
      "\ttrain 36-116: Loss: 0.0277 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 36-117: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 36-118: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-119: Loss: 0.1363 Acc: 75.0000%\n",
      "\ttrain 36-120: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-121: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 36-122: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 36-123: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 36-124: Loss: 0.0986 Acc: 75.0000%\n",
      "\ttrain 36-125: Loss: 0.3686 Acc: 75.0000%\n",
      "\ttrain 36-126: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 36-127: Loss: 0.0522 Acc: 100.0000%\n",
      "\ttrain 36-128: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 36-129: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 36-130: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 36-131: Loss: 0.0560 Acc: 75.0000%\n",
      "\ttrain 36-132: Loss: 0.0464 Acc: 100.0000%\n",
      "\ttrain 36-133: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-134: Loss: 0.0368 Acc: 100.0000%\n",
      "\ttrain 36-135: Loss: 0.0559 Acc: 100.0000%\n",
      "\ttrain 36-136: Loss: 0.0395 Acc: 100.0000%\n",
      "\ttrain 36-137: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 36-138: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 36-139: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 36-140: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 36-141: Loss: 0.1027 Acc: 75.0000%\n",
      "\ttrain 36-142: Loss: 0.0637 Acc: 100.0000%\n",
      "\ttrain 36-143: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 36-144: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 36-145: Loss: 0.0706 Acc: 75.0000%\n",
      "\ttrain 36-146: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-147: Loss: 0.0194 Acc: 100.0000%\n",
      "\ttrain 36-148: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 36-149: Loss: 0.2931 Acc: 75.0000%\n",
      "\ttrain 36-150: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 36-151: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 36-152: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 36-153: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-154: Loss: 0.0626 Acc: 75.0000%\n",
      "\ttrain 36-155: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-156: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 36-157: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 36-158: Loss: 0.0417 Acc: 100.0000%\n",
      "\ttrain 36-159: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 36-160: Loss: 0.0092 Acc: 100.0000%\n",
      "\ttrain 36-161: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 36-162: Loss: 0.0425 Acc: 100.0000%\n",
      "\ttrain 36-163: Loss: 0.0595 Acc: 75.0000%\n",
      "\ttrain 36-164: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 36-165: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 36-166: Loss: 0.0173 Acc: 100.0000%\n",
      "\ttrain 36-167: Loss: 0.0778 Acc: 75.0000%\n",
      "\ttrain 36-168: Loss: 0.0437 Acc: 100.0000%\n",
      "\ttrain 36-169: Loss: 0.0747 Acc: 75.0000%\n",
      "\ttrain 36-170: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-171: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 36-172: Loss: 0.1633 Acc: 75.0000%\n",
      "\ttrain 36-173: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 36-174: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 36-175: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 36-176: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 36-177: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 36-178: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 36-179: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 36-180: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-181: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 36-182: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 36-183: Loss: 0.3618 Acc: 75.0000%\n",
      "\ttrain 36-184: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-185: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 36-186: Loss: 0.0336 Acc: 100.0000%\n",
      "\ttrain 36-187: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 36-188: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 36-189: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-190: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 36-191: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 36-192: Loss: 0.1103 Acc: 75.0000%\n",
      "\ttrain 36-193: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 36-194: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 36-195: Loss: 0.0058 Acc: 100.0000%\n",
      "\ttrain 36-196: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 36-197: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 36-198: Loss: 0.0124 Acc: 100.0000%\n",
      "\ttrain 36-199: Loss: 0.0248 Acc: 100.0000%\n",
      "\ttrain 36-200: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 36-201: Loss: 0.0131 Acc: 100.0000%\n",
      "\ttrain 36-202: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-203: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 36-204: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 36-205: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 36-206: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 36-207: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 36-208: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 36-209: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 36-210: Loss: 0.0968 Acc: 75.0000%\n",
      "\ttrain 36-211: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 36-212: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 36-213: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 36-214: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 36-215: Loss: 0.0457 Acc: 100.0000%\n",
      "\ttrain 36-216: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 36-217: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 36-218: Loss: 0.0160 Acc: 100.0000%\n",
      "\ttrain 36-219: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 36-220: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 36-221: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 36-222: Loss: 0.0061 Acc: 100.0000%\n",
      "\ttrain 36-223: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 36-224: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 36-225: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 36-226: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 36-227: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 36-228: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 36-229: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-231: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 36-232: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 36-233: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 36-234: Loss: 0.0409 Acc: 100.0000%\n",
      "\ttrain 36-235: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 36-236: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 36-237: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 36-238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-239: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 36-240: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 36-241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 36-242: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 36-243: Loss: 0.1996 Acc: 50.0000%\n",
      "\ttrain 36-244: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 36-245: Loss: 0.1588 Acc: 75.0000%\n",
      "\tvalidation 36-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-5: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-6: Loss: 0.3892 Acc: 75.0000%\n",
      "\tvalidation 36-7: Loss: 0.1018 Acc: 75.0000%\n",
      "\tvalidation 36-8: Loss: 0.0483 Acc: 75.0000%\n",
      "\tvalidation 36-9: Loss: 0.2672 Acc: 75.0000%\n",
      "\tvalidation 36-10: Loss: 0.3365 Acc: 75.0000%\n",
      "\tvalidation 36-11: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-12: Loss: 0.2022 Acc: 75.0000%\n",
      "\tvalidation 36-13: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-14: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-15: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 36-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-17: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 36-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-19: Loss: 0.2819 Acc: 75.0000%\n",
      "\tvalidation 36-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-22: Loss: 0.0697 Acc: 75.0000%\n",
      "\tvalidation 36-23: Loss: 0.3483 Acc: 75.0000%\n",
      "\tvalidation 36-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-25: Loss: 0.1281 Acc: 75.0000%\n",
      "\tvalidation 36-26: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-27: Loss: 0.2012 Acc: 75.0000%\n",
      "\tvalidation 36-28: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 36-29: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-30: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 36-32: Loss: 0.1825 Acc: 75.0000%\n",
      "\tvalidation 36-33: Loss: 0.4085 Acc: 75.0000%\n",
      "\tvalidation 36-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-35: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 36-36: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 36-37: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-38: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-40: Loss: 0.1422 Acc: 75.0000%\n",
      "\tvalidation 36-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-42: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-45: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-46: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 36-47: Loss: 0.0318 Acc: 100.0000%\n",
      "\tvalidation 36-48: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-49: Loss: 0.0142 Acc: 100.0000%\n",
      "\tvalidation 36-50: Loss: 0.0421 Acc: 100.0000%\n",
      "\tvalidation 36-51: Loss: 0.0203 Acc: 100.0000%\n",
      "\tvalidation 36-52: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 36-53: Loss: 0.0107 Acc: 100.0000%\n",
      "\tvalidation 36-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-55: Loss: 0.0081 Acc: 100.0000%\n",
      "\tvalidation 36-56: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 36-57: Loss: 0.4357 Acc: 50.0000%\n",
      "\tvalidation 36-58: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 36-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-61: Loss: 0.5463 Acc: 25.0000%\n",
      "\tvalidation 36-62: Loss: 0.0463 Acc: 75.0000%\n",
      "\tvalidation 36-63: Loss: 0.0908 Acc: 75.0000%\n",
      "\tvalidation 36-64: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-65: Loss: 0.2815 Acc: 75.0000%\n",
      "\tvalidation 36-66: Loss: 0.3305 Acc: 75.0000%\n",
      "\tvalidation 36-67: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 36-68: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 36-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-70: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 36-72: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-73: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-76: Loss: 0.0399 Acc: 100.0000%\n",
      "\tvalidation 36-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-79: Loss: 0.1619 Acc: 75.0000%\n",
      "\tvalidation 36-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-81: Loss: 0.1767 Acc: 75.0000%\n",
      "\tvalidation 36-82: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-85: Loss: 0.0613 Acc: 75.0000%\n",
      "\tvalidation 36-86: Loss: 0.1219 Acc: 75.0000%\n",
      "\tvalidation 36-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-89: Loss: 0.1968 Acc: 75.0000%\n",
      "\tvalidation 36-90: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-91: Loss: 0.0210 Acc: 100.0000%\n",
      "\tvalidation 36-92: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-93: Loss: 0.4891 Acc: 50.0000%\n",
      "\tvalidation 36-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 36-95: Loss: 0.1057 Acc: 75.0000%\n",
      "\tvalidation 36-96: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 36-97: Loss: 0.2307 Acc: 75.0000%\n",
      "\tvalidation 36-98: Loss: 0.4193 Acc: 75.0000%\n",
      "\tvalidation 36-99: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 36-100: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 36-101: Loss: 0.0086 Acc: 100.0000%\n",
      "\tvalidation 36-102: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 36-103: Loss: 0.1122 Acc: 75.0000%\n",
      "\tvalidation 36-104: Loss: 0.3743 Acc: 75.0000%\n",
      "\tvalidation 36-105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0387 Acc: 95.0000%\n",
      "\tvalidation Loss: 0.0717 Acc: 91.6667%\n",
      "Time passed 0h 27m 57s\n",
      "--------------------\n",
      "Epoch [37/40]:\n",
      "\ttrain 37-1: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 37-2: Loss: 0.1801 Acc: 75.0000%\n",
      "\ttrain 37-3: Loss: 0.4198 Acc: 50.0000%\n",
      "\ttrain 37-4: Loss: 0.0697 Acc: 75.0000%\n",
      "\ttrain 37-5: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 37-6: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 37-7: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 37-8: Loss: 0.4437 Acc: 50.0000%\n",
      "\ttrain 37-9: Loss: 0.3653 Acc: 50.0000%\n",
      "\ttrain 37-10: Loss: 0.1580 Acc: 75.0000%\n",
      "\ttrain 37-11: Loss: 0.0318 Acc: 100.0000%\n",
      "\ttrain 37-12: Loss: 0.1396 Acc: 75.0000%\n",
      "\ttrain 37-13: Loss: 0.0582 Acc: 75.0000%\n",
      "\ttrain 37-14: Loss: 0.0181 Acc: 100.0000%\n",
      "\ttrain 37-15: Loss: 0.0812 Acc: 75.0000%\n",
      "\ttrain 37-16: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 37-17: Loss: 0.2137 Acc: 50.0000%\n",
      "\ttrain 37-18: Loss: 0.0243 Acc: 100.0000%\n",
      "\ttrain 37-19: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 37-20: Loss: 0.0442 Acc: 100.0000%\n",
      "\ttrain 37-21: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 37-22: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 37-23: Loss: 0.1095 Acc: 75.0000%\n",
      "\ttrain 37-24: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 37-25: Loss: 0.0509 Acc: 75.0000%\n",
      "\ttrain 37-26: Loss: 0.2617 Acc: 75.0000%\n",
      "\ttrain 37-27: Loss: 0.0151 Acc: 100.0000%\n",
      "\ttrain 37-28: Loss: 0.4045 Acc: 75.0000%\n",
      "\ttrain 37-29: Loss: 0.0919 Acc: 75.0000%\n",
      "\ttrain 37-30: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 37-31: Loss: 0.2043 Acc: 75.0000%\n",
      "\ttrain 37-32: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 37-33: Loss: 0.3999 Acc: 50.0000%\n",
      "\ttrain 37-34: Loss: 0.0306 Acc: 100.0000%\n",
      "\ttrain 37-35: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-36: Loss: 0.0690 Acc: 100.0000%\n",
      "\ttrain 37-37: Loss: 0.0074 Acc: 100.0000%\n",
      "\ttrain 37-38: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-39: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 37-40: Loss: 0.0969 Acc: 75.0000%\n",
      "\ttrain 37-41: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 37-42: Loss: 0.0462 Acc: 100.0000%\n",
      "\ttrain 37-43: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 37-44: Loss: 0.0979 Acc: 75.0000%\n",
      "\ttrain 37-45: Loss: 0.2446 Acc: 75.0000%\n",
      "\ttrain 37-46: Loss: 0.0904 Acc: 75.0000%\n",
      "\ttrain 37-47: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 37-48: Loss: 0.0168 Acc: 100.0000%\n",
      "\ttrain 37-49: Loss: 0.0402 Acc: 100.0000%\n",
      "\ttrain 37-50: Loss: 0.0397 Acc: 100.0000%\n",
      "\ttrain 37-51: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 37-52: Loss: 0.0351 Acc: 100.0000%\n",
      "\ttrain 37-53: Loss: 0.1568 Acc: 75.0000%\n",
      "\ttrain 37-54: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 37-55: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 37-56: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 37-57: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 37-58: Loss: 0.0287 Acc: 100.0000%\n",
      "\ttrain 37-59: Loss: 0.0300 Acc: 100.0000%\n",
      "\ttrain 37-60: Loss: 0.0571 Acc: 100.0000%\n",
      "\ttrain 37-61: Loss: 0.1366 Acc: 75.0000%\n",
      "\ttrain 37-62: Loss: 0.0346 Acc: 100.0000%\n",
      "\ttrain 37-63: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 37-64: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 37-65: Loss: 0.0165 Acc: 100.0000%\n",
      "\ttrain 37-66: Loss: 0.1716 Acc: 75.0000%\n",
      "\ttrain 37-67: Loss: 0.1083 Acc: 75.0000%\n",
      "\ttrain 37-68: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-69: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 37-70: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 37-71: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 37-72: Loss: 0.1963 Acc: 50.0000%\n",
      "\ttrain 37-73: Loss: 0.1790 Acc: 75.0000%\n",
      "\ttrain 37-74: Loss: 0.0954 Acc: 75.0000%\n",
      "\ttrain 37-75: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 37-76: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 37-77: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 37-78: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 37-79: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-80: Loss: 0.2386 Acc: 50.0000%\n",
      "\ttrain 37-81: Loss: 0.0154 Acc: 100.0000%\n",
      "\ttrain 37-82: Loss: 0.1509 Acc: 50.0000%\n",
      "\ttrain 37-83: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-84: Loss: 0.1136 Acc: 75.0000%\n",
      "\ttrain 37-85: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 37-86: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 37-87: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-88: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 37-89: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-90: Loss: 0.0867 Acc: 75.0000%\n",
      "\ttrain 37-91: Loss: 0.0827 Acc: 100.0000%\n",
      "\ttrain 37-92: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 37-93: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 37-94: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 37-95: Loss: 0.0418 Acc: 100.0000%\n",
      "\ttrain 37-96: Loss: 0.0185 Acc: 100.0000%\n",
      "\ttrain 37-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-98: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-99: Loss: 0.0665 Acc: 100.0000%\n",
      "\ttrain 37-100: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 37-101: Loss: 0.1314 Acc: 75.0000%\n",
      "\ttrain 37-102: Loss: 0.0136 Acc: 100.0000%\n",
      "\ttrain 37-103: Loss: 0.0309 Acc: 100.0000%\n",
      "\ttrain 37-104: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 37-105: Loss: 0.3860 Acc: 50.0000%\n",
      "\ttrain 37-106: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 37-107: Loss: 0.0293 Acc: 100.0000%\n",
      "\ttrain 37-108: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-109: Loss: 0.0186 Acc: 100.0000%\n",
      "\ttrain 37-110: Loss: 0.0576 Acc: 100.0000%\n",
      "\ttrain 37-111: Loss: 0.0538 Acc: 75.0000%\n",
      "\ttrain 37-112: Loss: 0.0179 Acc: 100.0000%\n",
      "\ttrain 37-113: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 37-114: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-115: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-116: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 37-117: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 37-118: Loss: 0.0729 Acc: 75.0000%\n",
      "\ttrain 37-119: Loss: 0.0712 Acc: 100.0000%\n",
      "\ttrain 37-120: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 37-121: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 37-122: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-123: Loss: 0.0205 Acc: 100.0000%\n",
      "\ttrain 37-124: Loss: 0.1217 Acc: 75.0000%\n",
      "\ttrain 37-125: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-126: Loss: 0.0174 Acc: 100.0000%\n",
      "\ttrain 37-127: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 37-128: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 37-129: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 37-130: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-131: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 37-132: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 37-133: Loss: 0.0261 Acc: 100.0000%\n",
      "\ttrain 37-134: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 37-135: Loss: 0.1921 Acc: 50.0000%\n",
      "\ttrain 37-136: Loss: 0.0083 Acc: 100.0000%\n",
      "\ttrain 37-137: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 37-138: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 37-139: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 37-140: Loss: 0.0067 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 37-141: Loss: 0.0696 Acc: 75.0000%\n",
      "\ttrain 37-142: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 37-143: Loss: 0.1740 Acc: 75.0000%\n",
      "\ttrain 37-144: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-145: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 37-146: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 37-147: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-148: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-149: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 37-150: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 37-151: Loss: 0.1573 Acc: 75.0000%\n",
      "\ttrain 37-152: Loss: 0.0487 Acc: 75.0000%\n",
      "\ttrain 37-153: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 37-154: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 37-155: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 37-156: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-157: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-158: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 37-159: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 37-160: Loss: 0.0143 Acc: 100.0000%\n",
      "\ttrain 37-161: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-162: Loss: 0.2727 Acc: 75.0000%\n",
      "\ttrain 37-163: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 37-164: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 37-165: Loss: 0.0252 Acc: 100.0000%\n",
      "\ttrain 37-166: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-167: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 37-168: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 37-169: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-170: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 37-171: Loss: 0.0285 Acc: 100.0000%\n",
      "\ttrain 37-172: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 37-173: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 37-174: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 37-175: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 37-176: Loss: 0.1563 Acc: 75.0000%\n",
      "\ttrain 37-177: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 37-178: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 37-179: Loss: 0.0355 Acc: 100.0000%\n",
      "\ttrain 37-180: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 37-181: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-182: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-183: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 37-184: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 37-185: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 37-186: Loss: 0.0175 Acc: 100.0000%\n",
      "\ttrain 37-187: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 37-188: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 37-189: Loss: 0.0826 Acc: 75.0000%\n",
      "\ttrain 37-190: Loss: 0.2008 Acc: 75.0000%\n",
      "\ttrain 37-191: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-192: Loss: 0.0502 Acc: 75.0000%\n",
      "\ttrain 37-193: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 37-194: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 37-195: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 37-196: Loss: 0.0734 Acc: 75.0000%\n",
      "\ttrain 37-197: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 37-198: Loss: 0.1667 Acc: 75.0000%\n",
      "\ttrain 37-199: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 37-200: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 37-201: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-202: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 37-203: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 37-204: Loss: 0.0484 Acc: 100.0000%\n",
      "\ttrain 37-205: Loss: 0.1706 Acc: 75.0000%\n",
      "\ttrain 37-206: Loss: 0.1491 Acc: 75.0000%\n",
      "\ttrain 37-207: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 37-208: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 37-209: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 37-210: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 37-211: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 37-212: Loss: 0.0332 Acc: 100.0000%\n",
      "\ttrain 37-213: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 37-214: Loss: 0.0617 Acc: 75.0000%\n",
      "\ttrain 37-215: Loss: 0.0251 Acc: 100.0000%\n",
      "\ttrain 37-216: Loss: 0.0177 Acc: 100.0000%\n",
      "\ttrain 37-217: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 37-218: Loss: 0.1166 Acc: 75.0000%\n",
      "\ttrain 37-219: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-220: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 37-221: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 37-222: Loss: 0.0571 Acc: 75.0000%\n",
      "\ttrain 37-223: Loss: 0.0349 Acc: 100.0000%\n",
      "\ttrain 37-224: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 37-225: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-226: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 37-227: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 37-228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 37-229: Loss: 0.2028 Acc: 75.0000%\n",
      "\ttrain 37-230: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 37-231: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 37-232: Loss: 0.1704 Acc: 75.0000%\n",
      "\ttrain 37-233: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 37-234: Loss: 0.0517 Acc: 100.0000%\n",
      "\ttrain 37-235: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 37-236: Loss: 0.0119 Acc: 100.0000%\n",
      "\ttrain 37-237: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 37-238: Loss: 0.1150 Acc: 75.0000%\n",
      "\ttrain 37-239: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 37-240: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 37-241: Loss: 0.2610 Acc: 75.0000%\n",
      "\ttrain 37-242: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 37-243: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 37-244: Loss: 0.0620 Acc: 100.0000%\n",
      "\ttrain 37-245: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-1: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 37-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-3: Loss: 0.0470 Acc: 75.0000%\n",
      "\tvalidation 37-4: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-5: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-6: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 37-7: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 37-8: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 37-9: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 37-10: Loss: 0.0072 Acc: 100.0000%\n",
      "\tvalidation 37-11: Loss: 0.0474 Acc: 100.0000%\n",
      "\tvalidation 37-12: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-13: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-14: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 37-15: Loss: 0.0457 Acc: 75.0000%\n",
      "\tvalidation 37-16: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-17: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-18: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 37-19: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-20: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 37-21: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-22: Loss: 0.0185 Acc: 100.0000%\n",
      "\tvalidation 37-23: Loss: 0.0101 Acc: 100.0000%\n",
      "\tvalidation 37-24: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 37-25: Loss: 0.0409 Acc: 100.0000%\n",
      "\tvalidation 37-26: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 37-27: Loss: 0.0214 Acc: 100.0000%\n",
      "\tvalidation 37-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-29: Loss: 0.1121 Acc: 75.0000%\n",
      "\tvalidation 37-30: Loss: 0.0802 Acc: 75.0000%\n",
      "\tvalidation 37-31: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 37-32: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 37-33: Loss: 0.0155 Acc: 100.0000%\n",
      "\tvalidation 37-34: Loss: 0.0220 Acc: 100.0000%\n",
      "\tvalidation 37-35: Loss: 0.0125 Acc: 100.0000%\n",
      "\tvalidation 37-36: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 37-37: Loss: 0.0060 Acc: 100.0000%\n",
      "\tvalidation 37-38: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 37-39: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 37-40: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 37-41: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 37-42: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-43: Loss: 0.0291 Acc: 100.0000%\n",
      "\tvalidation 37-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-45: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 37-46: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-47: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-48: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 37-49: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 37-50: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 37-51: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 37-52: Loss: 0.0095 Acc: 100.0000%\n",
      "\tvalidation 37-53: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 37-54: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 37-55: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-56: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 37-57: Loss: 0.0281 Acc: 100.0000%\n",
      "\tvalidation 37-58: Loss: 0.0084 Acc: 100.0000%\n",
      "\tvalidation 37-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-61: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 37-62: Loss: 0.0362 Acc: 100.0000%\n",
      "\tvalidation 37-63: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 37-64: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-68: Loss: 0.0087 Acc: 100.0000%\n",
      "\tvalidation 37-69: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 37-70: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 37-71: Loss: 0.0417 Acc: 100.0000%\n",
      "\tvalidation 37-72: Loss: 0.0109 Acc: 100.0000%\n",
      "\tvalidation 37-73: Loss: 0.0437 Acc: 100.0000%\n",
      "\tvalidation 37-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-75: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 37-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-77: Loss: 0.0123 Acc: 100.0000%\n",
      "\tvalidation 37-78: Loss: 0.0659 Acc: 75.0000%\n",
      "\tvalidation 37-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-80: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 37-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 37-82: Loss: 0.0139 Acc: 100.0000%\n",
      "\tvalidation 37-83: Loss: 0.0320 Acc: 100.0000%\n",
      "\tvalidation 37-84: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-85: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 37-86: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 37-87: Loss: 0.0164 Acc: 100.0000%\n",
      "\tvalidation 37-88: Loss: 0.0083 Acc: 100.0000%\n",
      "\tvalidation 37-89: Loss: 0.0191 Acc: 100.0000%\n",
      "\tvalidation 37-90: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-91: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 37-92: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 37-93: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 37-94: Loss: 0.0291 Acc: 100.0000%\n",
      "\tvalidation 37-95: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 37-96: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 37-97: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 37-98: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-99: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 37-100: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 37-101: Loss: 0.0385 Acc: 100.0000%\n",
      "\tvalidation 37-102: Loss: 0.0723 Acc: 75.0000%\n",
      "\tvalidation 37-103: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 37-104: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 37-105: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0506 Acc: 92.9592%\n",
      "\tvalidation Loss: 0.0119 Acc: 98.5714%\n",
      "Time passed 0h 28m 55s\n",
      "--------------------\n",
      "Epoch [38/40]:\n",
      "\ttrain 38-1: Loss: 0.1675 Acc: 75.0000%\n",
      "\ttrain 38-2: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 38-3: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 38-4: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 38-5: Loss: 0.0299 Acc: 100.0000%\n",
      "\ttrain 38-6: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-7: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 38-8: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 38-9: Loss: 0.0207 Acc: 100.0000%\n",
      "\ttrain 38-10: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 38-11: Loss: 0.0274 Acc: 100.0000%\n",
      "\ttrain 38-12: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 38-13: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-14: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 38-15: Loss: 0.0204 Acc: 100.0000%\n",
      "\ttrain 38-16: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 38-17: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-18: Loss: 0.0212 Acc: 100.0000%\n",
      "\ttrain 38-19: Loss: 0.0258 Acc: 100.0000%\n",
      "\ttrain 38-20: Loss: 0.1144 Acc: 75.0000%\n",
      "\ttrain 38-21: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-22: Loss: 0.1642 Acc: 75.0000%\n",
      "\ttrain 38-23: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 38-24: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-25: Loss: 0.2683 Acc: 75.0000%\n",
      "\ttrain 38-26: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 38-27: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-28: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 38-29: Loss: 0.1028 Acc: 75.0000%\n",
      "\ttrain 38-30: Loss: 0.0140 Acc: 100.0000%\n",
      "\ttrain 38-31: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 38-32: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 38-33: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 38-34: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 38-35: Loss: 0.0886 Acc: 75.0000%\n",
      "\ttrain 38-36: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-38: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 38-39: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 38-40: Loss: 0.0494 Acc: 100.0000%\n",
      "\ttrain 38-41: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 38-42: Loss: 0.0656 Acc: 100.0000%\n",
      "\ttrain 38-43: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-44: Loss: 0.1700 Acc: 75.0000%\n",
      "\ttrain 38-45: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-46: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-47: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-48: Loss: 0.0286 Acc: 100.0000%\n",
      "\ttrain 38-49: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-50: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 38-51: Loss: 0.0414 Acc: 100.0000%\n",
      "\ttrain 38-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-53: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-54: Loss: 0.1142 Acc: 75.0000%\n",
      "\ttrain 38-55: Loss: 0.0219 Acc: 100.0000%\n",
      "\ttrain 38-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-57: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 38-58: Loss: 0.0128 Acc: 100.0000%\n",
      "\ttrain 38-59: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-60: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-61: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-63: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-64: Loss: 0.0090 Acc: 100.0000%\n",
      "\ttrain 38-65: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-67: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-68: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-69: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-70: Loss: 0.0557 Acc: 75.0000%\n",
      "\ttrain 38-71: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-72: Loss: 0.0651 Acc: 75.0000%\n",
      "\ttrain 38-73: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 38-74: Loss: 0.0691 Acc: 75.0000%\n",
      "\ttrain 38-75: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 38-76: Loss: 0.0366 Acc: 100.0000%\n",
      "\ttrain 38-77: Loss: 0.5617 Acc: 50.0000%\n",
      "\ttrain 38-78: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-79: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-81: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 38-82: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 38-83: Loss: 0.0297 Acc: 100.0000%\n",
      "\ttrain 38-84: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 38-85: Loss: 0.0163 Acc: 100.0000%\n",
      "\ttrain 38-86: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 38-87: Loss: 0.0107 Acc: 100.0000%\n",
      "\ttrain 38-88: Loss: 0.0085 Acc: 100.0000%\n",
      "\ttrain 38-89: Loss: 0.1944 Acc: 75.0000%\n",
      "\ttrain 38-90: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 38-91: Loss: 0.0138 Acc: 100.0000%\n",
      "\ttrain 38-92: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 38-93: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-94: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 38-95: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-96: Loss: 0.2331 Acc: 75.0000%\n",
      "\ttrain 38-97: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 38-98: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-99: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 38-100: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-101: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 38-102: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 38-103: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 38-104: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 38-105: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-106: Loss: 0.0170 Acc: 100.0000%\n",
      "\ttrain 38-107: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 38-108: Loss: 0.0781 Acc: 75.0000%\n",
      "\ttrain 38-109: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-110: Loss: 0.0279 Acc: 100.0000%\n",
      "\ttrain 38-111: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-112: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 38-113: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 38-114: Loss: 0.0226 Acc: 100.0000%\n",
      "\ttrain 38-115: Loss: 0.0134 Acc: 100.0000%\n",
      "\ttrain 38-116: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 38-117: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-119: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 38-120: Loss: 0.0881 Acc: 75.0000%\n",
      "\ttrain 38-121: Loss: 0.0580 Acc: 75.0000%\n",
      "\ttrain 38-122: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 38-123: Loss: 0.0054 Acc: 100.0000%\n",
      "\ttrain 38-124: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 38-125: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-126: Loss: 0.0324 Acc: 100.0000%\n",
      "\ttrain 38-127: Loss: 0.0106 Acc: 100.0000%\n",
      "\ttrain 38-128: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 38-129: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-130: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 38-131: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 38-132: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-133: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-134: Loss: 0.0294 Acc: 100.0000%\n",
      "\ttrain 38-135: Loss: 0.0230 Acc: 100.0000%\n",
      "\ttrain 38-136: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 38-137: Loss: 0.0769 Acc: 75.0000%\n",
      "\ttrain 38-138: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-139: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 38-140: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 38-141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-143: Loss: 0.1137 Acc: 75.0000%\n",
      "\ttrain 38-144: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 38-145: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 38-146: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-147: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 38-148: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 38-149: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 38-150: Loss: 0.0766 Acc: 75.0000%\n",
      "\ttrain 38-151: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 38-152: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 38-153: Loss: 0.2827 Acc: 75.0000%\n",
      "\ttrain 38-154: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 38-155: Loss: 0.0319 Acc: 100.0000%\n",
      "\ttrain 38-156: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-157: Loss: 0.0307 Acc: 100.0000%\n",
      "\ttrain 38-158: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 38-159: Loss: 0.0120 Acc: 100.0000%\n",
      "\ttrain 38-160: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 38-161: Loss: 0.0228 Acc: 100.0000%\n",
      "\ttrain 38-162: Loss: 0.0080 Acc: 100.0000%\n",
      "\ttrain 38-163: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 38-164: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 38-165: Loss: 0.0522 Acc: 75.0000%\n",
      "\ttrain 38-166: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 38-167: Loss: 0.3977 Acc: 75.0000%\n",
      "\ttrain 38-168: Loss: 0.1262 Acc: 75.0000%\n",
      "\ttrain 38-169: Loss: 0.1840 Acc: 75.0000%\n",
      "\ttrain 38-170: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-171: Loss: 0.0030 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 38-172: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 38-173: Loss: 0.3374 Acc: 75.0000%\n",
      "\ttrain 38-174: Loss: 0.0449 Acc: 100.0000%\n",
      "\ttrain 38-175: Loss: 0.0585 Acc: 75.0000%\n",
      "\ttrain 38-176: Loss: 0.1669 Acc: 75.0000%\n",
      "\ttrain 38-177: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 38-178: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 38-179: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 38-180: Loss: 0.4552 Acc: 50.0000%\n",
      "\ttrain 38-181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-182: Loss: 0.1077 Acc: 75.0000%\n",
      "\ttrain 38-183: Loss: 0.0315 Acc: 100.0000%\n",
      "\ttrain 38-184: Loss: 0.0359 Acc: 100.0000%\n",
      "\ttrain 38-185: Loss: 0.1782 Acc: 75.0000%\n",
      "\ttrain 38-186: Loss: 0.0932 Acc: 75.0000%\n",
      "\ttrain 38-187: Loss: 0.0142 Acc: 100.0000%\n",
      "\ttrain 38-188: Loss: 0.1236 Acc: 75.0000%\n",
      "\ttrain 38-189: Loss: 0.2294 Acc: 75.0000%\n",
      "\ttrain 38-190: Loss: 0.1729 Acc: 50.0000%\n",
      "\ttrain 38-191: Loss: 0.0189 Acc: 100.0000%\n",
      "\ttrain 38-192: Loss: 0.1151 Acc: 75.0000%\n",
      "\ttrain 38-193: Loss: 0.0240 Acc: 100.0000%\n",
      "\ttrain 38-194: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 38-195: Loss: 0.1722 Acc: 75.0000%\n",
      "\ttrain 38-196: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 38-197: Loss: 0.1706 Acc: 75.0000%\n",
      "\ttrain 38-198: Loss: 0.0690 Acc: 75.0000%\n",
      "\ttrain 38-199: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 38-200: Loss: 0.0727 Acc: 75.0000%\n",
      "\ttrain 38-201: Loss: 0.0386 Acc: 100.0000%\n",
      "\ttrain 38-202: Loss: 0.0406 Acc: 100.0000%\n",
      "\ttrain 38-203: Loss: 0.0222 Acc: 100.0000%\n",
      "\ttrain 38-204: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 38-205: Loss: 0.0322 Acc: 100.0000%\n",
      "\ttrain 38-206: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 38-207: Loss: 0.0329 Acc: 100.0000%\n",
      "\ttrain 38-208: Loss: 0.0066 Acc: 100.0000%\n",
      "\ttrain 38-209: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 38-210: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 38-211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-212: Loss: 0.0183 Acc: 100.0000%\n",
      "\ttrain 38-213: Loss: 0.0613 Acc: 75.0000%\n",
      "\ttrain 38-214: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 38-215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 38-216: Loss: 0.2049 Acc: 75.0000%\n",
      "\ttrain 38-217: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 38-218: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 38-219: Loss: 0.0739 Acc: 75.0000%\n",
      "\ttrain 38-220: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 38-221: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 38-222: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 38-223: Loss: 0.0100 Acc: 100.0000%\n",
      "\ttrain 38-224: Loss: 0.0331 Acc: 100.0000%\n",
      "\ttrain 38-225: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 38-226: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 38-227: Loss: 0.0195 Acc: 100.0000%\n",
      "\ttrain 38-228: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 38-229: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 38-230: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 38-231: Loss: 0.0057 Acc: 100.0000%\n",
      "\ttrain 38-232: Loss: 0.0858 Acc: 75.0000%\n",
      "\ttrain 38-233: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 38-234: Loss: 0.0908 Acc: 75.0000%\n",
      "\ttrain 38-235: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 38-236: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 38-237: Loss: 0.0088 Acc: 100.0000%\n",
      "\ttrain 38-238: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 38-239: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 38-240: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 38-241: Loss: 0.0313 Acc: 100.0000%\n",
      "\ttrain 38-242: Loss: 0.0320 Acc: 100.0000%\n",
      "\ttrain 38-243: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 38-244: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 38-245: Loss: 0.0110 Acc: 100.0000%\n",
      "\tvalidation 38-1: Loss: 0.0061 Acc: 100.0000%\n",
      "\tvalidation 38-2: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-3: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-4: Loss: 0.1412 Acc: 75.0000%\n",
      "\tvalidation 38-5: Loss: 0.0100 Acc: 100.0000%\n",
      "\tvalidation 38-6: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-7: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 38-8: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-9: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-10: Loss: 0.0124 Acc: 100.0000%\n",
      "\tvalidation 38-11: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-12: Loss: 0.0085 Acc: 100.0000%\n",
      "\tvalidation 38-13: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 38-14: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-15: Loss: 0.0154 Acc: 100.0000%\n",
      "\tvalidation 38-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-17: Loss: 0.0606 Acc: 75.0000%\n",
      "\tvalidation 38-18: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-19: Loss: 0.1180 Acc: 75.0000%\n",
      "\tvalidation 38-20: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-21: Loss: 0.0435 Acc: 100.0000%\n",
      "\tvalidation 38-22: Loss: 0.0656 Acc: 100.0000%\n",
      "\tvalidation 38-23: Loss: 0.0441 Acc: 100.0000%\n",
      "\tvalidation 38-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-25: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 38-26: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-27: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-28: Loss: 0.0853 Acc: 75.0000%\n",
      "\tvalidation 38-29: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 38-30: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 38-31: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 38-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 38-33: Loss: 0.0322 Acc: 100.0000%\n",
      "\tvalidation 38-34: Loss: 0.0053 Acc: 100.0000%\n",
      "\tvalidation 38-35: Loss: 0.0098 Acc: 100.0000%\n",
      "\tvalidation 38-36: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-37: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-38: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 38-39: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-40: Loss: 0.0443 Acc: 100.0000%\n",
      "\tvalidation 38-41: Loss: 0.0074 Acc: 100.0000%\n",
      "\tvalidation 38-42: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 38-43: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-44: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 38-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-46: Loss: 0.0513 Acc: 75.0000%\n",
      "\tvalidation 38-47: Loss: 0.0045 Acc: 100.0000%\n",
      "\tvalidation 38-48: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 38-49: Loss: 0.0168 Acc: 100.0000%\n",
      "\tvalidation 38-50: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 38-51: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-52: Loss: 0.0772 Acc: 75.0000%\n",
      "\tvalidation 38-53: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 38-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-55: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 38-56: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 38-57: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 38-58: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 38-59: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-60: Loss: 0.1228 Acc: 75.0000%\n",
      "\tvalidation 38-61: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 38-62: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 38-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-64: Loss: 0.0381 Acc: 100.0000%\n",
      "\tvalidation 38-65: Loss: 0.0118 Acc: 100.0000%\n",
      "\tvalidation 38-66: Loss: 0.0376 Acc: 100.0000%\n",
      "\tvalidation 38-67: Loss: 0.0186 Acc: 100.0000%\n",
      "\tvalidation 38-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-69: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 38-70: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 38-71: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 38-72: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 38-73: Loss: 0.0151 Acc: 100.0000%\n",
      "\tvalidation 38-74: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 38-75: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 38-76: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 38-77: Loss: 0.0207 Acc: 100.0000%\n",
      "\tvalidation 38-78: Loss: 0.1606 Acc: 75.0000%\n",
      "\tvalidation 38-79: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 38-80: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-81: Loss: 0.0043 Acc: 100.0000%\n",
      "\tvalidation 38-82: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 38-83: Loss: 0.0871 Acc: 75.0000%\n",
      "\tvalidation 38-84: Loss: 0.0328 Acc: 100.0000%\n",
      "\tvalidation 38-85: Loss: 0.1400 Acc: 75.0000%\n",
      "\tvalidation 38-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-87: Loss: 0.1502 Acc: 75.0000%\n",
      "\tvalidation 38-88: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-89: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 38-90: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 38-91: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 38-92: Loss: 0.0170 Acc: 100.0000%\n",
      "\tvalidation 38-93: Loss: 0.0858 Acc: 75.0000%\n",
      "\tvalidation 38-94: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 38-95: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 38-96: Loss: 0.0106 Acc: 100.0000%\n",
      "\tvalidation 38-97: Loss: 0.0180 Acc: 100.0000%\n",
      "\tvalidation 38-98: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 38-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-100: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 38-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 38-102: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 38-103: Loss: 0.0369 Acc: 100.0000%\n",
      "\tvalidation 38-104: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 38-105: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0386 Acc: 94.8980%\n",
      "\tvalidation Loss: 0.0190 Acc: 97.1429%\n",
      "Time passed 0h 29m 49s\n",
      "--------------------\n",
      "Epoch [39/40]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-1: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-2: Loss: 0.1887 Acc: 75.0000%\n",
      "\ttrain 39-3: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-4: Loss: 0.1197 Acc: 75.0000%\n",
      "\ttrain 39-5: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 39-6: Loss: 0.0989 Acc: 75.0000%\n",
      "\ttrain 39-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-8: Loss: 0.1440 Acc: 50.0000%\n",
      "\ttrain 39-9: Loss: 0.0105 Acc: 100.0000%\n",
      "\ttrain 39-10: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-11: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 39-12: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 39-13: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 39-14: Loss: 0.0432 Acc: 100.0000%\n",
      "\ttrain 39-15: Loss: 0.0087 Acc: 100.0000%\n",
      "\ttrain 39-16: Loss: 0.1140 Acc: 75.0000%\n",
      "\ttrain 39-17: Loss: 0.0060 Acc: 100.0000%\n",
      "\ttrain 39-18: Loss: 0.0278 Acc: 100.0000%\n",
      "\ttrain 39-19: Loss: 0.0289 Acc: 100.0000%\n",
      "\ttrain 39-20: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-23: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-24: Loss: 0.0443 Acc: 100.0000%\n",
      "\ttrain 39-25: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-26: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-28: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 39-29: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-30: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 39-31: Loss: 0.0479 Acc: 75.0000%\n",
      "\ttrain 39-32: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-33: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-34: Loss: 0.0129 Acc: 100.0000%\n",
      "\ttrain 39-35: Loss: 0.0146 Acc: 100.0000%\n",
      "\ttrain 39-36: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 39-37: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-38: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-39: Loss: 0.0073 Acc: 100.0000%\n",
      "\ttrain 39-40: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-41: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 39-42: Loss: 0.0325 Acc: 100.0000%\n",
      "\ttrain 39-43: Loss: 0.0048 Acc: 100.0000%\n",
      "\ttrain 39-44: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 39-45: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-46: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 39-47: Loss: 0.0164 Acc: 100.0000%\n",
      "\ttrain 39-48: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 39-49: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 39-50: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 39-51: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-52: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 39-53: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 39-54: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-55: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-56: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-57: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-58: Loss: 0.1131 Acc: 75.0000%\n",
      "\ttrain 39-59: Loss: 0.0869 Acc: 75.0000%\n",
      "\ttrain 39-60: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-61: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 39-62: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-63: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 39-64: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 39-65: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-66: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-67: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 39-68: Loss: 0.0264 Acc: 100.0000%\n",
      "\ttrain 39-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 39-71: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 39-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-73: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 39-74: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 39-75: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 39-76: Loss: 0.0152 Acc: 100.0000%\n",
      "\ttrain 39-77: Loss: 0.0132 Acc: 100.0000%\n",
      "\ttrain 39-78: Loss: 0.2007 Acc: 75.0000%\n",
      "\ttrain 39-79: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 39-80: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-81: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-82: Loss: 0.0055 Acc: 100.0000%\n",
      "\ttrain 39-83: Loss: 0.1194 Acc: 75.0000%\n",
      "\ttrain 39-84: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-85: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-86: Loss: 0.1310 Acc: 50.0000%\n",
      "\ttrain 39-87: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 39-88: Loss: 0.1805 Acc: 75.0000%\n",
      "\ttrain 39-89: Loss: 0.0215 Acc: 100.0000%\n",
      "\ttrain 39-90: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-91: Loss: 0.0150 Acc: 100.0000%\n",
      "\ttrain 39-92: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-93: Loss: 0.2299 Acc: 75.0000%\n",
      "\ttrain 39-94: Loss: 0.0234 Acc: 100.0000%\n",
      "\ttrain 39-95: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 39-96: Loss: 0.1549 Acc: 75.0000%\n",
      "\ttrain 39-97: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 39-98: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-99: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 39-100: Loss: 0.1216 Acc: 75.0000%\n",
      "\ttrain 39-101: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-102: Loss: 0.0536 Acc: 100.0000%\n",
      "\ttrain 39-103: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 39-104: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 39-105: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 39-106: Loss: 0.0521 Acc: 75.0000%\n",
      "\ttrain 39-107: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-108: Loss: 0.1853 Acc: 50.0000%\n",
      "\ttrain 39-109: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 39-110: Loss: 0.0314 Acc: 100.0000%\n",
      "\ttrain 39-111: Loss: 0.1211 Acc: 75.0000%\n",
      "\ttrain 39-112: Loss: 0.0388 Acc: 100.0000%\n",
      "\ttrain 39-113: Loss: 0.0403 Acc: 100.0000%\n",
      "\ttrain 39-114: Loss: 0.0857 Acc: 75.0000%\n",
      "\ttrain 39-115: Loss: 0.0770 Acc: 75.0000%\n",
      "\ttrain 39-116: Loss: 0.0978 Acc: 75.0000%\n",
      "\ttrain 39-117: Loss: 0.0629 Acc: 75.0000%\n",
      "\ttrain 39-118: Loss: 0.0586 Acc: 100.0000%\n",
      "\ttrain 39-119: Loss: 0.0629 Acc: 75.0000%\n",
      "\ttrain 39-120: Loss: 0.0200 Acc: 100.0000%\n",
      "\ttrain 39-121: Loss: 0.1202 Acc: 75.0000%\n",
      "\ttrain 39-122: Loss: 0.0182 Acc: 100.0000%\n",
      "\ttrain 39-123: Loss: 0.0075 Acc: 100.0000%\n",
      "\ttrain 39-124: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-125: Loss: 0.0196 Acc: 100.0000%\n",
      "\ttrain 39-126: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 39-127: Loss: 0.0157 Acc: 100.0000%\n",
      "\ttrain 39-128: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 39-129: Loss: 0.1118 Acc: 75.0000%\n",
      "\ttrain 39-130: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 39-131: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-132: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-133: Loss: 0.0065 Acc: 100.0000%\n",
      "\ttrain 39-134: Loss: 0.1541 Acc: 75.0000%\n",
      "\ttrain 39-135: Loss: 0.0276 Acc: 100.0000%\n",
      "\ttrain 39-136: Loss: 0.0184 Acc: 100.0000%\n",
      "\ttrain 39-137: Loss: 0.1019 Acc: 75.0000%\n",
      "\ttrain 39-138: Loss: 0.1247 Acc: 75.0000%\n",
      "\ttrain 39-139: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 39-140: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 39-141: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-142: Loss: 0.0156 Acc: 100.0000%\n",
      "\ttrain 39-143: Loss: 0.0588 Acc: 100.0000%\n",
      "\ttrain 39-144: Loss: 0.3368 Acc: 50.0000%\n",
      "\ttrain 39-145: Loss: 0.0062 Acc: 100.0000%\n",
      "\ttrain 39-146: Loss: 0.0063 Acc: 100.0000%\n",
      "\ttrain 39-147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-148: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 39-149: Loss: 0.0053 Acc: 100.0000%\n",
      "\ttrain 39-150: Loss: 0.0180 Acc: 100.0000%\n",
      "\ttrain 39-151: Loss: 0.0102 Acc: 100.0000%\n",
      "\ttrain 39-152: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 39-153: Loss: 0.0167 Acc: 100.0000%\n",
      "\ttrain 39-154: Loss: 0.0450 Acc: 100.0000%\n",
      "\ttrain 39-155: Loss: 0.0079 Acc: 100.0000%\n",
      "\ttrain 39-156: Loss: 0.1462 Acc: 75.0000%\n",
      "\ttrain 39-157: Loss: 0.1232 Acc: 75.0000%\n",
      "\ttrain 39-158: Loss: 0.0344 Acc: 100.0000%\n",
      "\ttrain 39-159: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-160: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 39-161: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 39-162: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 39-163: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 39-164: Loss: 0.0861 Acc: 75.0000%\n",
      "\ttrain 39-165: Loss: 0.0463 Acc: 100.0000%\n",
      "\ttrain 39-166: Loss: 0.0507 Acc: 100.0000%\n",
      "\ttrain 39-167: Loss: 0.0298 Acc: 100.0000%\n",
      "\ttrain 39-168: Loss: 0.0296 Acc: 100.0000%\n",
      "\ttrain 39-169: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 39-170: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-171: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 39-172: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 39-173: Loss: 0.0206 Acc: 100.0000%\n",
      "\ttrain 39-174: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 39-175: Loss: 0.0064 Acc: 100.0000%\n",
      "\ttrain 39-176: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 39-177: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-178: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 39-179: Loss: 0.0254 Acc: 100.0000%\n",
      "\ttrain 39-180: Loss: 0.1496 Acc: 75.0000%\n",
      "\ttrain 39-181: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 39-182: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 39-183: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 39-184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 39-185: Loss: 0.0223 Acc: 100.0000%\n",
      "\ttrain 39-186: Loss: 0.0127 Acc: 100.0000%\n",
      "\ttrain 39-187: Loss: 0.1270 Acc: 75.0000%\n",
      "\ttrain 39-188: Loss: 0.2814 Acc: 75.0000%\n",
      "\ttrain 39-189: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 39-190: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 39-191: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-192: Loss: 0.1158 Acc: 75.0000%\n",
      "\ttrain 39-193: Loss: 0.0532 Acc: 75.0000%\n",
      "\ttrain 39-194: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 39-195: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-196: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 39-197: Loss: 0.0114 Acc: 100.0000%\n",
      "\ttrain 39-198: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-199: Loss: 0.1297 Acc: 75.0000%\n",
      "\ttrain 39-200: Loss: 0.0399 Acc: 100.0000%\n",
      "\ttrain 39-201: Loss: 0.1180 Acc: 75.0000%\n",
      "\ttrain 39-202: Loss: 0.0638 Acc: 75.0000%\n",
      "\ttrain 39-203: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 39-204: Loss: 0.0744 Acc: 75.0000%\n",
      "\ttrain 39-205: Loss: 0.0839 Acc: 75.0000%\n",
      "\ttrain 39-206: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 39-207: Loss: 0.2476 Acc: 75.0000%\n",
      "\ttrain 39-208: Loss: 0.1296 Acc: 75.0000%\n",
      "\ttrain 39-209: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 39-210: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 39-211: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 39-212: Loss: 0.0486 Acc: 75.0000%\n",
      "\ttrain 39-213: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 39-214: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 39-215: Loss: 0.0431 Acc: 100.0000%\n",
      "\ttrain 39-216: Loss: 0.0116 Acc: 100.0000%\n",
      "\ttrain 39-217: Loss: 0.0103 Acc: 100.0000%\n",
      "\ttrain 39-218: Loss: 0.0110 Acc: 100.0000%\n",
      "\ttrain 39-219: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 39-220: Loss: 0.1143 Acc: 75.0000%\n",
      "\ttrain 39-221: Loss: 0.0078 Acc: 100.0000%\n",
      "\ttrain 39-222: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 39-223: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 39-224: Loss: 0.0831 Acc: 75.0000%\n",
      "\ttrain 39-225: Loss: 0.0533 Acc: 100.0000%\n",
      "\ttrain 39-226: Loss: 0.0084 Acc: 100.0000%\n",
      "\ttrain 39-227: Loss: 0.0246 Acc: 100.0000%\n",
      "\ttrain 39-228: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 39-229: Loss: 0.0067 Acc: 100.0000%\n",
      "\ttrain 39-230: Loss: 0.0122 Acc: 100.0000%\n",
      "\ttrain 39-231: Loss: 0.0292 Acc: 100.0000%\n",
      "\ttrain 39-232: Loss: 0.0552 Acc: 100.0000%\n",
      "\ttrain 39-233: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 39-234: Loss: 0.0115 Acc: 100.0000%\n",
      "\ttrain 39-235: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 39-236: Loss: 0.1857 Acc: 50.0000%\n",
      "\ttrain 39-237: Loss: 0.1415 Acc: 75.0000%\n",
      "\ttrain 39-238: Loss: 0.0668 Acc: 75.0000%\n",
      "\ttrain 39-239: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 39-240: Loss: 0.1289 Acc: 75.0000%\n",
      "\ttrain 39-241: Loss: 0.0725 Acc: 75.0000%\n",
      "\ttrain 39-242: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 39-243: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 39-244: Loss: 0.0096 Acc: 100.0000%\n",
      "\ttrain 39-245: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 39-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-2: Loss: 0.0048 Acc: 100.0000%\n",
      "\tvalidation 39-3: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-4: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 39-5: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-6: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 39-7: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-8: Loss: 0.0052 Acc: 100.0000%\n",
      "\tvalidation 39-9: Loss: 0.0229 Acc: 100.0000%\n",
      "\tvalidation 39-10: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-11: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 39-12: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 39-13: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-14: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-15: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-16: Loss: 0.0604 Acc: 75.0000%\n",
      "\tvalidation 39-17: Loss: 0.0297 Acc: 100.0000%\n",
      "\tvalidation 39-18: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-19: Loss: 0.0375 Acc: 100.0000%\n",
      "\tvalidation 39-20: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 39-21: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 39-22: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-23: Loss: 0.0055 Acc: 100.0000%\n",
      "\tvalidation 39-24: Loss: 0.0096 Acc: 100.0000%\n",
      "\tvalidation 39-25: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-26: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 39-27: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 39-28: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-29: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 39-30: Loss: 0.0253 Acc: 100.0000%\n",
      "\tvalidation 39-31: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-32: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 39-33: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 39-34: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-35: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 39-36: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-37: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-38: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 39-39: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-40: Loss: 0.0033 Acc: 100.0000%\n",
      "\tvalidation 39-41: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 39-42: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-44: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 39-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-46: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 39-47: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 39-48: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 39-49: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-50: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 39-51: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 39-52: Loss: 0.0429 Acc: 100.0000%\n",
      "\tvalidation 39-53: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 39-54: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 39-55: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 39-56: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 39-57: Loss: 0.0056 Acc: 100.0000%\n",
      "\tvalidation 39-58: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-59: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-60: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 39-61: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-62: Loss: 0.0082 Acc: 100.0000%\n",
      "\tvalidation 39-63: Loss: 0.0481 Acc: 75.0000%\n",
      "\tvalidation 39-64: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-65: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 39-66: Loss: 0.0050 Acc: 100.0000%\n",
      "\tvalidation 39-67: Loss: 0.0578 Acc: 75.0000%\n",
      "\tvalidation 39-68: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-69: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-71: Loss: 0.0196 Acc: 100.0000%\n",
      "\tvalidation 39-72: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 39-73: Loss: 0.0064 Acc: 100.0000%\n",
      "\tvalidation 39-74: Loss: 0.1137 Acc: 75.0000%\n",
      "\tvalidation 39-75: Loss: 0.0049 Acc: 100.0000%\n",
      "\tvalidation 39-76: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 39-77: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 39-78: Loss: 0.0735 Acc: 75.0000%\n",
      "\tvalidation 39-79: Loss: 0.0530 Acc: 75.0000%\n",
      "\tvalidation 39-80: Loss: 0.0051 Acc: 100.0000%\n",
      "\tvalidation 39-81: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 39-82: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 39-83: Loss: 0.0181 Acc: 100.0000%\n",
      "\tvalidation 39-84: Loss: 0.0042 Acc: 100.0000%\n",
      "\tvalidation 39-85: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 39-86: Loss: 0.0092 Acc: 100.0000%\n",
      "\tvalidation 39-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-88: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 39-89: Loss: 0.0122 Acc: 100.0000%\n",
      "\tvalidation 39-90: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 39-91: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-92: Loss: 0.0040 Acc: 100.0000%\n",
      "\tvalidation 39-93: Loss: 0.0057 Acc: 100.0000%\n",
      "\tvalidation 39-94: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 39-95: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 39-96: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 39-97: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 39-98: Loss: 0.0103 Acc: 100.0000%\n",
      "\tvalidation 39-99: Loss: 0.0116 Acc: 100.0000%\n",
      "\tvalidation 39-100: Loss: 0.0483 Acc: 75.0000%\n",
      "\tvalidation 39-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 39-102: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 39-103: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 39-104: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 39-105: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0373 Acc: 93.9796%\n",
      "\tvalidation Loss: 0.0089 Acc: 98.3333%\n",
      "Time passed 0h 30m 54s\n",
      "--------------------\n",
      "Epoch [40/40]:\n",
      "\ttrain 40-1: Loss: 0.0093 Acc: 100.0000%\n",
      "\ttrain 40-2: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-3: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-4: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 40-5: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 40-6: Loss: 0.1410 Acc: 75.0000%\n",
      "\ttrain 40-7: Loss: 0.0702 Acc: 75.0000%\n",
      "\ttrain 40-8: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-9: Loss: 0.0070 Acc: 100.0000%\n",
      "\ttrain 40-10: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-11: Loss: 0.0068 Acc: 100.0000%\n",
      "\ttrain 40-12: Loss: 0.1797 Acc: 75.0000%\n",
      "\ttrain 40-13: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 40-14: Loss: 0.0396 Acc: 100.0000%\n",
      "\ttrain 40-15: Loss: 0.0153 Acc: 100.0000%\n",
      "\ttrain 40-16: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-17: Loss: 0.0341 Acc: 100.0000%\n",
      "\ttrain 40-18: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-19: Loss: 0.1768 Acc: 75.0000%\n",
      "\ttrain 40-20: Loss: 0.0291 Acc: 100.0000%\n",
      "\ttrain 40-21: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-22: Loss: 0.0135 Acc: 100.0000%\n",
      "\ttrain 40-23: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-25: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 40-26: Loss: 0.0469 Acc: 100.0000%\n",
      "\ttrain 40-27: Loss: 0.0203 Acc: 100.0000%\n",
      "\ttrain 40-28: Loss: 0.0679 Acc: 75.0000%\n",
      "\ttrain 40-29: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-30: Loss: 0.0727 Acc: 100.0000%\n",
      "\ttrain 40-31: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-33: Loss: 0.0097 Acc: 100.0000%\n",
      "\ttrain 40-34: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 40-35: Loss: 0.1102 Acc: 75.0000%\n",
      "\ttrain 40-36: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 40-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-38: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 40-39: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-40: Loss: 0.0749 Acc: 75.0000%\n",
      "\ttrain 40-41: Loss: 0.0229 Acc: 100.0000%\n",
      "\ttrain 40-42: Loss: 0.0231 Acc: 100.0000%\n",
      "\ttrain 40-43: Loss: 0.0440 Acc: 100.0000%\n",
      "\ttrain 40-44: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 40-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-46: Loss: 0.0584 Acc: 100.0000%\n",
      "\ttrain 40-47: Loss: 0.1335 Acc: 75.0000%\n",
      "\ttrain 40-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-49: Loss: 0.1513 Acc: 75.0000%\n",
      "\ttrain 40-50: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-51: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 40-52: Loss: 0.0250 Acc: 100.0000%\n",
      "\ttrain 40-53: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-54: Loss: 0.0056 Acc: 100.0000%\n",
      "\ttrain 40-55: Loss: 0.1195 Acc: 75.0000%\n",
      "\ttrain 40-56: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 40-57: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 40-58: Loss: 0.0190 Acc: 100.0000%\n",
      "\ttrain 40-59: Loss: 0.0323 Acc: 100.0000%\n",
      "\ttrain 40-60: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-61: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-62: Loss: 0.0394 Acc: 100.0000%\n",
      "\ttrain 40-63: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 40-64: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-65: Loss: 0.0290 Acc: 100.0000%\n",
      "\ttrain 40-66: Loss: 0.0373 Acc: 100.0000%\n",
      "\ttrain 40-67: Loss: 0.0532 Acc: 100.0000%\n",
      "\ttrain 40-68: Loss: 0.0046 Acc: 100.0000%\n",
      "\ttrain 40-69: Loss: 0.0076 Acc: 100.0000%\n",
      "\ttrain 40-70: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 40-71: Loss: 0.1891 Acc: 75.0000%\n",
      "\ttrain 40-72: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-73: Loss: 0.0109 Acc: 100.0000%\n",
      "\ttrain 40-74: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-75: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-76: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-77: Loss: 0.1324 Acc: 50.0000%\n",
      "\ttrain 40-78: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-79: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 40-80: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-81: Loss: 0.0984 Acc: 75.0000%\n",
      "\ttrain 40-82: Loss: 0.2495 Acc: 75.0000%\n",
      "\ttrain 40-83: Loss: 0.1774 Acc: 75.0000%\n",
      "\ttrain 40-84: Loss: 0.0145 Acc: 100.0000%\n",
      "\ttrain 40-85: Loss: 0.0227 Acc: 100.0000%\n",
      "\ttrain 40-86: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 40-87: Loss: 0.0253 Acc: 100.0000%\n",
      "\ttrain 40-88: Loss: 0.2404 Acc: 75.0000%\n",
      "\ttrain 40-89: Loss: 0.1069 Acc: 75.0000%\n",
      "\ttrain 40-90: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-91: Loss: 0.0308 Acc: 100.0000%\n",
      "\ttrain 40-92: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 40-93: Loss: 0.0451 Acc: 100.0000%\n",
      "\ttrain 40-94: Loss: 0.1433 Acc: 75.0000%\n",
      "\ttrain 40-95: Loss: 0.0069 Acc: 100.0000%\n",
      "\ttrain 40-96: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 40-97: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 40-98: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 40-99: Loss: 0.0469 Acc: 75.0000%\n",
      "\ttrain 40-100: Loss: 0.0312 Acc: 100.0000%\n",
      "\ttrain 40-101: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 40-102: Loss: 0.0902 Acc: 75.0000%\n",
      "\ttrain 40-103: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 40-104: Loss: 0.0365 Acc: 100.0000%\n",
      "\ttrain 40-105: Loss: 0.0273 Acc: 100.0000%\n",
      "\ttrain 40-106: Loss: 0.1265 Acc: 75.0000%\n",
      "\ttrain 40-107: Loss: 0.1308 Acc: 75.0000%\n",
      "\ttrain 40-108: Loss: 0.0277 Acc: 100.0000%\n",
      "\ttrain 40-109: Loss: 0.0162 Acc: 100.0000%\n",
      "\ttrain 40-110: Loss: 0.0594 Acc: 75.0000%\n",
      "\ttrain 40-111: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 40-112: Loss: 0.1736 Acc: 75.0000%\n",
      "\ttrain 40-113: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 40-114: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-115: Loss: 0.0249 Acc: 100.0000%\n",
      "\ttrain 40-116: Loss: 0.0210 Acc: 100.0000%\n",
      "\ttrain 40-117: Loss: 0.0427 Acc: 100.0000%\n",
      "\ttrain 40-118: Loss: 0.0288 Acc: 100.0000%\n",
      "\ttrain 40-119: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-120: Loss: 0.0171 Acc: 100.0000%\n",
      "\ttrain 40-121: Loss: 0.0353 Acc: 100.0000%\n",
      "\ttrain 40-122: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-123: Loss: 0.0188 Acc: 100.0000%\n",
      "\ttrain 40-124: Loss: 0.0378 Acc: 100.0000%\n",
      "\ttrain 40-125: Loss: 0.0091 Acc: 100.0000%\n",
      "\ttrain 40-126: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-127: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-128: Loss: 0.1522 Acc: 75.0000%\n",
      "\ttrain 40-129: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-130: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 40-131: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-132: Loss: 0.0385 Acc: 100.0000%\n",
      "\ttrain 40-133: Loss: 0.0575 Acc: 75.0000%\n",
      "\ttrain 40-134: Loss: 0.0082 Acc: 100.0000%\n",
      "\ttrain 40-135: Loss: 0.0357 Acc: 100.0000%\n",
      "\ttrain 40-136: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-137: Loss: 0.0247 Acc: 100.0000%\n",
      "\ttrain 40-138: Loss: 0.0601 Acc: 100.0000%\n",
      "\ttrain 40-139: Loss: 0.0121 Acc: 100.0000%\n",
      "\ttrain 40-140: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-141: Loss: 0.1285 Acc: 50.0000%\n",
      "\ttrain 40-142: Loss: 0.0104 Acc: 100.0000%\n",
      "\ttrain 40-143: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 40-144: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 40-145: Loss: 0.1134 Acc: 75.0000%\n",
      "\ttrain 40-146: Loss: 0.1117 Acc: 75.0000%\n",
      "\ttrain 40-147: Loss: 0.0534 Acc: 100.0000%\n",
      "\ttrain 40-148: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-149: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 40-150: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 40-152: Loss: 0.0713 Acc: 75.0000%\n",
      "\ttrain 40-153: Loss: 0.3251 Acc: 50.0000%\n",
      "\ttrain 40-154: Loss: 0.2030 Acc: 75.0000%\n",
      "\ttrain 40-155: Loss: 0.0281 Acc: 100.0000%\n",
      "\ttrain 40-156: Loss: 0.0466 Acc: 75.0000%\n",
      "\ttrain 40-157: Loss: 0.0615 Acc: 75.0000%\n",
      "\ttrain 40-158: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 40-159: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 40-160: Loss: 0.0141 Acc: 100.0000%\n",
      "\ttrain 40-161: Loss: 0.0498 Acc: 100.0000%\n",
      "\ttrain 40-162: Loss: 0.1607 Acc: 75.0000%\n",
      "\ttrain 40-163: Loss: 0.1275 Acc: 75.0000%\n",
      "\ttrain 40-164: Loss: 0.0155 Acc: 100.0000%\n",
      "\ttrain 40-165: Loss: 0.0745 Acc: 75.0000%\n",
      "\ttrain 40-166: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 40-167: Loss: 0.0118 Acc: 100.0000%\n",
      "\ttrain 40-168: Loss: 0.0304 Acc: 100.0000%\n",
      "\ttrain 40-169: Loss: 0.6262 Acc: 50.0000%\n",
      "\ttrain 40-170: Loss: 0.2267 Acc: 50.0000%\n",
      "\ttrain 40-171: Loss: 0.0594 Acc: 75.0000%\n",
      "\ttrain 40-172: Loss: 0.0517 Acc: 75.0000%\n",
      "\ttrain 40-173: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-174: Loss: 0.1007 Acc: 75.0000%\n",
      "\ttrain 40-175: Loss: 0.0148 Acc: 100.0000%\n",
      "\ttrain 40-176: Loss: 0.0467 Acc: 100.0000%\n",
      "\ttrain 40-177: Loss: 0.0594 Acc: 100.0000%\n",
      "\ttrain 40-178: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 40-179: Loss: 0.0265 Acc: 100.0000%\n",
      "\ttrain 40-180: Loss: 0.0041 Acc: 100.0000%\n",
      "\ttrain 40-181: Loss: 0.1147 Acc: 75.0000%\n",
      "\ttrain 40-182: Loss: 0.0334 Acc: 100.0000%\n",
      "\ttrain 40-183: Loss: 0.1347 Acc: 75.0000%\n",
      "\ttrain 40-184: Loss: 0.0627 Acc: 100.0000%\n",
      "\ttrain 40-185: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 40-186: Loss: 0.0364 Acc: 100.0000%\n",
      "\ttrain 40-187: Loss: 0.0071 Acc: 100.0000%\n",
      "\ttrain 40-188: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 40-189: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 40-190: Loss: 0.0529 Acc: 100.0000%\n",
      "\ttrain 40-191: Loss: 0.0731 Acc: 100.0000%\n",
      "\ttrain 40-192: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 40-193: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-194: Loss: 0.0335 Acc: 100.0000%\n",
      "\ttrain 40-195: Loss: 0.0089 Acc: 100.0000%\n",
      "\ttrain 40-196: Loss: 0.1551 Acc: 75.0000%\n",
      "\ttrain 40-197: Loss: 0.0178 Acc: 100.0000%\n",
      "\ttrain 40-198: Loss: 0.0275 Acc: 100.0000%\n",
      "\ttrain 40-199: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 40-200: Loss: 0.0130 Acc: 100.0000%\n",
      "\ttrain 40-201: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-202: Loss: 0.1469 Acc: 75.0000%\n",
      "\ttrain 40-203: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-204: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 40-205: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-206: Loss: 0.0675 Acc: 75.0000%\n",
      "\ttrain 40-207: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 40-208: Loss: 0.0113 Acc: 100.0000%\n",
      "\ttrain 40-209: Loss: 0.0086 Acc: 100.0000%\n",
      "\ttrain 40-210: Loss: 0.0040 Acc: 100.0000%\n",
      "\ttrain 40-211: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 40-212: Loss: 0.0661 Acc: 75.0000%\n",
      "\ttrain 40-213: Loss: 0.0625 Acc: 75.0000%\n",
      "\ttrain 40-214: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 40-215: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 40-216: Loss: 0.0081 Acc: 100.0000%\n",
      "\ttrain 40-217: Loss: 0.2474 Acc: 75.0000%\n",
      "\ttrain 40-218: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 40-219: Loss: 0.0422 Acc: 100.0000%\n",
      "\ttrain 40-220: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 40-221: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 40-222: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 40-223: Loss: 0.0612 Acc: 75.0000%\n",
      "\ttrain 40-224: Loss: 0.1045 Acc: 75.0000%\n",
      "\ttrain 40-225: Loss: 0.0159 Acc: 100.0000%\n",
      "\ttrain 40-226: Loss: 0.0117 Acc: 100.0000%\n",
      "\ttrain 40-227: Loss: 0.0393 Acc: 100.0000%\n",
      "\ttrain 40-228: Loss: 0.0077 Acc: 100.0000%\n",
      "\ttrain 40-229: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 40-230: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 40-231: Loss: 0.0381 Acc: 100.0000%\n",
      "\ttrain 40-232: Loss: 0.0094 Acc: 100.0000%\n",
      "\ttrain 40-233: Loss: 0.0233 Acc: 100.0000%\n",
      "\ttrain 40-234: Loss: 0.0095 Acc: 100.0000%\n",
      "\ttrain 40-235: Loss: 0.1720 Acc: 75.0000%\n",
      "\ttrain 40-236: Loss: 0.1029 Acc: 75.0000%\n",
      "\ttrain 40-237: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 40-238: Loss: 0.2151 Acc: 75.0000%\n",
      "\ttrain 40-239: Loss: 0.0358 Acc: 100.0000%\n",
      "\ttrain 40-240: Loss: 0.0101 Acc: 100.0000%\n",
      "\ttrain 40-241: Loss: 0.0899 Acc: 75.0000%\n",
      "\ttrain 40-242: Loss: 0.0818 Acc: 75.0000%\n",
      "\ttrain 40-243: Loss: 0.1031 Acc: 75.0000%\n",
      "\ttrain 40-244: Loss: 0.0712 Acc: 75.0000%\n",
      "\ttrain 40-245: Loss: 0.2268 Acc: 75.0000%\n",
      "\tvalidation 40-1: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-2: Loss: 0.0163 Acc: 100.0000%\n",
      "\tvalidation 40-3: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 40-4: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 40-5: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 40-6: Loss: 0.0307 Acc: 100.0000%\n",
      "\tvalidation 40-7: Loss: 0.0047 Acc: 100.0000%\n",
      "\tvalidation 40-8: Loss: 0.0070 Acc: 100.0000%\n",
      "\tvalidation 40-9: Loss: 0.0550 Acc: 75.0000%\n",
      "\tvalidation 40-10: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-11: Loss: 0.0233 Acc: 100.0000%\n",
      "\tvalidation 40-12: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-13: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-14: Loss: 0.0041 Acc: 100.0000%\n",
      "\tvalidation 40-15: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 40-16: Loss: 0.0063 Acc: 100.0000%\n",
      "\tvalidation 40-17: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-18: Loss: 0.0028 Acc: 100.0000%\n",
      "\tvalidation 40-19: Loss: 0.0046 Acc: 100.0000%\n",
      "\tvalidation 40-20: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-21: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-22: Loss: 0.0547 Acc: 75.0000%\n",
      "\tvalidation 40-23: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-24: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-25: Loss: 0.1217 Acc: 75.0000%\n",
      "\tvalidation 40-26: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-27: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 40-28: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-29: Loss: 0.1064 Acc: 75.0000%\n",
      "\tvalidation 40-30: Loss: 0.0032 Acc: 100.0000%\n",
      "\tvalidation 40-31: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-32: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-33: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-34: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 40-35: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-36: Loss: 0.0068 Acc: 100.0000%\n",
      "\tvalidation 40-37: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-38: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-39: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-40: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-41: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-42: Loss: 0.0533 Acc: 75.0000%\n",
      "\tvalidation 40-43: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-44: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-45: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 40-46: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-47: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-48: Loss: 0.0113 Acc: 100.0000%\n",
      "\tvalidation 40-49: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-51: Loss: 0.0177 Acc: 100.0000%\n",
      "\tvalidation 40-52: Loss: 0.0553 Acc: 75.0000%\n",
      "\tvalidation 40-53: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-54: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-55: Loss: 0.0171 Acc: 100.0000%\n",
      "\tvalidation 40-56: Loss: 0.0054 Acc: 100.0000%\n",
      "\tvalidation 40-57: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-58: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 40-59: Loss: 0.0094 Acc: 100.0000%\n",
      "\tvalidation 40-60: Loss: 0.0948 Acc: 75.0000%\n",
      "\tvalidation 40-61: Loss: 0.0038 Acc: 100.0000%\n",
      "\tvalidation 40-62: Loss: 0.1339 Acc: 75.0000%\n",
      "\tvalidation 40-63: Loss: 0.0037 Acc: 100.0000%\n",
      "\tvalidation 40-64: Loss: 0.0035 Acc: 100.0000%\n",
      "\tvalidation 40-65: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 40-66: Loss: 0.0102 Acc: 100.0000%\n",
      "\tvalidation 40-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-68: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-69: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-70: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 40-71: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 40-72: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-73: Loss: 0.0097 Acc: 100.0000%\n",
      "\tvalidation 40-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-75: Loss: 0.0548 Acc: 75.0000%\n",
      "\tvalidation 40-76: Loss: 0.0137 Acc: 100.0000%\n",
      "\tvalidation 40-77: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-78: Loss: 0.0213 Acc: 100.0000%\n",
      "\tvalidation 40-79: Loss: 0.0221 Acc: 100.0000%\n",
      "\tvalidation 40-80: Loss: 0.0194 Acc: 100.0000%\n",
      "\tvalidation 40-81: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-82: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 40-83: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 40-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 40-85: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 40-86: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 40-87: Loss: 0.0025 Acc: 100.0000%\n",
      "\tvalidation 40-88: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 40-89: Loss: 0.0104 Acc: 100.0000%\n",
      "\tvalidation 40-90: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-91: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 40-92: Loss: 0.0069 Acc: 100.0000%\n",
      "\tvalidation 40-93: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 40-94: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 40-95: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 40-96: Loss: 0.0034 Acc: 100.0000%\n",
      "\tvalidation 40-97: Loss: 0.0044 Acc: 100.0000%\n",
      "\tvalidation 40-98: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 40-99: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 40-100: Loss: 0.0422 Acc: 100.0000%\n",
      "\tvalidation 40-101: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 40-102: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 40-103: Loss: 0.0566 Acc: 75.0000%\n",
      "\tvalidation 40-104: Loss: 0.0071 Acc: 100.0000%\n",
      "\tvalidation 40-105: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain Loss: 0.0447 Acc: 93.2653%\n",
      "\tvalidation Loss: 0.0116 Acc: 97.6190%\n",
      "Time passed 0h 32m 1s\n",
      "--------------------\n",
      "Training complete in 0h 32m 1s\n",
      "Best validation Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "loss_train = [] # 训练集loss\n",
    "acc_train = [] # 训练集正确率\n",
    "loss_val = [] # 验证集loss\n",
    "acc_val = [] # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "\n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            i = 1\n",
    "            j = 1\n",
    "            # exp_lr_scheduler.step()\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            i = 1\n",
    "            j = 2\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            # if use_gpu:\n",
    "            #     inputs = inputs.cuda()\n",
    "            #     labels = labels.cuda()\n",
    "            # else:\n",
    "            #     inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            # '_'就是一个变量，换成a也是可以的，没有特别的意思，不过一般用_表示的变量好像都是没什么用的一个临时变量，大概是\n",
    "            # 一个编程习惯吧。所以这边'_,'没有特殊的含义，'_'就是一个变量，只是为了让preds取到max函数返回值的第二项，\n",
    "            # 即找到的最大值的索引位置（对应到这里就是类别标签）\n",
    "            # （max函数解释见https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max）\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, num_classes):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "\n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, i, loss.item()/4, torch.sum(preds == labels.data).item()/4.0*100))\n",
    "            i = i + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if j == 1:\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and j == 2:\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'validation' and epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"网络参数更新\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/params_vgg13.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "#             print(\"Model's state_dict:\")\n",
    "#             for param_tensor in best_model_wts:\n",
    "#                 print(param_tensor, \"\\t\", best_model_wts[param_tensor].size())\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.3460083820381943, 0.3329960160717672, 0.24938566903678738, 0.2140098344610662, 0.1673000127381208, 0.14460606661682227, 0.1261449129149622, 0.11457490069525582, 0.12630175013019115, 0.10800207435172432, 0.11809755651926508, 0.10945753982784796, 0.10588200837373733, 0.11257559403168912, 0.09633842163852283, 0.09676892970289502, 0.09574069684865523, 0.08148183135353788, 0.07132731381119514, 0.08268481895935778, 0.05543410308202919, 0.07510386109352112, 0.053073782823523694, 0.06552457182991261, 0.04841648445141559, 0.06009223804790147, 0.05785939374140331, 0.05941163632942706, 0.04877105562054381, 0.04101239921791213, 0.04952482591782297, 0.05007392608997773, 0.05229435245297393, 0.06325180077431153, 0.04111129389125474, 0.03873981821293734, 0.050634938858601514, 0.03859845968533535, 0.03725618294307164, 0.044734043217435175]\n",
      "loss_val: [0.34636583016032263, 0.2555231527203605, 0.18206988275051117, 0.1593647528617155, 0.10716774484940937, 0.1406105819912184, 0.10093039068437758, 0.10410742383627665, 0.09202566189425332, 0.09595364410252798, 0.1025137402472042, 0.08359268584421703, 0.15535496515887123, 0.08155036398342677, 0.05747041858377911, 0.07059557849452609, 0.03741495779582432, 0.028139028024105797, 0.02835676705553418, 0.03574619953121458, 0.015167495040666489, 0.03342809194610232, 0.015185115450904483, 0.024777679287251973, 0.009402555085363843, 0.020500338148503078, 0.057953740727333794, 0.009885294522557939, 0.011192190930956886, 0.03740471800168355, 0.004301681405022031, 0.008735522769746326, 0.030804139233770823, 0.013012538637433733, 0.00497756784870511, 0.07165448325020926, 0.011873574200130644, 0.01902058394182296, 0.008888489575613112, 0.011568484419868106]\n",
      "acc_train: [0.25, 0.3, 0.4775510204081633, 0.5326530612244897, 0.6683673469387755, 0.6948979591836735, 0.7295918367346939, 0.7336734693877551, 0.7122448979591837, 0.7377551020408163, 0.7285714285714285, 0.7836734693877551, 0.7836734693877551, 0.7581632653061224, 0.8357142857142857, 0.8295918367346938, 0.8428571428571429, 0.8612244897959184, 0.8948979591836734, 0.8806122448979592, 0.9193877551020408, 0.8918367346938776, 0.9204081632653062, 0.9091836734693878, 0.9244897959183673, 0.9142857142857143, 0.9173469387755102, 0.9122448979591836, 0.9244897959183673, 0.9377551020408164, 0.923469387755102, 0.9275510204081633, 0.9193877551020408, 0.9153061224489796, 0.9408163265306122, 0.95, 0.9295918367346939, 0.9489795918367347, 0.939795918367347, 0.9326530612244898]\n",
      "acc_val: [0.25, 0.5, 0.6214285714285714, 0.7357142857142858, 0.7380952380952381, 0.6595238095238095, 0.7452380952380953, 0.7333333333333333, 0.7523809523809524, 0.75, 0.8047619047619048, 0.8714285714285714, 0.680952380952381, 0.8071428571428572, 0.9071428571428571, 0.8404761904761905, 0.9523809523809523, 0.9619047619047619, 0.9857142857142858, 0.9595238095238096, 0.9809523809523809, 0.9547619047619048, 0.9761904761904762, 0.9642857142857143, 0.9928571428571429, 0.969047619047619, 0.9, 0.9952380952380953, 0.9785714285714285, 0.9523809523809523, 1.0, 0.9976190476190476, 0.9952380952380953, 0.9976190476190476, 0.9976190476190476, 0.9166666666666666, 0.9857142857142858, 0.9714285714285714, 0.9833333333333333, 0.9761904761904762]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss(VGG13)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy(VGG13)\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(1, 41, 2.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:     81    77    75    75\n",
      "Predicted:     81    77    75    75\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('75', '77', '79', '81')\n",
    "\n",
    "dataiter = iter(dataloders['validation'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[z]] for z in range(4)))\n",
    "\n",
    "# test\n",
    "outputs = model(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[z]] for z in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   Predicted\n",
      "\n",
      "\t   75\t77\t79\t81\n",
      "\n",
      "Actual 75  105\t0\t0\t0\t\n",
      "\n",
      "Actual 77  0\t105\t0\t0\t\n",
      "\n",
      "Actual 79  0\t0\t105\t0\t\n",
      "\n",
      "Actual 81  0\t0\t0\t105\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conc = {\n",
    "    '0': '75  ',\n",
    "    '1': '77  ',\n",
    "    '2': '79  ',\n",
    "    '3': '81  '\n",
    "}\n",
    "\n",
    "print(\"\\t   Predicted\\n\")\n",
    "print(\"\\t   75\\t77\\t79\\t81\\n\")\n",
    "for i in range(0, num_classes):\n",
    "    print(\"Actual \", end='')\n",
    "    print(conc[str(i)], end='')\n",
    "    for j in range(0, num_classes):\n",
    "        print(str(best_matrix[i][j]) + '\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
