{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# 增加了test数据集\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "display_step = 1\n",
    "num_classes = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载vgg13预训练模型\n",
    "model = models.vgg13(pretrained=False)\n",
    "model.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(4096, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(4096, num_classes))\n",
    "# 使用多块GPU\n",
    "# model = nn.DataParallel(model)\n",
    "# model.load_state_dict(torch.load('./parameter/ash_sand_1_16_vgg13_params.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop:裁剪 resize:缩放 flip:翻转\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.396, 0.434, 0.435], [0.055, 0.053, 0.054])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.396, 0.434, 0.435], [0.055, 0.053, 0.054])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# your image data file\n",
    "data_dir = './images_paste/images_ash_sand_1_16/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'validation']}\n",
    "# torchvision.datasets.ImageFolder返回的是list，这里用torch.utils.data.DataLoader类将list类型的输入数据封装成Tensor数据格式\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True,\n",
    "                                             num_workers = 50) for x in ['train', 'validation']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.396, 0.434, 0.435], [0.055, 0.053, 0.054])\n",
    "])\n",
    "data_dir_test = './images_paste/images_ash_sand_1_16/test/'\n",
    "image_datasets_test = datasets.ImageFolder(data_dir_test, data_transforms_test)\n",
    "dataloders_test = torch.utils.data.DataLoader(image_datasets_test,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = False,\n",
    "                                             num_workers = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用GPU，定义相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu: True\n"
     ]
    }
   ],
   "source": [
    "# 是否使用GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(\"use_gpu: \" + str(use_gpu))\n",
    "    \n",
    "# 定义损失函数，这里采用交叉熵函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化函数，这里采用随机梯度下降法\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "\n",
    "# 定义学习率的变化策略，这里采用torch.optim.lr_scheduler模块的StepLR类，表示每隔step_size个epoch就将学习率降为原来的gamma倍\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(epoch, loss_list, test_loss_list):\n",
    "    clear_output(True)\n",
    "    plt.title('epoch %s. train loss: %s. val loss: %s' % (epoch, loss_list[-1], test_loss_list[-1]))\n",
    "    plt.plot(loss_list, color=\"r\", label=\"train loss\")\n",
    "    plt.plot(test_loss_list, color=\"b\", label=\"val loss\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig('./figure/best_track_last_unet_dilate_reloss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.01\n",
      "Epoch [1/10]:\n",
      "\ttrain 1-1: Loss: 0.1268 Acc: 3.3333%\n",
      "\ttrain 1-2: Loss: 0.1270 Acc: 3.3333%\n",
      "\ttrain 1-3: Loss: 0.1272 Acc: 3.3333%\n",
      "\ttrain 1-4: Loss: 0.1279 Acc: 0.0000%\n",
      "\ttrain 1-5: Loss: 0.1288 Acc: 0.0000%\n",
      "\ttrain 1-6: Loss: 0.1278 Acc: 0.0000%\n",
      "\ttrain 1-7: Loss: 0.1288 Acc: 3.3333%\n",
      "\ttrain 1-8: Loss: 0.1267 Acc: 6.6667%\n",
      "\ttrain 1-9: Loss: 0.1298 Acc: 6.6667%\n",
      "\ttrain 1-10: Loss: 0.1288 Acc: 0.0000%\n",
      "\ttrain 1-11: Loss: 0.1257 Acc: 3.3333%\n",
      "\ttrain 1-12: Loss: 0.1269 Acc: 0.0000%\n",
      "\ttrain 1-13: Loss: 0.1287 Acc: 0.0000%\n",
      "\ttrain 1-14: Loss: 0.1270 Acc: 0.0000%\n",
      "\ttrain 1-15: Loss: 0.1264 Acc: 6.6667%\n",
      "\ttrain 1-16: Loss: 0.1267 Acc: 6.6667%\n",
      "\ttrain 1-17: Loss: 0.1266 Acc: 3.3333%\n",
      "\ttrain 1-18: Loss: 0.1284 Acc: 0.0000%\n",
      "\ttrain 1-19: Loss: 0.1273 Acc: 0.0000%\n",
      "\ttrain 1-20: Loss: 0.1269 Acc: 3.3333%\n",
      "\ttrain 1-21: Loss: 0.1257 Acc: 6.6667%\n",
      "\ttrain 1-22: Loss: 0.1277 Acc: 0.0000%\n",
      "\ttrain 1-23: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-24: Loss: 0.1257 Acc: 6.6667%\n",
      "\ttrain 1-25: Loss: 0.1267 Acc: 0.0000%\n",
      "\ttrain 1-26: Loss: 0.1270 Acc: 0.0000%\n",
      "\ttrain 1-27: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-28: Loss: 0.1276 Acc: 3.3333%\n",
      "\ttrain 1-29: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-30: Loss: 0.1257 Acc: 0.0000%\n",
      "\ttrain 1-31: Loss: 0.1277 Acc: 0.0000%\n",
      "\ttrain 1-32: Loss: 0.1268 Acc: 3.3333%\n",
      "\ttrain 1-33: Loss: 0.1270 Acc: 3.3333%\n",
      "\ttrain 1-34: Loss: 0.1265 Acc: 6.6667%\n",
      "\ttrain 1-35: Loss: 0.1272 Acc: 0.0000%\n",
      "\ttrain 1-36: Loss: 0.1260 Acc: 3.3333%\n",
      "\ttrain 1-37: Loss: 0.1264 Acc: 3.3333%\n",
      "\ttrain 1-38: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-39: Loss: 0.1260 Acc: 6.6667%\n",
      "\ttrain 1-40: Loss: 0.1264 Acc: 3.3333%\n",
      "\ttrain 1-41: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-42: Loss: 0.1253 Acc: 3.3333%\n",
      "\ttrain 1-43: Loss: 0.1247 Acc: 10.0000%\n",
      "\ttrain 1-44: Loss: 0.1264 Acc: 6.6667%\n",
      "\ttrain 1-45: Loss: 0.1247 Acc: 6.6667%\n",
      "\ttrain 1-46: Loss: 0.1272 Acc: 3.3333%\n",
      "\ttrain 1-47: Loss: 0.1256 Acc: 3.3333%\n",
      "\ttrain 1-48: Loss: 0.1276 Acc: 3.3333%\n",
      "\ttrain 1-49: Loss: 0.1251 Acc: 0.0000%\n",
      "\ttrain 1-50: Loss: 0.1231 Acc: 6.6667%\n",
      "\ttrain 1-51: Loss: 0.1284 Acc: 0.0000%\n",
      "\ttrain 1-52: Loss: 0.1239 Acc: 3.3333%\n",
      "\ttrain 1-53: Loss: 0.1276 Acc: 0.0000%\n",
      "\ttrain 1-54: Loss: 0.1256 Acc: 0.0000%\n",
      "\ttrain 1-55: Loss: 0.1252 Acc: 3.3333%\n",
      "\ttrain 1-56: Loss: 0.1238 Acc: 3.3333%\n",
      "\ttrain 1-57: Loss: 0.1249 Acc: 0.0000%\n",
      "\ttrain 1-58: Loss: 0.1233 Acc: 0.0000%\n",
      "\ttrain 1-59: Loss: 0.1273 Acc: 3.3333%\n",
      "\ttrain 1-60: Loss: 0.1243 Acc: 0.0000%\n",
      "\ttrain 1-61: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-62: Loss: 0.1200 Acc: 3.3333%\n",
      "\ttrain 1-63: Loss: 0.1255 Acc: 3.3333%\n",
      "\ttrain 1-64: Loss: 0.1220 Acc: 3.3333%\n",
      "\ttrain 1-65: Loss: 0.1229 Acc: 0.0000%\n",
      "\ttrain 1-66: Loss: 0.1195 Acc: 6.6667%\n",
      "\ttrain 1-67: Loss: 0.1178 Acc: 6.6667%\n",
      "\ttrain 1-68: Loss: 0.1222 Acc: 0.0000%\n",
      "\ttrain 1-69: Loss: 0.1228 Acc: 0.0000%\n",
      "\ttrain 1-70: Loss: 0.1216 Acc: 6.6667%\n",
      "\ttrain 1-71: Loss: 0.1208 Acc: 0.0000%\n",
      "\ttrain 1-72: Loss: 0.1226 Acc: 0.0000%\n",
      "\ttrain 1-73: Loss: 0.1170 Acc: 6.6667%\n",
      "\ttrain 1-74: Loss: 0.1204 Acc: 0.0000%\n",
      "\ttrain 1-75: Loss: 0.1203 Acc: 0.0000%\n",
      "\ttrain 1-76: Loss: 0.1217 Acc: 3.3333%\n",
      "\ttrain 1-77: Loss: 0.1185 Acc: 6.6667%\n",
      "\ttrain 1-78: Loss: 0.1241 Acc: 0.0000%\n",
      "\ttrain 1-79: Loss: 0.1185 Acc: 3.3333%\n",
      "\ttrain 1-80: Loss: 0.1150 Acc: 0.0000%\n",
      "\ttrain 1-81: Loss: 0.1204 Acc: 0.0000%\n",
      "\ttrain 1-82: Loss: 0.1161 Acc: 6.6667%\n",
      "\ttrain 1-83: Loss: 0.1158 Acc: 3.3333%\n",
      "\ttrain 1-84: Loss: 0.1247 Acc: 3.3333%\n",
      "\ttrain 1-85: Loss: 0.1246 Acc: 3.3333%\n",
      "\ttrain 1-86: Loss: 0.1213 Acc: 0.0000%\n",
      "\ttrain 1-87: Loss: 0.1171 Acc: 13.3333%\n",
      "\ttrain 1-88: Loss: 0.1207 Acc: 6.6667%\n",
      "\ttrain 1-89: Loss: 0.1175 Acc: 10.0000%\n",
      "\ttrain 1-90: Loss: 0.1165 Acc: 3.3333%\n",
      "\ttrain 1-91: Loss: 0.1227 Acc: 0.0000%\n",
      "\ttrain 1-92: Loss: 0.1183 Acc: 3.3333%\n",
      "\ttrain 1-93: Loss: 0.1224 Acc: 3.3333%\n",
      "\ttrain 1-94: Loss: 0.1200 Acc: 0.0000%\n",
      "\ttrain 1-95: Loss: 0.1153 Acc: 0.0000%\n",
      "\ttrain 1-96: Loss: 0.1199 Acc: 3.3333%\n",
      "\ttrain 1-97: Loss: 0.1152 Acc: 10.0000%\n",
      "\ttrain 1-98: Loss: 0.1197 Acc: 6.6667%\n",
      "\ttrain 1-99: Loss: 0.1230 Acc: 0.0000%\n",
      "\ttrain 1-100: Loss: 0.1156 Acc: 6.6667%\n",
      "\ttrain 1-101: Loss: 0.1284 Acc: 0.0000%\n",
      "\ttrain 1-102: Loss: 0.1253 Acc: 3.3333%\n",
      "\ttrain 1-103: Loss: 0.1246 Acc: 13.3333%\n",
      "\ttrain 1-104: Loss: 0.1248 Acc: 3.3333%\n",
      "\ttrain 1-105: Loss: 0.1166 Acc: 10.0000%\n",
      "\ttrain 1-106: Loss: 0.1443 Acc: 3.3333%\n",
      "\ttrain 1-107: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-108: Loss: 0.1267 Acc: 3.3333%\n",
      "\ttrain 1-109: Loss: 0.1267 Acc: 0.0000%\n",
      "\ttrain 1-110: Loss: 0.1269 Acc: 3.3333%\n",
      "\ttrain 1-111: Loss: 0.1272 Acc: 3.3333%\n",
      "\ttrain 1-112: Loss: 0.1268 Acc: 6.6667%\n",
      "\ttrain 1-113: Loss: 0.1269 Acc: 3.3333%\n",
      "\ttrain 1-114: Loss: 0.1270 Acc: 3.3333%\n",
      "\ttrain 1-115: Loss: 0.1272 Acc: 0.0000%\n",
      "\ttrain 1-116: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-117: Loss: 0.1265 Acc: 6.6667%\n",
      "\ttrain 1-118: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-119: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-120: Loss: 0.1267 Acc: 3.3333%\n",
      "\ttrain 1-121: Loss: 0.1274 Acc: 0.0000%\n",
      "\ttrain 1-122: Loss: 0.1274 Acc: 0.0000%\n",
      "\ttrain 1-123: Loss: 0.1251 Acc: 6.6667%\n",
      "\ttrain 1-124: Loss: 0.1262 Acc: 0.0000%\n",
      "\ttrain 1-125: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-126: Loss: 0.1266 Acc: 0.0000%\n",
      "\ttrain 1-127: Loss: 0.1259 Acc: 0.0000%\n",
      "\ttrain 1-128: Loss: 0.1255 Acc: 6.6667%\n",
      "\ttrain 1-129: Loss: 0.1251 Acc: 3.3333%\n",
      "\ttrain 1-130: Loss: 0.1258 Acc: 3.3333%\n",
      "\ttrain 1-131: Loss: 0.1233 Acc: 6.6667%\n",
      "\ttrain 1-132: Loss: 0.1259 Acc: 6.6667%\n",
      "\ttrain 1-133: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-134: Loss: 0.1242 Acc: 3.3333%\n",
      "\ttrain 1-135: Loss: 0.1233 Acc: 3.3333%\n",
      "\ttrain 1-136: Loss: 0.1248 Acc: 3.3333%\n",
      "\ttrain 1-137: Loss: 0.1264 Acc: 0.0000%\n",
      "\ttrain 1-138: Loss: 0.1246 Acc: 0.0000%\n",
      "\ttrain 1-139: Loss: 0.1246 Acc: 3.3333%\n",
      "\ttrain 1-140: Loss: 0.1239 Acc: 3.3333%\n",
      "\ttrain 1-141: Loss: 0.1229 Acc: 13.3333%\n",
      "\ttrain 1-142: Loss: 0.1211 Acc: 10.0000%\n",
      "\ttrain 1-143: Loss: 0.1216 Acc: 10.0000%\n",
      "\ttrain 1-144: Loss: 0.1221 Acc: 3.3333%\n",
      "\ttrain 1-145: Loss: 0.1197 Acc: 6.6667%\n",
      "\ttrain 1-146: Loss: 0.1220 Acc: 3.3333%\n",
      "\ttrain 1-147: Loss: 0.1184 Acc: 6.6667%\n",
      "\ttrain 1-148: Loss: 0.1226 Acc: 3.3333%\n",
      "\ttrain 1-149: Loss: 0.1228 Acc: 10.0000%\n",
      "\ttrain 1-150: Loss: 0.1265 Acc: 3.3333%\n",
      "\ttrain 1-151: Loss: 0.1275 Acc: 3.3333%\n",
      "\ttrain 1-152: Loss: 0.1270 Acc: 3.3333%\n",
      "\ttrain 1-153: Loss: 0.1273 Acc: 0.0000%\n",
      "\ttrain 1-154: Loss: 0.1251 Acc: 10.0000%\n",
      "\ttrain 1-155: Loss: 0.1281 Acc: 0.0000%\n",
      "\ttrain 1-156: Loss: 0.1276 Acc: 3.3333%\n",
      "\ttrain 1-157: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-158: Loss: 0.1273 Acc: 3.3333%\n",
      "\ttrain 1-159: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-160: Loss: 0.1265 Acc: 0.0000%\n",
      "\ttrain 1-161: Loss: 0.1279 Acc: 0.0000%\n",
      "\ttrain 1-162: Loss: 0.1270 Acc: 0.0000%\n",
      "\ttrain 1-163: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-164: Loss: 0.1287 Acc: 0.0000%\n",
      "\ttrain 1-165: Loss: 0.1260 Acc: 3.3333%\n",
      "\ttrain 1-166: Loss: 0.1271 Acc: 3.3333%\n",
      "\ttrain 1-167: Loss: 0.1247 Acc: 3.3333%\n",
      "\ttrain 1-168: Loss: 0.1263 Acc: 6.6667%\n",
      "\ttrain 1-169: Loss: 0.1266 Acc: 3.3333%\n",
      "\ttrain 1-170: Loss: 0.1262 Acc: 3.3333%\n",
      "\ttrain 1-171: Loss: 0.1259 Acc: 3.3333%\n",
      "\ttrain 1-172: Loss: 0.1261 Acc: 0.0000%\n",
      "\ttrain 1-173: Loss: 0.1277 Acc: 0.0000%\n",
      "\ttrain 1-174: Loss: 0.1292 Acc: 0.0000%\n",
      "\ttrain 1-175: Loss: 0.1269 Acc: 0.0000%\n",
      "\ttrain 1-176: Loss: 0.1261 Acc: 0.0000%\n",
      "\ttrain 1-177: Loss: 0.1276 Acc: 0.0000%\n",
      "\ttrain 1-178: Loss: 0.1261 Acc: 6.6667%\n",
      "\ttrain 1-179: Loss: 0.1258 Acc: 6.6667%\n",
      "\ttrain 1-180: Loss: 0.1258 Acc: 0.0000%\n",
      "\ttrain 1-181: Loss: 0.1253 Acc: 10.0000%\n",
      "\ttrain 1-182: Loss: 0.1251 Acc: 3.3333%\n",
      "\ttrain 1-183: Loss: 0.1250 Acc: 0.0000%\n",
      "\ttrain 1-184: Loss: 0.1265 Acc: 3.3333%\n",
      "\ttrain 1-185: Loss: 0.1274 Acc: 3.3333%\n",
      "\ttrain 1-186: Loss: 0.1229 Acc: 3.3333%\n",
      "\ttrain 1-187: Loss: 0.1272 Acc: 0.0000%\n",
      "\ttrain 1-188: Loss: 0.1238 Acc: 3.3333%\n",
      "\ttrain 1-189: Loss: 0.1219 Acc: 10.0000%\n",
      "\ttrain 1-190: Loss: 0.1282 Acc: 0.0000%\n",
      "\ttrain 1-191: Loss: 0.1271 Acc: 0.0000%\n",
      "\ttrain 1-192: Loss: 0.1222 Acc: 6.6667%\n",
      "\ttrain 1-193: Loss: 0.1243 Acc: 0.0000%\n",
      "\ttrain 1-194: Loss: 0.1241 Acc: 3.3333%\n",
      "\ttrain 1-195: Loss: 0.1219 Acc: 0.0000%\n",
      "\ttrain 1-196: Loss: 0.1227 Acc: 3.3333%\n",
      "\ttrain 1-197: Loss: 0.1264 Acc: 0.0000%\n",
      "\ttrain 1-198: Loss: 0.1215 Acc: 6.6667%\n",
      "\ttrain 1-199: Loss: 0.1202 Acc: 3.3333%\n",
      "\ttrain 1-200: Loss: 0.1260 Acc: 0.0000%\n",
      "\ttrain 1-201: Loss: 0.1173 Acc: 0.0000%\n",
      "\ttrain 1-202: Loss: 0.1230 Acc: 10.0000%\n",
      "\ttrain 1-203: Loss: 0.1196 Acc: 6.6667%\n",
      "\ttrain 1-204: Loss: 0.1201 Acc: 3.3333%\n",
      "\ttrain 1-205: Loss: 0.1224 Acc: 3.3333%\n",
      "\ttrain 1-206: Loss: 0.1198 Acc: 3.3333%\n",
      "\ttrain 1-207: Loss: 0.1170 Acc: 6.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-208: Loss: 0.1160 Acc: 13.3333%\n",
      "\ttrain 1-209: Loss: 0.1199 Acc: 0.0000%\n",
      "\ttrain 1-210: Loss: 0.1133 Acc: 6.6667%\n",
      "\ttrain 1-211: Loss: 0.1235 Acc: 6.6667%\n",
      "\ttrain 1-212: Loss: 0.1146 Acc: 10.0000%\n",
      "\ttrain 1-213: Loss: 0.1180 Acc: 0.0000%\n",
      "\ttrain 1-214: Loss: 0.1237 Acc: 3.3333%\n",
      "\ttrain 1-215: Loss: 0.1197 Acc: 6.6667%\n",
      "\ttrain 1-216: Loss: 0.1189 Acc: 3.3333%\n",
      "\ttrain 1-217: Loss: 0.1111 Acc: 0.0000%\n",
      "\ttrain 1-218: Loss: 0.1166 Acc: 10.0000%\n",
      "\ttrain 1-219: Loss: 0.1244 Acc: 3.3333%\n",
      "\ttrain 1-220: Loss: 0.1107 Acc: 10.0000%\n",
      "\ttrain 1-221: Loss: 0.1142 Acc: 13.3333%\n",
      "\ttrain 1-222: Loss: 0.1099 Acc: 10.0000%\n",
      "\ttrain 1-223: Loss: 0.1122 Acc: 3.3333%\n",
      "\ttrain 1-224: Loss: 0.1187 Acc: 3.3333%\n",
      "\ttrain 1-225: Loss: 0.1098 Acc: 6.6667%\n",
      "\ttrain 1-226: Loss: 0.1166 Acc: 10.0000%\n",
      "\ttrain 1-227: Loss: 0.1133 Acc: 10.0000%\n",
      "\ttrain 1-228: Loss: 0.1090 Acc: 3.3333%\n",
      "\ttrain 1-229: Loss: 0.1118 Acc: 6.6667%\n",
      "\ttrain 1-230: Loss: 0.1136 Acc: 3.3333%\n",
      "\ttrain 1-231: Loss: 0.1175 Acc: 6.6667%\n",
      "\ttrain 1-232: Loss: 0.1066 Acc: 20.0000%\n",
      "\ttrain 1-233: Loss: 0.1210 Acc: 3.3333%\n",
      "\ttrain 1-234: Loss: 0.1126 Acc: 10.0000%\n",
      "\ttrain 1-235: Loss: 0.1145 Acc: 6.6667%\n",
      "\ttrain 1-236: Loss: 0.1135 Acc: 13.3333%\n",
      "\ttrain 1-237: Loss: 0.1070 Acc: 10.0000%\n",
      "\ttrain 1-238: Loss: 0.1324 Acc: 3.3333%\n",
      "\ttrain 1-239: Loss: 0.1088 Acc: 10.0000%\n",
      "\ttrain 1-240: Loss: 0.1166 Acc: 10.0000%\n",
      "\ttrain 1-241: Loss: 0.1115 Acc: 6.6667%\n",
      "\ttrain 1-242: Loss: 0.1132 Acc: 10.0000%\n",
      "\ttrain 1-243: Loss: 0.1079 Acc: 10.0000%\n",
      "\ttrain 1-244: Loss: 0.1184 Acc: 10.0000%\n",
      "\ttrain 1-245: Loss: 0.1183 Acc: 3.3333%\n",
      "\ttrain 1-246: Loss: 0.1165 Acc: 3.3333%\n",
      "\ttrain 1-247: Loss: 0.1191 Acc: 3.3333%\n",
      "\ttrain 1-248: Loss: 0.1191 Acc: 10.0000%\n",
      "\ttrain 1-249: Loss: 0.1163 Acc: 6.6667%\n",
      "\ttrain 1-250: Loss: 0.1109 Acc: 6.6667%\n",
      "\ttrain 1-251: Loss: 0.1112 Acc: 13.3333%\n",
      "\ttrain 1-252: Loss: 0.1347 Acc: 3.3333%\n",
      "\ttrain 1-253: Loss: 0.1176 Acc: 3.3333%\n",
      "\ttrain 1-254: Loss: 0.1140 Acc: 3.3333%\n",
      "\ttrain 1-255: Loss: 0.1139 Acc: 13.3333%\n",
      "\ttrain 1-256: Loss: 0.1128 Acc: 3.3333%\n",
      "\ttrain 1-257: Loss: 0.1142 Acc: 10.0000%\n",
      "\ttrain 1-258: Loss: 0.1126 Acc: 6.6667%\n",
      "\ttrain 1-259: Loss: 0.1164 Acc: 10.0000%\n",
      "\ttrain 1-260: Loss: 0.1146 Acc: 6.6667%\n",
      "\ttrain 1-261: Loss: 0.1065 Acc: 16.6667%\n",
      "\ttrain 1-262: Loss: 0.1006 Acc: 13.3333%\n",
      "\ttrain 1-263: Loss: 0.1023 Acc: 10.0000%\n",
      "\ttrain 1-264: Loss: 0.1129 Acc: 10.0000%\n",
      "\ttrain 1-265: Loss: 0.1054 Acc: 16.6667%\n",
      "\ttrain 1-266: Loss: 0.1064 Acc: 3.3333%\n",
      "\ttrain 1-267: Loss: 0.1100 Acc: 3.3333%\n",
      "\ttrain 1-268: Loss: 0.1050 Acc: 13.3333%\n",
      "\ttrain 1-269: Loss: 0.1196 Acc: 13.3333%\n",
      "\ttrain 1-270: Loss: 0.1105 Acc: 6.6667%\n",
      "\ttrain 1-271: Loss: 0.1048 Acc: 6.6667%\n",
      "\ttrain 1-272: Loss: 0.1134 Acc: 10.0000%\n",
      "\ttrain 1-273: Loss: 0.1093 Acc: 6.6667%\n",
      "\ttrain 1-274: Loss: 0.1055 Acc: 10.0000%\n",
      "\ttrain 1-275: Loss: 0.1111 Acc: 23.3333%\n",
      "\ttrain 1-276: Loss: 0.1147 Acc: 3.3333%\n",
      "\ttrain 1-277: Loss: 0.1054 Acc: 3.3333%\n",
      "\ttrain 1-278: Loss: 0.1117 Acc: 6.6667%\n",
      "\ttrain 1-279: Loss: 0.1129 Acc: 3.3333%\n",
      "\ttrain 1-280: Loss: 0.1074 Acc: 3.3333%\n",
      "\ttrain 1-281: Loss: 0.1070 Acc: 13.3333%\n",
      "\ttrain 1-282: Loss: 0.0991 Acc: 10.0000%\n",
      "\ttrain 1-283: Loss: 0.0899 Acc: 30.0000%\n",
      "\ttrain 1-284: Loss: 0.1137 Acc: 3.3333%\n",
      "\ttrain 1-285: Loss: 0.1079 Acc: 10.0000%\n",
      "\ttrain 1-286: Loss: 0.1002 Acc: 23.3333%\n",
      "\ttrain 1-287: Loss: 0.1133 Acc: 0.0000%\n",
      "\ttrain 1-288: Loss: 0.1068 Acc: 13.3333%\n",
      "\ttrain 1-289: Loss: 0.1032 Acc: 10.0000%\n",
      "\ttrain 1-290: Loss: 0.0968 Acc: 16.6667%\n",
      "\ttrain 1-291: Loss: 0.1053 Acc: 6.6667%\n",
      "\ttrain 1-292: Loss: 0.0992 Acc: 10.0000%\n",
      "\ttrain 1-293: Loss: 0.1095 Acc: 10.0000%\n",
      "\ttrain 1-294: Loss: 0.1017 Acc: 10.0000%\n",
      "\ttrain 1-295: Loss: 0.1087 Acc: 10.0000%\n",
      "\ttrain 1-296: Loss: 0.0945 Acc: 26.6667%\n",
      "\ttrain 1-297: Loss: 0.1043 Acc: 10.0000%\n",
      "\ttrain 1-298: Loss: 0.1153 Acc: 10.0000%\n",
      "\ttrain 1-299: Loss: 0.1032 Acc: 10.0000%\n",
      "\ttrain 1-300: Loss: 0.1049 Acc: 6.6667%\n",
      "\ttrain 1-301: Loss: 0.0972 Acc: 13.3333%\n",
      "\ttrain 1-302: Loss: 0.1004 Acc: 16.6667%\n",
      "\ttrain 1-303: Loss: 0.0965 Acc: 16.6667%\n",
      "\ttrain 1-304: Loss: 0.0983 Acc: 10.0000%\n",
      "\ttrain 1-305: Loss: 0.0951 Acc: 20.0000%\n",
      "\ttrain 1-306: Loss: 0.1071 Acc: 6.6667%\n",
      "\ttrain 1-307: Loss: 0.1049 Acc: 6.6667%\n",
      "\ttrain 1-308: Loss: 0.0926 Acc: 13.3333%\n",
      "\ttrain 1-309: Loss: 0.0998 Acc: 3.3333%\n",
      "\ttrain 1-310: Loss: 0.1014 Acc: 13.3333%\n",
      "\ttrain 1-311: Loss: 0.0976 Acc: 13.3333%\n",
      "\ttrain 1-312: Loss: 0.0927 Acc: 30.0000%\n",
      "\ttrain 1-313: Loss: 0.0966 Acc: 10.0000%\n",
      "\ttrain 1-314: Loss: 0.0971 Acc: 10.0000%\n",
      "\ttrain 1-315: Loss: 0.0895 Acc: 13.3333%\n",
      "\ttrain 1-316: Loss: 0.0948 Acc: 16.6667%\n",
      "\ttrain 1-317: Loss: 0.0940 Acc: 16.6667%\n",
      "\ttrain 1-318: Loss: 0.0902 Acc: 20.0000%\n",
      "\ttrain 1-319: Loss: 0.0996 Acc: 16.6667%\n",
      "\ttrain 1-320: Loss: 0.0961 Acc: 16.6667%\n",
      "\ttrain 1-321: Loss: 0.1022 Acc: 10.0000%\n",
      "\ttrain 1-322: Loss: 0.1075 Acc: 16.6667%\n",
      "\ttrain 1-323: Loss: 0.1074 Acc: 13.3333%\n",
      "\ttrain 1-324: Loss: 0.0972 Acc: 6.6667%\n",
      "\ttrain 1-325: Loss: 0.0963 Acc: 16.6667%\n",
      "\ttrain 1-326: Loss: 0.0938 Acc: 26.6667%\n",
      "\ttrain 1-327: Loss: 0.1004 Acc: 16.6667%\n",
      "\ttrain 1-328: Loss: 0.1006 Acc: 16.6667%\n",
      "\ttrain 1-329: Loss: 0.0975 Acc: 30.0000%\n",
      "\ttrain 1-330: Loss: 0.1009 Acc: 6.6667%\n",
      "\ttrain 1-331: Loss: 0.0965 Acc: 23.3333%\n",
      "\ttrain 1-332: Loss: 0.1005 Acc: 10.0000%\n",
      "\ttrain 1-333: Loss: 0.0894 Acc: 26.6667%\n",
      "\ttrain 1-334: Loss: 0.0824 Acc: 43.3333%\n",
      "\ttrain 1-335: Loss: 0.1114 Acc: 16.6667%\n",
      "\ttrain 1-336: Loss: 0.0979 Acc: 20.0000%\n",
      "\ttrain 1-337: Loss: 0.0918 Acc: 20.0000%\n",
      "\ttrain 1-338: Loss: 0.0903 Acc: 23.3333%\n",
      "\ttrain 1-339: Loss: 0.0971 Acc: 10.0000%\n",
      "\ttrain 1-340: Loss: 0.0956 Acc: 16.6667%\n",
      "\ttrain 1-341: Loss: 0.0954 Acc: 23.3333%\n",
      "\ttrain 1-342: Loss: 0.1011 Acc: 16.6667%\n",
      "\ttrain 1-343: Loss: 0.0852 Acc: 20.0000%\n",
      "\ttrain 1-344: Loss: 0.0802 Acc: 33.3333%\n",
      "\ttrain 1-345: Loss: 0.1049 Acc: 20.0000%\n",
      "\ttrain 1-346: Loss: 0.0958 Acc: 30.0000%\n",
      "\ttrain 1-347: Loss: 0.0889 Acc: 26.6667%\n",
      "\ttrain 1-348: Loss: 0.0876 Acc: 20.0000%\n",
      "\ttrain 1-349: Loss: 0.0894 Acc: 20.0000%\n",
      "\ttrain 1-350: Loss: 0.0925 Acc: 20.0000%\n",
      "\ttrain 1-351: Loss: 0.0945 Acc: 13.3333%\n",
      "\ttrain 1-352: Loss: 0.0867 Acc: 16.6667%\n",
      "\ttrain 1-353: Loss: 0.0842 Acc: 23.3333%\n",
      "\ttrain 1-354: Loss: 0.0905 Acc: 23.3333%\n",
      "\ttrain 1-355: Loss: 0.0860 Acc: 16.6667%\n",
      "\ttrain 1-356: Loss: 0.0868 Acc: 16.6667%\n",
      "\ttrain 1-357: Loss: 0.0896 Acc: 26.6667%\n",
      "\ttrain 1-358: Loss: 0.0774 Acc: 33.3333%\n",
      "\ttrain 1-359: Loss: 0.0831 Acc: 20.0000%\n",
      "\ttrain 1-360: Loss: 0.0928 Acc: 20.0000%\n",
      "\ttrain 1-361: Loss: 0.0783 Acc: 30.0000%\n",
      "\ttrain 1-362: Loss: 0.0909 Acc: 26.6667%\n",
      "\ttrain 1-363: Loss: 0.0843 Acc: 33.3333%\n",
      "\ttrain 1-364: Loss: 0.1034 Acc: 16.6667%\n",
      "\ttrain 1-365: Loss: 0.0869 Acc: 13.3333%\n",
      "\ttrain 1-366: Loss: 0.0998 Acc: 13.3333%\n",
      "\ttrain 1-367: Loss: 0.0898 Acc: 16.6667%\n",
      "\ttrain 1-368: Loss: 0.0925 Acc: 23.3333%\n",
      "\ttrain 1-369: Loss: 0.0985 Acc: 10.0000%\n",
      "\ttrain 1-370: Loss: 0.0899 Acc: 16.6667%\n",
      "\ttrain 1-371: Loss: 0.1052 Acc: 13.3333%\n",
      "\ttrain 1-372: Loss: 0.0923 Acc: 13.3333%\n",
      "\ttrain 1-373: Loss: 0.0920 Acc: 13.3333%\n",
      "\ttrain 1-374: Loss: 0.0892 Acc: 30.0000%\n",
      "\ttrain 1-375: Loss: 0.0749 Acc: 40.0000%\n",
      "\ttrain 1-376: Loss: 0.1044 Acc: 16.6667%\n",
      "\ttrain 1-377: Loss: 0.0826 Acc: 26.6667%\n",
      "\ttrain 1-378: Loss: 0.0764 Acc: 36.6667%\n",
      "\ttrain 1-379: Loss: 0.1148 Acc: 23.3333%\n",
      "\ttrain 1-380: Loss: 0.0850 Acc: 23.3333%\n",
      "\ttrain 1-381: Loss: 0.0878 Acc: 20.0000%\n",
      "\ttrain 1-382: Loss: 0.0854 Acc: 20.0000%\n",
      "\ttrain 1-383: Loss: 0.0896 Acc: 20.0000%\n",
      "\ttrain 1-384: Loss: 0.0829 Acc: 10.0000%\n",
      "\ttrain 1-385: Loss: 0.0824 Acc: 26.6667%\n",
      "\ttrain 1-386: Loss: 0.0934 Acc: 6.6667%\n",
      "\ttrain 1-387: Loss: 0.0843 Acc: 30.0000%\n",
      "\ttrain 1-388: Loss: 0.0855 Acc: 26.6667%\n",
      "\ttrain 1-389: Loss: 0.0913 Acc: 23.3333%\n",
      "\ttrain 1-390: Loss: 0.0785 Acc: 26.6667%\n",
      "\ttrain 1-391: Loss: 0.0751 Acc: 26.6667%\n",
      "\ttrain 1-392: Loss: 0.0783 Acc: 26.6667%\n",
      "\ttrain 1-393: Loss: 0.0806 Acc: 20.0000%\n",
      "\ttrain 1-394: Loss: 0.0783 Acc: 26.6667%\n",
      "\ttrain 1-395: Loss: 0.0759 Acc: 26.6667%\n",
      "\ttrain 1-396: Loss: 0.0756 Acc: 30.0000%\n",
      "\ttrain 1-397: Loss: 0.0828 Acc: 26.6667%\n",
      "\ttrain 1-398: Loss: 0.0811 Acc: 16.6667%\n",
      "\ttrain 1-399: Loss: 0.0843 Acc: 20.0000%\n",
      "\ttrain 1-400: Loss: 0.0722 Acc: 33.3333%\n",
      "\ttrain 1-401: Loss: 0.0917 Acc: 10.0000%\n",
      "\ttrain 1-402: Loss: 0.0801 Acc: 43.3333%\n",
      "\ttrain 1-403: Loss: 0.0778 Acc: 26.6667%\n",
      "\ttrain 1-404: Loss: 0.0841 Acc: 23.3333%\n",
      "\ttrain 1-405: Loss: 0.0799 Acc: 33.3333%\n",
      "\ttrain 1-406: Loss: 0.0801 Acc: 20.0000%\n",
      "\ttrain 1-407: Loss: 0.0830 Acc: 16.6667%\n",
      "\ttrain 1-408: Loss: 0.0751 Acc: 26.6667%\n",
      "\ttrain 1-409: Loss: 0.0779 Acc: 33.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-410: Loss: 0.0785 Acc: 23.3333%\n",
      "\ttrain 1-411: Loss: 0.0868 Acc: 23.3333%\n",
      "\ttrain 1-412: Loss: 0.0707 Acc: 26.6667%\n",
      "\ttrain 1-413: Loss: 0.0699 Acc: 33.3333%\n",
      "\ttrain 1-414: Loss: 0.0892 Acc: 23.3333%\n",
      "\ttrain 1-415: Loss: 0.0910 Acc: 10.0000%\n",
      "\ttrain 1-416: Loss: 0.0686 Acc: 43.3333%\n",
      "\ttrain 1-417: Loss: 0.0754 Acc: 40.0000%\n",
      "\ttrain 1-418: Loss: 0.0655 Acc: 40.0000%\n",
      "\ttrain 1-419: Loss: 0.0789 Acc: 23.3333%\n",
      "\ttrain 1-420: Loss: 0.0779 Acc: 30.0000%\n",
      "\ttrain 1-421: Loss: 0.0775 Acc: 16.6667%\n",
      "\ttrain 1-422: Loss: 0.0669 Acc: 40.0000%\n",
      "\ttrain 1-423: Loss: 0.0862 Acc: 13.3333%\n",
      "\ttrain 1-424: Loss: 0.0809 Acc: 40.0000%\n",
      "\ttrain 1-425: Loss: 0.0812 Acc: 20.0000%\n",
      "\ttrain 1-426: Loss: 0.0781 Acc: 20.0000%\n",
      "\ttrain 1-427: Loss: 0.0779 Acc: 30.0000%\n",
      "\ttrain 1-428: Loss: 0.0724 Acc: 36.6667%\n",
      "\ttrain 1-429: Loss: 0.0788 Acc: 26.6667%\n",
      "\ttrain 1-430: Loss: 0.0549 Acc: 46.6667%\n",
      "\ttrain 1-431: Loss: 0.0764 Acc: 33.3333%\n",
      "\ttrain 1-432: Loss: 0.1017 Acc: 20.0000%\n",
      "\ttrain 1-433: Loss: 0.0740 Acc: 33.3333%\n",
      "\ttrain 1-434: Loss: 0.0765 Acc: 30.0000%\n",
      "\ttrain 1-435: Loss: 0.0858 Acc: 20.0000%\n",
      "\ttrain 1-436: Loss: 0.0866 Acc: 23.3333%\n",
      "\ttrain 1-437: Loss: 0.0762 Acc: 36.6667%\n",
      "\ttrain 1-438: Loss: 0.0707 Acc: 36.6667%\n",
      "\ttrain 1-439: Loss: 0.0817 Acc: 36.6667%\n",
      "\ttrain 1-440: Loss: 0.0959 Acc: 26.6667%\n",
      "\ttrain 1-441: Loss: 0.0773 Acc: 23.3333%\n",
      "\ttrain 1-442: Loss: 0.0842 Acc: 20.0000%\n",
      "\ttrain 1-443: Loss: 0.0795 Acc: 26.6667%\n",
      "\ttrain 1-444: Loss: 0.0722 Acc: 43.3333%\n",
      "\ttrain 1-445: Loss: 0.0664 Acc: 26.6667%\n",
      "\ttrain 1-446: Loss: 0.0751 Acc: 20.0000%\n",
      "\ttrain 1-447: Loss: 0.0819 Acc: 30.0000%\n",
      "\ttrain 1-448: Loss: 0.0756 Acc: 26.6667%\n",
      "\ttrain 1-449: Loss: 0.0684 Acc: 26.6667%\n",
      "\ttrain 1-450: Loss: 0.0772 Acc: 30.0000%\n",
      "\ttrain 1-451: Loss: 0.0744 Acc: 26.6667%\n",
      "\ttrain 1-452: Loss: 0.0836 Acc: 23.3333%\n",
      "\ttrain 1-453: Loss: 0.0672 Acc: 40.0000%\n",
      "\ttrain 1-454: Loss: 0.0747 Acc: 33.3333%\n",
      "\ttrain 1-455: Loss: 0.0649 Acc: 36.6667%\n",
      "\ttrain 1-456: Loss: 0.0788 Acc: 33.3333%\n",
      "\ttrain 1-457: Loss: 0.0729 Acc: 33.3333%\n",
      "\ttrain 1-458: Loss: 0.0669 Acc: 40.0000%\n",
      "\ttrain 1-459: Loss: 0.0704 Acc: 26.6667%\n",
      "\ttrain 1-460: Loss: 0.0718 Acc: 26.6667%\n",
      "\ttrain 1-461: Loss: 0.0786 Acc: 26.6667%\n",
      "\ttrain 1-462: Loss: 0.0738 Acc: 30.0000%\n",
      "\ttrain 1-463: Loss: 0.0778 Acc: 23.3333%\n",
      "\ttrain 1-464: Loss: 0.0675 Acc: 23.3333%\n",
      "\ttrain 1-465: Loss: 0.0665 Acc: 43.3333%\n",
      "\ttrain 1-466: Loss: 0.0686 Acc: 26.6667%\n",
      "\ttrain 1-467: Loss: 0.0707 Acc: 30.0000%\n",
      "\ttrain 1-468: Loss: 0.0604 Acc: 50.0000%\n",
      "\ttrain 1-469: Loss: 0.0497 Acc: 50.0000%\n",
      "\ttrain 1-470: Loss: 0.0515 Acc: 46.6667%\n",
      "\ttrain 1-471: Loss: 0.0663 Acc: 33.3333%\n",
      "\ttrain 1-472: Loss: 0.0589 Acc: 30.0000%\n",
      "\ttrain 1-473: Loss: 0.0746 Acc: 30.0000%\n",
      "\ttrain 1-474: Loss: 0.0704 Acc: 33.3333%\n",
      "\ttrain 1-475: Loss: 0.0819 Acc: 36.6667%\n",
      "\ttrain 1-476: Loss: 0.0660 Acc: 46.6667%\n",
      "\ttrain 1-477: Loss: 0.0586 Acc: 43.3333%\n",
      "\ttrain 1-478: Loss: 0.0750 Acc: 33.3333%\n",
      "\ttrain 1-479: Loss: 0.0575 Acc: 40.0000%\n",
      "\ttrain 1-480: Loss: 0.0651 Acc: 30.0000%\n",
      "\ttrain 1-481: Loss: 0.0556 Acc: 40.0000%\n",
      "\ttrain 1-482: Loss: 0.0541 Acc: 50.0000%\n",
      "\ttrain 1-483: Loss: 0.0727 Acc: 33.3333%\n",
      "\ttrain 1-484: Loss: 0.0750 Acc: 26.6667%\n",
      "\ttrain 1-485: Loss: 0.0690 Acc: 46.6667%\n",
      "\ttrain 1-486: Loss: 0.0710 Acc: 36.6667%\n",
      "\ttrain 1-487: Loss: 0.0751 Acc: 33.3333%\n",
      "\ttrain 1-488: Loss: 0.0747 Acc: 26.6667%\n",
      "\ttrain 1-489: Loss: 0.0724 Acc: 33.3333%\n",
      "\ttrain 1-490: Loss: 0.0658 Acc: 33.3333%\n",
      "\ttrain 1-491: Loss: 0.0695 Acc: 36.6667%\n",
      "\ttrain 1-492: Loss: 0.0559 Acc: 56.6667%\n",
      "\ttrain 1-493: Loss: 0.0881 Acc: 20.0000%\n",
      "\ttrain 1-494: Loss: 0.0768 Acc: 20.0000%\n",
      "\ttrain 1-495: Loss: 0.0722 Acc: 33.3333%\n",
      "\ttrain 1-496: Loss: 0.0808 Acc: 26.6667%\n",
      "\ttrain 1-497: Loss: 0.0709 Acc: 40.0000%\n",
      "\ttrain 1-498: Loss: 0.0652 Acc: 26.6667%\n",
      "\ttrain 1-499: Loss: 0.0727 Acc: 33.3333%\n",
      "\ttrain 1-500: Loss: 0.0616 Acc: 40.0000%\n",
      "\ttrain 1-501: Loss: 0.0633 Acc: 40.0000%\n",
      "\ttrain 1-502: Loss: 0.0715 Acc: 30.0000%\n",
      "\ttrain 1-503: Loss: 0.0590 Acc: 33.3333%\n",
      "\ttrain 1-504: Loss: 0.0592 Acc: 40.0000%\n",
      "\ttrain 1-505: Loss: 0.0649 Acc: 40.0000%\n",
      "\ttrain 1-506: Loss: 0.0545 Acc: 46.6667%\n",
      "\ttrain 1-507: Loss: 0.0635 Acc: 26.6667%\n",
      "\ttrain 1-508: Loss: 0.0635 Acc: 30.0000%\n",
      "\ttrain 1-509: Loss: 0.0553 Acc: 46.6667%\n",
      "\ttrain 1-510: Loss: 0.0603 Acc: 40.0000%\n",
      "\ttrain 1-511: Loss: 0.0695 Acc: 26.6667%\n",
      "\ttrain 1-512: Loss: 0.0414 Acc: 56.6667%\n",
      "\ttrain 1-513: Loss: 0.0581 Acc: 36.6667%\n",
      "\ttrain 1-514: Loss: 0.0631 Acc: 50.0000%\n",
      "\ttrain 1-515: Loss: 0.0620 Acc: 43.3333%\n",
      "\ttrain 1-516: Loss: 0.0497 Acc: 50.0000%\n",
      "\ttrain 1-517: Loss: 0.0454 Acc: 50.0000%\n",
      "\ttrain 1-518: Loss: 0.0607 Acc: 43.3333%\n",
      "\ttrain 1-519: Loss: 0.0600 Acc: 33.3333%\n",
      "\ttrain 1-520: Loss: 0.0836 Acc: 13.3333%\n",
      "\ttrain 1-521: Loss: 0.0753 Acc: 30.0000%\n",
      "\ttrain 1-522: Loss: 0.0905 Acc: 10.0000%\n",
      "\ttrain 1-523: Loss: 0.0877 Acc: 13.3333%\n",
      "\ttrain 1-524: Loss: 0.0727 Acc: 50.0000%\n",
      "\ttrain 1-525: Loss: 0.0669 Acc: 43.3333%\n",
      "\ttrain 1-526: Loss: 0.1083 Acc: 20.0000%\n",
      "\ttrain 1-527: Loss: 0.0645 Acc: 30.0000%\n",
      "\ttrain 1-528: Loss: 0.0710 Acc: 36.6667%\n",
      "\ttrain 1-529: Loss: 0.0657 Acc: 36.6667%\n",
      "\ttrain 1-530: Loss: 0.0671 Acc: 40.0000%\n",
      "\ttrain 1-531: Loss: 0.0661 Acc: 40.0000%\n",
      "\ttrain 1-532: Loss: 0.0645 Acc: 43.3333%\n",
      "\ttrain 1-533: Loss: 0.0663 Acc: 33.3333%\n",
      "\ttrain 1-534: Loss: 0.0703 Acc: 33.3333%\n",
      "\ttrain 1-535: Loss: 0.0669 Acc: 40.0000%\n",
      "\ttrain 1-536: Loss: 0.0617 Acc: 36.6667%\n",
      "\ttrain 1-537: Loss: 0.0584 Acc: 43.3333%\n",
      "\ttrain 1-538: Loss: 0.0579 Acc: 43.3333%\n",
      "\ttrain 1-539: Loss: 0.0521 Acc: 50.0000%\n",
      "\ttrain 1-540: Loss: 0.0653 Acc: 30.0000%\n",
      "\ttrain 1-541: Loss: 0.0477 Acc: 53.3333%\n",
      "\ttrain 1-542: Loss: 0.0504 Acc: 43.3333%\n",
      "\ttrain 1-543: Loss: 0.0578 Acc: 50.0000%\n",
      "\ttrain 1-544: Loss: 0.0796 Acc: 33.3333%\n",
      "\ttrain 1-545: Loss: 0.0696 Acc: 43.3333%\n",
      "\ttrain 1-546: Loss: 0.0582 Acc: 33.3333%\n",
      "\ttrain 1-547: Loss: 0.0526 Acc: 46.6667%\n",
      "\ttrain 1-548: Loss: 0.0583 Acc: 40.0000%\n",
      "\ttrain 1-549: Loss: 0.0570 Acc: 36.6667%\n",
      "\ttrain 1-550: Loss: 0.0601 Acc: 30.0000%\n",
      "\ttrain 1-551: Loss: 0.0612 Acc: 33.3333%\n",
      "\ttrain 1-552: Loss: 0.0669 Acc: 33.3333%\n",
      "\ttrain 1-553: Loss: 0.0631 Acc: 16.6667%\n",
      "\ttrain 1-554: Loss: 0.0601 Acc: 43.3333%\n",
      "\ttrain 1-555: Loss: 0.0496 Acc: 40.0000%\n",
      "\ttrain 1-556: Loss: 0.0517 Acc: 50.0000%\n",
      "\ttrain 1-557: Loss: 0.0596 Acc: 46.6667%\n",
      "\ttrain 1-558: Loss: 0.0562 Acc: 50.0000%\n",
      "\ttrain 1-559: Loss: 0.0607 Acc: 43.3333%\n",
      "\ttrain 1-560: Loss: 0.0642 Acc: 40.0000%\n",
      "\ttrain 1-561: Loss: 0.0647 Acc: 26.6667%\n",
      "\ttrain 1-562: Loss: 0.0576 Acc: 43.3333%\n",
      "\ttrain 1-563: Loss: 0.0648 Acc: 30.0000%\n",
      "\ttrain 1-564: Loss: 0.0602 Acc: 40.0000%\n",
      "\ttrain 1-565: Loss: 0.0537 Acc: 33.3333%\n",
      "\ttrain 1-566: Loss: 0.0466 Acc: 53.3333%\n",
      "\ttrain 1-567: Loss: 0.0505 Acc: 46.6667%\n",
      "\ttrain 1-568: Loss: 0.0497 Acc: 53.3333%\n",
      "\ttrain 1-569: Loss: 0.0498 Acc: 46.6667%\n",
      "\ttrain 1-570: Loss: 0.0433 Acc: 60.0000%\n",
      "\ttrain 1-571: Loss: 0.0534 Acc: 36.6667%\n",
      "\ttrain 1-572: Loss: 0.0512 Acc: 53.3333%\n",
      "\ttrain 1-573: Loss: 0.0514 Acc: 53.3333%\n",
      "\ttrain 1-574: Loss: 0.0516 Acc: 46.6667%\n",
      "\ttrain 1-575: Loss: 0.0591 Acc: 46.6667%\n",
      "\ttrain 1-576: Loss: 0.0552 Acc: 53.3333%\n",
      "\ttrain 1-577: Loss: 0.0673 Acc: 26.6667%\n",
      "\ttrain 1-578: Loss: 0.0534 Acc: 43.3333%\n",
      "\ttrain 1-579: Loss: 0.0548 Acc: 46.6667%\n",
      "\ttrain 1-580: Loss: 0.0531 Acc: 33.3333%\n",
      "\ttrain 1-581: Loss: 0.0539 Acc: 40.0000%\n",
      "\ttrain 1-582: Loss: 0.0592 Acc: 43.3333%\n",
      "\ttrain 1-583: Loss: 0.0544 Acc: 46.6667%\n",
      "\ttrain 1-584: Loss: 0.0571 Acc: 36.6667%\n",
      "\ttrain 1-585: Loss: 0.0599 Acc: 40.0000%\n",
      "\ttrain 1-586: Loss: 0.0460 Acc: 43.3333%\n",
      "\ttrain 1-587: Loss: 0.0536 Acc: 33.3333%\n",
      "\ttrain 1-588: Loss: 0.0638 Acc: 36.6667%\n",
      "\ttrain 1-589: Loss: 0.0483 Acc: 43.3333%\n",
      "\ttrain 1-590: Loss: 0.0534 Acc: 46.6667%\n",
      "\ttrain 1-591: Loss: 0.0401 Acc: 60.0000%\n",
      "\ttrain 1-592: Loss: 0.0406 Acc: 56.6667%\n",
      "\ttrain 1-593: Loss: 0.0660 Acc: 43.3333%\n",
      "\ttrain 1-594: Loss: 0.0491 Acc: 53.3333%\n",
      "\ttrain 1-595: Loss: 0.0373 Acc: 66.6667%\n",
      "\ttrain 1-596: Loss: 0.0413 Acc: 53.3333%\n",
      "\ttrain 1-597: Loss: 0.0510 Acc: 46.6667%\n",
      "\ttrain 1-598: Loss: 0.0655 Acc: 33.3333%\n",
      "\ttrain 1-599: Loss: 0.0506 Acc: 56.6667%\n",
      "\ttrain 1-600: Loss: 0.0449 Acc: 56.6667%\n",
      "\ttrain 1-601: Loss: 0.0524 Acc: 60.0000%\n",
      "\ttrain 1-602: Loss: 0.0683 Acc: 33.3333%\n",
      "\ttrain 1-603: Loss: 0.0473 Acc: 60.0000%\n",
      "\ttrain 1-604: Loss: 0.0440 Acc: 53.3333%\n",
      "\ttrain 1-605: Loss: 0.0492 Acc: 53.3333%\n",
      "\ttrain 1-606: Loss: 0.0563 Acc: 60.0000%\n",
      "\ttrain 1-607: Loss: 0.0577 Acc: 33.3333%\n",
      "\ttrain 1-608: Loss: 0.0595 Acc: 36.6667%\n",
      "\ttrain 1-609: Loss: 0.0577 Acc: 40.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-610: Loss: 0.0517 Acc: 50.0000%\n",
      "\ttrain 1-611: Loss: 0.0448 Acc: 43.3333%\n",
      "\ttrain 1-612: Loss: 0.0471 Acc: 53.3333%\n",
      "\ttrain 1-613: Loss: 0.0456 Acc: 53.3333%\n",
      "\ttrain 1-614: Loss: 0.0432 Acc: 56.6667%\n",
      "\ttrain 1-615: Loss: 0.0577 Acc: 56.6667%\n",
      "\ttrain 1-616: Loss: 0.0632 Acc: 43.3333%\n",
      "\ttrain 1-617: Loss: 0.0490 Acc: 63.3333%\n",
      "\ttrain 1-618: Loss: 0.0607 Acc: 33.3333%\n",
      "\ttrain 1-619: Loss: 0.0486 Acc: 40.0000%\n",
      "\ttrain 1-620: Loss: 0.0724 Acc: 33.3333%\n",
      "\ttrain 1-621: Loss: 0.0579 Acc: 46.6667%\n",
      "\ttrain 1-622: Loss: 0.0579 Acc: 46.6667%\n",
      "\ttrain 1-623: Loss: 0.0560 Acc: 43.3333%\n",
      "\ttrain 1-624: Loss: 0.0458 Acc: 63.3333%\n",
      "\ttrain 1-625: Loss: 0.0500 Acc: 60.0000%\n",
      "\ttrain 1-626: Loss: 0.0476 Acc: 56.6667%\n",
      "\ttrain 1-627: Loss: 0.0531 Acc: 50.0000%\n",
      "\ttrain 1-628: Loss: 0.0463 Acc: 53.3333%\n",
      "\ttrain 1-629: Loss: 0.0409 Acc: 60.0000%\n",
      "\ttrain 1-630: Loss: 0.0490 Acc: 50.0000%\n",
      "\ttrain 1-631: Loss: 0.0500 Acc: 46.6667%\n",
      "\ttrain 1-632: Loss: 0.0360 Acc: 60.0000%\n",
      "\ttrain 1-633: Loss: 0.0343 Acc: 66.6667%\n",
      "\ttrain 1-634: Loss: 0.0570 Acc: 50.0000%\n",
      "\ttrain 1-635: Loss: 0.0696 Acc: 26.6667%\n",
      "\ttrain 1-636: Loss: 0.0447 Acc: 56.6667%\n",
      "\ttrain 1-637: Loss: 0.0466 Acc: 56.6667%\n",
      "\ttrain 1-638: Loss: 0.0344 Acc: 63.3333%\n",
      "\ttrain 1-639: Loss: 0.0449 Acc: 50.0000%\n",
      "\ttrain 1-640: Loss: 0.0525 Acc: 53.3333%\n",
      "\ttrain 1-641: Loss: 0.0465 Acc: 46.6667%\n",
      "\ttrain 1-642: Loss: 0.0446 Acc: 56.6667%\n",
      "\ttrain 1-643: Loss: 0.0623 Acc: 40.0000%\n",
      "\ttrain 1-644: Loss: 0.0531 Acc: 36.6667%\n",
      "\ttrain 1-645: Loss: 0.0454 Acc: 63.3333%\n",
      "\ttrain 1-646: Loss: 0.0512 Acc: 46.6667%\n",
      "\ttrain 1-647: Loss: 0.0518 Acc: 46.6667%\n",
      "\ttrain 1-648: Loss: 0.0558 Acc: 46.6667%\n",
      "\ttrain 1-649: Loss: 0.0621 Acc: 46.6667%\n",
      "\ttrain 1-650: Loss: 0.0607 Acc: 43.3333%\n",
      "\ttrain 1-651: Loss: 0.0463 Acc: 50.0000%\n",
      "\ttrain 1-652: Loss: 0.0502 Acc: 53.3333%\n",
      "\ttrain 1-653: Loss: 0.0481 Acc: 56.6667%\n",
      "\ttrain 1-654: Loss: 0.0527 Acc: 43.3333%\n",
      "\ttrain 1-655: Loss: 0.0417 Acc: 63.3333%\n",
      "\ttrain 1-656: Loss: 0.0445 Acc: 53.3333%\n",
      "\ttrain 1-657: Loss: 0.0515 Acc: 40.0000%\n",
      "\ttrain 1-658: Loss: 0.0482 Acc: 53.3333%\n",
      "\ttrain 1-659: Loss: 0.0590 Acc: 40.0000%\n",
      "\ttrain 1-660: Loss: 0.0516 Acc: 46.6667%\n",
      "\ttrain 1-661: Loss: 0.0431 Acc: 50.0000%\n",
      "\ttrain 1-662: Loss: 0.0606 Acc: 40.0000%\n",
      "\ttrain 1-663: Loss: 0.0467 Acc: 63.3333%\n",
      "\ttrain 1-664: Loss: 0.0390 Acc: 66.6667%\n",
      "\ttrain 1-665: Loss: 0.0639 Acc: 36.6667%\n",
      "\ttrain 1-666: Loss: 0.0569 Acc: 33.3333%\n",
      "\ttrain 1-667: Loss: 0.0389 Acc: 56.6667%\n",
      "\ttrain 1-668: Loss: 0.0473 Acc: 46.6667%\n",
      "\ttrain 1-669: Loss: 0.0441 Acc: 53.3333%\n",
      "\ttrain 1-670: Loss: 0.0371 Acc: 60.0000%\n",
      "\ttrain 1-671: Loss: 0.0379 Acc: 56.6667%\n",
      "\ttrain 1-672: Loss: 0.0468 Acc: 53.3333%\n",
      "\ttrain 1-673: Loss: 0.0756 Acc: 26.6667%\n",
      "\ttrain 1-674: Loss: 0.0488 Acc: 46.6667%\n",
      "\ttrain 1-675: Loss: 0.0560 Acc: 46.6667%\n",
      "\ttrain 1-676: Loss: 0.0460 Acc: 26.6667%\n",
      "\ttrain 1-677: Loss: 0.0436 Acc: 60.0000%\n",
      "\ttrain 1-678: Loss: 0.0553 Acc: 43.3333%\n",
      "\ttrain 1-679: Loss: 0.0533 Acc: 53.3333%\n",
      "\ttrain 1-680: Loss: 0.0635 Acc: 30.0000%\n",
      "\ttrain 1-681: Loss: 0.0557 Acc: 53.3333%\n",
      "\ttrain 1-682: Loss: 0.0455 Acc: 50.0000%\n",
      "\ttrain 1-683: Loss: 0.0442 Acc: 46.6667%\n",
      "\ttrain 1-684: Loss: 0.0467 Acc: 50.0000%\n",
      "\ttrain 1-685: Loss: 0.0415 Acc: 53.3333%\n",
      "\ttrain 1-686: Loss: 0.0501 Acc: 53.3333%\n",
      "\ttrain 1-687: Loss: 0.0463 Acc: 50.0000%\n",
      "\ttrain 1-688: Loss: 0.0373 Acc: 53.3333%\n",
      "\ttrain 1-689: Loss: 0.0442 Acc: 63.3333%\n",
      "\ttrain 1-690: Loss: 0.0493 Acc: 60.0000%\n",
      "\ttrain 1-691: Loss: 0.0526 Acc: 50.0000%\n",
      "\ttrain 1-692: Loss: 0.0459 Acc: 53.3333%\n",
      "\ttrain 1-693: Loss: 0.0553 Acc: 46.6667%\n",
      "\ttrain 1-694: Loss: 0.0528 Acc: 46.6667%\n",
      "\ttrain 1-695: Loss: 0.0469 Acc: 56.6667%\n",
      "\ttrain 1-696: Loss: 0.0491 Acc: 46.6667%\n",
      "\ttrain 1-697: Loss: 0.0557 Acc: 36.6667%\n",
      "\ttrain 1-698: Loss: 0.0437 Acc: 53.3333%\n",
      "\ttrain 1-699: Loss: 0.0429 Acc: 46.6667%\n",
      "\ttrain 1-700: Loss: 0.0453 Acc: 50.0000%\n",
      "\ttrain 1-701: Loss: 0.0298 Acc: 73.3333%\n",
      "\ttrain 1-702: Loss: 0.0561 Acc: 60.0000%\n",
      "\ttrain 1-703: Loss: 0.0435 Acc: 50.0000%\n",
      "\ttrain 1-704: Loss: 0.0332 Acc: 66.6667%\n",
      "\ttrain 1-705: Loss: 0.0664 Acc: 46.6667%\n",
      "\ttrain 1-706: Loss: 0.0403 Acc: 60.0000%\n",
      "\ttrain 1-707: Loss: 0.0400 Acc: 60.0000%\n",
      "\ttrain 1-708: Loss: 0.0323 Acc: 56.6667%\n",
      "\ttrain 1-709: Loss: 0.0353 Acc: 60.0000%\n",
      "\ttrain 1-710: Loss: 0.0335 Acc: 56.6667%\n",
      "\ttrain 1-711: Loss: 0.0503 Acc: 53.3333%\n",
      "\ttrain 1-712: Loss: 0.0501 Acc: 46.6667%\n",
      "\ttrain 1-713: Loss: 0.0448 Acc: 56.6667%\n",
      "\ttrain 1-714: Loss: 0.0390 Acc: 63.3333%\n",
      "\ttrain 1-715: Loss: 0.0470 Acc: 46.6667%\n",
      "\ttrain 1-716: Loss: 0.0319 Acc: 70.0000%\n",
      "\ttrain 1-717: Loss: 0.0432 Acc: 40.0000%\n",
      "\ttrain 1-718: Loss: 0.0373 Acc: 63.3333%\n",
      "\ttrain 1-719: Loss: 0.0546 Acc: 36.6667%\n",
      "\ttrain 1-720: Loss: 0.0379 Acc: 56.6667%\n",
      "\ttrain 1-721: Loss: 0.0319 Acc: 73.3333%\n",
      "\ttrain 1-722: Loss: 0.0627 Acc: 53.3333%\n",
      "\ttrain 1-723: Loss: 0.0358 Acc: 63.3333%\n",
      "\ttrain 1-724: Loss: 0.0416 Acc: 53.3333%\n",
      "\ttrain 1-725: Loss: 0.0473 Acc: 53.3333%\n",
      "\ttrain 1-726: Loss: 0.0268 Acc: 83.3333%\n",
      "\ttrain 1-727: Loss: 0.0438 Acc: 56.6667%\n",
      "\ttrain 1-728: Loss: 0.0509 Acc: 56.6667%\n",
      "\ttrain 1-729: Loss: 0.0390 Acc: 63.3333%\n",
      "\ttrain 1-730: Loss: 0.0442 Acc: 66.6667%\n",
      "\ttrain 1-731: Loss: 0.0468 Acc: 56.6667%\n",
      "\ttrain 1-732: Loss: 0.0474 Acc: 63.3333%\n",
      "\ttrain 1-733: Loss: 0.0532 Acc: 43.3333%\n",
      "\ttrain 1-734: Loss: 0.0512 Acc: 53.3333%\n",
      "\ttrain 1-735: Loss: 0.0556 Acc: 50.0000%\n",
      "\ttrain 1-736: Loss: 0.0386 Acc: 70.0000%\n",
      "\ttrain 1-737: Loss: 0.0425 Acc: 63.3333%\n",
      "\ttrain 1-738: Loss: 0.0545 Acc: 36.6667%\n",
      "\ttrain 1-739: Loss: 0.0468 Acc: 56.6667%\n",
      "\ttrain 1-740: Loss: 0.0273 Acc: 63.3333%\n",
      "\ttrain 1-741: Loss: 0.0381 Acc: 53.3333%\n",
      "\ttrain 1-742: Loss: 0.0501 Acc: 50.0000%\n",
      "\ttrain 1-743: Loss: 0.0357 Acc: 60.0000%\n",
      "\ttrain 1-744: Loss: 0.0352 Acc: 70.0000%\n",
      "\ttrain 1-745: Loss: 0.0395 Acc: 53.3333%\n",
      "\ttrain 1-746: Loss: 0.0312 Acc: 53.3333%\n",
      "\ttrain 1-747: Loss: 0.0366 Acc: 66.6667%\n",
      "\ttrain 1-748: Loss: 0.0425 Acc: 60.0000%\n",
      "\ttrain 1-749: Loss: 0.0416 Acc: 60.0000%\n",
      "\ttrain 1-750: Loss: 0.0346 Acc: 56.6667%\n",
      "\ttrain 1-751: Loss: 0.0434 Acc: 53.3333%\n",
      "\ttrain 1-752: Loss: 0.0486 Acc: 53.3333%\n",
      "\ttrain 1-753: Loss: 0.0534 Acc: 53.3333%\n",
      "\ttrain 1-754: Loss: 0.0294 Acc: 66.6667%\n",
      "\ttrain 1-755: Loss: 0.0507 Acc: 40.0000%\n",
      "\ttrain 1-756: Loss: 0.0559 Acc: 40.0000%\n",
      "\ttrain 1-757: Loss: 0.0510 Acc: 50.0000%\n",
      "\ttrain 1-758: Loss: 0.0550 Acc: 56.6667%\n",
      "\ttrain 1-759: Loss: 0.0390 Acc: 76.6667%\n",
      "\ttrain 1-760: Loss: 0.0523 Acc: 43.3333%\n",
      "\ttrain 1-761: Loss: 0.0414 Acc: 60.0000%\n",
      "\ttrain 1-762: Loss: 0.0409 Acc: 56.6667%\n",
      "\ttrain 1-763: Loss: 0.0262 Acc: 80.0000%\n",
      "\ttrain 1-764: Loss: 0.0292 Acc: 73.3333%\n",
      "\ttrain 1-765: Loss: 0.0417 Acc: 53.3333%\n",
      "\ttrain 1-766: Loss: 0.0465 Acc: 56.6667%\n",
      "\ttrain 1-767: Loss: 0.0318 Acc: 70.0000%\n",
      "\ttrain 1-768: Loss: 0.0449 Acc: 53.3333%\n",
      "\ttrain 1-769: Loss: 0.0345 Acc: 66.6667%\n",
      "\ttrain 1-770: Loss: 0.0323 Acc: 66.6667%\n",
      "\ttrain 1-771: Loss: 0.0325 Acc: 70.0000%\n",
      "\ttrain 1-772: Loss: 0.0470 Acc: 60.0000%\n",
      "\ttrain 1-773: Loss: 0.0308 Acc: 70.0000%\n",
      "\ttrain 1-774: Loss: 0.0562 Acc: 36.6667%\n",
      "\ttrain 1-775: Loss: 0.0501 Acc: 53.3333%\n",
      "\ttrain 1-776: Loss: 0.0300 Acc: 66.6667%\n",
      "\ttrain 1-777: Loss: 0.0464 Acc: 60.0000%\n",
      "\ttrain 1-778: Loss: 0.0483 Acc: 40.0000%\n",
      "\ttrain 1-779: Loss: 0.0331 Acc: 63.3333%\n",
      "\ttrain 1-780: Loss: 0.0223 Acc: 80.0000%\n",
      "\ttrain 1-781: Loss: 0.0259 Acc: 76.6667%\n",
      "\ttrain 1-782: Loss: 0.0385 Acc: 53.3333%\n",
      "\ttrain 1-783: Loss: 0.0360 Acc: 56.6667%\n",
      "\ttrain 1-784: Loss: 0.0637 Acc: 46.6667%\n",
      "\ttrain 1-785: Loss: 0.0374 Acc: 56.6667%\n",
      "\ttrain 1-786: Loss: 0.0459 Acc: 46.6667%\n",
      "\ttrain 1-787: Loss: 0.0385 Acc: 70.0000%\n",
      "\ttrain 1-788: Loss: 0.0397 Acc: 63.3333%\n",
      "\ttrain 1-789: Loss: 0.0365 Acc: 70.0000%\n",
      "\ttrain 1-790: Loss: 0.0410 Acc: 56.6667%\n",
      "\ttrain 1-791: Loss: 0.0365 Acc: 63.3333%\n",
      "\ttrain 1-792: Loss: 0.0417 Acc: 53.3333%\n",
      "\ttrain 1-793: Loss: 0.0386 Acc: 63.3333%\n",
      "\ttrain 1-794: Loss: 0.0464 Acc: 53.3333%\n",
      "\ttrain 1-795: Loss: 0.0453 Acc: 60.0000%\n",
      "\ttrain 1-796: Loss: 0.0456 Acc: 60.0000%\n",
      "\ttrain 1-797: Loss: 0.0387 Acc: 60.0000%\n",
      "\ttrain 1-798: Loss: 0.0509 Acc: 40.0000%\n",
      "\ttrain 1-799: Loss: 0.0297 Acc: 80.0000%\n",
      "\ttrain 1-800: Loss: 0.0325 Acc: 63.3333%\n",
      "\ttrain 1-801: Loss: 0.0280 Acc: 70.0000%\n",
      "\ttrain 1-802: Loss: 0.0446 Acc: 53.3333%\n",
      "\ttrain 1-803: Loss: 0.0332 Acc: 60.0000%\n",
      "\ttrain 1-804: Loss: 0.0342 Acc: 66.6667%\n",
      "\ttrain 1-805: Loss: 0.0388 Acc: 46.6667%\n",
      "\ttrain 1-806: Loss: 0.0395 Acc: 63.3333%\n",
      "\ttrain 1-807: Loss: 0.0324 Acc: 66.6667%\n",
      "\ttrain 1-808: Loss: 0.0425 Acc: 66.6667%\n",
      "\ttrain 1-809: Loss: 0.0309 Acc: 70.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-810: Loss: 0.0321 Acc: 63.3333%\n",
      "\ttrain 1-811: Loss: 0.0298 Acc: 63.3333%\n",
      "\ttrain 1-812: Loss: 0.0478 Acc: 46.6667%\n",
      "\ttrain 1-813: Loss: 0.0404 Acc: 60.0000%\n",
      "\ttrain 1-814: Loss: 0.0431 Acc: 60.0000%\n",
      "\ttrain 1-815: Loss: 0.0448 Acc: 70.0000%\n",
      "\ttrain 1-816: Loss: 0.0365 Acc: 60.0000%\n",
      "\ttrain 1-817: Loss: 0.0403 Acc: 56.6667%\n",
      "\ttrain 1-818: Loss: 0.0442 Acc: 50.0000%\n",
      "\ttrain 1-819: Loss: 0.0472 Acc: 53.3333%\n",
      "\ttrain 1-820: Loss: 0.0355 Acc: 60.0000%\n",
      "\ttrain 1-821: Loss: 0.0369 Acc: 60.0000%\n",
      "\ttrain 1-822: Loss: 0.0292 Acc: 70.0000%\n",
      "\ttrain 1-823: Loss: 0.0293 Acc: 70.0000%\n",
      "\ttrain 1-824: Loss: 0.0211 Acc: 73.3333%\n",
      "\ttrain 1-825: Loss: 0.0343 Acc: 63.3333%\n",
      "\ttrain 1-826: Loss: 0.0329 Acc: 66.6667%\n",
      "\ttrain 1-827: Loss: 0.0237 Acc: 76.6667%\n",
      "\ttrain 1-828: Loss: 0.0464 Acc: 50.0000%\n",
      "\ttrain 1-829: Loss: 0.0440 Acc: 60.0000%\n",
      "\ttrain 1-830: Loss: 0.0475 Acc: 63.3333%\n",
      "\ttrain 1-831: Loss: 0.0390 Acc: 53.3333%\n",
      "\ttrain 1-832: Loss: 0.0272 Acc: 70.0000%\n",
      "\ttrain 1-833: Loss: 0.0340 Acc: 53.3333%\n",
      "\ttrain 1-834: Loss: 0.0501 Acc: 40.0000%\n",
      "\ttrain 1-835: Loss: 0.0295 Acc: 70.0000%\n",
      "\ttrain 1-836: Loss: 0.0342 Acc: 60.0000%\n",
      "\ttrain 1-837: Loss: 0.0400 Acc: 63.3333%\n",
      "\ttrain 1-838: Loss: 0.0337 Acc: 60.0000%\n",
      "\ttrain 1-839: Loss: 0.0284 Acc: 70.0000%\n",
      "\ttrain 1-840: Loss: 0.0317 Acc: 60.0000%\n",
      "\ttrain 1-841: Loss: 0.0370 Acc: 63.3333%\n",
      "\ttrain 1-842: Loss: 0.0366 Acc: 63.3333%\n",
      "\ttrain 1-843: Loss: 0.0276 Acc: 66.6667%\n",
      "\ttrain 1-844: Loss: 0.0344 Acc: 56.6667%\n",
      "\ttrain 1-845: Loss: 0.0267 Acc: 73.3333%\n",
      "\ttrain 1-846: Loss: 0.0319 Acc: 70.0000%\n",
      "\ttrain 1-847: Loss: 0.0420 Acc: 76.6667%\n",
      "\ttrain 1-848: Loss: 0.0510 Acc: 53.3333%\n",
      "\ttrain 1-849: Loss: 0.0423 Acc: 60.0000%\n",
      "\ttrain 1-850: Loss: 0.0390 Acc: 63.3333%\n",
      "\ttrain 1-851: Loss: 0.0289 Acc: 80.0000%\n",
      "\ttrain 1-852: Loss: 0.0356 Acc: 60.0000%\n",
      "\ttrain 1-853: Loss: 0.0241 Acc: 73.3333%\n",
      "\ttrain 1-854: Loss: 0.0261 Acc: 63.3333%\n",
      "\ttrain 1-855: Loss: 0.0352 Acc: 66.6667%\n",
      "\ttrain 1-856: Loss: 0.0333 Acc: 73.3333%\n",
      "\ttrain 1-857: Loss: 0.0314 Acc: 66.6667%\n",
      "\ttrain 1-858: Loss: 0.0298 Acc: 73.3333%\n",
      "\ttrain 1-859: Loss: 0.0266 Acc: 76.6667%\n",
      "\ttrain 1-860: Loss: 0.0233 Acc: 70.0000%\n",
      "\ttrain 1-861: Loss: 0.0275 Acc: 66.6667%\n",
      "\ttrain 1-862: Loss: 0.0232 Acc: 73.3333%\n",
      "\ttrain 1-863: Loss: 0.0359 Acc: 66.6667%\n",
      "\ttrain 1-864: Loss: 0.0363 Acc: 53.3333%\n",
      "\ttrain 1-865: Loss: 0.0286 Acc: 66.6667%\n",
      "\ttrain 1-866: Loss: 0.0549 Acc: 50.0000%\n",
      "\ttrain 1-867: Loss: 0.0262 Acc: 70.0000%\n",
      "\ttrain 1-868: Loss: 0.0353 Acc: 60.0000%\n",
      "\ttrain 1-869: Loss: 0.0464 Acc: 53.3333%\n",
      "\ttrain 1-870: Loss: 0.0304 Acc: 73.3333%\n",
      "\ttrain 1-871: Loss: 0.0348 Acc: 73.3333%\n",
      "\ttrain 1-872: Loss: 0.0337 Acc: 63.3333%\n",
      "\ttrain 1-873: Loss: 0.0406 Acc: 56.6667%\n",
      "\ttrain 1-874: Loss: 0.0268 Acc: 73.3333%\n",
      "\ttrain 1-875: Loss: 0.0411 Acc: 66.6667%\n",
      "\ttrain 1-876: Loss: 0.0201 Acc: 80.0000%\n",
      "\ttrain 1-877: Loss: 0.0292 Acc: 73.3333%\n",
      "\ttrain 1-878: Loss: 0.0456 Acc: 66.6667%\n",
      "\ttrain 1-879: Loss: 0.0402 Acc: 60.0000%\n",
      "\ttrain 1-880: Loss: 0.0229 Acc: 83.3333%\n",
      "\ttrain 1-881: Loss: 0.0284 Acc: 70.0000%\n",
      "\ttrain 1-882: Loss: 0.0305 Acc: 70.0000%\n",
      "\ttrain 1-883: Loss: 0.0298 Acc: 60.0000%\n",
      "\ttrain 1-884: Loss: 0.0235 Acc: 73.3333%\n",
      "\ttrain 1-885: Loss: 0.0274 Acc: 66.6667%\n",
      "\ttrain 1-886: Loss: 0.0244 Acc: 63.3333%\n",
      "\ttrain 1-887: Loss: 0.0414 Acc: 73.3333%\n",
      "\ttrain 1-888: Loss: 0.0224 Acc: 76.6667%\n",
      "\ttrain 1-889: Loss: 0.0297 Acc: 80.0000%\n",
      "\ttrain 1-890: Loss: 0.0283 Acc: 80.0000%\n",
      "\ttrain 1-891: Loss: 0.0323 Acc: 83.3333%\n",
      "\ttrain 1-892: Loss: 0.0311 Acc: 66.6667%\n",
      "\ttrain 1-893: Loss: 0.0473 Acc: 53.3333%\n",
      "\ttrain 1-894: Loss: 0.0339 Acc: 63.3333%\n",
      "\ttrain 1-895: Loss: 0.0286 Acc: 66.6667%\n",
      "\ttrain 1-896: Loss: 0.0309 Acc: 66.6667%\n",
      "\ttrain 1-897: Loss: 0.0264 Acc: 73.3333%\n",
      "\ttrain 1-898: Loss: 0.0286 Acc: 70.0000%\n",
      "\ttrain 1-899: Loss: 0.0155 Acc: 83.3333%\n",
      "\ttrain 1-900: Loss: 0.0196 Acc: 70.0000%\n",
      "\ttrain 1-901: Loss: 0.0426 Acc: 60.0000%\n",
      "\ttrain 1-902: Loss: 0.0279 Acc: 73.3333%\n",
      "\ttrain 1-903: Loss: 0.0429 Acc: 60.0000%\n",
      "\ttrain 1-904: Loss: 0.0309 Acc: 66.6667%\n",
      "\ttrain 1-905: Loss: 0.0475 Acc: 46.6667%\n",
      "\ttrain 1-906: Loss: 0.0311 Acc: 66.6667%\n",
      "\ttrain 1-907: Loss: 0.0310 Acc: 63.3333%\n",
      "\ttrain 1-908: Loss: 0.0211 Acc: 73.3333%\n",
      "\ttrain 1-909: Loss: 0.0204 Acc: 80.0000%\n",
      "\ttrain 1-910: Loss: 0.0370 Acc: 63.3333%\n",
      "\ttrain 1-911: Loss: 0.0374 Acc: 60.0000%\n",
      "\ttrain 1-912: Loss: 0.0301 Acc: 66.6667%\n",
      "\ttrain 1-913: Loss: 0.0287 Acc: 76.6667%\n",
      "\ttrain 1-914: Loss: 0.0222 Acc: 76.6667%\n",
      "\ttrain 1-915: Loss: 0.0260 Acc: 66.6667%\n",
      "\ttrain 1-916: Loss: 0.0214 Acc: 80.0000%\n",
      "\ttrain 1-917: Loss: 0.0185 Acc: 76.6667%\n",
      "\ttrain 1-918: Loss: 0.0370 Acc: 76.6667%\n",
      "\ttrain 1-919: Loss: 0.0339 Acc: 60.0000%\n",
      "\ttrain 1-920: Loss: 0.0279 Acc: 70.0000%\n",
      "\ttrain 1-921: Loss: 0.0359 Acc: 60.0000%\n",
      "\ttrain 1-922: Loss: 0.0275 Acc: 76.6667%\n",
      "\ttrain 1-923: Loss: 0.0324 Acc: 73.3333%\n",
      "\ttrain 1-924: Loss: 0.0407 Acc: 60.0000%\n",
      "\ttrain 1-925: Loss: 0.0315 Acc: 76.6667%\n",
      "\ttrain 1-926: Loss: 0.0357 Acc: 60.0000%\n",
      "\ttrain 1-927: Loss: 0.0454 Acc: 53.3333%\n",
      "\ttrain 1-928: Loss: 0.0224 Acc: 73.3333%\n",
      "\ttrain 1-929: Loss: 0.0460 Acc: 63.3333%\n",
      "\ttrain 1-930: Loss: 0.0253 Acc: 70.0000%\n",
      "\ttrain 1-931: Loss: 0.0261 Acc: 63.3333%\n",
      "\ttrain 1-932: Loss: 0.0260 Acc: 70.0000%\n",
      "\ttrain 1-933: Loss: 0.0254 Acc: 73.3333%\n",
      "\ttrain 1-934: Loss: 0.0289 Acc: 66.6667%\n",
      "\ttrain 1-935: Loss: 0.0285 Acc: 66.6667%\n",
      "\ttrain 1-936: Loss: 0.0314 Acc: 73.3333%\n",
      "\ttrain 1-937: Loss: 0.0219 Acc: 76.6667%\n",
      "\ttrain 1-938: Loss: 0.0262 Acc: 66.6667%\n",
      "\ttrain 1-939: Loss: 0.0193 Acc: 90.0000%\n",
      "\ttrain 1-940: Loss: 0.0157 Acc: 86.6667%\n",
      "\ttrain 1-941: Loss: 0.0314 Acc: 63.3333%\n",
      "\ttrain 1-942: Loss: 0.0284 Acc: 70.0000%\n",
      "\ttrain 1-943: Loss: 0.0268 Acc: 70.0000%\n",
      "\ttrain 1-944: Loss: 0.0208 Acc: 76.6667%\n",
      "\ttrain 1-945: Loss: 0.0200 Acc: 76.6667%\n",
      "\ttrain 1-946: Loss: 0.0276 Acc: 66.6667%\n",
      "\ttrain 1-947: Loss: 0.0403 Acc: 56.6667%\n",
      "\ttrain 1-948: Loss: 0.0313 Acc: 73.3333%\n",
      "\ttrain 1-949: Loss: 0.0239 Acc: 73.3333%\n",
      "\ttrain 1-950: Loss: 0.0222 Acc: 86.6667%\n",
      "\ttrain 1-951: Loss: 0.0310 Acc: 63.3333%\n",
      "\ttrain 1-952: Loss: 0.0245 Acc: 76.6667%\n",
      "\ttrain 1-953: Loss: 0.0329 Acc: 63.3333%\n",
      "\ttrain 1-954: Loss: 0.0424 Acc: 46.6667%\n",
      "\ttrain 1-955: Loss: 0.0180 Acc: 76.6667%\n",
      "\ttrain 1-956: Loss: 0.0161 Acc: 83.3333%\n",
      "\ttrain 1-957: Loss: 0.0361 Acc: 66.6667%\n",
      "\ttrain 1-958: Loss: 0.0364 Acc: 56.6667%\n",
      "\ttrain 1-959: Loss: 0.0292 Acc: 60.0000%\n",
      "\ttrain 1-960: Loss: 0.0231 Acc: 86.6667%\n",
      "\ttrain 1-961: Loss: 0.0291 Acc: 66.6667%\n",
      "\ttrain 1-962: Loss: 0.0176 Acc: 86.6667%\n",
      "\ttrain 1-963: Loss: 0.0285 Acc: 66.6667%\n",
      "\ttrain 1-964: Loss: 0.0220 Acc: 80.0000%\n",
      "\ttrain 1-965: Loss: 0.0242 Acc: 76.6667%\n",
      "\ttrain 1-966: Loss: 0.0320 Acc: 70.0000%\n",
      "\ttrain 1-967: Loss: 0.0304 Acc: 73.3333%\n",
      "\ttrain 1-968: Loss: 0.0206 Acc: 76.6667%\n",
      "\ttrain 1-969: Loss: 0.0321 Acc: 53.3333%\n",
      "\ttrain 1-970: Loss: 0.0175 Acc: 90.0000%\n",
      "\ttrain 1-971: Loss: 0.0187 Acc: 76.6667%\n",
      "\ttrain 1-972: Loss: 0.0191 Acc: 80.0000%\n",
      "\ttrain 1-973: Loss: 0.0284 Acc: 63.3333%\n",
      "\ttrain 1-974: Loss: 0.0270 Acc: 73.3333%\n",
      "\ttrain 1-975: Loss: 0.0200 Acc: 80.0000%\n",
      "\ttrain 1-976: Loss: 0.0300 Acc: 73.3333%\n",
      "\ttrain 1-977: Loss: 0.0314 Acc: 66.6667%\n",
      "\ttrain 1-978: Loss: 0.0352 Acc: 70.0000%\n",
      "\ttrain 1-979: Loss: 0.0191 Acc: 80.0000%\n",
      "\ttrain 1-980: Loss: 0.0319 Acc: 66.6667%\n",
      "\ttrain 1-981: Loss: 0.0344 Acc: 63.3333%\n",
      "\ttrain 1-982: Loss: 0.0211 Acc: 70.0000%\n",
      "\ttrain 1-983: Loss: 0.0230 Acc: 76.6667%\n",
      "\ttrain 1-984: Loss: 0.0174 Acc: 90.0000%\n",
      "\ttrain 1-985: Loss: 0.0227 Acc: 80.0000%\n",
      "\ttrain 1-986: Loss: 0.0249 Acc: 83.3333%\n",
      "\ttrain 1-987: Loss: 0.0270 Acc: 73.3333%\n",
      "\ttrain 1-988: Loss: 0.0237 Acc: 73.3333%\n",
      "\ttrain 1-989: Loss: 0.0261 Acc: 70.0000%\n",
      "\ttrain 1-990: Loss: 0.0243 Acc: 73.3333%\n",
      "\ttrain 1-991: Loss: 0.0206 Acc: 90.0000%\n",
      "\ttrain 1-992: Loss: 0.0141 Acc: 83.3333%\n",
      "\ttrain 1-993: Loss: 0.0275 Acc: 73.3333%\n",
      "\ttrain 1-994: Loss: 0.0319 Acc: 73.3333%\n",
      "\ttrain 1-995: Loss: 0.0285 Acc: 80.0000%\n",
      "\ttrain 1-996: Loss: 0.0189 Acc: 76.6667%\n",
      "\ttrain 1-997: Loss: 0.0175 Acc: 73.3333%\n",
      "\ttrain 1-998: Loss: 0.0161 Acc: 80.0000%\n",
      "\ttrain 1-999: Loss: 0.0319 Acc: 56.6667%\n",
      "\ttrain 1-1000: Loss: 0.0328 Acc: 66.6667%\n",
      "\ttrain 1-1001: Loss: 0.0187 Acc: 73.3333%\n",
      "\ttrain 1-1002: Loss: 0.0317 Acc: 76.6667%\n",
      "\ttrain 1-1003: Loss: 0.0305 Acc: 73.3333%\n",
      "\ttrain 1-1004: Loss: 0.0259 Acc: 70.0000%\n",
      "\ttrain 1-1005: Loss: 0.0213 Acc: 73.3333%\n",
      "\ttrain 1-1006: Loss: 0.0308 Acc: 66.6667%\n",
      "\ttrain 1-1007: Loss: 0.0302 Acc: 66.6667%\n",
      "\ttrain 1-1008: Loss: 0.0271 Acc: 76.6667%\n",
      "\ttrain 1-1009: Loss: 0.0246 Acc: 76.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-1010: Loss: 0.0189 Acc: 90.0000%\n",
      "\ttrain 1-1011: Loss: 0.0251 Acc: 76.6667%\n",
      "\ttrain 1-1012: Loss: 0.0188 Acc: 70.0000%\n",
      "\ttrain 1-1013: Loss: 0.0373 Acc: 63.3333%\n",
      "\ttrain 1-1014: Loss: 0.0269 Acc: 73.3333%\n",
      "\ttrain 1-1015: Loss: 0.0177 Acc: 80.0000%\n",
      "\ttrain 1-1016: Loss: 0.0265 Acc: 73.3333%\n",
      "\ttrain 1-1017: Loss: 0.0242 Acc: 76.6667%\n",
      "\ttrain 1-1018: Loss: 0.0206 Acc: 73.3333%\n",
      "\ttrain 1-1019: Loss: 0.0176 Acc: 80.0000%\n",
      "\ttrain 1-1020: Loss: 0.0292 Acc: 66.6667%\n",
      "\ttrain 1-1021: Loss: 0.0296 Acc: 73.3333%\n",
      "\ttrain 1-1022: Loss: 0.0154 Acc: 86.6667%\n",
      "\ttrain 1-1023: Loss: 0.0315 Acc: 66.6667%\n",
      "\ttrain 1-1024: Loss: 0.0294 Acc: 60.0000%\n",
      "\ttrain 1-1025: Loss: 0.0291 Acc: 70.0000%\n",
      "\ttrain 1-1026: Loss: 0.0228 Acc: 70.0000%\n",
      "\ttrain 1-1027: Loss: 0.0202 Acc: 80.0000%\n",
      "\ttrain 1-1028: Loss: 0.0196 Acc: 76.6667%\n",
      "\ttrain 1-1029: Loss: 0.0239 Acc: 80.0000%\n",
      "\ttrain 1-1030: Loss: 0.0237 Acc: 73.3333%\n",
      "\ttrain 1-1031: Loss: 0.0176 Acc: 80.0000%\n",
      "\ttrain 1-1032: Loss: 0.0237 Acc: 66.6667%\n",
      "\ttrain 1-1033: Loss: 0.0191 Acc: 80.0000%\n",
      "\ttrain 1-1034: Loss: 0.0268 Acc: 70.0000%\n",
      "\ttrain 1-1035: Loss: 0.0130 Acc: 86.6667%\n",
      "\ttrain 1-1036: Loss: 0.0129 Acc: 83.3333%\n",
      "\ttrain 1-1037: Loss: 0.0290 Acc: 63.3333%\n",
      "\ttrain 1-1038: Loss: 0.0252 Acc: 76.6667%\n",
      "\ttrain 1-1039: Loss: 0.0253 Acc: 70.0000%\n",
      "\ttrain 1-1040: Loss: 0.0331 Acc: 66.6667%\n",
      "\ttrain 1-1041: Loss: 0.0288 Acc: 70.0000%\n",
      "\ttrain 1-1042: Loss: 0.0163 Acc: 80.0000%\n",
      "\ttrain 1-1043: Loss: 0.0232 Acc: 73.3333%\n",
      "\ttrain 1-1044: Loss: 0.0177 Acc: 80.0000%\n",
      "\ttrain 1-1045: Loss: 0.0269 Acc: 76.6667%\n",
      "\ttrain 1-1046: Loss: 0.0270 Acc: 70.0000%\n",
      "\ttrain 1-1047: Loss: 0.0359 Acc: 56.6667%\n",
      "\ttrain 1-1048: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain 1-1049: Loss: 0.0307 Acc: 63.3333%\n",
      "\ttrain 1-1050: Loss: 0.0133 Acc: 86.6667%\n",
      "\ttrain 1-1051: Loss: 0.0200 Acc: 83.3333%\n",
      "\ttrain 1-1052: Loss: 0.0173 Acc: 80.0000%\n",
      "\ttrain 1-1053: Loss: 0.0445 Acc: 63.3333%\n",
      "\ttrain 1-1054: Loss: 0.0344 Acc: 70.0000%\n",
      "\ttrain 1-1055: Loss: 0.0157 Acc: 83.3333%\n",
      "\ttrain 1-1056: Loss: 0.0212 Acc: 76.6667%\n",
      "\ttrain 1-1057: Loss: 0.0332 Acc: 66.6667%\n",
      "\ttrain 1-1058: Loss: 0.0270 Acc: 73.3333%\n",
      "\ttrain 1-1059: Loss: 0.0299 Acc: 66.6667%\n",
      "\ttrain 1-1060: Loss: 0.0223 Acc: 70.0000%\n",
      "\ttrain 1-1061: Loss: 0.0140 Acc: 86.6667%\n",
      "\ttrain 1-1062: Loss: 0.0181 Acc: 83.3333%\n",
      "\ttrain 1-1063: Loss: 0.0223 Acc: 76.6667%\n",
      "\ttrain 1-1064: Loss: 0.0202 Acc: 80.0000%\n",
      "\ttrain 1-1065: Loss: 0.0151 Acc: 80.0000%\n",
      "\ttrain 1-1066: Loss: 0.0264 Acc: 73.3333%\n",
      "\ttrain 1-1067: Loss: 0.0490 Acc: 53.3333%\n",
      "\ttrain 1-1068: Loss: 0.0284 Acc: 70.0000%\n",
      "\ttrain 1-1069: Loss: 0.0369 Acc: 60.0000%\n",
      "\ttrain 1-1070: Loss: 0.0189 Acc: 83.3333%\n",
      "\ttrain 1-1071: Loss: 0.0223 Acc: 73.3333%\n",
      "\ttrain 1-1072: Loss: 0.0310 Acc: 60.0000%\n",
      "\ttrain 1-1073: Loss: 0.0299 Acc: 76.6667%\n",
      "\ttrain 1-1074: Loss: 0.0147 Acc: 80.0000%\n",
      "\ttrain 1-1075: Loss: 0.0318 Acc: 73.3333%\n",
      "\ttrain 1-1076: Loss: 0.0173 Acc: 86.6667%\n",
      "\ttrain 1-1077: Loss: 0.0227 Acc: 83.3333%\n",
      "\ttrain 1-1078: Loss: 0.0156 Acc: 86.6667%\n",
      "\ttrain 1-1079: Loss: 0.0170 Acc: 80.0000%\n",
      "\ttrain 1-1080: Loss: 0.0187 Acc: 76.6667%\n",
      "\ttrain 1-1081: Loss: 0.0324 Acc: 70.0000%\n",
      "\ttrain 1-1082: Loss: 0.0266 Acc: 76.6667%\n",
      "\ttrain 1-1083: Loss: 0.0320 Acc: 70.0000%\n",
      "\ttrain 1-1084: Loss: 0.0252 Acc: 66.6667%\n",
      "\ttrain 1-1085: Loss: 0.0324 Acc: 66.6667%\n",
      "\ttrain 1-1086: Loss: 0.0281 Acc: 73.3333%\n",
      "\ttrain 1-1087: Loss: 0.0231 Acc: 73.3333%\n",
      "\ttrain 1-1088: Loss: 0.0365 Acc: 53.3333%\n",
      "\ttrain 1-1089: Loss: 0.0229 Acc: 83.3333%\n",
      "\ttrain 1-1090: Loss: 0.0244 Acc: 76.6667%\n",
      "\ttrain 1-1091: Loss: 0.0249 Acc: 70.0000%\n",
      "\ttrain 1-1092: Loss: 0.0256 Acc: 76.6667%\n",
      "\ttrain 1-1093: Loss: 0.0275 Acc: 66.6667%\n",
      "\ttrain 1-1094: Loss: 0.0195 Acc: 86.6667%\n",
      "\ttrain 1-1095: Loss: 0.0265 Acc: 73.3333%\n",
      "\ttrain 1-1096: Loss: 0.0101 Acc: 90.0000%\n",
      "\ttrain 1-1097: Loss: 0.0235 Acc: 76.6667%\n",
      "\ttrain 1-1098: Loss: 0.0112 Acc: 83.3333%\n",
      "\ttrain 1-1099: Loss: 0.0136 Acc: 90.0000%\n",
      "\ttrain 1-1100: Loss: 0.0215 Acc: 83.3333%\n",
      "\ttrain 1-1101: Loss: 0.0216 Acc: 80.0000%\n",
      "\ttrain 1-1102: Loss: 0.0148 Acc: 83.3333%\n",
      "\ttrain 1-1103: Loss: 0.0160 Acc: 83.3333%\n",
      "\ttrain 1-1104: Loss: 0.0171 Acc: 83.3333%\n",
      "\ttrain 1-1105: Loss: 0.0232 Acc: 70.0000%\n",
      "\ttrain 1-1106: Loss: 0.0131 Acc: 86.6667%\n",
      "\ttrain 1-1107: Loss: 0.0197 Acc: 76.6667%\n",
      "\ttrain 1-1108: Loss: 0.0191 Acc: 83.3333%\n",
      "\ttrain 1-1109: Loss: 0.0175 Acc: 83.3333%\n",
      "\ttrain 1-1110: Loss: 0.0330 Acc: 76.6667%\n",
      "\ttrain 1-1111: Loss: 0.0227 Acc: 70.0000%\n",
      "\ttrain 1-1112: Loss: 0.0357 Acc: 70.0000%\n",
      "\ttrain 1-1113: Loss: 0.0205 Acc: 66.6667%\n",
      "\ttrain 1-1114: Loss: 0.0129 Acc: 86.6667%\n",
      "\ttrain 1-1115: Loss: 0.0243 Acc: 70.0000%\n",
      "\ttrain 1-1116: Loss: 0.0156 Acc: 80.0000%\n",
      "\ttrain 1-1117: Loss: 0.0162 Acc: 80.0000%\n",
      "\ttrain 1-1118: Loss: 0.0127 Acc: 86.6667%\n",
      "\ttrain 1-1119: Loss: 0.0237 Acc: 73.3333%\n",
      "\ttrain 1-1120: Loss: 0.0125 Acc: 93.3333%\n",
      "\ttrain 1-1121: Loss: 0.0166 Acc: 86.6667%\n",
      "\ttrain 1-1122: Loss: 0.0274 Acc: 70.0000%\n",
      "\ttrain 1-1123: Loss: 0.0147 Acc: 86.6667%\n",
      "\ttrain 1-1124: Loss: 0.0325 Acc: 70.0000%\n",
      "\ttrain 1-1125: Loss: 0.0188 Acc: 76.6667%\n",
      "\ttrain 1-1126: Loss: 0.0318 Acc: 73.3333%\n",
      "\ttrain 1-1127: Loss: 0.0145 Acc: 83.3333%\n",
      "\ttrain 1-1128: Loss: 0.0123 Acc: 86.6667%\n",
      "\ttrain 1-1129: Loss: 0.0221 Acc: 76.6667%\n",
      "\ttrain 1-1130: Loss: 0.0155 Acc: 70.0000%\n",
      "\ttrain 1-1131: Loss: 0.0095 Acc: 86.6667%\n",
      "\ttrain 1-1132: Loss: 0.0248 Acc: 70.0000%\n",
      "\ttrain 1-1133: Loss: 0.0204 Acc: 80.0000%\n",
      "\ttrain 1-1134: Loss: 0.0191 Acc: 80.0000%\n",
      "\ttrain 1-1135: Loss: 0.0191 Acc: 80.0000%\n",
      "\ttrain 1-1136: Loss: 0.0114 Acc: 86.6667%\n",
      "\ttrain 1-1137: Loss: 0.0189 Acc: 76.6667%\n",
      "\ttrain 1-1138: Loss: 0.0217 Acc: 73.3333%\n",
      "\ttrain 1-1139: Loss: 0.0149 Acc: 83.3333%\n",
      "\ttrain 1-1140: Loss: 0.0183 Acc: 76.6667%\n",
      "\ttrain 1-1141: Loss: 0.0171 Acc: 83.3333%\n",
      "\ttrain 1-1142: Loss: 0.0204 Acc: 80.0000%\n",
      "\ttrain 1-1143: Loss: 0.0268 Acc: 80.0000%\n",
      "\ttrain 1-1144: Loss: 0.0100 Acc: 90.0000%\n",
      "\ttrain 1-1145: Loss: 0.0165 Acc: 86.6667%\n",
      "\ttrain 1-1146: Loss: 0.0282 Acc: 76.6667%\n",
      "\ttrain 1-1147: Loss: 0.0164 Acc: 80.0000%\n",
      "\ttrain 1-1148: Loss: 0.0148 Acc: 83.3333%\n",
      "\ttrain 1-1149: Loss: 0.0241 Acc: 70.0000%\n",
      "\ttrain 1-1150: Loss: 0.0190 Acc: 83.3333%\n",
      "\ttrain 1-1151: Loss: 0.0282 Acc: 63.3333%\n",
      "\ttrain 1-1152: Loss: 0.0247 Acc: 76.6667%\n",
      "\ttrain 1-1153: Loss: 0.0152 Acc: 86.6667%\n",
      "\ttrain 1-1154: Loss: 0.0235 Acc: 63.3333%\n",
      "\ttrain 1-1155: Loss: 0.0246 Acc: 80.0000%\n",
      "\ttrain 1-1156: Loss: 0.0156 Acc: 86.6667%\n",
      "\ttrain 1-1157: Loss: 0.0129 Acc: 90.0000%\n",
      "\ttrain 1-1158: Loss: 0.0130 Acc: 80.0000%\n",
      "\ttrain 1-1159: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-1160: Loss: 0.0302 Acc: 66.6667%\n",
      "\ttrain 1-1161: Loss: 0.0122 Acc: 83.3333%\n",
      "\ttrain 1-1162: Loss: 0.0169 Acc: 80.0000%\n",
      "\ttrain 1-1163: Loss: 0.0328 Acc: 63.3333%\n",
      "\ttrain 1-1164: Loss: 0.0153 Acc: 80.0000%\n",
      "\ttrain 1-1165: Loss: 0.0422 Acc: 63.3333%\n",
      "\ttrain 1-1166: Loss: 0.0105 Acc: 93.3333%\n",
      "\ttrain 1-1167: Loss: 0.0144 Acc: 80.0000%\n",
      "\ttrain 1-1168: Loss: 0.0163 Acc: 83.3333%\n",
      "\ttrain 1-1169: Loss: 0.0255 Acc: 76.6667%\n",
      "\ttrain 1-1170: Loss: 0.0172 Acc: 80.0000%\n",
      "\ttrain 1-1171: Loss: 0.0139 Acc: 80.0000%\n",
      "\ttrain 1-1172: Loss: 0.0173 Acc: 86.6667%\n",
      "\ttrain 1-1173: Loss: 0.0173 Acc: 83.3333%\n",
      "\ttrain 1-1174: Loss: 0.0130 Acc: 83.3333%\n",
      "\ttrain 1-1175: Loss: 0.0258 Acc: 76.6667%\n",
      "\ttrain 1-1176: Loss: 0.0104 Acc: 83.3333%\n",
      "\ttrain 1-1177: Loss: 0.0198 Acc: 80.0000%\n",
      "\ttrain 1-1178: Loss: 0.0115 Acc: 93.3333%\n",
      "\ttrain 1-1179: Loss: 0.0355 Acc: 73.3333%\n",
      "\ttrain 1-1180: Loss: 0.0188 Acc: 83.3333%\n",
      "\ttrain 1-1181: Loss: 0.0147 Acc: 86.6667%\n",
      "\ttrain 1-1182: Loss: 0.0140 Acc: 86.6667%\n",
      "\ttrain 1-1183: Loss: 0.0104 Acc: 86.6667%\n",
      "\ttrain 1-1184: Loss: 0.0181 Acc: 80.0000%\n",
      "\ttrain 1-1185: Loss: 0.0251 Acc: 66.6667%\n",
      "\ttrain 1-1186: Loss: 0.0214 Acc: 76.6667%\n",
      "\ttrain 1-1187: Loss: 0.0118 Acc: 90.0000%\n",
      "\ttrain 1-1188: Loss: 0.0211 Acc: 80.0000%\n",
      "\ttrain 1-1189: Loss: 0.0172 Acc: 83.3333%\n",
      "\ttrain 1-1190: Loss: 0.0206 Acc: 73.3333%\n",
      "\ttrain 1-1191: Loss: 0.0231 Acc: 76.6667%\n",
      "\ttrain 1-1192: Loss: 0.0168 Acc: 80.0000%\n",
      "\ttrain 1-1193: Loss: 0.0258 Acc: 76.6667%\n",
      "\ttrain 1-1194: Loss: 0.0252 Acc: 73.3333%\n",
      "\ttrain 1-1195: Loss: 0.0443 Acc: 76.6667%\n",
      "\ttrain 1-1196: Loss: 0.0278 Acc: 80.0000%\n",
      "\ttrain 1-1197: Loss: 0.0163 Acc: 83.3333%\n",
      "\ttrain 1-1198: Loss: 0.0144 Acc: 76.6667%\n",
      "\ttrain 1-1199: Loss: 0.0148 Acc: 86.6667%\n",
      "\ttrain 1-1200: Loss: 0.0208 Acc: 80.0000%\n",
      "\ttrain 1-1201: Loss: 0.0208 Acc: 76.6667%\n",
      "\ttrain 1-1202: Loss: 0.0208 Acc: 80.0000%\n",
      "\ttrain 1-1203: Loss: 0.0204 Acc: 76.6667%\n",
      "\ttrain 1-1204: Loss: 0.0137 Acc: 83.3333%\n",
      "\ttrain 1-1205: Loss: 0.0059 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-1206: Loss: 0.0208 Acc: 80.0000%\n",
      "\ttrain 1-1207: Loss: 0.0204 Acc: 83.3333%\n",
      "\ttrain 1-1208: Loss: 0.0148 Acc: 90.0000%\n",
      "\ttrain 1-1209: Loss: 0.0153 Acc: 83.3333%\n",
      "\ttrain 1-1210: Loss: 0.0184 Acc: 73.3333%\n",
      "\ttrain 1-1211: Loss: 0.0302 Acc: 73.3333%\n",
      "\ttrain 1-1212: Loss: 0.0214 Acc: 80.0000%\n",
      "\ttrain 1-1213: Loss: 0.0091 Acc: 90.0000%\n",
      "\ttrain 1-1214: Loss: 0.0151 Acc: 80.0000%\n",
      "\ttrain 1-1215: Loss: 0.0176 Acc: 76.6667%\n",
      "\ttrain 1-1216: Loss: 0.0262 Acc: 80.0000%\n",
      "\ttrain 1-1217: Loss: 0.0124 Acc: 90.0000%\n",
      "\ttrain 1-1218: Loss: 0.0240 Acc: 76.6667%\n",
      "\ttrain 1-1219: Loss: 0.0130 Acc: 86.6667%\n",
      "\ttrain 1-1220: Loss: 0.0225 Acc: 70.0000%\n",
      "\ttrain 1-1221: Loss: 0.0246 Acc: 70.0000%\n",
      "\ttrain 1-1222: Loss: 0.0190 Acc: 83.3333%\n",
      "\ttrain 1-1223: Loss: 0.0268 Acc: 76.6667%\n",
      "\ttrain 1-1224: Loss: 0.0208 Acc: 80.0000%\n",
      "\ttrain 1-1225: Loss: 0.0168 Acc: 90.0000%\n",
      "\ttrain 1-1226: Loss: 0.0182 Acc: 83.3333%\n",
      "\ttrain 1-1227: Loss: 0.0233 Acc: 73.3333%\n",
      "\ttrain 1-1228: Loss: 0.0155 Acc: 83.3333%\n",
      "\ttrain 1-1229: Loss: 0.0072 Acc: 100.0000%\n",
      "\ttrain 1-1230: Loss: 0.0126 Acc: 90.0000%\n",
      "\ttrain 1-1231: Loss: 0.0126 Acc: 83.3333%\n",
      "\ttrain 1-1232: Loss: 0.0182 Acc: 86.6667%\n",
      "\ttrain 1-1233: Loss: 0.0138 Acc: 80.0000%\n",
      "\ttrain 1-1234: Loss: 0.0140 Acc: 83.3333%\n",
      "\ttrain 1-1235: Loss: 0.0129 Acc: 86.6667%\n",
      "\ttrain 1-1236: Loss: 0.0253 Acc: 73.3333%\n",
      "\ttrain 1-1237: Loss: 0.0310 Acc: 66.6667%\n",
      "\ttrain 1-1238: Loss: 0.0168 Acc: 83.3333%\n",
      "\ttrain 1-1239: Loss: 0.0206 Acc: 80.0000%\n",
      "\ttrain 1-1240: Loss: 0.0153 Acc: 86.6667%\n",
      "\ttrain 1-1241: Loss: 0.0209 Acc: 80.0000%\n",
      "\ttrain 1-1242: Loss: 0.0101 Acc: 90.0000%\n",
      "\ttrain 1-1243: Loss: 0.0380 Acc: 56.6667%\n",
      "\ttrain 1-1244: Loss: 0.0306 Acc: 66.6667%\n",
      "\ttrain 1-1245: Loss: 0.0284 Acc: 73.3333%\n",
      "\ttrain 1-1246: Loss: 0.0295 Acc: 76.6667%\n",
      "\ttrain 1-1247: Loss: 0.0195 Acc: 80.0000%\n",
      "\ttrain 1-1248: Loss: 0.0175 Acc: 90.0000%\n",
      "\ttrain 1-1249: Loss: 0.0174 Acc: 86.6667%\n",
      "\ttrain 1-1250: Loss: 0.0163 Acc: 90.0000%\n",
      "\ttrain 1-1251: Loss: 0.0169 Acc: 80.0000%\n",
      "\ttrain 1-1252: Loss: 0.0181 Acc: 80.0000%\n",
      "\ttrain 1-1253: Loss: 0.0328 Acc: 80.0000%\n",
      "\ttrain 1-1254: Loss: 0.0192 Acc: 83.3333%\n",
      "\ttrain 1-1255: Loss: 0.0197 Acc: 86.6667%\n",
      "\ttrain 1-1256: Loss: 0.0128 Acc: 86.6667%\n",
      "\ttrain 1-1257: Loss: 0.0213 Acc: 83.3333%\n",
      "\ttrain 1-1258: Loss: 0.0176 Acc: 76.6667%\n",
      "\ttrain 1-1259: Loss: 0.0138 Acc: 90.0000%\n",
      "\ttrain 1-1260: Loss: 0.0224 Acc: 80.0000%\n",
      "\ttrain 1-1261: Loss: 0.0194 Acc: 83.3333%\n",
      "\ttrain 1-1262: Loss: 0.0114 Acc: 90.0000%\n",
      "\ttrain 1-1263: Loss: 0.0102 Acc: 93.3333%\n",
      "\ttrain 1-1264: Loss: 0.0210 Acc: 70.0000%\n",
      "\ttrain 1-1265: Loss: 0.0227 Acc: 90.0000%\n",
      "\ttrain 1-1266: Loss: 0.0214 Acc: 80.0000%\n",
      "\ttrain 1-1267: Loss: 0.0204 Acc: 76.6667%\n",
      "\ttrain 1-1268: Loss: 0.0229 Acc: 76.6667%\n",
      "\ttrain 1-1269: Loss: 0.0170 Acc: 83.3333%\n",
      "\ttrain 1-1270: Loss: 0.0114 Acc: 90.0000%\n",
      "\ttrain 1-1271: Loss: 0.0131 Acc: 93.3333%\n",
      "\ttrain 1-1272: Loss: 0.0223 Acc: 73.3333%\n",
      "\ttrain 1-1273: Loss: 0.0227 Acc: 73.3333%\n",
      "\ttrain 1-1274: Loss: 0.0109 Acc: 86.6667%\n",
      "\ttrain 1-1275: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 1-1276: Loss: 0.0141 Acc: 83.3333%\n",
      "\ttrain 1-1277: Loss: 0.0094 Acc: 96.6667%\n",
      "\ttrain 1-1278: Loss: 0.0142 Acc: 86.6667%\n",
      "\ttrain 1-1279: Loss: 0.0196 Acc: 76.6667%\n",
      "\ttrain 1-1280: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 1-1281: Loss: 0.0184 Acc: 83.3333%\n",
      "\ttrain 1-1282: Loss: 0.0249 Acc: 76.6667%\n",
      "\ttrain 1-1283: Loss: 0.0186 Acc: 83.3333%\n",
      "\ttrain 1-1284: Loss: 0.0126 Acc: 80.0000%\n",
      "\ttrain 1-1285: Loss: 0.0117 Acc: 86.6667%\n",
      "\ttrain 1-1286: Loss: 0.0112 Acc: 83.3333%\n",
      "\ttrain 1-1287: Loss: 0.0110 Acc: 86.6667%\n",
      "\ttrain 1-1288: Loss: 0.0219 Acc: 76.6667%\n",
      "\ttrain 1-1289: Loss: 0.0163 Acc: 86.6667%\n",
      "\ttrain 1-1290: Loss: 0.0139 Acc: 90.0000%\n",
      "\ttrain 1-1291: Loss: 0.0182 Acc: 80.0000%\n",
      "\ttrain 1-1292: Loss: 0.0098 Acc: 93.3333%\n",
      "\ttrain 1-1293: Loss: 0.0150 Acc: 83.3333%\n",
      "\ttrain 1-1294: Loss: 0.0162 Acc: 83.3333%\n",
      "\ttrain 1-1295: Loss: 0.0109 Acc: 86.6667%\n",
      "\ttrain 1-1296: Loss: 0.0222 Acc: 70.0000%\n",
      "\ttrain 1-1297: Loss: 0.0141 Acc: 86.6667%\n",
      "\ttrain 1-1298: Loss: 0.0123 Acc: 86.6667%\n",
      "\ttrain 1-1299: Loss: 0.0211 Acc: 66.6667%\n",
      "\ttrain 1-1300: Loss: 0.0099 Acc: 86.6667%\n",
      "\ttrain 1-1301: Loss: 0.0192 Acc: 80.0000%\n",
      "\ttrain 1-1302: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-1303: Loss: 0.0089 Acc: 90.0000%\n",
      "\ttrain 1-1304: Loss: 0.0165 Acc: 80.0000%\n",
      "\ttrain 1-1305: Loss: 0.0113 Acc: 86.6667%\n",
      "\ttrain 1-1306: Loss: 0.0236 Acc: 80.0000%\n",
      "\ttrain 1-1307: Loss: 0.0106 Acc: 86.6667%\n",
      "\ttrain 1-1308: Loss: 0.0099 Acc: 96.6667%\n",
      "\ttrain 1-1309: Loss: 0.0134 Acc: 83.3333%\n",
      "\ttrain 1-1310: Loss: 0.0167 Acc: 83.3333%\n",
      "\ttrain 1-1311: Loss: 0.0087 Acc: 93.3333%\n",
      "\ttrain 1-1312: Loss: 0.0078 Acc: 90.0000%\n",
      "\ttrain 1-1313: Loss: 0.0175 Acc: 86.6667%\n",
      "\ttrain 1-1314: Loss: 0.0094 Acc: 86.6667%\n",
      "\ttrain 1-1315: Loss: 0.0179 Acc: 80.0000%\n",
      "\ttrain 1-1316: Loss: 0.0179 Acc: 80.0000%\n",
      "\ttrain 1-1317: Loss: 0.0119 Acc: 83.3333%\n",
      "\ttrain 1-1318: Loss: 0.0145 Acc: 86.6667%\n",
      "\ttrain 1-1319: Loss: 0.0296 Acc: 76.6667%\n",
      "\ttrain 1-1320: Loss: 0.0130 Acc: 90.0000%\n",
      "\ttrain 1-1321: Loss: 0.0113 Acc: 90.0000%\n",
      "\ttrain 1-1322: Loss: 0.0171 Acc: 86.6667%\n",
      "\ttrain 1-1323: Loss: 0.0140 Acc: 83.3333%\n",
      "\ttrain 1-1324: Loss: 0.0151 Acc: 83.3333%\n",
      "\ttrain 1-1325: Loss: 0.0126 Acc: 83.3333%\n",
      "\ttrain 1-1326: Loss: 0.0151 Acc: 86.6667%\n",
      "\ttrain 1-1327: Loss: 0.0087 Acc: 86.6667%\n",
      "\ttrain 1-1328: Loss: 0.0156 Acc: 83.3333%\n",
      "\ttrain 1-1329: Loss: 0.0194 Acc: 76.6667%\n",
      "\ttrain 1-1330: Loss: 0.0170 Acc: 73.3333%\n",
      "\ttrain 1-1331: Loss: 0.0100 Acc: 86.6667%\n",
      "\ttrain 1-1332: Loss: 0.0143 Acc: 86.6667%\n",
      "\ttrain 1-1333: Loss: 0.0395 Acc: 66.6667%\n",
      "\ttrain 1-1334: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-1335: Loss: 0.0081 Acc: 90.0000%\n",
      "\ttrain 1-1336: Loss: 0.0153 Acc: 86.6667%\n",
      "\ttrain 1-1337: Loss: 0.0243 Acc: 80.0000%\n",
      "\ttrain 1-1338: Loss: 0.0171 Acc: 83.3333%\n",
      "\ttrain 1-1339: Loss: 0.0090 Acc: 86.6667%\n",
      "\ttrain 1-1340: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 1-1341: Loss: 0.0101 Acc: 90.0000%\n",
      "\ttrain 1-1342: Loss: 0.0204 Acc: 73.3333%\n",
      "\ttrain 1-1343: Loss: 0.0162 Acc: 86.6667%\n",
      "\ttrain 1-1344: Loss: 0.0131 Acc: 93.3333%\n",
      "\ttrain 1-1345: Loss: 0.0088 Acc: 90.0000%\n",
      "\ttrain 1-1346: Loss: 0.0215 Acc: 76.6667%\n",
      "\ttrain 1-1347: Loss: 0.0139 Acc: 90.0000%\n",
      "\ttrain 1-1348: Loss: 0.0241 Acc: 76.6667%\n",
      "\ttrain 1-1349: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-1350: Loss: 0.0193 Acc: 80.0000%\n",
      "\ttrain 1-1351: Loss: 0.0252 Acc: 80.0000%\n",
      "\ttrain 1-1352: Loss: 0.0187 Acc: 86.6667%\n",
      "\ttrain 1-1353: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-1354: Loss: 0.0140 Acc: 86.6667%\n",
      "\ttrain 1-1355: Loss: 0.0090 Acc: 86.6667%\n",
      "\ttrain 1-1356: Loss: 0.0154 Acc: 83.3333%\n",
      "\ttrain 1-1357: Loss: 0.0109 Acc: 86.6667%\n",
      "\ttrain 1-1358: Loss: 0.0160 Acc: 83.3333%\n",
      "\ttrain 1-1359: Loss: 0.0183 Acc: 86.6667%\n",
      "\ttrain 1-1360: Loss: 0.0110 Acc: 86.6667%\n",
      "\ttrain 1-1361: Loss: 0.0148 Acc: 86.6667%\n",
      "\ttrain 1-1362: Loss: 0.0206 Acc: 73.3333%\n",
      "\ttrain 1-1363: Loss: 0.0124 Acc: 90.0000%\n",
      "\ttrain 1-1364: Loss: 0.0212 Acc: 73.3333%\n",
      "\ttrain 1-1365: Loss: 0.0136 Acc: 90.0000%\n",
      "\ttrain 1-1366: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-1367: Loss: 0.0103 Acc: 90.0000%\n",
      "\ttrain 1-1368: Loss: 0.0151 Acc: 86.6667%\n",
      "\ttrain 1-1369: Loss: 0.0103 Acc: 93.3333%\n",
      "\ttrain 1-1370: Loss: 0.0206 Acc: 86.6667%\n",
      "\ttrain 1-1371: Loss: 0.0146 Acc: 83.3333%\n",
      "\ttrain 1-1372: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain 1-1373: Loss: 0.0156 Acc: 73.3333%\n",
      "\ttrain 1-1374: Loss: 0.0177 Acc: 86.6667%\n",
      "\ttrain 1-1375: Loss: 0.0126 Acc: 86.6667%\n",
      "\ttrain 1-1376: Loss: 0.0148 Acc: 80.0000%\n",
      "\ttrain 1-1377: Loss: 0.0094 Acc: 90.0000%\n",
      "\ttrain 1-1378: Loss: 0.0109 Acc: 86.6667%\n",
      "\ttrain 1-1379: Loss: 0.0196 Acc: 76.6667%\n",
      "\ttrain 1-1380: Loss: 0.0076 Acc: 90.0000%\n",
      "\ttrain 1-1381: Loss: 0.0107 Acc: 90.0000%\n",
      "\ttrain 1-1382: Loss: 0.0102 Acc: 86.6667%\n",
      "\ttrain 1-1383: Loss: 0.0145 Acc: 86.6667%\n",
      "\ttrain 1-1384: Loss: 0.0101 Acc: 86.6667%\n",
      "\ttrain 1-1385: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-1386: Loss: 0.0193 Acc: 76.6667%\n",
      "\ttrain 1-1387: Loss: 0.0167 Acc: 80.0000%\n",
      "\ttrain 1-1388: Loss: 0.0100 Acc: 96.6667%\n",
      "\ttrain 1-1389: Loss: 0.0072 Acc: 90.0000%\n",
      "\ttrain 1-1390: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 1-1391: Loss: 0.0106 Acc: 86.6667%\n",
      "\ttrain 1-1392: Loss: 0.0098 Acc: 93.3333%\n",
      "\ttrain 1-1393: Loss: 0.0107 Acc: 83.3333%\n",
      "\ttrain 1-1394: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-1395: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-1396: Loss: 0.0113 Acc: 76.6667%\n",
      "\ttrain 1-1397: Loss: 0.0073 Acc: 90.0000%\n",
      "\ttrain 1-1398: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-1399: Loss: 0.0106 Acc: 90.0000%\n",
      "\ttrain 1-1400: Loss: 0.0135 Acc: 83.3333%\n",
      "\ttrain 1-1401: Loss: 0.0130 Acc: 86.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-1402: Loss: 0.0042 Acc: 90.0000%\n",
      "\ttrain 1-1403: Loss: 0.0077 Acc: 90.0000%\n",
      "\ttrain 1-1404: Loss: 0.0069 Acc: 90.0000%\n",
      "\ttrain 1-1405: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 1-1406: Loss: 0.0173 Acc: 80.0000%\n",
      "\ttrain 1-1407: Loss: 0.0303 Acc: 66.6667%\n",
      "\ttrain 1-1408: Loss: 0.0189 Acc: 73.3333%\n",
      "\ttrain 1-1409: Loss: 0.0197 Acc: 76.6667%\n",
      "\ttrain 1-1410: Loss: 0.0125 Acc: 83.3333%\n",
      "\ttrain 1-1411: Loss: 0.0117 Acc: 83.3333%\n",
      "\ttrain 1-1412: Loss: 0.0204 Acc: 73.3333%\n",
      "\ttrain 1-1413: Loss: 0.0243 Acc: 83.3333%\n",
      "\ttrain 1-1414: Loss: 0.0288 Acc: 73.3333%\n",
      "\ttrain 1-1415: Loss: 0.0116 Acc: 83.3333%\n",
      "\ttrain 1-1416: Loss: 0.0125 Acc: 86.6667%\n",
      "\ttrain 1-1417: Loss: 0.0220 Acc: 83.3333%\n",
      "\ttrain 1-1418: Loss: 0.0104 Acc: 86.6667%\n",
      "\ttrain 1-1419: Loss: 0.0171 Acc: 80.0000%\n",
      "\ttrain 1-1420: Loss: 0.0142 Acc: 80.0000%\n",
      "\ttrain 1-1421: Loss: 0.0140 Acc: 90.0000%\n",
      "\ttrain 1-1422: Loss: 0.0151 Acc: 83.3333%\n",
      "\ttrain 1-1423: Loss: 0.0122 Acc: 80.0000%\n",
      "\ttrain 1-1424: Loss: 0.0174 Acc: 83.3333%\n",
      "\ttrain 1-1425: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 1-1426: Loss: 0.0184 Acc: 80.0000%\n",
      "\ttrain 1-1427: Loss: 0.0076 Acc: 96.6667%\n",
      "\ttrain 1-1428: Loss: 0.0226 Acc: 83.3333%\n",
      "\ttrain 1-1429: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 1-1430: Loss: 0.0176 Acc: 86.6667%\n",
      "\ttrain 1-1431: Loss: 0.0106 Acc: 86.6667%\n",
      "\ttrain 1-1432: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 1-1433: Loss: 0.0098 Acc: 83.3333%\n",
      "\ttrain 1-1434: Loss: 0.0170 Acc: 90.0000%\n",
      "\ttrain 1-1435: Loss: 0.0124 Acc: 83.3333%\n",
      "\ttrain 1-1436: Loss: 0.0208 Acc: 76.6667%\n",
      "\ttrain 1-1437: Loss: 0.0107 Acc: 86.6667%\n",
      "\ttrain 1-1438: Loss: 0.0148 Acc: 93.3333%\n",
      "\ttrain 1-1439: Loss: 0.0127 Acc: 86.6667%\n",
      "\ttrain 1-1440: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 1-1441: Loss: 0.0155 Acc: 76.6667%\n",
      "\ttrain 1-1442: Loss: 0.0088 Acc: 90.0000%\n",
      "\ttrain 1-1443: Loss: 0.0069 Acc: 90.0000%\n",
      "\ttrain 1-1444: Loss: 0.0322 Acc: 73.3333%\n",
      "\ttrain 1-1445: Loss: 0.0234 Acc: 86.6667%\n",
      "\ttrain 1-1446: Loss: 0.0168 Acc: 73.3333%\n",
      "\ttrain 1-1447: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-1448: Loss: 0.0146 Acc: 73.3333%\n",
      "\ttrain 1-1449: Loss: 0.0113 Acc: 86.6667%\n",
      "\ttrain 1-1450: Loss: 0.0129 Acc: 93.3333%\n",
      "\ttrain 1-1451: Loss: 0.0133 Acc: 80.0000%\n",
      "\ttrain 1-1452: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-1453: Loss: 0.0139 Acc: 80.0000%\n",
      "\ttrain 1-1454: Loss: 0.0106 Acc: 90.0000%\n",
      "\ttrain 1-1455: Loss: 0.0172 Acc: 76.6667%\n",
      "\ttrain 1-1456: Loss: 0.0191 Acc: 80.0000%\n",
      "\ttrain 1-1457: Loss: 0.0233 Acc: 76.6667%\n",
      "\ttrain 1-1458: Loss: 0.0234 Acc: 76.6667%\n",
      "\ttrain 1-1459: Loss: 0.0196 Acc: 80.0000%\n",
      "\ttrain 1-1460: Loss: 0.0101 Acc: 90.0000%\n",
      "\ttrain 1-1461: Loss: 0.0172 Acc: 83.3333%\n",
      "\ttrain 1-1462: Loss: 0.0106 Acc: 90.0000%\n",
      "\ttrain 1-1463: Loss: 0.0186 Acc: 86.6667%\n",
      "\ttrain 1-1464: Loss: 0.0211 Acc: 83.3333%\n",
      "\ttrain 1-1465: Loss: 0.0089 Acc: 90.0000%\n",
      "\ttrain 1-1466: Loss: 0.0173 Acc: 86.6667%\n",
      "\ttrain 1-1467: Loss: 0.0076 Acc: 96.6667%\n",
      "\ttrain 1-1468: Loss: 0.0129 Acc: 86.6667%\n",
      "\ttrain 1-1469: Loss: 0.0160 Acc: 83.3333%\n",
      "\ttrain 1-1470: Loss: 0.0154 Acc: 83.3333%\n",
      "\ttrain 1-1471: Loss: 0.0153 Acc: 86.6667%\n",
      "\ttrain 1-1472: Loss: 0.0082 Acc: 90.0000%\n",
      "\ttrain 1-1473: Loss: 0.0045 Acc: 100.0000%\n",
      "\ttrain 1-1474: Loss: 0.0161 Acc: 80.0000%\n",
      "\ttrain 1-1475: Loss: 0.0169 Acc: 86.6667%\n",
      "\ttrain 1-1476: Loss: 0.0105 Acc: 86.6667%\n",
      "\ttrain 1-1477: Loss: 0.0138 Acc: 83.3333%\n",
      "\ttrain 1-1478: Loss: 0.0188 Acc: 80.0000%\n",
      "\ttrain 1-1479: Loss: 0.0141 Acc: 80.0000%\n",
      "\ttrain 1-1480: Loss: 0.0099 Acc: 86.6667%\n",
      "\ttrain 1-1481: Loss: 0.0179 Acc: 86.6667%\n",
      "\ttrain 1-1482: Loss: 0.0184 Acc: 76.6667%\n",
      "\ttrain 1-1483: Loss: 0.0288 Acc: 76.6667%\n",
      "\ttrain 1-1484: Loss: 0.0118 Acc: 86.6667%\n",
      "\ttrain 1-1485: Loss: 0.0089 Acc: 90.0000%\n",
      "\ttrain 1-1486: Loss: 0.0134 Acc: 90.0000%\n",
      "\ttrain 1-1487: Loss: 0.0141 Acc: 83.3333%\n",
      "\ttrain 1-1488: Loss: 0.0179 Acc: 73.3333%\n",
      "\ttrain 1-1489: Loss: 0.0131 Acc: 90.0000%\n",
      "\ttrain 1-1490: Loss: 0.0162 Acc: 86.6667%\n",
      "\ttrain 1-1491: Loss: 0.0152 Acc: 86.6667%\n",
      "\ttrain 1-1492: Loss: 0.0120 Acc: 90.0000%\n",
      "\ttrain 1-1493: Loss: 0.0184 Acc: 83.3333%\n",
      "\ttrain 1-1494: Loss: 0.0084 Acc: 86.6667%\n",
      "\ttrain 1-1495: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-1496: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-1497: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 1-1498: Loss: 0.0124 Acc: 83.3333%\n",
      "\ttrain 1-1499: Loss: 0.0107 Acc: 86.6667%\n",
      "\ttrain 1-1500: Loss: 0.0297 Acc: 73.3333%\n",
      "\ttrain 1-1501: Loss: 0.0178 Acc: 90.0000%\n",
      "\ttrain 1-1502: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-1503: Loss: 0.0219 Acc: 73.3333%\n",
      "\ttrain 1-1504: Loss: 0.0182 Acc: 83.3333%\n",
      "\ttrain 1-1505: Loss: 0.0083 Acc: 86.6667%\n",
      "\ttrain 1-1506: Loss: 0.0148 Acc: 83.3333%\n",
      "\ttrain 1-1507: Loss: 0.0079 Acc: 86.6667%\n",
      "\ttrain 1-1508: Loss: 0.0110 Acc: 80.0000%\n",
      "\ttrain 1-1509: Loss: 0.0119 Acc: 86.6667%\n",
      "\ttrain 1-1510: Loss: 0.0143 Acc: 90.0000%\n",
      "\ttrain 1-1511: Loss: 0.0073 Acc: 90.0000%\n",
      "\ttrain 1-1512: Loss: 0.0097 Acc: 86.6667%\n",
      "\ttrain 1-1513: Loss: 0.0100 Acc: 86.6667%\n",
      "\ttrain 1-1514: Loss: 0.0152 Acc: 83.3333%\n",
      "\ttrain 1-1515: Loss: 0.0117 Acc: 86.6667%\n",
      "\ttrain 1-1516: Loss: 0.0183 Acc: 76.6667%\n",
      "\ttrain 1-1517: Loss: 0.0184 Acc: 80.0000%\n",
      "\ttrain 1-1518: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-1519: Loss: 0.0125 Acc: 90.0000%\n",
      "\ttrain 1-1520: Loss: 0.0059 Acc: 100.0000%\n",
      "\ttrain 1-1521: Loss: 0.0097 Acc: 96.6667%\n",
      "\ttrain 1-1522: Loss: 0.0137 Acc: 86.6667%\n",
      "\ttrain 1-1523: Loss: 0.0139 Acc: 83.3333%\n",
      "\ttrain 1-1524: Loss: 0.0256 Acc: 80.0000%\n",
      "\ttrain 1-1525: Loss: 0.0132 Acc: 86.6667%\n",
      "\ttrain 1-1526: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 1-1527: Loss: 0.0156 Acc: 83.3333%\n",
      "\ttrain 1-1528: Loss: 0.0142 Acc: 86.6667%\n",
      "\ttrain 1-1529: Loss: 0.0122 Acc: 86.6667%\n",
      "\ttrain 1-1530: Loss: 0.0173 Acc: 83.3333%\n",
      "\ttrain 1-1531: Loss: 0.0138 Acc: 86.6667%\n",
      "\ttrain 1-1532: Loss: 0.0098 Acc: 90.0000%\n",
      "\ttrain 1-1533: Loss: 0.0098 Acc: 90.0000%\n",
      "\ttrain 1-1534: Loss: 0.0133 Acc: 90.0000%\n",
      "\ttrain 1-1535: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 1-1536: Loss: 0.0175 Acc: 83.3333%\n",
      "\ttrain 1-1537: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-1538: Loss: 0.0158 Acc: 86.6667%\n",
      "\ttrain 1-1539: Loss: 0.0143 Acc: 86.6667%\n",
      "\ttrain 1-1540: Loss: 0.0113 Acc: 80.0000%\n",
      "\ttrain 1-1541: Loss: 0.0124 Acc: 86.6667%\n",
      "\ttrain 1-1542: Loss: 0.0109 Acc: 90.0000%\n",
      "\ttrain 1-1543: Loss: 0.0132 Acc: 86.6667%\n",
      "\ttrain 1-1544: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-1545: Loss: 0.0140 Acc: 86.6667%\n",
      "\ttrain 1-1546: Loss: 0.0242 Acc: 73.3333%\n",
      "\ttrain 1-1547: Loss: 0.0217 Acc: 83.3333%\n",
      "\ttrain 1-1548: Loss: 0.0105 Acc: 90.0000%\n",
      "\ttrain 1-1549: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-1550: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-1551: Loss: 0.0212 Acc: 86.6667%\n",
      "\ttrain 1-1552: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 1-1553: Loss: 0.0165 Acc: 80.0000%\n",
      "\ttrain 1-1554: Loss: 0.0135 Acc: 90.0000%\n",
      "\ttrain 1-1555: Loss: 0.0121 Acc: 90.0000%\n",
      "\ttrain 1-1556: Loss: 0.0096 Acc: 86.6667%\n",
      "\ttrain 1-1557: Loss: 0.0223 Acc: 73.3333%\n",
      "\ttrain 1-1558: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 1-1559: Loss: 0.0097 Acc: 90.0000%\n",
      "\ttrain 1-1560: Loss: 0.0123 Acc: 93.3333%\n",
      "\ttrain 1-1561: Loss: 0.0088 Acc: 90.0000%\n",
      "\ttrain 1-1562: Loss: 0.0109 Acc: 83.3333%\n",
      "\ttrain 1-1563: Loss: 0.0135 Acc: 83.3333%\n",
      "\ttrain 1-1564: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-1565: Loss: 0.0109 Acc: 90.0000%\n",
      "\ttrain 1-1566: Loss: 0.0308 Acc: 86.6667%\n",
      "\ttrain 1-1567: Loss: 0.0235 Acc: 80.0000%\n",
      "\ttrain 1-1568: Loss: 0.0231 Acc: 83.3333%\n",
      "\ttrain 1-1569: Loss: 0.0211 Acc: 73.3333%\n",
      "\ttrain 1-1570: Loss: 0.0116 Acc: 93.3333%\n",
      "\ttrain 1-1571: Loss: 0.0166 Acc: 90.0000%\n",
      "\ttrain 1-1572: Loss: 0.0139 Acc: 90.0000%\n",
      "\ttrain 1-1573: Loss: 0.0083 Acc: 86.6667%\n",
      "\ttrain 1-1574: Loss: 0.0140 Acc: 90.0000%\n",
      "\ttrain 1-1575: Loss: 0.0043 Acc: 100.0000%\n",
      "\ttrain 1-1576: Loss: 0.0159 Acc: 86.6667%\n",
      "\ttrain 1-1577: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 1-1578: Loss: 0.0146 Acc: 86.6667%\n",
      "\ttrain 1-1579: Loss: 0.0071 Acc: 86.6667%\n",
      "\ttrain 1-1580: Loss: 0.0125 Acc: 86.6667%\n",
      "\ttrain 1-1581: Loss: 0.0076 Acc: 90.0000%\n",
      "\ttrain 1-1582: Loss: 0.0154 Acc: 86.6667%\n",
      "\ttrain 1-1583: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-1584: Loss: 0.0220 Acc: 80.0000%\n",
      "\ttrain 1-1585: Loss: 0.0143 Acc: 80.0000%\n",
      "\ttrain 1-1586: Loss: 0.0131 Acc: 86.6667%\n",
      "\ttrain 1-1587: Loss: 0.0182 Acc: 80.0000%\n",
      "\ttrain 1-1588: Loss: 0.0131 Acc: 76.6667%\n",
      "\ttrain 1-1589: Loss: 0.0131 Acc: 90.0000%\n",
      "\ttrain 1-1590: Loss: 0.0104 Acc: 86.6667%\n",
      "\ttrain 1-1591: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 1-1592: Loss: 0.0155 Acc: 76.6667%\n",
      "\ttrain 1-1593: Loss: 0.0109 Acc: 90.0000%\n",
      "\ttrain 1-1594: Loss: 0.0133 Acc: 90.0000%\n",
      "\ttrain 1-1595: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 1-1596: Loss: 0.0051 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-1597: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 1-1598: Loss: 0.0143 Acc: 83.3333%\n",
      "\ttrain 1-1599: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-1600: Loss: 0.0085 Acc: 86.6667%\n",
      "\ttrain 1-1601: Loss: 0.0140 Acc: 80.0000%\n",
      "\ttrain 1-1602: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-1603: Loss: 0.0113 Acc: 93.3333%\n",
      "\ttrain 1-1604: Loss: 0.0153 Acc: 76.6667%\n",
      "\ttrain 1-1605: Loss: 0.0122 Acc: 83.3333%\n",
      "\ttrain 1-1606: Loss: 0.0086 Acc: 90.0000%\n",
      "\ttrain 1-1607: Loss: 0.0142 Acc: 90.0000%\n",
      "\ttrain 1-1608: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-1609: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-1610: Loss: 0.0129 Acc: 86.6667%\n",
      "\ttrain 1-1611: Loss: 0.0105 Acc: 93.3333%\n",
      "\ttrain 1-1612: Loss: 0.0078 Acc: 86.6667%\n",
      "\ttrain 1-1613: Loss: 0.0189 Acc: 86.6667%\n",
      "\ttrain 1-1614: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 1-1615: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-1616: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 1-1617: Loss: 0.0119 Acc: 86.6667%\n",
      "\ttrain 1-1618: Loss: 0.0178 Acc: 80.0000%\n",
      "\ttrain 1-1619: Loss: 0.0108 Acc: 86.6667%\n",
      "\ttrain 1-1620: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 1-1621: Loss: 0.0113 Acc: 90.0000%\n",
      "\ttrain 1-1622: Loss: 0.0081 Acc: 90.0000%\n",
      "\ttrain 1-1623: Loss: 0.0152 Acc: 90.0000%\n",
      "\ttrain 1-1624: Loss: 0.0222 Acc: 76.6667%\n",
      "\ttrain 1-1625: Loss: 0.0115 Acc: 86.6667%\n",
      "\ttrain 1-1626: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-1627: Loss: 0.0207 Acc: 86.6667%\n",
      "\ttrain 1-1628: Loss: 0.0078 Acc: 83.3333%\n",
      "\ttrain 1-1629: Loss: 0.0168 Acc: 83.3333%\n",
      "\ttrain 1-1630: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-1631: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 1-1632: Loss: 0.0121 Acc: 90.0000%\n",
      "\ttrain 1-1633: Loss: 0.0122 Acc: 86.6667%\n",
      "\ttrain 1-1634: Loss: 0.0139 Acc: 83.3333%\n",
      "\ttrain 1-1635: Loss: 0.0109 Acc: 80.0000%\n",
      "\ttrain 1-1636: Loss: 0.0119 Acc: 93.3333%\n",
      "\ttrain 1-1637: Loss: 0.0137 Acc: 86.6667%\n",
      "\ttrain 1-1638: Loss: 0.0155 Acc: 90.0000%\n",
      "\ttrain 1-1639: Loss: 0.0163 Acc: 76.6667%\n",
      "\ttrain 1-1640: Loss: 0.0139 Acc: 83.3333%\n",
      "\ttrain 1-1641: Loss: 0.0128 Acc: 86.6667%\n",
      "\ttrain 1-1642: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-1643: Loss: 0.0083 Acc: 93.3333%\n",
      "\ttrain 1-1644: Loss: 0.0133 Acc: 76.6667%\n",
      "\ttrain 1-1645: Loss: 0.0121 Acc: 83.3333%\n",
      "\ttrain 1-1646: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-1647: Loss: 0.0103 Acc: 93.3333%\n",
      "\ttrain 1-1648: Loss: 0.0057 Acc: 90.0000%\n",
      "\ttrain 1-1649: Loss: 0.0199 Acc: 86.6667%\n",
      "\ttrain 1-1650: Loss: 0.0139 Acc: 83.3333%\n",
      "\ttrain 1-1651: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-1652: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-1653: Loss: 0.0081 Acc: 86.6667%\n",
      "\ttrain 1-1654: Loss: 0.0097 Acc: 86.6667%\n",
      "\ttrain 1-1655: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-1656: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-1657: Loss: 0.0099 Acc: 90.0000%\n",
      "\ttrain 1-1658: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-1659: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-1660: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 1-1661: Loss: 0.0148 Acc: 80.0000%\n",
      "\ttrain 1-1662: Loss: 0.0210 Acc: 90.0000%\n",
      "\ttrain 1-1663: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-1664: Loss: 0.0141 Acc: 86.6667%\n",
      "\ttrain 1-1665: Loss: 0.0187 Acc: 83.3333%\n",
      "\ttrain 1-1666: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-1667: Loss: 0.0080 Acc: 83.3333%\n",
      "\ttrain 1-1668: Loss: 0.0184 Acc: 80.0000%\n",
      "\ttrain 1-1669: Loss: 0.0148 Acc: 83.3333%\n",
      "\ttrain 1-1670: Loss: 0.0154 Acc: 86.6667%\n",
      "\ttrain 1-1671: Loss: 0.0147 Acc: 86.6667%\n",
      "\ttrain 1-1672: Loss: 0.0102 Acc: 90.0000%\n",
      "\ttrain 1-1673: Loss: 0.0058 Acc: 90.0000%\n",
      "\ttrain 1-1674: Loss: 0.0192 Acc: 80.0000%\n",
      "\ttrain 1-1675: Loss: 0.0121 Acc: 83.3333%\n",
      "\ttrain 1-1676: Loss: 0.0116 Acc: 90.0000%\n",
      "\ttrain 1-1677: Loss: 0.0078 Acc: 90.0000%\n",
      "\ttrain 1-1678: Loss: 0.0097 Acc: 83.3333%\n",
      "\ttrain 1-1679: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-1680: Loss: 0.0150 Acc: 83.3333%\n",
      "\ttrain 1-1681: Loss: 0.0212 Acc: 83.3333%\n",
      "\ttrain 1-1682: Loss: 0.0131 Acc: 86.6667%\n",
      "\ttrain 1-1683: Loss: 0.0159 Acc: 83.3333%\n",
      "\ttrain 1-1684: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain 1-1685: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-1686: Loss: 0.0103 Acc: 90.0000%\n",
      "\ttrain 1-1687: Loss: 0.0153 Acc: 83.3333%\n",
      "\ttrain 1-1688: Loss: 0.0111 Acc: 86.6667%\n",
      "\ttrain 1-1689: Loss: 0.0252 Acc: 83.3333%\n",
      "\ttrain 1-1690: Loss: 0.0102 Acc: 83.3333%\n",
      "\ttrain 1-1691: Loss: 0.0114 Acc: 86.6667%\n",
      "\ttrain 1-1692: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-1693: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 1-1694: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 1-1695: Loss: 0.0221 Acc: 80.0000%\n",
      "\ttrain 1-1696: Loss: 0.0160 Acc: 80.0000%\n",
      "\ttrain 1-1697: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 1-1698: Loss: 0.0147 Acc: 76.6667%\n",
      "\ttrain 1-1699: Loss: 0.0214 Acc: 83.3333%\n",
      "\ttrain 1-1700: Loss: 0.0100 Acc: 96.6667%\n",
      "\ttrain 1-1701: Loss: 0.0091 Acc: 90.0000%\n",
      "\ttrain 1-1702: Loss: 0.0209 Acc: 76.6667%\n",
      "\ttrain 1-1703: Loss: 0.0098 Acc: 93.3333%\n",
      "\ttrain 1-1704: Loss: 0.0160 Acc: 83.3333%\n",
      "\ttrain 1-1705: Loss: 0.0138 Acc: 86.6667%\n",
      "\ttrain 1-1706: Loss: 0.0080 Acc: 86.6667%\n",
      "\ttrain 1-1707: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-1708: Loss: 0.0113 Acc: 93.3333%\n",
      "\ttrain 1-1709: Loss: 0.0187 Acc: 80.0000%\n",
      "\ttrain 1-1710: Loss: 0.0068 Acc: 90.0000%\n",
      "\ttrain 1-1711: Loss: 0.0119 Acc: 93.3333%\n",
      "\ttrain 1-1712: Loss: 0.0104 Acc: 90.0000%\n",
      "\ttrain 1-1713: Loss: 0.0247 Acc: 80.0000%\n",
      "\ttrain 1-1714: Loss: 0.0092 Acc: 90.0000%\n",
      "\ttrain 1-1715: Loss: 0.0210 Acc: 80.0000%\n",
      "\ttrain 1-1716: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-1717: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 1-1718: Loss: 0.0106 Acc: 83.3333%\n",
      "\ttrain 1-1719: Loss: 0.0251 Acc: 73.3333%\n",
      "\ttrain 1-1720: Loss: 0.0103 Acc: 93.3333%\n",
      "\ttrain 1-1721: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-1722: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 1-1723: Loss: 0.0097 Acc: 83.3333%\n",
      "\ttrain 1-1724: Loss: 0.0078 Acc: 93.3333%\n",
      "\ttrain 1-1725: Loss: 0.0098 Acc: 83.3333%\n",
      "\ttrain 1-1726: Loss: 0.0068 Acc: 90.0000%\n",
      "\ttrain 1-1727: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 1-1728: Loss: 0.0162 Acc: 86.6667%\n",
      "\ttrain 1-1729: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-1730: Loss: 0.0089 Acc: 86.6667%\n",
      "\ttrain 1-1731: Loss: 0.0114 Acc: 93.3333%\n",
      "\ttrain 1-1732: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-1733: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 1-1734: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-1735: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-1736: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-1737: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-1738: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-1739: Loss: 0.0176 Acc: 86.6667%\n",
      "\ttrain 1-1740: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-1741: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-1742: Loss: 0.0125 Acc: 86.6667%\n",
      "\ttrain 1-1743: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 1-1744: Loss: 0.0022 Acc: 93.3333%\n",
      "\ttrain 1-1745: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-1746: Loss: 0.0109 Acc: 90.0000%\n",
      "\ttrain 1-1747: Loss: 0.0138 Acc: 86.6667%\n",
      "\ttrain 1-1748: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 1-1749: Loss: 0.0115 Acc: 83.3333%\n",
      "\ttrain 1-1750: Loss: 0.0050 Acc: 100.0000%\n",
      "\ttrain 1-1751: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-1752: Loss: 0.0098 Acc: 90.0000%\n",
      "\ttrain 1-1753: Loss: 0.0128 Acc: 83.3333%\n",
      "\ttrain 1-1754: Loss: 0.0050 Acc: 90.0000%\n",
      "\ttrain 1-1755: Loss: 0.0099 Acc: 90.0000%\n",
      "\ttrain 1-1756: Loss: 0.0196 Acc: 83.3333%\n",
      "\ttrain 1-1757: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-1758: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-1759: Loss: 0.0184 Acc: 93.3333%\n",
      "\ttrain 1-1760: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-1761: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-1762: Loss: 0.0086 Acc: 93.3333%\n",
      "\ttrain 1-1763: Loss: 0.0121 Acc: 90.0000%\n",
      "\ttrain 1-1764: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-1765: Loss: 0.0170 Acc: 83.3333%\n",
      "\ttrain 1-1766: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-1767: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-1768: Loss: 0.0081 Acc: 90.0000%\n",
      "\ttrain 1-1769: Loss: 0.0234 Acc: 76.6667%\n",
      "\ttrain 1-1770: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-1771: Loss: 0.0107 Acc: 86.6667%\n",
      "\ttrain 1-1772: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-1773: Loss: 0.0084 Acc: 96.6667%\n",
      "\ttrain 1-1774: Loss: 0.0184 Acc: 86.6667%\n",
      "\ttrain 1-1775: Loss: 0.0128 Acc: 90.0000%\n",
      "\ttrain 1-1776: Loss: 0.0106 Acc: 96.6667%\n",
      "\ttrain 1-1777: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 1-1778: Loss: 0.0091 Acc: 86.6667%\n",
      "\ttrain 1-1779: Loss: 0.0082 Acc: 90.0000%\n",
      "\ttrain 1-1780: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-1781: Loss: 0.0084 Acc: 86.6667%\n",
      "\ttrain 1-1782: Loss: 0.0095 Acc: 93.3333%\n",
      "\ttrain 1-1783: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-1784: Loss: 0.0035 Acc: 100.0000%\n",
      "\ttrain 1-1785: Loss: 0.0159 Acc: 93.3333%\n",
      "\ttrain 1-1786: Loss: 0.0100 Acc: 90.0000%\n",
      "\ttrain 1-1787: Loss: 0.0113 Acc: 83.3333%\n",
      "\ttrain 1-1788: Loss: 0.0104 Acc: 90.0000%\n",
      "\ttrain 1-1789: Loss: 0.0077 Acc: 90.0000%\n",
      "\ttrain 1-1790: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-1791: Loss: 0.0055 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-1792: Loss: 0.0168 Acc: 86.6667%\n",
      "\ttrain 1-1793: Loss: 0.0097 Acc: 86.6667%\n",
      "\ttrain 1-1794: Loss: 0.0124 Acc: 90.0000%\n",
      "\ttrain 1-1795: Loss: 0.0191 Acc: 76.6667%\n",
      "\ttrain 1-1796: Loss: 0.0086 Acc: 86.6667%\n",
      "\ttrain 1-1797: Loss: 0.0121 Acc: 93.3333%\n",
      "\ttrain 1-1798: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-1799: Loss: 0.0110 Acc: 83.3333%\n",
      "\ttrain 1-1800: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-1801: Loss: 0.0149 Acc: 80.0000%\n",
      "\ttrain 1-1802: Loss: 0.0180 Acc: 86.6667%\n",
      "\ttrain 1-1803: Loss: 0.0075 Acc: 86.6667%\n",
      "\ttrain 1-1804: Loss: 0.0110 Acc: 86.6667%\n",
      "\ttrain 1-1805: Loss: 0.0075 Acc: 90.0000%\n",
      "\ttrain 1-1806: Loss: 0.0108 Acc: 93.3333%\n",
      "\ttrain 1-1807: Loss: 0.0090 Acc: 86.6667%\n",
      "\ttrain 1-1808: Loss: 0.0167 Acc: 86.6667%\n",
      "\ttrain 1-1809: Loss: 0.0089 Acc: 86.6667%\n",
      "\ttrain 1-1810: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-1811: Loss: 0.0178 Acc: 86.6667%\n",
      "\ttrain 1-1812: Loss: 0.0181 Acc: 83.3333%\n",
      "\ttrain 1-1813: Loss: 0.0176 Acc: 83.3333%\n",
      "\ttrain 1-1814: Loss: 0.0121 Acc: 83.3333%\n",
      "\ttrain 1-1815: Loss: 0.0115 Acc: 90.0000%\n",
      "\ttrain 1-1816: Loss: 0.0188 Acc: 90.0000%\n",
      "\ttrain 1-1817: Loss: 0.0171 Acc: 86.6667%\n",
      "\ttrain 1-1818: Loss: 0.0126 Acc: 86.6667%\n",
      "\ttrain 1-1819: Loss: 0.0157 Acc: 83.3333%\n",
      "\ttrain 1-1820: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-1821: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 1-1822: Loss: 0.0077 Acc: 96.6667%\n",
      "\ttrain 1-1823: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-1824: Loss: 0.0154 Acc: 80.0000%\n",
      "\ttrain 1-1825: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-1826: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-1827: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-1828: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 1-1829: Loss: 0.0076 Acc: 90.0000%\n",
      "\ttrain 1-1830: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-1831: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-1832: Loss: 0.0356 Acc: 80.0000%\n",
      "\ttrain 1-1833: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 1-1834: Loss: 0.0116 Acc: 83.3333%\n",
      "\ttrain 1-1835: Loss: 0.0107 Acc: 93.3333%\n",
      "\ttrain 1-1836: Loss: 0.0114 Acc: 90.0000%\n",
      "\ttrain 1-1837: Loss: 0.0119 Acc: 86.6667%\n",
      "\ttrain 1-1838: Loss: 0.0089 Acc: 93.3333%\n",
      "\ttrain 1-1839: Loss: 0.0200 Acc: 80.0000%\n",
      "\ttrain 1-1840: Loss: 0.0099 Acc: 90.0000%\n",
      "\ttrain 1-1841: Loss: 0.0164 Acc: 80.0000%\n",
      "\ttrain 1-1842: Loss: 0.0109 Acc: 90.0000%\n",
      "\ttrain 1-1843: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 1-1844: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 1-1845: Loss: 0.0165 Acc: 83.3333%\n",
      "\ttrain 1-1846: Loss: 0.0086 Acc: 86.6667%\n",
      "\ttrain 1-1847: Loss: 0.0151 Acc: 83.3333%\n",
      "\ttrain 1-1848: Loss: 0.0071 Acc: 96.6667%\n",
      "\ttrain 1-1849: Loss: 0.0082 Acc: 90.0000%\n",
      "\ttrain 1-1850: Loss: 0.0079 Acc: 86.6667%\n",
      "\ttrain 1-1851: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-1852: Loss: 0.0152 Acc: 90.0000%\n",
      "\ttrain 1-1853: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 1-1854: Loss: 0.0145 Acc: 86.6667%\n",
      "\ttrain 1-1855: Loss: 0.0062 Acc: 90.0000%\n",
      "\ttrain 1-1856: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-1857: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-1858: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 1-1859: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 1-1860: Loss: 0.0214 Acc: 83.3333%\n",
      "\ttrain 1-1861: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-1862: Loss: 0.0107 Acc: 83.3333%\n",
      "\ttrain 1-1863: Loss: 0.0119 Acc: 90.0000%\n",
      "\ttrain 1-1864: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-1865: Loss: 0.0092 Acc: 90.0000%\n",
      "\ttrain 1-1866: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-1867: Loss: 0.0122 Acc: 86.6667%\n",
      "\ttrain 1-1868: Loss: 0.0056 Acc: 90.0000%\n",
      "\ttrain 1-1869: Loss: 0.0098 Acc: 90.0000%\n",
      "\ttrain 1-1870: Loss: 0.0130 Acc: 83.3333%\n",
      "\ttrain 1-1871: Loss: 0.0158 Acc: 83.3333%\n",
      "\ttrain 1-1872: Loss: 0.0117 Acc: 76.6667%\n",
      "\ttrain 1-1873: Loss: 0.0117 Acc: 93.3333%\n",
      "\ttrain 1-1874: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-1875: Loss: 0.0119 Acc: 86.6667%\n",
      "\ttrain 1-1876: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-1877: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-1878: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-1879: Loss: 0.0073 Acc: 96.6667%\n",
      "\ttrain 1-1880: Loss: 0.0089 Acc: 90.0000%\n",
      "\ttrain 1-1881: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-1882: Loss: 0.0075 Acc: 90.0000%\n",
      "\ttrain 1-1883: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-1884: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-1885: Loss: 0.0168 Acc: 86.6667%\n",
      "\ttrain 1-1886: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-1887: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 1-1888: Loss: 0.0266 Acc: 83.3333%\n",
      "\ttrain 1-1889: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-1890: Loss: 0.0197 Acc: 86.6667%\n",
      "\ttrain 1-1891: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-1892: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-1893: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-1894: Loss: 0.0126 Acc: 90.0000%\n",
      "\ttrain 1-1895: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-1896: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-1897: Loss: 0.0096 Acc: 96.6667%\n",
      "\ttrain 1-1898: Loss: 0.0139 Acc: 86.6667%\n",
      "\ttrain 1-1899: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-1900: Loss: 0.0083 Acc: 86.6667%\n",
      "\ttrain 1-1901: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-1902: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-1903: Loss: 0.0082 Acc: 90.0000%\n",
      "\ttrain 1-1904: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-1905: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 1-1906: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-1907: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-1908: Loss: 0.0136 Acc: 86.6667%\n",
      "\ttrain 1-1909: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-1910: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 1-1911: Loss: 0.0091 Acc: 83.3333%\n",
      "\ttrain 1-1912: Loss: 0.0222 Acc: 80.0000%\n",
      "\ttrain 1-1913: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-1914: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-1915: Loss: 0.0103 Acc: 96.6667%\n",
      "\ttrain 1-1916: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-1917: Loss: 0.0131 Acc: 93.3333%\n",
      "\ttrain 1-1918: Loss: 0.0061 Acc: 90.0000%\n",
      "\ttrain 1-1919: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 1-1920: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-1921: Loss: 0.0058 Acc: 90.0000%\n",
      "\ttrain 1-1922: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 1-1923: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-1924: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-1925: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 1-1926: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-1927: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-1928: Loss: 0.0071 Acc: 93.3333%\n",
      "\ttrain 1-1929: Loss: 0.0301 Acc: 73.3333%\n",
      "\ttrain 1-1930: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 1-1931: Loss: 0.0109 Acc: 93.3333%\n",
      "\ttrain 1-1932: Loss: 0.0101 Acc: 83.3333%\n",
      "\ttrain 1-1933: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-1934: Loss: 0.0084 Acc: 90.0000%\n",
      "\ttrain 1-1935: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 1-1936: Loss: 0.0113 Acc: 93.3333%\n",
      "\ttrain 1-1937: Loss: 0.0067 Acc: 93.3333%\n",
      "\ttrain 1-1938: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-1939: Loss: 0.0132 Acc: 86.6667%\n",
      "\ttrain 1-1940: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-1941: Loss: 0.0147 Acc: 86.6667%\n",
      "\ttrain 1-1942: Loss: 0.0038 Acc: 93.3333%\n",
      "\ttrain 1-1943: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-1944: Loss: 0.0049 Acc: 90.0000%\n",
      "\ttrain 1-1945: Loss: 0.0063 Acc: 90.0000%\n",
      "\ttrain 1-1946: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-1947: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 1-1948: Loss: 0.0093 Acc: 90.0000%\n",
      "\ttrain 1-1949: Loss: 0.0084 Acc: 93.3333%\n",
      "\ttrain 1-1950: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-1951: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-1952: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-1953: Loss: 0.0117 Acc: 93.3333%\n",
      "\ttrain 1-1954: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-1955: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-1956: Loss: 0.0149 Acc: 86.6667%\n",
      "\ttrain 1-1957: Loss: 0.0074 Acc: 90.0000%\n",
      "\ttrain 1-1958: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain 1-1959: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-1960: Loss: 0.0126 Acc: 83.3333%\n",
      "\ttrain 1-1961: Loss: 0.0139 Acc: 86.6667%\n",
      "\ttrain 1-1962: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-1963: Loss: 0.0148 Acc: 80.0000%\n",
      "\ttrain 1-1964: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-1965: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-1966: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-1967: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-1968: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-1969: Loss: 0.0069 Acc: 90.0000%\n",
      "\ttrain 1-1970: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 1-1971: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-1972: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-1973: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-1974: Loss: 0.0079 Acc: 86.6667%\n",
      "\ttrain 1-1975: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-1976: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 1-1977: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-1978: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 1-1979: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-1980: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-1981: Loss: 0.0122 Acc: 86.6667%\n",
      "\ttrain 1-1982: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-1983: Loss: 0.0025 Acc: 93.3333%\n",
      "\ttrain 1-1984: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-1985: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-1986: Loss: 0.0028 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-1987: Loss: 0.0064 Acc: 90.0000%\n",
      "\ttrain 1-1988: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-1989: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-1990: Loss: 0.0086 Acc: 93.3333%\n",
      "\ttrain 1-1991: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-1992: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 1-1993: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-1994: Loss: 0.0318 Acc: 80.0000%\n",
      "\ttrain 1-1995: Loss: 0.0123 Acc: 93.3333%\n",
      "\ttrain 1-1996: Loss: 0.0131 Acc: 90.0000%\n",
      "\ttrain 1-1997: Loss: 0.0273 Acc: 80.0000%\n",
      "\ttrain 1-1998: Loss: 0.0111 Acc: 83.3333%\n",
      "\ttrain 1-1999: Loss: 0.0108 Acc: 93.3333%\n",
      "\ttrain 1-2000: Loss: 0.0087 Acc: 93.3333%\n",
      "\ttrain 1-2001: Loss: 0.0107 Acc: 83.3333%\n",
      "\ttrain 1-2002: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-2003: Loss: 0.0170 Acc: 80.0000%\n",
      "\ttrain 1-2004: Loss: 0.0105 Acc: 93.3333%\n",
      "\ttrain 1-2005: Loss: 0.0107 Acc: 90.0000%\n",
      "\ttrain 1-2006: Loss: 0.0116 Acc: 83.3333%\n",
      "\ttrain 1-2007: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2008: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2009: Loss: 0.0093 Acc: 90.0000%\n",
      "\ttrain 1-2010: Loss: 0.0092 Acc: 90.0000%\n",
      "\ttrain 1-2011: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 1-2012: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-2013: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2014: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-2015: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-2016: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 1-2017: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 1-2018: Loss: 0.0088 Acc: 90.0000%\n",
      "\ttrain 1-2019: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-2020: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-2021: Loss: 0.0085 Acc: 90.0000%\n",
      "\ttrain 1-2022: Loss: 0.0080 Acc: 96.6667%\n",
      "\ttrain 1-2023: Loss: 0.0149 Acc: 83.3333%\n",
      "\ttrain 1-2024: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-2025: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-2026: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-2027: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-2028: Loss: 0.0100 Acc: 93.3333%\n",
      "\ttrain 1-2029: Loss: 0.0105 Acc: 86.6667%\n",
      "\ttrain 1-2030: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-2031: Loss: 0.0086 Acc: 93.3333%\n",
      "\ttrain 1-2032: Loss: 0.0055 Acc: 90.0000%\n",
      "\ttrain 1-2033: Loss: 0.0210 Acc: 80.0000%\n",
      "\ttrain 1-2034: Loss: 0.0052 Acc: 90.0000%\n",
      "\ttrain 1-2035: Loss: 0.0081 Acc: 83.3333%\n",
      "\ttrain 1-2036: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-2037: Loss: 0.0075 Acc: 96.6667%\n",
      "\ttrain 1-2038: Loss: 0.0055 Acc: 90.0000%\n",
      "\ttrain 1-2039: Loss: 0.0148 Acc: 93.3333%\n",
      "\ttrain 1-2040: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-2041: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-2042: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2043: Loss: 0.0079 Acc: 86.6667%\n",
      "\ttrain 1-2044: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain 1-2045: Loss: 0.0106 Acc: 93.3333%\n",
      "\ttrain 1-2046: Loss: 0.0048 Acc: 90.0000%\n",
      "\ttrain 1-2047: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-2048: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2049: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-2050: Loss: 0.0163 Acc: 83.3333%\n",
      "\ttrain 1-2051: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 1-2052: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 1-2053: Loss: 0.0104 Acc: 93.3333%\n",
      "\ttrain 1-2054: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 1-2055: Loss: 0.0091 Acc: 90.0000%\n",
      "\ttrain 1-2056: Loss: 0.0084 Acc: 90.0000%\n",
      "\ttrain 1-2057: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-2058: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-2059: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 1-2060: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-2061: Loss: 0.0083 Acc: 93.3333%\n",
      "\ttrain 1-2062: Loss: 0.0083 Acc: 93.3333%\n",
      "\ttrain 1-2063: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-2064: Loss: 0.0086 Acc: 86.6667%\n",
      "\ttrain 1-2065: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 1-2066: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-2067: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2068: Loss: 0.0091 Acc: 83.3333%\n",
      "\ttrain 1-2069: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-2070: Loss: 0.0082 Acc: 96.6667%\n",
      "\ttrain 1-2071: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-2072: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 1-2073: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 1-2074: Loss: 0.0106 Acc: 93.3333%\n",
      "\ttrain 1-2075: Loss: 0.0174 Acc: 86.6667%\n",
      "\ttrain 1-2076: Loss: 0.0095 Acc: 90.0000%\n",
      "\ttrain 1-2077: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 1-2078: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-2079: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-2080: Loss: 0.0279 Acc: 80.0000%\n",
      "\ttrain 1-2081: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2082: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2083: Loss: 0.0098 Acc: 93.3333%\n",
      "\ttrain 1-2084: Loss: 0.0157 Acc: 83.3333%\n",
      "\ttrain 1-2085: Loss: 0.0108 Acc: 90.0000%\n",
      "\ttrain 1-2086: Loss: 0.0113 Acc: 90.0000%\n",
      "\ttrain 1-2087: Loss: 0.0095 Acc: 90.0000%\n",
      "\ttrain 1-2088: Loss: 0.0103 Acc: 86.6667%\n",
      "\ttrain 1-2089: Loss: 0.0142 Acc: 86.6667%\n",
      "\ttrain 1-2090: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-2091: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-2092: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 1-2093: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2094: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-2095: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2096: Loss: 0.0222 Acc: 90.0000%\n",
      "\ttrain 1-2097: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2098: Loss: 0.0058 Acc: 90.0000%\n",
      "\ttrain 1-2099: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2100: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 1-2101: Loss: 0.0083 Acc: 93.3333%\n",
      "\ttrain 1-2102: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2103: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 1-2104: Loss: 0.0097 Acc: 90.0000%\n",
      "\ttrain 1-2105: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2106: Loss: 0.0108 Acc: 93.3333%\n",
      "\ttrain 1-2107: Loss: 0.0101 Acc: 86.6667%\n",
      "\ttrain 1-2108: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2109: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2110: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2111: Loss: 0.0097 Acc: 90.0000%\n",
      "\ttrain 1-2112: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2113: Loss: 0.0101 Acc: 90.0000%\n",
      "\ttrain 1-2114: Loss: 0.0120 Acc: 93.3333%\n",
      "\ttrain 1-2115: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-2116: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-2117: Loss: 0.0110 Acc: 93.3333%\n",
      "\ttrain 1-2118: Loss: 0.0128 Acc: 86.6667%\n",
      "\ttrain 1-2119: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2120: Loss: 0.0089 Acc: 86.6667%\n",
      "\ttrain 1-2121: Loss: 0.0083 Acc: 93.3333%\n",
      "\ttrain 1-2122: Loss: 0.0094 Acc: 90.0000%\n",
      "\ttrain 1-2123: Loss: 0.0085 Acc: 90.0000%\n",
      "\ttrain 1-2124: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-2125: Loss: 0.0208 Acc: 80.0000%\n",
      "\ttrain 1-2126: Loss: 0.0054 Acc: 90.0000%\n",
      "\ttrain 1-2127: Loss: 0.0080 Acc: 83.3333%\n",
      "\ttrain 1-2128: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-2129: Loss: 0.0061 Acc: 90.0000%\n",
      "\ttrain 1-2130: Loss: 0.0099 Acc: 90.0000%\n",
      "\ttrain 1-2131: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-2132: Loss: 0.0187 Acc: 86.6667%\n",
      "\ttrain 1-2133: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-2134: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2135: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 1-2136: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-2137: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-2138: Loss: 0.0029 Acc: 93.3333%\n",
      "\ttrain 1-2139: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 1-2140: Loss: 0.0125 Acc: 93.3333%\n",
      "\ttrain 1-2141: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2142: Loss: 0.0078 Acc: 93.3333%\n",
      "\ttrain 1-2143: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-2144: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2145: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-2146: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-2147: Loss: 0.0115 Acc: 93.3333%\n",
      "\ttrain 1-2148: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-2149: Loss: 0.0118 Acc: 93.3333%\n",
      "\ttrain 1-2150: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-2151: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2152: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-2153: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-2154: Loss: 0.0073 Acc: 90.0000%\n",
      "\ttrain 1-2155: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-2156: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2157: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2158: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2159: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-2160: Loss: 0.0161 Acc: 93.3333%\n",
      "\ttrain 1-2161: Loss: 0.0064 Acc: 90.0000%\n",
      "\ttrain 1-2162: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-2163: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-2164: Loss: 0.0111 Acc: 86.6667%\n",
      "\ttrain 1-2165: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 1-2166: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-2167: Loss: 0.0079 Acc: 90.0000%\n",
      "\ttrain 1-2168: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-2169: Loss: 0.0149 Acc: 86.6667%\n",
      "\ttrain 1-2170: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-2171: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 1-2172: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-2173: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-2174: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-2175: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-2176: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-2177: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-2178: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-2179: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2180: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 1-2181: Loss: 0.0118 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-2182: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2183: Loss: 0.0044 Acc: 90.0000%\n",
      "\ttrain 1-2184: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-2185: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2186: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2187: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2188: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2189: Loss: 0.0102 Acc: 90.0000%\n",
      "\ttrain 1-2190: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-2191: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-2192: Loss: 0.0177 Acc: 90.0000%\n",
      "\ttrain 1-2193: Loss: 0.0186 Acc: 90.0000%\n",
      "\ttrain 1-2194: Loss: 0.0084 Acc: 93.3333%\n",
      "\ttrain 1-2195: Loss: 0.0116 Acc: 86.6667%\n",
      "\ttrain 1-2196: Loss: 0.0245 Acc: 76.6667%\n",
      "\ttrain 1-2197: Loss: 0.0062 Acc: 90.0000%\n",
      "\ttrain 1-2198: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2199: Loss: 0.0085 Acc: 90.0000%\n",
      "\ttrain 1-2200: Loss: 0.0104 Acc: 90.0000%\n",
      "\ttrain 1-2201: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-2202: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 1-2203: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-2204: Loss: 0.0116 Acc: 90.0000%\n",
      "\ttrain 1-2205: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-2206: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-2207: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 1-2208: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2209: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-2210: Loss: 0.0086 Acc: 90.0000%\n",
      "\ttrain 1-2211: Loss: 0.0109 Acc: 86.6667%\n",
      "\ttrain 1-2212: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2213: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-2214: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2215: Loss: 0.0127 Acc: 86.6667%\n",
      "\ttrain 1-2216: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 1-2217: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-2218: Loss: 0.0204 Acc: 80.0000%\n",
      "\ttrain 1-2219: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-2220: Loss: 0.0039 Acc: 100.0000%\n",
      "\ttrain 1-2221: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2222: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-2223: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-2224: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2225: Loss: 0.0070 Acc: 96.6667%\n",
      "\ttrain 1-2226: Loss: 0.0095 Acc: 86.6667%\n",
      "\ttrain 1-2227: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-2228: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2229: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-2230: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2231: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-2232: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2233: Loss: 0.0100 Acc: 86.6667%\n",
      "\ttrain 1-2234: Loss: 0.0127 Acc: 86.6667%\n",
      "\ttrain 1-2235: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-2236: Loss: 0.0077 Acc: 96.6667%\n",
      "\ttrain 1-2237: Loss: 0.0067 Acc: 90.0000%\n",
      "\ttrain 1-2238: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2239: Loss: 0.0134 Acc: 86.6667%\n",
      "\ttrain 1-2240: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2241: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2242: Loss: 0.0156 Acc: 80.0000%\n",
      "\ttrain 1-2243: Loss: 0.0116 Acc: 90.0000%\n",
      "\ttrain 1-2244: Loss: 0.0131 Acc: 86.6667%\n",
      "\ttrain 1-2245: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-2246: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-2247: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-2248: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-2249: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-2250: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2251: Loss: 0.0051 Acc: 90.0000%\n",
      "\ttrain 1-2252: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 1-2253: Loss: 0.0119 Acc: 93.3333%\n",
      "\ttrain 1-2254: Loss: 0.0105 Acc: 90.0000%\n",
      "\ttrain 1-2255: Loss: 0.0066 Acc: 86.6667%\n",
      "\ttrain 1-2256: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-2257: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-2258: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-2259: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-2260: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2261: Loss: 0.0123 Acc: 93.3333%\n",
      "\ttrain 1-2262: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2263: Loss: 0.0157 Acc: 86.6667%\n",
      "\ttrain 1-2264: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-2265: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 1-2266: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 1-2267: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2268: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-2269: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-2270: Loss: 0.0160 Acc: 90.0000%\n",
      "\ttrain 1-2271: Loss: 0.0086 Acc: 96.6667%\n",
      "\ttrain 1-2272: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 1-2273: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2274: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2275: Loss: 0.0084 Acc: 90.0000%\n",
      "\ttrain 1-2276: Loss: 0.0078 Acc: 93.3333%\n",
      "\ttrain 1-2277: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-2278: Loss: 0.0053 Acc: 90.0000%\n",
      "\ttrain 1-2279: Loss: 0.0077 Acc: 96.6667%\n",
      "\ttrain 1-2280: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2281: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2282: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2283: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 1-2284: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-2285: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2286: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-2287: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2288: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 1-2289: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-2290: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2291: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-2292: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2293: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-2294: Loss: 0.0063 Acc: 86.6667%\n",
      "\ttrain 1-2295: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2296: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2297: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 1-2298: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-2299: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-2300: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-2301: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-2302: Loss: 0.0111 Acc: 90.0000%\n",
      "\ttrain 1-2303: Loss: 0.0071 Acc: 96.6667%\n",
      "\ttrain 1-2304: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-2305: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2306: Loss: 0.0171 Acc: 90.0000%\n",
      "\ttrain 1-2307: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-2308: Loss: 0.0162 Acc: 93.3333%\n",
      "\ttrain 1-2309: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-2310: Loss: 0.0092 Acc: 90.0000%\n",
      "\ttrain 1-2311: Loss: 0.0184 Acc: 83.3333%\n",
      "\ttrain 1-2312: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-2313: Loss: 0.0172 Acc: 86.6667%\n",
      "\ttrain 1-2314: Loss: 0.0247 Acc: 83.3333%\n",
      "\ttrain 1-2315: Loss: 0.0114 Acc: 86.6667%\n",
      "\ttrain 1-2316: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-2317: Loss: 0.0183 Acc: 90.0000%\n",
      "\ttrain 1-2318: Loss: 0.0159 Acc: 83.3333%\n",
      "\ttrain 1-2319: Loss: 0.0081 Acc: 90.0000%\n",
      "\ttrain 1-2320: Loss: 0.0080 Acc: 96.6667%\n",
      "\ttrain 1-2321: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-2322: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 1-2323: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 1-2324: Loss: 0.0118 Acc: 86.6667%\n",
      "\ttrain 1-2325: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 1-2326: Loss: 0.0125 Acc: 90.0000%\n",
      "\ttrain 1-2327: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2328: Loss: 0.0162 Acc: 86.6667%\n",
      "\ttrain 1-2329: Loss: 0.0101 Acc: 90.0000%\n",
      "\ttrain 1-2330: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2331: Loss: 0.0093 Acc: 93.3333%\n",
      "\ttrain 1-2332: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-2333: Loss: 0.0114 Acc: 90.0000%\n",
      "\ttrain 1-2334: Loss: 0.0114 Acc: 86.6667%\n",
      "\ttrain 1-2335: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 1-2336: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 1-2337: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2338: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-2339: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-2340: Loss: 0.0084 Acc: 93.3333%\n",
      "\ttrain 1-2341: Loss: 0.0193 Acc: 90.0000%\n",
      "\ttrain 1-2342: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-2343: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-2344: Loss: 0.0038 Acc: 100.0000%\n",
      "\ttrain 1-2345: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2346: Loss: 0.0062 Acc: 90.0000%\n",
      "\ttrain 1-2347: Loss: 0.0070 Acc: 90.0000%\n",
      "\ttrain 1-2348: Loss: 0.0132 Acc: 86.6667%\n",
      "\ttrain 1-2349: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2350: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-2351: Loss: 0.0078 Acc: 90.0000%\n",
      "\ttrain 1-2352: Loss: 0.0109 Acc: 93.3333%\n",
      "\ttrain 1-2353: Loss: 0.0076 Acc: 96.6667%\n",
      "\ttrain 1-2354: Loss: 0.0067 Acc: 93.3333%\n",
      "\ttrain 1-2355: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-2356: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 1-2357: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 1-2358: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 1-2359: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2360: Loss: 0.0088 Acc: 86.6667%\n",
      "\ttrain 1-2361: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-2362: Loss: 0.0154 Acc: 86.6667%\n",
      "\ttrain 1-2363: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-2364: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2365: Loss: 0.0113 Acc: 90.0000%\n",
      "\ttrain 1-2366: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2367: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 1-2368: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-2369: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-2370: Loss: 0.0109 Acc: 86.6667%\n",
      "\ttrain 1-2371: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 1-2372: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-2373: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2374: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-2375: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2376: Loss: 0.0014 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-2377: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-2378: Loss: 0.0101 Acc: 86.6667%\n",
      "\ttrain 1-2379: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2380: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-2381: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2382: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-2383: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-2384: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2385: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2386: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2387: Loss: 0.0021 Acc: 93.3333%\n",
      "\ttrain 1-2388: Loss: 0.0076 Acc: 86.6667%\n",
      "\ttrain 1-2389: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-2390: Loss: 0.0117 Acc: 90.0000%\n",
      "\ttrain 1-2391: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2392: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 1-2393: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2394: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2395: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-2396: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-2397: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2398: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2399: Loss: 0.0110 Acc: 90.0000%\n",
      "\ttrain 1-2400: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-2401: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 1-2402: Loss: 0.0108 Acc: 90.0000%\n",
      "\ttrain 1-2403: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2404: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-2405: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2406: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 1-2407: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 1-2408: Loss: 0.0096 Acc: 93.3333%\n",
      "\ttrain 1-2409: Loss: 0.0148 Acc: 86.6667%\n",
      "\ttrain 1-2410: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-2411: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2412: Loss: 0.0038 Acc: 90.0000%\n",
      "\ttrain 1-2413: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2414: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-2415: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2416: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-2417: Loss: 0.0145 Acc: 83.3333%\n",
      "\ttrain 1-2418: Loss: 0.0142 Acc: 93.3333%\n",
      "\ttrain 1-2419: Loss: 0.0091 Acc: 96.6667%\n",
      "\ttrain 1-2420: Loss: 0.0064 Acc: 90.0000%\n",
      "\ttrain 1-2421: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 1-2422: Loss: 0.0078 Acc: 93.3333%\n",
      "\ttrain 1-2423: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2424: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2425: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2426: Loss: 0.0118 Acc: 96.6667%\n",
      "\ttrain 1-2427: Loss: 0.0093 Acc: 90.0000%\n",
      "\ttrain 1-2428: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-2429: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2430: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 1-2431: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2432: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-2433: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2434: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-2435: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2436: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-2437: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2438: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-2439: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-2440: Loss: 0.0083 Acc: 96.6667%\n",
      "\ttrain 1-2441: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2442: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2443: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2444: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2445: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2446: Loss: 0.0189 Acc: 86.6667%\n",
      "\ttrain 1-2447: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2448: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 1-2449: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2450: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-2451: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2452: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-2453: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2454: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2455: Loss: 0.0116 Acc: 96.6667%\n",
      "\ttrain 1-2456: Loss: 0.0257 Acc: 90.0000%\n",
      "\ttrain 1-2457: Loss: 0.0105 Acc: 90.0000%\n",
      "\ttrain 1-2458: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2459: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2460: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-2461: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-2462: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2463: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-2464: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 1-2465: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 1-2466: Loss: 0.0053 Acc: 90.0000%\n",
      "\ttrain 1-2467: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 1-2468: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-2469: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2470: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-2471: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-2472: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2473: Loss: 0.0070 Acc: 86.6667%\n",
      "\ttrain 1-2474: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-2475: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2476: Loss: 0.0138 Acc: 86.6667%\n",
      "\ttrain 1-2477: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2478: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2479: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-2480: Loss: 0.0101 Acc: 96.6667%\n",
      "\ttrain 1-2481: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2482: Loss: 0.0049 Acc: 90.0000%\n",
      "\ttrain 1-2483: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-2484: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2485: Loss: 0.0118 Acc: 93.3333%\n",
      "\ttrain 1-2486: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-2487: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-2488: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-2489: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-2490: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-2491: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2492: Loss: 0.0194 Acc: 90.0000%\n",
      "\ttrain 1-2493: Loss: 0.0101 Acc: 96.6667%\n",
      "\ttrain 1-2494: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2495: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2496: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2497: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2498: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-2499: Loss: 0.0071 Acc: 93.3333%\n",
      "\ttrain 1-2500: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2501: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-2502: Loss: 0.0145 Acc: 90.0000%\n",
      "\ttrain 1-2503: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2504: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-2505: Loss: 0.0063 Acc: 90.0000%\n",
      "\ttrain 1-2506: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain 1-2507: Loss: 0.0113 Acc: 90.0000%\n",
      "\ttrain 1-2508: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 1-2509: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-2510: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-2511: Loss: 0.0115 Acc: 90.0000%\n",
      "\ttrain 1-2512: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2513: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-2514: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2515: Loss: 0.0093 Acc: 90.0000%\n",
      "\ttrain 1-2516: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-2517: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2518: Loss: 0.0099 Acc: 83.3333%\n",
      "\ttrain 1-2519: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-2520: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2521: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2522: Loss: 0.0154 Acc: 83.3333%\n",
      "\ttrain 1-2523: Loss: 0.0053 Acc: 90.0000%\n",
      "\ttrain 1-2524: Loss: 0.0101 Acc: 93.3333%\n",
      "\ttrain 1-2525: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2526: Loss: 0.0041 Acc: 90.0000%\n",
      "\ttrain 1-2527: Loss: 0.0060 Acc: 90.0000%\n",
      "\ttrain 1-2528: Loss: 0.0104 Acc: 93.3333%\n",
      "\ttrain 1-2529: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-2530: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2531: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 1-2532: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-2533: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 1-2534: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-2535: Loss: 0.0148 Acc: 90.0000%\n",
      "\ttrain 1-2536: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2537: Loss: 0.0116 Acc: 93.3333%\n",
      "\ttrain 1-2538: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 1-2539: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-2540: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-2541: Loss: 0.0084 Acc: 96.6667%\n",
      "\ttrain 1-2542: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2543: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2544: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 1-2545: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-2546: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2547: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2548: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2549: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-2550: Loss: 0.0037 Acc: 93.3333%\n",
      "\ttrain 1-2551: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2552: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-2553: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2554: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2555: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2556: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-2557: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-2558: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2559: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2560: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-2561: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-2562: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-2563: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2564: Loss: 0.0122 Acc: 93.3333%\n",
      "\ttrain 1-2565: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2566: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-2567: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-2568: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2569: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-2570: Loss: 0.0017 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-2571: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-2572: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-2573: Loss: 0.0178 Acc: 90.0000%\n",
      "\ttrain 1-2574: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2575: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2576: Loss: 0.0185 Acc: 86.6667%\n",
      "\ttrain 1-2577: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-2578: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-2579: Loss: 0.0219 Acc: 86.6667%\n",
      "\ttrain 1-2580: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-2581: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-2582: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2583: Loss: 0.0104 Acc: 93.3333%\n",
      "\ttrain 1-2584: Loss: 0.0182 Acc: 83.3333%\n",
      "\ttrain 1-2585: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 1-2586: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 1-2587: Loss: 0.0259 Acc: 86.6667%\n",
      "\ttrain 1-2588: Loss: 0.0288 Acc: 83.3333%\n",
      "\ttrain 1-2589: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2590: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-2591: Loss: 0.0126 Acc: 83.3333%\n",
      "\ttrain 1-2592: Loss: 0.0104 Acc: 86.6667%\n",
      "\ttrain 1-2593: Loss: 0.0174 Acc: 83.3333%\n",
      "\ttrain 1-2594: Loss: 0.0153 Acc: 80.0000%\n",
      "\ttrain 1-2595: Loss: 0.0107 Acc: 90.0000%\n",
      "\ttrain 1-2596: Loss: 0.0121 Acc: 90.0000%\n",
      "\ttrain 1-2597: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 1-2598: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2599: Loss: 0.0138 Acc: 83.3333%\n",
      "\ttrain 1-2600: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2601: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-2602: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-2603: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-2604: Loss: 0.0178 Acc: 90.0000%\n",
      "\ttrain 1-2605: Loss: 0.0140 Acc: 83.3333%\n",
      "\ttrain 1-2606: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2607: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2608: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2609: Loss: 0.0150 Acc: 83.3333%\n",
      "\ttrain 1-2610: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2611: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2612: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-2613: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2614: Loss: 0.0067 Acc: 90.0000%\n",
      "\ttrain 1-2615: Loss: 0.0094 Acc: 90.0000%\n",
      "\ttrain 1-2616: Loss: 0.0230 Acc: 86.6667%\n",
      "\ttrain 1-2617: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-2618: Loss: 0.0076 Acc: 86.6667%\n",
      "\ttrain 1-2619: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2620: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2621: Loss: 0.0107 Acc: 90.0000%\n",
      "\ttrain 1-2622: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-2623: Loss: 0.0093 Acc: 93.3333%\n",
      "\ttrain 1-2624: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 1-2625: Loss: 0.0129 Acc: 93.3333%\n",
      "\ttrain 1-2626: Loss: 0.0099 Acc: 86.6667%\n",
      "\ttrain 1-2627: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 1-2628: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2629: Loss: 0.0091 Acc: 90.0000%\n",
      "\ttrain 1-2630: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-2631: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2632: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2633: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 1-2634: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-2635: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2636: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2637: Loss: 0.0047 Acc: 90.0000%\n",
      "\ttrain 1-2638: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-2639: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2640: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2641: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2642: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2643: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 1-2644: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2645: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-2646: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-2647: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2648: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2649: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-2650: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2651: Loss: 0.0198 Acc: 93.3333%\n",
      "\ttrain 1-2652: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-2653: Loss: 0.0196 Acc: 90.0000%\n",
      "\ttrain 1-2654: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-2655: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-2656: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-2657: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2658: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 1-2659: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-2660: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2661: Loss: 0.0184 Acc: 83.3333%\n",
      "\ttrain 1-2662: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 1-2663: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2664: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 1-2665: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 1-2666: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 1-2667: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2668: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2669: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-2670: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2671: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-2672: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-2673: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-2674: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-2675: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2676: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-2677: Loss: 0.0118 Acc: 90.0000%\n",
      "\ttrain 1-2678: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-2679: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-2680: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2681: Loss: 0.0090 Acc: 86.6667%\n",
      "\ttrain 1-2682: Loss: 0.0049 Acc: 100.0000%\n",
      "\ttrain 1-2683: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-2684: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2685: Loss: 0.0127 Acc: 86.6667%\n",
      "\ttrain 1-2686: Loss: 0.0133 Acc: 90.0000%\n",
      "\ttrain 1-2687: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2688: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2689: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2690: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2691: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-2692: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-2693: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 1-2694: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-2695: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2696: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 1-2697: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 1-2698: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2699: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2700: Loss: 0.0042 Acc: 100.0000%\n",
      "\ttrain 1-2701: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 1-2702: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-2703: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2704: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-2705: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2706: Loss: 0.0112 Acc: 90.0000%\n",
      "\ttrain 1-2707: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-2708: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2709: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 1-2710: Loss: 0.0093 Acc: 93.3333%\n",
      "\ttrain 1-2711: Loss: 0.0130 Acc: 90.0000%\n",
      "\ttrain 1-2712: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2713: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2714: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2715: Loss: 0.0106 Acc: 93.3333%\n",
      "\ttrain 1-2716: Loss: 0.0142 Acc: 86.6667%\n",
      "\ttrain 1-2717: Loss: 0.0046 Acc: 90.0000%\n",
      "\ttrain 1-2718: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2719: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2720: Loss: 0.0084 Acc: 90.0000%\n",
      "\ttrain 1-2721: Loss: 0.0224 Acc: 86.6667%\n",
      "\ttrain 1-2722: Loss: 0.0099 Acc: 90.0000%\n",
      "\ttrain 1-2723: Loss: 0.0038 Acc: 93.3333%\n",
      "\ttrain 1-2724: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-2725: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-2726: Loss: 0.0116 Acc: 96.6667%\n",
      "\ttrain 1-2727: Loss: 0.0088 Acc: 90.0000%\n",
      "\ttrain 1-2728: Loss: 0.0070 Acc: 90.0000%\n",
      "\ttrain 1-2729: Loss: 0.0112 Acc: 93.3333%\n",
      "\ttrain 1-2730: Loss: 0.0067 Acc: 90.0000%\n",
      "\ttrain 1-2731: Loss: 0.0036 Acc: 100.0000%\n",
      "\ttrain 1-2732: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-2733: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-2734: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-2735: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 1-2736: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-2737: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2738: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-2739: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-2740: Loss: 0.0138 Acc: 86.6667%\n",
      "\ttrain 1-2741: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-2742: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2743: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2744: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 1-2745: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-2746: Loss: 0.0077 Acc: 90.0000%\n",
      "\ttrain 1-2747: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 1-2748: Loss: 0.0159 Acc: 83.3333%\n",
      "\ttrain 1-2749: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2750: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2751: Loss: 0.0100 Acc: 96.6667%\n",
      "\ttrain 1-2752: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 1-2753: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-2754: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-2755: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 1-2756: Loss: 0.0102 Acc: 90.0000%\n",
      "\ttrain 1-2757: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-2758: Loss: 0.0102 Acc: 90.0000%\n",
      "\ttrain 1-2759: Loss: 0.0217 Acc: 86.6667%\n",
      "\ttrain 1-2760: Loss: 0.0139 Acc: 90.0000%\n",
      "\ttrain 1-2761: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 1-2762: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-2763: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2764: Loss: 0.0024 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-2765: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 1-2766: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2767: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 1-2768: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-2769: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2770: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 1-2771: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-2772: Loss: 0.0101 Acc: 86.6667%\n",
      "\ttrain 1-2773: Loss: 0.0049 Acc: 90.0000%\n",
      "\ttrain 1-2774: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-2775: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-2776: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2777: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-2778: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-2779: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-2780: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2781: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2782: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-2783: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-2784: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-2785: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-2786: Loss: 0.0188 Acc: 83.3333%\n",
      "\ttrain 1-2787: Loss: 0.0115 Acc: 93.3333%\n",
      "\ttrain 1-2788: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2789: Loss: 0.0151 Acc: 96.6667%\n",
      "\ttrain 1-2790: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2791: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2792: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-2793: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2794: Loss: 0.0203 Acc: 86.6667%\n",
      "\ttrain 1-2795: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-2796: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2797: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-2798: Loss: 0.0073 Acc: 90.0000%\n",
      "\ttrain 1-2799: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-2800: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 1-2801: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 1-2802: Loss: 0.0040 Acc: 90.0000%\n",
      "\ttrain 1-2803: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-2804: Loss: 0.0162 Acc: 86.6667%\n",
      "\ttrain 1-2805: Loss: 0.0067 Acc: 90.0000%\n",
      "\ttrain 1-2806: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2807: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-2808: Loss: 0.0116 Acc: 93.3333%\n",
      "\ttrain 1-2809: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-2810: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2811: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2812: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-2813: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 1-2814: Loss: 0.0029 Acc: 100.0000%\n",
      "\ttrain 1-2815: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-2816: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2817: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-2818: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2819: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-2820: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2821: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2822: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2823: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-2824: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2825: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2826: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-2827: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-2828: Loss: 0.0117 Acc: 93.3333%\n",
      "\ttrain 1-2829: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2830: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2831: Loss: 0.0158 Acc: 93.3333%\n",
      "\ttrain 1-2832: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2833: Loss: 0.0067 Acc: 90.0000%\n",
      "\ttrain 1-2834: Loss: 0.0111 Acc: 93.3333%\n",
      "\ttrain 1-2835: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-2836: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2837: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2838: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-2839: Loss: 0.0237 Acc: 90.0000%\n",
      "\ttrain 1-2840: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2841: Loss: 0.0027 Acc: 93.3333%\n",
      "\ttrain 1-2842: Loss: 0.0307 Acc: 83.3333%\n",
      "\ttrain 1-2843: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-2844: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-2845: Loss: 0.0133 Acc: 86.6667%\n",
      "\ttrain 1-2846: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-2847: Loss: 0.0224 Acc: 80.0000%\n",
      "\ttrain 1-2848: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-2849: Loss: 0.0116 Acc: 86.6667%\n",
      "\ttrain 1-2850: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-2851: Loss: 0.0079 Acc: 96.6667%\n",
      "\ttrain 1-2852: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2853: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-2854: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 1-2855: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2856: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-2857: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-2858: Loss: 0.0099 Acc: 93.3333%\n",
      "\ttrain 1-2859: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-2860: Loss: 0.0172 Acc: 93.3333%\n",
      "\ttrain 1-2861: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-2862: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2863: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-2864: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-2865: Loss: 0.0151 Acc: 90.0000%\n",
      "\ttrain 1-2866: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-2867: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-2868: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-2869: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-2870: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-2871: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-2872: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-2873: Loss: 0.0037 Acc: 93.3333%\n",
      "\ttrain 1-2874: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 1-2875: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-2876: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-2877: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2878: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-2879: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-2880: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2881: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-2882: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2883: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2884: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-2885: Loss: 0.0098 Acc: 93.3333%\n",
      "\ttrain 1-2886: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-2887: Loss: 0.0121 Acc: 86.6667%\n",
      "\ttrain 1-2888: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2889: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 1-2890: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-2891: Loss: 0.0129 Acc: 93.3333%\n",
      "\ttrain 1-2892: Loss: 0.0115 Acc: 86.6667%\n",
      "\ttrain 1-2893: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2894: Loss: 0.0062 Acc: 90.0000%\n",
      "\ttrain 1-2895: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-2896: Loss: 0.0064 Acc: 90.0000%\n",
      "\ttrain 1-2897: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2898: Loss: 0.0095 Acc: 96.6667%\n",
      "\ttrain 1-2899: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-2900: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2901: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2902: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2903: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2904: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 1-2905: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-2906: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2907: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-2908: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-2909: Loss: 0.0088 Acc: 90.0000%\n",
      "\ttrain 1-2910: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2911: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-2912: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-2913: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-2914: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-2915: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-2916: Loss: 0.0037 Acc: 93.3333%\n",
      "\ttrain 1-2917: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2918: Loss: 0.0065 Acc: 96.6667%\n",
      "\ttrain 1-2919: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2920: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 1-2921: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-2922: Loss: 0.0109 Acc: 93.3333%\n",
      "\ttrain 1-2923: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2924: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2925: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-2926: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-2927: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2928: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2929: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-2930: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-2931: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-2932: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-2933: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-2934: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-2935: Loss: 0.0126 Acc: 93.3333%\n",
      "\ttrain 1-2936: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-2937: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-2938: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2939: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-2940: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2941: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-2942: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2943: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2944: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-2945: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-2946: Loss: 0.0103 Acc: 93.3333%\n",
      "\ttrain 1-2947: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2948: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2949: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 1-2950: Loss: 0.0086 Acc: 96.6667%\n",
      "\ttrain 1-2951: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-2952: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2953: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-2954: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2955: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2956: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-2957: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-2958: Loss: 0.0012 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-2959: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-2960: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2961: Loss: 0.0086 Acc: 96.6667%\n",
      "\ttrain 1-2962: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2963: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-2964: Loss: 0.0101 Acc: 93.3333%\n",
      "\ttrain 1-2965: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-2966: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-2967: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2968: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-2969: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-2970: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-2971: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-2972: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-2973: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-2974: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-2975: Loss: 0.0084 Acc: 90.0000%\n",
      "\ttrain 1-2976: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-2977: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-2978: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-2979: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 1-2980: Loss: 0.0089 Acc: 90.0000%\n",
      "\ttrain 1-2981: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-2982: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-2983: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-2984: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-2985: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2986: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-2987: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-2988: Loss: 0.0071 Acc: 96.6667%\n",
      "\ttrain 1-2989: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-2990: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 1-2991: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 1-2992: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-2993: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2994: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2995: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-2996: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-2997: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-2998: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-2999: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-3000: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3001: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-3002: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 1-3003: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3004: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-3005: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-3006: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3007: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3008: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3009: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3010: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3011: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3012: Loss: 0.0061 Acc: 90.0000%\n",
      "\ttrain 1-3013: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3014: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3015: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-3016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3017: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3018: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-3019: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3020: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-3021: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3022: Loss: 0.0043 Acc: 90.0000%\n",
      "\ttrain 1-3023: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3024: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3025: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3026: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-3027: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-3028: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3029: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3030: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3031: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-3032: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3033: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-3034: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-3035: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-3036: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-3037: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-3038: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-3039: Loss: 0.0143 Acc: 90.0000%\n",
      "\ttrain 1-3040: Loss: 0.0095 Acc: 96.6667%\n",
      "\ttrain 1-3041: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3042: Loss: 0.0077 Acc: 90.0000%\n",
      "\ttrain 1-3043: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3044: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3045: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-3046: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3047: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-3048: Loss: 0.0069 Acc: 86.6667%\n",
      "\ttrain 1-3049: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3050: Loss: 0.0029 Acc: 93.3333%\n",
      "\ttrain 1-3051: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3052: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-3053: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-3054: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3055: Loss: 0.0114 Acc: 93.3333%\n",
      "\ttrain 1-3056: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-3057: Loss: 0.0089 Acc: 90.0000%\n",
      "\ttrain 1-3058: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-3059: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3060: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-3061: Loss: 0.0070 Acc: 90.0000%\n",
      "\ttrain 1-3062: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3063: Loss: 0.0123 Acc: 93.3333%\n",
      "\ttrain 1-3064: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3065: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3066: Loss: 0.0058 Acc: 90.0000%\n",
      "\ttrain 1-3067: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3068: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3069: Loss: 0.0100 Acc: 86.6667%\n",
      "\ttrain 1-3070: Loss: 0.0132 Acc: 86.6667%\n",
      "\ttrain 1-3071: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3072: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3073: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3074: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-3075: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3076: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3077: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-3078: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-3079: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 1-3080: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3081: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-3082: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3083: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3084: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3085: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3086: Loss: 0.0158 Acc: 86.6667%\n",
      "\ttrain 1-3087: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3088: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-3089: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3090: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3091: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3092: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3093: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3094: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3095: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3096: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3097: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-3098: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3099: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-3100: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-3101: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-3102: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3103: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3104: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-3105: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3106: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3107: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3108: Loss: 0.0055 Acc: 90.0000%\n",
      "\ttrain 1-3109: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3110: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3111: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3112: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-3113: Loss: 0.0153 Acc: 86.6667%\n",
      "\ttrain 1-3114: Loss: 0.0024 Acc: 93.3333%\n",
      "\ttrain 1-3115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3116: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3117: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3118: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-3119: Loss: 0.0127 Acc: 90.0000%\n",
      "\ttrain 1-3120: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3121: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3122: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-3123: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-3124: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3125: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3126: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3127: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3128: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3129: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3130: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3131: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 1-3132: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3133: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3134: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3135: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3136: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3137: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3138: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-3139: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3140: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3141: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-3142: Loss: 0.0106 Acc: 93.3333%\n",
      "\ttrain 1-3143: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3144: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3145: Loss: 0.0101 Acc: 93.3333%\n",
      "\ttrain 1-3146: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3147: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3148: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-3149: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3150: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-3151: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3152: Loss: 0.0011 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-3153: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3154: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3155: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3156: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3157: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3158: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3159: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3160: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3161: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3162: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3163: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3164: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3166: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3167: Loss: 0.0100 Acc: 93.3333%\n",
      "\ttrain 1-3168: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3169: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3170: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3171: Loss: 0.0114 Acc: 93.3333%\n",
      "\ttrain 1-3172: Loss: 0.0108 Acc: 93.3333%\n",
      "\ttrain 1-3173: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3174: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 1-3175: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3176: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 1-3177: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3178: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3179: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3180: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-3181: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3182: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3183: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3184: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3185: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-3186: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3187: Loss: 0.0170 Acc: 90.0000%\n",
      "\ttrain 1-3188: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3189: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3190: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-3191: Loss: 0.0098 Acc: 96.6667%\n",
      "\ttrain 1-3192: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 1-3193: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-3194: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3195: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3196: Loss: 0.0050 Acc: 90.0000%\n",
      "\ttrain 1-3197: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3198: Loss: 0.0086 Acc: 96.6667%\n",
      "\ttrain 1-3199: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3200: Loss: 0.0093 Acc: 93.3333%\n",
      "\ttrain 1-3201: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3202: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3203: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3204: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3205: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-3206: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3207: Loss: 0.0104 Acc: 90.0000%\n",
      "\ttrain 1-3208: Loss: 0.0127 Acc: 93.3333%\n",
      "\ttrain 1-3209: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3210: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3211: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3212: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-3213: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3214: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-3215: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3216: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-3217: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3218: Loss: 0.0070 Acc: 96.6667%\n",
      "\ttrain 1-3219: Loss: 0.0082 Acc: 96.6667%\n",
      "\ttrain 1-3220: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-3221: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3222: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3223: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3224: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-3225: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3226: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 1-3227: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-3228: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-3229: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3230: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3231: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3232: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3233: Loss: 0.0074 Acc: 86.6667%\n",
      "\ttrain 1-3234: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3235: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-3236: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-3237: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3238: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 1-3239: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3240: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3241: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-3242: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3243: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3244: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-3245: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3246: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3247: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3248: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3249: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-3250: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3251: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3252: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3253: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3254: Loss: 0.0121 Acc: 93.3333%\n",
      "\ttrain 1-3255: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3256: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-3257: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3258: Loss: 0.0030 Acc: 93.3333%\n",
      "\ttrain 1-3259: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3260: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3261: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3262: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-3263: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3264: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3265: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3266: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 1-3267: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3268: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3269: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3270: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3271: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3272: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3273: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3274: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3275: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-3276: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 1-3277: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3278: Loss: 0.0088 Acc: 86.6667%\n",
      "\ttrain 1-3279: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-3280: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-3281: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3282: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-3283: Loss: 0.0138 Acc: 93.3333%\n",
      "\ttrain 1-3284: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3285: Loss: 0.0089 Acc: 93.3333%\n",
      "\ttrain 1-3286: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 1-3287: Loss: 0.0037 Acc: 93.3333%\n",
      "\ttrain 1-3288: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-3289: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3290: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 1-3291: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3292: Loss: 0.0118 Acc: 93.3333%\n",
      "\ttrain 1-3293: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3294: Loss: 0.0047 Acc: 90.0000%\n",
      "\ttrain 1-3295: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-3296: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3297: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-3298: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-3299: Loss: 0.0129 Acc: 93.3333%\n",
      "\ttrain 1-3300: Loss: 0.0057 Acc: 90.0000%\n",
      "\ttrain 1-3301: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-3302: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3303: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-3304: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-3305: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-3306: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-3307: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 1-3308: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3309: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3310: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3311: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-3312: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3313: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-3314: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3315: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3316: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3317: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3318: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 1-3319: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3320: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3321: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3322: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3323: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-3324: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3325: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 1-3326: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3327: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 1-3328: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3329: Loss: 0.0103 Acc: 96.6667%\n",
      "\ttrain 1-3330: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3331: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3332: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3333: Loss: 0.0095 Acc: 96.6667%\n",
      "\ttrain 1-3334: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3335: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3336: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-3337: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-3338: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3339: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3340: Loss: 0.0073 Acc: 96.6667%\n",
      "\ttrain 1-3341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3342: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-3343: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3344: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-3345: Loss: 0.0093 Acc: 90.0000%\n",
      "\ttrain 1-3346: Loss: 0.0064 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-3347: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3348: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3349: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 1-3350: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3351: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3352: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3353: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-3354: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3355: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3356: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-3357: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-3358: Loss: 0.0086 Acc: 93.3333%\n",
      "\ttrain 1-3359: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3360: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3361: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3362: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3363: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3364: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3365: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 1-3366: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-3367: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3368: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-3369: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3370: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 1-3371: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3372: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-3373: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3374: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3375: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3376: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3377: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-3378: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3379: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-3380: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-3381: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3382: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-3383: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3384: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 1-3385: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 1-3386: Loss: 0.0045 Acc: 90.0000%\n",
      "\ttrain 1-3387: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3388: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3389: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3390: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3391: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3392: Loss: 0.0117 Acc: 93.3333%\n",
      "\ttrain 1-3393: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3394: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3396: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3397: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3398: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3399: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 1-3400: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3401: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-3402: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-3403: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3404: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-3405: Loss: 0.0192 Acc: 93.3333%\n",
      "\ttrain 1-3406: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3407: Loss: 0.0046 Acc: 90.0000%\n",
      "\ttrain 1-3408: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-3409: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3410: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3411: Loss: 0.0030 Acc: 93.3333%\n",
      "\ttrain 1-3412: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3413: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3414: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3415: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3416: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3417: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3418: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 1-3419: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-3420: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 1-3421: Loss: 0.0141 Acc: 93.3333%\n",
      "\ttrain 1-3422: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3423: Loss: 0.0046 Acc: 90.0000%\n",
      "\ttrain 1-3424: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-3425: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3426: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-3427: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 1-3428: Loss: 0.0025 Acc: 93.3333%\n",
      "\ttrain 1-3429: Loss: 0.0069 Acc: 96.6667%\n",
      "\ttrain 1-3430: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-3431: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3432: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3433: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3434: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3435: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3436: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3437: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3438: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3439: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3440: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 1-3441: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3442: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-3443: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3444: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-3445: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3446: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-3447: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3448: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3449: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3450: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3451: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3452: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3453: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3454: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3455: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 1-3456: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3457: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3458: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3459: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 1-3460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3461: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3462: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3463: Loss: 0.0154 Acc: 93.3333%\n",
      "\ttrain 1-3464: Loss: 0.0055 Acc: 90.0000%\n",
      "\ttrain 1-3465: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3466: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3467: Loss: 0.0137 Acc: 90.0000%\n",
      "\ttrain 1-3468: Loss: 0.0087 Acc: 93.3333%\n",
      "\ttrain 1-3469: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3470: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3471: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-3472: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3473: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3474: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3475: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-3476: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3477: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 1-3478: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3479: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3480: Loss: 0.0089 Acc: 93.3333%\n",
      "\ttrain 1-3481: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3482: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3483: Loss: 0.0081 Acc: 96.6667%\n",
      "\ttrain 1-3484: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3485: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 1-3486: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3487: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 1-3488: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-3489: Loss: 0.0068 Acc: 90.0000%\n",
      "\ttrain 1-3490: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3491: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3492: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 1-3493: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-3494: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3495: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-3496: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3497: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3498: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-3499: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3500: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3501: Loss: 0.0107 Acc: 90.0000%\n",
      "\ttrain 1-3502: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3503: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3504: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3505: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3506: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3507: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3508: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-3509: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3510: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3511: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3512: Loss: 0.0037 Acc: 93.3333%\n",
      "\ttrain 1-3513: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3514: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3515: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-3516: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3517: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3518: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3519: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3520: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-3521: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3522: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3523: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3524: Loss: 0.0090 Acc: 86.6667%\n",
      "\ttrain 1-3525: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3526: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-3527: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3528: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 1-3529: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3530: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3531: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3532: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3533: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3534: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-3535: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-3536: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3537: Loss: 0.0111 Acc: 96.6667%\n",
      "\ttrain 1-3538: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-3539: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3540: Loss: 0.0006 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-3541: Loss: 0.0082 Acc: 96.6667%\n",
      "\ttrain 1-3542: Loss: 0.0111 Acc: 96.6667%\n",
      "\ttrain 1-3543: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3544: Loss: 0.0074 Acc: 96.6667%\n",
      "\ttrain 1-3545: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-3546: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3547: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3548: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-3549: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-3550: Loss: 0.0150 Acc: 93.3333%\n",
      "\ttrain 1-3551: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3552: Loss: 0.0022 Acc: 93.3333%\n",
      "\ttrain 1-3553: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3554: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3555: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3556: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3557: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3558: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 1-3559: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3560: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3561: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3562: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3563: Loss: 0.0109 Acc: 90.0000%\n",
      "\ttrain 1-3564: Loss: 0.0070 Acc: 90.0000%\n",
      "\ttrain 1-3565: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3566: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3567: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-3568: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3569: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3570: Loss: 0.0098 Acc: 93.3333%\n",
      "\ttrain 1-3571: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3572: Loss: 0.0132 Acc: 86.6667%\n",
      "\ttrain 1-3573: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3574: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3575: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3576: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-3577: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3578: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 1-3579: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3580: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3581: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3582: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3583: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3584: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3585: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3586: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 1-3587: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3588: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3590: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3591: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3592: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-3593: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3594: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3595: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3596: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3597: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-3598: Loss: 0.0075 Acc: 96.6667%\n",
      "\ttrain 1-3599: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-3600: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3601: Loss: 0.0073 Acc: 96.6667%\n",
      "\ttrain 1-3602: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3603: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3604: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3605: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3606: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3607: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-3608: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3609: Loss: 0.0142 Acc: 93.3333%\n",
      "\ttrain 1-3610: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-3611: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-3612: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3613: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3614: Loss: 0.0097 Acc: 93.3333%\n",
      "\ttrain 1-3615: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3616: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3617: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3618: Loss: 0.0026 Acc: 93.3333%\n",
      "\ttrain 1-3619: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-3620: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3621: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-3622: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3623: Loss: 0.0082 Acc: 96.6667%\n",
      "\ttrain 1-3624: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 1-3625: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3626: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3627: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3628: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3629: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 1-3630: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-3631: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3632: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 1-3633: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 1-3634: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-3635: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3636: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-3637: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3638: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-3639: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3640: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-3641: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3642: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3643: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3644: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-3645: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3646: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3647: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3648: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3649: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3650: Loss: 0.0081 Acc: 96.6667%\n",
      "\ttrain 1-3651: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3652: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3653: Loss: 0.0122 Acc: 90.0000%\n",
      "\ttrain 1-3654: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-3655: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-3656: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3657: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-3658: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3659: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3660: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3661: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3662: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3663: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3664: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3665: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-3666: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3667: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3668: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3669: Loss: 0.0148 Acc: 93.3333%\n",
      "\ttrain 1-3670: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3671: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3672: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3673: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3674: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3675: Loss: 0.0029 Acc: 93.3333%\n",
      "\ttrain 1-3676: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3677: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3678: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3679: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3680: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 1-3681: Loss: 0.0199 Acc: 96.6667%\n",
      "\ttrain 1-3682: Loss: 0.0155 Acc: 90.0000%\n",
      "\ttrain 1-3683: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3684: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3685: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-3686: Loss: 0.0051 Acc: 90.0000%\n",
      "\ttrain 1-3687: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 1-3688: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3689: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-3690: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 1-3691: Loss: 0.0052 Acc: 100.0000%\n",
      "\ttrain 1-3692: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-3693: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-3694: Loss: 0.0105 Acc: 96.6667%\n",
      "\ttrain 1-3695: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3696: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3697: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 1-3698: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3699: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3700: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 1-3701: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3702: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3703: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3704: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3705: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3706: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3707: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3708: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3709: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3710: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3711: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3712: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3713: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-3714: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3716: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-3717: Loss: 0.0071 Acc: 93.3333%\n",
      "\ttrain 1-3718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3719: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3720: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-3721: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3722: Loss: 0.0083 Acc: 90.0000%\n",
      "\ttrain 1-3723: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-3724: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3725: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3726: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3727: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 1-3728: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3730: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3731: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-3732: Loss: 0.0128 Acc: 90.0000%\n",
      "\ttrain 1-3733: Loss: 0.0011 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-3734: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3735: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3736: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3737: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3738: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3739: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-3740: Loss: 0.0285 Acc: 93.3333%\n",
      "\ttrain 1-3741: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3742: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3743: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3744: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-3745: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-3746: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3747: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3748: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3749: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 1-3750: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3751: Loss: 0.0057 Acc: 90.0000%\n",
      "\ttrain 1-3752: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3753: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3754: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3755: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3756: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3757: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-3758: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3759: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3760: Loss: 0.0296 Acc: 93.3333%\n",
      "\ttrain 1-3761: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3762: Loss: 0.0076 Acc: 90.0000%\n",
      "\ttrain 1-3763: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-3764: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3765: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3766: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-3767: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 1-3768: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 1-3769: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3770: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3771: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3772: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-3773: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 1-3774: Loss: 0.0068 Acc: 90.0000%\n",
      "\ttrain 1-3775: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3776: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 1-3777: Loss: 0.0079 Acc: 96.6667%\n",
      "\ttrain 1-3778: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3779: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3780: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 1-3781: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3782: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3783: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3784: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3785: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-3786: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3787: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 1-3788: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-3789: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3790: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3791: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3792: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3793: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-3794: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3795: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3796: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-3797: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3799: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-3800: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-3801: Loss: 0.0037 Acc: 100.0000%\n",
      "\ttrain 1-3802: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-3803: Loss: 0.0126 Acc: 96.6667%\n",
      "\ttrain 1-3804: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3805: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 1-3806: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-3807: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3808: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3809: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-3810: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-3811: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-3812: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3813: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-3814: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3815: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-3816: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-3817: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 1-3818: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3819: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3820: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3821: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3822: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3823: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3824: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-3825: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3826: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3827: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3828: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3829: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-3830: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3831: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3832: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3833: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3834: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3835: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3836: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3837: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3838: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3839: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3840: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3841: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3842: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3843: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3844: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3846: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3847: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3848: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3849: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3850: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3851: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3852: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 1-3853: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3854: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3855: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3856: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3857: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3858: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 1-3859: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3860: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3861: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3862: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3863: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 1-3864: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3865: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3866: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-3867: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3868: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 1-3869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3870: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3872: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 1-3873: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 1-3874: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-3875: Loss: 0.0220 Acc: 93.3333%\n",
      "\ttrain 1-3876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3877: Loss: 0.0119 Acc: 93.3333%\n",
      "\ttrain 1-3878: Loss: 0.0168 Acc: 83.3333%\n",
      "\ttrain 1-3879: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-3880: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 1-3881: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3882: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-3883: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 1-3884: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-3885: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3886: Loss: 0.0141 Acc: 86.6667%\n",
      "\ttrain 1-3887: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-3888: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3889: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3890: Loss: 0.0021 Acc: 100.0000%\n",
      "\ttrain 1-3891: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-3892: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3893: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 1-3894: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3895: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3896: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3897: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3898: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3899: Loss: 0.0085 Acc: 90.0000%\n",
      "\ttrain 1-3900: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-3901: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-3902: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3903: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3904: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3905: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-3906: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-3907: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3908: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3909: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3910: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-3911: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 1-3912: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3913: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3914: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3915: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3916: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3917: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3918: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3919: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-3920: Loss: 0.0025 Acc: 93.3333%\n",
      "\ttrain 1-3921: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 1-3922: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-3923: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-3924: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3925: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-3926: Loss: 0.0008 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-3927: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3928: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-3929: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3930: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-3931: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3932: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3933: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3934: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3935: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-3937: Loss: 0.0089 Acc: 93.3333%\n",
      "\ttrain 1-3938: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3939: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 1-3940: Loss: 0.0098 Acc: 96.6667%\n",
      "\ttrain 1-3941: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-3942: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3943: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-3944: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 1-3945: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-3946: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3947: Loss: 0.0125 Acc: 90.0000%\n",
      "\ttrain 1-3948: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3949: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3950: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3951: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3952: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 1-3953: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-3954: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-3955: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-3956: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 1-3957: Loss: 0.0091 Acc: 96.6667%\n",
      "\ttrain 1-3958: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3959: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-3960: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-3961: Loss: 0.0152 Acc: 93.3333%\n",
      "\ttrain 1-3962: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 1-3963: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 1-3964: Loss: 0.0046 Acc: 90.0000%\n",
      "\ttrain 1-3965: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3966: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-3967: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 1-3968: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 1-3969: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-3970: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-3971: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3972: Loss: 0.0137 Acc: 93.3333%\n",
      "\ttrain 1-3973: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3974: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-3975: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3976: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-3977: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-3978: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-3979: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-3980: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-3981: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-3982: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-3983: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 1-3984: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-3985: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-3986: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-3987: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-3988: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-3989: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-3990: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3991: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-3992: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-3993: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-3994: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-3995: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-3996: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-3997: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3998: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-3999: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4000: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-4001: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-4002: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4003: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-4004: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4005: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4006: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-4007: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4008: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4009: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4010: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4011: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4012: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-4013: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4015: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4016: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 1-4017: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4018: Loss: 0.0114 Acc: 93.3333%\n",
      "\ttrain 1-4019: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4020: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4021: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4022: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4023: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-4024: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4025: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4026: Loss: 0.0021 Acc: 93.3333%\n",
      "\ttrain 1-4027: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4028: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4029: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 1-4030: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4031: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4032: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4033: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-4034: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 1-4035: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4036: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-4037: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-4038: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4039: Loss: 0.0055 Acc: 90.0000%\n",
      "\ttrain 1-4040: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4041: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4042: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4044: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-4045: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 1-4046: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-4047: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-4048: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-4049: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4050: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4051: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4052: Loss: 0.0107 Acc: 93.3333%\n",
      "\ttrain 1-4053: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4054: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4055: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4056: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4057: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-4058: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-4059: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-4060: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-4061: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 1-4062: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4063: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 1-4064: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4065: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-4066: Loss: 0.0134 Acc: 93.3333%\n",
      "\ttrain 1-4067: Loss: 0.0183 Acc: 86.6667%\n",
      "\ttrain 1-4068: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-4069: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4070: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4071: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 1-4072: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 1-4073: Loss: 0.0090 Acc: 90.0000%\n",
      "\ttrain 1-4074: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-4075: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 1-4076: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4077: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4078: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 1-4079: Loss: 0.0101 Acc: 93.3333%\n",
      "\ttrain 1-4080: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4081: Loss: 0.0176 Acc: 93.3333%\n",
      "\ttrain 1-4082: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-4083: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4084: Loss: 0.0069 Acc: 96.6667%\n",
      "\ttrain 1-4085: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-4086: Loss: 0.0070 Acc: 90.0000%\n",
      "\ttrain 1-4087: Loss: 0.0157 Acc: 93.3333%\n",
      "\ttrain 1-4088: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4089: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-4090: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-4091: Loss: 0.0089 Acc: 93.3333%\n",
      "\ttrain 1-4092: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4093: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-4094: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4095: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 1-4096: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4097: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 1-4098: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4099: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 1-4100: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-4101: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-4102: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 1-4103: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4104: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 1-4105: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 1-4106: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4107: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-4108: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 1-4109: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-4110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4111: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4112: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-4113: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4114: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4115: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-4116: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4117: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4118: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 1-4119: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-4120: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4121: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4122: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4123: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-4124: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4125: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-4126: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4127: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 1-4128: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4130: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4132: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4133: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-4134: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-4135: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4136: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4137: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-4138: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4139: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4140: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4141: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 1-4142: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-4143: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4144: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 1-4145: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 1-4146: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4147: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-4148: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4149: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-4150: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 1-4151: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-4152: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4153: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-4154: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4155: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-4156: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4157: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4158: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 1-4159: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4160: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4161: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 1-4162: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-4163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4164: Loss: 0.0029 Acc: 93.3333%\n",
      "\ttrain 1-4165: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4166: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-4167: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4168: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-4169: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4170: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-4171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4172: Loss: 0.0028 Acc: 93.3333%\n",
      "\ttrain 1-4173: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-4174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4175: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4176: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4177: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 1-4178: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4179: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4180: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4181: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-4182: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4183: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 1-4184: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 1-4185: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4186: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-4187: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4188: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4189: Loss: 0.0157 Acc: 93.3333%\n",
      "\ttrain 1-4190: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4193: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4194: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4195: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4196: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4197: Loss: 0.0125 Acc: 90.0000%\n",
      "\ttrain 1-4198: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-4199: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-4200: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-4201: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-4202: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 1-4203: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-4204: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4205: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4206: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 1-4207: Loss: 0.0161 Acc: 93.3333%\n",
      "\ttrain 1-4208: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-4209: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 1-4210: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-4211: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4212: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 1-4213: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4214: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-4215: Loss: 0.0041 Acc: 90.0000%\n",
      "\ttrain 1-4216: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4217: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 1-4218: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4219: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4220: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4221: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 1-4222: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 1-4223: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-4224: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4225: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4226: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-4227: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4228: Loss: 0.0084 Acc: 93.3333%\n",
      "\ttrain 1-4229: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4230: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4231: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 1-4232: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4233: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4234: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4235: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4236: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4237: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-4238: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4239: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4240: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4241: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-4242: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 1-4243: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 1-4244: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4245: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4246: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4247: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4248: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4249: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-4250: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4251: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4253: Loss: 0.0026 Acc: 93.3333%\n",
      "\ttrain 1-4254: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4255: Loss: 0.0069 Acc: 90.0000%\n",
      "\ttrain 1-4256: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4257: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4258: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4259: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4261: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-4262: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4263: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-4264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4265: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4266: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 1-4267: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4268: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4270: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-4271: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4272: Loss: 0.0100 Acc: 93.3333%\n",
      "\ttrain 1-4273: Loss: 0.0071 Acc: 96.6667%\n",
      "\ttrain 1-4274: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4275: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4276: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4277: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4278: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-4279: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4280: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4281: Loss: 0.0247 Acc: 93.3333%\n",
      "\ttrain 1-4282: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-4283: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4284: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4285: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4286: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 1-4287: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-4288: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 1-4289: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4290: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4291: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4292: Loss: 0.0094 Acc: 96.6667%\n",
      "\ttrain 1-4293: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-4294: Loss: 0.0084 Acc: 96.6667%\n",
      "\ttrain 1-4295: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 1-4296: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 1-4297: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 1-4298: Loss: 0.0084 Acc: 90.0000%\n",
      "\ttrain 1-4299: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4300: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4301: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-4302: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4303: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4304: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 1-4305: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-4306: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-4307: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4308: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-4309: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4310: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 1-4311: Loss: 0.0040 Acc: 90.0000%\n",
      "\ttrain 1-4312: Loss: 0.0017 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 1-4313: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-4314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4315: Loss: 0.0049 Acc: 90.0000%\n",
      "\ttrain 1-4316: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-4317: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4319: Loss: 0.0084 Acc: 96.6667%\n",
      "\ttrain 1-4320: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 1-4321: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4322: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4323: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 1-4324: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-4325: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4326: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4327: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 1-4328: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 1-4329: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 1-4330: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4331: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4332: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4333: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 1-4334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4335: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 1-4336: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4337: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4338: Loss: 0.0067 Acc: 90.0000%\n",
      "\ttrain 1-4339: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4340: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 1-4341: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4342: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-4343: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4344: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 1-4345: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4346: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4347: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4348: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4349: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4350: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 1-4351: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-4352: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4353: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4354: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-4355: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4356: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4358: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-4359: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4360: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-4361: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 1-4362: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 1-4363: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4364: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4366: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4367: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4368: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4369: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-4370: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 1-4371: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4372: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4373: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4374: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 1-4375: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 1-4376: Loss: 0.0100 Acc: 93.3333%\n",
      "\ttrain 1-4377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4378: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-4379: Loss: 0.0117 Acc: 93.3333%\n",
      "\ttrain 1-4380: Loss: 0.0073 Acc: 96.6667%\n",
      "\ttrain 1-4381: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 1-4382: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4383: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4384: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-4385: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4386: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 1-4387: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 1-4388: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4389: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4390: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4391: Loss: 0.0045 Acc: 93.3333%\n",
      "\ttrain 1-4392: Loss: 0.0038 Acc: 93.3333%\n",
      "\ttrain 1-4393: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4394: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 1-4395: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4396: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4397: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4398: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 1-4399: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4400: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4401: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4402: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4403: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4404: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 1-4405: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-4406: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4407: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4408: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4409: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4410: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 1-4411: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4412: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4413: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4414: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 1-4415: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4416: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4417: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4418: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4420: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4422: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4423: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4424: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4425: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4426: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4427: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 1-4428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4430: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4432: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 1-4433: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4435: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 1-4436: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 1-4437: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4438: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4439: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 1-4440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4441: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4442: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4443: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4444: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4445: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 1-4446: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4447: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4448: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4449: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 1-4450: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4451: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4452: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4453: Loss: 0.0139 Acc: 93.3333%\n",
      "\ttrain 1-4454: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 1-4455: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4456: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4457: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4458: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4459: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 1-4460: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 1-4461: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4462: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 1-4463: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4464: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 1-4465: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-4466: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4467: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-4468: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4469: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 1-4470: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 1-4471: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 1-4472: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 1-4473: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4474: Loss: 0.0141 Acc: 93.3333%\n",
      "\ttrain 1-4475: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 1-4476: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 1-4477: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 1-4478: Loss: 0.0076 Acc: 96.6667%\n",
      "\ttrain 1-4479: Loss: 0.0114 Acc: 93.3333%\n",
      "\ttrain 1-4480: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4481: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 1-4482: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 1-4483: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4484: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 1-4485: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-4486: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 1-4487: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4488: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 1-4489: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 1-4490: Loss: 0.0073 Acc: 96.6667%\n",
      "\ttrain 1-4491: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 1-4492: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 1-4493: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 1-4494: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4495: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4496: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 1-4497: Loss: 0.0084 Acc: 96.6667%\n",
      "\ttrain 1-4498: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 1-4499: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 1-4500: Loss: 0.0169 Acc: 86.6667%\n",
      "\tvalidation 1-1: Loss: 0.0137 Acc: 90.0000%\n",
      "\tvalidation 1-2: Loss: 0.0158 Acc: 86.6667%\n",
      "\tvalidation 1-3: Loss: 0.0201 Acc: 90.0000%\n",
      "\tvalidation 1-4: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 1-5: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 1-6: Loss: 0.0180 Acc: 83.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-7: Loss: 0.0390 Acc: 66.6667%\n",
      "\tvalidation 1-8: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 1-9: Loss: 0.0171 Acc: 83.3333%\n",
      "\tvalidation 1-10: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 1-11: Loss: 0.0195 Acc: 86.6667%\n",
      "\tvalidation 1-12: Loss: 0.0105 Acc: 96.6667%\n",
      "\tvalidation 1-13: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 1-14: Loss: 0.0206 Acc: 80.0000%\n",
      "\tvalidation 1-15: Loss: 0.0128 Acc: 90.0000%\n",
      "\tvalidation 1-16: Loss: 0.0127 Acc: 90.0000%\n",
      "\tvalidation 1-17: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-18: Loss: 0.0118 Acc: 90.0000%\n",
      "\tvalidation 1-19: Loss: 0.0108 Acc: 90.0000%\n",
      "\tvalidation 1-20: Loss: 0.0155 Acc: 90.0000%\n",
      "\tvalidation 1-21: Loss: 0.0075 Acc: 90.0000%\n",
      "\tvalidation 1-22: Loss: 0.0175 Acc: 83.3333%\n",
      "\tvalidation 1-23: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-24: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 1-25: Loss: 0.0106 Acc: 93.3333%\n",
      "\tvalidation 1-26: Loss: 0.0070 Acc: 90.0000%\n",
      "\tvalidation 1-27: Loss: 0.0075 Acc: 90.0000%\n",
      "\tvalidation 1-28: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 1-29: Loss: 0.0131 Acc: 86.6667%\n",
      "\tvalidation 1-30: Loss: 0.0260 Acc: 86.6667%\n",
      "\tvalidation 1-31: Loss: 0.0084 Acc: 83.3333%\n",
      "\tvalidation 1-32: Loss: 0.0023 Acc: 93.3333%\n",
      "\tvalidation 1-33: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 1-34: Loss: 0.0212 Acc: 86.6667%\n",
      "\tvalidation 1-35: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-36: Loss: 0.0087 Acc: 90.0000%\n",
      "\tvalidation 1-37: Loss: 0.0266 Acc: 86.6667%\n",
      "\tvalidation 1-38: Loss: 0.0112 Acc: 90.0000%\n",
      "\tvalidation 1-39: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 1-40: Loss: 0.0109 Acc: 93.3333%\n",
      "\tvalidation 1-41: Loss: 0.0179 Acc: 83.3333%\n",
      "\tvalidation 1-42: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 1-43: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-44: Loss: 0.0120 Acc: 93.3333%\n",
      "\tvalidation 1-45: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 1-46: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-47: Loss: 0.0075 Acc: 90.0000%\n",
      "\tvalidation 1-48: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 1-49: Loss: 0.0099 Acc: 90.0000%\n",
      "\tvalidation 1-50: Loss: 0.0129 Acc: 86.6667%\n",
      "\tvalidation 1-51: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 1-52: Loss: 0.0078 Acc: 96.6667%\n",
      "\tvalidation 1-53: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 1-54: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 1-55: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-56: Loss: 0.0160 Acc: 93.3333%\n",
      "\tvalidation 1-57: Loss: 0.0040 Acc: 96.6667%\n",
      "\tvalidation 1-58: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 1-59: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-60: Loss: 0.0225 Acc: 83.3333%\n",
      "\tvalidation 1-61: Loss: 0.0172 Acc: 90.0000%\n",
      "\tvalidation 1-62: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 1-63: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-64: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 1-65: Loss: 0.0050 Acc: 93.3333%\n",
      "\tvalidation 1-66: Loss: 0.0187 Acc: 83.3333%\n",
      "\tvalidation 1-67: Loss: 0.0153 Acc: 93.3333%\n",
      "\tvalidation 1-68: Loss: 0.0139 Acc: 86.6667%\n",
      "\tvalidation 1-69: Loss: 0.0058 Acc: 90.0000%\n",
      "\tvalidation 1-70: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 1-71: Loss: 0.0225 Acc: 86.6667%\n",
      "\tvalidation 1-72: Loss: 0.0143 Acc: 93.3333%\n",
      "\tvalidation 1-73: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 1-74: Loss: 0.0241 Acc: 80.0000%\n",
      "\tvalidation 1-75: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 1-76: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 1-77: Loss: 0.0093 Acc: 96.6667%\n",
      "\tvalidation 1-78: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 1-79: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 1-80: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-81: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-82: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 1-83: Loss: 0.0173 Acc: 86.6667%\n",
      "\tvalidation 1-84: Loss: 0.0242 Acc: 86.6667%\n",
      "\tvalidation 1-85: Loss: 0.0089 Acc: 86.6667%\n",
      "\tvalidation 1-86: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 1-87: Loss: 0.0101 Acc: 86.6667%\n",
      "\tvalidation 1-88: Loss: 0.0211 Acc: 90.0000%\n",
      "\tvalidation 1-89: Loss: 0.0068 Acc: 93.3333%\n",
      "\tvalidation 1-90: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-91: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 1-92: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-93: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 1-94: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-95: Loss: 0.0081 Acc: 96.6667%\n",
      "\tvalidation 1-96: Loss: 0.0151 Acc: 90.0000%\n",
      "\tvalidation 1-97: Loss: 0.0068 Acc: 86.6667%\n",
      "\tvalidation 1-98: Loss: 0.0133 Acc: 93.3333%\n",
      "\tvalidation 1-99: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-100: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-101: Loss: 0.0053 Acc: 90.0000%\n",
      "\tvalidation 1-102: Loss: 0.0129 Acc: 90.0000%\n",
      "\tvalidation 1-103: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 1-104: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 1-105: Loss: 0.0147 Acc: 86.6667%\n",
      "\tvalidation 1-106: Loss: 0.0147 Acc: 90.0000%\n",
      "\tvalidation 1-107: Loss: 0.0198 Acc: 86.6667%\n",
      "\tvalidation 1-108: Loss: 0.0061 Acc: 96.6667%\n",
      "\tvalidation 1-109: Loss: 0.0202 Acc: 83.3333%\n",
      "\tvalidation 1-110: Loss: 0.0105 Acc: 93.3333%\n",
      "\tvalidation 1-111: Loss: 0.0148 Acc: 83.3333%\n",
      "\tvalidation 1-112: Loss: 0.0159 Acc: 80.0000%\n",
      "\tvalidation 1-113: Loss: 0.0151 Acc: 90.0000%\n",
      "\tvalidation 1-114: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 1-115: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 1-116: Loss: 0.0088 Acc: 93.3333%\n",
      "\tvalidation 1-117: Loss: 0.0131 Acc: 93.3333%\n",
      "\tvalidation 1-118: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-119: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 1-120: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 1-121: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-122: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 1-123: Loss: 0.0182 Acc: 93.3333%\n",
      "\tvalidation 1-124: Loss: 0.0035 Acc: 93.3333%\n",
      "\tvalidation 1-125: Loss: 0.0121 Acc: 93.3333%\n",
      "\tvalidation 1-126: Loss: 0.0045 Acc: 93.3333%\n",
      "\tvalidation 1-127: Loss: 0.0108 Acc: 83.3333%\n",
      "\tvalidation 1-128: Loss: 0.0129 Acc: 86.6667%\n",
      "\tvalidation 1-129: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-130: Loss: 0.0099 Acc: 90.0000%\n",
      "\tvalidation 1-131: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-132: Loss: 0.0133 Acc: 86.6667%\n",
      "\tvalidation 1-133: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-134: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 1-135: Loss: 0.0097 Acc: 90.0000%\n",
      "\tvalidation 1-136: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 1-137: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-138: Loss: 0.0265 Acc: 83.3333%\n",
      "\tvalidation 1-139: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-140: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 1-141: Loss: 0.0084 Acc: 96.6667%\n",
      "\tvalidation 1-142: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 1-143: Loss: 0.0072 Acc: 96.6667%\n",
      "\tvalidation 1-144: Loss: 0.0145 Acc: 90.0000%\n",
      "\tvalidation 1-145: Loss: 0.0214 Acc: 86.6667%\n",
      "\tvalidation 1-146: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 1-147: Loss: 0.0116 Acc: 90.0000%\n",
      "\tvalidation 1-148: Loss: 0.0145 Acc: 90.0000%\n",
      "\tvalidation 1-149: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-150: Loss: 0.0078 Acc: 90.0000%\n",
      "\tvalidation 1-151: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 1-152: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-153: Loss: 0.0227 Acc: 83.3333%\n",
      "\tvalidation 1-154: Loss: 0.0189 Acc: 93.3333%\n",
      "\tvalidation 1-155: Loss: 0.0069 Acc: 86.6667%\n",
      "\tvalidation 1-156: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 1-157: Loss: 0.0278 Acc: 83.3333%\n",
      "\tvalidation 1-158: Loss: 0.0062 Acc: 90.0000%\n",
      "\tvalidation 1-159: Loss: 0.0125 Acc: 86.6667%\n",
      "\tvalidation 1-160: Loss: 0.0145 Acc: 90.0000%\n",
      "\tvalidation 1-161: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 1-162: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 1-163: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-164: Loss: 0.0123 Acc: 93.3333%\n",
      "\tvalidation 1-165: Loss: 0.0130 Acc: 83.3333%\n",
      "\tvalidation 1-166: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-167: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 1-168: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 1-169: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 1-170: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 1-171: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 1-172: Loss: 0.0094 Acc: 86.6667%\n",
      "\tvalidation 1-173: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-174: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 1-175: Loss: 0.0110 Acc: 90.0000%\n",
      "\tvalidation 1-176: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 1-177: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 1-178: Loss: 0.0121 Acc: 86.6667%\n",
      "\tvalidation 1-179: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 1-180: Loss: 0.0086 Acc: 90.0000%\n",
      "\tvalidation 1-181: Loss: 0.0287 Acc: 83.3333%\n",
      "\tvalidation 1-182: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 1-183: Loss: 0.0176 Acc: 86.6667%\n",
      "\tvalidation 1-184: Loss: 0.0120 Acc: 83.3333%\n",
      "\tvalidation 1-185: Loss: 0.0139 Acc: 93.3333%\n",
      "\tvalidation 1-186: Loss: 0.0052 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-187: Loss: 0.0205 Acc: 86.6667%\n",
      "\tvalidation 1-188: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 1-189: Loss: 0.0080 Acc: 86.6667%\n",
      "\tvalidation 1-190: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 1-191: Loss: 0.0192 Acc: 90.0000%\n",
      "\tvalidation 1-192: Loss: 0.0242 Acc: 83.3333%\n",
      "\tvalidation 1-193: Loss: 0.0138 Acc: 90.0000%\n",
      "\tvalidation 1-194: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 1-195: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 1-196: Loss: 0.0080 Acc: 96.6667%\n",
      "\tvalidation 1-197: Loss: 0.0140 Acc: 86.6667%\n",
      "\tvalidation 1-198: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-199: Loss: 0.0097 Acc: 86.6667%\n",
      "\tvalidation 1-200: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 1-201: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 1-202: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-203: Loss: 0.0194 Acc: 86.6667%\n",
      "\tvalidation 1-204: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-205: Loss: 0.0039 Acc: 93.3333%\n",
      "\tvalidation 1-206: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 1-207: Loss: 0.0158 Acc: 86.6667%\n",
      "\tvalidation 1-208: Loss: 0.0254 Acc: 83.3333%\n",
      "\tvalidation 1-209: Loss: 0.0173 Acc: 80.0000%\n",
      "\tvalidation 1-210: Loss: 0.0146 Acc: 93.3333%\n",
      "\tvalidation 1-211: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 1-212: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 1-213: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-214: Loss: 0.0143 Acc: 93.3333%\n",
      "\tvalidation 1-215: Loss: 0.0096 Acc: 86.6667%\n",
      "\tvalidation 1-216: Loss: 0.0086 Acc: 90.0000%\n",
      "\tvalidation 1-217: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-218: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 1-219: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 1-220: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-221: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 1-222: Loss: 0.0156 Acc: 86.6667%\n",
      "\tvalidation 1-223: Loss: 0.0118 Acc: 90.0000%\n",
      "\tvalidation 1-224: Loss: 0.0156 Acc: 93.3333%\n",
      "\tvalidation 1-225: Loss: 0.0264 Acc: 80.0000%\n",
      "\tvalidation 1-226: Loss: 0.0085 Acc: 90.0000%\n",
      "\tvalidation 1-227: Loss: 0.0077 Acc: 86.6667%\n",
      "\tvalidation 1-228: Loss: 0.0113 Acc: 86.6667%\n",
      "\tvalidation 1-229: Loss: 0.0160 Acc: 86.6667%\n",
      "\tvalidation 1-230: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 1-231: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 1-232: Loss: 0.0055 Acc: 90.0000%\n",
      "\tvalidation 1-233: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 1-234: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 1-235: Loss: 0.0075 Acc: 86.6667%\n",
      "\tvalidation 1-236: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 1-237: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 1-238: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 1-239: Loss: 0.0063 Acc: 90.0000%\n",
      "\tvalidation 1-240: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-241: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-242: Loss: 0.0059 Acc: 90.0000%\n",
      "\tvalidation 1-243: Loss: 0.0159 Acc: 83.3333%\n",
      "\tvalidation 1-244: Loss: 0.0140 Acc: 83.3333%\n",
      "\tvalidation 1-245: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-246: Loss: 0.0074 Acc: 86.6667%\n",
      "\tvalidation 1-247: Loss: 0.0131 Acc: 86.6667%\n",
      "\tvalidation 1-248: Loss: 0.0056 Acc: 90.0000%\n",
      "\tvalidation 1-249: Loss: 0.0109 Acc: 90.0000%\n",
      "\tvalidation 1-250: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 1-251: Loss: 0.0302 Acc: 86.6667%\n",
      "\tvalidation 1-252: Loss: 0.0110 Acc: 86.6667%\n",
      "\tvalidation 1-253: Loss: 0.0152 Acc: 83.3333%\n",
      "\tvalidation 1-254: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 1-255: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-256: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-257: Loss: 0.0114 Acc: 93.3333%\n",
      "\tvalidation 1-258: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-259: Loss: 0.0109 Acc: 93.3333%\n",
      "\tvalidation 1-260: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 1-261: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 1-262: Loss: 0.0164 Acc: 73.3333%\n",
      "\tvalidation 1-263: Loss: 0.0063 Acc: 90.0000%\n",
      "\tvalidation 1-264: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 1-265: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 1-266: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-267: Loss: 0.0019 Acc: 100.0000%\n",
      "\tvalidation 1-268: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 1-269: Loss: 0.0071 Acc: 90.0000%\n",
      "\tvalidation 1-270: Loss: 0.0195 Acc: 90.0000%\n",
      "\tvalidation 1-271: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-272: Loss: 0.0086 Acc: 90.0000%\n",
      "\tvalidation 1-273: Loss: 0.0258 Acc: 93.3333%\n",
      "\tvalidation 1-274: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 1-275: Loss: 0.0152 Acc: 86.6667%\n",
      "\tvalidation 1-276: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-277: Loss: 0.0077 Acc: 90.0000%\n",
      "\tvalidation 1-278: Loss: 0.0122 Acc: 86.6667%\n",
      "\tvalidation 1-279: Loss: 0.0117 Acc: 86.6667%\n",
      "\tvalidation 1-280: Loss: 0.0110 Acc: 83.3333%\n",
      "\tvalidation 1-281: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 1-282: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 1-283: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 1-284: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-285: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-286: Loss: 0.0128 Acc: 86.6667%\n",
      "\tvalidation 1-287: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-288: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 1-289: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 1-290: Loss: 0.0197 Acc: 90.0000%\n",
      "\tvalidation 1-291: Loss: 0.0108 Acc: 93.3333%\n",
      "\tvalidation 1-292: Loss: 0.0062 Acc: 90.0000%\n",
      "\tvalidation 1-293: Loss: 0.0291 Acc: 83.3333%\n",
      "\tvalidation 1-294: Loss: 0.0103 Acc: 86.6667%\n",
      "\tvalidation 1-295: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 1-296: Loss: 0.0042 Acc: 90.0000%\n",
      "\tvalidation 1-297: Loss: 0.0245 Acc: 86.6667%\n",
      "\tvalidation 1-298: Loss: 0.0181 Acc: 83.3333%\n",
      "\tvalidation 1-299: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-300: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 1-301: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-302: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-303: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 1-304: Loss: 0.0199 Acc: 83.3333%\n",
      "\tvalidation 1-305: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-306: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 1-307: Loss: 0.0099 Acc: 86.6667%\n",
      "\tvalidation 1-308: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-309: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 1-310: Loss: 0.0230 Acc: 80.0000%\n",
      "\tvalidation 1-311: Loss: 0.0061 Acc: 90.0000%\n",
      "\tvalidation 1-312: Loss: 0.0133 Acc: 83.3333%\n",
      "\tvalidation 1-313: Loss: 0.0384 Acc: 80.0000%\n",
      "\tvalidation 1-314: Loss: 0.0134 Acc: 86.6667%\n",
      "\tvalidation 1-315: Loss: 0.0116 Acc: 93.3333%\n",
      "\tvalidation 1-316: Loss: 0.0065 Acc: 90.0000%\n",
      "\tvalidation 1-317: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 1-318: Loss: 0.0135 Acc: 90.0000%\n",
      "\tvalidation 1-319: Loss: 0.0071 Acc: 96.6667%\n",
      "\tvalidation 1-320: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 1-321: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-322: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 1-323: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 1-324: Loss: 0.0161 Acc: 86.6667%\n",
      "\tvalidation 1-325: Loss: 0.0172 Acc: 90.0000%\n",
      "\tvalidation 1-326: Loss: 0.0061 Acc: 93.3333%\n",
      "\tvalidation 1-327: Loss: 0.0310 Acc: 83.3333%\n",
      "\tvalidation 1-328: Loss: 0.0233 Acc: 80.0000%\n",
      "\tvalidation 1-329: Loss: 0.0232 Acc: 86.6667%\n",
      "\tvalidation 1-330: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-331: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 1-332: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 1-333: Loss: 0.0198 Acc: 83.3333%\n",
      "\tvalidation 1-334: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-335: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 1-336: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-337: Loss: 0.0138 Acc: 83.3333%\n",
      "\tvalidation 1-338: Loss: 0.0177 Acc: 90.0000%\n",
      "\tvalidation 1-339: Loss: 0.0176 Acc: 90.0000%\n",
      "\tvalidation 1-340: Loss: 0.0216 Acc: 93.3333%\n",
      "\tvalidation 1-341: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 1-342: Loss: 0.0122 Acc: 93.3333%\n",
      "\tvalidation 1-343: Loss: 0.0184 Acc: 93.3333%\n",
      "\tvalidation 1-344: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 1-345: Loss: 0.0175 Acc: 90.0000%\n",
      "\tvalidation 1-346: Loss: 0.0223 Acc: 90.0000%\n",
      "\tvalidation 1-347: Loss: 0.0166 Acc: 90.0000%\n",
      "\tvalidation 1-348: Loss: 0.0239 Acc: 83.3333%\n",
      "\tvalidation 1-349: Loss: 0.0139 Acc: 86.6667%\n",
      "\tvalidation 1-350: Loss: 0.0106 Acc: 86.6667%\n",
      "\tvalidation 1-351: Loss: 0.0066 Acc: 96.6667%\n",
      "\tvalidation 1-352: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 1-353: Loss: 0.0182 Acc: 83.3333%\n",
      "\tvalidation 1-354: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 1-355: Loss: 0.0126 Acc: 90.0000%\n",
      "\tvalidation 1-356: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 1-357: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-358: Loss: 0.0142 Acc: 93.3333%\n",
      "\tvalidation 1-359: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 1-360: Loss: 0.0116 Acc: 93.3333%\n",
      "\tvalidation 1-361: Loss: 0.0060 Acc: 90.0000%\n",
      "\tvalidation 1-362: Loss: 0.0084 Acc: 90.0000%\n",
      "\tvalidation 1-363: Loss: 0.0177 Acc: 83.3333%\n",
      "\tvalidation 1-364: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 1-365: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 1-366: Loss: 0.0095 Acc: 90.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-367: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-368: Loss: 0.0085 Acc: 93.3333%\n",
      "\tvalidation 1-369: Loss: 0.0095 Acc: 90.0000%\n",
      "\tvalidation 1-370: Loss: 0.0058 Acc: 96.6667%\n",
      "\tvalidation 1-371: Loss: 0.0196 Acc: 90.0000%\n",
      "\tvalidation 1-372: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 1-373: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-374: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-375: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 1-376: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-377: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-378: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 1-379: Loss: 0.0080 Acc: 90.0000%\n",
      "\tvalidation 1-380: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 1-381: Loss: 0.0209 Acc: 73.3333%\n",
      "\tvalidation 1-382: Loss: 0.0063 Acc: 90.0000%\n",
      "\tvalidation 1-383: Loss: 0.0124 Acc: 86.6667%\n",
      "\tvalidation 1-384: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 1-385: Loss: 0.0127 Acc: 90.0000%\n",
      "\tvalidation 1-386: Loss: 0.0121 Acc: 83.3333%\n",
      "\tvalidation 1-387: Loss: 0.0149 Acc: 86.6667%\n",
      "\tvalidation 1-388: Loss: 0.0144 Acc: 90.0000%\n",
      "\tvalidation 1-389: Loss: 0.0156 Acc: 83.3333%\n",
      "\tvalidation 1-390: Loss: 0.0080 Acc: 90.0000%\n",
      "\tvalidation 1-391: Loss: 0.0172 Acc: 83.3333%\n",
      "\tvalidation 1-392: Loss: 0.0067 Acc: 96.6667%\n",
      "\tvalidation 1-393: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 1-394: Loss: 0.0263 Acc: 86.6667%\n",
      "\tvalidation 1-395: Loss: 0.0129 Acc: 86.6667%\n",
      "\tvalidation 1-396: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 1-397: Loss: 0.0242 Acc: 83.3333%\n",
      "\tvalidation 1-398: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-399: Loss: 0.0135 Acc: 83.3333%\n",
      "\tvalidation 1-400: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-401: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-402: Loss: 0.0049 Acc: 90.0000%\n",
      "\tvalidation 1-403: Loss: 0.0083 Acc: 93.3333%\n",
      "\tvalidation 1-404: Loss: 0.0220 Acc: 80.0000%\n",
      "\tvalidation 1-405: Loss: 0.0222 Acc: 86.6667%\n",
      "\tvalidation 1-406: Loss: 0.0110 Acc: 86.6667%\n",
      "\tvalidation 1-407: Loss: 0.0194 Acc: 83.3333%\n",
      "\tvalidation 1-408: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 1-409: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 1-410: Loss: 0.0117 Acc: 90.0000%\n",
      "\tvalidation 1-411: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 1-412: Loss: 0.0024 Acc: 100.0000%\n",
      "\tvalidation 1-413: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 1-414: Loss: 0.0166 Acc: 86.6667%\n",
      "\tvalidation 1-415: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-416: Loss: 0.0209 Acc: 83.3333%\n",
      "\tvalidation 1-417: Loss: 0.0176 Acc: 86.6667%\n",
      "\tvalidation 1-418: Loss: 0.0090 Acc: 96.6667%\n",
      "\tvalidation 1-419: Loss: 0.0335 Acc: 73.3333%\n",
      "\tvalidation 1-420: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 1-421: Loss: 0.0071 Acc: 90.0000%\n",
      "\tvalidation 1-422: Loss: 0.0148 Acc: 93.3333%\n",
      "\tvalidation 1-423: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 1-424: Loss: 0.0076 Acc: 86.6667%\n",
      "\tvalidation 1-425: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 1-426: Loss: 0.0114 Acc: 86.6667%\n",
      "\tvalidation 1-427: Loss: 0.0200 Acc: 90.0000%\n",
      "\tvalidation 1-428: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-429: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 1-430: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 1-431: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 1-432: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-433: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 1-434: Loss: 0.0188 Acc: 93.3333%\n",
      "\tvalidation 1-435: Loss: 0.0197 Acc: 90.0000%\n",
      "\tvalidation 1-436: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 1-437: Loss: 0.0066 Acc: 90.0000%\n",
      "\tvalidation 1-438: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 1-439: Loss: 0.0115 Acc: 90.0000%\n",
      "\tvalidation 1-440: Loss: 0.0100 Acc: 96.6667%\n",
      "\tvalidation 1-441: Loss: 0.0115 Acc: 96.6667%\n",
      "\tvalidation 1-442: Loss: 0.0194 Acc: 90.0000%\n",
      "\tvalidation 1-443: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-444: Loss: 0.0043 Acc: 93.3333%\n",
      "\tvalidation 1-445: Loss: 0.0147 Acc: 90.0000%\n",
      "\tvalidation 1-446: Loss: 0.0104 Acc: 90.0000%\n",
      "\tvalidation 1-447: Loss: 0.0119 Acc: 86.6667%\n",
      "\tvalidation 1-448: Loss: 0.0330 Acc: 80.0000%\n",
      "\tvalidation 1-449: Loss: 0.0244 Acc: 76.6667%\n",
      "\tvalidation 1-450: Loss: 0.0166 Acc: 90.0000%\n",
      "\tvalidation 1-451: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-452: Loss: 0.0092 Acc: 90.0000%\n",
      "\tvalidation 1-453: Loss: 0.0270 Acc: 83.3333%\n",
      "\tvalidation 1-454: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-455: Loss: 0.0127 Acc: 86.6667%\n",
      "\tvalidation 1-456: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 1-457: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-458: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-459: Loss: 0.0078 Acc: 90.0000%\n",
      "\tvalidation 1-460: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-461: Loss: 0.0077 Acc: 90.0000%\n",
      "\tvalidation 1-462: Loss: 0.0093 Acc: 86.6667%\n",
      "\tvalidation 1-463: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-464: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-465: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 1-466: Loss: 0.0098 Acc: 90.0000%\n",
      "\tvalidation 1-467: Loss: 0.0234 Acc: 83.3333%\n",
      "\tvalidation 1-468: Loss: 0.0208 Acc: 83.3333%\n",
      "\tvalidation 1-469: Loss: 0.0175 Acc: 86.6667%\n",
      "\tvalidation 1-470: Loss: 0.0151 Acc: 83.3333%\n",
      "\tvalidation 1-471: Loss: 0.0094 Acc: 96.6667%\n",
      "\tvalidation 1-472: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 1-473: Loss: 0.0110 Acc: 83.3333%\n",
      "\tvalidation 1-474: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 1-475: Loss: 0.0182 Acc: 93.3333%\n",
      "\tvalidation 1-476: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-477: Loss: 0.0143 Acc: 93.3333%\n",
      "\tvalidation 1-478: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-479: Loss: 0.0061 Acc: 90.0000%\n",
      "\tvalidation 1-480: Loss: 0.0149 Acc: 83.3333%\n",
      "\tvalidation 1-481: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 1-482: Loss: 0.0103 Acc: 86.6667%\n",
      "\tvalidation 1-483: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 1-484: Loss: 0.0040 Acc: 93.3333%\n",
      "\tvalidation 1-485: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 1-486: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 1-487: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 1-488: Loss: 0.0315 Acc: 86.6667%\n",
      "\tvalidation 1-489: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 1-490: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 1-491: Loss: 0.0220 Acc: 83.3333%\n",
      "\tvalidation 1-492: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-493: Loss: 0.0146 Acc: 86.6667%\n",
      "\tvalidation 1-494: Loss: 0.0101 Acc: 93.3333%\n",
      "\tvalidation 1-495: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-496: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 1-497: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 1-498: Loss: 0.0128 Acc: 83.3333%\n",
      "\tvalidation 1-499: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 1-500: Loss: 0.0078 Acc: 90.0000%\n",
      "\tvalidation 1-501: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 1-502: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 1-503: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 1-504: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 1-505: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 1-506: Loss: 0.0116 Acc: 90.0000%\n",
      "\tvalidation 1-507: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 1-508: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 1-509: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 1-510: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-511: Loss: 0.0117 Acc: 90.0000%\n",
      "\tvalidation 1-512: Loss: 0.0213 Acc: 93.3333%\n",
      "\tvalidation 1-513: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-514: Loss: 0.0069 Acc: 86.6667%\n",
      "\tvalidation 1-515: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 1-516: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-517: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-518: Loss: 0.0139 Acc: 90.0000%\n",
      "\tvalidation 1-519: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-520: Loss: 0.0182 Acc: 86.6667%\n",
      "\tvalidation 1-521: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 1-522: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-523: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 1-524: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-525: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-526: Loss: 0.0040 Acc: 93.3333%\n",
      "\tvalidation 1-527: Loss: 0.0075 Acc: 90.0000%\n",
      "\tvalidation 1-528: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 1-529: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-530: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-531: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 1-532: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-533: Loss: 0.0077 Acc: 96.6667%\n",
      "\tvalidation 1-534: Loss: 0.0108 Acc: 90.0000%\n",
      "\tvalidation 1-535: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 1-536: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-537: Loss: 0.0130 Acc: 86.6667%\n",
      "\tvalidation 1-538: Loss: 0.0112 Acc: 90.0000%\n",
      "\tvalidation 1-539: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-540: Loss: 0.0170 Acc: 90.0000%\n",
      "\tvalidation 1-541: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-542: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 1-543: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 1-544: Loss: 0.0204 Acc: 86.6667%\n",
      "\tvalidation 1-545: Loss: 0.0103 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-546: Loss: 0.0316 Acc: 86.6667%\n",
      "\tvalidation 1-547: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 1-548: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-549: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-550: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 1-551: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-552: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-553: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-554: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 1-555: Loss: 0.0151 Acc: 80.0000%\n",
      "\tvalidation 1-556: Loss: 0.0105 Acc: 93.3333%\n",
      "\tvalidation 1-557: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-558: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 1-559: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 1-560: Loss: 0.0130 Acc: 93.3333%\n",
      "\tvalidation 1-561: Loss: 0.0062 Acc: 90.0000%\n",
      "\tvalidation 1-562: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-563: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 1-564: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 1-565: Loss: 0.0130 Acc: 83.3333%\n",
      "\tvalidation 1-566: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-567: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-568: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-569: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-570: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 1-571: Loss: 0.0122 Acc: 90.0000%\n",
      "\tvalidation 1-572: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-573: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 1-574: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 1-575: Loss: 0.0059 Acc: 96.6667%\n",
      "\tvalidation 1-576: Loss: 0.0200 Acc: 83.3333%\n",
      "\tvalidation 1-577: Loss: 0.0141 Acc: 86.6667%\n",
      "\tvalidation 1-578: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 1-579: Loss: 0.0131 Acc: 93.3333%\n",
      "\tvalidation 1-580: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-581: Loss: 0.0256 Acc: 86.6667%\n",
      "\tvalidation 1-582: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 1-583: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-584: Loss: 0.0145 Acc: 90.0000%\n",
      "\tvalidation 1-585: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 1-586: Loss: 0.0096 Acc: 90.0000%\n",
      "\tvalidation 1-587: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 1-588: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 1-589: Loss: 0.0066 Acc: 90.0000%\n",
      "\tvalidation 1-590: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 1-591: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-592: Loss: 0.0191 Acc: 83.3333%\n",
      "\tvalidation 1-593: Loss: 0.0149 Acc: 90.0000%\n",
      "\tvalidation 1-594: Loss: 0.0028 Acc: 93.3333%\n",
      "\tvalidation 1-595: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 1-596: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 1-597: Loss: 0.0124 Acc: 93.3333%\n",
      "\tvalidation 1-598: Loss: 0.0197 Acc: 80.0000%\n",
      "\tvalidation 1-599: Loss: 0.0165 Acc: 93.3333%\n",
      "\tvalidation 1-600: Loss: 0.0057 Acc: 90.0000%\n",
      "\tvalidation 1-601: Loss: 0.0182 Acc: 83.3333%\n",
      "\tvalidation 1-602: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 1-603: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 1-604: Loss: 0.0172 Acc: 83.3333%\n",
      "\tvalidation 1-605: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-606: Loss: 0.0207 Acc: 83.3333%\n",
      "\tvalidation 1-607: Loss: 0.0160 Acc: 90.0000%\n",
      "\tvalidation 1-608: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 1-609: Loss: 0.0187 Acc: 86.6667%\n",
      "\tvalidation 1-610: Loss: 0.0207 Acc: 86.6667%\n",
      "\tvalidation 1-611: Loss: 0.0061 Acc: 90.0000%\n",
      "\tvalidation 1-612: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 1-613: Loss: 0.0075 Acc: 90.0000%\n",
      "\tvalidation 1-614: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-615: Loss: 0.0260 Acc: 83.3333%\n",
      "\tvalidation 1-616: Loss: 0.0111 Acc: 86.6667%\n",
      "\tvalidation 1-617: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 1-618: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 1-619: Loss: 0.0031 Acc: 100.0000%\n",
      "\tvalidation 1-620: Loss: 0.0155 Acc: 83.3333%\n",
      "\tvalidation 1-621: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 1-622: Loss: 0.0158 Acc: 80.0000%\n",
      "\tvalidation 1-623: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-624: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 1-625: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 1-626: Loss: 0.0165 Acc: 86.6667%\n",
      "\tvalidation 1-627: Loss: 0.0103 Acc: 93.3333%\n",
      "\tvalidation 1-628: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 1-629: Loss: 0.0080 Acc: 90.0000%\n",
      "\tvalidation 1-630: Loss: 0.0161 Acc: 83.3333%\n",
      "\tvalidation 1-631: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 1-632: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 1-633: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-634: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-635: Loss: 0.0234 Acc: 83.3333%\n",
      "\tvalidation 1-636: Loss: 0.0036 Acc: 100.0000%\n",
      "\tvalidation 1-637: Loss: 0.0110 Acc: 83.3333%\n",
      "\tvalidation 1-638: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 1-639: Loss: 0.0039 Acc: 93.3333%\n",
      "\tvalidation 1-640: Loss: 0.0305 Acc: 80.0000%\n",
      "\tvalidation 1-641: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 1-642: Loss: 0.0254 Acc: 86.6667%\n",
      "\tvalidation 1-643: Loss: 0.0197 Acc: 86.6667%\n",
      "\tvalidation 1-644: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 1-645: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-646: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 1-647: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 1-648: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 1-649: Loss: 0.0183 Acc: 90.0000%\n",
      "\tvalidation 1-650: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 1-651: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-652: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 1-653: Loss: 0.0098 Acc: 90.0000%\n",
      "\tvalidation 1-654: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 1-655: Loss: 0.0136 Acc: 83.3333%\n",
      "\tvalidation 1-656: Loss: 0.0140 Acc: 93.3333%\n",
      "\tvalidation 1-657: Loss: 0.0085 Acc: 90.0000%\n",
      "\tvalidation 1-658: Loss: 0.0201 Acc: 86.6667%\n",
      "\tvalidation 1-659: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 1-660: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 1-661: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 1-662: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 1-663: Loss: 0.0177 Acc: 86.6667%\n",
      "\tvalidation 1-664: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 1-665: Loss: 0.0203 Acc: 83.3333%\n",
      "\tvalidation 1-666: Loss: 0.0123 Acc: 86.6667%\n",
      "\tvalidation 1-667: Loss: 0.0080 Acc: 93.3333%\n",
      "\tvalidation 1-668: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-669: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 1-670: Loss: 0.0236 Acc: 80.0000%\n",
      "\tvalidation 1-671: Loss: 0.0170 Acc: 90.0000%\n",
      "\tvalidation 1-672: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-673: Loss: 0.0185 Acc: 76.6667%\n",
      "\tvalidation 1-674: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 1-675: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-676: Loss: 0.0122 Acc: 96.6667%\n",
      "\tvalidation 1-677: Loss: 0.0133 Acc: 86.6667%\n",
      "\tvalidation 1-678: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-679: Loss: 0.0132 Acc: 86.6667%\n",
      "\tvalidation 1-680: Loss: 0.0465 Acc: 73.3333%\n",
      "\tvalidation 1-681: Loss: 0.0187 Acc: 83.3333%\n",
      "\tvalidation 1-682: Loss: 0.0156 Acc: 93.3333%\n",
      "\tvalidation 1-683: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-684: Loss: 0.0088 Acc: 86.6667%\n",
      "\tvalidation 1-685: Loss: 0.0268 Acc: 83.3333%\n",
      "\tvalidation 1-686: Loss: 0.0246 Acc: 83.3333%\n",
      "\tvalidation 1-687: Loss: 0.0148 Acc: 86.6667%\n",
      "\tvalidation 1-688: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 1-689: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-690: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 1-691: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 1-692: Loss: 0.0097 Acc: 93.3333%\n",
      "\tvalidation 1-693: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 1-694: Loss: 0.0163 Acc: 90.0000%\n",
      "\tvalidation 1-695: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 1-696: Loss: 0.0151 Acc: 86.6667%\n",
      "\tvalidation 1-697: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 1-698: Loss: 0.0188 Acc: 86.6667%\n",
      "\tvalidation 1-699: Loss: 0.0131 Acc: 93.3333%\n",
      "\tvalidation 1-700: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 1-701: Loss: 0.0109 Acc: 86.6667%\n",
      "\tvalidation 1-702: Loss: 0.0068 Acc: 96.6667%\n",
      "\tvalidation 1-703: Loss: 0.0293 Acc: 86.6667%\n",
      "\tvalidation 1-704: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 1-705: Loss: 0.0035 Acc: 93.3333%\n",
      "\tvalidation 1-706: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 1-707: Loss: 0.0112 Acc: 90.0000%\n",
      "\tvalidation 1-708: Loss: 0.0143 Acc: 90.0000%\n",
      "\tvalidation 1-709: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 1-710: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 1-711: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 1-712: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 1-713: Loss: 0.0153 Acc: 83.3333%\n",
      "\tvalidation 1-714: Loss: 0.0120 Acc: 93.3333%\n",
      "\tvalidation 1-715: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 1-716: Loss: 0.0102 Acc: 86.6667%\n",
      "\tvalidation 1-717: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 1-718: Loss: 0.0126 Acc: 86.6667%\n",
      "\tvalidation 1-719: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 1-720: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 1-721: Loss: 0.0101 Acc: 86.6667%\n",
      "\tvalidation 1-722: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 1-723: Loss: 0.0068 Acc: 90.0000%\n",
      "\tvalidation 1-724: Loss: 0.0080 Acc: 86.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-725: Loss: 0.0058 Acc: 90.0000%\n",
      "\tvalidation 1-726: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-727: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 1-728: Loss: 0.0118 Acc: 90.0000%\n",
      "\tvalidation 1-729: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 1-730: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-731: Loss: 0.0039 Acc: 93.3333%\n",
      "\tvalidation 1-732: Loss: 0.0099 Acc: 86.6667%\n",
      "\tvalidation 1-733: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 1-734: Loss: 0.0282 Acc: 86.6667%\n",
      "\tvalidation 1-735: Loss: 0.0187 Acc: 86.6667%\n",
      "\tvalidation 1-736: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 1-737: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 1-738: Loss: 0.0065 Acc: 90.0000%\n",
      "\tvalidation 1-739: Loss: 0.0144 Acc: 90.0000%\n",
      "\tvalidation 1-740: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-741: Loss: 0.0073 Acc: 90.0000%\n",
      "\tvalidation 1-742: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 1-743: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 1-744: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 1-745: Loss: 0.0169 Acc: 83.3333%\n",
      "\tvalidation 1-746: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-747: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 1-748: Loss: 0.0168 Acc: 86.6667%\n",
      "\tvalidation 1-749: Loss: 0.0136 Acc: 90.0000%\n",
      "\tvalidation 1-750: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 1-751: Loss: 0.0172 Acc: 86.6667%\n",
      "\tvalidation 1-752: Loss: 0.0273 Acc: 90.0000%\n",
      "\tvalidation 1-753: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 1-754: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-755: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 1-756: Loss: 0.0179 Acc: 83.3333%\n",
      "\tvalidation 1-757: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 1-758: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 1-759: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-760: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-761: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 1-762: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 1-763: Loss: 0.0053 Acc: 90.0000%\n",
      "\tvalidation 1-764: Loss: 0.0136 Acc: 86.6667%\n",
      "\tvalidation 1-765: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 1-766: Loss: 0.0243 Acc: 83.3333%\n",
      "\tvalidation 1-767: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 1-768: Loss: 0.0196 Acc: 83.3333%\n",
      "\tvalidation 1-769: Loss: 0.0088 Acc: 90.0000%\n",
      "\tvalidation 1-770: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 1-771: Loss: 0.0050 Acc: 93.3333%\n",
      "\tvalidation 1-772: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-773: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 1-774: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 1-775: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 1-776: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-777: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-778: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 1-779: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 1-780: Loss: 0.0140 Acc: 83.3333%\n",
      "\tvalidation 1-781: Loss: 0.0223 Acc: 86.6667%\n",
      "\tvalidation 1-782: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 1-783: Loss: 0.0103 Acc: 86.6667%\n",
      "\tvalidation 1-784: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 1-785: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 1-786: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 1-787: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-788: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-789: Loss: 0.0050 Acc: 93.3333%\n",
      "\tvalidation 1-790: Loss: 0.0033 Acc: 93.3333%\n",
      "\tvalidation 1-791: Loss: 0.0231 Acc: 86.6667%\n",
      "\tvalidation 1-792: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 1-793: Loss: 0.0151 Acc: 86.6667%\n",
      "\tvalidation 1-794: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-795: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 1-796: Loss: 0.0112 Acc: 96.6667%\n",
      "\tvalidation 1-797: Loss: 0.0121 Acc: 86.6667%\n",
      "\tvalidation 1-798: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 1-799: Loss: 0.0127 Acc: 93.3333%\n",
      "\tvalidation 1-800: Loss: 0.0318 Acc: 83.3333%\n",
      "\tvalidation 1-801: Loss: 0.0132 Acc: 90.0000%\n",
      "\tvalidation 1-802: Loss: 0.0300 Acc: 86.6667%\n",
      "\tvalidation 1-803: Loss: 0.0163 Acc: 90.0000%\n",
      "\tvalidation 1-804: Loss: 0.0079 Acc: 90.0000%\n",
      "\tvalidation 1-805: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 1-806: Loss: 0.0199 Acc: 83.3333%\n",
      "\tvalidation 1-807: Loss: 0.0126 Acc: 90.0000%\n",
      "\tvalidation 1-808: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 1-809: Loss: 0.0099 Acc: 90.0000%\n",
      "\tvalidation 1-810: Loss: 0.0058 Acc: 90.0000%\n",
      "\tvalidation 1-811: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 1-812: Loss: 0.0071 Acc: 90.0000%\n",
      "\tvalidation 1-813: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 1-814: Loss: 0.0168 Acc: 90.0000%\n",
      "\tvalidation 1-815: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 1-816: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 1-817: Loss: 0.0083 Acc: 90.0000%\n",
      "\tvalidation 1-818: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 1-819: Loss: 0.0187 Acc: 86.6667%\n",
      "\tvalidation 1-820: Loss: 0.0030 Acc: 100.0000%\n",
      "\tvalidation 1-821: Loss: 0.0114 Acc: 93.3333%\n",
      "\tvalidation 1-822: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 1-823: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 1-824: Loss: 0.0164 Acc: 90.0000%\n",
      "\tvalidation 1-825: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-826: Loss: 0.0184 Acc: 86.6667%\n",
      "\tvalidation 1-827: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-828: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 1-829: Loss: 0.0037 Acc: 93.3333%\n",
      "\tvalidation 1-830: Loss: 0.0144 Acc: 93.3333%\n",
      "\tvalidation 1-831: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-832: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 1-833: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 1-834: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-835: Loss: 0.0083 Acc: 90.0000%\n",
      "\tvalidation 1-836: Loss: 0.0277 Acc: 83.3333%\n",
      "\tvalidation 1-837: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-838: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-839: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-840: Loss: 0.0155 Acc: 90.0000%\n",
      "\tvalidation 1-841: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 1-842: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 1-843: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 1-844: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 1-845: Loss: 0.0025 Acc: 93.3333%\n",
      "\tvalidation 1-846: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 1-847: Loss: 0.0072 Acc: 90.0000%\n",
      "\tvalidation 1-848: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 1-849: Loss: 0.0322 Acc: 83.3333%\n",
      "\tvalidation 1-850: Loss: 0.0099 Acc: 86.6667%\n",
      "\tvalidation 1-851: Loss: 0.0064 Acc: 90.0000%\n",
      "\tvalidation 1-852: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 1-853: Loss: 0.0208 Acc: 83.3333%\n",
      "\tvalidation 1-854: Loss: 0.0168 Acc: 90.0000%\n",
      "\tvalidation 1-855: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-856: Loss: 0.0100 Acc: 96.6667%\n",
      "\tvalidation 1-857: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-858: Loss: 0.0204 Acc: 90.0000%\n",
      "\tvalidation 1-859: Loss: 0.0250 Acc: 83.3333%\n",
      "\tvalidation 1-860: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-861: Loss: 0.0095 Acc: 96.6667%\n",
      "\tvalidation 1-862: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 1-863: Loss: 0.0062 Acc: 86.6667%\n",
      "\tvalidation 1-864: Loss: 0.0224 Acc: 80.0000%\n",
      "\tvalidation 1-865: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 1-866: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-867: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 1-868: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 1-869: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 1-870: Loss: 0.0180 Acc: 83.3333%\n",
      "\tvalidation 1-871: Loss: 0.0123 Acc: 90.0000%\n",
      "\tvalidation 1-872: Loss: 0.0179 Acc: 86.6667%\n",
      "\tvalidation 1-873: Loss: 0.0105 Acc: 86.6667%\n",
      "\tvalidation 1-874: Loss: 0.0143 Acc: 83.3333%\n",
      "\tvalidation 1-875: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 1-876: Loss: 0.0119 Acc: 90.0000%\n",
      "\tvalidation 1-877: Loss: 0.0223 Acc: 76.6667%\n",
      "\tvalidation 1-878: Loss: 0.0167 Acc: 86.6667%\n",
      "\tvalidation 1-879: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 1-880: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 1-881: Loss: 0.0226 Acc: 86.6667%\n",
      "\tvalidation 1-882: Loss: 0.0057 Acc: 90.0000%\n",
      "\tvalidation 1-883: Loss: 0.0186 Acc: 90.0000%\n",
      "\tvalidation 1-884: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-885: Loss: 0.0202 Acc: 86.6667%\n",
      "\tvalidation 1-886: Loss: 0.0121 Acc: 93.3333%\n",
      "\tvalidation 1-887: Loss: 0.0061 Acc: 93.3333%\n",
      "\tvalidation 1-888: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-889: Loss: 0.0151 Acc: 90.0000%\n",
      "\tvalidation 1-890: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 1-891: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 1-892: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 1-893: Loss: 0.0088 Acc: 86.6667%\n",
      "\tvalidation 1-894: Loss: 0.0151 Acc: 80.0000%\n",
      "\tvalidation 1-895: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-896: Loss: 0.0267 Acc: 83.3333%\n",
      "\tvalidation 1-897: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-898: Loss: 0.0071 Acc: 90.0000%\n",
      "\tvalidation 1-899: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 1-900: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 1-901: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-902: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-903: Loss: 0.0067 Acc: 90.0000%\n",
      "\tvalidation 1-904: Loss: 0.0091 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-905: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 1-906: Loss: 0.0164 Acc: 83.3333%\n",
      "\tvalidation 1-907: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 1-908: Loss: 0.0196 Acc: 86.6667%\n",
      "\tvalidation 1-909: Loss: 0.0298 Acc: 73.3333%\n",
      "\tvalidation 1-910: Loss: 0.0083 Acc: 93.3333%\n",
      "\tvalidation 1-911: Loss: 0.0136 Acc: 83.3333%\n",
      "\tvalidation 1-912: Loss: 0.0106 Acc: 86.6667%\n",
      "\tvalidation 1-913: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 1-914: Loss: 0.0085 Acc: 93.3333%\n",
      "\tvalidation 1-915: Loss: 0.0150 Acc: 86.6667%\n",
      "\tvalidation 1-916: Loss: 0.0154 Acc: 90.0000%\n",
      "\tvalidation 1-917: Loss: 0.0170 Acc: 83.3333%\n",
      "\tvalidation 1-918: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-919: Loss: 0.0181 Acc: 90.0000%\n",
      "\tvalidation 1-920: Loss: 0.0164 Acc: 86.6667%\n",
      "\tvalidation 1-921: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-922: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 1-923: Loss: 0.0162 Acc: 86.6667%\n",
      "\tvalidation 1-924: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 1-925: Loss: 0.0255 Acc: 73.3333%\n",
      "\tvalidation 1-926: Loss: 0.0045 Acc: 90.0000%\n",
      "\tvalidation 1-927: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 1-928: Loss: 0.0134 Acc: 86.6667%\n",
      "\tvalidation 1-929: Loss: 0.0186 Acc: 83.3333%\n",
      "\tvalidation 1-930: Loss: 0.0119 Acc: 90.0000%\n",
      "\tvalidation 1-931: Loss: 0.0167 Acc: 93.3333%\n",
      "\tvalidation 1-932: Loss: 0.0250 Acc: 80.0000%\n",
      "\tvalidation 1-933: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 1-934: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 1-935: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-936: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 1-937: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 1-938: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 1-939: Loss: 0.0064 Acc: 90.0000%\n",
      "\tvalidation 1-940: Loss: 0.0110 Acc: 83.3333%\n",
      "\tvalidation 1-941: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 1-942: Loss: 0.0289 Acc: 83.3333%\n",
      "\tvalidation 1-943: Loss: 0.0083 Acc: 90.0000%\n",
      "\tvalidation 1-944: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 1-945: Loss: 0.0225 Acc: 83.3333%\n",
      "\tvalidation 1-946: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 1-947: Loss: 0.0160 Acc: 83.3333%\n",
      "\tvalidation 1-948: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 1-949: Loss: 0.0204 Acc: 83.3333%\n",
      "\tvalidation 1-950: Loss: 0.0061 Acc: 93.3333%\n",
      "\tvalidation 1-951: Loss: 0.0117 Acc: 93.3333%\n",
      "\tvalidation 1-952: Loss: 0.0178 Acc: 90.0000%\n",
      "\tvalidation 1-953: Loss: 0.0184 Acc: 86.6667%\n",
      "\tvalidation 1-954: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-955: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-956: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-957: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 1-958: Loss: 0.0281 Acc: 86.6667%\n",
      "\tvalidation 1-959: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 1-960: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 1-961: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 1-962: Loss: 0.0146 Acc: 90.0000%\n",
      "\tvalidation 1-963: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 1-964: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 1-965: Loss: 0.0037 Acc: 93.3333%\n",
      "\tvalidation 1-966: Loss: 0.0138 Acc: 90.0000%\n",
      "\tvalidation 1-967: Loss: 0.0139 Acc: 90.0000%\n",
      "\tvalidation 1-968: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 1-969: Loss: 0.0058 Acc: 96.6667%\n",
      "\tvalidation 1-970: Loss: 0.0213 Acc: 86.6667%\n",
      "\tvalidation 1-971: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 1-972: Loss: 0.0040 Acc: 93.3333%\n",
      "\tvalidation 1-973: Loss: 0.0166 Acc: 86.6667%\n",
      "\tvalidation 1-974: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-975: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-976: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 1-977: Loss: 0.0171 Acc: 86.6667%\n",
      "\tvalidation 1-978: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 1-979: Loss: 0.0167 Acc: 93.3333%\n",
      "\tvalidation 1-980: Loss: 0.0105 Acc: 96.6667%\n",
      "\tvalidation 1-981: Loss: 0.0127 Acc: 90.0000%\n",
      "\tvalidation 1-982: Loss: 0.0068 Acc: 90.0000%\n",
      "\tvalidation 1-983: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-984: Loss: 0.0177 Acc: 86.6667%\n",
      "\tvalidation 1-985: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 1-986: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 1-987: Loss: 0.0109 Acc: 90.0000%\n",
      "\tvalidation 1-988: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 1-989: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 1-990: Loss: 0.0135 Acc: 86.6667%\n",
      "\tvalidation 1-991: Loss: 0.0040 Acc: 93.3333%\n",
      "\tvalidation 1-992: Loss: 0.0149 Acc: 90.0000%\n",
      "\tvalidation 1-993: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-994: Loss: 0.0234 Acc: 86.6667%\n",
      "\tvalidation 1-995: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 1-996: Loss: 0.0131 Acc: 90.0000%\n",
      "\tvalidation 1-997: Loss: 0.0148 Acc: 90.0000%\n",
      "\tvalidation 1-998: Loss: 0.0067 Acc: 83.3333%\n",
      "\tvalidation 1-999: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 1-1000: Loss: 0.0183 Acc: 86.6667%\n",
      "\tvalidation 1-1001: Loss: 0.0147 Acc: 86.6667%\n",
      "\tvalidation 1-1002: Loss: 0.0077 Acc: 96.6667%\n",
      "\tvalidation 1-1003: Loss: 0.0130 Acc: 86.6667%\n",
      "\tvalidation 1-1004: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 1-1005: Loss: 0.0074 Acc: 86.6667%\n",
      "\tvalidation 1-1006: Loss: 0.0113 Acc: 86.6667%\n",
      "\tvalidation 1-1007: Loss: 0.0189 Acc: 83.3333%\n",
      "\tvalidation 1-1008: Loss: 0.0104 Acc: 90.0000%\n",
      "\tvalidation 1-1009: Loss: 0.0177 Acc: 90.0000%\n",
      "\tvalidation 1-1010: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-1011: Loss: 0.0122 Acc: 90.0000%\n",
      "\tvalidation 1-1012: Loss: 0.0083 Acc: 86.6667%\n",
      "\tvalidation 1-1013: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 1-1014: Loss: 0.0147 Acc: 90.0000%\n",
      "\tvalidation 1-1015: Loss: 0.0084 Acc: 90.0000%\n",
      "\tvalidation 1-1016: Loss: 0.0147 Acc: 90.0000%\n",
      "\tvalidation 1-1017: Loss: 0.0096 Acc: 90.0000%\n",
      "\tvalidation 1-1018: Loss: 0.0082 Acc: 90.0000%\n",
      "\tvalidation 1-1019: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-1020: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 1-1021: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 1-1022: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 1-1023: Loss: 0.0077 Acc: 96.6667%\n",
      "\tvalidation 1-1024: Loss: 0.0054 Acc: 90.0000%\n",
      "\tvalidation 1-1025: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-1026: Loss: 0.0087 Acc: 83.3333%\n",
      "\tvalidation 1-1027: Loss: 0.0200 Acc: 86.6667%\n",
      "\tvalidation 1-1028: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 1-1029: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-1030: Loss: 0.0332 Acc: 80.0000%\n",
      "\tvalidation 1-1031: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-1032: Loss: 0.0202 Acc: 83.3333%\n",
      "\tvalidation 1-1033: Loss: 0.0046 Acc: 93.3333%\n",
      "\tvalidation 1-1034: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 1-1035: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 1-1036: Loss: 0.0230 Acc: 83.3333%\n",
      "\tvalidation 1-1037: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 1-1038: Loss: 0.0034 Acc: 93.3333%\n",
      "\tvalidation 1-1039: Loss: 0.0205 Acc: 93.3333%\n",
      "\tvalidation 1-1040: Loss: 0.0085 Acc: 93.3333%\n",
      "\tvalidation 1-1041: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 1-1042: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 1-1043: Loss: 0.0129 Acc: 93.3333%\n",
      "\tvalidation 1-1044: Loss: 0.0033 Acc: 93.3333%\n",
      "\tvalidation 1-1045: Loss: 0.0258 Acc: 90.0000%\n",
      "\tvalidation 1-1046: Loss: 0.0116 Acc: 90.0000%\n",
      "\tvalidation 1-1047: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-1048: Loss: 0.0114 Acc: 86.6667%\n",
      "\tvalidation 1-1049: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 1-1050: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 1-1051: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-1052: Loss: 0.0106 Acc: 86.6667%\n",
      "\tvalidation 1-1053: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-1054: Loss: 0.0109 Acc: 90.0000%\n",
      "\tvalidation 1-1055: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 1-1056: Loss: 0.0225 Acc: 80.0000%\n",
      "\tvalidation 1-1057: Loss: 0.0159 Acc: 90.0000%\n",
      "\tvalidation 1-1058: Loss: 0.0193 Acc: 90.0000%\n",
      "\tvalidation 1-1059: Loss: 0.0133 Acc: 90.0000%\n",
      "\tvalidation 1-1060: Loss: 0.0109 Acc: 90.0000%\n",
      "\tvalidation 1-1061: Loss: 0.0041 Acc: 90.0000%\n",
      "\tvalidation 1-1062: Loss: 0.0052 Acc: 96.6667%\n",
      "\tvalidation 1-1063: Loss: 0.0129 Acc: 90.0000%\n",
      "\tvalidation 1-1064: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-1065: Loss: 0.0201 Acc: 86.6667%\n",
      "\tvalidation 1-1066: Loss: 0.0070 Acc: 86.6667%\n",
      "\tvalidation 1-1067: Loss: 0.0108 Acc: 90.0000%\n",
      "\tvalidation 1-1068: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 1-1069: Loss: 0.0249 Acc: 80.0000%\n",
      "\tvalidation 1-1070: Loss: 0.0067 Acc: 96.6667%\n",
      "\tvalidation 1-1071: Loss: 0.0170 Acc: 86.6667%\n",
      "\tvalidation 1-1072: Loss: 0.0072 Acc: 90.0000%\n",
      "\tvalidation 1-1073: Loss: 0.0212 Acc: 93.3333%\n",
      "\tvalidation 1-1074: Loss: 0.0130 Acc: 90.0000%\n",
      "\tvalidation 1-1075: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-1076: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-1077: Loss: 0.0171 Acc: 93.3333%\n",
      "\tvalidation 1-1078: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 1-1079: Loss: 0.0126 Acc: 86.6667%\n",
      "\tvalidation 1-1080: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 1-1081: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 1-1082: Loss: 0.0150 Acc: 90.0000%\n",
      "\tvalidation 1-1083: Loss: 0.0124 Acc: 90.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-1084: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 1-1085: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 1-1086: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 1-1087: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 1-1088: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 1-1089: Loss: 0.0169 Acc: 90.0000%\n",
      "\tvalidation 1-1090: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 1-1091: Loss: 0.0123 Acc: 90.0000%\n",
      "\tvalidation 1-1092: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 1-1093: Loss: 0.0114 Acc: 90.0000%\n",
      "\tvalidation 1-1094: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-1095: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 1-1096: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 1-1097: Loss: 0.0139 Acc: 90.0000%\n",
      "\tvalidation 1-1098: Loss: 0.0097 Acc: 90.0000%\n",
      "\tvalidation 1-1099: Loss: 0.0169 Acc: 90.0000%\n",
      "\tvalidation 1-1100: Loss: 0.0068 Acc: 93.3333%\n",
      "\tvalidation 1-1101: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-1102: Loss: 0.0190 Acc: 83.3333%\n",
      "\tvalidation 1-1103: Loss: 0.0050 Acc: 93.3333%\n",
      "\tvalidation 1-1104: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 1-1105: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-1106: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 1-1107: Loss: 0.0098 Acc: 86.6667%\n",
      "\tvalidation 1-1108: Loss: 0.0107 Acc: 90.0000%\n",
      "\tvalidation 1-1109: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-1110: Loss: 0.0078 Acc: 96.6667%\n",
      "\tvalidation 1-1111: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 1-1112: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 1-1113: Loss: 0.0031 Acc: 96.6667%\n",
      "\tvalidation 1-1114: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-1115: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-1116: Loss: 0.0091 Acc: 96.6667%\n",
      "\tvalidation 1-1117: Loss: 0.0106 Acc: 93.3333%\n",
      "\tvalidation 1-1118: Loss: 0.0068 Acc: 90.0000%\n",
      "\tvalidation 1-1119: Loss: 0.0219 Acc: 93.3333%\n",
      "\tvalidation 1-1120: Loss: 0.0134 Acc: 86.6667%\n",
      "\tvalidation 1-1121: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-1122: Loss: 0.0093 Acc: 96.6667%\n",
      "\tvalidation 1-1123: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-1124: Loss: 0.0263 Acc: 83.3333%\n",
      "\tvalidation 1-1125: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 1-1126: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-1127: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 1-1128: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 1-1129: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 1-1130: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-1131: Loss: 0.0200 Acc: 83.3333%\n",
      "\tvalidation 1-1132: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 1-1133: Loss: 0.0122 Acc: 93.3333%\n",
      "\tvalidation 1-1134: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 1-1135: Loss: 0.0096 Acc: 90.0000%\n",
      "\tvalidation 1-1136: Loss: 0.0126 Acc: 90.0000%\n",
      "\tvalidation 1-1137: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 1-1138: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 1-1139: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 1-1140: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 1-1141: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 1-1142: Loss: 0.0046 Acc: 93.3333%\n",
      "\tvalidation 1-1143: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 1-1144: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 1-1145: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 1-1146: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 1-1147: Loss: 0.0149 Acc: 86.6667%\n",
      "\tvalidation 1-1148: Loss: 0.0103 Acc: 96.6667%\n",
      "\tvalidation 1-1149: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 1-1150: Loss: 0.0138 Acc: 83.3333%\n",
      "\tvalidation 1-1151: Loss: 0.0117 Acc: 93.3333%\n",
      "\tvalidation 1-1152: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 1-1153: Loss: 0.0115 Acc: 93.3333%\n",
      "\tvalidation 1-1154: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 1-1155: Loss: 0.0142 Acc: 93.3333%\n",
      "\tvalidation 1-1156: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-1157: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-1158: Loss: 0.0312 Acc: 76.6667%\n",
      "\tvalidation 1-1159: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 1-1160: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 1-1161: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-1162: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 1-1163: Loss: 0.0118 Acc: 86.6667%\n",
      "\tvalidation 1-1164: Loss: 0.0080 Acc: 90.0000%\n",
      "\tvalidation 1-1165: Loss: 0.0101 Acc: 93.3333%\n",
      "\tvalidation 1-1166: Loss: 0.0171 Acc: 80.0000%\n",
      "\tvalidation 1-1167: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 1-1168: Loss: 0.0064 Acc: 90.0000%\n",
      "\tvalidation 1-1169: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 1-1170: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 1-1171: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-1172: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 1-1173: Loss: 0.0059 Acc: 90.0000%\n",
      "\tvalidation 1-1174: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 1-1175: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 1-1176: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 1-1177: Loss: 0.0267 Acc: 80.0000%\n",
      "\tvalidation 1-1178: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 1-1179: Loss: 0.0251 Acc: 86.6667%\n",
      "\tvalidation 1-1180: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 1-1181: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-1182: Loss: 0.0066 Acc: 90.0000%\n",
      "\tvalidation 1-1183: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 1-1184: Loss: 0.0145 Acc: 90.0000%\n",
      "\tvalidation 1-1185: Loss: 0.0088 Acc: 90.0000%\n",
      "\tvalidation 1-1186: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-1187: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-1188: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 1-1189: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 1-1190: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 1-1191: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-1192: Loss: 0.0063 Acc: 90.0000%\n",
      "\tvalidation 1-1193: Loss: 0.0127 Acc: 90.0000%\n",
      "\tvalidation 1-1194: Loss: 0.0110 Acc: 90.0000%\n",
      "\tvalidation 1-1195: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 1-1196: Loss: 0.0065 Acc: 90.0000%\n",
      "\tvalidation 1-1197: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 1-1198: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 1-1199: Loss: 0.0178 Acc: 90.0000%\n",
      "\tvalidation 1-1200: Loss: 0.0049 Acc: 90.0000%\n",
      "\tvalidation 1-1201: Loss: 0.0070 Acc: 90.0000%\n",
      "\tvalidation 1-1202: Loss: 0.0109 Acc: 93.3333%\n",
      "\tvalidation 1-1203: Loss: 0.0018 Acc: 100.0000%\n",
      "\tvalidation 1-1204: Loss: 0.0076 Acc: 96.6667%\n",
      "\tvalidation 1-1205: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 1-1206: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-1207: Loss: 0.0149 Acc: 90.0000%\n",
      "\tvalidation 1-1208: Loss: 0.0154 Acc: 83.3333%\n",
      "\tvalidation 1-1209: Loss: 0.0140 Acc: 90.0000%\n",
      "\tvalidation 1-1210: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 1-1211: Loss: 0.0091 Acc: 96.6667%\n",
      "\tvalidation 1-1212: Loss: 0.0092 Acc: 90.0000%\n",
      "\tvalidation 1-1213: Loss: 0.0158 Acc: 80.0000%\n",
      "\tvalidation 1-1214: Loss: 0.0095 Acc: 86.6667%\n",
      "\tvalidation 1-1215: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 1-1216: Loss: 0.0103 Acc: 86.6667%\n",
      "\tvalidation 1-1217: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 1-1218: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 1-1219: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 1-1220: Loss: 0.0095 Acc: 96.6667%\n",
      "\tvalidation 1-1221: Loss: 0.0155 Acc: 83.3333%\n",
      "\tvalidation 1-1222: Loss: 0.0137 Acc: 90.0000%\n",
      "\tvalidation 1-1223: Loss: 0.0161 Acc: 86.6667%\n",
      "\tvalidation 1-1224: Loss: 0.0132 Acc: 86.6667%\n",
      "\tvalidation 1-1225: Loss: 0.0030 Acc: 93.3333%\n",
      "\tvalidation 1-1226: Loss: 0.0072 Acc: 90.0000%\n",
      "\tvalidation 1-1227: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 1-1228: Loss: 0.0061 Acc: 93.3333%\n",
      "\tvalidation 1-1229: Loss: 0.0237 Acc: 80.0000%\n",
      "\tvalidation 1-1230: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 1-1231: Loss: 0.0144 Acc: 93.3333%\n",
      "\tvalidation 1-1232: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 1-1233: Loss: 0.0161 Acc: 90.0000%\n",
      "\tvalidation 1-1234: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 1-1235: Loss: 0.0182 Acc: 86.6667%\n",
      "\tvalidation 1-1236: Loss: 0.0068 Acc: 90.0000%\n",
      "\tvalidation 1-1237: Loss: 0.0068 Acc: 93.3333%\n",
      "\tvalidation 1-1238: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-1239: Loss: 0.0207 Acc: 90.0000%\n",
      "\tvalidation 1-1240: Loss: 0.0066 Acc: 90.0000%\n",
      "\tvalidation 1-1241: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 1-1242: Loss: 0.0095 Acc: 86.6667%\n",
      "\tvalidation 1-1243: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-1244: Loss: 0.0115 Acc: 93.3333%\n",
      "\tvalidation 1-1245: Loss: 0.0127 Acc: 86.6667%\n",
      "\tvalidation 1-1246: Loss: 0.0099 Acc: 90.0000%\n",
      "\tvalidation 1-1247: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 1-1248: Loss: 0.0134 Acc: 90.0000%\n",
      "\tvalidation 1-1249: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 1-1250: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 1-1251: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-1252: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 1-1253: Loss: 0.0029 Acc: 100.0000%\n",
      "\tvalidation 1-1254: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 1-1255: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 1-1256: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 1-1257: Loss: 0.0086 Acc: 90.0000%\n",
      "\tvalidation 1-1258: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 1-1259: Loss: 0.0092 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-1260: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-1261: Loss: 0.0156 Acc: 86.6667%\n",
      "\tvalidation 1-1262: Loss: 0.0109 Acc: 86.6667%\n",
      "\tvalidation 1-1263: Loss: 0.0074 Acc: 86.6667%\n",
      "\tvalidation 1-1264: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 1-1265: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-1266: Loss: 0.0142 Acc: 90.0000%\n",
      "\tvalidation 1-1267: Loss: 0.0085 Acc: 86.6667%\n",
      "\tvalidation 1-1268: Loss: 0.0147 Acc: 86.6667%\n",
      "\tvalidation 1-1269: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 1-1270: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 1-1271: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 1-1272: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 1-1273: Loss: 0.0147 Acc: 86.6667%\n",
      "\tvalidation 1-1274: Loss: 0.0262 Acc: 73.3333%\n",
      "\tvalidation 1-1275: Loss: 0.0202 Acc: 83.3333%\n",
      "\tvalidation 1-1276: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 1-1277: Loss: 0.0125 Acc: 86.6667%\n",
      "\tvalidation 1-1278: Loss: 0.0225 Acc: 83.3333%\n",
      "\tvalidation 1-1279: Loss: 0.0168 Acc: 86.6667%\n",
      "\tvalidation 1-1280: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 1-1281: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 1-1282: Loss: 0.0084 Acc: 96.6667%\n",
      "\tvalidation 1-1283: Loss: 0.0095 Acc: 80.0000%\n",
      "\tvalidation 1-1284: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 1-1285: Loss: 0.0050 Acc: 93.3333%\n",
      "\tvalidation 1-1286: Loss: 0.0068 Acc: 90.0000%\n",
      "\tvalidation 1-1287: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 1-1288: Loss: 0.0193 Acc: 86.6667%\n",
      "\tvalidation 1-1289: Loss: 0.0109 Acc: 86.6667%\n",
      "\tvalidation 1-1290: Loss: 0.0100 Acc: 93.3333%\n",
      "\tvalidation 1-1291: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 1-1292: Loss: 0.0180 Acc: 86.6667%\n",
      "\tvalidation 1-1293: Loss: 0.0213 Acc: 83.3333%\n",
      "\tvalidation 1-1294: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 1-1295: Loss: 0.0099 Acc: 90.0000%\n",
      "\tvalidation 1-1296: Loss: 0.0251 Acc: 83.3333%\n",
      "\tvalidation 1-1297: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 1-1298: Loss: 0.0169 Acc: 86.6667%\n",
      "\tvalidation 1-1299: Loss: 0.0078 Acc: 86.6667%\n",
      "\tvalidation 1-1300: Loss: 0.0070 Acc: 90.0000%\n",
      "\tvalidation 1-1301: Loss: 0.0108 Acc: 86.6667%\n",
      "\tvalidation 1-1302: Loss: 0.0117 Acc: 86.6667%\n",
      "\tvalidation 1-1303: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 1-1304: Loss: 0.0107 Acc: 80.0000%\n",
      "\tvalidation 1-1305: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 1-1306: Loss: 0.0172 Acc: 86.6667%\n",
      "\tvalidation 1-1307: Loss: 0.0134 Acc: 86.6667%\n",
      "\tvalidation 1-1308: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 1-1309: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 1-1310: Loss: 0.0040 Acc: 96.6667%\n",
      "\tvalidation 1-1311: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 1-1312: Loss: 0.0144 Acc: 90.0000%\n",
      "\tvalidation 1-1313: Loss: 0.0245 Acc: 80.0000%\n",
      "\tvalidation 1-1314: Loss: 0.0137 Acc: 93.3333%\n",
      "\tvalidation 1-1315: Loss: 0.0139 Acc: 86.6667%\n",
      "\tvalidation 1-1316: Loss: 0.0009 Acc: 96.6667%\n",
      "\tvalidation 1-1317: Loss: 0.0131 Acc: 86.6667%\n",
      "\tvalidation 1-1318: Loss: 0.0087 Acc: 90.0000%\n",
      "\tvalidation 1-1319: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-1320: Loss: 0.0186 Acc: 83.3333%\n",
      "\tvalidation 1-1321: Loss: 0.0121 Acc: 86.6667%\n",
      "\tvalidation 1-1322: Loss: 0.0148 Acc: 86.6667%\n",
      "\tvalidation 1-1323: Loss: 0.0146 Acc: 86.6667%\n",
      "\tvalidation 1-1324: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 1-1325: Loss: 0.0089 Acc: 93.3333%\n",
      "\tvalidation 1-1326: Loss: 0.0107 Acc: 90.0000%\n",
      "\tvalidation 1-1327: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 1-1328: Loss: 0.0073 Acc: 90.0000%\n",
      "\tvalidation 1-1329: Loss: 0.0111 Acc: 96.6667%\n",
      "\tvalidation 1-1330: Loss: 0.0220 Acc: 83.3333%\n",
      "\tvalidation 1-1331: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 1-1332: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 1-1333: Loss: 0.0207 Acc: 86.6667%\n",
      "\tvalidation 1-1334: Loss: 0.0114 Acc: 96.6667%\n",
      "\tvalidation 1-1335: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 1-1336: Loss: 0.0077 Acc: 83.3333%\n",
      "\tvalidation 1-1337: Loss: 0.0103 Acc: 86.6667%\n",
      "\tvalidation 1-1338: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-1339: Loss: 0.0111 Acc: 86.6667%\n",
      "\tvalidation 1-1340: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 1-1341: Loss: 0.0059 Acc: 96.6667%\n",
      "\tvalidation 1-1342: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 1-1343: Loss: 0.0165 Acc: 90.0000%\n",
      "\tvalidation 1-1344: Loss: 0.0127 Acc: 80.0000%\n",
      "\tvalidation 1-1345: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 1-1346: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 1-1347: Loss: 0.0112 Acc: 86.6667%\n",
      "\tvalidation 1-1348: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 1-1349: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 1-1350: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 1-1351: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-1352: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 1-1353: Loss: 0.0054 Acc: 90.0000%\n",
      "\tvalidation 1-1354: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-1355: Loss: 0.0116 Acc: 90.0000%\n",
      "\tvalidation 1-1356: Loss: 0.0176 Acc: 83.3333%\n",
      "\tvalidation 1-1357: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 1-1358: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 1-1359: Loss: 0.0125 Acc: 90.0000%\n",
      "\tvalidation 1-1360: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 1-1361: Loss: 0.0123 Acc: 90.0000%\n",
      "\tvalidation 1-1362: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 1-1363: Loss: 0.0026 Acc: 100.0000%\n",
      "\tvalidation 1-1364: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 1-1365: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 1-1366: Loss: 0.0124 Acc: 86.6667%\n",
      "\tvalidation 1-1367: Loss: 0.0074 Acc: 90.0000%\n",
      "\tvalidation 1-1368: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 1-1369: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 1-1370: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 1-1371: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 1-1372: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 1-1373: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 1-1374: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 1-1375: Loss: 0.0271 Acc: 80.0000%\n",
      "\tvalidation 1-1376: Loss: 0.0114 Acc: 90.0000%\n",
      "\tvalidation 1-1377: Loss: 0.0175 Acc: 83.3333%\n",
      "\tvalidation 1-1378: Loss: 0.0090 Acc: 90.0000%\n",
      "\tvalidation 1-1379: Loss: 0.0114 Acc: 93.3333%\n",
      "\tvalidation 1-1380: Loss: 0.0085 Acc: 96.6667%\n",
      "\tvalidation 1-1381: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 1-1382: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 1-1383: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-1384: Loss: 0.0092 Acc: 90.0000%\n",
      "\tvalidation 1-1385: Loss: 0.0159 Acc: 86.6667%\n",
      "\tvalidation 1-1386: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 1-1387: Loss: 0.0158 Acc: 86.6667%\n",
      "\tvalidation 1-1388: Loss: 0.0153 Acc: 86.6667%\n",
      "\tvalidation 1-1389: Loss: 0.0183 Acc: 90.0000%\n",
      "\tvalidation 1-1390: Loss: 0.0129 Acc: 93.3333%\n",
      "\tvalidation 1-1391: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 1-1392: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-1393: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 1-1394: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-1395: Loss: 0.0115 Acc: 86.6667%\n",
      "\tvalidation 1-1396: Loss: 0.0095 Acc: 90.0000%\n",
      "\tvalidation 1-1397: Loss: 0.0088 Acc: 90.0000%\n",
      "\tvalidation 1-1398: Loss: 0.0169 Acc: 93.3333%\n",
      "\tvalidation 1-1399: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 1-1400: Loss: 0.0184 Acc: 80.0000%\n",
      "\tvalidation 1-1401: Loss: 0.0164 Acc: 90.0000%\n",
      "\tvalidation 1-1402: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 1-1403: Loss: 0.0197 Acc: 83.3333%\n",
      "\tvalidation 1-1404: Loss: 0.0109 Acc: 93.3333%\n",
      "\tvalidation 1-1405: Loss: 0.0104 Acc: 90.0000%\n",
      "\tvalidation 1-1406: Loss: 0.0026 Acc: 93.3333%\n",
      "\tvalidation 1-1407: Loss: 0.0185 Acc: 83.3333%\n",
      "\tvalidation 1-1408: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 1-1409: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 1-1410: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 1-1411: Loss: 0.0135 Acc: 83.3333%\n",
      "\tvalidation 1-1412: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 1-1413: Loss: 0.0168 Acc: 93.3333%\n",
      "\tvalidation 1-1414: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 1-1415: Loss: 0.0095 Acc: 86.6667%\n",
      "\tvalidation 1-1416: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 1-1417: Loss: 0.0036 Acc: 93.3333%\n",
      "\tvalidation 1-1418: Loss: 0.0217 Acc: 86.6667%\n",
      "\tvalidation 1-1419: Loss: 0.0171 Acc: 80.0000%\n",
      "\tvalidation 1-1420: Loss: 0.0037 Acc: 93.3333%\n",
      "\tvalidation 1-1421: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 1-1422: Loss: 0.0150 Acc: 86.6667%\n",
      "\tvalidation 1-1423: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 1-1424: Loss: 0.0200 Acc: 86.6667%\n",
      "\tvalidation 1-1425: Loss: 0.0070 Acc: 90.0000%\n",
      "\tvalidation 1-1426: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 1-1427: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 1-1428: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 1-1429: Loss: 0.0061 Acc: 93.3333%\n",
      "\tvalidation 1-1430: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 1-1431: Loss: 0.0203 Acc: 83.3333%\n",
      "\tvalidation 1-1432: Loss: 0.0074 Acc: 96.6667%\n",
      "\tvalidation 1-1433: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 1-1434: Loss: 0.0164 Acc: 86.6667%\n",
      "\tvalidation 1-1435: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 1-1436: Loss: 0.0026 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 1-1437: Loss: 0.0090 Acc: 90.0000%\n",
      "\tvalidation 1-1438: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 1-1439: Loss: 0.0088 Acc: 93.3333%\n",
      "\tvalidation 1-1440: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 1-1441: Loss: 0.0066 Acc: 90.0000%\n",
      "\tvalidation 1-1442: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 1-1443: Loss: 0.0210 Acc: 83.3333%\n",
      "\tvalidation 1-1444: Loss: 0.0224 Acc: 86.6667%\n",
      "\tvalidation 1-1445: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-1446: Loss: 0.0231 Acc: 83.3333%\n",
      "\tvalidation 1-1447: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 1-1448: Loss: 0.0143 Acc: 83.3333%\n",
      "\tvalidation 1-1449: Loss: 0.0141 Acc: 90.0000%\n",
      "\tvalidation 1-1450: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 1-1451: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-1452: Loss: 0.0097 Acc: 90.0000%\n",
      "\tvalidation 1-1453: Loss: 0.0114 Acc: 86.6667%\n",
      "\tvalidation 1-1454: Loss: 0.0281 Acc: 83.3333%\n",
      "\tvalidation 1-1455: Loss: 0.0077 Acc: 90.0000%\n",
      "\tvalidation 1-1456: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 1-1457: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 1-1458: Loss: 0.0219 Acc: 80.0000%\n",
      "\tvalidation 1-1459: Loss: 0.0170 Acc: 90.0000%\n",
      "\tvalidation 1-1460: Loss: 0.0271 Acc: 83.3333%\n",
      "\tvalidation 1-1461: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 1-1462: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 1-1463: Loss: 0.0257 Acc: 83.3333%\n",
      "\tvalidation 1-1464: Loss: 0.0201 Acc: 80.0000%\n",
      "\tvalidation 1-1465: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 1-1466: Loss: 0.0189 Acc: 90.0000%\n",
      "\tvalidation 1-1467: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 1-1468: Loss: 0.0035 Acc: 93.3333%\n",
      "\tvalidation 1-1469: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 1-1470: Loss: 0.0066 Acc: 90.0000%\n",
      "\tvalidation 1-1471: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 1-1472: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 1-1473: Loss: 0.0060 Acc: 90.0000%\n",
      "\tvalidation 1-1474: Loss: 0.0075 Acc: 83.3333%\n",
      "\tvalidation 1-1475: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 1-1476: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 1-1477: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 1-1478: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 1-1479: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 1-1480: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 1-1481: Loss: 0.0191 Acc: 90.0000%\n",
      "\tvalidation 1-1482: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 1-1483: Loss: 0.0085 Acc: 86.6667%\n",
      "\tvalidation 1-1484: Loss: 0.0020 Acc: 100.0000%\n",
      "\tvalidation 1-1485: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 1-1486: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 1-1487: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 1-1488: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 1-1489: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 1-1490: Loss: 0.0199 Acc: 93.3333%\n",
      "\tvalidation 1-1491: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 1-1492: Loss: 0.0106 Acc: 86.6667%\n",
      "\tvalidation 1-1493: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 1-1494: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 1-1495: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 1-1496: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 1-1497: Loss: 0.0023 Acc: 100.0000%\n",
      "\tvalidation 1-1498: Loss: 0.0134 Acc: 93.3333%\n",
      "\tvalidation 1-1499: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 1-1500: Loss: 0.0120 Acc: 86.6667%\n",
      "\ttrain Loss: 0.0218 Acc: 80.3659%\n",
      "\tvalidation Loss: 0.0100 Acc: 91.5378%\n",
      "Network parameter update.\n",
      "Time passed 0h 50m 29s\n",
      "--------------------\n",
      "learning_rate: 0.01\n",
      "Epoch [2/10]:\n",
      "\ttrain 2-1: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4: Loss: 0.0086 Acc: 90.0000%\n",
      "\ttrain 2-5: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-6: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-7: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 2-8: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-9: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-10: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-11: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-12: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-13: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-14: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 2-15: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-16: Loss: 0.0128 Acc: 90.0000%\n",
      "\ttrain 2-17: Loss: 0.0165 Acc: 90.0000%\n",
      "\ttrain 2-18: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-19: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-20: Loss: 0.0067 Acc: 93.3333%\n",
      "\ttrain 2-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-22: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-23: Loss: 0.0061 Acc: 86.6667%\n",
      "\ttrain 2-24: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 2-25: Loss: 0.0173 Acc: 86.6667%\n",
      "\ttrain 2-26: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-27: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-28: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-29: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-30: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-31: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-32: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-33: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-34: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-35: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-36: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 2-37: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-38: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 2-39: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-40: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-41: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-42: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-43: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-44: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-45: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-46: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-47: Loss: 0.0100 Acc: 93.3333%\n",
      "\ttrain 2-48: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-49: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-50: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-51: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-52: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-53: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-54: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-55: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-56: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-59: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-61: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-62: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-63: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-64: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-65: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-66: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 2-67: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-68: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-69: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-70: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-71: Loss: 0.0034 Acc: 100.0000%\n",
      "\ttrain 2-72: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-73: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-74: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-75: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-76: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-77: Loss: 0.0113 Acc: 96.6667%\n",
      "\ttrain 2-78: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-79: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-80: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-81: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-82: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 2-83: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-84: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-85: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 2-86: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-88: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 2-89: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 2-90: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-91: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-92: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-93: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 2-94: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-95: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-96: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-97: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-98: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-99: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-100: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-101: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-102: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-103: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-104: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-106: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-107: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 2-108: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-109: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 2-110: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-111: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-112: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-113: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-114: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-115: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-116: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-117: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-118: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-119: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-120: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-121: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-122: Loss: 0.0038 Acc: 93.3333%\n",
      "\ttrain 2-123: Loss: 0.0011 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-124: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-125: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 2-126: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-129: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-130: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-131: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-132: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-133: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-134: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-135: Loss: 0.0069 Acc: 96.6667%\n",
      "\ttrain 2-136: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-137: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-139: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-140: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-141: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-142: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-143: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-144: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-145: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-146: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-147: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-148: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-149: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-150: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-151: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-152: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-153: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-154: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-155: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-156: Loss: 0.0102 Acc: 93.3333%\n",
      "\ttrain 2-157: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-158: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-160: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-162: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-163: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-164: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-165: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-166: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-167: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-168: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-169: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-170: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-172: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-173: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 2-174: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-175: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-176: Loss: 0.0079 Acc: 90.0000%\n",
      "\ttrain 2-177: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-178: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-179: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-180: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-181: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-182: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 2-183: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-184: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-185: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-189: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-190: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-191: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-192: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-193: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-194: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-195: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-196: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-197: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 2-198: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-199: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-200: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-201: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-204: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-205: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-206: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-207: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-208: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-210: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-211: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-212: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-213: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-214: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-215: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-216: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-217: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-218: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-219: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-220: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-221: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 2-222: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-223: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-224: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-225: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-227: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-228: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-229: Loss: 0.0028 Acc: 93.3333%\n",
      "\ttrain 2-230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-231: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 2-232: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-233: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-234: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-235: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-236: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-237: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-238: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-239: Loss: 0.0082 Acc: 96.6667%\n",
      "\ttrain 2-240: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-241: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-242: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-243: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-244: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-245: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-246: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-247: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-248: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 2-249: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-250: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-251: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-252: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-254: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-255: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-256: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-257: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-260: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 2-261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-262: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-264: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-265: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-266: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-267: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-268: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-269: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-272: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-273: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-274: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-275: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-277: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-279: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-280: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-282: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 2-283: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-284: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-286: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-287: Loss: 0.0096 Acc: 86.6667%\n",
      "\ttrain 2-288: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-289: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-290: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-291: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-292: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-293: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-294: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 2-295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-296: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-297: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-299: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-300: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-302: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-303: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-304: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-306: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-307: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 2-308: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-309: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-310: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-311: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-312: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-314: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-315: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-316: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-317: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-318: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-319: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-320: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-321: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-322: Loss: 0.0101 Acc: 93.3333%\n",
      "\ttrain 2-323: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-324: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-325: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-326: Loss: 0.0102 Acc: 96.6667%\n",
      "\ttrain 2-327: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-328: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-329: Loss: 0.0086 Acc: 96.6667%\n",
      "\ttrain 2-330: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-331: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-332: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-334: Loss: 0.0080 Acc: 90.0000%\n",
      "\ttrain 2-335: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-336: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 2-337: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-338: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-340: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-341: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-342: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-343: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-344: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-345: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-346: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-347: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-348: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-349: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-350: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 2-351: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-352: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-353: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 2-354: Loss: 0.0068 Acc: 90.0000%\n",
      "\ttrain 2-355: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-356: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-357: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-358: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-359: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-360: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-361: Loss: 0.0119 Acc: 93.3333%\n",
      "\ttrain 2-362: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-363: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-364: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-365: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-366: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-367: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-368: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-370: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-371: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-372: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-373: Loss: 0.0166 Acc: 90.0000%\n",
      "\ttrain 2-374: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-375: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 2-376: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-377: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-378: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-380: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-381: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-382: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-383: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 2-384: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 2-385: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-386: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-387: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-388: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-389: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-390: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-391: Loss: 0.0049 Acc: 90.0000%\n",
      "\ttrain 2-392: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-393: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-394: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-395: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-396: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-397: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-398: Loss: 0.0109 Acc: 93.3333%\n",
      "\ttrain 2-399: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-400: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-401: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-402: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-403: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-404: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-405: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-406: Loss: 0.0121 Acc: 90.0000%\n",
      "\ttrain 2-407: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-408: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-409: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-410: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-411: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-412: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-413: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-414: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-415: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-416: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-417: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-418: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-419: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-420: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 2-421: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 2-422: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-425: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-426: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-427: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 2-428: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-429: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-430: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-431: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-432: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-433: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-434: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-435: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-436: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-437: Loss: 0.0086 Acc: 93.3333%\n",
      "\ttrain 2-438: Loss: 0.0139 Acc: 90.0000%\n",
      "\ttrain 2-439: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-440: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-441: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-442: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-443: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-444: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-445: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-446: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-447: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-449: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-450: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 2-451: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-452: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-453: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-454: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-455: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-456: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-457: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-458: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 2-459: Loss: 0.0131 Acc: 90.0000%\n",
      "\ttrain 2-460: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-461: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-462: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-463: Loss: 0.0098 Acc: 96.6667%\n",
      "\ttrain 2-464: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-465: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-466: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-467: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-468: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-469: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 2-470: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-471: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-472: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-473: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-474: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-475: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-476: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-477: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-478: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-479: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-480: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-481: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-482: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-483: Loss: 0.0112 Acc: 86.6667%\n",
      "\ttrain 2-484: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-485: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-486: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-487: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-488: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-489: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-490: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-491: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-494: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-495: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-496: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-497: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-500: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-501: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-502: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-503: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-504: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-505: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-506: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-507: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-508: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-510: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-511: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-512: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-513: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-514: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-515: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-518: Loss: 0.0015 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-519: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-521: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-522: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-523: Loss: 0.0033 Acc: 100.0000%\n",
      "\ttrain 2-524: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-525: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-526: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-527: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-528: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 2-529: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-530: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-531: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-532: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-533: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-534: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-535: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-536: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-537: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-538: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-539: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-541: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 2-542: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-543: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-544: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-545: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-546: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-547: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-548: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-549: Loss: 0.0025 Acc: 93.3333%\n",
      "\ttrain 2-550: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-551: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-552: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-553: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 2-554: Loss: 0.0106 Acc: 93.3333%\n",
      "\ttrain 2-555: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-556: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-557: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-558: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-559: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-560: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-561: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-562: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-563: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-564: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 2-565: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-566: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-567: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-568: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-569: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-570: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-571: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-572: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-573: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-574: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-575: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-576: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-578: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-579: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-580: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-581: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-582: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-584: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-585: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-586: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-587: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-588: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-589: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-590: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-591: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-593: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-595: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-597: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-598: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-600: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-601: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-602: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-603: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-607: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-608: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-609: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-610: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-612: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-613: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-614: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-615: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-616: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-617: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-618: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-619: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-620: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-622: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-624: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-628: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-629: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-631: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-632: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-633: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-634: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-635: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-636: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-637: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-639: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-640: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-641: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-642: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-643: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-644: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-645: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-646: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-647: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-648: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-649: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-651: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-652: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-653: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-656: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-657: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-658: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-659: Loss: 0.0038 Acc: 93.3333%\n",
      "\ttrain 2-660: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-661: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-662: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-663: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 2-664: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-665: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-666: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-667: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-668: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-669: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-671: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-672: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-673: Loss: 0.0115 Acc: 96.6667%\n",
      "\ttrain 2-674: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 2-675: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-676: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-677: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-678: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-679: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-680: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-681: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-682: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-683: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-684: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-685: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-686: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-687: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-688: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-689: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-690: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-691: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-692: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-693: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-694: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-695: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-696: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-697: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-698: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-699: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-700: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-701: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-702: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 2-703: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-704: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-705: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-706: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-707: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-708: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-710: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-711: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-712: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-713: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-714: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-715: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-716: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-717: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-718: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-719: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-721: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-722: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-723: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-724: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-725: Loss: 0.0088 Acc: 96.6667%\n",
      "\ttrain 2-726: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-727: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-728: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-729: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-730: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-731: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-733: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-734: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-735: Loss: 0.0024 Acc: 93.3333%\n",
      "\ttrain 2-736: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-737: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-738: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-739: Loss: 0.0158 Acc: 96.6667%\n",
      "\ttrain 2-740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-741: Loss: 0.0079 Acc: 96.6667%\n",
      "\ttrain 2-742: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-743: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-744: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-745: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-746: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-747: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-748: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-749: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-750: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-751: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-752: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-753: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-754: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-755: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-756: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 2-757: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-758: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-759: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-760: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-761: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-762: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 2-763: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-764: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-765: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-766: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-767: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-768: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-769: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-770: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-771: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-772: Loss: 0.0017 Acc: 93.3333%\n",
      "\ttrain 2-773: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 2-774: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-775: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-776: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-777: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-778: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-780: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-783: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-784: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-785: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-788: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-789: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-790: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-791: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-792: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-794: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-795: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-796: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-797: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-798: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-799: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-800: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-801: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-802: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-803: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 2-804: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-806: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-807: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-809: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 2-810: Loss: 0.0101 Acc: 96.6667%\n",
      "\ttrain 2-811: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-812: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-813: Loss: 0.0083 Acc: 93.3333%\n",
      "\ttrain 2-814: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-815: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-816: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-817: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-818: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-819: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-820: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-821: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-822: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-823: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-824: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-825: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-826: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-827: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-828: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-829: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 2-830: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-831: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-832: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-833: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-834: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-835: Loss: 0.0056 Acc: 90.0000%\n",
      "\ttrain 2-836: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-838: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-839: Loss: 0.0109 Acc: 96.6667%\n",
      "\ttrain 2-840: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-841: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 2-842: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-843: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-844: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-845: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-846: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-847: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-848: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-849: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-850: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-851: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-852: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-853: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-854: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 2-855: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-856: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-857: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-858: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-859: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 2-860: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-861: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-862: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-863: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-864: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-865: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-866: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-867: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-868: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-869: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-870: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-871: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-872: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-873: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-874: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-876: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-877: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-878: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-879: Loss: 0.0130 Acc: 96.6667%\n",
      "\ttrain 2-880: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-881: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-882: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-883: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-884: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-885: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-886: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-887: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-888: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-889: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-890: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-891: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-892: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-893: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-894: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 2-895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-896: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-897: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-898: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-899: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-900: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-901: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-903: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-904: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-905: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-906: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-907: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-908: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-910: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-911: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-912: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-914: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-915: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-916: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-917: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-918: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-921: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-923: Loss: 0.0130 Acc: 86.6667%\n",
      "\ttrain 2-924: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-926: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-927: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-928: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-929: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-930: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 2-931: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-932: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-933: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 2-934: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-935: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-936: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-937: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-938: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-939: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-940: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-942: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-943: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-944: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-945: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-946: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-947: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-948: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-949: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-950: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-951: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-952: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 2-953: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-954: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-955: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-956: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-957: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-958: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-959: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-960: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-961: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-962: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-964: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-965: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-966: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-968: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-969: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-970: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-972: Loss: 0.0073 Acc: 93.3333%\n",
      "\ttrain 2-973: Loss: 0.0087 Acc: 96.6667%\n",
      "\ttrain 2-974: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-977: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-978: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-979: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-980: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-981: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-982: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-983: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-984: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-985: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-986: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 2-987: Loss: 0.0026 Acc: 93.3333%\n",
      "\ttrain 2-988: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-989: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 2-990: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-991: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-992: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-993: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-994: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-995: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-996: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-998: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-999: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-1000: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1001: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1002: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1003: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1004: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1005: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-1006: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1007: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 2-1008: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1009: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1010: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1011: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-1012: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1013: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1014: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-1015: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1017: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1018: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1019: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1020: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1021: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-1022: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1023: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1024: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1025: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1026: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1027: Loss: 0.0150 Acc: 96.6667%\n",
      "\ttrain 2-1028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1029: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1030: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1031: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1032: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1033: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1034: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1035: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1036: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1037: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1038: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1039: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1040: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 2-1041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1042: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1044: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1045: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-1046: Loss: 0.0063 Acc: 93.3333%\n",
      "\ttrain 2-1047: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1048: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1049: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-1050: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1051: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1052: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1053: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1054: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1055: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-1056: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-1057: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1058: Loss: 0.0102 Acc: 90.0000%\n",
      "\ttrain 2-1059: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1060: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-1061: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1062: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1063: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-1064: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-1065: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1066: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-1067: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-1068: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1069: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 2-1070: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1072: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1073: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1074: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1075: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1076: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1077: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1078: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1080: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1082: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1083: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1084: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1085: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1086: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1087: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1088: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1089: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1090: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 2-1091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1092: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1093: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1094: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1095: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1096: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 2-1097: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1098: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1099: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1100: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1102: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1104: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-1105: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1106: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-1107: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-1108: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-1109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1110: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1114: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1115: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1117: Loss: 0.0043 Acc: 90.0000%\n",
      "\ttrain 2-1118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1119: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1120: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-1121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1122: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1125: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1127: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1128: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1129: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1130: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1131: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-1132: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-1133: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1134: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 2-1135: Loss: 0.0099 Acc: 93.3333%\n",
      "\ttrain 2-1136: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1138: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-1139: Loss: 0.0082 Acc: 90.0000%\n",
      "\ttrain 2-1140: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1141: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1142: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1143: Loss: 0.0087 Acc: 90.0000%\n",
      "\ttrain 2-1144: Loss: 0.0103 Acc: 90.0000%\n",
      "\ttrain 2-1145: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1146: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1148: Loss: 0.0051 Acc: 93.3333%\n",
      "\ttrain 2-1149: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1150: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1152: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1153: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 2-1154: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 2-1155: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-1156: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-1157: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-1158: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-1159: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1160: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1161: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1162: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1163: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 2-1164: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-1165: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1167: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1168: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1169: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1170: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1171: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1172: Loss: 0.0095 Acc: 96.6667%\n",
      "\ttrain 2-1173: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1174: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1175: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1176: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1177: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1178: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1179: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 2-1180: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1181: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1182: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1183: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1184: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1185: Loss: 0.0109 Acc: 96.6667%\n",
      "\ttrain 2-1186: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1187: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1188: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1189: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1190: Loss: 0.0080 Acc: 93.3333%\n",
      "\ttrain 2-1191: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 2-1192: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1193: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1194: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1195: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1196: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1197: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1198: Loss: 0.0024 Acc: 93.3333%\n",
      "\ttrain 2-1199: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1200: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1201: Loss: 0.0149 Acc: 90.0000%\n",
      "\ttrain 2-1202: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-1203: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-1204: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-1205: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1206: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1207: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-1208: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1209: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1210: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1211: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-1212: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-1213: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-1214: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1215: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-1216: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1217: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1218: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 2-1219: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1220: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 2-1221: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1222: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1223: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1224: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1225: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1226: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1227: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1230: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1231: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-1232: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1233: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1235: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-1236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1237: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1238: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1239: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1240: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1241: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1243: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1244: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1245: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-1246: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1247: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1249: Loss: 0.0080 Acc: 96.6667%\n",
      "\ttrain 2-1250: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1251: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-1252: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1253: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1254: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1255: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1256: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1258: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-1259: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1260: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1261: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-1262: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1263: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1264: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1265: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1266: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1267: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1268: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1269: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1270: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1271: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-1272: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1273: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1274: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1276: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1277: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1278: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1279: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-1280: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1283: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-1284: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1285: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1287: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1289: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1290: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1291: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1293: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1294: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1295: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-1296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1297: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1299: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-1300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1301: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1302: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1303: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1304: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1305: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1307: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1308: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1310: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1311: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1312: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1313: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 2-1314: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1316: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1317: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-1318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1319: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1320: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1321: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1324: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1330: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1331: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1332: Loss: 0.0071 Acc: 96.6667%\n",
      "\ttrain 2-1333: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1336: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1338: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1341: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-1342: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1344: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1345: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1346: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1348: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 2-1349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1354: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-1355: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1356: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1357: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1358: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-1359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1360: Loss: 0.0097 Acc: 96.6667%\n",
      "\ttrain 2-1361: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1362: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1364: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1366: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-1367: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1368: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1369: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1370: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1371: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1372: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-1373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1374: Loss: 0.0030 Acc: 93.3333%\n",
      "\ttrain 2-1375: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1376: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1377: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1378: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-1379: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1380: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-1381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1382: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1383: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-1384: Loss: 0.0146 Acc: 93.3333%\n",
      "\ttrain 2-1385: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1386: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1388: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1390: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1391: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-1392: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1393: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1394: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1395: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1396: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1397: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-1398: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1399: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1400: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1401: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-1402: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1403: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1405: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1406: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1407: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1408: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-1409: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 2-1410: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1411: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 2-1412: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1413: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-1414: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-1415: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1417: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1418: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1419: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1421: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-1422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1423: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 2-1424: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1425: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1426: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 2-1427: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1429: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1430: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1432: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1433: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1437: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-1438: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1439: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-1440: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1441: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1442: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-1443: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 2-1444: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1446: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1447: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1448: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1449: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1451: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-1452: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1453: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1454: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-1455: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1458: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-1459: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 2-1460: Loss: 0.0071 Acc: 93.3333%\n",
      "\ttrain 2-1461: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1462: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1463: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1464: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-1465: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-1466: Loss: 0.0240 Acc: 90.0000%\n",
      "\ttrain 2-1467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1468: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-1469: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1470: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1471: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1472: Loss: 0.0106 Acc: 93.3333%\n",
      "\ttrain 2-1473: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1474: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1475: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1476: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-1477: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 2-1478: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1479: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1480: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1481: Loss: 0.0069 Acc: 90.0000%\n",
      "\ttrain 2-1482: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-1483: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1484: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1485: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1486: Loss: 0.0071 Acc: 96.6667%\n",
      "\ttrain 2-1487: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1488: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1489: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-1490: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1491: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-1492: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1493: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1494: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1495: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1496: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1497: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-1498: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1499: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1500: Loss: 0.0093 Acc: 96.6667%\n",
      "\ttrain 2-1501: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1502: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1503: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1504: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1505: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1506: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1507: Loss: 0.0150 Acc: 86.6667%\n",
      "\ttrain 2-1508: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 2-1509: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1510: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1511: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1512: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1513: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1514: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1515: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1516: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1517: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1518: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1519: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1520: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1521: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1522: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-1523: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1524: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1525: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1526: Loss: 0.0029 Acc: 93.3333%\n",
      "\ttrain 2-1527: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1528: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1529: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1530: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1531: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-1532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1533: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1534: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1535: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1536: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-1537: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1538: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1539: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1540: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-1541: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1542: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1543: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1545: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-1546: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-1547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1549: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1550: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1551: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1552: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1553: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1554: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1555: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1556: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-1557: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1558: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1559: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1560: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1561: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1562: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1563: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1565: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1566: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1567: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1569: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1570: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1572: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 2-1573: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1574: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1575: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1576: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1578: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1579: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-1580: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1581: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1582: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1583: Loss: 0.0074 Acc: 93.3333%\n",
      "\ttrain 2-1584: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1585: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1587: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1588: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-1589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1590: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-1591: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-1592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1593: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1594: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1595: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-1596: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1597: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1598: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1599: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1600: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1601: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1602: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1603: Loss: 0.0156 Acc: 90.0000%\n",
      "\ttrain 2-1604: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-1605: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-1606: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-1607: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-1608: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-1609: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1610: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1611: Loss: 0.0173 Acc: 86.6667%\n",
      "\ttrain 2-1612: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-1613: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-1614: Loss: 0.0087 Acc: 96.6667%\n",
      "\ttrain 2-1615: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1616: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1617: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1618: Loss: 0.0066 Acc: 90.0000%\n",
      "\ttrain 2-1619: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1620: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 2-1621: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1622: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-1623: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-1624: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1625: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1626: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1627: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1628: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1629: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1630: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 2-1631: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1632: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1633: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1634: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1635: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1636: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1637: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 2-1638: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1639: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 2-1640: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1641: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1642: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 2-1643: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-1644: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1645: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-1646: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1647: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1648: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1649: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1650: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1651: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 2-1652: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1653: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1654: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1655: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1656: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1657: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1658: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1659: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1660: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1661: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1662: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1663: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1664: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1665: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1666: Loss: 0.0108 Acc: 90.0000%\n",
      "\ttrain 2-1667: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1668: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-1669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1670: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1671: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-1672: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 2-1673: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1674: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1675: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1676: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1678: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1679: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1680: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1681: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1682: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1683: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1684: Loss: 0.0003 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-1685: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1686: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1687: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1688: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1689: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-1690: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 2-1691: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1692: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 2-1693: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1694: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1695: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1696: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1697: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-1698: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1699: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1700: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1701: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1702: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1704: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1705: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1706: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1707: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1708: Loss: 0.0032 Acc: 93.3333%\n",
      "\ttrain 2-1709: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 2-1710: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1711: Loss: 0.0157 Acc: 90.0000%\n",
      "\ttrain 2-1712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1713: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1714: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-1715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1716: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1717: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1718: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1719: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-1720: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1721: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1722: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1723: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1724: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1725: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1727: Loss: 0.0080 Acc: 96.6667%\n",
      "\ttrain 2-1728: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1729: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1730: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-1731: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-1732: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-1733: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1734: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1735: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1736: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1737: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1738: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1739: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1741: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1742: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1743: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-1744: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1745: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-1746: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-1747: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-1748: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1749: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1750: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1751: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 2-1752: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1753: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1754: Loss: 0.0070 Acc: 90.0000%\n",
      "\ttrain 2-1755: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1756: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1757: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-1758: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1759: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1761: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1762: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1763: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1764: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1765: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1766: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1767: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 2-1768: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1769: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1770: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1771: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-1772: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-1773: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1775: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1776: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-1777: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 2-1778: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-1779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1780: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1783: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1784: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1785: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-1786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1787: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 2-1788: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1789: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1790: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1791: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1792: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1793: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1794: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1795: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1797: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1798: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1799: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1800: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1801: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-1802: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-1803: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1804: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1805: Loss: 0.0085 Acc: 93.3333%\n",
      "\ttrain 2-1806: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-1807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1808: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1809: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1810: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 2-1811: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 2-1812: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-1813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1815: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1816: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1817: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1818: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1819: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1820: Loss: 0.0085 Acc: 96.6667%\n",
      "\ttrain 2-1821: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1822: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1823: Loss: 0.0095 Acc: 93.3333%\n",
      "\ttrain 2-1824: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-1825: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1826: Loss: 0.0093 Acc: 93.3333%\n",
      "\ttrain 2-1827: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-1828: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1829: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1830: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1831: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1832: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1833: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1834: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 2-1835: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1836: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-1837: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-1838: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1839: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1840: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-1841: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-1842: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1843: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1844: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1845: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1846: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1847: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1848: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1849: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1850: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-1851: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-1852: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1853: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1855: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-1856: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1857: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1858: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-1859: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1860: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1861: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1862: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1864: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1865: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1866: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-1867: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1868: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1869: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1870: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-1871: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1872: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1873: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1874: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1876: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-1877: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1878: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1879: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1880: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1881: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1882: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1885: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1886: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1887: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1888: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1889: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1890: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1891: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1892: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1893: Loss: 0.0075 Acc: 96.6667%\n",
      "\ttrain 2-1894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1895: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1896: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-1897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1898: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1900: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1902: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-1903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1905: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-1906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1907: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1908: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1909: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-1910: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1911: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1912: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1914: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1915: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-1916: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1917: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1918: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1919: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1920: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1921: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1923: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-1924: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1926: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1927: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1928: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1929: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1930: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1931: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1932: Loss: 0.0117 Acc: 96.6667%\n",
      "\ttrain 2-1933: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1934: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1935: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1937: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-1938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1939: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1940: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1941: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-1942: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1943: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1944: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1945: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1946: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1947: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1948: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1949: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-1950: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-1951: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1952: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 2-1953: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1954: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1955: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1956: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-1957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1958: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-1959: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-1960: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1961: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1962: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1964: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1965: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-1966: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1968: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 2-1969: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1970: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 2-1971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1973: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1976: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-1977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1978: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1979: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1982: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-1983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1984: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-1985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1986: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-1987: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1988: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-1989: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1990: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-1991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1992: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1994: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1995: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-1996: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-1997: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-1998: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-1999: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2000: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2001: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2002: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 2-2003: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2004: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2005: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2006: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2008: Loss: 0.0070 Acc: 96.6667%\n",
      "\ttrain 2-2009: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2010: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2011: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2012: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2013: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2014: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2015: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2016: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2017: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2018: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2019: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2020: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2022: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-2023: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2024: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-2025: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2027: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2028: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2029: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-2030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2031: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-2032: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2033: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-2034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2035: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2036: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-2037: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2038: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2039: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2040: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2041: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2042: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2043: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-2044: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2045: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2046: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2047: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2048: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2051: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2052: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2053: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2054: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2055: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2056: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2057: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-2058: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2059: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2060: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2062: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-2063: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2065: Loss: 0.0020 Acc: 93.3333%\n",
      "\ttrain 2-2066: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-2067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2068: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-2069: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2070: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2071: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2072: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-2073: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-2074: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2075: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2076: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-2077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2078: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2080: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-2081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2082: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-2083: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2084: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 2-2085: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2087: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2089: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-2090: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2091: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-2092: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2093: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-2094: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2095: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2096: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2097: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2098: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2099: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2100: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-2101: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2104: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-2105: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-2106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2107: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2108: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-2109: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-2110: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2111: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2112: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2113: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2114: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2115: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-2116: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2118: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2120: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2122: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2123: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2124: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2125: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2129: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2130: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2131: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2135: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2136: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2137: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2138: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2140: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2143: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2144: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-2145: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2146: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2147: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2148: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-2149: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-2150: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2151: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2152: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2153: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-2154: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-2155: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2156: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2157: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2159: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2161: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2162: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2163: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-2164: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-2165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2169: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2170: Loss: 0.0116 Acc: 96.6667%\n",
      "\ttrain 2-2171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2173: Loss: 0.0149 Acc: 96.6667%\n",
      "\ttrain 2-2174: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2175: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-2176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2177: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2178: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2179: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2180: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2181: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2185: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2186: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2187: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2188: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2189: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2190: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2192: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 2-2193: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-2194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2197: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2199: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-2200: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2201: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2202: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2203: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2205: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 2-2206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2207: Loss: 0.0087 Acc: 96.6667%\n",
      "\ttrain 2-2208: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-2209: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2210: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-2211: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2212: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-2213: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-2214: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-2215: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2216: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2218: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2219: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2221: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2222: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 2-2223: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2224: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2225: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 2-2226: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-2227: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2228: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2229: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2230: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2231: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2233: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2234: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-2235: Loss: 0.0117 Acc: 90.0000%\n",
      "\ttrain 2-2236: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2239: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2240: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2242: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2244: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2245: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2246: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2247: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2249: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2251: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-2252: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2253: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2254: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 2-2255: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2256: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-2257: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-2258: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-2259: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2260: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-2261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2263: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-2264: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2265: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2267: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2269: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2271: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2272: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2273: Loss: 0.0336 Acc: 96.6667%\n",
      "\ttrain 2-2274: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2276: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2277: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2278: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2280: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-2281: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2282: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 2-2283: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2284: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-2285: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2286: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2287: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2288: Loss: 0.0091 Acc: 93.3333%\n",
      "\ttrain 2-2289: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2290: Loss: 0.0108 Acc: 90.0000%\n",
      "\ttrain 2-2291: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2292: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 2-2293: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-2294: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-2295: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2296: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2297: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2299: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2300: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2301: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2302: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2303: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-2304: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2305: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-2306: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-2307: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2308: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2309: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2310: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2311: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-2312: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 2-2313: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2314: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-2315: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2316: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2317: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2318: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-2319: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2320: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2321: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2322: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-2323: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2324: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2325: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2326: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2327: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 2-2328: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2329: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2330: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2331: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2332: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2333: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2334: Loss: 0.0060 Acc: 93.3333%\n",
      "\ttrain 2-2335: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2336: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2337: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2338: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2339: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2340: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2341: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2342: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2343: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2344: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2346: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-2347: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2348: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2349: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2350: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2351: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2354: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2355: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2356: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2357: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 2-2358: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2360: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2361: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2363: Loss: 0.0118 Acc: 93.3333%\n",
      "\ttrain 2-2364: Loss: 0.0048 Acc: 93.3333%\n",
      "\ttrain 2-2365: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-2366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2367: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2368: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2370: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2371: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2373: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-2374: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2375: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2376: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2377: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2378: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2379: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2380: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2381: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2382: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2384: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 2-2385: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2386: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2388: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2389: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2391: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2393: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2395: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2396: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-2397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2398: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2399: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2402: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2403: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2404: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2405: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-2406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2408: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2409: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2410: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2412: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2413: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 2-2414: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2415: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2417: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2418: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2420: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2421: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2424: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2425: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2426: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2429: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2430: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2431: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2432: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2433: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2434: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2435: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2436: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2437: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-2438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2439: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2440: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2441: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2442: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2443: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2446: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2448: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2449: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2452: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-2453: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-2454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2455: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2456: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2457: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2458: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-2459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2461: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2462: Loss: 0.0024 Acc: 93.3333%\n",
      "\ttrain 2-2463: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2464: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2465: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2466: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2467: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2468: Loss: 0.0104 Acc: 96.6667%\n",
      "\ttrain 2-2469: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2471: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2472: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-2473: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2475: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2476: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2477: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-2478: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2480: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2481: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2482: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2483: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-2484: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2486: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2487: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-2488: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2489: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2490: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-2491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2494: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2495: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2497: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2500: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2501: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2502: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2503: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-2504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2505: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2506: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2507: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2508: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2509: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2510: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-2511: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2512: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2513: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 2-2514: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-2515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2518: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-2519: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2521: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2522: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2523: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2524: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2525: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-2526: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2527: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2528: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2529: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-2530: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-2531: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2532: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2533: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2534: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2536: Loss: 0.0084 Acc: 93.3333%\n",
      "\ttrain 2-2537: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-2538: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2539: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2541: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-2542: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2543: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2544: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-2545: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-2546: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2547: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-2548: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2549: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2550: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2551: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2552: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2553: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2554: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 2-2555: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-2556: Loss: 0.0053 Acc: 93.3333%\n",
      "\ttrain 2-2557: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2558: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 2-2559: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2560: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2561: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2562: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2563: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2566: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-2567: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2568: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2569: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2570: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2571: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2572: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2573: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2574: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2575: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2576: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2577: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2578: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2581: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2582: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2583: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2584: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-2585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2587: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2588: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2589: Loss: 0.0076 Acc: 96.6667%\n",
      "\ttrain 2-2590: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-2591: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2592: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2593: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2596: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2597: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2598: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2600: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2601: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-2602: Loss: 0.0271 Acc: 93.3333%\n",
      "\ttrain 2-2603: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2604: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2605: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2607: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-2608: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2609: Loss: 0.0068 Acc: 93.3333%\n",
      "\ttrain 2-2610: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2611: Loss: 0.0070 Acc: 96.6667%\n",
      "\ttrain 2-2612: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-2613: Loss: 0.0093 Acc: 93.3333%\n",
      "\ttrain 2-2614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2615: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-2616: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-2617: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-2618: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-2619: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2620: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 2-2621: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-2622: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2623: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-2624: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2625: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-2626: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2627: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2628: Loss: 0.0099 Acc: 93.3333%\n",
      "\ttrain 2-2629: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-2630: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2631: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2632: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-2633: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-2634: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2635: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2636: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2637: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2638: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 2-2639: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2640: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2641: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2642: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2643: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-2644: Loss: 0.0028 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-2645: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2646: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2647: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2648: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2649: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2650: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2651: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-2652: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2653: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2654: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2655: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2656: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2657: Loss: 0.0103 Acc: 96.6667%\n",
      "\ttrain 2-2658: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2659: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-2660: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 2-2661: Loss: 0.0024 Acc: 93.3333%\n",
      "\ttrain 2-2662: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-2663: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2664: Loss: 0.0069 Acc: 96.6667%\n",
      "\ttrain 2-2665: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2666: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 2-2667: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-2668: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2669: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2671: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-2672: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2673: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2674: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-2675: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2676: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2677: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2678: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2679: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2680: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-2681: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2683: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-2684: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2686: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2687: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-2688: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2689: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2690: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2691: Loss: 0.0092 Acc: 93.3333%\n",
      "\ttrain 2-2692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2696: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2697: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2698: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2699: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2700: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2701: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2703: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-2704: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2705: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2706: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-2707: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2708: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-2709: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2710: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2711: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2713: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2714: Loss: 0.0133 Acc: 96.6667%\n",
      "\ttrain 2-2715: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-2716: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2717: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 2-2718: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2719: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2720: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2721: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2722: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2723: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 2-2724: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-2725: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2726: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2727: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-2728: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2729: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2730: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2731: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2732: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2733: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2734: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2735: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-2736: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2737: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2738: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2739: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2741: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2742: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-2743: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2744: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 2-2745: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-2746: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2747: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2748: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2749: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2750: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2751: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2752: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2753: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2754: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2755: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2756: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2757: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-2758: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-2759: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2760: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-2761: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2762: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2763: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2764: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2765: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-2766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2767: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2768: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2769: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 2-2770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2772: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2773: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2774: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-2775: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2776: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2777: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2778: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2779: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 2-2780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2781: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2782: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2783: Loss: 0.0137 Acc: 96.6667%\n",
      "\ttrain 2-2784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2785: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2786: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2787: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2788: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-2789: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2790: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2791: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2792: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-2793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2794: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 2-2795: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-2796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2797: Loss: 0.0111 Acc: 93.3333%\n",
      "\ttrain 2-2798: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2799: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-2800: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2801: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2802: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-2803: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2804: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2805: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2807: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2808: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2809: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2810: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-2811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2812: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2813: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2815: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2816: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-2817: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2818: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2819: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2820: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2821: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2822: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2823: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2824: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2825: Loss: 0.0047 Acc: 93.3333%\n",
      "\ttrain 2-2826: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2827: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-2828: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-2829: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2830: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-2831: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2832: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-2833: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2834: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2835: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 2-2836: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-2837: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2838: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2839: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-2840: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2841: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2842: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2843: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2844: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2846: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-2847: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2848: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2849: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2850: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2852: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-2853: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2854: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2855: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2856: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2857: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-2858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2859: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2860: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2861: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2862: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2864: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2865: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2866: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2867: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2868: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2870: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2872: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2873: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2874: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2875: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2878: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2879: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2880: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2881: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2882: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2883: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2885: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2886: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2887: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2888: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2889: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-2890: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2891: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2892: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 2-2893: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-2894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2895: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2896: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-2897: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-2898: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2902: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2903: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2904: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2905: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2906: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-2907: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2908: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-2909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2910: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-2911: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2914: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2915: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2916: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2917: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2918: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2919: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-2920: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2921: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-2922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2924: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2926: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2928: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2929: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2930: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2931: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-2932: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2933: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2934: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-2935: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2937: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2939: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-2940: Loss: 0.0044 Acc: 93.3333%\n",
      "\ttrain 2-2941: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 2-2942: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 2-2943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2944: Loss: 0.0105 Acc: 96.6667%\n",
      "\ttrain 2-2945: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2946: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2947: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2948: Loss: 0.0129 Acc: 90.0000%\n",
      "\ttrain 2-2949: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-2950: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2951: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 2-2952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-2953: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2954: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2955: Loss: 0.0036 Acc: 93.3333%\n",
      "\ttrain 2-2956: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-2957: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-2958: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-2959: Loss: 0.0095 Acc: 96.6667%\n",
      "\ttrain 2-2960: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2961: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2962: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-2963: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-2964: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-2965: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2966: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2967: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2968: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-2969: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2970: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-2971: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2972: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-2973: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-2974: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-2975: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 2-2976: Loss: 0.0085 Acc: 96.6667%\n",
      "\ttrain 2-2977: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2978: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-2979: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-2980: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-2981: Loss: 0.0103 Acc: 90.0000%\n",
      "\ttrain 2-2982: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2983: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-2984: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 2-2985: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2986: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 2-2987: Loss: 0.0096 Acc: 96.6667%\n",
      "\ttrain 2-2988: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-2989: Loss: 0.0089 Acc: 96.6667%\n",
      "\ttrain 2-2990: Loss: 0.0066 Acc: 93.3333%\n",
      "\ttrain 2-2991: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-2992: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-2993: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-2994: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 2-2995: Loss: 0.0041 Acc: 93.3333%\n",
      "\ttrain 2-2996: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-2997: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-2998: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-2999: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-3000: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3001: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-3002: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-3003: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3004: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-3005: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-3006: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3007: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3008: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3009: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-3010: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-3011: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3012: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3013: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-3014: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3015: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3016: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3017: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3018: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3019: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3020: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3021: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3022: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3023: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3024: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3026: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3028: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-3029: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3032: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-3033: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3034: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3035: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3036: Loss: 0.0027 Acc: 93.3333%\n",
      "\ttrain 2-3037: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3038: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3040: Loss: 0.0076 Acc: 93.3333%\n",
      "\ttrain 2-3041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3042: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3043: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-3044: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3045: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3046: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-3047: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3048: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3051: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 2-3052: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3053: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 2-3054: Loss: 0.0086 Acc: 96.6667%\n",
      "\ttrain 2-3055: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 2-3056: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-3057: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-3058: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3059: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-3060: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3061: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3062: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-3063: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-3064: Loss: 0.0046 Acc: 93.3333%\n",
      "\ttrain 2-3065: Loss: 0.0076 Acc: 96.6667%\n",
      "\ttrain 2-3066: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3068: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3069: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-3070: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-3071: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3072: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3073: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3074: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 2-3075: Loss: 0.0033 Acc: 93.3333%\n",
      "\ttrain 2-3076: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-3077: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3078: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 2-3079: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-3080: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3082: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3083: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3084: Loss: 0.0079 Acc: 93.3333%\n",
      "\ttrain 2-3085: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3086: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3087: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3088: Loss: 0.0020 Acc: 93.3333%\n",
      "\ttrain 2-3089: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3090: Loss: 0.0043 Acc: 93.3333%\n",
      "\ttrain 2-3091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3092: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-3093: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-3094: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-3095: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3096: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-3097: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3098: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3099: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3100: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3102: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3103: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3106: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3107: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3109: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3110: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3112: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3114: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3115: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3116: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3117: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3120: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3123: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3130: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3131: Loss: 0.0070 Acc: 96.6667%\n",
      "\ttrain 2-3132: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-3133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3135: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3136: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3137: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3138: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-3139: Loss: 0.0108 Acc: 93.3333%\n",
      "\ttrain 2-3140: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3141: Loss: 0.0267 Acc: 93.3333%\n",
      "\ttrain 2-3142: Loss: 0.0034 Acc: 93.3333%\n",
      "\ttrain 2-3143: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3144: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-3145: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3146: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-3147: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3148: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 2-3149: Loss: 0.0081 Acc: 93.3333%\n",
      "\ttrain 2-3150: Loss: 0.0107 Acc: 93.3333%\n",
      "\ttrain 2-3151: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3152: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3153: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-3154: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3155: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3156: Loss: 0.0139 Acc: 90.0000%\n",
      "\ttrain 2-3157: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3158: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3159: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3160: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3161: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-3162: Loss: 0.0092 Acc: 90.0000%\n",
      "\ttrain 2-3163: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3164: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3166: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3167: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-3168: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3169: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-3170: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-3171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3172: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3173: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3174: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3175: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-3176: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3177: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-3178: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3179: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3180: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3181: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3182: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3183: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3184: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3185: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3186: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-3187: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3188: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3189: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3190: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3191: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3192: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3193: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3194: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3195: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3197: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3198: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3199: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3200: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-3201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3203: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3205: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3206: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-3207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3211: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3212: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-3213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3214: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3215: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3216: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3217: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3218: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3220: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3221: Loss: 0.0032 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-3222: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3223: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3224: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3227: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3228: Loss: 0.0166 Acc: 96.6667%\n",
      "\ttrain 2-3229: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3230: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3231: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3232: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-3233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3235: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3236: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3237: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3239: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3240: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3241: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3242: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3243: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3244: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 2-3245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3247: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-3248: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3249: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3250: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3251: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-3252: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3253: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-3254: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3255: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3257: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3258: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3259: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3260: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3261: Loss: 0.0203 Acc: 93.3333%\n",
      "\ttrain 2-3262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3263: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3265: Loss: 0.0055 Acc: 93.3333%\n",
      "\ttrain 2-3266: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3267: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3268: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3269: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3270: Loss: 0.0103 Acc: 90.0000%\n",
      "\ttrain 2-3271: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 2-3272: Loss: 0.0095 Acc: 90.0000%\n",
      "\ttrain 2-3273: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3274: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3275: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3276: Loss: 0.0079 Acc: 96.6667%\n",
      "\ttrain 2-3277: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3278: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3279: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-3280: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 2-3281: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 2-3282: Loss: 0.0055 Acc: 90.0000%\n",
      "\ttrain 2-3283: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-3284: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3285: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-3286: Loss: 0.0224 Acc: 96.6667%\n",
      "\ttrain 2-3287: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3288: Loss: 0.0169 Acc: 93.3333%\n",
      "\ttrain 2-3289: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3290: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 2-3291: Loss: 0.0075 Acc: 93.3333%\n",
      "\ttrain 2-3292: Loss: 0.0108 Acc: 93.3333%\n",
      "\ttrain 2-3293: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-3294: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3295: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3296: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3297: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3298: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 2-3299: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-3300: Loss: 0.0083 Acc: 96.6667%\n",
      "\ttrain 2-3301: Loss: 0.0117 Acc: 83.3333%\n",
      "\ttrain 2-3302: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3303: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 2-3304: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3305: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3306: Loss: 0.0062 Acc: 93.3333%\n",
      "\ttrain 2-3307: Loss: 0.0088 Acc: 93.3333%\n",
      "\ttrain 2-3308: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-3309: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3310: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3311: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3312: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 2-3313: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-3314: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-3315: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-3316: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3317: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3318: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3319: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3321: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3322: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3323: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3324: Loss: 0.0136 Acc: 96.6667%\n",
      "\ttrain 2-3325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3326: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3327: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-3328: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3329: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3330: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3331: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3332: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3333: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-3334: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-3335: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3336: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3338: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3339: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3340: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3342: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3344: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3346: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-3347: Loss: 0.0087 Acc: 96.6667%\n",
      "\ttrain 2-3348: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3349: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3351: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3352: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3353: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3354: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3355: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3356: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3358: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3360: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3361: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3363: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3364: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-3365: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3366: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3367: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-3368: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3370: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 2-3371: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3373: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3374: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3376: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3377: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-3378: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3379: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3381: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3382: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-3383: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3384: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3385: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-3386: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3387: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3391: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3393: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 2-3394: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3395: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3396: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3399: Loss: 0.0082 Acc: 93.3333%\n",
      "\ttrain 2-3400: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 2-3401: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3402: Loss: 0.0056 Acc: 93.3333%\n",
      "\ttrain 2-3403: Loss: 0.0065 Acc: 93.3333%\n",
      "\ttrain 2-3404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3405: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3406: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-3407: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3408: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3409: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3410: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3411: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3412: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-3413: Loss: 0.0004 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-3414: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3415: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3416: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3417: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3418: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3419: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3420: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-3421: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-3422: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3423: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-3424: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3425: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3426: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3427: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3428: Loss: 0.0042 Acc: 93.3333%\n",
      "\ttrain 2-3429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3430: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-3431: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-3432: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3434: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3435: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3437: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3439: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3440: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3442: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3443: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3445: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3446: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-3447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3449: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3451: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3452: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3453: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3455: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3456: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3458: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-3459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3465: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3466: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3469: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3471: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-3472: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3475: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3477: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3478: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3479: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 2-3480: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3481: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3482: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-3483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3484: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3486: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-3487: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3488: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3489: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3490: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-3491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3492: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3494: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-3495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3496: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-3497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3498: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-3499: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3500: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3501: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3502: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3505: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3507: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3508: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-3509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3510: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3511: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-3512: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-3513: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3514: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3517: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-3518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3519: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-3520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3521: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-3522: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3523: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-3524: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3526: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3527: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-3528: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3529: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3530: Loss: 0.0077 Acc: 96.6667%\n",
      "\ttrain 2-3531: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 2-3532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3533: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3534: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3535: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3536: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3537: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3538: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3539: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3540: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3541: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3542: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-3543: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3544: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-3545: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3546: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3549: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-3550: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3551: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3552: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3553: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3554: Loss: 0.0089 Acc: 96.6667%\n",
      "\ttrain 2-3555: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3556: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3557: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3558: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-3559: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3560: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3561: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3562: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3563: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-3564: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3566: Loss: 0.0054 Acc: 93.3333%\n",
      "\ttrain 2-3567: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3568: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3569: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3570: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-3571: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3572: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 2-3573: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3574: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 2-3575: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-3576: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3578: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3581: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3582: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-3583: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3584: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3586: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3587: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3588: Loss: 0.0031 Acc: 93.3333%\n",
      "\ttrain 2-3589: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 2-3590: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3591: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-3592: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3593: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3596: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3597: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3598: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 2-3599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3600: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3603: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3604: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3605: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-3606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3607: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3609: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3610: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3611: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-3612: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3613: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3615: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3616: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3617: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-3618: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3619: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-3620: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-3621: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3622: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3624: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3627: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3628: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3629: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3631: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3632: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-3633: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3634: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3635: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3636: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-3637: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3639: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 2-3640: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3641: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3642: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3643: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3644: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3645: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3646: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3648: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3649: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3650: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3651: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3652: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-3653: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3654: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3656: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3657: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3658: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3660: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-3661: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3663: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-3664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3665: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3666: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3667: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3668: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3669: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3670: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3671: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3672: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3673: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3674: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3675: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3678: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-3679: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3680: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-3681: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3684: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-3685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3686: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3687: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3688: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3689: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3690: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3691: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3694: Loss: 0.0096 Acc: 90.0000%\n",
      "\ttrain 2-3695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3696: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3697: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3698: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3699: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3700: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-3701: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3702: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-3703: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3704: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3705: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3706: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3707: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3708: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3710: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3711: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3712: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-3713: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3714: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-3715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3716: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3717: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3718: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3719: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3721: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3722: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-3723: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3724: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3725: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-3726: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3727: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3728: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3730: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3731: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3733: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3734: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3735: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3736: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3737: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3738: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3739: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3740: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3741: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3742: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3743: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3744: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3745: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-3746: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3747: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3748: Loss: 0.0058 Acc: 93.3333%\n",
      "\ttrain 2-3749: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3750: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3751: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3752: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3753: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3754: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3755: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3756: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-3757: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3758: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3759: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3761: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3762: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3763: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3764: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3765: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3766: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3767: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3768: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-3769: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3770: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3772: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-3773: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3775: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3777: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-3778: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-3779: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-3780: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3781: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3782: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3783: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3785: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-3786: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3787: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3788: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-3789: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3790: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3793: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3794: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 2-3795: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3797: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-3798: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3799: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3800: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3801: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3802: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3804: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3805: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-3806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3809: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3810: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-3811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3812: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-3813: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3815: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-3816: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-3817: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3818: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3819: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-3820: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-3821: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3822: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3823: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3824: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3825: Loss: 0.0023 Acc: 93.3333%\n",
      "\ttrain 2-3826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3827: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3829: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3830: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3831: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3832: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3833: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3834: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-3835: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3836: Loss: 0.0087 Acc: 93.3333%\n",
      "\ttrain 2-3837: Loss: 0.0158 Acc: 96.6667%\n",
      "\ttrain 2-3838: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3839: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3840: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3841: Loss: 0.0071 Acc: 93.3333%\n",
      "\ttrain 2-3842: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3843: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3844: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-3845: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3846: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-3847: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3848: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3849: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3850: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-3851: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-3852: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-3853: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3855: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3856: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-3857: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3858: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-3859: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3860: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3861: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 2-3862: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3863: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-3864: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3865: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3866: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3867: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3868: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3869: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-3870: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3872: Loss: 0.0050 Acc: 93.3333%\n",
      "\ttrain 2-3873: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3874: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3875: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3876: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3878: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3879: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-3880: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3881: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-3882: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-3883: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3885: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-3886: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3887: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3889: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 2-3890: Loss: 0.0022 Acc: 93.3333%\n",
      "\ttrain 2-3891: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-3892: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3893: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3896: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3898: Loss: 0.0170 Acc: 90.0000%\n",
      "\ttrain 2-3899: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3901: Loss: 0.0123 Acc: 93.3333%\n",
      "\ttrain 2-3902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3904: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3905: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3906: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3907: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-3908: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3909: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-3910: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3911: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3912: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-3913: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3914: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 2-3915: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-3916: Loss: 0.0027 Acc: 93.3333%\n",
      "\ttrain 2-3917: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3918: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3919: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3920: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3921: Loss: 0.0035 Acc: 93.3333%\n",
      "\ttrain 2-3922: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3924: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3925: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3926: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3927: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-3928: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-3929: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3930: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3931: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3932: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3933: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3934: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-3935: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3936: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3937: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3939: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-3940: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 2-3941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3942: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3943: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-3944: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-3945: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3946: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-3947: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-3948: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3949: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3950: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3951: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3952: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-3953: Loss: 0.0071 Acc: 93.3333%\n",
      "\ttrain 2-3954: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3955: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3957: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3958: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-3959: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3960: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-3961: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3962: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3963: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-3964: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-3965: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3966: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3967: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3969: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-3970: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3971: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-3972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3973: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3974: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3975: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3978: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3979: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-3980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3981: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 2-3982: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3983: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-3984: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3985: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 2-3986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3987: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3988: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-3989: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-3990: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3991: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3992: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-3993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-3994: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-3995: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-3996: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-3997: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-3998: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-3999: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-4000: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4001: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-4002: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-4003: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4004: Loss: 0.0057 Acc: 93.3333%\n",
      "\ttrain 2-4005: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4006: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-4007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4008: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4009: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-4010: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4011: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4012: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4013: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4014: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-4015: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4016: Loss: 0.0090 Acc: 93.3333%\n",
      "\ttrain 2-4017: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4018: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4019: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-4020: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 2-4021: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4022: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-4023: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-4024: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 2-4025: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4027: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4028: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-4029: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-4030: Loss: 0.0076 Acc: 90.0000%\n",
      "\ttrain 2-4031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4032: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-4033: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4034: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4035: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4036: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4037: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4038: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-4039: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4040: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4041: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-4042: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4043: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4044: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-4045: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-4046: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4047: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4049: Loss: 0.0256 Acc: 93.3333%\n",
      "\ttrain 2-4050: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4051: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4052: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4053: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4054: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4055: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 2-4056: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4057: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4058: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4059: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4060: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4061: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4062: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4063: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4064: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4065: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4066: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4067: Loss: 0.0049 Acc: 93.3333%\n",
      "\ttrain 2-4068: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4070: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-4071: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-4072: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4073: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-4074: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4075: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4077: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-4078: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4079: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4080: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4082: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4083: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4084: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4085: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-4086: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4087: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4088: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4089: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4090: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4091: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4092: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 2-4093: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4094: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4095: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4096: Loss: 0.0037 Acc: 93.3333%\n",
      "\ttrain 2-4097: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4098: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4099: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4100: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4101: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 2-4102: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-4103: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4106: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4107: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4109: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4110: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4111: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-4112: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 2-4113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4114: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4115: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-4116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4117: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4118: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 2-4119: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 2-4120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4122: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4125: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4127: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4128: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 2-4129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4135: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-4136: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4138: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4139: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 2-4140: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4141: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4142: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4143: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 2-4144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4145: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4149: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-4150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4151: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4152: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4155: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-4156: Loss: 0.0078 Acc: 96.6667%\n",
      "\ttrain 2-4157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4158: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-4159: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4161: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4162: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4163: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4168: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4169: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-4170: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-4171: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4172: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4173: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4174: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4175: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-4176: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4177: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-4178: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4179: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4180: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 2-4181: Loss: 0.0006 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-4182: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4183: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4184: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 2-4185: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4186: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4187: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4188: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4189: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 2-4190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4191: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4193: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4194: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-4195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4197: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-4198: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4199: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4200: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4201: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4202: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4203: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4205: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4206: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-4207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4210: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4211: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4212: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4213: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4214: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-4215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4216: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-4217: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4218: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4220: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4224: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-4225: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4226: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4227: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4230: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 2-4231: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4232: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4236: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4237: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4239: Loss: 0.0070 Acc: 93.3333%\n",
      "\ttrain 2-4240: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4241: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4242: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 2-4243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4244: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4245: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4246: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4247: Loss: 0.0122 Acc: 93.3333%\n",
      "\ttrain 2-4248: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4251: Loss: 0.0074 Acc: 96.6667%\n",
      "\ttrain 2-4252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4253: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-4254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4255: Loss: 0.0059 Acc: 93.3333%\n",
      "\ttrain 2-4256: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4257: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4259: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4260: Loss: 0.0012 Acc: 100.0000%\n",
      "\ttrain 2-4261: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4265: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4266: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4267: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4268: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-4269: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4270: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4271: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4272: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4273: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 2-4274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4275: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-4276: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-4277: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4278: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4279: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4280: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4281: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4283: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4284: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4285: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4287: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4288: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4290: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-4291: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4292: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4293: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-4294: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 2-4295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4296: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4297: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4298: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4299: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4300: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4304: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 2-4305: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 2-4306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4307: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4308: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-4309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4311: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4313: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 2-4314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4316: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-4317: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4320: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4323: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4326: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4327: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 2-4328: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-4329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4332: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4333: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4334: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4335: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-4336: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4338: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-4339: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4341: Loss: 0.0074 Acc: 96.6667%\n",
      "\ttrain 2-4342: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-4343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4344: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4347: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4348: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4350: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 2-4351: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4352: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 2-4353: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4354: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4355: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4356: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-4357: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4358: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 2-4359: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 2-4360: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 2-4361: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-4362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4363: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4364: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-4365: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4366: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4368: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4369: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4370: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 2-4371: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 2-4372: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 2-4373: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 2-4374: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4375: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4376: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4377: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4378: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 2-4379: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4381: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 2-4382: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4383: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4384: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4385: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4386: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 2-4387: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4390: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-4391: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4393: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 2-4394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4396: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-4397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4398: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4399: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 2-4400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4401: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 2-4402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4403: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4406: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-4407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4408: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4409: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 2-4410: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4411: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4412: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 2-4413: Loss: 0.0163 Acc: 90.0000%\n",
      "\ttrain 2-4414: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4415: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4416: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-4417: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 2-4418: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-4419: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-4420: Loss: 0.0105 Acc: 93.3333%\n",
      "\ttrain 2-4421: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4422: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-4423: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4424: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-4425: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 2-4426: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4427: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-4428: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4429: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-4430: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-4431: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 2-4432: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4434: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4435: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4436: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4437: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 2-4438: Loss: 0.0017 Acc: 100.0000%\n",
      "\ttrain 2-4439: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4440: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 2-4441: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 2-4442: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4443: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 2-4444: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-4445: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 2-4446: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4447: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4448: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4449: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 2-4450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4451: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4452: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4453: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4455: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4456: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-4457: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 2-4458: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4459: Loss: 0.0103 Acc: 90.0000%\n",
      "\ttrain 2-4460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4461: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 2-4462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4465: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4466: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4467: Loss: 0.0061 Acc: 93.3333%\n",
      "\ttrain 2-4468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4469: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 2-4470: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4471: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-4472: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 2-4473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4474: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4475: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4477: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 2-4478: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 2-4479: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4480: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 2-4481: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 2-4482: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 2-4483: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-4484: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 2-4485: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 2-4486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4487: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 2-4488: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-4489: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 2-4490: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 2-4491: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 2-4492: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 2-4493: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 2-4494: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 2-4495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4496: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 2-4497: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 2-4498: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 2-4499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 2-4500: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-2: Loss: 0.0187 Acc: 93.3333%\n",
      "\tvalidation 2-3: Loss: 0.0231 Acc: 90.0000%\n",
      "\tvalidation 2-4: Loss: 0.0074 Acc: 90.0000%\n",
      "\tvalidation 2-5: Loss: 0.0143 Acc: 93.3333%\n",
      "\tvalidation 2-6: Loss: 0.0227 Acc: 86.6667%\n",
      "\tvalidation 2-7: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 2-8: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 2-9: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 2-10: Loss: 0.0144 Acc: 93.3333%\n",
      "\tvalidation 2-11: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 2-12: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-13: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 2-14: Loss: 0.0150 Acc: 90.0000%\n",
      "\tvalidation 2-15: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-16: Loss: 0.0095 Acc: 90.0000%\n",
      "\tvalidation 2-17: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 2-18: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-19: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-20: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 2-21: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-22: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 2-23: Loss: 0.0137 Acc: 90.0000%\n",
      "\tvalidation 2-24: Loss: 0.0172 Acc: 90.0000%\n",
      "\tvalidation 2-25: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 2-26: Loss: 0.0058 Acc: 96.6667%\n",
      "\tvalidation 2-27: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-28: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-29: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 2-30: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-31: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 2-32: Loss: 0.0217 Acc: 90.0000%\n",
      "\tvalidation 2-33: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 2-34: Loss: 0.0077 Acc: 96.6667%\n",
      "\tvalidation 2-35: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 2-36: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-37: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 2-38: Loss: 0.0100 Acc: 93.3333%\n",
      "\tvalidation 2-39: Loss: 0.0112 Acc: 90.0000%\n",
      "\tvalidation 2-40: Loss: 0.0194 Acc: 90.0000%\n",
      "\tvalidation 2-41: Loss: 0.0120 Acc: 96.6667%\n",
      "\tvalidation 2-42: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 2-43: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 2-44: Loss: 0.0069 Acc: 96.6667%\n",
      "\tvalidation 2-45: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 2-46: Loss: 0.0085 Acc: 90.0000%\n",
      "\tvalidation 2-47: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-48: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-49: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-50: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-51: Loss: 0.0105 Acc: 96.6667%\n",
      "\tvalidation 2-52: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 2-53: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 2-54: Loss: 0.0207 Acc: 90.0000%\n",
      "\tvalidation 2-55: Loss: 0.0232 Acc: 86.6667%\n",
      "\tvalidation 2-56: Loss: 0.0039 Acc: 93.3333%\n",
      "\tvalidation 2-57: Loss: 0.0088 Acc: 90.0000%\n",
      "\tvalidation 2-58: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 2-59: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 2-60: Loss: 0.0081 Acc: 96.6667%\n",
      "\tvalidation 2-61: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-62: Loss: 0.0232 Acc: 86.6667%\n",
      "\tvalidation 2-63: Loss: 0.0006 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-64: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-65: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 2-66: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 2-67: Loss: 0.0218 Acc: 93.3333%\n",
      "\tvalidation 2-68: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-69: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-70: Loss: 0.0137 Acc: 90.0000%\n",
      "\tvalidation 2-71: Loss: 0.0131 Acc: 96.6667%\n",
      "\tvalidation 2-72: Loss: 0.0288 Acc: 83.3333%\n",
      "\tvalidation 2-73: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 2-74: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 2-75: Loss: 0.0150 Acc: 86.6667%\n",
      "\tvalidation 2-76: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-77: Loss: 0.0190 Acc: 90.0000%\n",
      "\tvalidation 2-78: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 2-79: Loss: 0.0141 Acc: 93.3333%\n",
      "\tvalidation 2-80: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 2-81: Loss: 0.0119 Acc: 90.0000%\n",
      "\tvalidation 2-82: Loss: 0.0130 Acc: 90.0000%\n",
      "\tvalidation 2-83: Loss: 0.0078 Acc: 86.6667%\n",
      "\tvalidation 2-84: Loss: 0.0340 Acc: 90.0000%\n",
      "\tvalidation 2-85: Loss: 0.0160 Acc: 93.3333%\n",
      "\tvalidation 2-86: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-87: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 2-88: Loss: 0.0088 Acc: 93.3333%\n",
      "\tvalidation 2-89: Loss: 0.0184 Acc: 90.0000%\n",
      "\tvalidation 2-90: Loss: 0.0195 Acc: 86.6667%\n",
      "\tvalidation 2-91: Loss: 0.0063 Acc: 90.0000%\n",
      "\tvalidation 2-92: Loss: 0.0256 Acc: 90.0000%\n",
      "\tvalidation 2-93: Loss: 0.0168 Acc: 90.0000%\n",
      "\tvalidation 2-94: Loss: 0.0131 Acc: 93.3333%\n",
      "\tvalidation 2-95: Loss: 0.0143 Acc: 93.3333%\n",
      "\tvalidation 2-96: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-97: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 2-98: Loss: 0.0113 Acc: 96.6667%\n",
      "\tvalidation 2-99: Loss: 0.0107 Acc: 90.0000%\n",
      "\tvalidation 2-100: Loss: 0.0066 Acc: 96.6667%\n",
      "\tvalidation 2-101: Loss: 0.0164 Acc: 86.6667%\n",
      "\tvalidation 2-102: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 2-103: Loss: 0.0080 Acc: 90.0000%\n",
      "\tvalidation 2-104: Loss: 0.0121 Acc: 96.6667%\n",
      "\tvalidation 2-105: Loss: 0.0079 Acc: 96.6667%\n",
      "\tvalidation 2-106: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 2-107: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-108: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-109: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-110: Loss: 0.0179 Acc: 90.0000%\n",
      "\tvalidation 2-111: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-112: Loss: 0.0122 Acc: 90.0000%\n",
      "\tvalidation 2-113: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 2-114: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 2-115: Loss: 0.0339 Acc: 83.3333%\n",
      "\tvalidation 2-116: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 2-117: Loss: 0.0110 Acc: 86.6667%\n",
      "\tvalidation 2-118: Loss: 0.0083 Acc: 96.6667%\n",
      "\tvalidation 2-119: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 2-120: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 2-121: Loss: 0.0243 Acc: 90.0000%\n",
      "\tvalidation 2-122: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-123: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 2-124: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-125: Loss: 0.0187 Acc: 86.6667%\n",
      "\tvalidation 2-126: Loss: 0.0337 Acc: 86.6667%\n",
      "\tvalidation 2-127: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 2-128: Loss: 0.0245 Acc: 86.6667%\n",
      "\tvalidation 2-129: Loss: 0.0244 Acc: 86.6667%\n",
      "\tvalidation 2-130: Loss: 0.0098 Acc: 96.6667%\n",
      "\tvalidation 2-131: Loss: 0.0239 Acc: 83.3333%\n",
      "\tvalidation 2-132: Loss: 0.0151 Acc: 93.3333%\n",
      "\tvalidation 2-133: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 2-134: Loss: 0.0199 Acc: 90.0000%\n",
      "\tvalidation 2-135: Loss: 0.0046 Acc: 90.0000%\n",
      "\tvalidation 2-136: Loss: 0.0232 Acc: 90.0000%\n",
      "\tvalidation 2-137: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 2-138: Loss: 0.0203 Acc: 90.0000%\n",
      "\tvalidation 2-139: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 2-140: Loss: 0.0055 Acc: 93.3333%\n",
      "\tvalidation 2-141: Loss: 0.0108 Acc: 93.3333%\n",
      "\tvalidation 2-142: Loss: 0.0096 Acc: 96.6667%\n",
      "\tvalidation 2-143: Loss: 0.0154 Acc: 90.0000%\n",
      "\tvalidation 2-144: Loss: 0.0115 Acc: 90.0000%\n",
      "\tvalidation 2-145: Loss: 0.0180 Acc: 86.6667%\n",
      "\tvalidation 2-146: Loss: 0.0080 Acc: 93.3333%\n",
      "\tvalidation 2-147: Loss: 0.0104 Acc: 90.0000%\n",
      "\tvalidation 2-148: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-149: Loss: 0.0255 Acc: 86.6667%\n",
      "\tvalidation 2-150: Loss: 0.0236 Acc: 93.3333%\n",
      "\tvalidation 2-151: Loss: 0.0333 Acc: 83.3333%\n",
      "\tvalidation 2-152: Loss: 0.0180 Acc: 90.0000%\n",
      "\tvalidation 2-153: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 2-154: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 2-155: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 2-156: Loss: 0.0123 Acc: 86.6667%\n",
      "\tvalidation 2-157: Loss: 0.0164 Acc: 86.6667%\n",
      "\tvalidation 2-158: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 2-159: Loss: 0.0082 Acc: 86.6667%\n",
      "\tvalidation 2-160: Loss: 0.0091 Acc: 86.6667%\n",
      "\tvalidation 2-161: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-162: Loss: 0.0154 Acc: 86.6667%\n",
      "\tvalidation 2-163: Loss: 0.0053 Acc: 90.0000%\n",
      "\tvalidation 2-164: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 2-165: Loss: 0.0183 Acc: 86.6667%\n",
      "\tvalidation 2-166: Loss: 0.0159 Acc: 93.3333%\n",
      "\tvalidation 2-167: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-168: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 2-169: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-170: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 2-171: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-172: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-173: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 2-174: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 2-175: Loss: 0.0024 Acc: 93.3333%\n",
      "\tvalidation 2-176: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 2-177: Loss: 0.0085 Acc: 96.6667%\n",
      "\tvalidation 2-178: Loss: 0.0088 Acc: 93.3333%\n",
      "\tvalidation 2-179: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 2-180: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 2-181: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-182: Loss: 0.0025 Acc: 93.3333%\n",
      "\tvalidation 2-183: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 2-184: Loss: 0.0319 Acc: 83.3333%\n",
      "\tvalidation 2-185: Loss: 0.0178 Acc: 86.6667%\n",
      "\tvalidation 2-186: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-187: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 2-188: Loss: 0.0197 Acc: 86.6667%\n",
      "\tvalidation 2-189: Loss: 0.0148 Acc: 90.0000%\n",
      "\tvalidation 2-190: Loss: 0.0146 Acc: 93.3333%\n",
      "\tvalidation 2-191: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-192: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-193: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-194: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 2-195: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 2-196: Loss: 0.0280 Acc: 83.3333%\n",
      "\tvalidation 2-197: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-198: Loss: 0.0045 Acc: 93.3333%\n",
      "\tvalidation 2-199: Loss: 0.0196 Acc: 86.6667%\n",
      "\tvalidation 2-200: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 2-201: Loss: 0.0104 Acc: 96.6667%\n",
      "\tvalidation 2-202: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 2-203: Loss: 0.0182 Acc: 90.0000%\n",
      "\tvalidation 2-204: Loss: 0.0034 Acc: 93.3333%\n",
      "\tvalidation 2-205: Loss: 0.0177 Acc: 93.3333%\n",
      "\tvalidation 2-206: Loss: 0.0261 Acc: 90.0000%\n",
      "\tvalidation 2-207: Loss: 0.0150 Acc: 90.0000%\n",
      "\tvalidation 2-208: Loss: 0.0033 Acc: 90.0000%\n",
      "\tvalidation 2-209: Loss: 0.0243 Acc: 86.6667%\n",
      "\tvalidation 2-210: Loss: 0.0171 Acc: 86.6667%\n",
      "\tvalidation 2-211: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 2-212: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-213: Loss: 0.0067 Acc: 96.6667%\n",
      "\tvalidation 2-214: Loss: 0.0130 Acc: 93.3333%\n",
      "\tvalidation 2-215: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 2-216: Loss: 0.0156 Acc: 96.6667%\n",
      "\tvalidation 2-217: Loss: 0.0160 Acc: 90.0000%\n",
      "\tvalidation 2-218: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-219: Loss: 0.0248 Acc: 83.3333%\n",
      "\tvalidation 2-220: Loss: 0.0085 Acc: 93.3333%\n",
      "\tvalidation 2-221: Loss: 0.0179 Acc: 83.3333%\n",
      "\tvalidation 2-222: Loss: 0.0149 Acc: 86.6667%\n",
      "\tvalidation 2-223: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-224: Loss: 0.0187 Acc: 86.6667%\n",
      "\tvalidation 2-225: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 2-226: Loss: 0.0077 Acc: 96.6667%\n",
      "\tvalidation 2-227: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 2-228: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 2-229: Loss: 0.0074 Acc: 96.6667%\n",
      "\tvalidation 2-230: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-231: Loss: 0.0032 Acc: 90.0000%\n",
      "\tvalidation 2-232: Loss: 0.0198 Acc: 90.0000%\n",
      "\tvalidation 2-233: Loss: 0.0241 Acc: 86.6667%\n",
      "\tvalidation 2-234: Loss: 0.0176 Acc: 90.0000%\n",
      "\tvalidation 2-235: Loss: 0.0261 Acc: 86.6667%\n",
      "\tvalidation 2-236: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-237: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 2-238: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 2-239: Loss: 0.0195 Acc: 90.0000%\n",
      "\tvalidation 2-240: Loss: 0.0123 Acc: 93.3333%\n",
      "\tvalidation 2-241: Loss: 0.0194 Acc: 86.6667%\n",
      "\tvalidation 2-242: Loss: 0.0191 Acc: 83.3333%\n",
      "\tvalidation 2-243: Loss: 0.0056 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-244: Loss: 0.0073 Acc: 90.0000%\n",
      "\tvalidation 2-245: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-246: Loss: 0.0169 Acc: 90.0000%\n",
      "\tvalidation 2-247: Loss: 0.0136 Acc: 86.6667%\n",
      "\tvalidation 2-248: Loss: 0.0118 Acc: 93.3333%\n",
      "\tvalidation 2-249: Loss: 0.0164 Acc: 86.6667%\n",
      "\tvalidation 2-250: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 2-251: Loss: 0.0157 Acc: 86.6667%\n",
      "\tvalidation 2-252: Loss: 0.0222 Acc: 86.6667%\n",
      "\tvalidation 2-253: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-254: Loss: 0.0215 Acc: 90.0000%\n",
      "\tvalidation 2-255: Loss: 0.0171 Acc: 93.3333%\n",
      "\tvalidation 2-256: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 2-257: Loss: 0.0140 Acc: 90.0000%\n",
      "\tvalidation 2-258: Loss: 0.0160 Acc: 90.0000%\n",
      "\tvalidation 2-259: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 2-260: Loss: 0.0157 Acc: 93.3333%\n",
      "\tvalidation 2-261: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 2-262: Loss: 0.0150 Acc: 93.3333%\n",
      "\tvalidation 2-263: Loss: 0.0266 Acc: 90.0000%\n",
      "\tvalidation 2-264: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 2-265: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 2-266: Loss: 0.0298 Acc: 83.3333%\n",
      "\tvalidation 2-267: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 2-268: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 2-269: Loss: 0.0271 Acc: 86.6667%\n",
      "\tvalidation 2-270: Loss: 0.0163 Acc: 83.3333%\n",
      "\tvalidation 2-271: Loss: 0.0369 Acc: 83.3333%\n",
      "\tvalidation 2-272: Loss: 0.0181 Acc: 90.0000%\n",
      "\tvalidation 2-273: Loss: 0.0265 Acc: 83.3333%\n",
      "\tvalidation 2-274: Loss: 0.0111 Acc: 96.6667%\n",
      "\tvalidation 2-275: Loss: 0.0027 Acc: 100.0000%\n",
      "\tvalidation 2-276: Loss: 0.0170 Acc: 86.6667%\n",
      "\tvalidation 2-277: Loss: 0.0100 Acc: 86.6667%\n",
      "\tvalidation 2-278: Loss: 0.0119 Acc: 93.3333%\n",
      "\tvalidation 2-279: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-280: Loss: 0.0415 Acc: 83.3333%\n",
      "\tvalidation 2-281: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 2-282: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 2-283: Loss: 0.0118 Acc: 93.3333%\n",
      "\tvalidation 2-284: Loss: 0.0055 Acc: 93.3333%\n",
      "\tvalidation 2-285: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-286: Loss: 0.0146 Acc: 90.0000%\n",
      "\tvalidation 2-287: Loss: 0.0084 Acc: 96.6667%\n",
      "\tvalidation 2-288: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 2-289: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 2-290: Loss: 0.0141 Acc: 93.3333%\n",
      "\tvalidation 2-291: Loss: 0.0105 Acc: 93.3333%\n",
      "\tvalidation 2-292: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 2-293: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-294: Loss: 0.0276 Acc: 86.6667%\n",
      "\tvalidation 2-295: Loss: 0.0119 Acc: 90.0000%\n",
      "\tvalidation 2-296: Loss: 0.0128 Acc: 93.3333%\n",
      "\tvalidation 2-297: Loss: 0.0126 Acc: 90.0000%\n",
      "\tvalidation 2-298: Loss: 0.0122 Acc: 96.6667%\n",
      "\tvalidation 2-299: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 2-300: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-301: Loss: 0.0125 Acc: 90.0000%\n",
      "\tvalidation 2-302: Loss: 0.0090 Acc: 90.0000%\n",
      "\tvalidation 2-303: Loss: 0.0125 Acc: 96.6667%\n",
      "\tvalidation 2-304: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 2-305: Loss: 0.0156 Acc: 90.0000%\n",
      "\tvalidation 2-306: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-307: Loss: 0.0055 Acc: 93.3333%\n",
      "\tvalidation 2-308: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 2-309: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 2-310: Loss: 0.0130 Acc: 93.3333%\n",
      "\tvalidation 2-311: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 2-312: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 2-313: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-314: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-315: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-316: Loss: 0.0202 Acc: 86.6667%\n",
      "\tvalidation 2-317: Loss: 0.0072 Acc: 96.6667%\n",
      "\tvalidation 2-318: Loss: 0.0248 Acc: 90.0000%\n",
      "\tvalidation 2-319: Loss: 0.0120 Acc: 96.6667%\n",
      "\tvalidation 2-320: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-321: Loss: 0.0170 Acc: 93.3333%\n",
      "\tvalidation 2-322: Loss: 0.0085 Acc: 90.0000%\n",
      "\tvalidation 2-323: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 2-324: Loss: 0.0156 Acc: 93.3333%\n",
      "\tvalidation 2-325: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-326: Loss: 0.0110 Acc: 90.0000%\n",
      "\tvalidation 2-327: Loss: 0.0095 Acc: 90.0000%\n",
      "\tvalidation 2-328: Loss: 0.0132 Acc: 93.3333%\n",
      "\tvalidation 2-329: Loss: 0.0128 Acc: 93.3333%\n",
      "\tvalidation 2-330: Loss: 0.0070 Acc: 86.6667%\n",
      "\tvalidation 2-331: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 2-332: Loss: 0.0122 Acc: 93.3333%\n",
      "\tvalidation 2-333: Loss: 0.0181 Acc: 80.0000%\n",
      "\tvalidation 2-334: Loss: 0.0070 Acc: 90.0000%\n",
      "\tvalidation 2-335: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 2-336: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-337: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 2-338: Loss: 0.0035 Acc: 93.3333%\n",
      "\tvalidation 2-339: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-340: Loss: 0.0187 Acc: 90.0000%\n",
      "\tvalidation 2-341: Loss: 0.0132 Acc: 90.0000%\n",
      "\tvalidation 2-342: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 2-343: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 2-344: Loss: 0.0084 Acc: 90.0000%\n",
      "\tvalidation 2-345: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-346: Loss: 0.0166 Acc: 90.0000%\n",
      "\tvalidation 2-347: Loss: 0.0160 Acc: 90.0000%\n",
      "\tvalidation 2-348: Loss: 0.0137 Acc: 93.3333%\n",
      "\tvalidation 2-349: Loss: 0.0068 Acc: 93.3333%\n",
      "\tvalidation 2-350: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 2-351: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-352: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 2-353: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-354: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 2-355: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-356: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 2-357: Loss: 0.0199 Acc: 86.6667%\n",
      "\tvalidation 2-358: Loss: 0.0040 Acc: 93.3333%\n",
      "\tvalidation 2-359: Loss: 0.0228 Acc: 86.6667%\n",
      "\tvalidation 2-360: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-361: Loss: 0.0208 Acc: 90.0000%\n",
      "\tvalidation 2-362: Loss: 0.0087 Acc: 86.6667%\n",
      "\tvalidation 2-363: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 2-364: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-365: Loss: 0.0172 Acc: 93.3333%\n",
      "\tvalidation 2-366: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-367: Loss: 0.0126 Acc: 86.6667%\n",
      "\tvalidation 2-368: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 2-369: Loss: 0.0219 Acc: 86.6667%\n",
      "\tvalidation 2-370: Loss: 0.0164 Acc: 90.0000%\n",
      "\tvalidation 2-371: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 2-372: Loss: 0.0223 Acc: 90.0000%\n",
      "\tvalidation 2-373: Loss: 0.0116 Acc: 96.6667%\n",
      "\tvalidation 2-374: Loss: 0.0125 Acc: 96.6667%\n",
      "\tvalidation 2-375: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 2-376: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-377: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 2-378: Loss: 0.0141 Acc: 93.3333%\n",
      "\tvalidation 2-379: Loss: 0.0154 Acc: 86.6667%\n",
      "\tvalidation 2-380: Loss: 0.0182 Acc: 90.0000%\n",
      "\tvalidation 2-381: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 2-382: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 2-383: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 2-384: Loss: 0.0262 Acc: 76.6667%\n",
      "\tvalidation 2-385: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-386: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 2-387: Loss: 0.0172 Acc: 90.0000%\n",
      "\tvalidation 2-388: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 2-389: Loss: 0.0092 Acc: 90.0000%\n",
      "\tvalidation 2-390: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 2-391: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 2-392: Loss: 0.0303 Acc: 90.0000%\n",
      "\tvalidation 2-393: Loss: 0.0141 Acc: 83.3333%\n",
      "\tvalidation 2-394: Loss: 0.0058 Acc: 90.0000%\n",
      "\tvalidation 2-395: Loss: 0.0247 Acc: 90.0000%\n",
      "\tvalidation 2-396: Loss: 0.0140 Acc: 90.0000%\n",
      "\tvalidation 2-397: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-398: Loss: 0.0171 Acc: 86.6667%\n",
      "\tvalidation 2-399: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-400: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-401: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-402: Loss: 0.0172 Acc: 90.0000%\n",
      "\tvalidation 2-403: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-404: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 2-405: Loss: 0.0056 Acc: 90.0000%\n",
      "\tvalidation 2-406: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-407: Loss: 0.0136 Acc: 90.0000%\n",
      "\tvalidation 2-408: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 2-409: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 2-410: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-411: Loss: 0.0173 Acc: 93.3333%\n",
      "\tvalidation 2-412: Loss: 0.0173 Acc: 93.3333%\n",
      "\tvalidation 2-413: Loss: 0.0181 Acc: 90.0000%\n",
      "\tvalidation 2-414: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 2-415: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-416: Loss: 0.0152 Acc: 90.0000%\n",
      "\tvalidation 2-417: Loss: 0.0131 Acc: 90.0000%\n",
      "\tvalidation 2-418: Loss: 0.0190 Acc: 90.0000%\n",
      "\tvalidation 2-419: Loss: 0.0324 Acc: 86.6667%\n",
      "\tvalidation 2-420: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 2-421: Loss: 0.0072 Acc: 90.0000%\n",
      "\tvalidation 2-422: Loss: 0.0175 Acc: 90.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-423: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-424: Loss: 0.0033 Acc: 93.3333%\n",
      "\tvalidation 2-425: Loss: 0.0112 Acc: 90.0000%\n",
      "\tvalidation 2-426: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 2-427: Loss: 0.0088 Acc: 86.6667%\n",
      "\tvalidation 2-428: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-429: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 2-430: Loss: 0.0148 Acc: 90.0000%\n",
      "\tvalidation 2-431: Loss: 0.0150 Acc: 86.6667%\n",
      "\tvalidation 2-432: Loss: 0.0240 Acc: 83.3333%\n",
      "\tvalidation 2-433: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 2-434: Loss: 0.0346 Acc: 83.3333%\n",
      "\tvalidation 2-435: Loss: 0.0035 Acc: 93.3333%\n",
      "\tvalidation 2-436: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-437: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-438: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 2-439: Loss: 0.0078 Acc: 96.6667%\n",
      "\tvalidation 2-440: Loss: 0.0161 Acc: 86.6667%\n",
      "\tvalidation 2-441: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-442: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-443: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 2-444: Loss: 0.0147 Acc: 90.0000%\n",
      "\tvalidation 2-445: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 2-446: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-447: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 2-448: Loss: 0.0125 Acc: 93.3333%\n",
      "\tvalidation 2-449: Loss: 0.0117 Acc: 86.6667%\n",
      "\tvalidation 2-450: Loss: 0.0125 Acc: 93.3333%\n",
      "\tvalidation 2-451: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 2-452: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-453: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-454: Loss: 0.0098 Acc: 96.6667%\n",
      "\tvalidation 2-455: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 2-456: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 2-457: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 2-458: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 2-459: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 2-460: Loss: 0.0046 Acc: 90.0000%\n",
      "\tvalidation 2-461: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 2-462: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 2-463: Loss: 0.0148 Acc: 93.3333%\n",
      "\tvalidation 2-464: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 2-465: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 2-466: Loss: 0.0289 Acc: 83.3333%\n",
      "\tvalidation 2-467: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 2-468: Loss: 0.0152 Acc: 86.6667%\n",
      "\tvalidation 2-469: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 2-470: Loss: 0.0140 Acc: 90.0000%\n",
      "\tvalidation 2-471: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 2-472: Loss: 0.0186 Acc: 90.0000%\n",
      "\tvalidation 2-473: Loss: 0.0108 Acc: 90.0000%\n",
      "\tvalidation 2-474: Loss: 0.0108 Acc: 93.3333%\n",
      "\tvalidation 2-475: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 2-476: Loss: 0.0145 Acc: 83.3333%\n",
      "\tvalidation 2-477: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-478: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 2-479: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 2-480: Loss: 0.0105 Acc: 96.6667%\n",
      "\tvalidation 2-481: Loss: 0.0170 Acc: 90.0000%\n",
      "\tvalidation 2-482: Loss: 0.0017 Acc: 100.0000%\n",
      "\tvalidation 2-483: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 2-484: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-485: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-486: Loss: 0.0236 Acc: 80.0000%\n",
      "\tvalidation 2-487: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-488: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 2-489: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 2-490: Loss: 0.0261 Acc: 90.0000%\n",
      "\tvalidation 2-491: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 2-492: Loss: 0.0137 Acc: 96.6667%\n",
      "\tvalidation 2-493: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-494: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 2-495: Loss: 0.0096 Acc: 96.6667%\n",
      "\tvalidation 2-496: Loss: 0.0066 Acc: 96.6667%\n",
      "\tvalidation 2-497: Loss: 0.0122 Acc: 90.0000%\n",
      "\tvalidation 2-498: Loss: 0.0180 Acc: 93.3333%\n",
      "\tvalidation 2-499: Loss: 0.0322 Acc: 80.0000%\n",
      "\tvalidation 2-500: Loss: 0.0269 Acc: 90.0000%\n",
      "\tvalidation 2-501: Loss: 0.0257 Acc: 86.6667%\n",
      "\tvalidation 2-502: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 2-503: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-504: Loss: 0.0146 Acc: 86.6667%\n",
      "\tvalidation 2-505: Loss: 0.0156 Acc: 86.6667%\n",
      "\tvalidation 2-506: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 2-507: Loss: 0.0118 Acc: 93.3333%\n",
      "\tvalidation 2-508: Loss: 0.0382 Acc: 83.3333%\n",
      "\tvalidation 2-509: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-510: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-511: Loss: 0.0265 Acc: 83.3333%\n",
      "\tvalidation 2-512: Loss: 0.0139 Acc: 90.0000%\n",
      "\tvalidation 2-513: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 2-514: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-515: Loss: 0.0113 Acc: 90.0000%\n",
      "\tvalidation 2-516: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-517: Loss: 0.0190 Acc: 86.6667%\n",
      "\tvalidation 2-518: Loss: 0.0257 Acc: 86.6667%\n",
      "\tvalidation 2-519: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 2-520: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-521: Loss: 0.0040 Acc: 96.6667%\n",
      "\tvalidation 2-522: Loss: 0.0206 Acc: 90.0000%\n",
      "\tvalidation 2-523: Loss: 0.0098 Acc: 83.3333%\n",
      "\tvalidation 2-524: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 2-525: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 2-526: Loss: 0.0223 Acc: 83.3333%\n",
      "\tvalidation 2-527: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 2-528: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 2-529: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 2-530: Loss: 0.0278 Acc: 83.3333%\n",
      "\tvalidation 2-531: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 2-532: Loss: 0.0129 Acc: 90.0000%\n",
      "\tvalidation 2-533: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 2-534: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 2-535: Loss: 0.0148 Acc: 93.3333%\n",
      "\tvalidation 2-536: Loss: 0.0085 Acc: 96.6667%\n",
      "\tvalidation 2-537: Loss: 0.0187 Acc: 90.0000%\n",
      "\tvalidation 2-538: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-539: Loss: 0.0118 Acc: 86.6667%\n",
      "\tvalidation 2-540: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 2-541: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-542: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-543: Loss: 0.0058 Acc: 90.0000%\n",
      "\tvalidation 2-544: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 2-545: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 2-546: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 2-547: Loss: 0.0106 Acc: 96.6667%\n",
      "\tvalidation 2-548: Loss: 0.0233 Acc: 90.0000%\n",
      "\tvalidation 2-549: Loss: 0.0187 Acc: 90.0000%\n",
      "\tvalidation 2-550: Loss: 0.0020 Acc: 93.3333%\n",
      "\tvalidation 2-551: Loss: 0.0313 Acc: 86.6667%\n",
      "\tvalidation 2-552: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 2-553: Loss: 0.0074 Acc: 96.6667%\n",
      "\tvalidation 2-554: Loss: 0.0079 Acc: 90.0000%\n",
      "\tvalidation 2-555: Loss: 0.0133 Acc: 96.6667%\n",
      "\tvalidation 2-556: Loss: 0.0122 Acc: 86.6667%\n",
      "\tvalidation 2-557: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 2-558: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 2-559: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 2-560: Loss: 0.0173 Acc: 90.0000%\n",
      "\tvalidation 2-561: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 2-562: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-563: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-564: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 2-565: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 2-566: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 2-567: Loss: 0.0024 Acc: 93.3333%\n",
      "\tvalidation 2-568: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 2-569: Loss: 0.0111 Acc: 90.0000%\n",
      "\tvalidation 2-570: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 2-571: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-572: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 2-573: Loss: 0.0261 Acc: 86.6667%\n",
      "\tvalidation 2-574: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 2-575: Loss: 0.0069 Acc: 96.6667%\n",
      "\tvalidation 2-576: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-577: Loss: 0.0493 Acc: 76.6667%\n",
      "\tvalidation 2-578: Loss: 0.0149 Acc: 90.0000%\n",
      "\tvalidation 2-579: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-580: Loss: 0.0057 Acc: 90.0000%\n",
      "\tvalidation 2-581: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-582: Loss: 0.0203 Acc: 90.0000%\n",
      "\tvalidation 2-583: Loss: 0.0061 Acc: 96.6667%\n",
      "\tvalidation 2-584: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 2-585: Loss: 0.0113 Acc: 86.6667%\n",
      "\tvalidation 2-586: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-587: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 2-588: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 2-589: Loss: 0.0105 Acc: 93.3333%\n",
      "\tvalidation 2-590: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 2-591: Loss: 0.0295 Acc: 83.3333%\n",
      "\tvalidation 2-592: Loss: 0.0080 Acc: 96.6667%\n",
      "\tvalidation 2-593: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 2-594: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 2-595: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 2-596: Loss: 0.0014 Acc: 100.0000%\n",
      "\tvalidation 2-597: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 2-598: Loss: 0.0103 Acc: 93.3333%\n",
      "\tvalidation 2-599: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 2-600: Loss: 0.0072 Acc: 90.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-601: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 2-602: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 2-603: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 2-604: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 2-605: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-606: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 2-607: Loss: 0.0168 Acc: 80.0000%\n",
      "\tvalidation 2-608: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-609: Loss: 0.0066 Acc: 96.6667%\n",
      "\tvalidation 2-610: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 2-611: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 2-612: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 2-613: Loss: 0.0272 Acc: 90.0000%\n",
      "\tvalidation 2-614: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 2-615: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 2-616: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 2-617: Loss: 0.0143 Acc: 90.0000%\n",
      "\tvalidation 2-618: Loss: 0.0101 Acc: 93.3333%\n",
      "\tvalidation 2-619: Loss: 0.0037 Acc: 93.3333%\n",
      "\tvalidation 2-620: Loss: 0.0118 Acc: 90.0000%\n",
      "\tvalidation 2-621: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 2-622: Loss: 0.0122 Acc: 93.3333%\n",
      "\tvalidation 2-623: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-624: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 2-625: Loss: 0.0099 Acc: 96.6667%\n",
      "\tvalidation 2-626: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 2-627: Loss: 0.0151 Acc: 86.6667%\n",
      "\tvalidation 2-628: Loss: 0.0279 Acc: 90.0000%\n",
      "\tvalidation 2-629: Loss: 0.0255 Acc: 86.6667%\n",
      "\tvalidation 2-630: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-631: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 2-632: Loss: 0.0150 Acc: 93.3333%\n",
      "\tvalidation 2-633: Loss: 0.0185 Acc: 93.3333%\n",
      "\tvalidation 2-634: Loss: 0.0176 Acc: 86.6667%\n",
      "\tvalidation 2-635: Loss: 0.0236 Acc: 93.3333%\n",
      "\tvalidation 2-636: Loss: 0.0194 Acc: 86.6667%\n",
      "\tvalidation 2-637: Loss: 0.0072 Acc: 96.6667%\n",
      "\tvalidation 2-638: Loss: 0.0258 Acc: 80.0000%\n",
      "\tvalidation 2-639: Loss: 0.0206 Acc: 86.6667%\n",
      "\tvalidation 2-640: Loss: 0.0352 Acc: 86.6667%\n",
      "\tvalidation 2-641: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-642: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 2-643: Loss: 0.0039 Acc: 93.3333%\n",
      "\tvalidation 2-644: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 2-645: Loss: 0.0124 Acc: 96.6667%\n",
      "\tvalidation 2-646: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-647: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 2-648: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 2-649: Loss: 0.0173 Acc: 90.0000%\n",
      "\tvalidation 2-650: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 2-651: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 2-652: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-653: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 2-654: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 2-655: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 2-656: Loss: 0.0200 Acc: 90.0000%\n",
      "\tvalidation 2-657: Loss: 0.0088 Acc: 93.3333%\n",
      "\tvalidation 2-658: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 2-659: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-660: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 2-661: Loss: 0.0168 Acc: 93.3333%\n",
      "\tvalidation 2-662: Loss: 0.0085 Acc: 93.3333%\n",
      "\tvalidation 2-663: Loss: 0.0171 Acc: 90.0000%\n",
      "\tvalidation 2-664: Loss: 0.0045 Acc: 93.3333%\n",
      "\tvalidation 2-665: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-666: Loss: 0.0106 Acc: 96.6667%\n",
      "\tvalidation 2-667: Loss: 0.0103 Acc: 86.6667%\n",
      "\tvalidation 2-668: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 2-669: Loss: 0.0159 Acc: 90.0000%\n",
      "\tvalidation 2-670: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 2-671: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 2-672: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-673: Loss: 0.0065 Acc: 86.6667%\n",
      "\tvalidation 2-674: Loss: 0.0111 Acc: 96.6667%\n",
      "\tvalidation 2-675: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 2-676: Loss: 0.0264 Acc: 83.3333%\n",
      "\tvalidation 2-677: Loss: 0.0124 Acc: 90.0000%\n",
      "\tvalidation 2-678: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-679: Loss: 0.0177 Acc: 90.0000%\n",
      "\tvalidation 2-680: Loss: 0.0221 Acc: 90.0000%\n",
      "\tvalidation 2-681: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-682: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-683: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-684: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 2-685: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-686: Loss: 0.0129 Acc: 93.3333%\n",
      "\tvalidation 2-687: Loss: 0.0034 Acc: 93.3333%\n",
      "\tvalidation 2-688: Loss: 0.0178 Acc: 90.0000%\n",
      "\tvalidation 2-689: Loss: 0.0155 Acc: 90.0000%\n",
      "\tvalidation 2-690: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-691: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 2-692: Loss: 0.0252 Acc: 90.0000%\n",
      "\tvalidation 2-693: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 2-694: Loss: 0.0163 Acc: 93.3333%\n",
      "\tvalidation 2-695: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 2-696: Loss: 0.0185 Acc: 93.3333%\n",
      "\tvalidation 2-697: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 2-698: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 2-699: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 2-700: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 2-701: Loss: 0.0086 Acc: 90.0000%\n",
      "\tvalidation 2-702: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 2-703: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 2-704: Loss: 0.0119 Acc: 93.3333%\n",
      "\tvalidation 2-705: Loss: 0.0095 Acc: 96.6667%\n",
      "\tvalidation 2-706: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 2-707: Loss: 0.0068 Acc: 96.6667%\n",
      "\tvalidation 2-708: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-709: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 2-710: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 2-711: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-712: Loss: 0.0198 Acc: 90.0000%\n",
      "\tvalidation 2-713: Loss: 0.0179 Acc: 90.0000%\n",
      "\tvalidation 2-714: Loss: 0.0286 Acc: 90.0000%\n",
      "\tvalidation 2-715: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 2-716: Loss: 0.0060 Acc: 90.0000%\n",
      "\tvalidation 2-717: Loss: 0.0168 Acc: 93.3333%\n",
      "\tvalidation 2-718: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-719: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-720: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-721: Loss: 0.0135 Acc: 90.0000%\n",
      "\tvalidation 2-722: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 2-723: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-724: Loss: 0.0193 Acc: 83.3333%\n",
      "\tvalidation 2-725: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 2-726: Loss: 0.0078 Acc: 96.6667%\n",
      "\tvalidation 2-727: Loss: 0.0244 Acc: 83.3333%\n",
      "\tvalidation 2-728: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 2-729: Loss: 0.0058 Acc: 93.3333%\n",
      "\tvalidation 2-730: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 2-731: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 2-732: Loss: 0.0101 Acc: 93.3333%\n",
      "\tvalidation 2-733: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-734: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-735: Loss: 0.0096 Acc: 96.6667%\n",
      "\tvalidation 2-736: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 2-737: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-738: Loss: 0.0180 Acc: 90.0000%\n",
      "\tvalidation 2-739: Loss: 0.0207 Acc: 83.3333%\n",
      "\tvalidation 2-740: Loss: 0.0054 Acc: 93.3333%\n",
      "\tvalidation 2-741: Loss: 0.0163 Acc: 93.3333%\n",
      "\tvalidation 2-742: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 2-743: Loss: 0.0141 Acc: 86.6667%\n",
      "\tvalidation 2-744: Loss: 0.0068 Acc: 96.6667%\n",
      "\tvalidation 2-745: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 2-746: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-747: Loss: 0.0165 Acc: 90.0000%\n",
      "\tvalidation 2-748: Loss: 0.0124 Acc: 93.3333%\n",
      "\tvalidation 2-749: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 2-750: Loss: 0.0046 Acc: 93.3333%\n",
      "\tvalidation 2-751: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 2-752: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 2-753: Loss: 0.0417 Acc: 83.3333%\n",
      "\tvalidation 2-754: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-755: Loss: 0.0255 Acc: 86.6667%\n",
      "\tvalidation 2-756: Loss: 0.0173 Acc: 93.3333%\n",
      "\tvalidation 2-757: Loss: 0.0111 Acc: 96.6667%\n",
      "\tvalidation 2-758: Loss: 0.0127 Acc: 90.0000%\n",
      "\tvalidation 2-759: Loss: 0.0089 Acc: 93.3333%\n",
      "\tvalidation 2-760: Loss: 0.0116 Acc: 86.6667%\n",
      "\tvalidation 2-761: Loss: 0.0081 Acc: 96.6667%\n",
      "\tvalidation 2-762: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-763: Loss: 0.0113 Acc: 93.3333%\n",
      "\tvalidation 2-764: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 2-765: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 2-766: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-767: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 2-768: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 2-769: Loss: 0.0097 Acc: 93.3333%\n",
      "\tvalidation 2-770: Loss: 0.0144 Acc: 90.0000%\n",
      "\tvalidation 2-771: Loss: 0.0280 Acc: 83.3333%\n",
      "\tvalidation 2-772: Loss: 0.0223 Acc: 90.0000%\n",
      "\tvalidation 2-773: Loss: 0.0271 Acc: 86.6667%\n",
      "\tvalidation 2-774: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-775: Loss: 0.0162 Acc: 83.3333%\n",
      "\tvalidation 2-776: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-777: Loss: 0.0079 Acc: 90.0000%\n",
      "\tvalidation 2-778: Loss: 0.0130 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-779: Loss: 0.0174 Acc: 93.3333%\n",
      "\tvalidation 2-780: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 2-781: Loss: 0.0133 Acc: 90.0000%\n",
      "\tvalidation 2-782: Loss: 0.0293 Acc: 80.0000%\n",
      "\tvalidation 2-783: Loss: 0.0181 Acc: 93.3333%\n",
      "\tvalidation 2-784: Loss: 0.0197 Acc: 90.0000%\n",
      "\tvalidation 2-785: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-786: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-787: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 2-788: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 2-789: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 2-790: Loss: 0.0139 Acc: 93.3333%\n",
      "\tvalidation 2-791: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-792: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-793: Loss: 0.0031 Acc: 96.6667%\n",
      "\tvalidation 2-794: Loss: 0.0215 Acc: 83.3333%\n",
      "\tvalidation 2-795: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 2-796: Loss: 0.0127 Acc: 93.3333%\n",
      "\tvalidation 2-797: Loss: 0.0078 Acc: 90.0000%\n",
      "\tvalidation 2-798: Loss: 0.0031 Acc: 93.3333%\n",
      "\tvalidation 2-799: Loss: 0.0199 Acc: 90.0000%\n",
      "\tvalidation 2-800: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 2-801: Loss: 0.0198 Acc: 86.6667%\n",
      "\tvalidation 2-802: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-803: Loss: 0.0076 Acc: 96.6667%\n",
      "\tvalidation 2-804: Loss: 0.0158 Acc: 93.3333%\n",
      "\tvalidation 2-805: Loss: 0.0075 Acc: 90.0000%\n",
      "\tvalidation 2-806: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 2-807: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 2-808: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 2-809: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 2-810: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 2-811: Loss: 0.0149 Acc: 96.6667%\n",
      "\tvalidation 2-812: Loss: 0.0235 Acc: 90.0000%\n",
      "\tvalidation 2-813: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-814: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-815: Loss: 0.0281 Acc: 86.6667%\n",
      "\tvalidation 2-816: Loss: 0.0390 Acc: 80.0000%\n",
      "\tvalidation 2-817: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-818: Loss: 0.0080 Acc: 93.3333%\n",
      "\tvalidation 2-819: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 2-820: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 2-821: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-822: Loss: 0.0118 Acc: 90.0000%\n",
      "\tvalidation 2-823: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 2-824: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 2-825: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-826: Loss: 0.0319 Acc: 90.0000%\n",
      "\tvalidation 2-827: Loss: 0.0024 Acc: 93.3333%\n",
      "\tvalidation 2-828: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 2-829: Loss: 0.0156 Acc: 90.0000%\n",
      "\tvalidation 2-830: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 2-831: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 2-832: Loss: 0.0040 Acc: 96.6667%\n",
      "\tvalidation 2-833: Loss: 0.0109 Acc: 96.6667%\n",
      "\tvalidation 2-834: Loss: 0.0134 Acc: 90.0000%\n",
      "\tvalidation 2-835: Loss: 0.0031 Acc: 96.6667%\n",
      "\tvalidation 2-836: Loss: 0.0179 Acc: 93.3333%\n",
      "\tvalidation 2-837: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 2-838: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-839: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 2-840: Loss: 0.0124 Acc: 93.3333%\n",
      "\tvalidation 2-841: Loss: 0.0081 Acc: 90.0000%\n",
      "\tvalidation 2-842: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 2-843: Loss: 0.0200 Acc: 90.0000%\n",
      "\tvalidation 2-844: Loss: 0.0200 Acc: 90.0000%\n",
      "\tvalidation 2-845: Loss: 0.0042 Acc: 90.0000%\n",
      "\tvalidation 2-846: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 2-847: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 2-848: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 2-849: Loss: 0.0079 Acc: 96.6667%\n",
      "\tvalidation 2-850: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 2-851: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 2-852: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 2-853: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-854: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 2-855: Loss: 0.0150 Acc: 90.0000%\n",
      "\tvalidation 2-856: Loss: 0.0081 Acc: 96.6667%\n",
      "\tvalidation 2-857: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-858: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 2-859: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 2-860: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-861: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-862: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-863: Loss: 0.0060 Acc: 90.0000%\n",
      "\tvalidation 2-864: Loss: 0.0034 Acc: 93.3333%\n",
      "\tvalidation 2-865: Loss: 0.0193 Acc: 93.3333%\n",
      "\tvalidation 2-866: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-867: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-868: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 2-869: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 2-870: Loss: 0.0115 Acc: 96.6667%\n",
      "\tvalidation 2-871: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 2-872: Loss: 0.0191 Acc: 90.0000%\n",
      "\tvalidation 2-873: Loss: 0.0109 Acc: 93.3333%\n",
      "\tvalidation 2-874: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-875: Loss: 0.0323 Acc: 80.0000%\n",
      "\tvalidation 2-876: Loss: 0.0094 Acc: 93.3333%\n",
      "\tvalidation 2-877: Loss: 0.0228 Acc: 90.0000%\n",
      "\tvalidation 2-878: Loss: 0.0126 Acc: 86.6667%\n",
      "\tvalidation 2-879: Loss: 0.0203 Acc: 93.3333%\n",
      "\tvalidation 2-880: Loss: 0.0222 Acc: 83.3333%\n",
      "\tvalidation 2-881: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 2-882: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 2-883: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 2-884: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 2-885: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 2-886: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-887: Loss: 0.0202 Acc: 90.0000%\n",
      "\tvalidation 2-888: Loss: 0.0152 Acc: 90.0000%\n",
      "\tvalidation 2-889: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 2-890: Loss: 0.0275 Acc: 86.6667%\n",
      "\tvalidation 2-891: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 2-892: Loss: 0.0227 Acc: 90.0000%\n",
      "\tvalidation 2-893: Loss: 0.0064 Acc: 90.0000%\n",
      "\tvalidation 2-894: Loss: 0.0152 Acc: 90.0000%\n",
      "\tvalidation 2-895: Loss: 0.0252 Acc: 86.6667%\n",
      "\tvalidation 2-896: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 2-897: Loss: 0.0342 Acc: 83.3333%\n",
      "\tvalidation 2-898: Loss: 0.0084 Acc: 96.6667%\n",
      "\tvalidation 2-899: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 2-900: Loss: 0.0088 Acc: 93.3333%\n",
      "\tvalidation 2-901: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-902: Loss: 0.0028 Acc: 93.3333%\n",
      "\tvalidation 2-903: Loss: 0.0134 Acc: 90.0000%\n",
      "\tvalidation 2-904: Loss: 0.0176 Acc: 90.0000%\n",
      "\tvalidation 2-905: Loss: 0.0134 Acc: 90.0000%\n",
      "\tvalidation 2-906: Loss: 0.0178 Acc: 86.6667%\n",
      "\tvalidation 2-907: Loss: 0.0298 Acc: 80.0000%\n",
      "\tvalidation 2-908: Loss: 0.0323 Acc: 86.6667%\n",
      "\tvalidation 2-909: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 2-910: Loss: 0.0163 Acc: 86.6667%\n",
      "\tvalidation 2-911: Loss: 0.0234 Acc: 93.3333%\n",
      "\tvalidation 2-912: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-913: Loss: 0.0149 Acc: 90.0000%\n",
      "\tvalidation 2-914: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 2-915: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-916: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-917: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-918: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 2-919: Loss: 0.0097 Acc: 96.6667%\n",
      "\tvalidation 2-920: Loss: 0.0058 Acc: 96.6667%\n",
      "\tvalidation 2-921: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 2-922: Loss: 0.0189 Acc: 86.6667%\n",
      "\tvalidation 2-923: Loss: 0.0064 Acc: 90.0000%\n",
      "\tvalidation 2-924: Loss: 0.0235 Acc: 90.0000%\n",
      "\tvalidation 2-925: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 2-926: Loss: 0.0165 Acc: 86.6667%\n",
      "\tvalidation 2-927: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 2-928: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 2-929: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 2-930: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-931: Loss: 0.0164 Acc: 90.0000%\n",
      "\tvalidation 2-932: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-933: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-934: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 2-935: Loss: 0.0255 Acc: 83.3333%\n",
      "\tvalidation 2-936: Loss: 0.0115 Acc: 93.3333%\n",
      "\tvalidation 2-937: Loss: 0.0237 Acc: 90.0000%\n",
      "\tvalidation 2-938: Loss: 0.0139 Acc: 90.0000%\n",
      "\tvalidation 2-939: Loss: 0.0146 Acc: 83.3333%\n",
      "\tvalidation 2-940: Loss: 0.0109 Acc: 90.0000%\n",
      "\tvalidation 2-941: Loss: 0.0392 Acc: 86.6667%\n",
      "\tvalidation 2-942: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-943: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-944: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-945: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-946: Loss: 0.0101 Acc: 93.3333%\n",
      "\tvalidation 2-947: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 2-948: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 2-949: Loss: 0.0169 Acc: 83.3333%\n",
      "\tvalidation 2-950: Loss: 0.0257 Acc: 83.3333%\n",
      "\tvalidation 2-951: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 2-952: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-953: Loss: 0.0080 Acc: 93.3333%\n",
      "\tvalidation 2-954: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 2-955: Loss: 0.0301 Acc: 83.3333%\n",
      "\tvalidation 2-956: Loss: 0.0160 Acc: 90.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-957: Loss: 0.0207 Acc: 83.3333%\n",
      "\tvalidation 2-958: Loss: 0.0200 Acc: 90.0000%\n",
      "\tvalidation 2-959: Loss: 0.0088 Acc: 90.0000%\n",
      "\tvalidation 2-960: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 2-961: Loss: 0.0027 Acc: 93.3333%\n",
      "\tvalidation 2-962: Loss: 0.0303 Acc: 86.6667%\n",
      "\tvalidation 2-963: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-964: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 2-965: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 2-966: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-967: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 2-968: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 2-969: Loss: 0.0108 Acc: 93.3333%\n",
      "\tvalidation 2-970: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-971: Loss: 0.0260 Acc: 93.3333%\n",
      "\tvalidation 2-972: Loss: 0.0202 Acc: 93.3333%\n",
      "\tvalidation 2-973: Loss: 0.0182 Acc: 90.0000%\n",
      "\tvalidation 2-974: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-975: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 2-976: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-977: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 2-978: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 2-979: Loss: 0.0097 Acc: 90.0000%\n",
      "\tvalidation 2-980: Loss: 0.0421 Acc: 80.0000%\n",
      "\tvalidation 2-981: Loss: 0.0058 Acc: 96.6667%\n",
      "\tvalidation 2-982: Loss: 0.0195 Acc: 86.6667%\n",
      "\tvalidation 2-983: Loss: 0.0116 Acc: 86.6667%\n",
      "\tvalidation 2-984: Loss: 0.0095 Acc: 93.3333%\n",
      "\tvalidation 2-985: Loss: 0.0125 Acc: 90.0000%\n",
      "\tvalidation 2-986: Loss: 0.0074 Acc: 96.6667%\n",
      "\tvalidation 2-987: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-988: Loss: 0.0129 Acc: 90.0000%\n",
      "\tvalidation 2-989: Loss: 0.0128 Acc: 90.0000%\n",
      "\tvalidation 2-990: Loss: 0.0423 Acc: 73.3333%\n",
      "\tvalidation 2-991: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 2-992: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 2-993: Loss: 0.0161 Acc: 86.6667%\n",
      "\tvalidation 2-994: Loss: 0.0297 Acc: 86.6667%\n",
      "\tvalidation 2-995: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 2-996: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-997: Loss: 0.0122 Acc: 86.6667%\n",
      "\tvalidation 2-998: Loss: 0.0145 Acc: 93.3333%\n",
      "\tvalidation 2-999: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 2-1000: Loss: 0.0077 Acc: 90.0000%\n",
      "\tvalidation 2-1001: Loss: 0.0474 Acc: 83.3333%\n",
      "\tvalidation 2-1002: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 2-1003: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 2-1004: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 2-1005: Loss: 0.0275 Acc: 90.0000%\n",
      "\tvalidation 2-1006: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-1007: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 2-1008: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-1009: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 2-1010: Loss: 0.0225 Acc: 90.0000%\n",
      "\tvalidation 2-1011: Loss: 0.0302 Acc: 76.6667%\n",
      "\tvalidation 2-1012: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 2-1013: Loss: 0.0127 Acc: 93.3333%\n",
      "\tvalidation 2-1014: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 2-1015: Loss: 0.0259 Acc: 90.0000%\n",
      "\tvalidation 2-1016: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 2-1017: Loss: 0.0045 Acc: 93.3333%\n",
      "\tvalidation 2-1018: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 2-1019: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-1020: Loss: 0.0209 Acc: 90.0000%\n",
      "\tvalidation 2-1021: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 2-1022: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-1023: Loss: 0.0194 Acc: 90.0000%\n",
      "\tvalidation 2-1024: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 2-1025: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-1026: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-1027: Loss: 0.0201 Acc: 90.0000%\n",
      "\tvalidation 2-1028: Loss: 0.0015 Acc: 100.0000%\n",
      "\tvalidation 2-1029: Loss: 0.0236 Acc: 86.6667%\n",
      "\tvalidation 2-1030: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 2-1031: Loss: 0.0128 Acc: 96.6667%\n",
      "\tvalidation 2-1032: Loss: 0.0350 Acc: 86.6667%\n",
      "\tvalidation 2-1033: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-1034: Loss: 0.0129 Acc: 93.3333%\n",
      "\tvalidation 2-1035: Loss: 0.0158 Acc: 93.3333%\n",
      "\tvalidation 2-1036: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 2-1037: Loss: 0.0178 Acc: 96.6667%\n",
      "\tvalidation 2-1038: Loss: 0.0240 Acc: 90.0000%\n",
      "\tvalidation 2-1039: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 2-1040: Loss: 0.0228 Acc: 90.0000%\n",
      "\tvalidation 2-1041: Loss: 0.0141 Acc: 93.3333%\n",
      "\tvalidation 2-1042: Loss: 0.0043 Acc: 90.0000%\n",
      "\tvalidation 2-1043: Loss: 0.0114 Acc: 90.0000%\n",
      "\tvalidation 2-1044: Loss: 0.0130 Acc: 93.3333%\n",
      "\tvalidation 2-1045: Loss: 0.0262 Acc: 83.3333%\n",
      "\tvalidation 2-1046: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 2-1047: Loss: 0.0246 Acc: 86.6667%\n",
      "\tvalidation 2-1048: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 2-1049: Loss: 0.0056 Acc: 90.0000%\n",
      "\tvalidation 2-1050: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 2-1051: Loss: 0.0187 Acc: 93.3333%\n",
      "\tvalidation 2-1052: Loss: 0.0309 Acc: 80.0000%\n",
      "\tvalidation 2-1053: Loss: 0.0119 Acc: 90.0000%\n",
      "\tvalidation 2-1054: Loss: 0.0109 Acc: 96.6667%\n",
      "\tvalidation 2-1055: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 2-1056: Loss: 0.0134 Acc: 90.0000%\n",
      "\tvalidation 2-1057: Loss: 0.0114 Acc: 93.3333%\n",
      "\tvalidation 2-1058: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 2-1059: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 2-1060: Loss: 0.0082 Acc: 93.3333%\n",
      "\tvalidation 2-1061: Loss: 0.0241 Acc: 83.3333%\n",
      "\tvalidation 2-1062: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 2-1063: Loss: 0.0058 Acc: 96.6667%\n",
      "\tvalidation 2-1064: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 2-1065: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 2-1066: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-1067: Loss: 0.0052 Acc: 96.6667%\n",
      "\tvalidation 2-1068: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 2-1069: Loss: 0.0112 Acc: 90.0000%\n",
      "\tvalidation 2-1070: Loss: 0.0115 Acc: 90.0000%\n",
      "\tvalidation 2-1071: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 2-1072: Loss: 0.0224 Acc: 90.0000%\n",
      "\tvalidation 2-1073: Loss: 0.0140 Acc: 93.3333%\n",
      "\tvalidation 2-1074: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 2-1075: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 2-1076: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 2-1077: Loss: 0.0071 Acc: 96.6667%\n",
      "\tvalidation 2-1078: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 2-1079: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 2-1080: Loss: 0.0231 Acc: 90.0000%\n",
      "\tvalidation 2-1081: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 2-1082: Loss: 0.0167 Acc: 86.6667%\n",
      "\tvalidation 2-1083: Loss: 0.0059 Acc: 90.0000%\n",
      "\tvalidation 2-1084: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-1085: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 2-1086: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-1087: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-1088: Loss: 0.0340 Acc: 90.0000%\n",
      "\tvalidation 2-1089: Loss: 0.0331 Acc: 86.6667%\n",
      "\tvalidation 2-1090: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 2-1091: Loss: 0.0125 Acc: 93.3333%\n",
      "\tvalidation 2-1092: Loss: 0.0163 Acc: 86.6667%\n",
      "\tvalidation 2-1093: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-1094: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 2-1095: Loss: 0.0075 Acc: 93.3333%\n",
      "\tvalidation 2-1096: Loss: 0.0104 Acc: 96.6667%\n",
      "\tvalidation 2-1097: Loss: 0.0118 Acc: 96.6667%\n",
      "\tvalidation 2-1098: Loss: 0.0254 Acc: 90.0000%\n",
      "\tvalidation 2-1099: Loss: 0.0068 Acc: 93.3333%\n",
      "\tvalidation 2-1100: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 2-1101: Loss: 0.0013 Acc: 100.0000%\n",
      "\tvalidation 2-1102: Loss: 0.0093 Acc: 86.6667%\n",
      "\tvalidation 2-1103: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-1104: Loss: 0.0440 Acc: 76.6667%\n",
      "\tvalidation 2-1105: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-1106: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 2-1107: Loss: 0.0077 Acc: 90.0000%\n",
      "\tvalidation 2-1108: Loss: 0.0080 Acc: 93.3333%\n",
      "\tvalidation 2-1109: Loss: 0.0077 Acc: 90.0000%\n",
      "\tvalidation 2-1110: Loss: 0.0083 Acc: 96.6667%\n",
      "\tvalidation 2-1111: Loss: 0.0171 Acc: 93.3333%\n",
      "\tvalidation 2-1112: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 2-1113: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-1114: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 2-1115: Loss: 0.0266 Acc: 90.0000%\n",
      "\tvalidation 2-1116: Loss: 0.0106 Acc: 93.3333%\n",
      "\tvalidation 2-1117: Loss: 0.0120 Acc: 86.6667%\n",
      "\tvalidation 2-1118: Loss: 0.0130 Acc: 93.3333%\n",
      "\tvalidation 2-1119: Loss: 0.0124 Acc: 93.3333%\n",
      "\tvalidation 2-1120: Loss: 0.0083 Acc: 96.6667%\n",
      "\tvalidation 2-1121: Loss: 0.0084 Acc: 90.0000%\n",
      "\tvalidation 2-1122: Loss: 0.0129 Acc: 93.3333%\n",
      "\tvalidation 2-1123: Loss: 0.0085 Acc: 96.6667%\n",
      "\tvalidation 2-1124: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 2-1125: Loss: 0.0145 Acc: 93.3333%\n",
      "\tvalidation 2-1126: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 2-1127: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 2-1128: Loss: 0.0140 Acc: 93.3333%\n",
      "\tvalidation 2-1129: Loss: 0.0093 Acc: 90.0000%\n",
      "\tvalidation 2-1130: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-1131: Loss: 0.0230 Acc: 86.6667%\n",
      "\tvalidation 2-1132: Loss: 0.0002 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-1133: Loss: 0.0192 Acc: 86.6667%\n",
      "\tvalidation 2-1134: Loss: 0.0052 Acc: 96.6667%\n",
      "\tvalidation 2-1135: Loss: 0.0055 Acc: 93.3333%\n",
      "\tvalidation 2-1136: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-1137: Loss: 0.0518 Acc: 73.3333%\n",
      "\tvalidation 2-1138: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 2-1139: Loss: 0.0207 Acc: 90.0000%\n",
      "\tvalidation 2-1140: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-1141: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 2-1142: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-1143: Loss: 0.0124 Acc: 86.6667%\n",
      "\tvalidation 2-1144: Loss: 0.0132 Acc: 90.0000%\n",
      "\tvalidation 2-1145: Loss: 0.0115 Acc: 90.0000%\n",
      "\tvalidation 2-1146: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 2-1147: Loss: 0.0204 Acc: 86.6667%\n",
      "\tvalidation 2-1148: Loss: 0.0120 Acc: 93.3333%\n",
      "\tvalidation 2-1149: Loss: 0.0151 Acc: 90.0000%\n",
      "\tvalidation 2-1150: Loss: 0.0022 Acc: 93.3333%\n",
      "\tvalidation 2-1151: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 2-1152: Loss: 0.0110 Acc: 93.3333%\n",
      "\tvalidation 2-1153: Loss: 0.0186 Acc: 90.0000%\n",
      "\tvalidation 2-1154: Loss: 0.0076 Acc: 93.3333%\n",
      "\tvalidation 2-1155: Loss: 0.0282 Acc: 90.0000%\n",
      "\tvalidation 2-1156: Loss: 0.0250 Acc: 93.3333%\n",
      "\tvalidation 2-1157: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 2-1158: Loss: 0.0076 Acc: 90.0000%\n",
      "\tvalidation 2-1159: Loss: 0.0132 Acc: 90.0000%\n",
      "\tvalidation 2-1160: Loss: 0.0131 Acc: 90.0000%\n",
      "\tvalidation 2-1161: Loss: 0.0118 Acc: 90.0000%\n",
      "\tvalidation 2-1162: Loss: 0.0238 Acc: 90.0000%\n",
      "\tvalidation 2-1163: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 2-1164: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 2-1165: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 2-1166: Loss: 0.0160 Acc: 93.3333%\n",
      "\tvalidation 2-1167: Loss: 0.0117 Acc: 93.3333%\n",
      "\tvalidation 2-1168: Loss: 0.0069 Acc: 96.6667%\n",
      "\tvalidation 2-1169: Loss: 0.0160 Acc: 83.3333%\n",
      "\tvalidation 2-1170: Loss: 0.0100 Acc: 96.6667%\n",
      "\tvalidation 2-1171: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 2-1172: Loss: 0.0090 Acc: 93.3333%\n",
      "\tvalidation 2-1173: Loss: 0.0167 Acc: 90.0000%\n",
      "\tvalidation 2-1174: Loss: 0.0154 Acc: 93.3333%\n",
      "\tvalidation 2-1175: Loss: 0.0038 Acc: 93.3333%\n",
      "\tvalidation 2-1176: Loss: 0.0197 Acc: 86.6667%\n",
      "\tvalidation 2-1177: Loss: 0.0048 Acc: 93.3333%\n",
      "\tvalidation 2-1178: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 2-1179: Loss: 0.0158 Acc: 90.0000%\n",
      "\tvalidation 2-1180: Loss: 0.0079 Acc: 93.3333%\n",
      "\tvalidation 2-1181: Loss: 0.0224 Acc: 93.3333%\n",
      "\tvalidation 2-1182: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 2-1183: Loss: 0.0241 Acc: 90.0000%\n",
      "\tvalidation 2-1184: Loss: 0.0162 Acc: 90.0000%\n",
      "\tvalidation 2-1185: Loss: 0.0188 Acc: 86.6667%\n",
      "\tvalidation 2-1186: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 2-1187: Loss: 0.0022 Acc: 100.0000%\n",
      "\tvalidation 2-1188: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 2-1189: Loss: 0.0154 Acc: 93.3333%\n",
      "\tvalidation 2-1190: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-1191: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-1192: Loss: 0.0153 Acc: 93.3333%\n",
      "\tvalidation 2-1193: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 2-1194: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 2-1195: Loss: 0.0187 Acc: 93.3333%\n",
      "\tvalidation 2-1196: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 2-1197: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-1198: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 2-1199: Loss: 0.0242 Acc: 86.6667%\n",
      "\tvalidation 2-1200: Loss: 0.0212 Acc: 90.0000%\n",
      "\tvalidation 2-1201: Loss: 0.0147 Acc: 86.6667%\n",
      "\tvalidation 2-1202: Loss: 0.0087 Acc: 93.3333%\n",
      "\tvalidation 2-1203: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 2-1204: Loss: 0.0373 Acc: 80.0000%\n",
      "\tvalidation 2-1205: Loss: 0.0140 Acc: 93.3333%\n",
      "\tvalidation 2-1206: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 2-1207: Loss: 0.0132 Acc: 90.0000%\n",
      "\tvalidation 2-1208: Loss: 0.0151 Acc: 90.0000%\n",
      "\tvalidation 2-1209: Loss: 0.0115 Acc: 93.3333%\n",
      "\tvalidation 2-1210: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 2-1211: Loss: 0.0370 Acc: 80.0000%\n",
      "\tvalidation 2-1212: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 2-1213: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-1214: Loss: 0.0091 Acc: 96.6667%\n",
      "\tvalidation 2-1215: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 2-1216: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 2-1217: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 2-1218: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 2-1219: Loss: 0.0124 Acc: 86.6667%\n",
      "\tvalidation 2-1220: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 2-1221: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1222: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 2-1223: Loss: 0.0201 Acc: 90.0000%\n",
      "\tvalidation 2-1224: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 2-1225: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 2-1226: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-1227: Loss: 0.0116 Acc: 93.3333%\n",
      "\tvalidation 2-1228: Loss: 0.0153 Acc: 90.0000%\n",
      "\tvalidation 2-1229: Loss: 0.0151 Acc: 90.0000%\n",
      "\tvalidation 2-1230: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 2-1231: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 2-1232: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 2-1233: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-1234: Loss: 0.0042 Acc: 93.3333%\n",
      "\tvalidation 2-1235: Loss: 0.0059 Acc: 86.6667%\n",
      "\tvalidation 2-1236: Loss: 0.0116 Acc: 93.3333%\n",
      "\tvalidation 2-1237: Loss: 0.0232 Acc: 90.0000%\n",
      "\tvalidation 2-1238: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 2-1239: Loss: 0.0153 Acc: 83.3333%\n",
      "\tvalidation 2-1240: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-1241: Loss: 0.0326 Acc: 90.0000%\n",
      "\tvalidation 2-1242: Loss: 0.0129 Acc: 90.0000%\n",
      "\tvalidation 2-1243: Loss: 0.0076 Acc: 96.6667%\n",
      "\tvalidation 2-1244: Loss: 0.0102 Acc: 90.0000%\n",
      "\tvalidation 2-1245: Loss: 0.0139 Acc: 93.3333%\n",
      "\tvalidation 2-1246: Loss: 0.0125 Acc: 93.3333%\n",
      "\tvalidation 2-1247: Loss: 0.0090 Acc: 90.0000%\n",
      "\tvalidation 2-1248: Loss: 0.0022 Acc: 93.3333%\n",
      "\tvalidation 2-1249: Loss: 0.0295 Acc: 86.6667%\n",
      "\tvalidation 2-1250: Loss: 0.0217 Acc: 90.0000%\n",
      "\tvalidation 2-1251: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-1252: Loss: 0.0117 Acc: 96.6667%\n",
      "\tvalidation 2-1253: Loss: 0.0215 Acc: 90.0000%\n",
      "\tvalidation 2-1254: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-1255: Loss: 0.0160 Acc: 93.3333%\n",
      "\tvalidation 2-1256: Loss: 0.0060 Acc: 90.0000%\n",
      "\tvalidation 2-1257: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 2-1258: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-1259: Loss: 0.0114 Acc: 96.6667%\n",
      "\tvalidation 2-1260: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-1261: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 2-1262: Loss: 0.0232 Acc: 80.0000%\n",
      "\tvalidation 2-1263: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 2-1264: Loss: 0.0185 Acc: 90.0000%\n",
      "\tvalidation 2-1265: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 2-1266: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-1267: Loss: 0.0188 Acc: 90.0000%\n",
      "\tvalidation 2-1268: Loss: 0.0073 Acc: 90.0000%\n",
      "\tvalidation 2-1269: Loss: 0.0042 Acc: 90.0000%\n",
      "\tvalidation 2-1270: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 2-1271: Loss: 0.0179 Acc: 86.6667%\n",
      "\tvalidation 2-1272: Loss: 0.0050 Acc: 90.0000%\n",
      "\tvalidation 2-1273: Loss: 0.0174 Acc: 93.3333%\n",
      "\tvalidation 2-1274: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-1275: Loss: 0.0101 Acc: 90.0000%\n",
      "\tvalidation 2-1276: Loss: 0.0269 Acc: 80.0000%\n",
      "\tvalidation 2-1277: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 2-1278: Loss: 0.0277 Acc: 76.6667%\n",
      "\tvalidation 2-1279: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 2-1280: Loss: 0.0192 Acc: 90.0000%\n",
      "\tvalidation 2-1281: Loss: 0.0271 Acc: 83.3333%\n",
      "\tvalidation 2-1282: Loss: 0.0079 Acc: 90.0000%\n",
      "\tvalidation 2-1283: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 2-1284: Loss: 0.0341 Acc: 83.3333%\n",
      "\tvalidation 2-1285: Loss: 0.0058 Acc: 90.0000%\n",
      "\tvalidation 2-1286: Loss: 0.0166 Acc: 86.6667%\n",
      "\tvalidation 2-1287: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 2-1288: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 2-1289: Loss: 0.0061 Acc: 90.0000%\n",
      "\tvalidation 2-1290: Loss: 0.0069 Acc: 90.0000%\n",
      "\tvalidation 2-1291: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 2-1292: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 2-1293: Loss: 0.0109 Acc: 90.0000%\n",
      "\tvalidation 2-1294: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 2-1295: Loss: 0.0235 Acc: 90.0000%\n",
      "\tvalidation 2-1296: Loss: 0.0181 Acc: 90.0000%\n",
      "\tvalidation 2-1297: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-1298: Loss: 0.0134 Acc: 83.3333%\n",
      "\tvalidation 2-1299: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 2-1300: Loss: 0.0115 Acc: 93.3333%\n",
      "\tvalidation 2-1301: Loss: 0.0152 Acc: 90.0000%\n",
      "\tvalidation 2-1302: Loss: 0.0240 Acc: 83.3333%\n",
      "\tvalidation 2-1303: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-1304: Loss: 0.0180 Acc: 90.0000%\n",
      "\tvalidation 2-1305: Loss: 0.0055 Acc: 93.3333%\n",
      "\tvalidation 2-1306: Loss: 0.0220 Acc: 86.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-1307: Loss: 0.0151 Acc: 86.6667%\n",
      "\tvalidation 2-1308: Loss: 0.0045 Acc: 93.3333%\n",
      "\tvalidation 2-1309: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 2-1310: Loss: 0.0079 Acc: 90.0000%\n",
      "\tvalidation 2-1311: Loss: 0.0046 Acc: 93.3333%\n",
      "\tvalidation 2-1312: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 2-1313: Loss: 0.0046 Acc: 93.3333%\n",
      "\tvalidation 2-1314: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 2-1315: Loss: 0.0019 Acc: 93.3333%\n",
      "\tvalidation 2-1316: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 2-1317: Loss: 0.0050 Acc: 93.3333%\n",
      "\tvalidation 2-1318: Loss: 0.0052 Acc: 90.0000%\n",
      "\tvalidation 2-1319: Loss: 0.0141 Acc: 90.0000%\n",
      "\tvalidation 2-1320: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 2-1321: Loss: 0.0323 Acc: 80.0000%\n",
      "\tvalidation 2-1322: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 2-1323: Loss: 0.0071 Acc: 93.3333%\n",
      "\tvalidation 2-1324: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 2-1325: Loss: 0.0175 Acc: 83.3333%\n",
      "\tvalidation 2-1326: Loss: 0.0101 Acc: 96.6667%\n",
      "\tvalidation 2-1327: Loss: 0.0201 Acc: 86.6667%\n",
      "\tvalidation 2-1328: Loss: 0.0100 Acc: 90.0000%\n",
      "\tvalidation 2-1329: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1330: Loss: 0.0203 Acc: 86.6667%\n",
      "\tvalidation 2-1331: Loss: 0.0139 Acc: 93.3333%\n",
      "\tvalidation 2-1332: Loss: 0.0056 Acc: 93.3333%\n",
      "\tvalidation 2-1333: Loss: 0.0249 Acc: 86.6667%\n",
      "\tvalidation 2-1334: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 2-1335: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-1336: Loss: 0.0198 Acc: 86.6667%\n",
      "\tvalidation 2-1337: Loss: 0.0106 Acc: 96.6667%\n",
      "\tvalidation 2-1338: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 2-1339: Loss: 0.0167 Acc: 93.3333%\n",
      "\tvalidation 2-1340: Loss: 0.0192 Acc: 86.6667%\n",
      "\tvalidation 2-1341: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 2-1342: Loss: 0.0117 Acc: 93.3333%\n",
      "\tvalidation 2-1343: Loss: 0.0190 Acc: 93.3333%\n",
      "\tvalidation 2-1344: Loss: 0.0100 Acc: 96.6667%\n",
      "\tvalidation 2-1345: Loss: 0.0190 Acc: 86.6667%\n",
      "\tvalidation 2-1346: Loss: 0.0076 Acc: 96.6667%\n",
      "\tvalidation 2-1347: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 2-1348: Loss: 0.0145 Acc: 90.0000%\n",
      "\tvalidation 2-1349: Loss: 0.0106 Acc: 86.6667%\n",
      "\tvalidation 2-1350: Loss: 0.0198 Acc: 90.0000%\n",
      "\tvalidation 2-1351: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 2-1352: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1353: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1354: Loss: 0.0311 Acc: 80.0000%\n",
      "\tvalidation 2-1355: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 2-1356: Loss: 0.0409 Acc: 83.3333%\n",
      "\tvalidation 2-1357: Loss: 0.0174 Acc: 90.0000%\n",
      "\tvalidation 2-1358: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 2-1359: Loss: 0.0078 Acc: 90.0000%\n",
      "\tvalidation 2-1360: Loss: 0.0208 Acc: 83.3333%\n",
      "\tvalidation 2-1361: Loss: 0.0254 Acc: 86.6667%\n",
      "\tvalidation 2-1362: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 2-1363: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 2-1364: Loss: 0.0009 Acc: 96.6667%\n",
      "\tvalidation 2-1365: Loss: 0.0199 Acc: 90.0000%\n",
      "\tvalidation 2-1366: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 2-1367: Loss: 0.0296 Acc: 86.6667%\n",
      "\tvalidation 2-1368: Loss: 0.0083 Acc: 93.3333%\n",
      "\tvalidation 2-1369: Loss: 0.0203 Acc: 83.3333%\n",
      "\tvalidation 2-1370: Loss: 0.0412 Acc: 83.3333%\n",
      "\tvalidation 2-1371: Loss: 0.0102 Acc: 93.3333%\n",
      "\tvalidation 2-1372: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-1373: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 2-1374: Loss: 0.0227 Acc: 86.6667%\n",
      "\tvalidation 2-1375: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 2-1376: Loss: 0.0047 Acc: 93.3333%\n",
      "\tvalidation 2-1377: Loss: 0.0354 Acc: 86.6667%\n",
      "\tvalidation 2-1378: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 2-1379: Loss: 0.0078 Acc: 96.6667%\n",
      "\tvalidation 2-1380: Loss: 0.0178 Acc: 83.3333%\n",
      "\tvalidation 2-1381: Loss: 0.0218 Acc: 86.6667%\n",
      "\tvalidation 2-1382: Loss: 0.0111 Acc: 96.6667%\n",
      "\tvalidation 2-1383: Loss: 0.0109 Acc: 93.3333%\n",
      "\tvalidation 2-1384: Loss: 0.0098 Acc: 96.6667%\n",
      "\tvalidation 2-1385: Loss: 0.0084 Acc: 96.6667%\n",
      "\tvalidation 2-1386: Loss: 0.0244 Acc: 93.3333%\n",
      "\tvalidation 2-1387: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 2-1388: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 2-1389: Loss: 0.0103 Acc: 93.3333%\n",
      "\tvalidation 2-1390: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 2-1391: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 2-1392: Loss: 0.0269 Acc: 90.0000%\n",
      "\tvalidation 2-1393: Loss: 0.0120 Acc: 93.3333%\n",
      "\tvalidation 2-1394: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1395: Loss: 0.0054 Acc: 90.0000%\n",
      "\tvalidation 2-1396: Loss: 0.0098 Acc: 86.6667%\n",
      "\tvalidation 2-1397: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 2-1398: Loss: 0.0069 Acc: 93.3333%\n",
      "\tvalidation 2-1399: Loss: 0.0124 Acc: 93.3333%\n",
      "\tvalidation 2-1400: Loss: 0.0163 Acc: 90.0000%\n",
      "\tvalidation 2-1401: Loss: 0.0279 Acc: 86.6667%\n",
      "\tvalidation 2-1402: Loss: 0.0099 Acc: 90.0000%\n",
      "\tvalidation 2-1403: Loss: 0.0049 Acc: 90.0000%\n",
      "\tvalidation 2-1404: Loss: 0.0103 Acc: 93.3333%\n",
      "\tvalidation 2-1405: Loss: 0.0217 Acc: 86.6667%\n",
      "\tvalidation 2-1406: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 2-1407: Loss: 0.0150 Acc: 90.0000%\n",
      "\tvalidation 2-1408: Loss: 0.0139 Acc: 86.6667%\n",
      "\tvalidation 2-1409: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 2-1410: Loss: 0.0252 Acc: 86.6667%\n",
      "\tvalidation 2-1411: Loss: 0.0152 Acc: 86.6667%\n",
      "\tvalidation 2-1412: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 2-1413: Loss: 0.0165 Acc: 90.0000%\n",
      "\tvalidation 2-1414: Loss: 0.0083 Acc: 93.3333%\n",
      "\tvalidation 2-1415: Loss: 0.0251 Acc: 83.3333%\n",
      "\tvalidation 2-1416: Loss: 0.0193 Acc: 93.3333%\n",
      "\tvalidation 2-1417: Loss: 0.0041 Acc: 93.3333%\n",
      "\tvalidation 2-1418: Loss: 0.0271 Acc: 80.0000%\n",
      "\tvalidation 2-1419: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-1420: Loss: 0.0279 Acc: 90.0000%\n",
      "\tvalidation 2-1421: Loss: 0.0166 Acc: 90.0000%\n",
      "\tvalidation 2-1422: Loss: 0.0077 Acc: 93.3333%\n",
      "\tvalidation 2-1423: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-1424: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 2-1425: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 2-1426: Loss: 0.0123 Acc: 93.3333%\n",
      "\tvalidation 2-1427: Loss: 0.0064 Acc: 93.3333%\n",
      "\tvalidation 2-1428: Loss: 0.0122 Acc: 90.0000%\n",
      "\tvalidation 2-1429: Loss: 0.0121 Acc: 90.0000%\n",
      "\tvalidation 2-1430: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 2-1431: Loss: 0.0189 Acc: 90.0000%\n",
      "\tvalidation 2-1432: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 2-1433: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 2-1434: Loss: 0.0221 Acc: 90.0000%\n",
      "\tvalidation 2-1435: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 2-1436: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-1437: Loss: 0.0336 Acc: 90.0000%\n",
      "\tvalidation 2-1438: Loss: 0.0066 Acc: 96.6667%\n",
      "\tvalidation 2-1439: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 2-1440: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 2-1441: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 2-1442: Loss: 0.0249 Acc: 90.0000%\n",
      "\tvalidation 2-1443: Loss: 0.0163 Acc: 86.6667%\n",
      "\tvalidation 2-1444: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 2-1445: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-1446: Loss: 0.0224 Acc: 90.0000%\n",
      "\tvalidation 2-1447: Loss: 0.0091 Acc: 90.0000%\n",
      "\tvalidation 2-1448: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 2-1449: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 2-1450: Loss: 0.0151 Acc: 93.3333%\n",
      "\tvalidation 2-1451: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 2-1452: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 2-1453: Loss: 0.0119 Acc: 86.6667%\n",
      "\tvalidation 2-1454: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 2-1455: Loss: 0.0219 Acc: 86.6667%\n",
      "\tvalidation 2-1456: Loss: 0.0052 Acc: 93.3333%\n",
      "\tvalidation 2-1457: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 2-1458: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 2-1459: Loss: 0.0105 Acc: 90.0000%\n",
      "\tvalidation 2-1460: Loss: 0.0090 Acc: 96.6667%\n",
      "\tvalidation 2-1461: Loss: 0.0415 Acc: 66.6667%\n",
      "\tvalidation 2-1462: Loss: 0.0214 Acc: 93.3333%\n",
      "\tvalidation 2-1463: Loss: 0.0153 Acc: 93.3333%\n",
      "\tvalidation 2-1464: Loss: 0.0031 Acc: 93.3333%\n",
      "\tvalidation 2-1465: Loss: 0.0201 Acc: 83.3333%\n",
      "\tvalidation 2-1466: Loss: 0.0205 Acc: 80.0000%\n",
      "\tvalidation 2-1467: Loss: 0.0072 Acc: 93.3333%\n",
      "\tvalidation 2-1468: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 2-1469: Loss: 0.0025 Acc: 93.3333%\n",
      "\tvalidation 2-1470: Loss: 0.0178 Acc: 93.3333%\n",
      "\tvalidation 2-1471: Loss: 0.0180 Acc: 93.3333%\n",
      "\tvalidation 2-1472: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 2-1473: Loss: 0.0082 Acc: 90.0000%\n",
      "\tvalidation 2-1474: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 2-1475: Loss: 0.0189 Acc: 93.3333%\n",
      "\tvalidation 2-1476: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-1477: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 2-1478: Loss: 0.0165 Acc: 83.3333%\n",
      "\tvalidation 2-1479: Loss: 0.0016 Acc: 100.0000%\n",
      "\tvalidation 2-1480: Loss: 0.0291 Acc: 83.3333%\n",
      "\tvalidation 2-1481: Loss: 0.0090 Acc: 96.6667%\n",
      "\tvalidation 2-1482: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 2-1483: Loss: 0.0128 Acc: 96.6667%\n",
      "\tvalidation 2-1484: Loss: 0.0105 Acc: 96.6667%\n",
      "\tvalidation 2-1485: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 2-1486: Loss: 0.0322 Acc: 86.6667%\n",
      "\tvalidation 2-1487: Loss: 0.0168 Acc: 93.3333%\n",
      "\tvalidation 2-1488: Loss: 0.0094 Acc: 90.0000%\n",
      "\tvalidation 2-1489: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 2-1490: Loss: 0.0103 Acc: 93.3333%\n",
      "\tvalidation 2-1491: Loss: 0.0114 Acc: 93.3333%\n",
      "\tvalidation 2-1492: Loss: 0.0206 Acc: 86.6667%\n",
      "\tvalidation 2-1493: Loss: 0.0036 Acc: 93.3333%\n",
      "\tvalidation 2-1494: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 2-1495: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 2-1496: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 2-1497: Loss: 0.0029 Acc: 93.3333%\n",
      "\tvalidation 2-1498: Loss: 0.0183 Acc: 83.3333%\n",
      "\tvalidation 2-1499: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 2-1500: Loss: 0.0099 Acc: 90.0000%\n",
      "\ttrain Loss: 0.0014 Acc: 98.7222%\n",
      "\tvalidation Loss: 0.0107 Acc: 92.9333%\n",
      "Time passed 1h 40m 13s\n",
      "--------------------\n",
      "learning_rate: 0.01\n",
      "Epoch [3/10]:\n",
      "\ttrain 3-1: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-3: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-5: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-6: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 3-7: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-8: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-9: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-10: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 3-11: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-12: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 3-13: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-14: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-15: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-16: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-17: Loss: 0.0086 Acc: 93.3333%\n",
      "\ttrain 3-18: Loss: 0.0068 Acc: 96.6667%\n",
      "\ttrain 3-19: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 3-20: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 3-21: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-22: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-23: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-24: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-25: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-26: Loss: 0.0131 Acc: 96.6667%\n",
      "\ttrain 3-27: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-30: Loss: 0.0052 Acc: 93.3333%\n",
      "\ttrain 3-31: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 3-32: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 3-33: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-34: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-35: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-36: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-37: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-38: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-39: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-40: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-41: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-42: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-44: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-48: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-49: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-50: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-52: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-56: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-57: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-58: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-59: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-60: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-62: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 3-63: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-64: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-65: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-66: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-68: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-69: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-71: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-82: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-84: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-85: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-86: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-87: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-88: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-89: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-90: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-91: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-94: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-98: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-99: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 3-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-101: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-102: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 3-103: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-105: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-107: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-110: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-111: Loss: 0.0028 Acc: 93.3333%\n",
      "\ttrain 3-112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-114: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-116: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-120: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-124: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 3-125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-130: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 3-131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-132: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 3-133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-134: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-136: Loss: 0.0087 Acc: 96.6667%\n",
      "\ttrain 3-137: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-139: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-145: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-148: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-150: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-151: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-152: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-157: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-159: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-160: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-161: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 3-162: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-164: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-165: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-171: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-173: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 3-174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-175: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-177: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-179: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-181: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-182: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 3-183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-185: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-187: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-191: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-193: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-194: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-195: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 3-196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-197: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 3-198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-200: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 3-201: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-207: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-210: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-218: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-224: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-227: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-229: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-231: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-236: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-237: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-243: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-247: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-255: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-259: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-261: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 3-262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-266: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-267: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-268: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-272: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-273: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-274: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-277: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-280: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 3-281: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-290: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-291: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-293: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-294: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-302: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-303: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 3-304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-308: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-311: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-317: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-319: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-322: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-323: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-331: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-332: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-336: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-341: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-342: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-346: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-350: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-354: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-355: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-356: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-358: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-360: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 3-361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-368: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-371: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-376: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 3-377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-380: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-382: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 3-383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-384: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-385: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-386: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-391: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-393: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-395: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-396: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-399: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-403: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-408: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-409: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-410: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-411: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-412: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-413: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-414: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 3-415: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-416: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 3-417: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-418: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-419: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-421: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-426: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-430: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-431: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 3-432: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-437: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-439: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-442: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-443: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-445: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-446: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-449: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-453: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-455: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-458: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-463: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-465: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-466: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-468: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-469: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-471: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-472: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-473: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-475: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-477: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-478: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-480: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-481: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-487: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-489: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-490: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-494: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-500: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-501: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-502: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 3-503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-504: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-505: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-507: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-508: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-510: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-511: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-512: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-513: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-514: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-519: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-521: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 3-522: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-523: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-524: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-526: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-527: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-528: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-529: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-530: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-531: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-532: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-533: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-534: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-536: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-537: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-538: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-539: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-541: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-542: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-543: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-545: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-546: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-549: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-550: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-551: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-552: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-553: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-554: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-555: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-556: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-557: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-558: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-559: Loss: 0.0078 Acc: 93.3333%\n",
      "\ttrain 3-560: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-561: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 3-562: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-563: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-566: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-567: Loss: 0.0015 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-569: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-570: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-572: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-573: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-574: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-575: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-576: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-578: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-580: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-581: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-582: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-584: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-587: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-588: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-590: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-591: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-593: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-595: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-597: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 3-598: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 3-599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-600: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-603: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-606: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-607: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-609: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-610: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-612: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-613: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-615: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-616: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-617: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-618: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-619: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-620: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 3-621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-622: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-624: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 3-625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-628: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-629: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-630: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-631: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-632: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-633: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-634: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-635: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-636: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-637: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-638: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-639: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-640: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-641: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-642: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-643: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-644: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-645: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-646: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-648: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-649: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-651: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-652: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-653: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-656: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-657: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-658: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-660: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-661: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-663: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-665: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-666: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-667: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-668: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-670: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-671: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-672: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-673: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-674: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-675: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-678: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 3-679: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-680: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-681: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-684: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-686: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-687: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-688: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-689: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-690: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-691: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-696: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-697: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-698: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-699: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-700: Loss: 0.0152 Acc: 93.3333%\n",
      "\ttrain 3-701: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-704: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-705: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-706: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-707: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-708: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-709: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-710: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-711: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-713: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-714: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-716: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-717: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-719: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-721: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-722: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-723: Loss: 0.0061 Acc: 96.6667%\n",
      "\ttrain 3-724: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-725: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-727: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-728: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-729: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-730: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-731: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-733: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-734: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-735: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-736: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 3-737: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-738: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-739: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-741: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-742: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-743: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-744: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-745: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-746: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-747: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-748: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-749: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-750: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-751: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-752: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-753: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-754: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-755: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-756: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-757: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-758: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-759: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-760: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-761: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-762: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-763: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-764: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-765: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-767: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-768: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-769: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-772: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-773: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-775: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-777: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-778: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-783: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-785: Loss: 0.0067 Acc: 96.6667%\n",
      "\ttrain 3-786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-788: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-789: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-790: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-794: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-795: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-797: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-799: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-800: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-801: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-802: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-804: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-809: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-810: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-812: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-815: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-816: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-817: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-818: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-819: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-820: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-821: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-822: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-823: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-824: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-825: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-827: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-829: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-830: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-831: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-832: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-833: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-834: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-835: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-836: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-838: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-839: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-840: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-841: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-842: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-843: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-844: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-846: Loss: 0.0100 Acc: 96.6667%\n",
      "\ttrain 3-847: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-848: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-849: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-850: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-852: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-853: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-855: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-856: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-857: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-859: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-860: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-861: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-862: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-864: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-865: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-866: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-867: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-868: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-870: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-872: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-873: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-874: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 3-875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-878: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-879: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 3-880: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-881: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-882: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-884: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-885: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-886: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-887: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-889: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-890: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-891: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-892: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-893: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-896: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-898: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-905: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-907: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-908: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-910: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-911: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-914: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-915: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-916: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-917: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-918: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-921: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-924: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-925: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-926: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-928: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-929: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 3-930: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-931: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-932: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-933: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-934: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-935: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-937: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-939: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-940: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-942: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-944: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-945: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-946: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-947: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-948: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-949: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-950: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-951: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-953: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-954: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 3-955: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-958: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-959: Loss: 0.0047 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-960: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-961: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-962: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-964: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-965: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-966: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-969: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-970: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-973: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-978: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-979: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-982: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-984: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-987: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 3-988: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-989: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-990: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-992: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-994: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-995: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-996: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-998: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-999: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1000: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1001: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-1002: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1003: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1004: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1005: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1006: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1008: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1009: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1010: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1011: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1012: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1013: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1015: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1017: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1018: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1019: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1020: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 3-1021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1022: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1023: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1024: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1029: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1030: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 3-1031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1032: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1033: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1035: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1036: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1037: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1038: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1040: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1042: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1044: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1045: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1046: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1047: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1051: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1052: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-1053: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1054: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1055: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1056: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1057: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1058: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1059: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1060: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1062: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 3-1063: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1065: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1066: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1068: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1070: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1072: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1073: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1074: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1075: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1078: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1080: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1082: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1083: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1084: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1085: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1087: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-1088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1089: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1090: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1092: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1093: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-1094: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1095: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1096: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1097: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-1098: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1099: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1106: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-1107: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1110: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1111: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1113: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-1114: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 3-1115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1134: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-1135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1136: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1139: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-1140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1142: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1145: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1147: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-1148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1151: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-1152: Loss: 0.0064 Acc: 93.3333%\n",
      "\ttrain 3-1153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1157: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 3-1158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1161: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1168: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 3-1169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1173: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1175: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 3-1176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1177: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 3-1178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1185: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1186: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1193: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1198: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1202: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1203: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 3-1204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1213: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-1214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1215: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1218: Loss: 0.0066 Acc: 96.6667%\n",
      "\ttrain 3-1219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1221: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1223: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1227: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1235: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1236: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 3-1237: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1238: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1241: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1247: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1257: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1258: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1261: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1273: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1275: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-1276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1277: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1279: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-1280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1289: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1291: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1294: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1301: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-1302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1308: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1311: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1317: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1318: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1325: Loss: 0.0039 Acc: 93.3333%\n",
      "\ttrain 3-1326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1328: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1336: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1341: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1342: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-1343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1347: Loss: 0.0013 Acc: 100.0000%\n",
      "\ttrain 3-1348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1349: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1353: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1354: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1355: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1356: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1358: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1359: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1367: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-1368: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1376: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1381: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1382: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1384: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1385: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1386: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1389: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1391: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1392: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1393: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1396: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1399: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1403: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1408: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 3-1409: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1410: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1412: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1413: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1414: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-1415: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-1416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1417: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1418: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1426: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1428: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1430: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1431: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1432: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1436: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 3-1437: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1439: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1442: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1443: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1446: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1449: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1450: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1453: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1455: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1458: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1465: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1466: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1469: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1471: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1472: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1475: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1476: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1477: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1478: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1480: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1481: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1483: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1487: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1489: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1490: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1492: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-1493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1494: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1500: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1501: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1502: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1505: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1507: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1508: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 3-1509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1510: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1511: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-1512: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1513: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1514: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1516: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-1517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1519: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1521: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1522: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1523: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1524: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1526: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1527: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1528: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1529: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1530: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1531: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1533: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-1534: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1536: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1537: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1538: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1539: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1541: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 3-1542: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1543: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1545: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1546: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 3-1547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1549: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1550: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1551: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1552: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1553: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1554: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1555: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1556: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1557: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-1558: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 3-1559: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1560: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1561: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1562: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1563: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1566: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1567: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1569: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1570: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1572: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1573: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1574: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1575: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1576: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1578: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1581: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1582: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1584: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1587: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1588: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1590: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1591: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1592: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-1593: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1594: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-1595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1597: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1598: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1600: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1603: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 3-1604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1607: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1609: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1610: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 3-1611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1612: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1613: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1615: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1616: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1617: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1618: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1619: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1620: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1622: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1624: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1625: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1628: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1629: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1631: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1632: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1633: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-1634: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1635: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1636: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1637: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1639: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1640: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1641: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1642: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1643: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 3-1644: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1645: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1646: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1648: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1649: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1651: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1652: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1653: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1656: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1657: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1658: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1660: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1661: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1663: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1665: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1666: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1667: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-1668: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1671: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1672: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1673: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-1674: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1675: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1678: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1679: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1680: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1681: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1684: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1686: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1687: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-1688: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-1689: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1690: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1691: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1696: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1697: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1698: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1699: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 3-1700: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1701: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1704: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1705: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1706: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1707: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1708: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1710: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1711: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1713: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-1714: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-1715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1716: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1717: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1719: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1721: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1722: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1723: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1724: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-1725: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1727: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1728: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1730: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1731: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1733: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1734: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1735: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1736: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1737: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1738: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1739: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1741: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-1742: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 3-1743: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-1744: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1745: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1746: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1747: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1748: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1749: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1750: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1751: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1752: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 3-1753: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1754: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1755: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1756: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 3-1757: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1758: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1759: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1761: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1762: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1763: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1764: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1765: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1767: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1768: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1769: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1771: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1772: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1773: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1774: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1775: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 3-1776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1777: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1778: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 3-1779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1783: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-1784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1785: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-1786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1788: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1789: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1790: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-1791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1794: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1795: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 3-1796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1797: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1799: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-1800: Loss: 0.0091 Acc: 96.6667%\n",
      "\ttrain 3-1801: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1802: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1804: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1809: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1810: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1812: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1815: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1816: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1817: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1818: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1819: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-1820: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1821: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1822: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1823: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1824: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-1825: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-1826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1827: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1829: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1830: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-1831: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1832: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1833: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1834: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1835: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1836: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1838: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1839: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1840: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1841: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-1842: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1843: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1844: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1846: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1847: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1848: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1849: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1850: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1852: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1853: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1855: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1856: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1857: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1859: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1860: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-1861: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1862: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-1863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1864: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-1865: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1866: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1867: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-1868: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1870: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1872: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1873: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1874: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1877: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-1878: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1879: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-1880: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-1881: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1882: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-1883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1885: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1886: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1887: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1889: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-1890: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1891: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1892: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1893: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1896: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1898: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1902: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1903: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 3-1904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1905: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1907: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1908: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1910: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1911: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1913: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-1914: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1915: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-1916: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-1917: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-1918: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1921: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1924: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1926: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1928: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1929: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1930: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1931: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1932: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1933: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1934: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 3-1935: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1937: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1939: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1940: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1942: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1944: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 3-1945: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1946: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1947: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1948: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1949: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1950: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1951: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1953: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1954: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1955: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1958: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-1959: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1960: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1961: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1962: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 3-1963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1964: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1965: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-1966: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1969: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1970: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1973: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1978: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1979: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1982: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-1983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1984: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-1985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1987: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1988: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1989: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1990: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1992: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1994: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1995: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-1996: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1998: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-1999: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2000: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2001: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2002: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2003: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2004: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2005: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2006: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2008: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2009: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2010: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2011: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-2012: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2013: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2015: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2017: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2018: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2019: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2020: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2022: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2023: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2024: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2026: Loss: 0.0075 Acc: 96.6667%\n",
      "\ttrain 3-2027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2029: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2032: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2033: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2035: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2036: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2037: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2038: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2040: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2042: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2044: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2045: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2046: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2047: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2051: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2052: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2053: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2054: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2055: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2056: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2057: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2058: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2059: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2060: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2062: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2063: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2065: Loss: 0.0055 Acc: 96.6667%\n",
      "\ttrain 3-2066: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2068: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-2069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2070: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2072: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2073: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-2074: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2075: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2078: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2080: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2082: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2083: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2084: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2085: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2087: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2089: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2090: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 3-2091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2092: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-2093: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2094: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-2095: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2096: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2097: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2098: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2099: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2100: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2106: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-2107: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2111: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 3-2112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2113: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-2114: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 3-2115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2117: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 3-2118: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2121: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2129: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 3-2130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2136: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-2137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2145: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-2146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2152: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2154: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2163: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-2164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2165: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 3-2166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2171: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-2172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2173: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2174: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2177: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2184: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-2185: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2188: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 3-2189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2193: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2197: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-2198: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-2199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2201: Loss: 0.0071 Acc: 90.0000%\n",
      "\ttrain 3-2202: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2203: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 3-2204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2205: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 3-2206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2207: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2209: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-2210: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2218: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2227: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-2228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2230: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-2231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2240: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2247: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2248: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 3-2249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2253: Loss: 0.0064 Acc: 96.6667%\n",
      "\ttrain 3-2254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2258: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-2259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2265: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-2266: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-2267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2269: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2273: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-2274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2277: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2286: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-2287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2288: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2291: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2294: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2298: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-2299: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2304: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2307: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2308: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2311: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2317: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2326: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 3-2327: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-2328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2334: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2336: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2337: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-2338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2342: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 3-2343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2353: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-2354: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-2355: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2356: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2358: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2368: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2376: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2377: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2380: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2382: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2384: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2385: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2386: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2389: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-2390: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 3-2391: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2393: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2396: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-2397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2399: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2403: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2405: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2408: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-2409: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2410: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2412: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2413: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2414: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2415: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2417: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 3-2418: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2422: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-2423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2426: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2428: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-2429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2430: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2432: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2437: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2439: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2440: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 3-2441: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-2442: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2443: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2444: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2446: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2449: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2453: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2455: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2457: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-2458: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2462: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2465: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2466: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2467: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2469: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2471: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2472: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2475: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2477: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2478: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2480: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2481: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-2482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2487: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2489: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-2490: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2494: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-2495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2497: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2498: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2500: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2501: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2502: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2505: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2507: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2508: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2510: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-2511: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2512: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2513: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-2514: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-2515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2519: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2521: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 3-2522: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2523: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2524: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2526: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2527: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2528: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-2529: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2530: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2531: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2533: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2534: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2536: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 3-2537: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2538: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 3-2539: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2541: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2542: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2543: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2545: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2546: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2548: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-2549: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2550: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2551: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2552: Loss: 0.0072 Acc: 93.3333%\n",
      "\ttrain 3-2553: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2554: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2555: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2556: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2557: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2558: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2559: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2560: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-2561: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2562: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2563: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2566: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2567: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2569: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2570: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2572: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2573: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2574: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-2575: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 3-2576: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2578: Loss: 0.0040 Acc: 93.3333%\n",
      "\ttrain 3-2579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2581: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2582: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2584: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2587: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2588: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2589: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 3-2590: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2591: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2593: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-2594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2597: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 3-2598: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-2599: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 3-2600: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2603: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2606: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-2607: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2609: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2610: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2612: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2613: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2615: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2616: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2617: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2618: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2619: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2620: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2622: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2624: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2628: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-2629: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2631: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2632: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2633: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2634: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2635: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2636: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 3-2637: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2639: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2640: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2641: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2642: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2643: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2644: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2645: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2646: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-2647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2648: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2649: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2651: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-2652: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2653: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2656: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2657: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2658: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2660: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2661: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2663: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2665: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2666: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2667: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2668: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-2669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2671: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2672: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2673: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2674: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 3-2675: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2678: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2679: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2680: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2681: Loss: 0.0036 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-2682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2684: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2686: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2687: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2688: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 3-2689: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2690: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2691: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2696: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2697: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2698: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2699: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2700: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2701: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2704: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2705: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2706: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2707: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2708: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2710: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2711: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2713: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2714: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2716: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 3-2717: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2719: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2720: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-2721: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2722: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2723: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2724: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2725: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-2726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2727: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2728: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-2729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2730: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-2731: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2733: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2734: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2735: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-2736: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2737: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2738: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2739: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2741: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-2742: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2743: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2744: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2745: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2746: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2747: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2748: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2749: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2750: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2751: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2752: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2753: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2754: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2755: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2756: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2757: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2758: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2759: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2761: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2762: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2763: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2764: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2765: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2767: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2768: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2769: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2772: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2773: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2775: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2777: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2778: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2781: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2783: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2785: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2788: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2789: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2790: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 3-2791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2793: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-2794: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-2795: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2797: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2799: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2800: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2801: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2802: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2804: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2809: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2810: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-2811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2812: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2815: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-2816: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2817: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2818: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2819: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2820: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2821: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2822: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2823: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2824: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2825: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2827: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2829: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2830: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2831: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2832: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2833: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 3-2834: Loss: 0.0089 Acc: 93.3333%\n",
      "\ttrain 3-2835: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2836: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2838: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-2839: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2840: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2841: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2842: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2843: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2844: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2846: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2847: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2848: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2849: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2850: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2852: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2853: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2855: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2856: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2857: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2859: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2860: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2861: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2862: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2864: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2865: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-2866: Loss: 0.0073 Acc: 96.6667%\n",
      "\ttrain 3-2867: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2868: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2869: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2870: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2872: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-2873: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2874: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2878: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2879: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2880: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2881: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2882: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2885: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2886: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2887: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2889: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2890: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2891: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2892: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2893: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2894: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2896: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2898: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2905: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 3-2906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2907: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2908: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2910: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2911: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2914: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2915: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2916: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2917: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-2918: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2921: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2924: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2926: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2928: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-2929: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2930: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-2931: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2932: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2933: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2934: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2935: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2936: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-2937: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-2938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2939: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2940: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2942: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2944: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2945: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 3-2946: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2947: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2948: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2949: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2950: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2951: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-2952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2953: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2954: Loss: 0.0050 Acc: 96.6667%\n",
      "\ttrain 3-2955: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2958: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-2959: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-2960: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2961: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2962: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2964: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2965: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2966: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2969: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2970: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2973: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2978: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2979: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2980: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-2981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2982: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2984: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2987: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2988: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2989: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2990: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2992: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2994: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2995: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2996: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-2998: Loss: 0.0077 Acc: 93.3333%\n",
      "\ttrain 3-2999: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3000: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-3001: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3002: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3003: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3004: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3005: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3006: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3008: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3009: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 3-3010: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3011: Loss: 0.0028 Acc: 100.0000%\n",
      "\ttrain 3-3012: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3013: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3015: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3017: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3018: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3019: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3020: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-3021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3022: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3023: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 3-3024: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-3025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3029: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3032: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3033: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3035: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3036: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3037: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3038: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3040: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-3041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3042: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3043: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3044: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3045: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3046: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3047: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3051: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3052: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3053: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3054: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3055: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3056: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3057: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-3058: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3059: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3060: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-3061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3062: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3063: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-3064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3065: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3066: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3068: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3070: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3072: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3073: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3074: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3075: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3078: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3080: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3082: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 3-3083: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3084: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3085: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3087: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 3-3088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3089: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3090: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3092: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3093: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3094: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3095: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3096: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3097: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3098: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3099: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3107: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3114: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3122: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3125: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 3-3126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3136: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3144: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3145: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-3146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3152: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3154: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-3155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3163: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-3164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3166: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 3-3167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3171: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3173: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3177: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3185: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3193: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3201: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-3202: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3204: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3214: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 3-3215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3216: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 3-3217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3218: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3227: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3233: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 3-3234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3241: Loss: 0.0062 Acc: 96.6667%\n",
      "\ttrain 3-3242: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3247: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 3-3248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3254: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-3255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3256: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-3257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3273: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3277: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-3278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3291: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3294: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 3-3295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3308: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3311: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3317: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3322: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3325: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 3-3326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3328: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-3329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3331: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-3332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3336: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-3337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3340: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 3-3341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3342: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3351: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-3352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3354: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-3355: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3356: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3358: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3364: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-3365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3368: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3376: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3382: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3384: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3385: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3386: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3391: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3393: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3396: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3399: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3403: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3408: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3409: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3410: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3412: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3413: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3414: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3415: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3417: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-3418: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3424: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-3425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3426: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3430: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3432: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-3433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3437: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3439: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3442: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3443: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3445: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-3446: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3447: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 3-3448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3449: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3453: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3455: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3456: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 3-3457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3458: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3465: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-3466: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3469: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-3470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3471: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3472: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-3473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3475: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3477: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3478: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3480: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-3481: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3485: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3487: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3489: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3490: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3493: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-3494: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3500: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3501: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3502: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3505: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3507: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3508: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3509: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-3510: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3511: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3512: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3513: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3514: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3519: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3521: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3522: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 3-3523: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3524: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3526: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 3-3527: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3528: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3529: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3530: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3531: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3533: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3534: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3536: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3537: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3538: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3539: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3540: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-3541: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3542: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3543: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-3544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3545: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3546: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3549: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-3550: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 3-3551: Loss: 0.0031 Acc: 100.0000%\n",
      "\ttrain 3-3552: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3553: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3554: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3555: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3556: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3557: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3558: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3559: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3560: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3561: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3562: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3563: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3566: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3567: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3569: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3570: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3572: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3573: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 3-3574: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3575: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3576: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3577: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3578: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3581: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3582: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3584: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3587: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3588: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3590: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3591: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3593: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3597: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3598: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3599: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 3-3600: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3603: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3607: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3609: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3610: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3612: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3613: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3614: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3615: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3616: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3617: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3618: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3619: Loss: 0.0025 Acc: 100.0000%\n",
      "\ttrain 3-3620: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3622: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3623: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-3624: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3628: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3629: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3631: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3632: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3633: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3634: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3635: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3636: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-3637: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3639: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3640: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3641: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3642: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 3-3643: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3644: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-3645: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3646: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 3-3647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3648: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3649: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3651: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 3-3652: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3653: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3656: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 3-3657: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3658: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3660: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3661: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3663: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3665: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3666: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3667: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3668: Loss: 0.0014 Acc: 96.6667%\n",
      "\ttrain 3-3669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3671: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3672: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3673: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3674: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3675: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3678: Loss: 0.0060 Acc: 96.6667%\n",
      "\ttrain 3-3679: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3680: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 3-3681: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3684: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3686: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-3687: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3688: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3689: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3690: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3691: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-3692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3696: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3697: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3698: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3699: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3700: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3701: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3704: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3705: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3706: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3707: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3708: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3710: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3711: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3713: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3714: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3716: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3717: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3719: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3721: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3722: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3723: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3724: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 3-3725: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3727: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3728: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3730: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3731: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3733: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3734: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3735: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3736: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3737: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3738: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3739: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3741: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3742: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3743: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3744: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3745: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3746: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3747: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3748: Loss: 0.0016 Acc: 100.0000%\n",
      "\ttrain 3-3749: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3750: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3751: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3752: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3753: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3754: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3755: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3756: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3757: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3758: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3759: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3761: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3762: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3763: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3764: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-3765: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3767: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3768: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3769: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3772: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3773: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3775: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3777: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3778: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3783: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3784: Loss: 0.0023 Acc: 100.0000%\n",
      "\ttrain 3-3785: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-3786: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-3787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3788: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3789: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3790: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3794: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3795: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3797: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3799: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3800: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-3801: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3802: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3804: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3809: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3810: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3812: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3815: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3816: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3817: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3818: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3819: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3820: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3821: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3822: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3823: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3824: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3825: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3827: Loss: 0.0001 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-3828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3829: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3830: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3831: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3832: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-3833: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3834: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3835: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3836: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3838: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3839: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3840: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3841: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3842: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3843: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3844: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3846: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3847: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3848: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-3849: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 3-3850: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3852: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3853: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-3854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3855: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-3856: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3857: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3859: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3860: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3861: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3862: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3864: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3865: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3866: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3867: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3868: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3870: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3872: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3873: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3874: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3878: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3879: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3880: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 3-3881: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3882: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3885: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3886: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3887: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3889: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3890: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3891: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3892: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3893: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3896: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3898: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3905: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3907: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3908: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3910: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3911: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3914: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3915: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3916: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3917: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-3918: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 3-3919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3921: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3924: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3926: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3928: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3929: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3930: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3931: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3932: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3933: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3934: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3935: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3937: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3939: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3940: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3942: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3944: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3945: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3946: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3947: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3948: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3949: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3950: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3951: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3953: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3954: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3955: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3958: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3959: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3960: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-3961: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3962: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3964: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3965: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3966: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3969: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3970: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3973: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3978: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3979: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-3980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3982: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3984: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3987: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3988: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3989: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-3990: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-3991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3992: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3993: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-3994: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-3995: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3996: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 3-3997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3998: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-3999: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4000: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4001: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4002: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4003: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4004: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4005: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4006: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4008: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4009: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4010: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 3-4011: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 3-4012: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4013: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4015: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4017: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4018: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-4019: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-4020: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4022: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4023: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4024: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4029: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4032: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4033: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4035: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4036: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4037: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4038: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4040: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4042: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4044: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4045: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4046: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4047: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4050: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4051: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4052: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4053: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 3-4054: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4055: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4056: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 3-4057: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4058: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4059: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4060: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4062: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4063: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4065: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4066: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4068: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4070: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4072: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4073: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4074: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4075: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4078: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4080: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4082: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4083: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4084: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4085: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 3-4086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4087: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4089: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4090: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4092: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4093: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4094: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 3-4095: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4096: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4097: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4098: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4099: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 3-4100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4107: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-4108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4111: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 3-4112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4114: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4117: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-4118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4119: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 3-4120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4124: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-4125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4136: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4145: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-4146: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 3-4147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4152: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-4153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4155: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-4156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4162: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-4163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4167: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 3-4168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4170: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 3-4171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4173: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4175: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-4176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4177: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4178: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 3-4179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4184: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 3-4185: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 3-4186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4188: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 3-4189: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 3-4190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4193: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4195: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4196: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 3-4197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4206: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4209: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-4210: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 3-4211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4217: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-4218: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4220: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-4221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4227: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4229: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 3-4230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4247: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-4248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4264: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-4265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4270: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 3-4271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4273: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4277: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4291: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4294: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4297: Loss: 0.0018 Acc: 93.3333%\n",
      "\ttrain 3-4298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4308: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 3-4309: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-4310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4311: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4317: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-4318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4330: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 3-4331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4336: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4337: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4338: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 3-4339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4342: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4354: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4355: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4356: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4358: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4368: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4376: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-4377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4382: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4384: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4385: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-4386: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4391: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4393: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4396: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4399: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4400: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 3-4401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4403: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4408: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4409: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 3-4410: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4412: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4413: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4414: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4415: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4417: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4418: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4423: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 3-4424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4426: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 3-4427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4429: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 3-4430: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4432: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4435: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 3-4436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4437: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4439: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4442: Loss: 0.0020 Acc: 100.0000%\n",
      "\ttrain 3-4443: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-4444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4446: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 3-4447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4449: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4450: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4453: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4455: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4458: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4463: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 3-4464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4465: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4466: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4467: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4469: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4471: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4472: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4475: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 3-4476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4477: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 3-4478: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4480: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4481: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4487: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 3-4488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4489: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4490: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4494: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 3-4500: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1: Loss: 0.0336 Acc: 96.6667%\n",
      "\tvalidation 3-2: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-3: Loss: 0.0279 Acc: 96.6667%\n",
      "\tvalidation 3-4: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 3-5: Loss: 0.0280 Acc: 96.6667%\n",
      "\tvalidation 3-6: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-7: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-8: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-9: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 3-10: Loss: 0.0344 Acc: 96.6667%\n",
      "\tvalidation 3-11: Loss: 0.0134 Acc: 93.3333%\n",
      "\tvalidation 3-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-13: Loss: 0.0722 Acc: 90.0000%\n",
      "\tvalidation 3-14: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 3-15: Loss: 0.0889 Acc: 83.3333%\n",
      "\tvalidation 3-16: Loss: 0.0219 Acc: 90.0000%\n",
      "\tvalidation 3-17: Loss: 0.0211 Acc: 93.3333%\n",
      "\tvalidation 3-18: Loss: 0.0167 Acc: 93.3333%\n",
      "\tvalidation 3-19: Loss: 0.0315 Acc: 96.6667%\n",
      "\tvalidation 3-20: Loss: 0.0229 Acc: 96.6667%\n",
      "\tvalidation 3-21: Loss: 0.0404 Acc: 93.3333%\n",
      "\tvalidation 3-22: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-23: Loss: 0.0382 Acc: 83.3333%\n",
      "\tvalidation 3-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-25: Loss: 0.0222 Acc: 96.6667%\n",
      "\tvalidation 3-26: Loss: 0.0541 Acc: 90.0000%\n",
      "\tvalidation 3-27: Loss: 0.0327 Acc: 96.6667%\n",
      "\tvalidation 3-28: Loss: 0.0191 Acc: 96.6667%\n",
      "\tvalidation 3-29: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-30: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-32: Loss: 0.0514 Acc: 90.0000%\n",
      "\tvalidation 3-33: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-34: Loss: 0.0674 Acc: 90.0000%\n",
      "\tvalidation 3-35: Loss: 0.0059 Acc: 96.6667%\n",
      "\tvalidation 3-36: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 3-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-38: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 3-39: Loss: 0.0513 Acc: 93.3333%\n",
      "\tvalidation 3-40: Loss: 0.0435 Acc: 90.0000%\n",
      "\tvalidation 3-41: Loss: 0.0321 Acc: 96.6667%\n",
      "\tvalidation 3-42: Loss: 0.0328 Acc: 96.6667%\n",
      "\tvalidation 3-43: Loss: 0.0551 Acc: 90.0000%\n",
      "\tvalidation 3-44: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-45: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-46: Loss: 0.0120 Acc: 90.0000%\n",
      "\tvalidation 3-47: Loss: 0.0205 Acc: 93.3333%\n",
      "\tvalidation 3-48: Loss: 0.0181 Acc: 96.6667%\n",
      "\tvalidation 3-49: Loss: 0.0130 Acc: 93.3333%\n",
      "\tvalidation 3-50: Loss: 0.0351 Acc: 93.3333%\n",
      "\tvalidation 3-51: Loss: 0.0253 Acc: 93.3333%\n",
      "\tvalidation 3-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-53: Loss: 0.0382 Acc: 86.6667%\n",
      "\tvalidation 3-54: Loss: 0.0357 Acc: 93.3333%\n",
      "\tvalidation 3-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-56: Loss: 0.0349 Acc: 90.0000%\n",
      "\tvalidation 3-57: Loss: 0.0292 Acc: 96.6667%\n",
      "\tvalidation 3-58: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-59: Loss: 0.0229 Acc: 93.3333%\n",
      "\tvalidation 3-60: Loss: 0.0314 Acc: 86.6667%\n",
      "\tvalidation 3-61: Loss: 0.0133 Acc: 93.3333%\n",
      "\tvalidation 3-62: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 3-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-64: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-65: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-66: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-68: Loss: 0.0162 Acc: 96.6667%\n",
      "\tvalidation 3-69: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-70: Loss: 0.0309 Acc: 93.3333%\n",
      "\tvalidation 3-71: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 3-72: Loss: 0.0340 Acc: 93.3333%\n",
      "\tvalidation 3-73: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 3-74: Loss: 0.0185 Acc: 96.6667%\n",
      "\tvalidation 3-75: Loss: 0.0333 Acc: 83.3333%\n",
      "\tvalidation 3-76: Loss: 0.0502 Acc: 93.3333%\n",
      "\tvalidation 3-77: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 3-78: Loss: 0.0328 Acc: 96.6667%\n",
      "\tvalidation 3-79: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-80: Loss: 0.0238 Acc: 93.3333%\n",
      "\tvalidation 3-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-82: Loss: 0.0080 Acc: 96.6667%\n",
      "\tvalidation 3-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-84: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 3-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-86: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 3-87: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-88: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-89: Loss: 0.0513 Acc: 93.3333%\n",
      "\tvalidation 3-90: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 3-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-92: Loss: 0.0089 Acc: 93.3333%\n",
      "\tvalidation 3-93: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-94: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 3-95: Loss: 0.0196 Acc: 96.6667%\n",
      "\tvalidation 3-96: Loss: 0.0061 Acc: 96.6667%\n",
      "\tvalidation 3-97: Loss: 0.0739 Acc: 90.0000%\n",
      "\tvalidation 3-98: Loss: 0.0295 Acc: 96.6667%\n",
      "\tvalidation 3-99: Loss: 0.0327 Acc: 96.6667%\n",
      "\tvalidation 3-100: Loss: 0.0326 Acc: 96.6667%\n",
      "\tvalidation 3-101: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-102: Loss: 0.0118 Acc: 93.3333%\n",
      "\tvalidation 3-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-104: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 3-105: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-106: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 3-107: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-108: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 3-109: Loss: 0.0114 Acc: 96.6667%\n",
      "\tvalidation 3-110: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 3-111: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-112: Loss: 0.0160 Acc: 93.3333%\n",
      "\tvalidation 3-113: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-114: Loss: 0.0098 Acc: 96.6667%\n",
      "\tvalidation 3-115: Loss: 0.0151 Acc: 96.6667%\n",
      "\tvalidation 3-116: Loss: 0.0326 Acc: 96.6667%\n",
      "\tvalidation 3-117: Loss: 0.0431 Acc: 90.0000%\n",
      "\tvalidation 3-118: Loss: 0.0497 Acc: 90.0000%\n",
      "\tvalidation 3-119: Loss: 0.0139 Acc: 96.6667%\n",
      "\tvalidation 3-120: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-121: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 3-122: Loss: 0.0269 Acc: 96.6667%\n",
      "\tvalidation 3-123: Loss: 0.0483 Acc: 93.3333%\n",
      "\tvalidation 3-124: Loss: 0.0067 Acc: 96.6667%\n",
      "\tvalidation 3-125: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-126: Loss: 0.0332 Acc: 93.3333%\n",
      "\tvalidation 3-127: Loss: 0.0363 Acc: 96.6667%\n",
      "\tvalidation 3-128: Loss: 0.0499 Acc: 93.3333%\n",
      "\tvalidation 3-129: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-130: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-131: Loss: 0.0369 Acc: 93.3333%\n",
      "\tvalidation 3-132: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-133: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-134: Loss: 0.0510 Acc: 93.3333%\n",
      "\tvalidation 3-135: Loss: 0.0213 Acc: 93.3333%\n",
      "\tvalidation 3-136: Loss: 0.0477 Acc: 90.0000%\n",
      "\tvalidation 3-137: Loss: 0.0503 Acc: 93.3333%\n",
      "\tvalidation 3-138: Loss: 0.0210 Acc: 96.6667%\n",
      "\tvalidation 3-139: Loss: 0.0204 Acc: 96.6667%\n",
      "\tvalidation 3-140: Loss: 0.0797 Acc: 90.0000%\n",
      "\tvalidation 3-141: Loss: 0.0291 Acc: 90.0000%\n",
      "\tvalidation 3-142: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 3-143: Loss: 0.0093 Acc: 96.6667%\n",
      "\tvalidation 3-144: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-145: Loss: 0.0044 Acc: 93.3333%\n",
      "\tvalidation 3-146: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-147: Loss: 0.0141 Acc: 96.6667%\n",
      "\tvalidation 3-148: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 3-149: Loss: 0.0293 Acc: 96.6667%\n",
      "\tvalidation 3-150: Loss: 0.0084 Acc: 93.3333%\n",
      "\tvalidation 3-151: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-152: Loss: 0.0641 Acc: 90.0000%\n",
      "\tvalidation 3-153: Loss: 0.0151 Acc: 96.6667%\n",
      "\tvalidation 3-154: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 3-155: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-156: Loss: 0.0242 Acc: 96.6667%\n",
      "\tvalidation 3-157: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-158: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-159: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-160: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 3-161: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 3-162: Loss: 0.0665 Acc: 93.3333%\n",
      "\tvalidation 3-163: Loss: 0.0756 Acc: 90.0000%\n",
      "\tvalidation 3-164: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-165: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-166: Loss: 0.0125 Acc: 96.6667%\n",
      "\tvalidation 3-167: Loss: 0.0299 Acc: 93.3333%\n",
      "\tvalidation 3-168: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-169: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-170: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-171: Loss: 0.0412 Acc: 90.0000%\n",
      "\tvalidation 3-172: Loss: 0.0400 Acc: 86.6667%\n",
      "\tvalidation 3-173: Loss: 0.0518 Acc: 90.0000%\n",
      "\tvalidation 3-174: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-175: Loss: 0.0450 Acc: 93.3333%\n",
      "\tvalidation 3-176: Loss: 0.0203 Acc: 93.3333%\n",
      "\tvalidation 3-177: Loss: 0.0439 Acc: 93.3333%\n",
      "\tvalidation 3-178: Loss: 0.0485 Acc: 90.0000%\n",
      "\tvalidation 3-179: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-180: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 3-181: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-182: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-183: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-184: Loss: 0.0303 Acc: 93.3333%\n",
      "\tvalidation 3-185: Loss: 0.0490 Acc: 90.0000%\n",
      "\tvalidation 3-186: Loss: 0.0639 Acc: 93.3333%\n",
      "\tvalidation 3-187: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-188: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 3-189: Loss: 0.0012 Acc: 100.0000%\n",
      "\tvalidation 3-190: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-191: Loss: 0.0203 Acc: 90.0000%\n",
      "\tvalidation 3-192: Loss: 0.0067 Acc: 93.3333%\n",
      "\tvalidation 3-193: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 3-194: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-195: Loss: 0.0078 Acc: 96.6667%\n",
      "\tvalidation 3-196: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-197: Loss: 0.0502 Acc: 90.0000%\n",
      "\tvalidation 3-198: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-199: Loss: 0.0269 Acc: 93.3333%\n",
      "\tvalidation 3-200: Loss: 0.0462 Acc: 90.0000%\n",
      "\tvalidation 3-201: Loss: 0.0074 Acc: 93.3333%\n",
      "\tvalidation 3-202: Loss: 0.0071 Acc: 96.6667%\n",
      "\tvalidation 3-203: Loss: 0.0458 Acc: 93.3333%\n",
      "\tvalidation 3-204: Loss: 0.0535 Acc: 93.3333%\n",
      "\tvalidation 3-205: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-206: Loss: 0.0111 Acc: 96.6667%\n",
      "\tvalidation 3-207: Loss: 0.0085 Acc: 93.3333%\n",
      "\tvalidation 3-208: Loss: 0.0364 Acc: 93.3333%\n",
      "\tvalidation 3-209: Loss: 0.0468 Acc: 90.0000%\n",
      "\tvalidation 3-210: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-211: Loss: 0.0126 Acc: 96.6667%\n",
      "\tvalidation 3-212: Loss: 0.0362 Acc: 96.6667%\n",
      "\tvalidation 3-213: Loss: 0.0520 Acc: 90.0000%\n",
      "\tvalidation 3-214: Loss: 0.0162 Acc: 93.3333%\n",
      "\tvalidation 3-215: Loss: 0.0235 Acc: 96.6667%\n",
      "\tvalidation 3-216: Loss: 0.0230 Acc: 93.3333%\n",
      "\tvalidation 3-217: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-218: Loss: 0.0491 Acc: 93.3333%\n",
      "\tvalidation 3-219: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 3-220: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-221: Loss: 0.0288 Acc: 96.6667%\n",
      "\tvalidation 3-222: Loss: 0.0403 Acc: 93.3333%\n",
      "\tvalidation 3-223: Loss: 0.0108 Acc: 96.6667%\n",
      "\tvalidation 3-224: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-225: Loss: 0.0265 Acc: 93.3333%\n",
      "\tvalidation 3-226: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-227: Loss: 0.0257 Acc: 96.6667%\n",
      "\tvalidation 3-228: Loss: 0.0678 Acc: 90.0000%\n",
      "\tvalidation 3-229: Loss: 0.0597 Acc: 90.0000%\n",
      "\tvalidation 3-230: Loss: 0.0442 Acc: 90.0000%\n",
      "\tvalidation 3-231: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-232: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-233: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-234: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 3-235: Loss: 0.0371 Acc: 90.0000%\n",
      "\tvalidation 3-236: Loss: 0.0347 Acc: 93.3333%\n",
      "\tvalidation 3-237: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 3-238: Loss: 0.0199 Acc: 96.6667%\n",
      "\tvalidation 3-239: Loss: 0.0221 Acc: 93.3333%\n",
      "\tvalidation 3-240: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-241: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-242: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-243: Loss: 0.0309 Acc: 93.3333%\n",
      "\tvalidation 3-244: Loss: 0.0092 Acc: 93.3333%\n",
      "\tvalidation 3-245: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 3-246: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 3-247: Loss: 0.0130 Acc: 96.6667%\n",
      "\tvalidation 3-248: Loss: 0.0185 Acc: 93.3333%\n",
      "\tvalidation 3-249: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-250: Loss: 0.0059 Acc: 93.3333%\n",
      "\tvalidation 3-251: Loss: 0.0323 Acc: 93.3333%\n",
      "\tvalidation 3-252: Loss: 0.0158 Acc: 96.6667%\n",
      "\tvalidation 3-253: Loss: 0.0210 Acc: 96.6667%\n",
      "\tvalidation 3-254: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-255: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-256: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-257: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-258: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-259: Loss: 0.0128 Acc: 93.3333%\n",
      "\tvalidation 3-260: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-261: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-262: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 3-263: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 3-264: Loss: 0.0405 Acc: 93.3333%\n",
      "\tvalidation 3-265: Loss: 0.0192 Acc: 96.6667%\n",
      "\tvalidation 3-266: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-267: Loss: 0.0502 Acc: 86.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-268: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-269: Loss: 0.0161 Acc: 96.6667%\n",
      "\tvalidation 3-270: Loss: 0.0584 Acc: 90.0000%\n",
      "\tvalidation 3-271: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-272: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 3-273: Loss: 0.0215 Acc: 93.3333%\n",
      "\tvalidation 3-274: Loss: 0.0415 Acc: 93.3333%\n",
      "\tvalidation 3-275: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-276: Loss: 0.0052 Acc: 96.6667%\n",
      "\tvalidation 3-277: Loss: 0.0155 Acc: 93.3333%\n",
      "\tvalidation 3-278: Loss: 0.0290 Acc: 93.3333%\n",
      "\tvalidation 3-279: Loss: 0.0597 Acc: 90.0000%\n",
      "\tvalidation 3-280: Loss: 0.0244 Acc: 96.6667%\n",
      "\tvalidation 3-281: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-282: Loss: 0.0419 Acc: 90.0000%\n",
      "\tvalidation 3-283: Loss: 0.0091 Acc: 93.3333%\n",
      "\tvalidation 3-284: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-285: Loss: 0.0363 Acc: 86.6667%\n",
      "\tvalidation 3-286: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-287: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 3-288: Loss: 0.0261 Acc: 93.3333%\n",
      "\tvalidation 3-289: Loss: 0.0241 Acc: 93.3333%\n",
      "\tvalidation 3-290: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-291: Loss: 0.0200 Acc: 96.6667%\n",
      "\tvalidation 3-292: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-293: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-294: Loss: 0.0081 Acc: 93.3333%\n",
      "\tvalidation 3-295: Loss: 0.0136 Acc: 93.3333%\n",
      "\tvalidation 3-296: Loss: 0.0319 Acc: 96.6667%\n",
      "\tvalidation 3-297: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-298: Loss: 0.0393 Acc: 93.3333%\n",
      "\tvalidation 3-299: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-300: Loss: 0.0221 Acc: 96.6667%\n",
      "\tvalidation 3-301: Loss: 0.0302 Acc: 96.6667%\n",
      "\tvalidation 3-302: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 3-303: Loss: 0.0129 Acc: 96.6667%\n",
      "\tvalidation 3-304: Loss: 0.0108 Acc: 96.6667%\n",
      "\tvalidation 3-305: Loss: 0.0112 Acc: 96.6667%\n",
      "\tvalidation 3-306: Loss: 0.0151 Acc: 93.3333%\n",
      "\tvalidation 3-307: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-308: Loss: 0.0281 Acc: 96.6667%\n",
      "\tvalidation 3-309: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 3-310: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-311: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-312: Loss: 0.0315 Acc: 96.6667%\n",
      "\tvalidation 3-313: Loss: 0.0048 Acc: 96.6667%\n",
      "\tvalidation 3-314: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 3-315: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-316: Loss: 0.0277 Acc: 93.3333%\n",
      "\tvalidation 3-317: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-318: Loss: 0.0353 Acc: 93.3333%\n",
      "\tvalidation 3-319: Loss: 0.0550 Acc: 83.3333%\n",
      "\tvalidation 3-320: Loss: 0.0658 Acc: 90.0000%\n",
      "\tvalidation 3-321: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-322: Loss: 0.0215 Acc: 96.6667%\n",
      "\tvalidation 3-323: Loss: 0.0277 Acc: 93.3333%\n",
      "\tvalidation 3-324: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 3-325: Loss: 0.0477 Acc: 93.3333%\n",
      "\tvalidation 3-326: Loss: 0.0170 Acc: 96.6667%\n",
      "\tvalidation 3-327: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-328: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-329: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-330: Loss: 0.0800 Acc: 86.6667%\n",
      "\tvalidation 3-331: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-332: Loss: 0.0162 Acc: 96.6667%\n",
      "\tvalidation 3-333: Loss: 0.0406 Acc: 93.3333%\n",
      "\tvalidation 3-334: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 3-335: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-336: Loss: 0.0235 Acc: 93.3333%\n",
      "\tvalidation 3-337: Loss: 0.0430 Acc: 86.6667%\n",
      "\tvalidation 3-338: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-339: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-340: Loss: 0.0302 Acc: 96.6667%\n",
      "\tvalidation 3-341: Loss: 0.0261 Acc: 96.6667%\n",
      "\tvalidation 3-342: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-343: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-344: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 3-345: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 3-346: Loss: 0.0212 Acc: 96.6667%\n",
      "\tvalidation 3-347: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-348: Loss: 0.0362 Acc: 93.3333%\n",
      "\tvalidation 3-349: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-350: Loss: 0.0601 Acc: 93.3333%\n",
      "\tvalidation 3-351: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-352: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-353: Loss: 0.0040 Acc: 96.6667%\n",
      "\tvalidation 3-354: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-355: Loss: 0.0495 Acc: 93.3333%\n",
      "\tvalidation 3-356: Loss: 0.0228 Acc: 93.3333%\n",
      "\tvalidation 3-357: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-358: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-359: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-360: Loss: 0.0429 Acc: 93.3333%\n",
      "\tvalidation 3-361: Loss: 0.0488 Acc: 90.0000%\n",
      "\tvalidation 3-362: Loss: 0.0406 Acc: 93.3333%\n",
      "\tvalidation 3-363: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-364: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 3-365: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-366: Loss: 0.0202 Acc: 96.6667%\n",
      "\tvalidation 3-367: Loss: 0.0190 Acc: 96.6667%\n",
      "\tvalidation 3-368: Loss: 0.0397 Acc: 90.0000%\n",
      "\tvalidation 3-369: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 3-370: Loss: 0.0138 Acc: 93.3333%\n",
      "\tvalidation 3-371: Loss: 0.0080 Acc: 96.6667%\n",
      "\tvalidation 3-372: Loss: 0.0107 Acc: 93.3333%\n",
      "\tvalidation 3-373: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 3-374: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 3-375: Loss: 0.0385 Acc: 93.3333%\n",
      "\tvalidation 3-376: Loss: 0.0153 Acc: 96.6667%\n",
      "\tvalidation 3-377: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-378: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-379: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-380: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-381: Loss: 0.0156 Acc: 96.6667%\n",
      "\tvalidation 3-382: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-383: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-384: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-385: Loss: 0.0186 Acc: 86.6667%\n",
      "\tvalidation 3-386: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-387: Loss: 0.0291 Acc: 96.6667%\n",
      "\tvalidation 3-388: Loss: 0.0368 Acc: 96.6667%\n",
      "\tvalidation 3-389: Loss: 0.0500 Acc: 93.3333%\n",
      "\tvalidation 3-390: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-391: Loss: 0.0047 Acc: 96.6667%\n",
      "\tvalidation 3-392: Loss: 0.0284 Acc: 90.0000%\n",
      "\tvalidation 3-393: Loss: 0.0273 Acc: 96.6667%\n",
      "\tvalidation 3-394: Loss: 0.0151 Acc: 96.6667%\n",
      "\tvalidation 3-395: Loss: 0.0200 Acc: 96.6667%\n",
      "\tvalidation 3-396: Loss: 0.0084 Acc: 96.6667%\n",
      "\tvalidation 3-397: Loss: 0.0480 Acc: 90.0000%\n",
      "\tvalidation 3-398: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-399: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-400: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 3-401: Loss: 0.0178 Acc: 96.6667%\n",
      "\tvalidation 3-402: Loss: 0.0055 Acc: 93.3333%\n",
      "\tvalidation 3-403: Loss: 0.0689 Acc: 93.3333%\n",
      "\tvalidation 3-404: Loss: 0.0199 Acc: 96.6667%\n",
      "\tvalidation 3-405: Loss: 0.0068 Acc: 96.6667%\n",
      "\tvalidation 3-406: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-407: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-408: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-409: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-410: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-411: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 3-412: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-413: Loss: 0.0361 Acc: 96.6667%\n",
      "\tvalidation 3-414: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 3-415: Loss: 0.0063 Acc: 93.3333%\n",
      "\tvalidation 3-416: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-417: Loss: 0.0333 Acc: 96.6667%\n",
      "\tvalidation 3-418: Loss: 0.0169 Acc: 90.0000%\n",
      "\tvalidation 3-419: Loss: 0.0174 Acc: 96.6667%\n",
      "\tvalidation 3-420: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 3-421: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 3-422: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 3-423: Loss: 0.0447 Acc: 90.0000%\n",
      "\tvalidation 3-424: Loss: 0.0523 Acc: 93.3333%\n",
      "\tvalidation 3-425: Loss: 0.0183 Acc: 96.6667%\n",
      "\tvalidation 3-426: Loss: 0.0181 Acc: 93.3333%\n",
      "\tvalidation 3-427: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-428: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-429: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-430: Loss: 0.0221 Acc: 96.6667%\n",
      "\tvalidation 3-431: Loss: 0.0398 Acc: 93.3333%\n",
      "\tvalidation 3-432: Loss: 0.0368 Acc: 93.3333%\n",
      "\tvalidation 3-433: Loss: 0.0407 Acc: 93.3333%\n",
      "\tvalidation 3-434: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-435: Loss: 0.0637 Acc: 83.3333%\n",
      "\tvalidation 3-436: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-437: Loss: 0.0244 Acc: 90.0000%\n",
      "\tvalidation 3-438: Loss: 0.0009 Acc: 96.6667%\n",
      "\tvalidation 3-439: Loss: 0.0320 Acc: 90.0000%\n",
      "\tvalidation 3-440: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-441: Loss: 0.0400 Acc: 90.0000%\n",
      "\tvalidation 3-442: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-443: Loss: 0.0147 Acc: 96.6667%\n",
      "\tvalidation 3-444: Loss: 0.0277 Acc: 93.3333%\n",
      "\tvalidation 3-445: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-446: Loss: 0.0232 Acc: 96.6667%\n",
      "\tvalidation 3-447: Loss: 0.0223 Acc: 96.6667%\n",
      "\tvalidation 3-448: Loss: 0.0360 Acc: 90.0000%\n",
      "\tvalidation 3-449: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-450: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 3-451: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-452: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-453: Loss: 0.0151 Acc: 93.3333%\n",
      "\tvalidation 3-454: Loss: 0.0272 Acc: 93.3333%\n",
      "\tvalidation 3-455: Loss: 0.0126 Acc: 93.3333%\n",
      "\tvalidation 3-456: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 3-457: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-458: Loss: 0.0112 Acc: 96.6667%\n",
      "\tvalidation 3-459: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-460: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-461: Loss: 0.0291 Acc: 96.6667%\n",
      "\tvalidation 3-462: Loss: 0.0049 Acc: 93.3333%\n",
      "\tvalidation 3-463: Loss: 0.0260 Acc: 96.6667%\n",
      "\tvalidation 3-464: Loss: 0.0364 Acc: 86.6667%\n",
      "\tvalidation 3-465: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-466: Loss: 0.0183 Acc: 96.6667%\n",
      "\tvalidation 3-467: Loss: 0.0836 Acc: 86.6667%\n",
      "\tvalidation 3-468: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-469: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-470: Loss: 0.0133 Acc: 96.6667%\n",
      "\tvalidation 3-471: Loss: 0.0281 Acc: 93.3333%\n",
      "\tvalidation 3-472: Loss: 0.0326 Acc: 96.6667%\n",
      "\tvalidation 3-473: Loss: 0.0343 Acc: 96.6667%\n",
      "\tvalidation 3-474: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 3-475: Loss: 0.0284 Acc: 96.6667%\n",
      "\tvalidation 3-476: Loss: 0.0189 Acc: 93.3333%\n",
      "\tvalidation 3-477: Loss: 0.0605 Acc: 93.3333%\n",
      "\tvalidation 3-478: Loss: 0.0219 Acc: 93.3333%\n",
      "\tvalidation 3-479: Loss: 0.0302 Acc: 93.3333%\n",
      "\tvalidation 3-480: Loss: 0.0342 Acc: 93.3333%\n",
      "\tvalidation 3-481: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-482: Loss: 0.0535 Acc: 93.3333%\n",
      "\tvalidation 3-483: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 3-484: Loss: 0.1147 Acc: 80.0000%\n",
      "\tvalidation 3-485: Loss: 0.0068 Acc: 96.6667%\n",
      "\tvalidation 3-486: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 3-487: Loss: 0.0337 Acc: 96.6667%\n",
      "\tvalidation 3-488: Loss: 0.0175 Acc: 93.3333%\n",
      "\tvalidation 3-489: Loss: 0.0242 Acc: 93.3333%\n",
      "\tvalidation 3-490: Loss: 0.0164 Acc: 93.3333%\n",
      "\tvalidation 3-491: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-492: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-493: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 3-494: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-495: Loss: 0.0331 Acc: 93.3333%\n",
      "\tvalidation 3-496: Loss: 0.0235 Acc: 93.3333%\n",
      "\tvalidation 3-497: Loss: 0.0025 Acc: 93.3333%\n",
      "\tvalidation 3-498: Loss: 0.0249 Acc: 96.6667%\n",
      "\tvalidation 3-499: Loss: 0.0343 Acc: 93.3333%\n",
      "\tvalidation 3-500: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-501: Loss: 0.0031 Acc: 96.6667%\n",
      "\tvalidation 3-502: Loss: 0.0130 Acc: 96.6667%\n",
      "\tvalidation 3-503: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-504: Loss: 0.0249 Acc: 96.6667%\n",
      "\tvalidation 3-505: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-506: Loss: 0.0371 Acc: 93.3333%\n",
      "\tvalidation 3-507: Loss: 0.0360 Acc: 90.0000%\n",
      "\tvalidation 3-508: Loss: 0.0414 Acc: 93.3333%\n",
      "\tvalidation 3-509: Loss: 0.0785 Acc: 90.0000%\n",
      "\tvalidation 3-510: Loss: 0.0229 Acc: 90.0000%\n",
      "\tvalidation 3-511: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-512: Loss: 0.0510 Acc: 90.0000%\n",
      "\tvalidation 3-513: Loss: 0.0234 Acc: 93.3333%\n",
      "\tvalidation 3-514: Loss: 0.0597 Acc: 86.6667%\n",
      "\tvalidation 3-515: Loss: 0.0144 Acc: 96.6667%\n",
      "\tvalidation 3-516: Loss: 0.0451 Acc: 93.3333%\n",
      "\tvalidation 3-517: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-518: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 3-519: Loss: 0.0340 Acc: 93.3333%\n",
      "\tvalidation 3-520: Loss: 0.0066 Acc: 93.3333%\n",
      "\tvalidation 3-521: Loss: 0.0259 Acc: 83.3333%\n",
      "\tvalidation 3-522: Loss: 0.0267 Acc: 93.3333%\n",
      "\tvalidation 3-523: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 3-524: Loss: 0.0341 Acc: 96.6667%\n",
      "\tvalidation 3-525: Loss: 0.0024 Acc: 96.6667%\n",
      "\tvalidation 3-526: Loss: 0.0346 Acc: 90.0000%\n",
      "\tvalidation 3-527: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-528: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-529: Loss: 0.0513 Acc: 93.3333%\n",
      "\tvalidation 3-530: Loss: 0.0222 Acc: 93.3333%\n",
      "\tvalidation 3-531: Loss: 0.0099 Acc: 96.6667%\n",
      "\tvalidation 3-532: Loss: 0.0498 Acc: 90.0000%\n",
      "\tvalidation 3-533: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-534: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-535: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-536: Loss: 0.0343 Acc: 90.0000%\n",
      "\tvalidation 3-537: Loss: 0.0252 Acc: 93.3333%\n",
      "\tvalidation 3-538: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-539: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 3-540: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-541: Loss: 0.0452 Acc: 93.3333%\n",
      "\tvalidation 3-542: Loss: 0.0675 Acc: 90.0000%\n",
      "\tvalidation 3-543: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-544: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 3-545: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 3-546: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 3-547: Loss: 0.0350 Acc: 93.3333%\n",
      "\tvalidation 3-548: Loss: 0.0243 Acc: 96.6667%\n",
      "\tvalidation 3-549: Loss: 0.0422 Acc: 90.0000%\n",
      "\tvalidation 3-550: Loss: 0.0200 Acc: 96.6667%\n",
      "\tvalidation 3-551: Loss: 0.0099 Acc: 93.3333%\n",
      "\tvalidation 3-552: Loss: 0.0065 Acc: 96.6667%\n",
      "\tvalidation 3-553: Loss: 0.0331 Acc: 93.3333%\n",
      "\tvalidation 3-554: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-555: Loss: 0.0517 Acc: 93.3333%\n",
      "\tvalidation 3-556: Loss: 0.0378 Acc: 93.3333%\n",
      "\tvalidation 3-557: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-558: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-559: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-560: Loss: 0.0153 Acc: 93.3333%\n",
      "\tvalidation 3-561: Loss: 0.0699 Acc: 90.0000%\n",
      "\tvalidation 3-562: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-563: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 3-564: Loss: 0.0177 Acc: 96.6667%\n",
      "\tvalidation 3-565: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-566: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 3-567: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-568: Loss: 0.0897 Acc: 90.0000%\n",
      "\tvalidation 3-569: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 3-570: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 3-571: Loss: 0.0637 Acc: 93.3333%\n",
      "\tvalidation 3-572: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 3-573: Loss: 0.0168 Acc: 96.6667%\n",
      "\tvalidation 3-574: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-575: Loss: 0.0391 Acc: 93.3333%\n",
      "\tvalidation 3-576: Loss: 0.0239 Acc: 96.6667%\n",
      "\tvalidation 3-577: Loss: 0.0174 Acc: 96.6667%\n",
      "\tvalidation 3-578: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-579: Loss: 0.0569 Acc: 90.0000%\n",
      "\tvalidation 3-580: Loss: 0.0308 Acc: 93.3333%\n",
      "\tvalidation 3-581: Loss: 0.0224 Acc: 93.3333%\n",
      "\tvalidation 3-582: Loss: 0.0272 Acc: 96.6667%\n",
      "\tvalidation 3-583: Loss: 0.0116 Acc: 96.6667%\n",
      "\tvalidation 3-584: Loss: 0.0110 Acc: 96.6667%\n",
      "\tvalidation 3-585: Loss: 0.0137 Acc: 96.6667%\n",
      "\tvalidation 3-586: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-587: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 3-588: Loss: 0.0247 Acc: 93.3333%\n",
      "\tvalidation 3-589: Loss: 0.0283 Acc: 90.0000%\n",
      "\tvalidation 3-590: Loss: 0.0354 Acc: 93.3333%\n",
      "\tvalidation 3-591: Loss: 0.0034 Acc: 96.6667%\n",
      "\tvalidation 3-592: Loss: 0.0067 Acc: 96.6667%\n",
      "\tvalidation 3-593: Loss: 0.0408 Acc: 90.0000%\n",
      "\tvalidation 3-594: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-595: Loss: 0.0338 Acc: 93.3333%\n",
      "\tvalidation 3-596: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-597: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-598: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-599: Loss: 0.0143 Acc: 93.3333%\n",
      "\tvalidation 3-600: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-601: Loss: 0.0151 Acc: 96.6667%\n",
      "\tvalidation 3-602: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 3-603: Loss: 0.0749 Acc: 80.0000%\n",
      "\tvalidation 3-604: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-605: Loss: 0.0356 Acc: 93.3333%\n",
      "\tvalidation 3-606: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 3-607: Loss: 0.0297 Acc: 93.3333%\n",
      "\tvalidation 3-608: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-609: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-610: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-611: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-612: Loss: 0.0331 Acc: 96.6667%\n",
      "\tvalidation 3-613: Loss: 0.0171 Acc: 93.3333%\n",
      "\tvalidation 3-614: Loss: 0.0202 Acc: 96.6667%\n",
      "\tvalidation 3-615: Loss: 0.0221 Acc: 93.3333%\n",
      "\tvalidation 3-616: Loss: 0.0229 Acc: 96.6667%\n",
      "\tvalidation 3-617: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-618: Loss: 0.0348 Acc: 90.0000%\n",
      "\tvalidation 3-619: Loss: 0.0324 Acc: 96.6667%\n",
      "\tvalidation 3-620: Loss: 0.0059 Acc: 96.6667%\n",
      "\tvalidation 3-621: Loss: 0.0123 Acc: 96.6667%\n",
      "\tvalidation 3-622: Loss: 0.0142 Acc: 96.6667%\n",
      "\tvalidation 3-623: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 3-624: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 3-625: Loss: 0.0333 Acc: 93.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-626: Loss: 0.0526 Acc: 90.0000%\n",
      "\tvalidation 3-627: Loss: 0.0204 Acc: 96.6667%\n",
      "\tvalidation 3-628: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-629: Loss: 0.0165 Acc: 96.6667%\n",
      "\tvalidation 3-630: Loss: 0.0482 Acc: 93.3333%\n",
      "\tvalidation 3-631: Loss: 0.1180 Acc: 83.3333%\n",
      "\tvalidation 3-632: Loss: 0.0099 Acc: 96.6667%\n",
      "\tvalidation 3-633: Loss: 0.0265 Acc: 93.3333%\n",
      "\tvalidation 3-634: Loss: 0.0185 Acc: 96.6667%\n",
      "\tvalidation 3-635: Loss: 0.0420 Acc: 93.3333%\n",
      "\tvalidation 3-636: Loss: 0.0319 Acc: 93.3333%\n",
      "\tvalidation 3-637: Loss: 0.0365 Acc: 93.3333%\n",
      "\tvalidation 3-638: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-639: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-640: Loss: 0.0119 Acc: 96.6667%\n",
      "\tvalidation 3-641: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-642: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 3-643: Loss: 0.0089 Acc: 90.0000%\n",
      "\tvalidation 3-644: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-645: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-646: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-647: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-648: Loss: 0.0143 Acc: 96.6667%\n",
      "\tvalidation 3-649: Loss: 0.0096 Acc: 93.3333%\n",
      "\tvalidation 3-650: Loss: 0.0774 Acc: 90.0000%\n",
      "\tvalidation 3-651: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-652: Loss: 0.0289 Acc: 90.0000%\n",
      "\tvalidation 3-653: Loss: 0.0712 Acc: 90.0000%\n",
      "\tvalidation 3-654: Loss: 0.0542 Acc: 93.3333%\n",
      "\tvalidation 3-655: Loss: 0.0343 Acc: 96.6667%\n",
      "\tvalidation 3-656: Loss: 0.0435 Acc: 93.3333%\n",
      "\tvalidation 3-657: Loss: 0.0125 Acc: 96.6667%\n",
      "\tvalidation 3-658: Loss: 0.0056 Acc: 96.6667%\n",
      "\tvalidation 3-659: Loss: 0.0213 Acc: 96.6667%\n",
      "\tvalidation 3-660: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 3-661: Loss: 0.0123 Acc: 96.6667%\n",
      "\tvalidation 3-662: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 3-663: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-664: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 3-665: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-666: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-667: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-668: Loss: 0.0266 Acc: 96.6667%\n",
      "\tvalidation 3-669: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-670: Loss: 0.0349 Acc: 93.3333%\n",
      "\tvalidation 3-671: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 3-672: Loss: 0.0059 Acc: 96.6667%\n",
      "\tvalidation 3-673: Loss: 0.0345 Acc: 96.6667%\n",
      "\tvalidation 3-674: Loss: 0.0156 Acc: 96.6667%\n",
      "\tvalidation 3-675: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-676: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-677: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-678: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 3-679: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 3-680: Loss: 0.0081 Acc: 96.6667%\n",
      "\tvalidation 3-681: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-682: Loss: 0.0453 Acc: 90.0000%\n",
      "\tvalidation 3-683: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-684: Loss: 0.0650 Acc: 90.0000%\n",
      "\tvalidation 3-685: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-686: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-687: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-688: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-689: Loss: 0.0329 Acc: 96.6667%\n",
      "\tvalidation 3-690: Loss: 0.0392 Acc: 90.0000%\n",
      "\tvalidation 3-691: Loss: 0.0072 Acc: 96.6667%\n",
      "\tvalidation 3-692: Loss: 0.0145 Acc: 96.6667%\n",
      "\tvalidation 3-693: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 3-694: Loss: 0.0148 Acc: 96.6667%\n",
      "\tvalidation 3-695: Loss: 0.0239 Acc: 93.3333%\n",
      "\tvalidation 3-696: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-697: Loss: 0.0373 Acc: 93.3333%\n",
      "\tvalidation 3-698: Loss: 0.0549 Acc: 90.0000%\n",
      "\tvalidation 3-699: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 3-700: Loss: 0.0668 Acc: 86.6667%\n",
      "\tvalidation 3-701: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-702: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 3-703: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 3-704: Loss: 0.0103 Acc: 96.6667%\n",
      "\tvalidation 3-705: Loss: 0.0098 Acc: 93.3333%\n",
      "\tvalidation 3-706: Loss: 0.0489 Acc: 93.3333%\n",
      "\tvalidation 3-707: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-708: Loss: 0.0959 Acc: 86.6667%\n",
      "\tvalidation 3-709: Loss: 0.0287 Acc: 93.3333%\n",
      "\tvalidation 3-710: Loss: 0.0331 Acc: 96.6667%\n",
      "\tvalidation 3-711: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-712: Loss: 0.0660 Acc: 86.6667%\n",
      "\tvalidation 3-713: Loss: 0.0076 Acc: 96.6667%\n",
      "\tvalidation 3-714: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-715: Loss: 0.0282 Acc: 90.0000%\n",
      "\tvalidation 3-716: Loss: 0.0616 Acc: 90.0000%\n",
      "\tvalidation 3-717: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-718: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 3-719: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-720: Loss: 0.0287 Acc: 93.3333%\n",
      "\tvalidation 3-721: Loss: 0.0070 Acc: 93.3333%\n",
      "\tvalidation 3-722: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-723: Loss: 0.0134 Acc: 96.6667%\n",
      "\tvalidation 3-724: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-725: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-726: Loss: 0.0175 Acc: 93.3333%\n",
      "\tvalidation 3-727: Loss: 0.0243 Acc: 96.6667%\n",
      "\tvalidation 3-728: Loss: 0.0383 Acc: 90.0000%\n",
      "\tvalidation 3-729: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-730: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-731: Loss: 0.0232 Acc: 90.0000%\n",
      "\tvalidation 3-732: Loss: 0.0273 Acc: 93.3333%\n",
      "\tvalidation 3-733: Loss: 0.0229 Acc: 93.3333%\n",
      "\tvalidation 3-734: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-735: Loss: 0.0277 Acc: 93.3333%\n",
      "\tvalidation 3-736: Loss: 0.0249 Acc: 93.3333%\n",
      "\tvalidation 3-737: Loss: 0.0386 Acc: 93.3333%\n",
      "\tvalidation 3-738: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-739: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-740: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-741: Loss: 0.0021 Acc: 96.6667%\n",
      "\tvalidation 3-742: Loss: 0.0212 Acc: 96.6667%\n",
      "\tvalidation 3-743: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-744: Loss: 0.0310 Acc: 96.6667%\n",
      "\tvalidation 3-745: Loss: 0.0152 Acc: 96.6667%\n",
      "\tvalidation 3-746: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-747: Loss: 0.0053 Acc: 93.3333%\n",
      "\tvalidation 3-748: Loss: 0.0051 Acc: 93.3333%\n",
      "\tvalidation 3-749: Loss: 0.0420 Acc: 93.3333%\n",
      "\tvalidation 3-750: Loss: 0.0398 Acc: 93.3333%\n",
      "\tvalidation 3-751: Loss: 0.0166 Acc: 93.3333%\n",
      "\tvalidation 3-752: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 3-753: Loss: 0.0060 Acc: 96.6667%\n",
      "\tvalidation 3-754: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 3-755: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-756: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-757: Loss: 0.0393 Acc: 93.3333%\n",
      "\tvalidation 3-758: Loss: 0.0498 Acc: 93.3333%\n",
      "\tvalidation 3-759: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 3-760: Loss: 0.0305 Acc: 96.6667%\n",
      "\tvalidation 3-761: Loss: 0.0507 Acc: 93.3333%\n",
      "\tvalidation 3-762: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-763: Loss: 0.0437 Acc: 93.3333%\n",
      "\tvalidation 3-764: Loss: 0.0315 Acc: 93.3333%\n",
      "\tvalidation 3-765: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-766: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 3-767: Loss: 0.0123 Acc: 93.3333%\n",
      "\tvalidation 3-768: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-769: Loss: 0.0441 Acc: 90.0000%\n",
      "\tvalidation 3-770: Loss: 0.0670 Acc: 93.3333%\n",
      "\tvalidation 3-771: Loss: 0.0264 Acc: 93.3333%\n",
      "\tvalidation 3-772: Loss: 0.0311 Acc: 96.6667%\n",
      "\tvalidation 3-773: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 3-774: Loss: 0.0035 Acc: 96.6667%\n",
      "\tvalidation 3-775: Loss: 0.0459 Acc: 90.0000%\n",
      "\tvalidation 3-776: Loss: 0.0267 Acc: 96.6667%\n",
      "\tvalidation 3-777: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 3-778: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-779: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-780: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-781: Loss: 0.0138 Acc: 96.6667%\n",
      "\tvalidation 3-782: Loss: 0.0122 Acc: 96.6667%\n",
      "\tvalidation 3-783: Loss: 0.0160 Acc: 96.6667%\n",
      "\tvalidation 3-784: Loss: 0.0152 Acc: 96.6667%\n",
      "\tvalidation 3-785: Loss: 0.0501 Acc: 90.0000%\n",
      "\tvalidation 3-786: Loss: 0.0515 Acc: 93.3333%\n",
      "\tvalidation 3-787: Loss: 0.0511 Acc: 90.0000%\n",
      "\tvalidation 3-788: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-789: Loss: 0.0091 Acc: 96.6667%\n",
      "\tvalidation 3-790: Loss: 0.0395 Acc: 86.6667%\n",
      "\tvalidation 3-791: Loss: 0.0523 Acc: 93.3333%\n",
      "\tvalidation 3-792: Loss: 0.0897 Acc: 90.0000%\n",
      "\tvalidation 3-793: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-794: Loss: 0.0156 Acc: 96.6667%\n",
      "\tvalidation 3-795: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-796: Loss: 0.0291 Acc: 93.3333%\n",
      "\tvalidation 3-797: Loss: 0.0148 Acc: 96.6667%\n",
      "\tvalidation 3-798: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-799: Loss: 0.0135 Acc: 96.6667%\n",
      "\tvalidation 3-800: Loss: 0.0339 Acc: 96.6667%\n",
      "\tvalidation 3-801: Loss: 0.0205 Acc: 93.3333%\n",
      "\tvalidation 3-802: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-803: Loss: 0.0245 Acc: 96.6667%\n",
      "\tvalidation 3-804: Loss: 0.0058 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-805: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-806: Loss: 0.0325 Acc: 93.3333%\n",
      "\tvalidation 3-807: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-808: Loss: 0.0226 Acc: 96.6667%\n",
      "\tvalidation 3-809: Loss: 0.0129 Acc: 93.3333%\n",
      "\tvalidation 3-810: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-811: Loss: 0.0333 Acc: 93.3333%\n",
      "\tvalidation 3-812: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 3-813: Loss: 0.0223 Acc: 93.3333%\n",
      "\tvalidation 3-814: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-815: Loss: 0.0388 Acc: 93.3333%\n",
      "\tvalidation 3-816: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-817: Loss: 0.0324 Acc: 90.0000%\n",
      "\tvalidation 3-818: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-819: Loss: 0.0355 Acc: 93.3333%\n",
      "\tvalidation 3-820: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 3-821: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-822: Loss: 0.0074 Acc: 96.6667%\n",
      "\tvalidation 3-823: Loss: 0.0214 Acc: 96.6667%\n",
      "\tvalidation 3-824: Loss: 0.0707 Acc: 90.0000%\n",
      "\tvalidation 3-825: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 3-826: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-827: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-828: Loss: 0.0420 Acc: 93.3333%\n",
      "\tvalidation 3-829: Loss: 0.0274 Acc: 90.0000%\n",
      "\tvalidation 3-830: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-831: Loss: 0.0309 Acc: 96.6667%\n",
      "\tvalidation 3-832: Loss: 0.0163 Acc: 96.6667%\n",
      "\tvalidation 3-833: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-834: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-835: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-836: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-837: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-838: Loss: 0.0641 Acc: 86.6667%\n",
      "\tvalidation 3-839: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-840: Loss: 0.0268 Acc: 93.3333%\n",
      "\tvalidation 3-841: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-842: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-843: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-844: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-845: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 3-846: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-847: Loss: 0.0289 Acc: 93.3333%\n",
      "\tvalidation 3-848: Loss: 0.0263 Acc: 93.3333%\n",
      "\tvalidation 3-849: Loss: 0.0380 Acc: 93.3333%\n",
      "\tvalidation 3-850: Loss: 0.0695 Acc: 86.6667%\n",
      "\tvalidation 3-851: Loss: 0.0605 Acc: 93.3333%\n",
      "\tvalidation 3-852: Loss: 0.0251 Acc: 93.3333%\n",
      "\tvalidation 3-853: Loss: 0.0180 Acc: 96.6667%\n",
      "\tvalidation 3-854: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-855: Loss: 0.0273 Acc: 93.3333%\n",
      "\tvalidation 3-856: Loss: 0.0268 Acc: 93.3333%\n",
      "\tvalidation 3-857: Loss: 0.0381 Acc: 90.0000%\n",
      "\tvalidation 3-858: Loss: 0.0104 Acc: 93.3333%\n",
      "\tvalidation 3-859: Loss: 0.0219 Acc: 96.6667%\n",
      "\tvalidation 3-860: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-861: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-862: Loss: 0.0282 Acc: 93.3333%\n",
      "\tvalidation 3-863: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-864: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 3-865: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-866: Loss: 0.0113 Acc: 96.6667%\n",
      "\tvalidation 3-867: Loss: 0.0733 Acc: 90.0000%\n",
      "\tvalidation 3-868: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 3-869: Loss: 0.0032 Acc: 93.3333%\n",
      "\tvalidation 3-870: Loss: 0.0527 Acc: 83.3333%\n",
      "\tvalidation 3-871: Loss: 0.0266 Acc: 93.3333%\n",
      "\tvalidation 3-872: Loss: 0.0225 Acc: 96.6667%\n",
      "\tvalidation 3-873: Loss: 0.0299 Acc: 96.6667%\n",
      "\tvalidation 3-874: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-875: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-876: Loss: 0.0383 Acc: 93.3333%\n",
      "\tvalidation 3-877: Loss: 0.0387 Acc: 93.3333%\n",
      "\tvalidation 3-878: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 3-879: Loss: 0.0580 Acc: 93.3333%\n",
      "\tvalidation 3-880: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-881: Loss: 0.0193 Acc: 93.3333%\n",
      "\tvalidation 3-882: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-883: Loss: 0.0068 Acc: 96.6667%\n",
      "\tvalidation 3-884: Loss: 0.0090 Acc: 96.6667%\n",
      "\tvalidation 3-885: Loss: 0.0301 Acc: 96.6667%\n",
      "\tvalidation 3-886: Loss: 0.0320 Acc: 90.0000%\n",
      "\tvalidation 3-887: Loss: 0.0131 Acc: 90.0000%\n",
      "\tvalidation 3-888: Loss: 0.0231 Acc: 93.3333%\n",
      "\tvalidation 3-889: Loss: 0.0175 Acc: 96.6667%\n",
      "\tvalidation 3-890: Loss: 0.0412 Acc: 96.6667%\n",
      "\tvalidation 3-891: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-892: Loss: 0.0168 Acc: 93.3333%\n",
      "\tvalidation 3-893: Loss: 0.0221 Acc: 96.6667%\n",
      "\tvalidation 3-894: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-895: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-896: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-897: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 3-898: Loss: 0.0108 Acc: 96.6667%\n",
      "\tvalidation 3-899: Loss: 0.0511 Acc: 90.0000%\n",
      "\tvalidation 3-900: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-901: Loss: 0.0152 Acc: 93.3333%\n",
      "\tvalidation 3-902: Loss: 0.0883 Acc: 86.6667%\n",
      "\tvalidation 3-903: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-904: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-905: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 3-906: Loss: 0.0085 Acc: 90.0000%\n",
      "\tvalidation 3-907: Loss: 0.0008 Acc: 100.0000%\n",
      "\tvalidation 3-908: Loss: 0.0317 Acc: 96.6667%\n",
      "\tvalidation 3-909: Loss: 0.0564 Acc: 86.6667%\n",
      "\tvalidation 3-910: Loss: 0.0083 Acc: 96.6667%\n",
      "\tvalidation 3-911: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-912: Loss: 0.0450 Acc: 93.3333%\n",
      "\tvalidation 3-913: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-914: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-915: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-916: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-917: Loss: 0.0015 Acc: 96.6667%\n",
      "\tvalidation 3-918: Loss: 0.0309 Acc: 93.3333%\n",
      "\tvalidation 3-919: Loss: 0.0073 Acc: 93.3333%\n",
      "\tvalidation 3-920: Loss: 0.0109 Acc: 96.6667%\n",
      "\tvalidation 3-921: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 3-922: Loss: 0.0313 Acc: 96.6667%\n",
      "\tvalidation 3-923: Loss: 0.0217 Acc: 96.6667%\n",
      "\tvalidation 3-924: Loss: 0.0168 Acc: 96.6667%\n",
      "\tvalidation 3-925: Loss: 0.0250 Acc: 86.6667%\n",
      "\tvalidation 3-926: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-927: Loss: 0.0450 Acc: 93.3333%\n",
      "\tvalidation 3-928: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-929: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-930: Loss: 0.0022 Acc: 96.6667%\n",
      "\tvalidation 3-931: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-932: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 3-933: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-934: Loss: 0.0183 Acc: 96.6667%\n",
      "\tvalidation 3-935: Loss: 0.0280 Acc: 93.3333%\n",
      "\tvalidation 3-936: Loss: 0.0311 Acc: 93.3333%\n",
      "\tvalidation 3-937: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-938: Loss: 0.0285 Acc: 93.3333%\n",
      "\tvalidation 3-939: Loss: 0.0351 Acc: 96.6667%\n",
      "\tvalidation 3-940: Loss: 0.0097 Acc: 96.6667%\n",
      "\tvalidation 3-941: Loss: 0.0119 Acc: 96.6667%\n",
      "\tvalidation 3-942: Loss: 0.0259 Acc: 93.3333%\n",
      "\tvalidation 3-943: Loss: 0.0458 Acc: 93.3333%\n",
      "\tvalidation 3-944: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-945: Loss: 0.0051 Acc: 96.6667%\n",
      "\tvalidation 3-946: Loss: 0.0163 Acc: 96.6667%\n",
      "\tvalidation 3-947: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 3-948: Loss: 0.0324 Acc: 93.3333%\n",
      "\tvalidation 3-949: Loss: 0.0073 Acc: 96.6667%\n",
      "\tvalidation 3-950: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-951: Loss: 0.0216 Acc: 93.3333%\n",
      "\tvalidation 3-952: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-953: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-954: Loss: 0.0435 Acc: 93.3333%\n",
      "\tvalidation 3-955: Loss: 0.0337 Acc: 96.6667%\n",
      "\tvalidation 3-956: Loss: 0.0184 Acc: 96.6667%\n",
      "\tvalidation 3-957: Loss: 0.0150 Acc: 96.6667%\n",
      "\tvalidation 3-958: Loss: 0.0176 Acc: 96.6667%\n",
      "\tvalidation 3-959: Loss: 0.0115 Acc: 96.6667%\n",
      "\tvalidation 3-960: Loss: 0.0301 Acc: 93.3333%\n",
      "\tvalidation 3-961: Loss: 0.0057 Acc: 96.6667%\n",
      "\tvalidation 3-962: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-963: Loss: 0.0036 Acc: 96.6667%\n",
      "\tvalidation 3-964: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-965: Loss: 0.0287 Acc: 96.6667%\n",
      "\tvalidation 3-966: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 3-967: Loss: 0.0495 Acc: 93.3333%\n",
      "\tvalidation 3-968: Loss: 0.0273 Acc: 93.3333%\n",
      "\tvalidation 3-969: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-970: Loss: 0.0132 Acc: 93.3333%\n",
      "\tvalidation 3-971: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-972: Loss: 0.0224 Acc: 90.0000%\n",
      "\tvalidation 3-973: Loss: 0.0238 Acc: 96.6667%\n",
      "\tvalidation 3-974: Loss: 0.0315 Acc: 96.6667%\n",
      "\tvalidation 3-975: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-976: Loss: 0.0207 Acc: 93.3333%\n",
      "\tvalidation 3-977: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-978: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-979: Loss: 0.0222 Acc: 93.3333%\n",
      "\tvalidation 3-980: Loss: 0.0221 Acc: 96.6667%\n",
      "\tvalidation 3-981: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-982: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-983: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 3-984: Loss: 0.0246 Acc: 90.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-985: Loss: 0.0300 Acc: 93.3333%\n",
      "\tvalidation 3-986: Loss: 0.0333 Acc: 96.6667%\n",
      "\tvalidation 3-987: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-988: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-989: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-990: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-991: Loss: 0.0028 Acc: 96.6667%\n",
      "\tvalidation 3-992: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-993: Loss: 0.0152 Acc: 96.6667%\n",
      "\tvalidation 3-994: Loss: 0.0145 Acc: 93.3333%\n",
      "\tvalidation 3-995: Loss: 0.0261 Acc: 96.6667%\n",
      "\tvalidation 3-996: Loss: 0.0011 Acc: 100.0000%\n",
      "\tvalidation 3-997: Loss: 0.0197 Acc: 93.3333%\n",
      "\tvalidation 3-998: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-999: Loss: 0.0086 Acc: 96.6667%\n",
      "\tvalidation 3-1000: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1001: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-1002: Loss: 0.0185 Acc: 93.3333%\n",
      "\tvalidation 3-1003: Loss: 0.0226 Acc: 90.0000%\n",
      "\tvalidation 3-1004: Loss: 0.0268 Acc: 93.3333%\n",
      "\tvalidation 3-1005: Loss: 0.0267 Acc: 93.3333%\n",
      "\tvalidation 3-1006: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1007: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1008: Loss: 0.0310 Acc: 93.3333%\n",
      "\tvalidation 3-1009: Loss: 0.0627 Acc: 90.0000%\n",
      "\tvalidation 3-1010: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1011: Loss: 0.0105 Acc: 96.6667%\n",
      "\tvalidation 3-1012: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1013: Loss: 0.0108 Acc: 96.6667%\n",
      "\tvalidation 3-1014: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 3-1015: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 3-1016: Loss: 0.0242 Acc: 96.6667%\n",
      "\tvalidation 3-1017: Loss: 0.0167 Acc: 96.6667%\n",
      "\tvalidation 3-1018: Loss: 0.0240 Acc: 96.6667%\n",
      "\tvalidation 3-1019: Loss: 0.0113 Acc: 96.6667%\n",
      "\tvalidation 3-1020: Loss: 0.0228 Acc: 93.3333%\n",
      "\tvalidation 3-1021: Loss: 0.0342 Acc: 96.6667%\n",
      "\tvalidation 3-1022: Loss: 0.0027 Acc: 96.6667%\n",
      "\tvalidation 3-1023: Loss: 0.0171 Acc: 96.6667%\n",
      "\tvalidation 3-1024: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-1025: Loss: 0.0300 Acc: 93.3333%\n",
      "\tvalidation 3-1026: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1027: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 3-1028: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1029: Loss: 0.0565 Acc: 93.3333%\n",
      "\tvalidation 3-1030: Loss: 0.0289 Acc: 90.0000%\n",
      "\tvalidation 3-1031: Loss: 0.0162 Acc: 93.3333%\n",
      "\tvalidation 3-1032: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1033: Loss: 0.0298 Acc: 96.6667%\n",
      "\tvalidation 3-1034: Loss: 0.0122 Acc: 96.6667%\n",
      "\tvalidation 3-1035: Loss: 0.0214 Acc: 93.3333%\n",
      "\tvalidation 3-1036: Loss: 0.0032 Acc: 96.6667%\n",
      "\tvalidation 3-1037: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1038: Loss: 0.0654 Acc: 90.0000%\n",
      "\tvalidation 3-1039: Loss: 0.0233 Acc: 96.6667%\n",
      "\tvalidation 3-1040: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-1041: Loss: 0.0547 Acc: 90.0000%\n",
      "\tvalidation 3-1042: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1043: Loss: 0.0025 Acc: 96.6667%\n",
      "\tvalidation 3-1044: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1045: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 3-1046: Loss: 0.0546 Acc: 93.3333%\n",
      "\tvalidation 3-1047: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1048: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1049: Loss: 0.0092 Acc: 96.6667%\n",
      "\tvalidation 3-1050: Loss: 0.0044 Acc: 96.6667%\n",
      "\tvalidation 3-1051: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1052: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-1053: Loss: 0.0125 Acc: 93.3333%\n",
      "\tvalidation 3-1054: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1055: Loss: 0.0329 Acc: 96.6667%\n",
      "\tvalidation 3-1056: Loss: 0.0065 Acc: 93.3333%\n",
      "\tvalidation 3-1057: Loss: 0.0173 Acc: 93.3333%\n",
      "\tvalidation 3-1058: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1059: Loss: 0.0312 Acc: 96.6667%\n",
      "\tvalidation 3-1060: Loss: 0.0448 Acc: 93.3333%\n",
      "\tvalidation 3-1061: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 3-1062: Loss: 0.0532 Acc: 93.3333%\n",
      "\tvalidation 3-1063: Loss: 0.0411 Acc: 93.3333%\n",
      "\tvalidation 3-1064: Loss: 0.0049 Acc: 96.6667%\n",
      "\tvalidation 3-1065: Loss: 0.0410 Acc: 93.3333%\n",
      "\tvalidation 3-1066: Loss: 0.0020 Acc: 96.6667%\n",
      "\tvalidation 3-1067: Loss: 0.0549 Acc: 90.0000%\n",
      "\tvalidation 3-1068: Loss: 0.0504 Acc: 93.3333%\n",
      "\tvalidation 3-1069: Loss: 0.0127 Acc: 96.6667%\n",
      "\tvalidation 3-1070: Loss: 0.0039 Acc: 96.6667%\n",
      "\tvalidation 3-1071: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1072: Loss: 0.0215 Acc: 96.6667%\n",
      "\tvalidation 3-1073: Loss: 0.0144 Acc: 93.3333%\n",
      "\tvalidation 3-1074: Loss: 0.0164 Acc: 96.6667%\n",
      "\tvalidation 3-1075: Loss: 0.0618 Acc: 90.0000%\n",
      "\tvalidation 3-1076: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1077: Loss: 0.0161 Acc: 93.3333%\n",
      "\tvalidation 3-1078: Loss: 0.0322 Acc: 96.6667%\n",
      "\tvalidation 3-1079: Loss: 0.0103 Acc: 96.6667%\n",
      "\tvalidation 3-1080: Loss: 0.0266 Acc: 93.3333%\n",
      "\tvalidation 3-1081: Loss: 0.0322 Acc: 96.6667%\n",
      "\tvalidation 3-1082: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1083: Loss: 0.0082 Acc: 96.6667%\n",
      "\tvalidation 3-1084: Loss: 0.0305 Acc: 93.3333%\n",
      "\tvalidation 3-1085: Loss: 0.0223 Acc: 86.6667%\n",
      "\tvalidation 3-1086: Loss: 0.0182 Acc: 93.3333%\n",
      "\tvalidation 3-1087: Loss: 0.0543 Acc: 93.3333%\n",
      "\tvalidation 3-1088: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-1089: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-1090: Loss: 0.0365 Acc: 93.3333%\n",
      "\tvalidation 3-1091: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1092: Loss: 0.0302 Acc: 96.6667%\n",
      "\tvalidation 3-1093: Loss: 0.0634 Acc: 90.0000%\n",
      "\tvalidation 3-1094: Loss: 0.0472 Acc: 90.0000%\n",
      "\tvalidation 3-1095: Loss: 0.0341 Acc: 93.3333%\n",
      "\tvalidation 3-1096: Loss: 0.0556 Acc: 93.3333%\n",
      "\tvalidation 3-1097: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1098: Loss: 0.0476 Acc: 93.3333%\n",
      "\tvalidation 3-1099: Loss: 0.0548 Acc: 93.3333%\n",
      "\tvalidation 3-1100: Loss: 0.0338 Acc: 96.6667%\n",
      "\tvalidation 3-1101: Loss: 0.0588 Acc: 93.3333%\n",
      "\tvalidation 3-1102: Loss: 0.0150 Acc: 93.3333%\n",
      "\tvalidation 3-1103: Loss: 0.0031 Acc: 96.6667%\n",
      "\tvalidation 3-1104: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-1105: Loss: 0.0038 Acc: 96.6667%\n",
      "\tvalidation 3-1106: Loss: 0.0430 Acc: 93.3333%\n",
      "\tvalidation 3-1107: Loss: 0.0077 Acc: 96.6667%\n",
      "\tvalidation 3-1108: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-1109: Loss: 0.0412 Acc: 86.6667%\n",
      "\tvalidation 3-1110: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1111: Loss: 0.0436 Acc: 93.3333%\n",
      "\tvalidation 3-1112: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1113: Loss: 0.0216 Acc: 93.3333%\n",
      "\tvalidation 3-1114: Loss: 0.0117 Acc: 93.3333%\n",
      "\tvalidation 3-1115: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1116: Loss: 0.0212 Acc: 96.6667%\n",
      "\tvalidation 3-1117: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1118: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-1119: Loss: 0.0257 Acc: 93.3333%\n",
      "\tvalidation 3-1120: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1121: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1122: Loss: 0.0292 Acc: 93.3333%\n",
      "\tvalidation 3-1123: Loss: 0.0107 Acc: 96.6667%\n",
      "\tvalidation 3-1124: Loss: 0.0226 Acc: 93.3333%\n",
      "\tvalidation 3-1125: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1126: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1127: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1128: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1129: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1130: Loss: 0.0191 Acc: 96.6667%\n",
      "\tvalidation 3-1131: Loss: 0.0527 Acc: 90.0000%\n",
      "\tvalidation 3-1132: Loss: 0.0179 Acc: 93.3333%\n",
      "\tvalidation 3-1133: Loss: 0.0138 Acc: 96.6667%\n",
      "\tvalidation 3-1134: Loss: 0.0308 Acc: 96.6667%\n",
      "\tvalidation 3-1135: Loss: 0.0290 Acc: 93.3333%\n",
      "\tvalidation 3-1136: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-1137: Loss: 0.0170 Acc: 96.6667%\n",
      "\tvalidation 3-1138: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1139: Loss: 0.0206 Acc: 96.6667%\n",
      "\tvalidation 3-1140: Loss: 0.0324 Acc: 90.0000%\n",
      "\tvalidation 3-1141: Loss: 0.0308 Acc: 96.6667%\n",
      "\tvalidation 3-1142: Loss: 0.0322 Acc: 93.3333%\n",
      "\tvalidation 3-1143: Loss: 0.0477 Acc: 93.3333%\n",
      "\tvalidation 3-1144: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-1145: Loss: 0.0458 Acc: 93.3333%\n",
      "\tvalidation 3-1146: Loss: 0.0190 Acc: 93.3333%\n",
      "\tvalidation 3-1147: Loss: 0.0276 Acc: 96.6667%\n",
      "\tvalidation 3-1148: Loss: 0.0600 Acc: 93.3333%\n",
      "\tvalidation 3-1149: Loss: 0.0117 Acc: 96.6667%\n",
      "\tvalidation 3-1150: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-1151: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1152: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 3-1153: Loss: 0.0317 Acc: 90.0000%\n",
      "\tvalidation 3-1154: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1155: Loss: 0.0318 Acc: 96.6667%\n",
      "\tvalidation 3-1156: Loss: 0.0140 Acc: 96.6667%\n",
      "\tvalidation 3-1157: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-1158: Loss: 0.0285 Acc: 93.3333%\n",
      "\tvalidation 3-1159: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 3-1160: Loss: 0.0007 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-1161: Loss: 0.0368 Acc: 93.3333%\n",
      "\tvalidation 3-1162: Loss: 0.0307 Acc: 96.6667%\n",
      "\tvalidation 3-1163: Loss: 0.0518 Acc: 90.0000%\n",
      "\tvalidation 3-1164: Loss: 0.0125 Acc: 96.6667%\n",
      "\tvalidation 3-1165: Loss: 0.0146 Acc: 93.3333%\n",
      "\tvalidation 3-1166: Loss: 0.0289 Acc: 93.3333%\n",
      "\tvalidation 3-1167: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1168: Loss: 0.0222 Acc: 93.3333%\n",
      "\tvalidation 3-1169: Loss: 0.0466 Acc: 93.3333%\n",
      "\tvalidation 3-1170: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1171: Loss: 0.0262 Acc: 96.6667%\n",
      "\tvalidation 3-1172: Loss: 0.0227 Acc: 96.6667%\n",
      "\tvalidation 3-1173: Loss: 0.0363 Acc: 90.0000%\n",
      "\tvalidation 3-1174: Loss: 0.0221 Acc: 96.6667%\n",
      "\tvalidation 3-1175: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1176: Loss: 0.0117 Acc: 96.6667%\n",
      "\tvalidation 3-1177: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1178: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1179: Loss: 0.0045 Acc: 96.6667%\n",
      "\tvalidation 3-1180: Loss: 0.0384 Acc: 93.3333%\n",
      "\tvalidation 3-1181: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1182: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1183: Loss: 0.0213 Acc: 93.3333%\n",
      "\tvalidation 3-1184: Loss: 0.0163 Acc: 96.6667%\n",
      "\tvalidation 3-1185: Loss: 0.0580 Acc: 86.6667%\n",
      "\tvalidation 3-1186: Loss: 0.0224 Acc: 96.6667%\n",
      "\tvalidation 3-1187: Loss: 0.0009 Acc: 96.6667%\n",
      "\tvalidation 3-1188: Loss: 0.0447 Acc: 93.3333%\n",
      "\tvalidation 3-1189: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1190: Loss: 0.0154 Acc: 96.6667%\n",
      "\tvalidation 3-1191: Loss: 0.0346 Acc: 93.3333%\n",
      "\tvalidation 3-1192: Loss: 0.0106 Acc: 96.6667%\n",
      "\tvalidation 3-1193: Loss: 0.0592 Acc: 86.6667%\n",
      "\tvalidation 3-1194: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 3-1195: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1196: Loss: 0.0086 Acc: 93.3333%\n",
      "\tvalidation 3-1197: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1198: Loss: 0.0282 Acc: 96.6667%\n",
      "\tvalidation 3-1199: Loss: 0.0570 Acc: 90.0000%\n",
      "\tvalidation 3-1200: Loss: 0.0156 Acc: 93.3333%\n",
      "\tvalidation 3-1201: Loss: 0.0513 Acc: 86.6667%\n",
      "\tvalidation 3-1202: Loss: 0.0105 Acc: 93.3333%\n",
      "\tvalidation 3-1203: Loss: 0.0135 Acc: 93.3333%\n",
      "\tvalidation 3-1204: Loss: 0.0050 Acc: 96.6667%\n",
      "\tvalidation 3-1205: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1206: Loss: 0.0425 Acc: 93.3333%\n",
      "\tvalidation 3-1207: Loss: 0.0238 Acc: 93.3333%\n",
      "\tvalidation 3-1208: Loss: 0.0382 Acc: 96.6667%\n",
      "\tvalidation 3-1209: Loss: 0.0572 Acc: 86.6667%\n",
      "\tvalidation 3-1210: Loss: 0.0407 Acc: 93.3333%\n",
      "\tvalidation 3-1211: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 3-1212: Loss: 0.0413 Acc: 93.3333%\n",
      "\tvalidation 3-1213: Loss: 0.0345 Acc: 93.3333%\n",
      "\tvalidation 3-1214: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-1215: Loss: 0.0288 Acc: 90.0000%\n",
      "\tvalidation 3-1216: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1217: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 3-1218: Loss: 0.0111 Acc: 93.3333%\n",
      "\tvalidation 3-1219: Loss: 0.0294 Acc: 93.3333%\n",
      "\tvalidation 3-1220: Loss: 0.0710 Acc: 86.6667%\n",
      "\tvalidation 3-1221: Loss: 0.0088 Acc: 96.6667%\n",
      "\tvalidation 3-1222: Loss: 0.0309 Acc: 93.3333%\n",
      "\tvalidation 3-1223: Loss: 0.0156 Acc: 96.6667%\n",
      "\tvalidation 3-1224: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1225: Loss: 0.0137 Acc: 90.0000%\n",
      "\tvalidation 3-1226: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-1227: Loss: 0.0231 Acc: 93.3333%\n",
      "\tvalidation 3-1228: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 3-1229: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1230: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1231: Loss: 0.0112 Acc: 93.3333%\n",
      "\tvalidation 3-1232: Loss: 0.0627 Acc: 90.0000%\n",
      "\tvalidation 3-1233: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-1234: Loss: 0.0003 Acc: 100.0000%\n",
      "\tvalidation 3-1235: Loss: 0.0619 Acc: 90.0000%\n",
      "\tvalidation 3-1236: Loss: 0.0070 Acc: 96.6667%\n",
      "\tvalidation 3-1237: Loss: 0.0326 Acc: 96.6667%\n",
      "\tvalidation 3-1238: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1239: Loss: 0.0161 Acc: 96.6667%\n",
      "\tvalidation 3-1240: Loss: 0.0330 Acc: 93.3333%\n",
      "\tvalidation 3-1241: Loss: 0.0368 Acc: 96.6667%\n",
      "\tvalidation 3-1242: Loss: 0.0455 Acc: 86.6667%\n",
      "\tvalidation 3-1243: Loss: 0.0345 Acc: 93.3333%\n",
      "\tvalidation 3-1244: Loss: 0.0009 Acc: 96.6667%\n",
      "\tvalidation 3-1245: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-1246: Loss: 0.0053 Acc: 96.6667%\n",
      "\tvalidation 3-1247: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1248: Loss: 0.0351 Acc: 93.3333%\n",
      "\tvalidation 3-1249: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1250: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1251: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1252: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1253: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1254: Loss: 0.0425 Acc: 93.3333%\n",
      "\tvalidation 3-1255: Loss: 0.0223 Acc: 96.6667%\n",
      "\tvalidation 3-1256: Loss: 0.0021 Acc: 100.0000%\n",
      "\tvalidation 3-1257: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1258: Loss: 0.0337 Acc: 93.3333%\n",
      "\tvalidation 3-1259: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1260: Loss: 0.0352 Acc: 93.3333%\n",
      "\tvalidation 3-1261: Loss: 0.0017 Acc: 96.6667%\n",
      "\tvalidation 3-1262: Loss: 0.0055 Acc: 96.6667%\n",
      "\tvalidation 3-1263: Loss: 0.0401 Acc: 93.3333%\n",
      "\tvalidation 3-1264: Loss: 0.0594 Acc: 93.3333%\n",
      "\tvalidation 3-1265: Loss: 0.0513 Acc: 90.0000%\n",
      "\tvalidation 3-1266: Loss: 0.0120 Acc: 93.3333%\n",
      "\tvalidation 3-1267: Loss: 0.0258 Acc: 93.3333%\n",
      "\tvalidation 3-1268: Loss: 0.0601 Acc: 90.0000%\n",
      "\tvalidation 3-1269: Loss: 0.0367 Acc: 93.3333%\n",
      "\tvalidation 3-1270: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1271: Loss: 0.0194 Acc: 93.3333%\n",
      "\tvalidation 3-1272: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1273: Loss: 0.0262 Acc: 96.6667%\n",
      "\tvalidation 3-1274: Loss: 0.0306 Acc: 93.3333%\n",
      "\tvalidation 3-1275: Loss: 0.0149 Acc: 96.6667%\n",
      "\tvalidation 3-1276: Loss: 0.0009 Acc: 96.6667%\n",
      "\tvalidation 3-1277: Loss: 0.0158 Acc: 93.3333%\n",
      "\tvalidation 3-1278: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 3-1279: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1280: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1281: Loss: 0.0096 Acc: 96.6667%\n",
      "\tvalidation 3-1282: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1283: Loss: 0.0617 Acc: 90.0000%\n",
      "\tvalidation 3-1284: Loss: 0.0157 Acc: 96.6667%\n",
      "\tvalidation 3-1285: Loss: 0.0340 Acc: 93.3333%\n",
      "\tvalidation 3-1286: Loss: 0.0375 Acc: 93.3333%\n",
      "\tvalidation 3-1287: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-1288: Loss: 0.0231 Acc: 93.3333%\n",
      "\tvalidation 3-1289: Loss: 0.0346 Acc: 93.3333%\n",
      "\tvalidation 3-1290: Loss: 0.0213 Acc: 96.6667%\n",
      "\tvalidation 3-1291: Loss: 0.0921 Acc: 86.6667%\n",
      "\tvalidation 3-1292: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1293: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1294: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1295: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 3-1296: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1297: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1298: Loss: 0.0005 Acc: 100.0000%\n",
      "\tvalidation 3-1299: Loss: 0.0068 Acc: 93.3333%\n",
      "\tvalidation 3-1300: Loss: 0.0426 Acc: 93.3333%\n",
      "\tvalidation 3-1301: Loss: 0.0515 Acc: 86.6667%\n",
      "\tvalidation 3-1302: Loss: 0.0241 Acc: 96.6667%\n",
      "\tvalidation 3-1303: Loss: 0.0287 Acc: 93.3333%\n",
      "\tvalidation 3-1304: Loss: 0.0121 Acc: 96.6667%\n",
      "\tvalidation 3-1305: Loss: 0.0375 Acc: 90.0000%\n",
      "\tvalidation 3-1306: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-1307: Loss: 0.0146 Acc: 93.3333%\n",
      "\tvalidation 3-1308: Loss: 0.0060 Acc: 93.3333%\n",
      "\tvalidation 3-1309: Loss: 0.0250 Acc: 96.6667%\n",
      "\tvalidation 3-1310: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1311: Loss: 0.0225 Acc: 93.3333%\n",
      "\tvalidation 3-1312: Loss: 0.0541 Acc: 90.0000%\n",
      "\tvalidation 3-1313: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-1314: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1315: Loss: 0.0336 Acc: 93.3333%\n",
      "\tvalidation 3-1316: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1317: Loss: 0.0451 Acc: 93.3333%\n",
      "\tvalidation 3-1318: Loss: 0.0145 Acc: 96.6667%\n",
      "\tvalidation 3-1319: Loss: 0.0366 Acc: 93.3333%\n",
      "\tvalidation 3-1320: Loss: 0.0151 Acc: 93.3333%\n",
      "\tvalidation 3-1321: Loss: 0.0010 Acc: 100.0000%\n",
      "\tvalidation 3-1322: Loss: 0.0240 Acc: 96.6667%\n",
      "\tvalidation 3-1323: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1324: Loss: 0.0231 Acc: 96.6667%\n",
      "\tvalidation 3-1325: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1326: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-1327: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-1328: Loss: 0.0121 Acc: 93.3333%\n",
      "\tvalidation 3-1329: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1330: Loss: 0.0346 Acc: 96.6667%\n",
      "\tvalidation 3-1331: Loss: 0.0278 Acc: 93.3333%\n",
      "\tvalidation 3-1332: Loss: 0.0352 Acc: 93.3333%\n",
      "\tvalidation 3-1333: Loss: 0.0174 Acc: 96.6667%\n",
      "\tvalidation 3-1334: Loss: 0.0293 Acc: 96.6667%\n",
      "\tvalidation 3-1335: Loss: 0.0788 Acc: 90.0000%\n",
      "\tvalidation 3-1336: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation 3-1337: Loss: 0.0110 Acc: 96.6667%\n",
      "\tvalidation 3-1338: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1339: Loss: 0.0031 Acc: 96.6667%\n",
      "\tvalidation 3-1340: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1341: Loss: 0.0173 Acc: 93.3333%\n",
      "\tvalidation 3-1342: Loss: 0.0398 Acc: 93.3333%\n",
      "\tvalidation 3-1343: Loss: 0.0516 Acc: 90.0000%\n",
      "\tvalidation 3-1344: Loss: 0.0377 Acc: 93.3333%\n",
      "\tvalidation 3-1345: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 3-1346: Loss: 0.0221 Acc: 96.6667%\n",
      "\tvalidation 3-1347: Loss: 0.0463 Acc: 86.6667%\n",
      "\tvalidation 3-1348: Loss: 0.0298 Acc: 96.6667%\n",
      "\tvalidation 3-1349: Loss: 0.0037 Acc: 96.6667%\n",
      "\tvalidation 3-1350: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-1351: Loss: 0.0023 Acc: 96.6667%\n",
      "\tvalidation 3-1352: Loss: 0.0057 Acc: 93.3333%\n",
      "\tvalidation 3-1353: Loss: 0.0127 Acc: 90.0000%\n",
      "\tvalidation 3-1354: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1355: Loss: 0.0313 Acc: 96.6667%\n",
      "\tvalidation 3-1356: Loss: 0.0457 Acc: 90.0000%\n",
      "\tvalidation 3-1357: Loss: 0.0052 Acc: 96.6667%\n",
      "\tvalidation 3-1358: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-1359: Loss: 0.0064 Acc: 96.6667%\n",
      "\tvalidation 3-1360: Loss: 0.0002 Acc: 100.0000%\n",
      "\tvalidation 3-1361: Loss: 0.0492 Acc: 90.0000%\n",
      "\tvalidation 3-1362: Loss: 0.0428 Acc: 93.3333%\n",
      "\tvalidation 3-1363: Loss: 0.0569 Acc: 86.6667%\n",
      "\tvalidation 3-1364: Loss: 0.0253 Acc: 93.3333%\n",
      "\tvalidation 3-1365: Loss: 0.0318 Acc: 93.3333%\n",
      "\tvalidation 3-1366: Loss: 0.0019 Acc: 96.6667%\n",
      "\tvalidation 3-1367: Loss: 0.0484 Acc: 93.3333%\n",
      "\tvalidation 3-1368: Loss: 0.0224 Acc: 93.3333%\n",
      "\tvalidation 3-1369: Loss: 0.0499 Acc: 90.0000%\n",
      "\tvalidation 3-1370: Loss: 0.0603 Acc: 90.0000%\n",
      "\tvalidation 3-1371: Loss: 0.0190 Acc: 96.6667%\n",
      "\tvalidation 3-1372: Loss: 0.0010 Acc: 96.6667%\n",
      "\tvalidation 3-1373: Loss: 0.0186 Acc: 96.6667%\n",
      "\tvalidation 3-1374: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1375: Loss: 0.0087 Acc: 96.6667%\n",
      "\tvalidation 3-1376: Loss: 0.0006 Acc: 100.0000%\n",
      "\tvalidation 3-1377: Loss: 0.0177 Acc: 93.3333%\n",
      "\tvalidation 3-1378: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1379: Loss: 0.0231 Acc: 93.3333%\n",
      "\tvalidation 3-1380: Loss: 0.0271 Acc: 93.3333%\n",
      "\tvalidation 3-1381: Loss: 0.0149 Acc: 93.3333%\n",
      "\tvalidation 3-1382: Loss: 0.0041 Acc: 96.6667%\n",
      "\tvalidation 3-1383: Loss: 0.0569 Acc: 93.3333%\n",
      "\tvalidation 3-1384: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1385: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 3-1386: Loss: 0.0014 Acc: 96.6667%\n",
      "\tvalidation 3-1387: Loss: 0.0389 Acc: 93.3333%\n",
      "\tvalidation 3-1388: Loss: 0.0147 Acc: 96.6667%\n",
      "\tvalidation 3-1389: Loss: 0.0121 Acc: 93.3333%\n",
      "\tvalidation 3-1390: Loss: 0.0011 Acc: 96.6667%\n",
      "\tvalidation 3-1391: Loss: 0.0138 Acc: 96.6667%\n",
      "\tvalidation 3-1392: Loss: 0.0314 Acc: 96.6667%\n",
      "\tvalidation 3-1393: Loss: 0.1060 Acc: 86.6667%\n",
      "\tvalidation 3-1394: Loss: 0.0391 Acc: 90.0000%\n",
      "\tvalidation 3-1395: Loss: 0.0016 Acc: 96.6667%\n",
      "\tvalidation 3-1396: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1397: Loss: 0.0009 Acc: 100.0000%\n",
      "\tvalidation 3-1398: Loss: 0.0269 Acc: 96.6667%\n",
      "\tvalidation 3-1399: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1400: Loss: 0.0075 Acc: 96.6667%\n",
      "\tvalidation 3-1401: Loss: 0.1073 Acc: 83.3333%\n",
      "\tvalidation 3-1402: Loss: 0.0052 Acc: 96.6667%\n",
      "\tvalidation 3-1403: Loss: 0.0226 Acc: 96.6667%\n",
      "\tvalidation 3-1404: Loss: 0.0347 Acc: 96.6667%\n",
      "\tvalidation 3-1405: Loss: 0.0043 Acc: 96.6667%\n",
      "\tvalidation 3-1406: Loss: 0.0711 Acc: 90.0000%\n",
      "\tvalidation 3-1407: Loss: 0.0331 Acc: 93.3333%\n",
      "\tvalidation 3-1408: Loss: 0.0222 Acc: 96.6667%\n",
      "\tvalidation 3-1409: Loss: 0.0061 Acc: 96.6667%\n",
      "\tvalidation 3-1410: Loss: 0.0430 Acc: 90.0000%\n",
      "\tvalidation 3-1411: Loss: 0.0539 Acc: 90.0000%\n",
      "\tvalidation 3-1412: Loss: 0.0081 Acc: 96.6667%\n",
      "\tvalidation 3-1413: Loss: 0.0013 Acc: 96.6667%\n",
      "\tvalidation 3-1414: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1415: Loss: 0.0062 Acc: 96.6667%\n",
      "\tvalidation 3-1416: Loss: 0.0421 Acc: 96.6667%\n",
      "\tvalidation 3-1417: Loss: 0.0026 Acc: 96.6667%\n",
      "\tvalidation 3-1418: Loss: 0.0067 Acc: 96.6667%\n",
      "\tvalidation 3-1419: Loss: 0.0146 Acc: 93.3333%\n",
      "\tvalidation 3-1420: Loss: 0.0250 Acc: 96.6667%\n",
      "\tvalidation 3-1421: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1422: Loss: 0.0124 Acc: 96.6667%\n",
      "\tvalidation 3-1423: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1424: Loss: 0.0180 Acc: 93.3333%\n",
      "\tvalidation 3-1425: Loss: 0.0963 Acc: 86.6667%\n",
      "\tvalidation 3-1426: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1427: Loss: 0.0209 Acc: 96.6667%\n",
      "\tvalidation 3-1428: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1429: Loss: 0.0146 Acc: 96.6667%\n",
      "\tvalidation 3-1430: Loss: 0.0285 Acc: 96.6667%\n",
      "\tvalidation 3-1431: Loss: 0.0211 Acc: 96.6667%\n",
      "\tvalidation 3-1432: Loss: 0.0498 Acc: 86.6667%\n",
      "\tvalidation 3-1433: Loss: 0.0530 Acc: 93.3333%\n",
      "\tvalidation 3-1434: Loss: 0.0336 Acc: 96.6667%\n",
      "\tvalidation 3-1435: Loss: 0.0785 Acc: 86.6667%\n",
      "\tvalidation 3-1436: Loss: 0.0046 Acc: 96.6667%\n",
      "\tvalidation 3-1437: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1438: Loss: 0.0104 Acc: 96.6667%\n",
      "\tvalidation 3-1439: Loss: 0.0828 Acc: 86.6667%\n",
      "\tvalidation 3-1440: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1441: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1442: Loss: 0.0118 Acc: 93.3333%\n",
      "\tvalidation 3-1443: Loss: 0.0125 Acc: 96.6667%\n",
      "\tvalidation 3-1444: Loss: 0.0054 Acc: 96.6667%\n",
      "\tvalidation 3-1445: Loss: 0.0029 Acc: 96.6667%\n",
      "\tvalidation 3-1446: Loss: 0.0144 Acc: 96.6667%\n",
      "\tvalidation 3-1447: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1448: Loss: 0.0062 Acc: 93.3333%\n",
      "\tvalidation 3-1449: Loss: 0.0229 Acc: 90.0000%\n",
      "\tvalidation 3-1450: Loss: 0.0240 Acc: 96.6667%\n",
      "\tvalidation 3-1451: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1452: Loss: 0.0488 Acc: 93.3333%\n",
      "\tvalidation 3-1453: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1454: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1455: Loss: 0.0037 Acc: 93.3333%\n",
      "\tvalidation 3-1456: Loss: 0.0030 Acc: 96.6667%\n",
      "\tvalidation 3-1457: Loss: 0.0412 Acc: 86.6667%\n",
      "\tvalidation 3-1458: Loss: 0.0576 Acc: 76.6667%\n",
      "\tvalidation 3-1459: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1460: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-1461: Loss: 0.0348 Acc: 93.3333%\n",
      "\tvalidation 3-1462: Loss: 0.0018 Acc: 96.6667%\n",
      "\tvalidation 3-1463: Loss: 0.0153 Acc: 96.6667%\n",
      "\tvalidation 3-1464: Loss: 0.0200 Acc: 96.6667%\n",
      "\tvalidation 3-1465: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1466: Loss: 0.0063 Acc: 96.6667%\n",
      "\tvalidation 3-1467: Loss: 0.0004 Acc: 100.0000%\n",
      "\tvalidation 3-1468: Loss: 0.0091 Acc: 96.6667%\n",
      "\tvalidation 3-1469: Loss: 0.0085 Acc: 96.6667%\n",
      "\tvalidation 3-1470: Loss: 0.0193 Acc: 96.6667%\n",
      "\tvalidation 3-1471: Loss: 0.0102 Acc: 96.6667%\n",
      "\tvalidation 3-1472: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1473: Loss: 0.0460 Acc: 90.0000%\n",
      "\tvalidation 3-1474: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1475: Loss: 0.0093 Acc: 93.3333%\n",
      "\tvalidation 3-1476: Loss: 0.0438 Acc: 93.3333%\n",
      "\tvalidation 3-1477: Loss: 0.0657 Acc: 86.6667%\n",
      "\tvalidation 3-1478: Loss: 0.0283 Acc: 93.3333%\n",
      "\tvalidation 3-1479: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1480: Loss: 0.0007 Acc: 100.0000%\n",
      "\tvalidation 3-1481: Loss: 0.0078 Acc: 93.3333%\n",
      "\tvalidation 3-1482: Loss: 0.0042 Acc: 96.6667%\n",
      "\tvalidation 3-1483: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1484: Loss: 0.0279 Acc: 96.6667%\n",
      "\tvalidation 3-1485: Loss: 0.0001 Acc: 100.0000%\n",
      "\tvalidation 3-1486: Loss: 0.0601 Acc: 90.0000%\n",
      "\tvalidation 3-1487: Loss: 0.0397 Acc: 90.0000%\n",
      "\tvalidation 3-1488: Loss: 0.0207 Acc: 96.6667%\n",
      "\tvalidation 3-1489: Loss: 0.0334 Acc: 96.6667%\n",
      "\tvalidation 3-1490: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1491: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1492: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1493: Loss: 0.0199 Acc: 96.6667%\n",
      "\tvalidation 3-1494: Loss: 0.0214 Acc: 96.6667%\n",
      "\tvalidation 3-1495: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1496: Loss: 0.0033 Acc: 96.6667%\n",
      "\tvalidation 3-1497: Loss: 0.0012 Acc: 96.6667%\n",
      "\tvalidation 3-1498: Loss: 0.0413 Acc: 93.3333%\n",
      "\tvalidation 3-1499: Loss: 0.0000 Acc: 100.0000%\n",
      "\tvalidation 3-1500: Loss: 0.0341 Acc: 90.0000%\n",
      "\ttrain Loss: 0.0003 Acc: 99.7237%\n",
      "\tvalidation Loss: 0.0182 Acc: 95.8022%\n",
      "Time passed 2h 30m 15s\n",
      "--------------------\n",
      "learning_rate: 0.01\n",
      "Epoch [4/10]:\n",
      "\ttrain 4-1: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-3: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-4: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-5: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 4-6: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-7: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-8: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-9: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-10: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-11: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-12: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-13: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-14: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-15: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-16: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-17: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-18: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-19: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-20: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-21: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-22: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-23: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-24: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-25: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-26: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-27: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-28: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-29: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-30: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 4-31: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-32: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-33: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 4-34: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-35: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-36: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-37: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-38: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-39: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 4-40: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-41: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-42: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 4-43: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-44: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-45: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-46: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-47: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-48: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-49: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-50: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-51: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-52: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-53: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-54: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-55: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-56: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-57: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-58: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 4-59: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-60: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-61: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-62: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-63: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-64: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 4-65: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-66: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-67: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-68: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-69: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-70: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-71: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-72: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-73: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-74: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-75: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-76: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-77: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-78: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-79: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-80: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-81: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-82: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-83: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-84: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-85: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-86: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 4-87: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-88: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-89: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-90: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 4-91: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-92: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-93: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-94: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-95: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-96: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-97: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-98: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-99: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-101: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 4-102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-107: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 4-108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-112: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 4-113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-114: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-116: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 4-117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-119: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 4-120: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-127: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 4-128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-129: Loss: 0.0026 Acc: 100.0000%\n",
      "\ttrain 4-130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-136: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-145: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-151: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-152: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-171: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-173: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-177: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-182: Loss: 0.0094 Acc: 93.3333%\n",
      "\ttrain 4-183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-185: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 4-186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-193: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-195: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 4-196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-198: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-206: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-218: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-220: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 4-221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-222: Loss: 0.0057 Acc: 96.6667%\n",
      "\ttrain 4-223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-227: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-236: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-239: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 4-240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-247: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-248: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-249: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-273: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-277: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-289: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-291: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-294: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-308: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-311: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-316: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-317: Loss: 0.0024 Acc: 96.6667%\n",
      "\ttrain 4-318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-336: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-342: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-343: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 4-344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-345: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-352: Loss: 0.0053 Acc: 96.6667%\n",
      "\ttrain 4-353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-354: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-355: Loss: 0.0051 Acc: 96.6667%\n",
      "\ttrain 4-356: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-358: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-368: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-372: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 4-373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-376: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-382: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-384: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 4-385: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-386: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-391: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-393: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-396: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-398: Loss: 0.0008 Acc: 100.0000%\n",
      "\ttrain 4-399: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-402: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-403: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-408: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-409: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-410: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-412: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-413: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 4-414: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-415: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-417: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-418: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-419: Loss: 0.0126 Acc: 96.6667%\n",
      "\ttrain 4-420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-426: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 4-427: Loss: 0.0054 Acc: 96.6667%\n",
      "\ttrain 4-428: Loss: 0.0010 Acc: 96.6667%\n",
      "\ttrain 4-429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-430: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-432: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 4-433: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-434: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 4-435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-437: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-439: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-442: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-443: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 4-444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-446: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-447: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-449: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-450: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 4-451: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 4-452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-453: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-454: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-455: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-458: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-461: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 4-462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-465: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-466: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-469: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-471: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-472: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-475: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-477: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-478: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-479: Loss: 0.0063 Acc: 96.6667%\n",
      "\ttrain 4-480: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-481: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-485: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-487: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-489: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-490: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-494: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-498: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-500: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-501: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-502: Loss: 0.0072 Acc: 96.6667%\n",
      "\ttrain 4-503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-505: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-507: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-508: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-510: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-511: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 4-512: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-513: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-514: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-519: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-521: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-522: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-523: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 4-524: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-526: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-527: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-528: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-529: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-530: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-531: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-533: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-534: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-536: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-537: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-538: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-539: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-541: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-542: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 4-543: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-545: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-546: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-549: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-550: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-551: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-552: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-553: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-554: Loss: 0.0011 Acc: 96.6667%\n",
      "\ttrain 4-555: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-556: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-557: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 4-558: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-559: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-560: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-561: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-562: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-563: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-565: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-566: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 4-567: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-569: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-570: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-572: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-573: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-574: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-575: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-576: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-577: Loss: 0.0012 Acc: 96.6667%\n",
      "\ttrain 4-578: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-581: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-582: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-584: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-587: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 4-588: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-590: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-591: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-593: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-594: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-597: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-598: Loss: 0.0051 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-600: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-603: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-607: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-609: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-610: Loss: 0.0017 Acc: 96.6667%\n",
      "\ttrain 4-611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-612: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-613: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-615: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-616: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 4-617: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-618: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-619: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-620: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-622: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-624: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-628: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-629: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-631: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-632: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-633: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-634: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-635: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-636: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-637: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-639: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-640: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-641: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-642: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-643: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-644: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-645: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-646: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-648: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-649: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 4-650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-651: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-652: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-653: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 4-654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-656: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-657: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-658: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-660: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-661: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-663: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-665: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-666: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-667: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-668: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 4-669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-671: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-672: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-673: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-674: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-675: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-677: Loss: 0.0032 Acc: 100.0000%\n",
      "\ttrain 4-678: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-679: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-680: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-681: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-684: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-686: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-687: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-688: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-689: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-690: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-691: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-692: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-693: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 4-694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-695: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-696: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-697: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-698: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-699: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-700: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-701: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-704: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-705: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-706: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-707: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-708: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-710: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-711: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-713: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-714: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-716: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-717: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-719: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-721: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-722: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-723: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-724: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-725: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-727: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-728: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-730: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 4-731: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-733: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-734: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-735: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-736: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-737: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-738: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-739: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-740: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 4-741: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-742: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-743: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-744: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-745: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-746: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 4-747: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-748: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-749: Loss: 0.0019 Acc: 96.6667%\n",
      "\ttrain 4-750: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-751: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-752: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-753: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-754: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-755: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-756: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-757: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-758: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-759: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-761: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-762: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-763: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-764: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-765: Loss: 0.0036 Acc: 96.6667%\n",
      "\ttrain 4-766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-767: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-768: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-769: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-772: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-773: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-775: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-777: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-778: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-783: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-785: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-788: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-789: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-790: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-794: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-795: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-797: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-799: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-800: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-801: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-802: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-804: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-809: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-810: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-812: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-815: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-816: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-817: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-818: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-819: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-820: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-821: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-822: Loss: 0.0026 Acc: 96.6667%\n",
      "\ttrain 4-823: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-824: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-825: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-827: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 4-828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-829: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-830: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-831: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 4-832: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-833: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-834: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-835: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-836: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-838: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-839: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-840: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-841: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-842: Loss: 0.0015 Acc: 100.0000%\n",
      "\ttrain 4-843: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-844: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-846: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-847: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-848: Loss: 0.0014 Acc: 100.0000%\n",
      "\ttrain 4-849: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-850: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-852: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-853: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-855: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-856: Loss: 0.0056 Acc: 96.6667%\n",
      "\ttrain 4-857: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-859: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-860: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-861: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-862: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-864: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-865: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-866: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-867: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-868: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-870: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 4-871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-872: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-873: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-874: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-875: Loss: 0.0018 Acc: 96.6667%\n",
      "\ttrain 4-876: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-878: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-879: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-880: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-881: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-882: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-884: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-885: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-886: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-887: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-889: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-890: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-891: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-892: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-893: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-894: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-895: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-896: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 4-897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-898: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-905: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-907: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-908: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-910: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-911: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-914: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-915: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-916: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-917: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-918: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-921: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-922: Loss: 0.0095 Acc: 96.6667%\n",
      "\ttrain 4-923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-924: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-926: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-928: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-929: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-930: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-931: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-932: Loss: 0.0069 Acc: 93.3333%\n",
      "\ttrain 4-933: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-934: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-935: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-936: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-937: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-939: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-940: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-942: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-944: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-945: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-946: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-947: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-948: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 4-949: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-950: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-951: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-953: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-954: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-955: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-958: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-959: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 4-960: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-961: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-962: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-964: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-965: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-966: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-969: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-970: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-973: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-978: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-979: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-982: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-984: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-987: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-988: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-989: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-990: Loss: 0.0048 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-992: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-994: Loss: 0.0030 Acc: 100.0000%\n",
      "\ttrain 4-995: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-996: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-998: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-999: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-1000: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1001: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1002: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1003: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1004: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1005: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1006: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1008: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1009: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1010: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1011: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1012: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1013: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1015: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1017: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1018: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1019: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1020: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1022: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1023: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1024: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1029: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1032: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1033: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1035: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 4-1036: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1037: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1038: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1040: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 4-1041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1042: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1044: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1045: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1046: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1047: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1051: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-1052: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1053: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1054: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1055: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1056: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1057: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1058: Loss: 0.0030 Acc: 96.6667%\n",
      "\ttrain 4-1059: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1060: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1062: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1063: Loss: 0.0023 Acc: 96.6667%\n",
      "\ttrain 4-1064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1065: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1066: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 4-1067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1068: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1070: Loss: 0.0082 Acc: 96.6667%\n",
      "\ttrain 4-1071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1072: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1073: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1074: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1075: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1078: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1080: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1081: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1082: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1083: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1084: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1085: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1087: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1089: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1090: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1092: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1093: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1094: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1095: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1096: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1097: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1098: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1099: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1100: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 4-1101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1107: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1114: Loss: 0.0010 Acc: 100.0000%\n",
      "\ttrain 4-1115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1116: Loss: 0.0031 Acc: 96.6667%\n",
      "\ttrain 4-1117: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1120: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1129: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1132: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1136: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1139: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1144: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1145: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1148: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1152: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-1153: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1171: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1173: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1177: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1181: Loss: 0.0021 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-1182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1185: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1187: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-1188: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 4-1189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1193: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 4-1194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1195: Loss: 0.0018 Acc: 100.0000%\n",
      "\ttrain 4-1196: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-1197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1198: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1201: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1204: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 4-1205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1206: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 4-1207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1217: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 4-1218: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1219: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 4-1220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1223: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1225: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1227: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1243: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1247: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1250: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1252: Loss: 0.0025 Acc: 96.6667%\n",
      "\ttrain 4-1253: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1258: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-1259: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1260: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1263: Loss: 0.0034 Acc: 96.6667%\n",
      "\ttrain 4-1264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1271: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1273: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1274: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1277: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1291: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1294: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1295: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1296: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 4-1297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1302: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 4-1303: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1308: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1311: Loss: 0.0013 Acc: 96.6667%\n",
      "\ttrain 4-1312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1313: Loss: 0.0024 Acc: 100.0000%\n",
      "\ttrain 4-1314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1317: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1323: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1324: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1326: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1327: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1329: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1336: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1339: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1342: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1343: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1346: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1351: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 4-1352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1354: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1355: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1356: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1358: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1363: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 4-1364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1367: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-1368: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1372: Loss: 0.0030 Acc: 96.6667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-1373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1375: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1376: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1380: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-1381: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1382: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1383: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1384: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1385: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1386: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1387: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1388: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1389: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1390: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1391: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1392: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1393: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1394: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1395: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1396: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1397: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1398: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1399: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1400: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1401: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1402: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1403: Loss: 0.0038 Acc: 96.6667%\n",
      "\ttrain 4-1404: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1405: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1406: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1407: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1408: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1409: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1410: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1411: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1412: Loss: 0.0019 Acc: 100.0000%\n",
      "\ttrain 4-1413: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1414: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1415: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1416: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1417: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1418: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1419: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1420: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1421: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1422: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1423: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1424: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1425: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1426: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 4-1427: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1428: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1429: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1430: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1431: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1432: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1433: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1434: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1435: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1436: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1437: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1438: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1439: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1440: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1441: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1442: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1443: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1444: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1445: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1446: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1447: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1448: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1449: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1450: Loss: 0.0020 Acc: 96.6667%\n",
      "\ttrain 4-1451: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1452: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1453: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1454: Loss: 0.0052 Acc: 96.6667%\n",
      "\ttrain 4-1455: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1456: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1457: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1458: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1459: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1460: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1461: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1462: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1463: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1464: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1465: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1466: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1467: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1468: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1469: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1470: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1471: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1472: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1473: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1474: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1475: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1476: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1477: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1478: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1479: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1480: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1481: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1482: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1483: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1484: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1485: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1486: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1487: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1488: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1489: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1490: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1491: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1492: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1493: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1494: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1495: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1496: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1497: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1498: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1499: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1500: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1501: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1502: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1503: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1504: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1505: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1506: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1507: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1508: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1509: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1510: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1511: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1512: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1513: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1514: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1515: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1516: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1517: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1518: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1519: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1520: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1521: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1522: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 4-1523: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1524: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1525: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1526: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1527: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1528: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1529: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1530: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1531: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1532: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1533: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1534: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1535: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1536: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1537: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1538: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1539: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-1540: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1541: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1542: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1543: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1544: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1545: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1546: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1547: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1548: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1549: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 4-1550: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1551: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1552: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1553: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1554: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1555: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1556: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1557: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1558: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-1559: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1560: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1561: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1562: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1563: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-1564: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1565: Loss: 0.0016 Acc: 96.6667%\n",
      "\ttrain 4-1566: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1567: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1568: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1569: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1570: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1571: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1572: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1573: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1574: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1575: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1576: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1577: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1578: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1579: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1580: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1581: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1582: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1583: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1584: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1585: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1586: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1587: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1588: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1589: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1590: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1591: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1592: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1593: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1594: Loss: 0.0049 Acc: 96.6667%\n",
      "\ttrain 4-1595: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1596: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1597: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 4-1598: Loss: 0.0028 Acc: 96.6667%\n",
      "\ttrain 4-1599: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1600: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1601: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1602: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1603: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1604: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1605: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1606: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1607: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1608: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1609: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1610: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1611: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1612: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1613: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1614: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1615: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1616: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1617: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1618: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1619: Loss: 0.0042 Acc: 96.6667%\n",
      "\ttrain 4-1620: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1621: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1622: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1623: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1624: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1625: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1626: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1627: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1628: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1629: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1630: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1631: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1632: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1633: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1634: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1635: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1636: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1637: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1638: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1639: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1640: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1641: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1642: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1643: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1644: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1645: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1646: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1647: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1648: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1649: Loss: 0.0027 Acc: 100.0000%\n",
      "\ttrain 4-1650: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1651: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1652: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1653: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1654: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1655: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1656: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1657: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 4-1658: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1659: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1660: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1661: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1662: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1663: Loss: 0.0008 Acc: 96.6667%\n",
      "\ttrain 4-1664: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1665: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1666: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 4-1667: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1668: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1669: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1670: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1671: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1672: Loss: 0.0007 Acc: 100.0000%\n",
      "\ttrain 4-1673: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1674: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1675: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1676: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1677: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1678: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1679: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1680: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1681: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1682: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1683: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1684: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1685: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1686: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1687: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1688: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1689: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-1690: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1691: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1692: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1693: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1694: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1695: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1696: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1697: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1698: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1699: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1700: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1701: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1702: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1703: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1704: Loss: 0.0006 Acc: 100.0000%\n",
      "\ttrain 4-1705: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1706: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1707: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1708: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1709: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1710: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 4-1711: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1712: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1713: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1714: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1715: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1716: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1717: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1718: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1719: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1720: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1721: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1722: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1723: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1724: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1725: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1726: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1727: Loss: 0.0058 Acc: 96.6667%\n",
      "\ttrain 4-1728: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1729: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1730: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1731: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1732: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1733: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1734: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1735: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1736: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1737: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1738: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1739: Loss: 0.0059 Acc: 96.6667%\n",
      "\ttrain 4-1740: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1741: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1742: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1743: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1744: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1745: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1746: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1747: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1748: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1749: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1750: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1751: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1752: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1753: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1754: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-1755: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1756: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1757: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1758: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1759: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1760: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1761: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1762: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1763: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1764: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1765: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1766: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1767: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1768: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1769: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1770: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1771: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1772: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1773: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1774: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1775: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1776: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1777: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1778: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1779: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1780: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1781: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1782: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1783: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1784: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1785: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1786: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1787: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1788: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1789: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1790: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1791: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1792: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1793: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1794: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1795: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1796: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1797: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1798: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1799: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1800: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1801: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1802: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1803: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1804: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1805: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1806: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1807: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1808: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1809: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1810: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1811: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1812: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1813: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1814: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1815: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 4-1816: Loss: 0.0015 Acc: 96.6667%\n",
      "\ttrain 4-1817: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1818: Loss: 0.0043 Acc: 96.6667%\n",
      "\ttrain 4-1819: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1820: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1821: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1822: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1823: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1824: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1825: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1826: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1827: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1828: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1829: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1830: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1831: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1832: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1833: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1834: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1835: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1836: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1837: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1838: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1839: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1840: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1841: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1842: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1843: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1844: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1845: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1846: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1847: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1848: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1849: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1850: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1851: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1852: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1853: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1854: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1855: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1856: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1857: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1858: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1859: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1860: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-1861: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 4-1862: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-1863: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1864: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1865: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1866: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1867: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1868: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1869: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1870: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1871: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1872: Loss: 0.0009 Acc: 100.0000%\n",
      "\ttrain 4-1873: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1874: Loss: 0.0022 Acc: 96.6667%\n",
      "\ttrain 4-1875: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1876: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1877: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1878: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1879: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1880: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1881: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1882: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1883: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1884: Loss: 0.0009 Acc: 96.6667%\n",
      "\ttrain 4-1885: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1886: Loss: 0.0011 Acc: 100.0000%\n",
      "\ttrain 4-1887: Loss: 0.0002 Acc: 100.0000%\n",
      "\ttrain 4-1888: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1889: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1890: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1891: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1892: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1893: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1894: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 4-1895: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1896: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1897: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1898: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1899: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1900: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1901: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1902: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1903: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1904: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1905: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1906: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1907: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1908: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1909: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1910: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1911: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1912: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1913: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1914: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1915: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1916: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1917: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1918: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1919: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1920: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1921: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1922: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1923: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1924: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1925: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1926: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1927: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1928: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1929: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1930: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1931: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1932: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1933: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1934: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1935: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1936: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-1937: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1938: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1939: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-1940: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1941: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1942: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1943: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1944: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1945: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-1946: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1947: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1948: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1949: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1950: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1951: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1952: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1953: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1954: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1955: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-1956: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1957: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1958: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1959: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1960: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1961: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1962: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1963: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1964: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1965: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1966: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1967: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1968: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1969: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1970: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1971: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1972: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1973: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1974: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1975: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1976: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1977: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1978: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1979: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1980: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1981: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1982: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1983: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1984: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1985: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1986: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1987: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1988: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1989: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1990: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1991: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1992: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1993: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1994: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1995: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1996: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1997: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-1998: Loss: 0.0047 Acc: 96.6667%\n",
      "\ttrain 4-1999: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2000: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2001: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2002: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2003: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2004: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2005: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2006: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2007: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2008: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2009: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2010: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2011: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2012: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2013: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2014: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2015: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2016: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2017: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2018: Loss: 0.0003 Acc: 100.0000%\n",
      "\ttrain 4-2019: Loss: 0.0046 Acc: 96.6667%\n",
      "\ttrain 4-2020: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2021: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2022: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2023: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2024: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2025: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2026: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2027: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2028: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2029: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 4-2030: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2031: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2032: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2033: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2034: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2035: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2036: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2037: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2038: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2039: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2040: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2041: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2042: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2043: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2044: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2045: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2046: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2047: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2048: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2049: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2050: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2051: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2052: Loss: 0.0027 Acc: 96.6667%\n",
      "\ttrain 4-2053: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2054: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2055: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2056: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2057: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2058: Loss: 0.0032 Acc: 96.6667%\n",
      "\ttrain 4-2059: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2060: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2061: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2062: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2063: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2064: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2065: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2066: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2067: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2068: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2069: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2070: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2071: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2072: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2073: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2074: Loss: 0.0005 Acc: 100.0000%\n",
      "\ttrain 4-2075: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2076: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2077: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2078: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2079: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2080: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2081: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2082: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2083: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2084: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2085: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2086: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2087: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2088: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2089: Loss: 0.0004 Acc: 100.0000%\n",
      "\ttrain 4-2090: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2091: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2092: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2093: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2094: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2095: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2096: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2097: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2098: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2099: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2100: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2101: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2102: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2103: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2104: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2105: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2106: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2107: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2108: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2109: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2110: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2111: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2112: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2113: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2114: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2115: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2116: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2117: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 4-2118: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2119: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2120: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2121: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2122: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2123: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2124: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2125: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2126: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2127: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2128: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2129: Loss: 0.0022 Acc: 100.0000%\n",
      "\ttrain 4-2130: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2131: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2132: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 4-2133: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2134: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2135: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2136: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-2137: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2138: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2139: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2140: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2141: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2142: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2143: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2144: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 4-2145: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2146: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2147: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2148: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2149: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2150: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2151: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2152: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2153: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2154: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2155: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2156: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2157: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2158: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2159: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2160: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2161: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2162: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2163: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2164: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2165: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2166: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2167: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2168: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2169: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2170: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2171: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2172: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2173: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2174: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2175: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2176: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2177: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2178: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2179: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2180: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2181: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2182: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2183: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2184: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2185: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2186: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2187: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2188: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2189: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2190: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2191: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2192: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2193: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2194: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2195: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2196: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2197: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2198: Loss: 0.0048 Acc: 96.6667%\n",
      "\ttrain 4-2199: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2200: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2201: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-2202: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2203: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2204: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2205: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2206: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2207: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2208: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2209: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2210: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2211: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2212: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2213: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2214: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2215: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2216: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2217: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2218: Loss: 0.0033 Acc: 96.6667%\n",
      "\ttrain 4-2219: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2220: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2221: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2222: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2223: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2224: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2225: Loss: 0.0045 Acc: 96.6667%\n",
      "\ttrain 4-2226: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2227: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2228: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2229: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2230: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2231: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2232: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2233: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2234: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2235: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2236: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2237: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2238: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2239: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2240: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2241: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2242: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2243: Loss: 0.0021 Acc: 96.6667%\n",
      "\ttrain 4-2244: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2245: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2246: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2247: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2248: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2249: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2250: Loss: 0.0040 Acc: 96.6667%\n",
      "\ttrain 4-2251: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2252: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2253: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2254: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2255: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2256: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2257: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2258: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2259: Loss: 0.0029 Acc: 96.6667%\n",
      "\ttrain 4-2260: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2261: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2262: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2263: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2264: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2265: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2266: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2267: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2268: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2269: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2270: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2271: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2272: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2273: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2274: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2275: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2276: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2277: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2278: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2279: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2280: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2281: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2282: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2283: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2284: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2285: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2286: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2287: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2288: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2289: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2290: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2291: Loss: 0.0035 Acc: 96.6667%\n",
      "\ttrain 4-2292: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2293: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2294: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2295: Loss: 0.0041 Acc: 96.6667%\n",
      "\ttrain 4-2296: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2297: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2298: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2299: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2300: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2301: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2302: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2303: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2304: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2305: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2306: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2307: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2308: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2309: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2310: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2311: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2312: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2313: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2314: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2315: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2316: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2317: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2318: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2319: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2320: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2321: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2322: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2323: Loss: 0.0037 Acc: 96.6667%\n",
      "\ttrain 4-2324: Loss: 0.0044 Acc: 96.6667%\n",
      "\ttrain 4-2325: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2326: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2327: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain 4-2328: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2329: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2330: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2331: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2332: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2333: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2334: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2335: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2336: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2337: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2338: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2339: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2340: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2341: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2342: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2343: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2344: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2345: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2346: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2347: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2348: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2349: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2350: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2351: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2352: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2353: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2354: Loss: 0.0039 Acc: 96.6667%\n",
      "\ttrain 4-2355: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2356: Loss: 0.0001 Acc: 100.0000%\n",
      "\ttrain 4-2357: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2358: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2359: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2360: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2361: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2362: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2363: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2364: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2365: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2366: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2367: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2368: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2369: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2370: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2371: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2372: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2373: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2374: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2375: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2376: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2377: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2378: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2379: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2380: Loss: 0.0000 Acc: 100.0000%\n",
      "\ttrain 4-2381: Loss: 0.0000 Acc: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0\n",
    "lowest_loss = 99999\n",
    "loss_train = [] # 训练集loss\n",
    "acc_train = [] # 训练集正确率\n",
    "loss_val = [] # 验证集loss\n",
    "acc_val = [] # 验证集正确率\n",
    "best_matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "f = open('./result/ash_sand_1_16_vgg13_result.txt', 'a')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    exp_lr_scheduler.step()  # 调整学习率\n",
    "    print('learning_rate: {}'.format(learning_rate))\n",
    "    f.write('learning_rate: {}\\n'.format(learning_rate))\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch [{}/{}]:'.format(epoch + 1, epochs))\n",
    "        f.write('Epoch [{}/{}]:\\n'.format(epoch + 1, epochs))\n",
    "        \n",
    "    # 每一轮都跑一遍训练集和验证集\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "        else:\n",
    "            model.eval()  # 把module设置为评估模式\n",
    "\n",
    "        batch_num = 1\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        matrix = [[0 for i in range(num_classes)] for i in range(num_classes)]\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in dataloders[phase]:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # 先将网络中的所有梯度置0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 网络的前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 得到模型预测该样本属于哪个类别的信息\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 训练时，应用回传和优化\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # 记录当前batch_size的loss以及数据对应的分类准确数量\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'validation':\n",
    "                for k in range(0, batch_size):\n",
    "                    matrix[labels.data.cpu().numpy()[k]][preds.cpu().numpy()[k]] += 1\n",
    "\n",
    "            print('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch + 1, batch_num, loss.item()/batch_size, 1.0*torch.sum(preds == labels.data).item()/batch_size*100))\n",
    "            f.write('\\t{} {}-{}: Loss: {:.4f} Acc: {:.4f}%\\n'.format(phase, epoch + 1, batch_num, loss.item()/batch_size, 1.0*torch.sum(preds == labels.data).item()/batch_size*100))\n",
    "            batch_num = batch_num + 1\n",
    "\n",
    "        # 计算并打印这一轮训练的loss和分类准确率\n",
    "        if phase == 'train':\n",
    "            epoch_loss_train = running_loss / dataset_sizes['train']\n",
    "            epoch_acc_train = running_corrects.item() / dataset_sizes['train']\n",
    "            loss_train.append(epoch_loss_train)\n",
    "            acc_train.append(epoch_acc_train)            \n",
    "        else:\n",
    "            epoch_loss_val = running_loss / dataset_sizes['validation']\n",
    "            epoch_acc_val = running_corrects.item() / dataset_sizes['validation']\n",
    "            loss_val.append(epoch_loss_val)\n",
    "            acc_val.append(epoch_acc_val)\n",
    "\n",
    "        if epoch % display_step == 0 and phase == 'validation':\n",
    "            print('\\ttrain Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            print('\\tvalidation Loss: {:.4f} Acc: {:.4f}%'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "            f.write('\\ttrain Loss: {:.4f} Acc: {:.4f}%\\n'.format(epoch_loss_train, epoch_acc_train*100))\n",
    "            f.write('\\tvalidation Loss: {:.4f} Acc: {:.4f}%\\n'.format(epoch_loss_val, epoch_acc_val*100))\n",
    "\n",
    "        # 保存验证集loss最低的模型参数\n",
    "        if phase == 'validation' and epoch_loss_val < lowest_loss:\n",
    "            lowest_loss = epoch_loss_val\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = model.state_dict()\n",
    "            print(\"Network parameter update.\")\n",
    "            f.write(\"Network parameter update.\\n\")\n",
    "            # 保存最优参数\n",
    "            torch.save(best_model_wts, './parameter/ash_sand_1_16_vgg13_params.pth')\n",
    "            best_matrix = copy.deepcopy(matrix)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time passed {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    print('-' * 20)\n",
    "    f.write('Time passed {:.0f}h {:.0f}m {:.0f}s\\n'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "    f.write('-' * 20 + \"\\n\")\n",
    "\n",
    "# 计算训练所耗时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))\n",
    "f.write('Training complete in {:.0f}h {:.0f}m {:.0f}s\\n'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "f.write('Best validation Acc: {:4f}\\n'.format(best_acc))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: [0.021833318329405813, 0.0014407199390216933, 0.00032527742480284585, 0.0002587402284748675, 0.0001882534123776933, 0.00016868358577698653, 0.00015489695771059913, 0.00014540919900250638, 0.00013823575775018045, 0.00013249928033554363]\n",
      "loss_val: [0.0099713846718582, 0.010703109660750488, 0.018153290844454047, 0.017048350075682325, 0.014173218087267484, 0.015874593382346418, 0.01582116131678068, 0.015175456417852234, 0.015998392209870916, 0.016135089348500574]\n",
      "acc_train: [0.8036592592592593, 0.9872222222222222, 0.997237037037037, 0.997874074074074, 0.9984518518518518, 0.9986666666666667, 0.9987481481481482, 0.9988222222222222, 0.9988074074074074, 0.9988888888888889]\n",
      "acc_val: [0.9153777777777777, 0.9293333333333333, 0.9580222222222222, 0.9555555555555556, 0.9590444444444445, 0.9605333333333334, 0.9596888888888889, 0.9613555555555555, 0.9618444444444444, 0.9612888888888889]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEYCAYAAAB2qXBEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYFdWd//H3hwZBQREBN1BBJbK5oK3ROLhOHOK+xIXRRIzRxFEnY5afmsRoHJNoYhJjhuhoRlFjJEZHg9EEN0jMRCONioIrKmqDS4MiICAC398fVZcuLrf3e/ve7v68nqeernuq6txTjda3z1LnKCIwMzNrrW7lLoCZmXVsDiRmZtYmDiRmZtYmDiRmZtYmDiRmZtYmDiRmZtYmDiRWVJImSIrMtlTSLEnnSereDt9/maTISwtJl7Uwn/+QdHxRC5fkO0/SpGLna1ZOJf8f27qsE4FaYLN0/5fAlsD3ylCW/dKytMR/AH8D/rf4xTHrXBxIrFSeiYi56f6DknYGvkYDgUSSgB4RsarYBYmIJ4qdpyUk9YyIj8tdDisvN21Ze5kBbCZpS1jXxPMbSV+S9CKwCjgiPbaJpKskvS5pVfrzO5LW++9V0hhJj0laKWm+pEsA5X9xoaYtSbtLukfSIkkrJL0k6eJc2YAdgFMzTXST8q6dIumD9Nr/kzS2wPd+Lb3PlZJqCp1TiKRekn4uabakZZLekXSfpOEFzh0q6bb0nI8lvSbpF3nnHCjpIUkfSvoobWo8s4nfz5A0fUImbZKkWkn7Sfq7pBXAj9Njp0h6VFJdWuanJZ1eoLzdJV0o6fn091In6c+ShkvaOv33/lqB6y6TtFxSv+b8Dq19uUZi7WUosAZYlkk7GNgD+D7wHjAv7UeZCowE/hN4DtgXuATYAvgGgKQBwKPAO8DpwMfAt4DtmyqIpH2A6cBc4AKSZq9hwG7pKccBDwCzgMvStLr02j2Bx4CngbOA5cBXgYclfSYiZqbnnQlcA0wCfgfsDNwBbNpU+YCe6XlXAG+n9/1vwOOSRkTEO+l3DAWeTMvwPeCV9P4Py9zrMcDdwP8BXwEWAqNIAmVr9AUmA1cD3wZWpOk7AncBVwJrgQOAX0vaOCKuz1w/GTiW5HfzMNArPXebiHhR0r3A2cC6YCipCjgTuDMiPmhlua2UIsKbt6JtwAQggF1I/lDpR/IAWwPcmzlvHskDcOu867+QXn9AXvp3SGotW6aff5B+3i5zTm+SB2XkXRvAZZnPfwXeAjZp5D7mAb8pkP4I8AKwUSatKk27N/3cLc3/z3nXnpyWZVILf6dVwCbAUuCCTPqtJIF52wauU3ofNUC3RvJf7/eTpg1J0ydk0ialacc0Ud5u6b/9jcCsTPoh6fX/3si1B6XnjM2kHZ2m7Vvu/769Fd7ctGWl8iLwCfA+8CvgduBLeec8Eelf1xnjgDeAv6fNIN3TWsqDQA+S2gkkHehPRMRbuQsj4iPgvsYKJWkTYH/g9ohY3pIbkrQxcCDwe2Btpmwi+ev6gPTUwel2Z14WdwOrm/ldJ0n6h6TF6TUfAX1IAnTOYcAfI2JBA9nsQlLz+HVErG3O9zbDJ8AfC5R3mKQ7JM1Pz/kE+HKB8gZJgCkoIqYDz5P88ZHzFeDZcF9XxXLTlpXKcSRNRkuBNyJiZYFz3i6QtiXJw++TBvLtn/7cBphd4Pi7TZSrH8lfzC0dxQVJE1MVSTPbJYVOSPtxtilUlohYLWlRU18i6SiS5rBbSJr9FpI0Fz1A0hSU05/G7yP3u2rNvTakLiLWZBMk9QEeIqlhXgS8SlJbPIf1/3joD7wfESto3HXA1WlfSR+SPy7OK07xrRQcSKxUZkf9qK2GFFrDYBHwOnBSA9fMS3++DWxV4HihtKwPSB7Kg5o4r5DF6bUTSZqVNhARayXlAuR6ZUlrL/03vGoDpwBzI2JC5toeJIEsayGN38fC9GdT9/oxsFFeWkPlLPRvth9J8B8bEX/LJWrD94YWAluk/SaNBZNbgR+RNJP2IwlQtzdyvpWZm7as0vwZ2A5YFhE1Bbbcw/FxYF9J2+UulNQbOKqxzNPmrL8Bp6VNVQ35GFjveNp09hiwO/BUofKlp9aS9JHkB8MTaN4fb5uwYRPYF0hqQ1kPAkdK2obCXiYJvF+WtMFotow3gNF5aUc0o5w5m6Q/19Ui09FVx+Sd9yBJM+CXG8ssIpaQBI6vkNRo7kjTrEK5RmKV5nbgDOARST8lGTm1EbATSafrsWkw+DnJSKYH06GruVFbTTWbAHwT+AvJKKifkjz4dwT2iIjz03OeB8ZKOpJkZNjCiJgHfJ2ks36qpP8hqRkNAPYEqiLiorRW8n2SUUs3k4xU2pmk2ac5D8Q/A8dK+jlJf0Q1cD5JjSjrUuBwkv6kH5KMQhsEjIuI0yIiJP0HyUuVj0q6nmT02QiSQQuXpvlMBr4r6TvAE8BYYHwzypnz9/S+Jkq6lGTQw3dJaiB9cydFxDRJdwM/S/8AeJSk3+sA4P60fyTnV9T3k2RHfVklKndvv7fOtVE/amvnJs6bR4FRUemxXiTDbl8kCRDvk7yHchnQPXNebijuSmA+Sb/F92li1FaaNoakY34xSfB5Ebgwc3x4mvdy8kZakTyIJ5MMWf6YJBBNAQ7P+46vkfy1v5Jk5NQ/pfc9qYnfTTeSob8L0u//S1reDa4lCbB3kDy0V5L0T/ws75xDgGkkI7yWkQTnM/J+378gCYpLSfpn9qHwqK3aBsp8CMmQ6BVpGf49/ffK/7foTjIC72WSfpQ6kr6fXQrk+RIwo9z/TXtrelP6D2ZmVjEk7UIypPqsiPifcpfHGudAYmYVQ9JgkmbA76c/d46mR3lZmbmz3cwqyZdJ+k62Av7VQaRjcI3EzMzaxDUSMzNrky4x/HfAgAExZMiQchfDzKxDmTlz5sKIGNjUeV0ikAwZMoSampqmTzQzs3UkvdGc89y0ZWZmbeJAYmZmbeJAYmZmbeJAYmZmbVLSQCLpJknvSSq0bgRKXCtprqRn02VMc8dOl/RKup2eSd9L0nPpNdc2MaupmZmVWKlrJJNIFqVpyOdI1soeRrJO83UAkrYgmdn00ySTx12aTktNes5Zmesay9/MzEqspMN/I+KvkoY0csoxwK2RvF7/hKTN07UVDgIeioj3ASQ9BIyTNB3YLNIlNyXdChwL/KlkN2FWSSJg7dr6n7n93AwV+fvNTSvF8eaUodjXt0ZLGjVa2gBSrt99dn+jjWDs2JaVu4XK/R7JIJIFgHJq07TG0msLpG9A0tkktRy233774pXYii8CPvmk4W316obTVq9ef7+xtJae31Ta6tWFH+rN3W/NdWYttfXW8HahVa2Lp9yBpGQi4gbgBoDq6mr/H9gWy5fDo4/C9OmwZEnLHvjNOXfNmiaLYGat1A5/gJQ7kMwnWVY1Z3CaNp+keSubPj1NH1zgfCu2BQvgj3+E++6DRx6BFZ6EtWJI0K1bsknrb7nj2f3mppXieHPKUOzrW6IlD9mWnlvu331uf4stml/uVip3IJkCnCdpMknH+ocR8bakqcAPMx3shwEXR8T7kpZI2hf4B/BF4JdlKXlnEwFPPZUEjvvuS/bbU/fu0KNH4a2hY9271x/L/mxuWlvzqKqqf6DnHuqN7Td1vLl5mFWYkgYSSXeQ1CwGSKolGYnVAyAiridZYvNwkrWml5Os1U0aMP6TZHlVgMtzHe8k63RPAjYm6WR3R3trLV+e1Dbuuw/uvz+phTRk5Eg48kjYaafmPeSbezz3QPYD0qzD6hLrkVRXV4cnbUzNn58Ejfvug4cfhpUrC5/XvTsceCAcdVR9ADGzLkXSzIiobuq8cjdtWamtXZs0U+X6OxprsurfHw4/PAkehx0Gffu2XznNrMNyIOmMsk1Wf/xj40P/Ro6sr3Xst1/SzGRm1gIOJJ3F/Pnrj7JqqMmqR4+kyerII5MAsuOO7VtOM+t0HEg6qlyTVW6U1dNPN3yum6zMrIQcSDqS5cuTDvI//rH5TVZHHQX77usmKzMrGQeSSrdmDfzmN/D73zevySrX3+EmKzNrJw4kle4nP4GLLy58LNtk9S//Aptt1r5lMzPDgaTyTZ26/mc3WZlZhXEgqWQR8Oyz9Z+ffBL23rt85TEzK8BL7Vay+fPh/XRmmL59obrJF0zNzNqdA0klmzWrfn+33TwflZlVJAeSSpZt1tp99/KVw8ysEQ4klSy/RmJmVoEcSCqZayRm1gE4kFSqFSvgpZeSfQlGjSpveczMGuBAUqnmzEnm0wIYNgx69y5veczMGlDSQCJpnKSXJM2VdFGB4ztIekTSs5KmSxqcph8s6ZnMtlLSsemxSZJezxzbo5T3UDbZZi33j5hZBSvZC4mSqoCJwGeBWmCGpCkR8XzmtKuBWyPiFkmHAD8CvhAR04A90ny2IFmK98HMdd+KiLtKVfaKkO1od/+ImVWwUtZI9gHmRsRrEbEKmAwck3fOSODRdH9ageMAnwf+FBHLS1bSSuSOdjPrIEoZSAYBb2U+16ZpWbOA49P944BNJfXPO+cU4I68tB+kzWE/l9Sz0JdLOltSjaSaurq61t1BuUR46K+ZdRjl7mz/JnCgpKeBA4H5wJrcQUnbALsC2ZkLLwaGA3sDWwAXFso4Im6IiOqIqB44cGCJil8i8+fDBx8k+337wvbbl7c8ZmaNKOWkjfOB7TKfB6dp60TEAtIaiaQ+wAkRsThzyknAPRHxSeaa3GpOH0u6mSQYdS6eGsXMOpBS1khmAMMkDZW0EUkT1ZTsCZIGSMqV4WLgprw8xpPXrJXWUpAk4FhgdgnKXl7uaDezDqRkgSQiVgPnkTRLvQDcGRFzJF0u6ej0tIOAlyS9DGwF/CB3vaQhJDWav+Rlfbuk54DngAHAFaW6h7Lx0F8z60BKuh5JRDwAPJCX9r3M/l1AwWG8ETGPDTvniYhDilvKCuQaiZl1IOXubLd8K1bAyy8n+xKMHl3e8piZNcGBpNLkT42yySblLY+ZWRMcSCqNX0Q0sw7GgaTS+EVEM+tgHEgqjTvazayDcSCpJBFu2jKzDqekw3+thWpr66dG2Xxz2G67xs8368Ii4KOPYOlSWLYs+bl0KaxaBWvWwOrV9Vs5PldVQY8e0L17/dbY51Kd26sXDB9e2n8LB5JKkv8ioqdG6dIiktHgy5YlD8zcz+z+smXJg2ujjaBnz8Z/Nnasqqp97if34M9t2QDQUFpD5yxbluRpjRswAEo9b60DSSVxR3uHtHr1hg/3Qg/8po7lpy1f3n4Pyqqq5gWjxoLU6tWNB4CPPvKDvxy6t8NT3oGkkrijvWKsXg3vvJNMxLxgQfIzt+U+v/de8rBctarcpW27NWuS2s+KFeUuSctsvDFsummy9emTbL16JQ/Pqqr1m3sKpRX7cy6tqmrD5q5PPmn4c2uPNefc/vkLc5SAA0klqeA5tu6+G376U1iyJPkPsznbFlu0z19DLREBH35YODBkP7/7bv17oeXUq1fycOzde8Ofuf3u3ZMHxscfJ0GtNT/bq6awySb1D/1cAGjt59y9W/n5n6FSZKdG6datYqZGiYAf/AAuuaR112+2WcsCT//+yYOiNd1Dq1bVB4VscMjfX17ktTa7dWv8Qd9UWkPHNtmk/fou1qzZMMC0NBh17954EOjTp33ux9qfA0mlqMCpUVatgrPPhltuaX0eS5Yk2+uvN/+aHj3qg0qhrU+fpPMwvxZR7A7FLbeEQYOSbdtt6/dzn7feOgmUPXt27HERUn2zTO/e5S6NdUQOJJWiwjraP/gAjj8epk+vTzv0ULjyyqRpaNGiZHv//fr9/O2DD1rXZPLJJ0nT0rvvFu121tO7d8PBIbe/9dZJB7KZNc2BpFJU0IuIr70Ghx8OL71Un3bmmXDddUltobnWrIHFixsPNoUCUmubnrp1SwJAQ8Eht7/ZZh27BmFWaRxIKkWF1Ej+/nc45hhYuLA+7Uc/ggsvbPnDt6qqvjlq2LDmX7dyZeOBZskSGDhww0Cx1VZugzcrBweSShBREUN/f/c7OP30pOMUkrb/W2+Fk05q33L06lUfHMys8pV0ri1J4yS9JGmupIsKHN9B0iOSnpU0XdLgzLE1kp5JtymZ9KGS/pHm+bt0PfiOrbY2aQOCskyNEgE//CGcckp9EBkwAKZNa/8gYmYdT8kCiaQqYCLwOWAkMF7SyLzTrgZujYjdgMuBH2WOrYiIPdLt6Ez6VcDPI2Jn4APgzFLdQ7vJb9Zqxwb8VauS/o/vfKc+bfhw+Mc/YL/92q0YZtaBlbJGsg8wNyJei4hVwGTgmLxzRgKPpvvTChxfjyQBh1C/zvstwLFFK3G5lKmjffFi+Nzn4Oab69MOPjjpJ9lxx3Yrhpl1cKUMJIOAtzKfa9O0rFnA8en+ccCmknIv9PeSVCPpCUm5YNEfWBwRqxvJEwBJZ6fX19SVesaytipDR/vrr8NnPgOPPlqfNmEC/PnP0K9fuxTBzDqJcq9H8k3gQElPAwcC84E16bEdIqIa+FfgGkk7tSTjiLghIqojonrgwIFFLXTRtXNH+xNPwKc/DS+8UJ92xRVw001+d8LMWq6Uo7bmA9le48Fp2joRsYC0RiKpD3BCRCxOj81Pf74maTowBrgb2FxS97RWskGeHc7y5fDKK8l+t24walRJv+6uu+ALX0iG2EISOCZNgvHjS/q1ZtaJlbJGMgMYlo6y2gg4BZiSPUHSAEm5MlwM3JSm95PUM3cOsD/wfEQESV/K59NrTgf+UMJ7KL12mholAn78YzjxxPog0r8/PPKIg4iZtU3JAklaYzgPmAq8ANwZEXMkXS4pNwrrIOAlSS8DWwE/SNNHADWSZpEEjisj4vn02IXA1yXNJekz+Z9S3UO7aIeO9k8+ga98JXmpMGfYsKSJ65/+qSRfaWZdSElfSIyIB4AH8tK+l9m/i/oRWNlz/g7s2kCer5GMCOscStzR/uGHSS3koYfq0w44AP73f9tnnQIz6/zK3dluJayRvPEG7L//+kHktNPgwQcdRMyseBxIyil/apQi1khmzEhGZs2ZU5922WXJlCc9exbta8zMPNdWWb31VkmmRrnnHjj11PplU3v0SIb2nnZaUbI3M1uPayTllL+0bhunRolIlsM94YT6ILLFFvDwww4iZlY6rpGUUxFfRFy9Gs4/H66/vj5t553h/vvhU59qU9ZmZo1yICmnInW0L1kCJ5+cTG+Ss//+cO+9ySy+Zmal5KatcipCR/tbbyXvgmSDyPjxSXOWg4iZtQcHknIpwtQoM2cmI7Oee64+7ZJL4Pbbk8WhzMzag5u2yqWNU6NMmZLUPHLrm/foATfemKxwaGbWnlwjKZdWdrRHwC9+AcceWx9ENt8cpk51EDGz8nCNpFxa0dG+ejVccAH813/Vpw0dCg88kKxqaGZWDg4k5dLCjvalS5M11R/IzFy2337whz9ApS+3Ymadm5u2yiGiRTWS2loYO3b9IHLSSckU8A4iZlZuDiTlkD81yuDBBU9bvhx+/etkZFa2AnPxxXDHHbDxxu1QVjOzJrhpqxzyO9rzpkZ55RW47jq4+eb6eAPQvTv893/Dl77UTuU0M2sGB5JyyJ9jC1izJmm6mjgxGYGVr18/+P3v4dBD26mMZmbNVNKmLUnjJL0kaa6kiwoc30HSI5KelTRd0uA0fQ9Jj0uakx47OXPNJEmvS3om3fYo5T2URKZGUrfjp7nySthpJzj66A2DyE47JRMxzp3rIGJmlalkNRJJVcBE4LNALTBD0pTMkrkAVwO3RsQtkg4BfgR8AVgOfDEiXpG0LTBT0tSIyDX0fCtdXbFjevZZnmRv/ovzuPPC8Xy8av3DEhxxBJx7Lhx2WPLiu5lZpSpl09Y+wNx0aVwkTQaOAbKBZCTw9XR/GnAvQES8nDshIhZIeg8YCGR6DDqeFStg8i0f86uXbqOGvZPETBDp3x/OPBO++tXk/RAzs46glH/rDgLeynyuTdOyZgHHp/vHAZtKWm8RWEn7ABsBr2aSf5A2ef1cUsH1/iSdLalGUk1dXV1b7qPNXnsNvvWtZHDWl87pWR9EUnvvDZMmJYO5rrrKQcTMOpZyN5p8EzhQ0tPAgcB8YE3uoKRtgNuAMyIinZiKi4HhwN7AFsCFhTKOiBsiojoiqgeW4WWLtWuTzvMjjkjWBbn6anj//frjPVnJ6UOm8+ST8OSTyfQmHs5rZh1RKZu25gPZtWMHp2nrRMQC0hqJpD7ACbl+EEmbAfcD34mIJzLXvJ3ufizpZpJgVDHefz9Z1va665KaSL4hmy7inKVX8SVuYsBZX4e9D2r3MpqZFVMpA8kMYJikoSQB5BTgX7MnSBoAvJ/WNi4GbkrTNwLuIemIvyvvmm0i4m1JAo4FZpfwHppt5sxk6O4dd8DKlRseHzcu6Tz/3I8/T9Vj05PENq6KaGZWCUoWSCJitaTzgKlAFXBTRMyRdDlQExFTgIOAH0kK4K/AuenlJwEHAP0lTUjTJkTEM8DtkgYCAp4Bvlqqe2jKypXJux0TJ8I//rHh8c03T14ePOecpHmLCDjt6foTWrmYlZlZJVFElLsMJVddXR01NTVFy2/evOQN81//GhYu3PD4mDFJ7WP8+LxlRt58E3bYIdnv1w8WLdrgrXYzs0ohaWZEVDd1nt9sb6a1a+Ghh5Lax/33169JlbPRRslEiueem8yNVTA+5M/46yBiZp2AA0kTPvggGZp73XX1K+Nmbb998t7HmWfClls2kVkr1iAxM6t0DiQNeOaZpPZx++3Ji4T5PvvZpPZxxBHJZIrN0sI1SMzMOgIHkgZ8+9vwpz+tn9a3L0yYkHSe77JLKzJt5fK6ZmaVrNwvJFasc8+t399tt6Rzff58uOaaVgaR5cvr28a6dYNRo4pSTjOzcnONpAHjxsF558HJJ8P++xehX3z27GT4L8CnPuXX2M2s03AgaUBVFfzyl0XM0B3tZtZJuWmrvbij3cw6KQeS9uKOdjPrpBxI2kNEweV1zcw6AweS9vDmm/Dhh8l+v37JwiRmZp2EA0l7yO9o99QoZtaJNBlIJA2V1CvzeWNJQ0pZqE7HHe1m1ok1p0byeyA7ReGaNM2ay0N/zawTa04g6R4Rq3If0v2NSlekTsg1EjPrxJoTSOokHZ37IOkYoMAqHFbQRx95ahQz69SaE0i+Cnxb0puS3gQuBL7SnMwljZP0kqS5ki4qcHwHSY9IelbSdEmDM8dOl/RKup2eSd9L0nNpntemS+5Wrjlz6qdG2WUXT41iZp1Ok4EkIl6NiH2BkcDIiPhMRMxt6jpJVcBE4HPpteMljcw77WqSddl3Ay4HfpReuwVwKfBpYB/gUkn90muuA84ChqXbuCbvspzcrGVmnVxzRm39UNLmEbEsIpZJ6ifpimbkvQ8wNyJeS/tVJgPH5J0zEng03Z+WOf4vwEMR8X5EfAA8BIyTtA2wWUQ8EckawbcCxzajLOXjjnYz6+Sa07T1uYhYnPuQPtgPb8Z1g4C3Mp9r07SsWcDx6f5xwKaS+jdy7aB0v7E8AZB0tqQaSTV1dXXNKG6JuEZiZp1ccwJJlaSeuQ+SNgZ6NnJ+S3wTOFDS08CBwHyS4cVtFhE3RER1RFQPHDiwGFm2phCukZhZp9ecaeRvBx6RdDMgYAJwSzOumw9sl/k8OE1bJyIWkNZIJPUBToiIxZLmAwflXTs9vX5wXvp6eVaU/KlRBhWsPJmZdWjN6Wy/CrgCGAHsAkwFdmhG3jOAYemb8RsBpwBTsidIGiApV4aLgZvS/anAYWl/TD/gMGBqRLwNLJG0bzpa64vAH5pRlvLIn/G3wgeYmZm1RnPn2noXCOBE4BDghaYuiIjVwHkkQeEF4M6ImCPp8sx7KQcBL0l6GdgK+EF67fvAf5IEoxnA5WkawL8BvwbmAq8CeSurVxA3a5lZF9Bg05akTwHj020h8DtAEXFwczOPiAeAB/LSvpfZvwu4q4Frb6K+hpJNrwFGN7cMZeWOdjPrAhrrI3kReAw4MvfeiKQL2qVUnYVrJGbWBTTWtHU88DYwTdKNkg4l6Wy35sifGmVk/ruYZmadQ4OBJCLujYhTgOEkLwv+B7ClpOskHdZeBeywZs/21Chm1iU0Z9TWRxHx24g4imS47dMk821ZY7y0rpl1ES1aITEiPkhf9Du0VAXqNPKH/pqZdVJeardU3NFuZl2EA0kp5E+N4qYtM+vEHEhKITs1yhZbeGoUM+vUHEhKIf9FRE+NYmadmANJKbij3cy6EAeSUnBHu5l1IQ4kpeA5tsysC3EgKbaPPoK56ZL23brBqFHlLY+ZWYk5kBRb/tQovXqVtzxmZiXmQFJs7h8xsy7GgaTY3D9iZl2MA0mxeeivmXUxJQ0kksZJeknSXEkXFTi+vaRpkp6W9Kykw9P0UyU9k9nWStojPTY9zTN3bMtS3kOL5E+N4kBiZl1AYysktomkKmAi8FmgFpghaUpEPJ857bska7lfJ2kkybK8QyLiduD2NJ9dgXsj4pnMdaemS+5WljfegCVLkv0ttoBtty1veczM2kEpayT7AHMj4rWIWAVMBo7JOyeAzdL9vsCCAvmMT6+tfPm1EU+NYmZdQCkDySDgrczn2jQt6zLgNEm1JLWR8wvkczJwR17azWmz1iVS4ae1pLMl1Uiqqaura9UNtJg72s2sCyp3Z/t4YFJEDAYOB26TtK5Mkj4NLI+I2ZlrTo2IXYGx6faFQhmnC3BVR0T1wIEDS3cHWe5oN7MuqJSBZD6wXebz4DQt60zgToCIeBzoBQzIHD+FvNpIRMxPfy4FfkvShFYZ3NFuZl1QKQPJDGCYpKGSNiIJClPyznkTOBRA0giSQFKXfu4GnESmf0RSd0kD0v0ewJHAbCpBdmqUqioYObK85TEzayclG7UVEaslnQdMBaqAmyJijqTLgZqImAJ8A7hR0gUkHe8TInLzi3AA8FZEvJbJticwNQ0iVcDDwI2luocW8dQoZtZFlSyQAETEAySd6Nm072X2nwf2b+Da6cC+eWkfAXsVvaDF4I52M+uiyt3Z3nm4f8TMuigHkmJxjcTMuigHkmLw1Chm1oU5kBRDdmrzdVVsAAAPcklEQVSU/v09NYqZdSkOJMWQ36zlqVHMrAtxICkGN2uZWRfmQFIM7mg3sy7MgaQYXCMxsy7MgaStPDWKmXVxDiRt9dxznhrFzLo0B5K2crOWmXVxDiRt5Y52M+viHEjayjUSM+viHEjaIn9qFNdIzKwLciBpi3nzPDWKmXV5DiRtkd+s5alRzKwLKmkgkTRO0kuS5kq6qMDx7SVNk/S0pGclHZ6mD5G0QtIz6XZ95pq9JD2X5nmtVMantzvazcxKF0gkVQETgc8BI4HxkvLf1vsucGdEjCFZ0/1XmWOvRsQe6fbVTPp1wFnAsHQbV6p7aJI72s3MSloj2QeYGxGvRcQqYDJwTN45AWyW7vcFFjSWoaRtgM0i4ol0bfdbgWOLW+wWcI3EzKykgWQQ8Fbmc22alnUZcJqkWpK13c/PHBuaNnn9RdLYTJ61TeQJgKSzJdVIqqmrq2vDbTRg2TJ49dVk31OjmFkXVu7O9vHApIgYDBwO3CapG/A2sH3a5PV14LeSNmsknw1ExA0RUR0R1QMHDix6wZk921OjmJkB3UuY93xgu8znwWla1pmkfRwR8bikXsCAiHgP+DhNnynpVeBT6fWDm8izfWSbtdw/YmZdWClrJDOAYZKGStqIpDN9St45bwKHAkgaAfQC6iQNTDvrkbQjSaf6axHxNrBE0r7paK0vAn8o4T00zB3tZmZACWskEbFa0nnAVKAKuCki5ki6HKiJiCnAN4AbJV1A0vE+ISJC0gHA5ZI+AdYCX42I99Os/w2YBGwM/Cnd2p872s3MAFDk2vk7serq6qipqSlehhHQty8sXZp8nj/fb7WbWacjaWZEVDd1Xrk72zumefPqg0j//rDNNmUtjplZOTmQtEZ+R7unRjGzLsyBpDXc0W5mto4DSWu4o93MbB0HktZwjcTMbB0HkpbKnxplxIjylsfMrMwcSFoqOzXK8OGeGsXMujwHkpZy/4iZ2XocSFrKc2yZma3HgaSl3NFuZrYeB5KWWLt2/UDipi0zMweSFnnjjfqpUQYM8NQoZmY4kLRMfke7p0YxMyvpwladj/tHzMruk08+oba2lpUrV5a7KJ1Gr169GDx4MD169GjV9Q4kLeGhv2ZlV1tby6abbsqQIUOQWwXaLCJYtGgRtbW1DB06tFV5uGmrJTz016zsVq5cSf/+/R1EikQS/fv3b1MNr6SBRNI4SS9JmivpogLHt5c0TdLTkp6VdHia/llJMyU9l/48JHPN9DTPZ9Jty1Lewzr5U6OMHNkuX2tmG3IQKa62/j5L1rSVrrk+EfgsUAvMkDQlIp7PnPZd4M6IuE7SSOABYAiwEDgqIhZIGk2yXO+gzHWnRkQRlzxshueeq98fPhx69mzXrzczq1SlrJHsA8yNiNciYhUwGTgm75wANkv3+wILACLi6YhYkKbPATaWVN4ntzvazQxYvHgxv/rVr1p83eGHH87ixYtLUKLyK2UgGQS8lflcy/q1CoDLgNMk1ZLURs4vkM8JwFMR8XEm7ea0WesSNVAnk3S2pBpJNXV1da2+iXXc0W5mNBxIVq9e3eh1DzzwAJtvvnmpilVW5e5sHw9MiojBwOHAbZLWlUnSKOAq4CuZa06NiF2Bsen2hUIZR8QNEVEdEdUDBw5se0nd0W5WeaTSbQ246KKLePXVV9ljjz3Ye++9GTt2LEcffTQj037TY489lr322otRo0Zxww03rLtuyJAhLFy4kHnz5jFixAjOOussRo0axWGHHcaKFStK/qsqpVIGkvnAdpnPg9O0rDOBOwEi4nGgFzAAQNJg4B7gixHxau6CiJif/lwK/JakCa201q5dv4/EgcSsy7ryyivZaaedeOaZZ/jJT37CU089xS9+8QtefvllAG666SZmzpxJTU0N1157LYsWLdogj1deeYVzzz2XOXPmsPnmm3P33Xe3920UVSkDyQxgmKShkjYCTgGm5J3zJnAogKQRJIGkTtLmwP3ARRHxf7mTJXWXlAs0PYAjgdklvIfEvHnrT42y9dYl/0oz6xj22Wef9d6/uPbaa9l9993Zd999eeutt3jllVc2uGbo0KHsscceAOy1117MmzevvYpbEiUbtRURqyWdRzLiqgq4KSLmSLocqImIKcA3gBslXUDS8T4hIiK9bmfge5K+l2Z5GPARMDUNIlXAw8CNpbqHdfI72j300Kwy5BaZK6PevXuv258+fToPP/wwjz/+OJtssgkHHXRQwfczemZGfVZVVXX4pq2SvtkeEQ+QdKJn076X2X8e2L/AdVcAVzSQ7V7FLGOzuKPdzFKbbropS3MtFHk+/PBD+vXrxyabbMKLL77IE0880c6lKw9PkdIcHvprZqn+/fuz//77M3r0aDbeeGO22mqrdcfGjRvH9ddfz4gRI9hll13Yd999y1jS9qOogKphqVVXV0dNTRveX9x55/q32p96CsaMKU7BzKzFXnjhBUaMGFHuYnQ6hX6vkmZGRHVT15Z7+G/lW7q0Poh07+6pUczM8jiQNGV2ZlCYp0YxM9uAA0lT3NFuZtYoB5KmuKPdzKxRDiRNcY3EzKxRDiSN8dQoZmZNciBpTHZqlIEDPTWKmbVKnz59AFiwYAGf//znC55z0EEH0dRrCtdccw3Lly9f97lSpqZ3IGlMfrOWp0YxszbYdtttueuuu1p9fX4gqZSp6R1IGuOOdrOKVoZZ5IFkKvmJEyeu+3zZZZdxxRVXcOihh7Lnnnuy66678oc//GGD6+bNm8fo0aMBWLFiBaeccgojRozguOOOW2++rXPOOYfq6mpGjRrFpZdeCiSTQS5YsICDDz6Ygw8+GKifmh7gZz/7GaNHj2b06NFcc801676vXaasj4hOv+21117RKscdF5FMCxcxaVLr8jCzonr++efX7ef+9yzF1pinnnoqDjjggHWfR4wYEW+++WZ8+OGHERFRV1cXO+20U6xduzYiInr37h0REa+//nqMGjUqIiJ++tOfxhlnnBEREbNmzYqqqqqYMWNGREQsWrQoIiJWr14dBx54YMyaNSsiInbYYYeoq6tb9725zzU1NTF69OhYtmxZLF26NEaOHBlPPfVUvP7661FVVRVPP/10RESceOKJcdtttzX5e63//VITzXjGukbSGNdIzKyAMWPG8N5777FgwQJmzZpFv3792Hrrrfn2t7/Nbrvtxj//8z8zf/583n333Qbz+Otf/8ppp50GwG677cZumVGhd955J3vuuSdjxoxhzpw5PP/8842W529/+xvHHXccvXv3pk+fPhx//PE89thjQPtMWe9JGxuSPzWK5/YxqzjlnCrwxBNP5K677uKdd97h5JNP5vbbb6euro6ZM2fSo0cPhgwZUnAK+aa8/vrrXH311cyYMYN+/foxYcKEVuWT0x5T1rtG0pDssF9PjWJmeU4++WQmT57MXXfdxYknnsiHH37IlltuSY8ePZg2bRpvvPFGo9cfcMAB/Pa3vwVg9uzZPJu2gCxZsoTevXvTt29f3n33Xf70pz+tu6ahKezHjh3Lvffey/Lly/noo4+45557GDt2bBHvtnGukTTEzVpm1ohRo0axdOlSBg0axDbbbMOpp57KUUcdxa677kp1dTXDhw9v9PpzzjmHM844gxEjRjBixAj22itZamn33XdnzJgxDB8+nO222479969fsunss89m3LhxbLvttkybNm1d+p577smECRPYZ59k5fEvf/nLjBkzpt1WXizpNPKSxgG/IFnN8NcRcWXe8e2BW4DN03MuimQxLCRdTLKm+xrg3yNianPyLKRV08ifcw5cf32yf9VV8P/+X8uuN7OS8DTypdGWaeRLViORVAVMBD4L1AIzJE2JZFXEnO8Cd0bEdZJGkqymOCTdPwUYBWwLPCzpU+k1TeVZHN/6Fhx0UPIuyaGHFj17M7POopRNW/sAcyPiNQBJk4FjgOxDP4DN0v2+wIJ0/xhgckR8DLwuaW6aH83Iszh23DHZTj656FmbmXUmpexsHwS8lflcm6ZlXQacJqmWpDZyfhPXNidPM+vkStkk3xW19fdZ7lFb44FJETEYOBy4TVJRyiTpbEk1kmrq6uqKkaWZVYBevXqxaNEiB5MiiQgWLVpEr169Wp1HKZu25gPbZT4PTtOyzgTGAUTE45J6AQOauLapPEnzuwG4AZLO9tbdgplVmsGDB1NbW4v/QCyeXr16MXjw4FZfX8pAMgMYJmkoycP+FOBf8855EzgUmCRpBNALqAOmAL+V9DOSzvZhwJOAmpGnmXViPXr0YOjQoeUuhmWULJBExGpJ5wFTSYbq3hQRcyRdTjJ/yxTgG8CNki4g6XifkM7vMkfSnSSd6KuBcyNiDUChPEt1D2Zm1rSSvkdSKVr1HomZWRfX3PdIyt3ZbmZmHVyXqJFIqgMan/imYQOAhUUsjplZR7FDRAxs6qQuEUjaQlJNc6p2ZmZdlZu2zMysTRxIzMysTRxImnZDuQtgZlbJ3EdiZmZt4hqJmZm1iQOJmZm1iQNJAyTdJOk9SbPLXRYzs0rmQNKwSaQzE5uZWcMcSBoQEX8F3i93OczMKp0DiZmZtYkDiZmZtYkDiZmZtYkDiZmZtYkDSQMk3QE8DuwiqVbSmeUuk5lZJfIUKWZm1iaukZiZWZs4kJiZWZs4kJiZWZs4kJiZWZs4kJiZWZs4kJi1kqQ1kp7JbBcVMe8hnnnaOoru5S6AWQe2IiL2KHchzMrNNRKzIpM0T9KPJT0n6UlJO6fpQyQ9KulZSY9I2j5N30rSPZJmpdtn0qyqJN0oaY6kByVtnJ7/75KeT/OZXKbbNFvHgcSs9TbOa9o6OXPsw4jYFfgv4Jo07ZfALRGxG3A7cG2afi3wl4jYHdgTmJOmDwMmRsQoYDFwQpp+ETAmzeerpbo5s+bym+1mrSRpWUT0KZA+DzgkIl6T1AN4JyL6S1oIbBMRn6Tpb0fEAEl1wOCI+DiTxxDgoYgYln6+EOgREVdI+jOwDLgXuDcilpX4Vs0a5RqJWWlEA/st8XFmfw31fZpHABNJai8zJLmv08rKgcSsNE7O/Hw83f87cEq6fyrwWLr/CHAOgKQqSX0bylRSN2C7iJgGXAj0BTaoFZm1J/8lY9Z6G0t6JvP5zxGRGwLcT9KzJLWK8Wna+cDNkr4F1AFnpOlfA25IZ5heQxJU3m7gO6uA36TBRsC1EbG4aHdk1gruIzErsrSPpDoiFpa7LGbtwU1bZmbWJq6RmJlZm7hGYmZmbeJAYmZmbeJAYmZmbeJAYmZmbeJAYmZmbfL/AfW/h4Xg+PqtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "f = open('./result/ash_sand_1_16_vgg13_result.txt', 'a')\n",
    "\n",
    "print('loss_train: ' + str(loss_train))\n",
    "print('loss_val: ' + str(loss_val))\n",
    "print('acc_train: ' + str(acc_train))\n",
    "print('acc_val: ' + str(acc_val))\n",
    "f.write('loss_train: ' + str(loss_train) + '\\n')\n",
    "f.write('loss_val: ' + str(loss_val) + '\\n')\n",
    "f.write('acc_train: ' + str(acc_train) + '\\n')\n",
    "f.write('acc_val: ' + str(acc_val) + '\\n')\n",
    "f.close()\n",
    "\n",
    "# 绘制第一个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Loss\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(1, epochs + 1, 10.0))\n",
    "plt.plot(range(1,epochs + 1), loss_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), loss_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "# 绘制第二个图，在一幅图上画两条曲线\n",
    "plt.figure()\n",
    "plt.title(\"Predicted accuracy\",fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xticks(np.arange(1, epochs + 1, 10.0))\n",
    "plt.plot(range(1,epochs + 1), acc_train,color='r', linewidth = 3.0, label='train')\n",
    "plt.plot(range(1,epochs + 1), acc_val,color='b', linewidth = 3.0, label='validation')\n",
    "plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  保存混淆矩阵为excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook # xlsx\n",
    "\n",
    "def save(data, path):\n",
    "    # xlsx\n",
    "    workbook = Workbook()\n",
    "    booksheet = workbook.active  # 获取当前活跃的sheet,默认是第一个sheet\n",
    "    h = len(data) # 行数\n",
    "    l = len(data[0]) #列数\n",
    "    for i in range(h):\n",
    "        for j in range(l):\n",
    "            booksheet.cell(i+1, j+1).value = data[i][j]\n",
    "    workbook.save(path)\n",
    "\n",
    "save(best_matrix,'./result/ash_sand_1_16_vgg13_confusion_matrix.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====start test=====\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 6 6 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "labels: [3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "preds: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "labels: [6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [ 7  7  7  7  7  7  7  7  6  7  7  7  7  7  7  7  7  7  7 44  7  7  7  7\n",
      "  7  7  7  7  7  7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [6 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [ 7  7  7  7  7  7  7  7  7  6  6 44  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  6  7  7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "labels: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "preds: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 8 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [ 9  9  9 10 10  9  9 10  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10  9 10  9  9\n",
      "  9  9  9  9  9  9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "preds: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels: [ 9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [ 9  9  9  9  9  9  9  9  9  9 10 10 10  9 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10  9  9 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10  9 10 10  9  9 10 10 10 10 10 10\n",
      " 10 10 10 10  9 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10  9  9 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10  9  9 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10  9 10 10 10 10  8  8  8 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10  9  9 10 10 10  9 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10  9 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10  9  9 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "preds: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9  9  9 10  9\n",
      " 10 10 10  9 10 10]\n",
      "labels: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [ 9  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9  9 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11  6  6  6\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 10]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 43 10 10 11 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 10\n",
      " 10 11 10 10 10 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [10 11 11 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "preds: [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 20 12 12 12 12 12 12 12 12 12 12 20 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12]\n",
      "preds: [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 20 12 12 12 12]\n",
      "labels: [12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "preds: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 21 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 21 22 22 22 22 22 22 22 22\n",
      " 22 22 21 21 21 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 21 21 22 22 22 22 22 21 21 21 22 22 22 22 22 21 21 22 21 21 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 21 22 21 22 21 21 22 22 21\n",
      " 22 22 22 22 21 21]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [21 21 22 22 21 22 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 21 21\n",
      " 21 21 21 22 21 21]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [21 21 22 22 22 22 22 22 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 21 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 21]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 21 21 21 21 21 21 21 22 21\n",
      " 21 22 21 22 21 21]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 21 22 22 21 21 21 21 21 21 21 21 21 22 22 21 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22]\n",
      "labels: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [22 22 22 22 22 22 22 22 22 22 22 22 22 22 21 21 21 21 21 21 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23 23 23 23 23\n",
      " 23 24 23 23 23 24]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 24 24 24 24 24 23 24 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23 23\n",
      " 23 23 24 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [24 24 23 23 24 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 24 24 23 23 23 23 23 23 23 24 23 23 24 24\n",
      " 24 23 23 23 24 24]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 24 24 23 24 23 23 23 23 23 23 23 23 23 23 23 23 24 23 23 23 24 24\n",
      " 23 23 24 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 24 23 23 24 24 24 24 23 24 23 24 24 24 24 24 24 24 24 24 24 23 24\n",
      " 24 24 24 24 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [24 24 23 23 23 23 24 24 24 23 24 24 23 23 24 23 24 24 24 24 24 23 23 24\n",
      " 24 24 23 24 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [24 24 24 23 24 24 23 23 24 24 24 24 24 24 24 24 24 24 23 23 24 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 29 29 23 29 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 25  6  6 20 23 23 23 23 23 23 24 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 24 23 24 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24\n",
      " 24 23 23 24 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 24 23 23 24 24 23 23 23 24 24 23 24 24 24 24 23 24 24 23 24 24\n",
      " 24 24 23 24 23 24]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 24 23 23 23 23 24 23 24 23 23 24 24 24 24 24 24 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 24 23 23 23 23 24 24 24 24 24 24 24 23 24 23 23 24 24 24 24 24 24\n",
      " 24 24 24 23 23 24]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [24 24 24 24 24 24 24 24 24 23 24 24 24 24 24 24 24 24 24 24 23 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [24 23 24 24 24 24 24 24 24 24 24 24 23 24 24 23 24 23 23 23 24 23 23 23\n",
      " 24 23 24 24 24 24]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 24 23 23 23 23 23 23 23 23 23 23 23 24 24 23 24 24 24 24 24 23 23 24\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 24 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 24 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "preds: [23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 23 23 23\n",
      " 24 23 23 24 24 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 23 24 23 24 23 23 24 24 24 24 24 24 23 24 23 24 24 23 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 23 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 23 24 24 23 24 24 24 24 24 24 24 24 24 24 24 24 23 24 23 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 23 24 24 24 24\n",
      " 24 23 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 23 24 24 23 24 24 24\n",
      " 24 23 23 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 23 24 24 24 24 24 24 23 24 24 24 23 24 24 24 24 24 24 24 24 24 24 23\n",
      " 24 24 24 24 23 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 23 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 23 23 23\n",
      " 23 23 23 23 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [23 23 23 24 23 24 24 24 24 24 24 24 24 23 23 23 23 23 23 23 23 24 23 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [23 23 24 23 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23 23 23 23 23 23\n",
      " 24 23 23 23 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [23 23 23 24 23 24 23 23 23 23 23 23 23 23 23 23 24 24 23 23 23 23 23 23\n",
      " 23 23 23 23 24 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [23 23 23 23 23 23 23 24 24 24 23 23 24 23 24 23 24 24 23 23 24 23 24 23\n",
      " 23 23 24 23 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 23 23 24 23 24 24 23 23 23 23 24 23 23 23 23 23 23 24 23 23 23 24\n",
      " 23 23 23 23 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 23 23 24 23 24 24 23 23 23 24 24 24 24 24 24 24 24 24 24 24\n",
      " 23 23 23 23 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 23 23 23 23 23 24 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 23 23 24 24 23 23 24 24 23 23 24 23 23 24 23 23 23 23 23 24 23\n",
      " 24 24 24 24 24 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 23 24 24 24 24 24 24 23 23 23 23 23\n",
      " 23 23 23 24 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 23 24 24 24 23 24 23\n",
      " 23 23 23 23 23 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [23 24 23 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23 23 23 23 23 23 24\n",
      " 23 23 23 23 23 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [23 23 23 23 24 23 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23 23 23 23\n",
      " 23 23 24 23 23 23]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 24 24 24]\n",
      "preds: [23 23 23 23 23 23 23 24 23 23 23 23 23 23 23 23 23 23 24 23 23 23 23 23\n",
      " 23 23 23 23 23 24]\n",
      "labels: [24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [23 23 23 23 24 23 23 23 23 23 25 25 25 24 25 25 25 25 25 25 25 25 25 25\n",
      " 25 26 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [25 25 25 25 25 25 25 25 25 23 23 23 25 23 23 23 23 23 23 23 23 23 23 25\n",
      " 23 23 23 25 25 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 25 25 25 25 24 24 25 24 25 25 24 25 25 25 24 24 24 24 24 24 24\n",
      " 24 24 25 24 24 24]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 25 25 24 24 24 24 25 24 24 24 24 24 24 24 24 24 24 25 24 24 24 24 24\n",
      " 24 24 24 24 24 25]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [25 24 24 24 24 24 24 24 24 24 25 25 25 24 24 24 24 24 24 24 24 24 25 24\n",
      " 24 24 24 24 24 24]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [24 24 24 25 24 24 24 25 24 24 25 24 24 24 25 24 24 24 24 24 24 20 24 23\n",
      " 24 25 24 24 24 24]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25]\n",
      "preds: [24 24 24 24 24 24 25 24 24 24 24 24 24 24 24 24 24 25 24 24 24 24 24 24\n",
      " 24 24 24 24 25 24]\n",
      "labels: [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [24 24 24 24 24 24 24 24 24 25 24 24 24 24 24 24 24 24 24 24 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 27 27 27 25 27 26 27 27 27 27 27 27 27\n",
      " 27 27 27 26 26 27]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 27 26 27 27 26 27 27 27 26 27 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "preds: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 26 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 26\n",
      " 27 26 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 26 26 26 27 26 26 27 27 27 27 27 27 27 27 27 26 26 26 26\n",
      " 27 27 27 27 27 26]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 26 27 27 27 27 27 27 27 27 27 27 27 27 27 25 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 26 26 26 26 26 27 26 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 26 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 26 27 27\n",
      " 26 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [26 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 26 26 27 26 26 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 26 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 26 26 27 26 26 26 26 26 26 26 26 26 26 27 26 26 26 26 26\n",
      " 26 26 26 26 26 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 27 26 27 27 27 27 27 27\n",
      " 26 26 26 26 26 26]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [26 26 27 26 26 26 26 26 26 27 26 26 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 26 26 26 26 26 26 26 26 26 26 27 27 26 26 26 26 26 26\n",
      " 26 26 26 26 27 26]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [26 26 26 26 26 26 26 26 26 27 26 26 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 29 27 27 27 27 27 27 27 27 27 27 28 27 27 27 26 27 26 26 26 26 27 28\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 26 26]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 26 26 27 26 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 27 27 27]\n",
      "preds: [26 27 26 27 27 26 26 27 26 27 26 27 27 27 27 27 27 27 27 27 26 26 26 27\n",
      " 27 27 26 27 27 27]\n",
      "labels: [27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 24 24 28 24]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 24 24 24 24 28 24 24 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 26\n",
      " 28 28 28 28 28 26]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [26 28 26 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 25 28 28 28 28 28 28 28 28 28 28  6 28 28 28 28 28 28\n",
      " 28 28 28 28  6 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 25 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 26 26 28 26 26 28 28\n",
      " 26 28 26 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 26 26 26 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "preds: [28 28 28 28 28 23 28 39 37 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 28 28 28 28 28 28\n",
      " 28 29 28 28 28 28]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 28 28 28 28 28 29 28 28 28 28 31 28 31 28 28 31 29 31 28 28 29 28 28\n",
      " 28 28 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 29 28 26 28 26 28 28 28 29 28 28 28 28 28 29 28 28 28 28 29 29 29 29\n",
      " 26 26 26 29 26 26]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [26 29 26 29 29 26 29 29 26 26 26 26 29 29 26 29 26 29 29 31 31 29 28 26\n",
      " 29 29 29 28 31 28]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 31 31 31 31 29 31 31 28 28 28 28 28 28 28 28 29 28 31 31 31 31 26 31\n",
      " 26 26 26 29 26 30]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [31 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 28 28\n",
      " 28 28 28 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 28 29 29 29 29 29 29 29 29 28 28 28 29 29\n",
      " 29 29 29 28 28 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 24 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 28 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 28 28 28 29 29 28 28 29 29 29 29 29 29 28 28 28 28 28 28 29\n",
      " 28 28 28 29 29 28]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 28 29 29 29 29 29 29 29 29 29 28\n",
      " 29 28 28 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 28 28 28 29 29 29 29 29 29 29 29 31 29 29 31 29 29 31 29 29 29 29 29\n",
      " 31 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 26 29 29 29 26 26 29 29 29 26 31 26 26 26 26 26 31\n",
      " 31 29 31 31 31 31]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [31 31 31 31 31 31 29 29 31 31 31 31 31 31 31 31 31 31 29 29 31 31 31 31\n",
      " 31 31 31 28 26 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [31 31 31 31 31 31 26 31 31 31 29 31 31 26 31 31 26 31 31 31 31 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 28]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 28 28 28 28 29 29 29 29 28 29 28 28 28 29 28 29 28 29 29 28 28 29 28\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 28 28 28 28 28 28 28 29 29 29 29 28 29 28 28 28 28 28 28 28 28 29 28\n",
      " 28 28 28 28 28 28]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 28 28 29 29 28 29 28 28 29 28 31 28 31 29 31 29 31 31 31 31 29 31 28\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 28 28 29 29 28 28 28 28 29 28 28 29 29 29 29\n",
      " 26 29 26 26 29 26]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [26 26 26 26 26 26 26 26 26 29 29 31 31 26 31 26 26 28 26 29 29 29 26 28\n",
      " 16 16 26 28 28 28]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 26 29 26 26 26 26 26 26 26 26 26 26 29 26 29 26 26 29 29 30 29 29 29\n",
      " 29 29 29 29 28 31]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [28 28 28 29 29 29 29 22 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "preds: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [30 30 30 30 30 30 30 30 30 30 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 31 30 31 30 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 30 31 31 30 31 31 31 30 31 31 30 30 30 30 30 30 30 30 30 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 31 31 31 31 31 30 30 30 30 31 30 31 31 31 31 31 31 31 31 31 31 30 31\n",
      " 31 31 31 31 30 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 31 31 30 30 30 30 30 30 30 30 30 30 30 31 31 30 30 31 31\n",
      " 31 31 30 31 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 30 31 30 30 30 30 30 30 30 30 30 30 30 30 31 31 30 30 30 30 30 30 31\n",
      " 31 31 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 31 30 31 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 31 31 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 31 30 30 30 30 30 30 30 31 31 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 31 30 30 31 30 30 30 30 30 30 30 31 31 30 31 31 31 30 30 30\n",
      " 30 30 30 31 30 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 31 31 30 30 31 31 30 31 30 31 30 30 30 31 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 31 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 31 31 31 31 31 31 31 30 30 30 30 30 30 30 30 30 30 30 31 31 30\n",
      " 31 31 31 31 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 31 31 31 30 31 31 31 31 31 31 31 31 31 31 30 31 31 31 31 31 31 31 31\n",
      " 31 31 30 30 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 31 31 31 31 31 31 31 30 31 31 31 31 31 31 31 31 31 31 30 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 31 31 31 31 31 31 31 31 31 31 30 31 31 31 31 31 31 31 31 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 31 31 31 31 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 31 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 31 31 30 31\n",
      " 31 31 31 31 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 31 31 30 31 31 31 31 31 31 31 31 31 31 30 31 31 31 31 31 31 31 31 31\n",
      " 31 30 31 31 31 31]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 31 31 31]\n",
      "preds: [31 30 30 31 30 30 30 30 30 31 30 30 30 31 30 30 30 30 30 30 31 30 30 30\n",
      " 30 30 30 30 30 30]\n",
      "labels: [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [30 30 30 30 30 30 30 30 30 30 30 30 30 31 31 30 30 30 31 30 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "preds: [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 41  6]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [ 6 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 33 33 33]\n",
      "labels: [33 33 33 33 33 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [33 33 33 33 33 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 34 34 34]\n",
      "labels: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 32 32 35 32 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "preds: [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 21 36 36 21\n",
      " 21 21 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "labels: [36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 37 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 37 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 38 38\n",
      " 38 38 38 38 37 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 37 37 38 37 37 38 37 37 38 38 37 38 38 38 38 38 38 37 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 37 38 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 38 38 38 38 38 38\n",
      " 37 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 37 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 37 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 37 37 38 38 38 38 37 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 37 38 37 37 38 38 38 37 37 37 38 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 37 37 37 37 38 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 38 37 37 37 37 37 38 38 37 38 38 38 38 38 38 38 38 38 38 37 38 38\n",
      " 38 38 38 38 38 38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 38 38 38 38 38 38\n",
      " 38 37 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 37 38 38 38 38 38 38\n",
      " 38 38 38 38 37 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 37 37 37 37 37 37 37 37 37 37 38 37 37 37 37 37 37 37 37 37 37 38\n",
      " 37 37 37 37 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 37 37 37 37 37 37 37 38 37 38 38 38 38 38 38 38 38 37 38 38 38\n",
      " 38 38 37 38 37 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 37 37 37 37 37 38 37 37 37 37 37 37 37 37 37 37 38 37 37 37 37\n",
      " 37 37 37 38 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 37 37 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 37 37 37 38 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 38 37 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 37 37 37 38\n",
      " 37 37 37 37 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 37 37 37 37 37 38 37 37 37 37 38 37 37 37 37 37 37 37 37 37 37 38 37\n",
      " 37 37 37 37 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 38 37 37 37 37 37 37 37 37 37 37 38 37 37 37 37 37 37 37 37 37\n",
      " 37 38 37 37 37 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [37 37 37 37 37 37 38 37 37 37 37 37 37 37 37 37 37 38 37 37 37 37 37 37\n",
      " 38 37 37 38 38 37]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [41 41 38 41 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "preds: [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39]\n",
      "labels: [39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "labels: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 38 41 38\n",
      " 38 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 43 41 41 43]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [43 41 43 43 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 43 43 41\n",
      " 43 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "preds: [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n",
      " 41 41 41 41 41 41]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n",
      " 42 42 42 42 42 42]\n",
      "labels: [42 42 42 42 42 42 42 42 42 42 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [42 42 42 42 42 42 42 42 42 42 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 39 39 37\n",
      " 38 38 37 37 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 38 37 37 37 37 37 36 37 37 43 38 43 43 43 36 38 43 38 38 43 43 38 38\n",
      " 43 43 43 43 38 38]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [38 43 43 43 38 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 37 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [43 43 43 43 43 43 43 38 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 38 43 43 43 43 38 43 38 38 43\n",
      " 38 38 38 38 43 38]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [38 43 38 43 43 38 38 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 42 42 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43]\n",
      "labels: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "labels: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "preds: [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n",
      " 44 44 44 44 44 44]\n",
      "Test complete in 0h 10m 20s\n"
     ]
    }
   ],
   "source": [
    "# 开始测试\n",
    "since = time.time()\n",
    "model.eval()\n",
    "number = 0\n",
    "matrix2 = [[0 for i in range(1000)] for i in range(num_classes)]\n",
    "f = open('./result/ash_sand_1_16_vgg13_result.txt', 'a')\n",
    "print(\"=====start test=====\")\n",
    "f.write(\"=====start test=====\")\n",
    "\n",
    "# Iterate over data.\n",
    "for data in dataloders_test:\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "    print('labels: ' + str(labels.data.cpu().numpy()))\n",
    "    f.write('labels: ' + str(labels.data.cpu().numpy()) + '\\n')\n",
    "\n",
    "    # PyTorch更新至0.4.0后，将Variable和Tensor合并\n",
    "    if use_gpu:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    # 先将网络中的所有梯度置0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 网络的前向传播\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = loss_fn(outputs, labels)\n",
    "\n",
    "    # 得到模型预测该样本属于哪个类别的信息\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    print('preds: ' + str(preds.data.cpu().numpy()))\n",
    "    f.write('preds: ' + str(preds.data.cpu().numpy()) + '\\n')\n",
    "    for k in range(batch_size):\n",
    "        matrix2[labels.data.cpu().numpy()[k]][number] = preds.cpu().numpy()[k]\n",
    "        number += 1\n",
    "        if number == 1000:\n",
    "            number = 0\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Test complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, time_elapsed % 60))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 250, 300, 350, 400, 450, 500, 550, 600, 605, 610, 615, 620, 625, 630, 635, 640, 645, 650, 655, 660, 665, 670, 675, 680, 685, 690, 695, 700, 705, 710, 715, 720, 725, 730, 735, 740, 745, 750, 755, 760, 765, 770, 775, 780]\n",
      "0\n",
      " - 预测正确数量：997\n",
      " - 方差：269.18999999999994\n",
      "1\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "2\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "3\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "4\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "5\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "6\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "7\n",
      " - 预测正确数量：988\n",
      " - 方差：130.79840000000004\n",
      "8\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "9\n",
      " - 预测正确数量：994\n",
      " - 方差：0.1496\n",
      "10\n",
      " - 预测正确数量：961\n",
      " - 方差：1.1558999999999997\n",
      "11\n",
      " - 预测正确数量：984\n",
      " - 方差：65.514975\n",
      "12\n",
      " - 预测正确数量：997\n",
      " - 方差：4.785600000000001\n",
      "13\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "14\n",
      " - 预测正确数量：533\n",
      " - 方差：6.2227749999999995\n",
      "15\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "16\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "17\n",
      " - 预测正确数量：994\n",
      " - 方差：105.45497500000003\n",
      "18\n",
      " - 预测正确数量：283\n",
      " - 方差：175.95589999999999\n",
      "19\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "20\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "21\n",
      " - 预测正确数量：984\n",
      " - 方差：0.39359999999999995\n",
      "22\n",
      " - 预测正确数量：759\n",
      " - 方差：4.572975000000001\n",
      "23\n",
      " - 预测正确数量：793\n",
      " - 方差：68.73477500000001\n",
      "24\n",
      " - 预测正确数量：705\n",
      " - 方差：5.199375\n",
      "25\n",
      " - 预测正确数量：846\n",
      " - 方差：4.976775\n",
      "26\n",
      " - 预测正确数量：977\n",
      " - 方差：0.5639749999999999\n",
      "27\n",
      " - 预测正确数量：869\n",
      " - 方差：3.0467750000000007\n",
      "28\n",
      " - 预测正确数量：971\n",
      " - 方差：90.58277499999998\n",
      "29\n",
      " - 预测正确数量：686\n",
      " - 方差：36.4311\n",
      "30\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "31\n",
      " - 预测正确数量：221\n",
      " - 方差：4.303975\n",
      "32\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "33\n",
      " - 预测正确数量：997\n",
      " - 方差：102.68190000000003\n",
      "34\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "35\n",
      " - 预测正确数量：997\n",
      " - 方差：0.6729750000000002\n",
      "36\n",
      " - 预测正确数量：996\n",
      " - 方差：22.41\n",
      "37\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "38\n",
      " - 预测正确数量：739\n",
      " - 方差：5.5749749999999985\n",
      "39\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "40\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "41\n",
      " - 预测正确数量：989\n",
      " - 方差：1.4737749999999998\n",
      "42\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n",
      "43\n",
      " - 预测正确数量：956\n",
      " - 方差：28.809375\n",
      "44\n",
      " - 预测正确数量：1000\n",
      " - 方差：0.0\n"
     ]
    }
   ],
   "source": [
    "# conc 浓度\n",
    "matrix_conc = [[0 for i in range(1000)] for i in range(num_classes)]\n",
    "concentration = []\n",
    "density = 200\n",
    "while True:\n",
    "    concentration.append(density)\n",
    "    if density == 780:\n",
    "        break\n",
    "    if density < 600:\n",
    "        density += 50\n",
    "    else:\n",
    "        density += 5\n",
    "print(concentration)\n",
    "for x in range(num_classes):\n",
    "    for y in range(1000):\n",
    "        matrix_conc[x][y] = concentration[matrix2[x][y]]  # matrix2:0-44; concentration:200-780\n",
    "\n",
    "for label in range(num_classes):\n",
    "    count = 0\n",
    "    print(label)\n",
    "    for k in range(1000):\n",
    "        if matrix2[label][k] == label:\n",
    "            count += 1\n",
    "    print(\" - 预测正确数量：\" + str(count))\n",
    "        # 方差\n",
    "    var = np.var(matrix_conc[label])\n",
    "    print(\" - 方差：\" + str(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均方差：25.32571611111111\n"
     ]
    }
   ],
   "source": [
    "var_sum = 0\n",
    "for label in range(num_classes):\n",
    "    var_sum += np.var(matrix_conc[label])\n",
    "var_ave = var_sum / num_classes\n",
    "print(\"平均方差：\" + str(var_ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集正确率：0.9159111111111111\n"
     ]
    }
   ],
   "source": [
    "acc_count = 0\n",
    "for label in range(num_classes):\n",
    "    for k in range(1000):\n",
    "        if matrix2[label][k] == label:\n",
    "            acc_count += 1\n",
    "print(\"测试集正确率：\" + str(acc_count/len(image_datasets_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75%-78%浓度平均方差：0.7968472222222223\n"
     ]
    }
   ],
   "source": [
    "# 75%-78%浓度方差\n",
    "var_sum2 = 0\n",
    "for label in range(38, 45):\n",
    "    var_sum2 += np.var(matrix_conc[label])\n",
    "var_ave2 = var_sum2 / num_classes\n",
    "print(\"75%-78%浓度平均方差：\" + str(var_ave2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看波动性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x2880 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "colors = ['#F0F8FF', '#FAEBD7', '#00FFFF', '#7FFFD4', '#F0FFFF', '#F5F5DC', '#FFE4C4', '#000000', '#FFEBCD', '#0000FF', '#8A2BE2', '#A52A2A', '#DEB887', '#5F9EA0', '#7FFF00', '#D2691E', '#FF7F50', '#6495ED', '#FFF8DC', '#DC143C', '#00FFFF', '#00008B', '#008B8B', '#B8860B', '#A9A9A9', '#006400', '#BDB76B', '#8B008B', '#556B2F', '#FF8C00', '#9932CC', '#8B0000', '#E9967A', '#8FBC8F', '#483D8B', '#2F4F4F', '#00CED1', '#9400D3', '#FF1493', '#00BFFF', '#696969', '#1E90FF', '#B22222', '#FFFAF0', '#228B22']\n",
    "\n",
    "plt.figure(figsize=(10,40))\n",
    "plt.title('Test',fontsize=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"predict\")\n",
    "plt.xticks(np.arange(0, 1000, 50))\n",
    "for label in range(num_classes):\n",
    "    plt.plot(range(1000), matrix_conc[label],color=colors[label], label=str(concentration[label]))\n",
    "    plt.legend()  # 设置图例和其中的文本的显示\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
