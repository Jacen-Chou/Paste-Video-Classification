1. 稠密光流的学习
2. 均匀度判断
3. 将现有48类图像做下densenet

#### 20190125 寒假前讨论记录

纯尾砂膏体的图像分类做出来分类正确率是97%

正确率这么高，怀疑是因为各个浓度的样本集各自具有高度的一致性，也就是
每个样本集内部的样本很相似，不同样本集容易区分。所以需要给样本集内部
的样本增加随机量

下一步思路：
+ 训练集和验证集增加随机量（调整亮度、对比度，加噪声，缩放，切割），注意
验证集要事先存好，不能random，避免每次验证的图像不一样，带来误差
+ 验证模型迁移性（用一种膏体的模型去跑另外一种膏体）
+ 为满足工业要求：生产稳定性、速度（每个视频采集固定2min，每秒25帧，
全部送入网络，看得到的预测浓度是不是稳定(stable)，分析两点:1.波动性;2.方差）


#### 20190225 跟师兄讨论

##### 目前进展

1. 发现模型迁移性不好
2. 发现生产稳定性还行，但不是很稳定：http://202.204.62.145:8888/notebooks/ZhouJiacheng/paste_video_classification/second_experiment/images_stability_test.ipynb

##### 师兄指导

1. 做验证生产稳定性实验时候，测试集错误，和训练集有重合，重新再做一次实验

    + 每个视频5min，按照下面要求分割：

        ```
        2min - train 训练集
        1min - validation 验证集
        2min - test 测试集
        6:2:2
        1500
        500
        500
        ```
        
        用验证集求Loss，把验证集中最低的Loss的模型参数保存下来
        
        K-fold K折交叉验证
        
        求方差，浓度按去掉百分号的算，如75%则在计算方差时，用75
        
        尤其是在75%-80%浓度求方差
    + ![](https://i.loli.net/2019/02/25/5c73b48f6c583.jpg)
    
        优化思路：取5个细节，和一个整体缩放，把总共6个112*112*512堆起来，再卷积和分类
        
        进阶：fine-grained


2. 论文及顶会讲解

    + 论文查找：谷歌学术 https://scholar.google.com/
      选择2015年以来的
    + 顶会：https://www.ccf.org.cn/xspj/rgzn/
    + 要发顶会的话，则必须要在公有数据集上验证
    + 尽量别发EI文章

#### 20190305 跟师兄讨论
1. 计算测试集正确率
2. 查找除了方差以外的其他数据稳定性方法，如最大最小差值，差分绝对值之和等
   “中午去图书馆找了找应用统计学里关于离散程度的描述，除了标准差和方差，还有
   很多，如极差range，平均离差 mean deviation，四分位数极差（interquantile range），
   箱线图，偏度，峰度，离散系数（标准差除以平均值），标准分数”
3. 近期去设计如何解决高分辨率图像分类的实验方案

#### 20190307 跟师兄讨论
1. 用新的256*256测试集跑vgg13网络
2. 在1920*1080测试集上滑动窗口224*224，送入网络检测
3. 调整学习率（1）VGG，step,（2）VGG cosin,论文:《Bag of Tricks for Image Classification with Convolutional Neural Networks》
4. 加入SPPNet,论文:《Spatial Pyramid Pooling in Deep Convolutional Networks for visual Recognition》
5. 验证集正确率大于训练集正确率，解决此问题。尝试：把训练集和验证集的预处理方式设置成一样
6. 建议用一张卡跑，可以同时进行多个实验
7. 修改transforms.Normalize参数，mean（平均值）和std（标准差）都自己算，根据1920*1080的原图来算
    以RGB中的R为例，把所有R通道的值加起来，再求'mean=sum÷1920÷1080÷图片数量', 'std=标准差'
    https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=normalize#torchvision.transforms.Normalize
    参考博客代码：https://blog.csdn.net/weixin_38533896/article/details/85951903
    ```
    计算结果：
    R_mean: 0.395985
    G_mean: 0.434179
    B_mean: 0.434528
    R_std: 0.054672
    G_std: 0.052740
    B_std: 0.054149
    ```
8. 增加数据集数量，要求原图1920*1080，训练集3000，验证集1000，测试集1000，按视频时间依次顺序取，最开始一段作训练集，
    中间一段作验证集，最后一段作测试集，不再随机，一共3min20s
    （后修改为：# 按视频时间依次顺序取，最开始一段作训练集，后面随机取验证集和测试集，一共3min20s）
9. 更改学习率设置，初步打算每10epochs降低，除以10
10. 除了vgg13，再跑ResNet、DenseNet，作比较，取效果最好的网络

#### 20190320 师兄指导

给了一个网络结构，尝试实现并查看效果

#### 20190327 材料基因组组会

1. 查看63%、67.5%视频样本，有没有问题
2. 做下一步实验之前，要先验证以下两个问题：
    1. 证明1920*1080,batch_size=1,用一张显卡，vgg13_bn跑不了（编写代码，验证内存会溢出）
    2. 证明测试集随机裁一块224*224，可能会裁到螺旋桨，导致正确率降低（用随机裁的方式，编写代码，验证正确率低的结果）
3. 用这个网络：
   ![](https://i.loli.net/2019/03/27/5c9b38e3a312a.jpg)
   学习Res Block， 可以用多个block
   按如下表格，做对比实验：
   ![](https://i.loli.net/2019/03/27/5c9b39320a446.jpg)

#### 20190401 师兄指导

重写forward方法，来提取某一层得到的结果(指导博客：https://www.jianshu.com/p/0a23db1df55a)

#### 20190508 材料基因组组会

师兄指导，跟班老师汇报的时候，该怎么讲：
1. 背景介绍向师兄学习怎么讲：矿山矿体开采过程中，因为矿石处在地下，所以将矿石开采出来的时候，地下会出现采空区，因此需要物质回填到采空区，
   这种物质就是膏体。在矿石开采过程中，会留下很多尾砂、淬渣，工业中将尾砂、淬渣等与胶结剂、水进行混合，得到具有一定稳定性、可塑性的牙膏状的浆体，
   再将这种浆体在外加力(泵压)或重力作用下以柱塞流的形态，用管道输送到地下采空区完成充填。在这个过程中，膏体的浓度至关重要，如果浓度过高，会导致
   失去流动性，无法输送进地下；而浓度过低，则可能造成填充效果不理想，不够结实。因此膏体浓度的测量十分重要。

2. 全图缩放1920*1080 --> 224*224：能够提取到整体图像的轮廓特征，但是会丧失原图分辨率，失去膏体细粒度信息，并且会放大拍摄角度、光照等
  对分类效果的干扰，可能导致模型提取出来的图像特征并不完全是膏体特征。
3. 随机裁剪224*224：保持了原图的分辨率，能够提取出膏体的细粒度信息，但是有可能会裁剪到螺旋桨叶片，这就不是膏体了，因此裁剪会带来误差。
   总体评价来说，对于工业应用，随机裁剪的处理方式更加适合。
4. 因此想到了模型融合的方式，来减小裁剪到螺旋桨叶片对分类精确度的影响。

师兄要求跟班老师汇报的时候：
1. 每种基础模型至少有一个
2. 输出结果融合、高层特征图融合都要有
3. 不能停留在理论阶段，一定要做出结果，要验证融合有效果
4. 可以采用小数据集

#### 20190514 师兄指导

1. 模型融合：使用随机裁剪训练，使用全图裁剪求平均，及五张图求平均对比，准确率和时延;
2. 缩放，随机裁剪训练过程中加入亮度增强，查看结果正确率